{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r w2v_model\n",
    "# from word2vec.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments=pd.read_csv(\"arguments-test.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=pd.read_csv(\"labels-test.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# check for duplicate rows\n",
    "duplicate_rows=arguments.duplicated().sum()\n",
    "print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the two sets\n",
    "test_set = pd.concat([arguments, labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    # set lowercase\n",
    "    processed_text = [token.text.lower()for token in doc]\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Conclusion</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Premise</th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Self-direction: thought</th>\n",
       "      <th>Self-direction: action</th>\n",
       "      <th>Stimulation</th>\n",
       "      <th>Hedonism</th>\n",
       "      <th>Achievement</th>\n",
       "      <th>...</th>\n",
       "      <th>Conformity: rules</th>\n",
       "      <th>Conformity: interpersonal</th>\n",
       "      <th>Humility</th>\n",
       "      <th>Benevolence: caring</th>\n",
       "      <th>Benevolence: dependability</th>\n",
       "      <th>Universalism: concern</th>\n",
       "      <th>Universalism: nature</th>\n",
       "      <th>Universalism: tolerance</th>\n",
       "      <th>Universalism: objectivity</th>\n",
       "      <th>premise_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A26004</td>\n",
       "      <td>We should end affirmative action</td>\n",
       "      <td>against</td>\n",
       "      <td>affirmative action helps with employment equity.</td>\n",
       "      <td>A26004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[affirmative, action, helps, with, employment,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A26010</td>\n",
       "      <td>We should end affirmative action</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>affirmative action can be considered discrimin...</td>\n",
       "      <td>A26010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[affirmative, action, can, be, considered, dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A26016</td>\n",
       "      <td>We should ban naturopathy</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>naturopathy is very dangerous for the most vul...</td>\n",
       "      <td>A26016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[naturopathy, is, very, dangerous, for, the, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A26024</td>\n",
       "      <td>We should prohibit women in combat</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>women shouldn't be in combat because they aren...</td>\n",
       "      <td>A26024</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[women, should, n't, be, in, combat, because, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A26026</td>\n",
       "      <td>We should ban naturopathy</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>once eradicated illnesses are returning due to...</td>\n",
       "      <td>A26026</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[once, eradicated, illnesses, are, returning, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argument ID                          Conclusion       Stance   \n",
       "0      A26004    We should end affirmative action      against  \\\n",
       "1      A26010    We should end affirmative action  in favor of   \n",
       "2      A26016           We should ban naturopathy  in favor of   \n",
       "3      A26024  We should prohibit women in combat  in favor of   \n",
       "4      A26026           We should ban naturopathy  in favor of   \n",
       "\n",
       "                                             Premise Argument ID   \n",
       "0   affirmative action helps with employment equity.      A26004  \\\n",
       "1  affirmative action can be considered discrimin...      A26010   \n",
       "2  naturopathy is very dangerous for the most vul...      A26016   \n",
       "3  women shouldn't be in combat because they aren...      A26024   \n",
       "4  once eradicated illnesses are returning due to...      A26026   \n",
       "\n",
       "   Self-direction: thought  Self-direction: action  Stimulation  Hedonism   \n",
       "0                        0                       0            0         0  \\\n",
       "1                        0                       0            0         0   \n",
       "2                        0                       0            0         0   \n",
       "3                        0                       0            0         0   \n",
       "4                        0                       0            0         0   \n",
       "\n",
       "   Achievement  ...  Conformity: rules  Conformity: interpersonal  Humility   \n",
       "0            1  ...                  0                          0         0  \\\n",
       "1            1  ...                  0                          0         0   \n",
       "2            1  ...                  0                          0         0   \n",
       "3            1  ...                  0                          0         0   \n",
       "4            1  ...                  0                          0         0   \n",
       "\n",
       "   Benevolence: caring  Benevolence: dependability  Universalism: concern   \n",
       "0                    0                           0                      1  \\\n",
       "1                    0                           0                      1   \n",
       "2                    0                           1                      1   \n",
       "3                    0                           0                      0   \n",
       "4                    1                           1                      0   \n",
       "\n",
       "   Universalism: nature  Universalism: tolerance  Universalism: objectivity   \n",
       "0                     0                        1                          0  \\\n",
       "1                     0                        1                          1   \n",
       "2                     0                        0                          0   \n",
       "3                     0                        0                          0   \n",
       "4                     0                        0                          0   \n",
       "\n",
       "                                   premise_tokenized  \n",
       "0  [affirmative, action, helps, with, employment,...  \n",
       "1  [affirmative, action, can, be, considered, dis...  \n",
       "2  [naturopathy, is, very, dangerous, for, the, m...  \n",
       "3  [women, should, n't, be, in, combat, because, ...  \n",
       "4  [once, eradicated, illnesses, are, returning, ...  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we pre-process the arguments with spacy\n",
    "test_set[\"premise_tokenized\"] = test_set[\"Premise\"].apply(preprocess_text)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we generalize labels according to the following dictionary\n",
    "general_dictionary={\n",
    "    \"Self-direction: thought\":\"Openness to change\",\n",
    "    \"Self-direction: action\":\"Openness to change\",\n",
    "    \"Stimulation\":\"Openness to change\",\n",
    "    \"Hedonism\":\"Openness to change\",\n",
    "    \"Achievement\":\"Self-Enhancement\",\n",
    "    \"Power: dominance\":\"Self-Enhancement\",\n",
    "    \"Power: resources\":\"Self-Enhancement\",\n",
    "    \"Face\":\"Self-Enhancement\",\n",
    "    \"Security: personal\":\"Conservation\",\n",
    "    \"Security: societal\":\"Conservation\",\n",
    "    \"Tradition\":\"Conservation\",\n",
    "    \"Conformity: rules\":\"Conservation\",\n",
    "    \"Conformity: interpersonal\":\"Conservation\",\n",
    "    \"Humility\":\"Conservation\",\n",
    "    \"Benevolence: caring\":\"Self-Transcendence\",\n",
    "    \"Benevolence: dependability\":\"Self-Transcendence\",\n",
    "    \"Universalism: concern\":\"Self-Transcendence\",\n",
    "    \"Universalism: nature\":\"Self-Transcendence\",\n",
    "    \"Universalism: tolerance\":\"Self-Transcendence\",\n",
    "    \"Universalism: objectivity\":\"Self-Transcendence\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set[\"Openness to change\"]=test_set[\"Self-direction: thought\"]+test_set[\"Self-direction: action\"]+test_set[\"Stimulation\"]+test_set[\"Hedonism\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set[\"Self-Enhancement\"]=test_set[\"Achievement\"]+test_set[\"Power: dominance\"]+test_set[\"Power: resources\"]+test_set[\"Face\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set[\"Conservation\"]=test_set[\"Security: personal\"]+test_set[\"Security: societal\"]+test_set[\"Tradition\"]+test_set[\"Conformity: rules\"]+test_set[\"Conformity: interpersonal\"]+test_set[\"Humility\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set[\"Self-Transcendence\"]=test_set[\"Benevolence: caring\"]+test_set[\"Benevolence: dependability\"]+test_set[\"Universalism: concern\"]+test_set[\"Universalism: nature\"]+test_set[\"Universalism: tolerance\"]+test_set[\"Universalism: objectivity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now drop the original features\n",
    "for key in general_dictionary:\n",
    "    if key!=general_dictionary[key]:\n",
    "        test_set=test_set.drop(key, axis=1)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Conclusion</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Premise</th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>premise_tokenized</th>\n",
       "      <th>Openness to change</th>\n",
       "      <th>Self-Enhancement</th>\n",
       "      <th>Conservation</th>\n",
       "      <th>Self-Transcendence</th>\n",
       "      <th>general_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A26004</td>\n",
       "      <td>We should end affirmative action</td>\n",
       "      <td>against</td>\n",
       "      <td>affirmative action helps with employment equity.</td>\n",
       "      <td>A26004</td>\n",
       "      <td>[affirmative, action, helps, with, employment,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1, 1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A26010</td>\n",
       "      <td>We should end affirmative action</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>affirmative action can be considered discrimin...</td>\n",
       "      <td>A26010</td>\n",
       "      <td>[affirmative, action, can, be, considered, dis...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 1, 0, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A26016</td>\n",
       "      <td>We should ban naturopathy</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>naturopathy is very dangerous for the most vul...</td>\n",
       "      <td>A26016</td>\n",
       "      <td>[naturopathy, is, very, dangerous, for, the, m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1, 1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A26024</td>\n",
       "      <td>We should prohibit women in combat</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>women shouldn't be in combat because they aren...</td>\n",
       "      <td>A26024</td>\n",
       "      <td>[women, should, n't, be, in, combat, because, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A26026</td>\n",
       "      <td>We should ban naturopathy</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>once eradicated illnesses are returning due to...</td>\n",
       "      <td>A26026</td>\n",
       "      <td>[once, eradicated, illnesses, are, returning, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1, 2, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>E07272</td>\n",
       "      <td>We should end mass migration together.</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>Mass migration is a phenomenon that causes dam...</td>\n",
       "      <td>E07272</td>\n",
       "      <td>[mass, migration, is, a, phenomenon, that, cau...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>E07273</td>\n",
       "      <td>We should end mass migration together.</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>Mass migration hurts the migrants themselves i...</td>\n",
       "      <td>E07273</td>\n",
       "      <td>[mass, migration, hurts, the, migrants, themse...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>E07275</td>\n",
       "      <td>We should consider Russian interests in the EU...</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>It is neither in the interests of the EU nor R...</td>\n",
       "      <td>E07275</td>\n",
       "      <td>[it, is, neither, in, the, interests, of, the,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>E07280</td>\n",
       "      <td>We should adopt an extension of the applicatio...</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>Foreign Policy at the EU level should be based...</td>\n",
       "      <td>E07280</td>\n",
       "      <td>[foreign, policy, at, the, eu, level, should, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 0, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>E08023</td>\n",
       "      <td>We should abolish covid digital pass</td>\n",
       "      <td>against</td>\n",
       "      <td>You owe the fact that you can drink your coffe...</td>\n",
       "      <td>E08023</td>\n",
       "      <td>[you, owe, the, fact, that, you, can, drink, y...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 4, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1576 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Argument ID                                         Conclusion   \n",
       "0         A26004                   We should end affirmative action  \\\n",
       "1         A26010                   We should end affirmative action   \n",
       "2         A26016                          We should ban naturopathy   \n",
       "3         A26024                 We should prohibit women in combat   \n",
       "4         A26026                          We should ban naturopathy   \n",
       "...          ...                                                ...   \n",
       "1571      E07272             We should end mass migration together.   \n",
       "1572      E07273             We should end mass migration together.   \n",
       "1573      E07275  We should consider Russian interests in the EU...   \n",
       "1574      E07280  We should adopt an extension of the applicatio...   \n",
       "1575      E08023               We should abolish covid digital pass   \n",
       "\n",
       "           Stance                                            Premise   \n",
       "0         against   affirmative action helps with employment equity.  \\\n",
       "1     in favor of  affirmative action can be considered discrimin...   \n",
       "2     in favor of  naturopathy is very dangerous for the most vul...   \n",
       "3     in favor of  women shouldn't be in combat because they aren...   \n",
       "4     in favor of  once eradicated illnesses are returning due to...   \n",
       "...           ...                                                ...   \n",
       "1571  in favor of  Mass migration is a phenomenon that causes dam...   \n",
       "1572  in favor of  Mass migration hurts the migrants themselves i...   \n",
       "1573  in favor of  It is neither in the interests of the EU nor R...   \n",
       "1574  in favor of  Foreign Policy at the EU level should be based...   \n",
       "1575      against  You owe the fact that you can drink your coffe...   \n",
       "\n",
       "     Argument ID                                  premise_tokenized   \n",
       "0         A26004  [affirmative, action, helps, with, employment,...  \\\n",
       "1         A26010  [affirmative, action, can, be, considered, dis...   \n",
       "2         A26016  [naturopathy, is, very, dangerous, for, the, m...   \n",
       "3         A26024  [women, should, n't, be, in, combat, because, ...   \n",
       "4         A26026  [once, eradicated, illnesses, are, returning, ...   \n",
       "...          ...                                                ...   \n",
       "1571      E07272  [mass, migration, is, a, phenomenon, that, cau...   \n",
       "1572      E07273  [mass, migration, hurts, the, migrants, themse...   \n",
       "1573      E07275  [it, is, neither, in, the, interests, of, the,...   \n",
       "1574      E07280  [foreign, policy, at, the, eu, level, should, ...   \n",
       "1575      E08023  [you, owe, the, fact, that, you, can, drink, y...   \n",
       "\n",
       "      Openness to change  Self-Enhancement  Conservation  Self-Transcendence   \n",
       "0                      0                 1             1                   2  \\\n",
       "1                      0                 1             0                   3   \n",
       "2                      0                 1             1                   2   \n",
       "3                      0                 1             0                   0   \n",
       "4                      0                 1             2                   2   \n",
       "...                  ...               ...           ...                 ...   \n",
       "1571                   0                 0             1                   0   \n",
       "1572                   0                 0             1                   2   \n",
       "1573                   1                 1             1                   2   \n",
       "1574                   1                 1             0                   2   \n",
       "1575                   0                 0             4                   3   \n",
       "\n",
       "     general_label  \n",
       "0     [0, 1, 1, 2]  \n",
       "1     [0, 1, 0, 3]  \n",
       "2     [0, 1, 1, 2]  \n",
       "3     [0, 1, 0, 0]  \n",
       "4     [0, 1, 2, 2]  \n",
       "...            ...  \n",
       "1571  [0, 0, 1, 0]  \n",
       "1572  [0, 0, 1, 2]  \n",
       "1573  [1, 1, 1, 2]  \n",
       "1574  [1, 1, 0, 2]  \n",
       "1575  [0, 0, 4, 3]  \n",
       "\n",
       "[1576 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the generalized label columns and store them in a separate DataFrame\n",
    "label_columns=test_set[[\n",
    "\"Openness to change\",\n",
    "\"Self-Enhancement\",\n",
    "\"Conservation\",\n",
    "\"Self-Transcendence\"]]\n",
    "\n",
    "# convert the label columns to a multi-class format (one-hot encoding)\n",
    "test_set['general_label'] = label_columns.apply(lambda row: row.to_list(), axis=1)\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranform the labels in binary encoding\n",
    "binary_labels = []\n",
    "\n",
    "for label in test_set[\"general_label\"]:\n",
    "    new_label = []\n",
    "\n",
    "    for value in label:\n",
    "        if value > 0:\n",
    "            new_label.append(1)\n",
    "        else:\n",
    "            new_label.append(0)\n",
    "\n",
    "    binary_labels.append(new_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the vectors from the w2v model for the validation set\n",
    "test_w2v_vectors = []\n",
    "for arg in test_set[\"premise_tokenized\"]:\n",
    "    seq = []\n",
    "\n",
    "    for word in arg:\n",
    "        if word in w2v_model.wv:\n",
    "            seq.append(w2v_model.wv[word])\n",
    "        else:\n",
    "            seq.append(np.zeros(150)) #if the word is not in the model i append an array of zeros equal to the embeddings dimension, that is 150\n",
    "        \n",
    "    test_w2v_vectors.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_w2v_vectors = [np.array(arg) for arg in test_w2v_vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(binary_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now go on with the training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r input_w2v\n",
    "# from undersampling_w2v.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r df\n",
    "# from undersampling_w2v.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r y_val\n",
    "# from preprocessing_validation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r val_w2v_vectors\n",
    "# from preprocessing_validation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163 147 163\n"
     ]
    }
   ],
   "source": [
    "# this max_len variable will help pad the train and validation set and test set\n",
    "max_len_val = max(len(arg) for arg in val_w2v_vectors)\n",
    "max_len_train = max(len(arg) for arg in input_w2v)\n",
    "max_len_test = max(len(arg) for arg in test_w2v_vectors)  \n",
    "print(max_len_val, max_len_train, max_len_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we choose the highest max_len so that we don't lose information\n",
    "max_len = 163"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we pad the train and validation set and create the labels for training\n",
    "X_train = pad_sequences(input_w2v, maxlen=max_len)\n",
    "X_val = pad_sequences(val_w2v_vectors, max_len)\n",
    "X_test = pad_sequences(test_w2v_vectors, max_len)\n",
    "train_labels = [row.labels for id, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to implement our classification problem (that is multi-class and multi-label) we will use binary crossentropy with a sigmoid activation\n",
    "# function in the last layer: now we transform pur probabilities labels in \"binary\" labels.\n",
    "y_train = []\n",
    "for label in train_labels:\n",
    "    new_label = []\n",
    "    for value in label:\n",
    "        if value > 0:\n",
    "            new_label.append(1)\n",
    "        else:\n",
    "            new_label.append(0)\n",
    "    y_train.append(new_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we tranform our y_train in an array\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 150 150\n"
     ]
    }
   ],
   "source": [
    "# we make sure the train, test and validation set have the same embedding dimension and we set it as the variable \"emb_len\"\n",
    "print(len(X_train[0][0]), len(X_val[0][0]), len(X_test[0][0]))\n",
    "emb_len = len(X_val[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using early stopping to make sure we don't overfit the small dataset\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first define a function that will be a scheduler and will permit to our learning rate to decrease over epochs\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 6:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\cate9\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "44/44 [==============================] - 41s 763ms/step - loss: 0.7100 - accuracy: 0.1964 - val_loss: 0.6826 - val_accuracy: 0.3058 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "44/44 [==============================] - 29s 672ms/step - loss: 0.6700 - accuracy: 0.1520 - val_loss: 0.6816 - val_accuracy: 0.3008 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "44/44 [==============================] - 38s 872ms/step - loss: 0.6680 - accuracy: 0.1368 - val_loss: 0.6795 - val_accuracy: 0.2893 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "44/44 [==============================] - 37s 851ms/step - loss: 0.6588 - accuracy: 0.1224 - val_loss: 0.6769 - val_accuracy: 0.3109 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "44/44 [==============================] - 38s 858ms/step - loss: 0.6547 - accuracy: 0.1394 - val_loss: 0.6743 - val_accuracy: 0.3058 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "44/44 [==============================] - 39s 881ms/step - loss: 0.6570 - accuracy: 0.1173 - val_loss: 0.6748 - val_accuracy: 0.2976 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "44/44 [==============================] - 39s 883ms/step - loss: 0.6543 - accuracy: 0.1004 - val_loss: 0.6740 - val_accuracy: 0.1942 - lr: 9.0484e-04\n",
      "Epoch 8/50\n",
      "44/44 [==============================] - 39s 895ms/step - loss: 0.6499 - accuracy: 0.1134 - val_loss: 0.6736 - val_accuracy: 0.2107 - lr: 9.0484e-04\n",
      "Epoch 9/50\n",
      "44/44 [==============================] - 34s 778ms/step - loss: 0.6480 - accuracy: 0.1076 - val_loss: 0.6738 - val_accuracy: 0.2405 - lr: 9.0484e-04\n",
      "Epoch 10/50\n",
      "44/44 [==============================] - 45s 1s/step - loss: 0.6452 - accuracy: 0.1159 - val_loss: 0.6737 - val_accuracy: 0.2113 - lr: 9.0484e-04\n",
      "Epoch 11/50\n",
      "44/44 [==============================] - 46s 1s/step - loss: 0.6456 - accuracy: 0.1011 - val_loss: 0.6715 - val_accuracy: 0.1593 - lr: 9.0484e-04\n",
      "Epoch 12/50\n",
      "44/44 [==============================] - 47s 1s/step - loss: 0.6430 - accuracy: 0.1408 - val_loss: 0.6724 - val_accuracy: 0.2030 - lr: 9.0484e-04\n",
      "Epoch 13/50\n",
      "44/44 [==============================] - 48s 1s/step - loss: 0.6401 - accuracy: 0.1397 - val_loss: 0.6728 - val_accuracy: 0.1472 - lr: 9.0484e-04\n",
      "Epoch 14/50\n",
      "44/44 [==============================] - 46s 1s/step - loss: 0.6384 - accuracy: 0.1484 - val_loss: 0.6729 - val_accuracy: 0.1675 - lr: 9.0484e-04\n",
      "Epoch 15/50\n",
      "44/44 [==============================] - 38s 873ms/step - loss: 0.6334 - accuracy: 0.1758 - val_loss: 0.6726 - val_accuracy: 0.1155 - lr: 9.0484e-04\n",
      "Epoch 16/50\n",
      "44/44 [==============================] - 42s 963ms/step - loss: 0.6321 - accuracy: 0.2094 - val_loss: 0.6763 - val_accuracy: 0.1263 - lr: 9.0484e-04\n",
      "Epoch 17/50\n",
      "44/44 [==============================] - 39s 900ms/step - loss: 0.6320 - accuracy: 0.1910 - val_loss: 0.6730 - val_accuracy: 0.1428 - lr: 9.0484e-04\n",
      "Epoch 18/50\n",
      "44/44 [==============================] - 39s 890ms/step - loss: 0.6296 - accuracy: 0.2430 - val_loss: 0.6751 - val_accuracy: 0.1110 - lr: 9.0484e-04\n",
      "Epoch 19/50\n",
      "44/44 [==============================] - 39s 880ms/step - loss: 0.6256 - accuracy: 0.2296 - val_loss: 0.6799 - val_accuracy: 0.1117 - lr: 9.0484e-04\n",
      "Epoch 20/50\n",
      "44/44 [==============================] - 38s 869ms/step - loss: 0.6269 - accuracy: 0.2823 - val_loss: 0.6800 - val_accuracy: 0.0964 - lr: 9.0484e-04\n",
      "Epoch 21/50\n",
      "44/44 [==============================] - ETA: 0s - loss: 0.6230 - accuracy: 0.2592Restoring model weights from the end of the best epoch: 11.\n",
      "44/44 [==============================] - 38s 871ms/step - loss: 0.6230 - accuracy: 0.2592 - val_loss: 0.6827 - val_accuracy: 0.1079 - lr: 9.0484e-04\n",
      "Epoch 21: early stopping\n",
      "50/50 [==============================] - 6s 105ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      1.00      0.46       474\n",
      "           1       0.40      1.00      0.57       628\n",
      "           2       0.69      1.00      0.81      1082\n",
      "           3       0.80      1.00      0.89      1254\n",
      "\n",
      "   micro avg       0.55      1.00      0.71      3438\n",
      "   macro avg       0.55      1.00      0.68      3438\n",
      "weighted avg       0.62      1.00      0.75      3438\n",
      " samples avg       0.55      1.00      0.68      3438\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_params = {'batch': 64, 'dropout': 0.7, 'optimizer': 'adam'}\n",
    "\n",
    "initial_lr = 0.001  # the default starting learning rate for Adam\n",
    "\n",
    "patience = 10  \n",
    "\n",
    "# the learning rate scheduler takes as input a function that returns the desired learning rate for a given epoch\n",
    "lr_scheduler = LearningRateScheduler(lambda epoch: scheduler(epoch, initial_lr)) \n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience, verbose=1, restore_best_weights=True)\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, dropout=best_params[\"dropout\"], return_sequences=True, recurrent_dropout= best_params[\"dropout\"], input_shape = (max_len, emb_len), activation=\"relu\"))\n",
    "model.add(Dropout(best_params[\"dropout\"]))\n",
    "model.add(LSTM(50, dropout=best_params[\"dropout\"], recurrent_dropout=best_params[\"dropout\"], activation=\"relu\"))\n",
    "model.add(Dropout(best_params[\"dropout\"]))\n",
    "model.add(Dense(4, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=best_params[\"optimizer\"], metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "        epochs=50,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=best_params[\"batch\"],\n",
    "        verbose=1,\n",
    "        callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "y_pred_probs = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "y_pred_binary = (y_pred_probs > threshold).astype(int)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
