{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Conclusion</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Premise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A01002</td>\n",
       "      <td>We should ban human cloning</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>we should ban human cloning as it will only ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A01005</td>\n",
       "      <td>We should ban fast food</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>fast food should be banned because it is reall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A01006</td>\n",
       "      <td>We should end the use of economic sanctions</td>\n",
       "      <td>against</td>\n",
       "      <td>sometimes economic sanctions are the only thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A01007</td>\n",
       "      <td>We should abolish capital punishment</td>\n",
       "      <td>against</td>\n",
       "      <td>capital punishment is sometimes the only optio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A01008</td>\n",
       "      <td>We should ban factory farming</td>\n",
       "      <td>against</td>\n",
       "      <td>factory farming allows for the production of c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argument ID                                   Conclusion       Stance   \n",
       "0      A01002                  We should ban human cloning  in favor of  \\\n",
       "1      A01005                      We should ban fast food  in favor of   \n",
       "2      A01006  We should end the use of economic sanctions      against   \n",
       "3      A01007         We should abolish capital punishment      against   \n",
       "4      A01008                We should ban factory farming      against   \n",
       "\n",
       "                                             Premise  \n",
       "0  we should ban human cloning as it will only ca...  \n",
       "1  fast food should be banned because it is reall...  \n",
       "2  sometimes economic sanctions are the only thin...  \n",
       "3  capital punishment is sometimes the only optio...  \n",
       "4  factory farming allows for the production of c...  "
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"arguments-training.tsv\"\n",
    "df = pd.read_table(path, sep = \"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the Argument ID column so that there is no space\n",
    "df.rename(columns={\"Argument ID\": \"Argument_ID\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we drop the row with no labels\n",
    "df.drop(index=3358, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the row indices\n",
    "df=df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    # set lowercase\n",
    "    processed_text = [token.text.lower()for token in doc]\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument_ID</th>\n",
       "      <th>Conclusion</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Premise</th>\n",
       "      <th>premise_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A01002</td>\n",
       "      <td>We should ban human cloning</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>we should ban human cloning as it will only ca...</td>\n",
       "      <td>[we, should, ban, human, cloning, as, it, will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A01005</td>\n",
       "      <td>We should ban fast food</td>\n",
       "      <td>in favor of</td>\n",
       "      <td>fast food should be banned because it is reall...</td>\n",
       "      <td>[fast, food, should, be, banned, because, it, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A01006</td>\n",
       "      <td>We should end the use of economic sanctions</td>\n",
       "      <td>against</td>\n",
       "      <td>sometimes economic sanctions are the only thin...</td>\n",
       "      <td>[sometimes, economic, sanctions, are, the, onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A01007</td>\n",
       "      <td>We should abolish capital punishment</td>\n",
       "      <td>against</td>\n",
       "      <td>capital punishment is sometimes the only optio...</td>\n",
       "      <td>[capital, punishment, is, sometimes, the, only...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A01008</td>\n",
       "      <td>We should ban factory farming</td>\n",
       "      <td>against</td>\n",
       "      <td>factory farming allows for the production of c...</td>\n",
       "      <td>[factory, farming, allows, for, the, productio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argument_ID                                   Conclusion       Stance   \n",
       "0      A01002                  We should ban human cloning  in favor of  \\\n",
       "1      A01005                      We should ban fast food  in favor of   \n",
       "2      A01006  We should end the use of economic sanctions      against   \n",
       "3      A01007         We should abolish capital punishment      against   \n",
       "4      A01008                We should ban factory farming      against   \n",
       "\n",
       "                                             Premise   \n",
       "0  we should ban human cloning as it will only ca...  \\\n",
       "1  fast food should be banned because it is reall...   \n",
       "2  sometimes economic sanctions are the only thin...   \n",
       "3  capital punishment is sometimes the only optio...   \n",
       "4  factory farming allows for the production of c...   \n",
       "\n",
       "                                   premise_tokenized  \n",
       "0  [we, should, ban, human, cloning, as, it, will...  \n",
       "1  [fast, food, should, be, banned, because, it, ...  \n",
       "2  [sometimes, economic, sanctions, are, the, onl...  \n",
       "3  [capital, punishment, is, sometimes, the, only...  \n",
       "4  [factory, farming, allows, for, the, productio...  "
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we pre-process the arguments with spacy\n",
    "df[\"premise_tokenized\"] = df[\"Premise\"].apply(preprocess_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [[doc for doc in row.premise_tokenized] for idx, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 19:00:07,233 : INFO : collecting all words and their counts\n",
      "2023-12-06 19:00:07,234 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2023-12-06 19:00:07,340 : INFO : collected 60123 token types (unigram + bigrams) from a corpus of 127374 words and 5392 sentences\n",
      "2023-12-06 19:00:07,340 : INFO : merged Phrases<60123 vocab, min_count=20, threshold=100, max_vocab_size=40000000>\n",
      "2023-12-06 19:00:07,341 : INFO : Phrases lifecycle event {'msg': 'built Phrases<60123 vocab, min_count=20, threshold=100, max_vocab_size=40000000> in 0.11s', 'datetime': '2023-12-06T19:00:07.341767', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "2023-12-06 19:00:07,349 : INFO : exporting phrases from Phrases<60123 vocab, min_count=20, threshold=100, max_vocab_size=40000000>\n",
      "2023-12-06 19:00:07,412 : INFO : FrozenPhrases lifecycle event {'msg': 'exported FrozenPhrases<40 phrases, min_count=20, threshold=100> from Phrases<60123 vocab, min_count=20, threshold=100, max_vocab_size=40000000> in 0.06s', 'datetime': '2023-12-06T19:00:07.412589', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['we',\n",
       "  'should',\n",
       "  'ban',\n",
       "  'human_cloning',\n",
       "  'as',\n",
       "  'it',\n",
       "  'will',\n",
       "  'only',\n",
       "  'cause',\n",
       "  'huge',\n",
       "  'issues',\n",
       "  'when',\n",
       "  'you',\n",
       "  'have',\n",
       "  'a',\n",
       "  'bunch',\n",
       "  'of',\n",
       "  'the',\n",
       "  'same',\n",
       "  'humans',\n",
       "  'running',\n",
       "  'around',\n",
       "  'all',\n",
       "  'acting',\n",
       "  'the',\n",
       "  'same',\n",
       "  '.'],\n",
       " ['fast_food',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned',\n",
       "  'because',\n",
       "  'it',\n",
       "  'is',\n",
       "  'really',\n",
       "  'bad',\n",
       "  'for',\n",
       "  'your',\n",
       "  'health',\n",
       "  'and',\n",
       "  'is',\n",
       "  'costly',\n",
       "  '.'],\n",
       " ['sometimes',\n",
       "  'economic_sanctions',\n",
       "  'are',\n",
       "  'the',\n",
       "  'only',\n",
       "  'thing',\n",
       "  'that',\n",
       "  'will',\n",
       "  'get',\n",
       "  'the',\n",
       "  'corrupt',\n",
       "  'governments',\n",
       "  'to',\n",
       "  'take',\n",
       "  'action'],\n",
       " ['capital_punishment',\n",
       "  'is',\n",
       "  'sometimes',\n",
       "  'the',\n",
       "  'only',\n",
       "  'option',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'criminals',\n",
       "  'from',\n",
       "  'committing',\n",
       "  'more',\n",
       "  'crimes',\n",
       "  '.'],\n",
       " ['factory_farming',\n",
       "  'allows',\n",
       "  'for',\n",
       "  'the',\n",
       "  'production',\n",
       "  'of',\n",
       "  'cheap',\n",
       "  'food',\n",
       "  ',',\n",
       "  'which',\n",
       "  'is',\n",
       "  'a',\n",
       "  'necessity',\n",
       "  'for',\n",
       "  'families',\n",
       "  'surviving',\n",
       "  'on',\n",
       "  'a',\n",
       "  'low',\n",
       "  'income',\n",
       "  '.'],\n",
       " ['nuclear_weapons',\n",
       "  'help',\n",
       "  'keep',\n",
       "  'the',\n",
       "  'peace',\n",
       "  'in',\n",
       "  'uncertain',\n",
       "  'times'],\n",
       " ['it',\n",
       "  'should',\n",
       "  'be',\n",
       "  'allowed',\n",
       "  'if',\n",
       "  'the',\n",
       "  'student',\n",
       "  'wants',\n",
       "  'to',\n",
       "  'pray',\n",
       "  'as',\n",
       "  'long',\n",
       "  'as',\n",
       "  'it',\n",
       "  'is',\n",
       "  'not',\n",
       "  'interfering',\n",
       "  'with',\n",
       "  'his',\n",
       "  'classes'],\n",
       " ['three',\n",
       "  'strike',\n",
       "  'laws',\n",
       "  'can',\n",
       "  'cause',\n",
       "  'young',\n",
       "  'people',\n",
       "  'to',\n",
       "  'be',\n",
       "  'put',\n",
       "  'away',\n",
       "  'for',\n",
       "  'life',\n",
       "  'without',\n",
       "  'a',\n",
       "  'chance',\n",
       "  'to',\n",
       "  'straight',\n",
       "  'out',\n",
       "  'their',\n",
       "  'life'],\n",
       " ['adopting',\n",
       "  'austerity_regime',\n",
       "  'will',\n",
       "  'have',\n",
       "  'very',\n",
       "  'negative',\n",
       "  'impact',\n",
       "  'on',\n",
       "  'the',\n",
       "  'poor',\n",
       "  'and',\n",
       "  'the',\n",
       "  'vulnerable',\n",
       "  'in',\n",
       "  'society',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'adopt',\n",
       "  'an',\n",
       "  'austerity_regime',\n",
       "  'because',\n",
       "  'it',\n",
       "  'is',\n",
       "  'unfair',\n",
       "  'to',\n",
       "  'expect',\n",
       "  'future',\n",
       "  'generations',\n",
       "  'to',\n",
       "  'settle',\n",
       "  'the',\n",
       "  'debts',\n",
       "  'that',\n",
       "  'we',\n",
       "  'run',\n",
       "  'up'],\n",
       " ['gender',\n",
       "  'neutral_language',\n",
       "  'is',\n",
       "  'just',\n",
       "  'another',\n",
       "  'way',\n",
       "  'to',\n",
       "  'try',\n",
       "  'to',\n",
       "  'please',\n",
       "  'a',\n",
       "  'group',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'we',\n",
       "  'have',\n",
       "  'two',\n",
       "  'sexes',\n",
       "  ',',\n",
       "  'men',\n",
       "  'and',\n",
       "  'women',\n",
       "  'and',\n",
       "  'they',\n",
       "  'should',\n",
       "  'be',\n",
       "  'differentiate',\n",
       "  'by',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'words',\n",
       "  '.'],\n",
       " ['economic_sanctions',\n",
       "  'provide',\n",
       "  'a',\n",
       "  'non',\n",
       "  '-',\n",
       "  'military',\n",
       "  'sanction',\n",
       "  'to',\n",
       "  'use',\n",
       "  'against',\n",
       "  'countries',\n",
       "  '.'],\n",
       " ['factory_farming',\n",
       "  'cuts',\n",
       "  'too',\n",
       "  'many',\n",
       "  'health',\n",
       "  'and',\n",
       "  'safety',\n",
       "  'corners',\n",
       "  'as',\n",
       "  'opposed',\n",
       "  'to',\n",
       "  'smaller',\n",
       "  'family',\n",
       "  'farms',\n",
       "  ',',\n",
       "  'this',\n",
       "  'leads',\n",
       "  'to',\n",
       "  'potentially',\n",
       "  'unsafe',\n",
       "  'and',\n",
       "  'unhealthy',\n",
       "  'products',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'important',\n",
       "  'for',\n",
       "  'news',\n",
       "  'organizations',\n",
       "  'to',\n",
       "  'transfer',\n",
       "  'to',\n",
       "  'new',\n",
       "  'forms',\n",
       "  'of',\n",
       "  'media',\n",
       "  ',',\n",
       "  'like',\n",
       "  'the',\n",
       "  'internet',\n",
       "  ',',\n",
       "  'but',\n",
       "  'it',\n",
       "  'is',\n",
       "  'costly',\n",
       "  'and',\n",
       "  'requires',\n",
       "  'subsidization',\n",
       "  '.'],\n",
       " ['there',\n",
       "  'are',\n",
       "  'parades',\n",
       "  'for',\n",
       "  'every',\n",
       "  'group',\n",
       "  'and',\n",
       "  'it',\n",
       "  'is',\n",
       "  'discrimination',\n",
       "  'not',\n",
       "  'to',\n",
       "  'give',\n",
       "  'gays',\n",
       "  'their',\n",
       "  'parade'],\n",
       " ['children',\n",
       "  'have',\n",
       "  'not',\n",
       "  'grown',\n",
       "  'and',\n",
       "  'truly',\n",
       "  'formed',\n",
       "  'their',\n",
       "  'adult',\n",
       "  'looks',\n",
       "  '.',\n",
       "  '  ',\n",
       "  'cosmetic_surgery',\n",
       "  'for',\n",
       "  'a',\n",
       "  'child',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned',\n",
       "  'until',\n",
       "  'as',\n",
       "  'an',\n",
       "  'adult',\n",
       "  'the',\n",
       "  'child',\n",
       "  'can',\n",
       "  'make',\n",
       "  'a',\n",
       "  'informed',\n",
       "  'choice',\n",
       "  'over',\n",
       "  'their',\n",
       "  'bodies',\n",
       "  'not',\n",
       "  'a',\n",
       "  'whim',\n",
       "  'of',\n",
       "  'a',\n",
       "  'child',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'legalize',\n",
       "  'prostitution',\n",
       "  'because',\n",
       "  'it',\n",
       "  'will',\n",
       "  'be',\n",
       "  'regulated',\n",
       "  'meaning',\n",
       "  'the',\n",
       "  'females',\n",
       "  'will',\n",
       "  'be',\n",
       "  'safer'],\n",
       " ['embryonic_stem',\n",
       "  'cell_research',\n",
       "  'should',\n",
       "  'be',\n",
       "  'subsidized',\n",
       "  'because',\n",
       "  'it',\n",
       "  'may',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'the',\n",
       "  'development',\n",
       "  'of',\n",
       "  'treatments',\n",
       "  'for',\n",
       "  'a',\n",
       "  'number',\n",
       "  'of',\n",
       "  'serious',\n",
       "  'medical',\n",
       "  'conditions',\n",
       "  '.'],\n",
       " ['algorithms',\n",
       "  'may',\n",
       "  'not',\n",
       "  'be',\n",
       "  '100',\n",
       "  '%',\n",
       "  'accurate',\n",
       "  'and',\n",
       "  'reflect',\n",
       "  'the',\n",
       "  'situation',\n",
       "  'in',\n",
       "  'the',\n",
       "  'real',\n",
       "  'market'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'legalize',\n",
       "  'the',\n",
       "  'organ_trade',\n",
       "  'because',\n",
       "  'currently',\n",
       "  'people',\n",
       "  'are',\n",
       "  'punished',\n",
       "  'for',\n",
       "  'obeying',\n",
       "  'the',\n",
       "  'law',\n",
       "  'and',\n",
       "  'not',\n",
       "  'purchasing',\n",
       "  'organs',\n",
       "  ',',\n",
       "  'in',\n",
       "  'the',\n",
       "  'form',\n",
       "  'of',\n",
       "  'longer',\n",
       "  'wait',\n",
       "  'times',\n",
       "  '.'],\n",
       " ['if',\n",
       "  'you',\n",
       "  'start',\n",
       "  'legalizing',\n",
       "  'drugs',\n",
       "  'it',\n",
       "  'could',\n",
       "  'open',\n",
       "  'up',\n",
       "  'the',\n",
       "  'floodgates',\n",
       "  'for',\n",
       "  'more',\n",
       "  'legalization',\n",
       "  'of',\n",
       "  'dangerous',\n",
       "  'drugs',\n",
       "  '.'],\n",
       " ['nuclear_weapons',\n",
       "  'pose',\n",
       "  'too',\n",
       "  'serious',\n",
       "  'a',\n",
       "  'threat',\n",
       "  'to',\n",
       "  'our',\n",
       "  'world',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'we',\n",
       "  'must',\n",
       "  'abolish',\n",
       "  'them',\n",
       "  'now',\n",
       "  '.'],\n",
       " ['telemarketing',\n",
       "  'does',\n",
       "  \"n't\",\n",
       "  'differentiate',\n",
       "  'between',\n",
       "  'people',\n",
       "  'who',\n",
       "  'are',\n",
       "  'interested',\n",
       "  'in',\n",
       "  'being',\n",
       "  'called',\n",
       "  'and',\n",
       "  'those',\n",
       "  'who',\n",
       "  'are',\n",
       "  \"n't\"],\n",
       " ['school',\n",
       "  'prayer',\n",
       "  'can',\n",
       "  'not',\n",
       "  'account',\n",
       "  'for',\n",
       "  'the',\n",
       "  'array',\n",
       "  'of',\n",
       "  'beliefs',\n",
       "  'or',\n",
       "  'non',\n",
       "  '-',\n",
       "  'beliefs',\n",
       "  'students',\n",
       "  'may',\n",
       "  'hold',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'abolish',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'and',\n",
       "  'bear_arms',\n",
       "  'as',\n",
       "  'everyone',\n",
       "  'has',\n",
       "  'a',\n",
       "  'right',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'guns',\n",
       "  'as',\n",
       "  'a',\n",
       "  'mean',\n",
       "  'of',\n",
       "  'protection',\n",
       "  'as',\n",
       "  'stated',\n",
       "  'in',\n",
       "  'the',\n",
       "  'constitution',\n",
       "  '.'],\n",
       " ['they',\n",
       "  'are',\n",
       "  'nothing',\n",
       "  'but',\n",
       "  'a',\n",
       "  'cult',\n",
       "  'and',\n",
       "  'manipulate',\n",
       "  'their',\n",
       "  'members'],\n",
       " ['we',\n",
       "  'need',\n",
       "  'more',\n",
       "  'organs',\n",
       "  'than',\n",
       "  'people',\n",
       "  'donate',\n",
       "  'so',\n",
       "  'legalizing',\n",
       "  'it',\n",
       "  'would',\n",
       "  'be',\n",
       "  'a',\n",
       "  'good',\n",
       "  'thing'],\n",
       " ['school',\n",
       "  'prayer',\n",
       "  'is',\n",
       "  'divisive',\n",
       "  'and',\n",
       "  'requires',\n",
       "  'children',\n",
       "  'to',\n",
       "  'either',\n",
       "  'support',\n",
       "  'religion',\n",
       "  'without',\n",
       "  'question',\n",
       "  'or',\n",
       "  'be',\n",
       "  'treated',\n",
       "  'as',\n",
       "  'different',\n",
       "  'if',\n",
       "  'they',\n",
       "  'do',\n",
       "  'not',\n",
       "  'wish',\n",
       "  'to',\n",
       "  'attend',\n",
       "  ',',\n",
       "  'which',\n",
       "  'marks',\n",
       "  'people',\n",
       "  'out',\n",
       "  'by',\n",
       "  'their',\n",
       "  'differences',\n",
       "  'at',\n",
       "  'an',\n",
       "  'early',\n",
       "  'age',\n",
       "  '.'],\n",
       " ['wikipedia',\n",
       "  'can',\n",
       "  'form',\n",
       "  'biased',\n",
       "  'opinions',\n",
       "  'on',\n",
       "  'topics',\n",
       "  'or',\n",
       "  'misinform',\n",
       "  'the',\n",
       "  'general',\n",
       "  'public',\n",
       "  'and',\n",
       "  'therefore',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'subsidized'],\n",
       " ['where',\n",
       "  'compulsory_voting',\n",
       "  'exists',\n",
       "  ',',\n",
       "  'in',\n",
       "  'countries',\n",
       "  'like',\n",
       "  'australia',\n",
       "  ',',\n",
       "  'participation',\n",
       "  'rates',\n",
       "  'are',\n",
       "  'the',\n",
       "  'highest',\n",
       "  'in',\n",
       "  'the',\n",
       "  'world',\n",
       "  '.',\n",
       "  'this',\n",
       "  'inevitably',\n",
       "  'leads',\n",
       "  'to',\n",
       "  'more',\n",
       "  'truly',\n",
       "  'representative',\n",
       "  'democracy',\n",
       "  '.'],\n",
       " ['legalizing',\n",
       "  'prostitution',\n",
       "  'will',\n",
       "  'further',\n",
       "  'demean',\n",
       "  'a',\n",
       "  'woman',\n",
       "  'or',\n",
       "  'man',\n",
       "  'and',\n",
       "  'result',\n",
       "  'in',\n",
       "  'unnecessary',\n",
       "  'violence',\n",
       "  '.'],\n",
       " ['there',\n",
       "  'are',\n",
       "  'questions',\n",
       "  'of',\n",
       "  'it',\n",
       "  \"'s\",\n",
       "  'legitimacy',\n",
       "  'and',\n",
       "  'whether',\n",
       "  'it',\n",
       "  'is',\n",
       "  'a',\n",
       "  'cult',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'members',\n",
       "  'have',\n",
       "  'to',\n",
       "  'pay',\n",
       "  'more',\n",
       "  'to',\n",
       "  'move',\n",
       "  'up',\n",
       "  'the',\n",
       "  'levels',\n",
       "  'thereby',\n",
       "  'leading',\n",
       "  'some',\n",
       "  'to',\n",
       "  'come',\n",
       "  'into',\n",
       "  'financial',\n",
       "  'troubles',\n",
       "  'due',\n",
       "  'to',\n",
       "  'this'],\n",
       " ['this',\n",
       "  'law',\n",
       "  'keeps',\n",
       "  'communities',\n",
       "  'safe',\n",
       "  'by',\n",
       "  'not',\n",
       "  'letting',\n",
       "  'criminals',\n",
       "  'run',\n",
       "  'rampant',\n",
       "  'with',\n",
       "  'only',\n",
       "  'slaps',\n",
       "  'on',\n",
       "  'the',\n",
       "  'wrist'],\n",
       " ['cannabis',\n",
       "  'has',\n",
       "  'been',\n",
       "  'shown',\n",
       "  'to',\n",
       "  'be',\n",
       "  'safer',\n",
       "  'than',\n",
       "  'alcohol',\n",
       "  'and',\n",
       "  'less',\n",
       "  'addictive',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'there',\n",
       "  'is',\n",
       "  'no',\n",
       "  'real',\n",
       "  'reason',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'it',\n",
       "  'an',\n",
       "  'illegal',\n",
       "  'substance',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'have',\n",
       "  'to',\n",
       "  'change',\n",
       "  'our',\n",
       "  'language',\n",
       "  'to',\n",
       "  'accommodate',\n",
       "  'those',\n",
       "  'who',\n",
       "  'do',\n",
       "  'not',\n",
       "  'adhere',\n",
       "  'to',\n",
       "  'a',\n",
       "  'specific',\n",
       "  'gender'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'abolish',\n",
       "  'zoos',\n",
       "  'as',\n",
       "  'animals',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'kept',\n",
       "  'in',\n",
       "  'captivity',\n",
       "  'and',\n",
       "  'should',\n",
       "  'be',\n",
       "  'in',\n",
       "  'a',\n",
       "  'natural',\n",
       "  'environment',\n",
       "  '.'],\n",
       " ['fast_food',\n",
       "  'is',\n",
       "  'bad',\n",
       "  'for',\n",
       "  'adults',\n",
       "  'and',\n",
       "  'children',\n",
       "  'and',\n",
       "  'causes',\n",
       "  'obesity',\n",
       "  'and',\n",
       "  'the',\n",
       "  'risk',\n",
       "  'of',\n",
       "  'diabetes',\n",
       "  'in',\n",
       "  'many',\n",
       "  'cases',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'would',\n",
       "  'give',\n",
       "  'people',\n",
       "  'more',\n",
       "  'of',\n",
       "  'a',\n",
       "  'choice',\n",
       "  ' ',\n",
       "  'and',\n",
       "  'provides',\n",
       "  'someone',\n",
       "  'for',\n",
       "  'every',\n",
       "  'culture',\n",
       "  'to',\n",
       "  'vote',\n",
       "  'for'],\n",
       " ['fast_food',\n",
       "  'is',\n",
       "  'bad',\n",
       "  'for',\n",
       "  'our',\n",
       "  'health',\n",
       "  'and',\n",
       "  'we',\n",
       "  'really',\n",
       "  'should',\n",
       "  'ban',\n",
       "  'any',\n",
       "  'of',\n",
       "  'it'],\n",
       " ['autonomous_cars',\n",
       "  'will',\n",
       "  'take',\n",
       "  'away',\n",
       "  'the',\n",
       "  'jobs',\n",
       "  'of',\n",
       "  'thousands',\n",
       "  'of',\n",
       "  'people',\n",
       "  'around',\n",
       "  'the',\n",
       "  'world',\n",
       "  'by',\n",
       "  'removing',\n",
       "  'the',\n",
       "  'function',\n",
       "  'of',\n",
       "  'drivers',\n",
       "  '.'],\n",
       " ['journalism',\n",
       "  'and',\n",
       "  'free',\n",
       "  'expression',\n",
       "  'of',\n",
       "  'information',\n",
       "  'and',\n",
       "  'exchange',\n",
       "  'of',\n",
       "  'ideas',\n",
       "  'is',\n",
       "  'a',\n",
       "  'basic',\n",
       "  'human',\n",
       "  'right',\n",
       "  ',',\n",
       "  'and',\n",
       "  'subsidizing',\n",
       "  'this',\n",
       "  'would',\n",
       "  'improve',\n",
       "  'its',\n",
       "  'quality',\n",
       "  'and',\n",
       "  'reach',\n",
       "  '.'],\n",
       " ['pride_parades', 'create', 'a', 'huge', 'disturbance'],\n",
       " ['olympic_games',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'banned',\n",
       "  '.',\n",
       "  'they',\n",
       "  'are',\n",
       "  'the',\n",
       "  'tissue',\n",
       "  'that',\n",
       "  'solidify',\n",
       "  'the',\n",
       "  'friendship',\n",
       "  'between',\n",
       "  'nations',\n",
       "  'in',\n",
       "  'the',\n",
       "  'world',\n",
       "  'and',\n",
       "  'a',\n",
       "  'reminder',\n",
       "  'of',\n",
       "  'a',\n",
       "  'peaceful',\n",
       "  'world',\n",
       "  'which',\n",
       "  'should',\n",
       "  'be',\n",
       "  'the',\n",
       "  'world',\n",
       "  'vision'],\n",
       " ['factory',\n",
       "  'farms',\n",
       "  'keep',\n",
       "  'animals',\n",
       "  'in',\n",
       "  'tight',\n",
       "  'spaces',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'they',\n",
       "  'are',\n",
       "  'forced',\n",
       "  'to',\n",
       "  'live',\n",
       "  'in',\n",
       "  'cages',\n",
       "  'and',\n",
       "  'not',\n",
       "  'allowed',\n",
       "  'to',\n",
       "  'roam',\n",
       "  'as',\n",
       "  'they',\n",
       "  'were',\n",
       "  'meant',\n",
       "  'to',\n",
       "  '.'],\n",
       " ['capital_punishment',\n",
       "  'has',\n",
       "  'been',\n",
       "  'proven',\n",
       "  'ineffective',\n",
       "  'in',\n",
       "  'reducing',\n",
       "  'crime',\n",
       "  'rates',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'abolish',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'bear_arms',\n",
       "  'because',\n",
       "  'the',\n",
       "  'law',\n",
       "  'was',\n",
       "  'set',\n",
       "  'forth',\n",
       "  'by',\n",
       "  'our',\n",
       "  'founding',\n",
       "  'fathers',\n",
       "  ',',\n",
       "  'therefore',\n",
       "  'making',\n",
       "  'it',\n",
       "  'an',\n",
       "  'american',\n",
       "  'right',\n",
       "  '.'],\n",
       " ['there',\n",
       "  'are',\n",
       "  'more',\n",
       "  'important',\n",
       "  'things',\n",
       "  'to',\n",
       "  'spend',\n",
       "  'public',\n",
       "  'funds',\n",
       "  'on',\n",
       "  'such',\n",
       "  'as',\n",
       "  'health',\n",
       "  'care',\n",
       "  ',',\n",
       "  'housing',\n",
       "  'and',\n",
       "  'education',\n",
       "  '.'],\n",
       " ['school_uniforms',\n",
       "  'keep',\n",
       "  'children',\n",
       "  'from',\n",
       "  'being',\n",
       "  'able',\n",
       "  'to',\n",
       "  'express',\n",
       "  'themselves',\n",
       "  'through',\n",
       "  'their',\n",
       "  'clothing',\n",
       "  'choices',\n",
       "  '.'],\n",
       " ['human_cloning',\n",
       "  'is',\n",
       "  'an',\n",
       "  'unnatural',\n",
       "  'act',\n",
       "  'that',\n",
       "  'goes',\n",
       "  'against',\n",
       "  'the',\n",
       "  'laws',\n",
       "  'of',\n",
       "  'nature',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'it',\n",
       "  'is',\n",
       "  'too',\n",
       "  'dangerous',\n",
       "  'of',\n",
       "  'an',\n",
       "  'act',\n",
       "  'and',\n",
       "  'is',\n",
       "  'something',\n",
       "  'man',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'tampering',\n",
       "  'with',\n",
       "  '.'],\n",
       " ['why',\n",
       "  'should',\n",
       "  'homosexuals',\n",
       "  'have',\n",
       "  'a',\n",
       "  'pride',\n",
       "  'parade?heterosexuals',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'have',\n",
       "  'them',\n",
       "  '!'],\n",
       " ['allowing',\n",
       "  'children',\n",
       "  'to',\n",
       "  'pray',\n",
       "  'and',\n",
       "  'take',\n",
       "  'some',\n",
       "  'quiet',\n",
       "  'time',\n",
       "  'in',\n",
       "  'school',\n",
       "  'can',\n",
       "  'be',\n",
       "  'beneficial',\n",
       "  'for',\n",
       "  'their',\n",
       "  'mental',\n",
       "  'health',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'adopt',\n",
       "  'a',\n",
       "  'multi',\n",
       "  '-',\n",
       "  'party_system',\n",
       "  'as',\n",
       "  'the',\n",
       "  'current',\n",
       "  'two',\n",
       "  'party_system',\n",
       "  'does',\n",
       "  'not',\n",
       "  'fit',\n",
       "  'the',\n",
       "  'diverse',\n",
       "  'society',\n",
       "  'that',\n",
       "  'it',\n",
       "  'is',\n",
       "  'supposed',\n",
       "  'to',\n",
       "  'represent',\n",
       "  '.'],\n",
       " ['ip',\n",
       "  'rights',\n",
       "  'enable',\n",
       "  'large',\n",
       "  'corporations',\n",
       "  'to',\n",
       "  'have',\n",
       "  'a',\n",
       "  'stranglehold',\n",
       "  'over',\n",
       "  'creators',\n",
       "  'designs',\n",
       "  'and',\n",
       "  'work',\n",
       "  'and',\n",
       "  'should',\n",
       "  'be',\n",
       "  'abolished'],\n",
       " ['there',\n",
       "  'are',\n",
       "  'many',\n",
       "  'sectors',\n",
       "  'need',\n",
       "  'subsidizing',\n",
       "  'more',\n",
       "  'than',\n",
       "  'journalism',\n",
       "  ',',\n",
       "  ' ',\n",
       "  'journalists',\n",
       "  'already',\n",
       "  'make',\n",
       "  'good',\n",
       "  'money',\n",
       "  ',',\n",
       "  'more',\n",
       "  'money',\n",
       "  'to',\n",
       "  'them',\n",
       "  'will',\n",
       "  'be',\n",
       "  'a',\n",
       "  'waste',\n",
       "  '.'],\n",
       " ['cannabis',\n",
       "  'is',\n",
       "  'highly',\n",
       "  'addictive',\n",
       "  ',',\n",
       "  'studies',\n",
       "  'show',\n",
       "  'up',\n",
       "  'to',\n",
       "  'one',\n",
       "  '-',\n",
       "  'in10',\n",
       "  'users',\n",
       "  'develop',\n",
       "  'dependence',\n",
       "  'over',\n",
       "  'time'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'adopt',\n",
       "  'gender',\n",
       "  'neutral_language',\n",
       "  'because',\n",
       "  'were',\n",
       "  'created',\n",
       "  'as',\n",
       "  'male',\n",
       "  'and',\n",
       "  'female'],\n",
       " ['whaling',\n",
       "  'is',\n",
       "  'a',\n",
       "  'barbaric',\n",
       "  'practice',\n",
       "  'that',\n",
       "  'destroys',\n",
       "  'majestic',\n",
       "  'animals'],\n",
       " ['executives',\n",
       "  'deserve',\n",
       "  'the',\n",
       "  'money',\n",
       "  'as',\n",
       "  'they',\n",
       "  'do',\n",
       "  'a',\n",
       "  'stressful',\n",
       "  'and',\n",
       "  'demanding',\n",
       "  'job',\n",
       "  'leading',\n",
       "  'large',\n",
       "  'organizations',\n",
       "  'that',\n",
       "  'hire',\n",
       "  'large',\n",
       "  'number',\n",
       "  'of',\n",
       "  'people',\n",
       "  '.'],\n",
       " ['zero',\n",
       "  'telerance',\n",
       "  'policied',\n",
       "  'do',\n",
       "  'not',\n",
       "  'address',\n",
       "  'underlying',\n",
       "  'causes',\n",
       "  'for',\n",
       "  'the',\n",
       "  'behaviour',\n",
       "  'that',\n",
       "  'is',\n",
       "  'causing',\n",
       "  'the',\n",
       "  'issue'],\n",
       " ['school_uniforms',\n",
       "  'are',\n",
       "  'too',\n",
       "  'expensive',\n",
       "  'and',\n",
       "  'many',\n",
       "  'parents',\n",
       "  'can',\n",
       "  'not',\n",
       "  'afford',\n",
       "  'the',\n",
       "  'extra',\n",
       "  'expense',\n",
       "  '.'],\n",
       " ['nuclear_weapons',\n",
       "  'should',\n",
       "  'be',\n",
       "  'abolished',\n",
       "  'because',\n",
       "  'they',\n",
       "  'have',\n",
       "  'to',\n",
       "  'potential',\n",
       "  'to',\n",
       "  'cause',\n",
       "  'so',\n",
       "  'much',\n",
       "  'destruction',\n",
       "  '.'],\n",
       " ['ideas',\n",
       "  'are',\n",
       "  'free',\n",
       "  'thoughts',\n",
       "  'so',\n",
       "  'it',\n",
       "  \"'s\",\n",
       "  'not',\n",
       "  'fair',\n",
       "  'for',\n",
       "  'one',\n",
       "  'person',\n",
       "  'to',\n",
       "  'profit',\n",
       "  'off',\n",
       "  'of',\n",
       "  'it'],\n",
       " ['economic_sanctions',\n",
       "  'affect',\n",
       "  'poor',\n",
       "  'people',\n",
       "  'more',\n",
       "  'than',\n",
       "  'governments'],\n",
       " ['factory_farming',\n",
       "  'is',\n",
       "  'bad',\n",
       "  'for',\n",
       "  'the',\n",
       "  'environment',\n",
       "  'and',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned'],\n",
       " ['if',\n",
       "  'we',\n",
       "  'legalize',\n",
       "  'the',\n",
       "  'organ_trade',\n",
       "  'we',\n",
       "  'will',\n",
       "  'save',\n",
       "  'lives',\n",
       "  ',',\n",
       "  'by',\n",
       "  'ensuring',\n",
       "  'that',\n",
       "  'more',\n",
       "  'people',\n",
       "  'who',\n",
       "  'need',\n",
       "  'an',\n",
       "  'organ',\n",
       "  'transplant',\n",
       "  'actually',\n",
       "  'get',\n",
       "  'one',\n",
       "  '.'],\n",
       " ['embryonic_stem',\n",
       "  'cell_research',\n",
       "  'should',\n",
       "  'be',\n",
       "  'subsidized',\n",
       "  'because',\n",
       "  'it',\n",
       "  'only',\n",
       "  'requires',\n",
       "  'a',\n",
       "  'small',\n",
       "  'amount',\n",
       "  'of',\n",
       "  'cells',\n",
       "  'because',\n",
       "  'of',\n",
       "  'the',\n",
       "  'fast',\n",
       "  'replication',\n",
       "  'rate'],\n",
       " ['private_military',\n",
       "  'companies',\n",
       "  'could',\n",
       "  'be',\n",
       "  'a',\n",
       "  'danger',\n",
       "  'to',\n",
       "  'our',\n",
       "  'national',\n",
       "  'security',\n",
       "  'because',\n",
       "  'their',\n",
       "  'motives',\n",
       "  'are',\n",
       "  'financial',\n",
       "  'in',\n",
       "  'nature',\n",
       "  'which',\n",
       "  'means',\n",
       "  'they',\n",
       "  'could',\n",
       "  'act',\n",
       "  'in',\n",
       "  'ways',\n",
       "  'that',\n",
       "  'are',\n",
       "  'not',\n",
       "  'in',\n",
       "  'our',\n",
       "  'country',\n",
       "  \"'s\",\n",
       "  'best',\n",
       "  'interest',\n",
       "  'politcally',\n",
       "  '.'],\n",
       " ['libertarianism',\n",
       "  'fosters',\n",
       "  'a',\n",
       "  'more',\n",
       "  'equitable',\n",
       "  'and',\n",
       "  'efficient',\n",
       "  'society',\n",
       "  'for',\n",
       "  'all'],\n",
       " ['these',\n",
       "  'are',\n",
       "  'usually',\n",
       "  'located',\n",
       "  'in',\n",
       "  'universities',\n",
       "  '.',\n",
       "  'students',\n",
       "  'need',\n",
       "  'to',\n",
       "  'prepare',\n",
       "  'for',\n",
       "  'the',\n",
       "  'real',\n",
       "  'world',\n",
       "  'and',\n",
       "  'know',\n",
       "  'how',\n",
       "  'to',\n",
       "  'handle',\n",
       "  'conflict',\n",
       "  '.',\n",
       "  'once',\n",
       "  'they',\n",
       "  'leave',\n",
       "  'school',\n",
       "  'they',\n",
       "  \"'ll\",\n",
       "  'have',\n",
       "  'no',\n",
       "  'idea',\n",
       "  'how',\n",
       "  'to',\n",
       "  'handle',\n",
       "  'the',\n",
       "  'constant',\n",
       "  'conflict',\n",
       "  'in',\n",
       "  'life',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'autonomous_cars',\n",
       "  'should',\n",
       "  'result',\n",
       "  'in',\n",
       "  'a',\n",
       "  'substantial',\n",
       "  'reduction',\n",
       "  'in',\n",
       "  'road',\n",
       "  'traffic',\n",
       "  'accidents',\n",
       "  'which',\n",
       "  'currently',\n",
       "  'are',\n",
       "  'largely',\n",
       "  'a',\n",
       "  'result',\n",
       "  'of',\n",
       "  'human',\n",
       "  'error',\n",
       "  '.'],\n",
       " ['cosmetic_surgery', 'is', 'unnecessary', 'and', 'dangerous', '.'],\n",
       " ['the',\n",
       "  'olympic_games',\n",
       "  'cause',\n",
       "  'turmoil',\n",
       "  'and',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'money',\n",
       "  '.'],\n",
       " ['legalizing',\n",
       "  'marijuana',\n",
       "  'would',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'a',\n",
       "  'reduction',\n",
       "  'in',\n",
       "  'gang',\n",
       "  '-',\n",
       "  'related',\n",
       "  'drug',\n",
       "  'violence',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'adopt',\n",
       "  'gender',\n",
       "  '-',\n",
       "  'neutral_language',\n",
       "  'because',\n",
       "  'it',\n",
       "  'avoids',\n",
       "  'offending',\n",
       "  'people',\n",
       "  'with',\n",
       "  'gender',\n",
       "  'stereo',\n",
       "  '-',\n",
       "  'types'],\n",
       " ['algorithmic_trading',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned',\n",
       "  'as',\n",
       "  'it',\n",
       "  'manipulates',\n",
       "  'the',\n",
       "  'economy',\n",
       "  'to',\n",
       "  'benefit',\n",
       "  'stockholders',\n",
       "  '.'],\n",
       " ['there',\n",
       "  'is',\n",
       "  'little',\n",
       "  'difference',\n",
       "  'between',\n",
       "  'the',\n",
       "  'whaling',\n",
       "  'industry',\n",
       "  ' ',\n",
       "  'and',\n",
       "  'our',\n",
       "  'farming',\n",
       "  'industries',\n",
       "  ';',\n",
       "  'humans',\n",
       "  'are',\n",
       "  'entitled',\n",
       "  'to',\n",
       "  'hunt',\n",
       "  'animals',\n",
       "  'to',\n",
       "  'eat',\n",
       "  'them',\n",
       "  'and',\n",
       "  'utilize',\n",
       "  'them',\n",
       "  'to',\n",
       "  'our',\n",
       "  'benefit',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'world',\n",
       "  'of',\n",
       "  'show',\n",
       "  'has',\n",
       "  'proven',\n",
       "  'to',\n",
       "  'be',\n",
       "  'full',\n",
       "  'of',\n",
       "  'vices',\n",
       "  'that',\n",
       "  'in',\n",
       "  'the',\n",
       "  'case',\n",
       "  'of',\n",
       "  'children',\n",
       "  'is',\n",
       "  'very',\n",
       "  'harmful'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'limit',\n",
       "  'executives',\n",
       "  'earnings',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'some',\n",
       "  'ceo',\n",
       "  \"'s\",\n",
       "  'get',\n",
       "  'millions',\n",
       "  'of',\n",
       "  'dollars',\n",
       "  'for',\n",
       "  'a',\n",
       "  'salary',\n",
       "  'plus',\n",
       "  'housing',\n",
       "  ',',\n",
       "  'airplanes',\n",
       "  ',',\n",
       "  'and',\n",
       "  'even',\n",
       "  'get',\n",
       "  'a',\n",
       "  'package',\n",
       "  'to',\n",
       "  'leave',\n",
       "  'the',\n",
       "  'company',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'all',\n",
       "  'this',\n",
       "  'while',\n",
       "  'average',\n",
       "  'worker',\n",
       "  'could',\n",
       "  'use',\n",
       "  'more',\n",
       "  '.'],\n",
       " ['this',\n",
       "  'research',\n",
       "  'is',\n",
       "  'very',\n",
       "  'controversial',\n",
       "  'and',\n",
       "  'against',\n",
       "  'many',\n",
       "  'religions'],\n",
       " ['three',\n",
       "  'is',\n",
       "  'an',\n",
       "  'arbitrary',\n",
       "  'number',\n",
       "  'and',\n",
       "  'may',\n",
       "  'not',\n",
       "  'be',\n",
       "  'appropriate',\n",
       "  'in',\n",
       "  'some',\n",
       "  'instances',\n",
       "  'or',\n",
       "  'for',\n",
       "  'some',\n",
       "  'crimes'],\n",
       " ['the',\n",
       "  'loss',\n",
       "  'of',\n",
       "  'experience',\n",
       "  'and',\n",
       "  'knowledge',\n",
       "  'from',\n",
       "  'mandatory_retirement',\n",
       "  'is',\n",
       "  'costly',\n",
       "  'to',\n",
       "  'businesses'],\n",
       " ['student_loans',\n",
       "  'set',\n",
       "  'children',\n",
       "  'up',\n",
       "  'to',\n",
       "  'be',\n",
       "  'valuable',\n",
       "  'citizens',\n",
       "  'and',\n",
       "  'the',\n",
       "  'state',\n",
       "  'should',\n",
       "  'support',\n",
       "  'this'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'do',\n",
       "  'this',\n",
       "  'because',\n",
       "  'other',\n",
       "  'countries',\n",
       "  'like',\n",
       "  'china',\n",
       "  'already',\n",
       "  'did',\n",
       "  'and',\n",
       "  'it',\n",
       "  'caused',\n",
       "  'an',\n",
       "  'epidemic',\n",
       "  'where',\n",
       "  'there',\n",
       "  'is',\n",
       "  'a',\n",
       "  'huge',\n",
       "  'imbalance',\n",
       "  'of',\n",
       "  'males',\n",
       "  'to',\n",
       "  'females',\n",
       "  'which',\n",
       "  'disrupts',\n",
       "  'the',\n",
       "  'population'],\n",
       " ['collectivism',\n",
       "  'prevents',\n",
       "  'original',\n",
       "  'thoughts',\n",
       "  'and',\n",
       "  'discourages',\n",
       "  'people',\n",
       "  'from',\n",
       "  'looking',\n",
       "  'for',\n",
       "  'their',\n",
       "  'own',\n",
       "  'ideas'],\n",
       " ['missionary_work',\n",
       "  'plays',\n",
       "  'on',\n",
       "  'the',\n",
       "  'ignorance',\n",
       "  'of',\n",
       "  'local',\n",
       "  'people',\n",
       "  'to',\n",
       "  'exploit',\n",
       "  'them'],\n",
       " ['activists',\n",
       "  'judges',\n",
       "  'are',\n",
       "  \"n't\",\n",
       "  'the',\n",
       "  'ones',\n",
       "  'shaping',\n",
       "  'the',\n",
       "  'laws',\n",
       "  '.',\n",
       "  'they',\n",
       "  \"'re\",\n",
       "  'not',\n",
       "  '\"',\n",
       "  'all',\n",
       "  '\"',\n",
       "  'the',\n",
       "  'people',\n",
       "  'for',\n",
       "  'who',\n",
       "  'the',\n",
       "  'laws',\n",
       "  'are',\n",
       "  'voted',\n",
       "  'for',\n",
       "  '.',\n",
       "  'judicial_activism',\n",
       "  'has',\n",
       "  'to',\n",
       "  'be',\n",
       "  'limited',\n",
       "  'to',\n",
       "  'only',\n",
       "  'check',\n",
       "  'for',\n",
       "  'overuse',\n",
       "  'of',\n",
       "  'the',\n",
       "  'power',\n",
       "  'by',\n",
       "  'governments'],\n",
       " ['subsidizing',\n",
       "  'wikipedia',\n",
       "  'can',\n",
       "  'cause',\n",
       "  'it',\n",
       "  'to',\n",
       "  'provide',\n",
       "  'biased',\n",
       "  'information'],\n",
       " ['treating',\n",
       "  'everyone',\n",
       "  'as',\n",
       "  'a',\n",
       "  'large',\n",
       "  'group',\n",
       "  'unit',\n",
       "  'is',\n",
       "  'not',\n",
       "  'helpful',\n",
       "  'for',\n",
       "  'people',\n",
       "  'who',\n",
       "  'have',\n",
       "  'different',\n",
       "  'individual',\n",
       "  'needs',\n",
       "  '.'],\n",
       " ['fast_food',\n",
       "  'is',\n",
       "  'sometimes',\n",
       "  'the',\n",
       "  'only',\n",
       "  'way',\n",
       "  'poor',\n",
       "  'people',\n",
       "  'can',\n",
       "  'feed',\n",
       "  'their',\n",
       "  'families',\n",
       "  'cheaply',\n",
       "  '.',\n",
       "  'if',\n",
       "  'you',\n",
       "  'ban',\n",
       "  'it',\n",
       "  'then',\n",
       "  'you',\n",
       "  'are',\n",
       "  'taking',\n",
       "  'away',\n",
       "  'someone',\n",
       "  \"'s\",\n",
       "  'only',\n",
       "  'meal',\n",
       "  '.'],\n",
       " ['prayer',\n",
       "  'in',\n",
       "  'schools',\n",
       "  'violates',\n",
       "  'a',\n",
       "  'person',\n",
       "  \"'s\",\n",
       "  'right',\n",
       "  'to',\n",
       "  'follow',\n",
       "  'whatever',\n",
       "  'religion',\n",
       "  'they',\n",
       "  'choose',\n",
       "  '.'],\n",
       " ['compulsory_voting',\n",
       "  'goes',\n",
       "  'against',\n",
       "  'people',\n",
       "  \"'s\",\n",
       "  'liberties',\n",
       "  'and',\n",
       "  'freedoms',\n",
       "  '.'],\n",
       " ['economic_sanctions',\n",
       "  'can',\n",
       "  'assist',\n",
       "  'in',\n",
       "  'deterring',\n",
       "  'deadly',\n",
       "  'threats',\n",
       "  'against',\n",
       "  'our',\n",
       "  'nation'],\n",
       " ['compulsory_voting', 'makes', 'for', 'more', 'informed', 'voters'],\n",
       " ['there',\n",
       "  'are',\n",
       "  'so',\n",
       "  'many',\n",
       "  'people',\n",
       "  'in',\n",
       "  'the',\n",
       "  'world',\n",
       "  'we',\n",
       "  'all',\n",
       "  'have',\n",
       "  'to',\n",
       "  'appreciate',\n",
       "  'that',\n",
       "  'we',\n",
       "  'need',\n",
       "  'to',\n",
       "  'adopt',\n",
       "  'certain',\n",
       "  'rules',\n",
       "  'and',\n",
       "  'etiquette',\n",
       "  'which',\n",
       "  'everyone',\n",
       "  'follows',\n",
       "  ',',\n",
       "  'if',\n",
       "  'everyone',\n",
       "  'pleased',\n",
       "  'themselves',\n",
       "  'no',\n",
       "  'one',\n",
       "  'would',\n",
       "  'help',\n",
       "  'each',\n",
       "  'other',\n",
       "  '.'],\n",
       " ['subsidizing',\n",
       "  'wikipedia',\n",
       "  'could',\n",
       "  'be',\n",
       "  'a',\n",
       "  'back',\n",
       "  'gateway',\n",
       "  'to',\n",
       "  'some',\n",
       "  'form',\n",
       "  'of',\n",
       "  'governmental',\n",
       "  'control',\n",
       "  ',',\n",
       "  'debasing',\n",
       "  'the',\n",
       "  'validity',\n",
       "  'of',\n",
       "  'the',\n",
       "  'articles',\n",
       "  'and',\n",
       "  'information',\n",
       "  'provided',\n",
       "  '.'],\n",
       " ['pride_parades',\n",
       "  'encourage',\n",
       "  'people',\n",
       "  'to',\n",
       "  'claim',\n",
       "  'the',\n",
       "  'rights',\n",
       "  'and',\n",
       "  'freedoms',\n",
       "  'they',\n",
       "  'are',\n",
       "  'entitled',\n",
       "  'to'],\n",
       " ['pride_parades',\n",
       "  'can',\n",
       "  'show',\n",
       "  'everyone',\n",
       "  'that',\n",
       "  'we',\n",
       "  'tolerate',\n",
       "  'everyone'],\n",
       " ['it',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned',\n",
       "  'so',\n",
       "  'that',\n",
       "  'it',\n",
       "  'does',\n",
       "  \"n't\",\n",
       "  'take',\n",
       "  'away',\n",
       "  'our',\n",
       "  'farms',\n",
       "  'and',\n",
       "  'will',\n",
       "  'cause',\n",
       "  'more',\n",
       "  'global',\n",
       "  'warming'],\n",
       " ['zoos',\n",
       "  'do',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'conservation',\n",
       "  'work',\n",
       "  'and',\n",
       "  'have',\n",
       "  'successfully',\n",
       "  'bred',\n",
       "  'animals',\n",
       "  'which',\n",
       "  'were',\n",
       "  'on',\n",
       "  'the',\n",
       "  'verge',\n",
       "  'of',\n",
       "  'extinction',\n",
       "  '.'],\n",
       " ['cosmetic_surgery',\n",
       "  'for',\n",
       "  'minors',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned',\n",
       "  'because',\n",
       "  'they',\n",
       "  'are',\n",
       "  'not',\n",
       "  'finished',\n",
       "  'growing',\n",
       "  'no',\n",
       "  'do',\n",
       "  'they',\n",
       "  'have',\n",
       "  'a',\n",
       "  'mature',\n",
       "  'enough',\n",
       "  'background',\n",
       "  'to',\n",
       "  'make',\n",
       "  'a',\n",
       "  'sound',\n",
       "  'decision',\n",
       "  'towards',\n",
       "  'this',\n",
       "  'procedure',\n",
       "  '.'],\n",
       " ['targeted_killing',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'banned',\n",
       "  'because',\n",
       "  'it',\n",
       "  'means',\n",
       "  'that',\n",
       "  'dangerous',\n",
       "  'people',\n",
       "  'can',\n",
       "  'be',\n",
       "  'stopped',\n",
       "  'from',\n",
       "  'injuring',\n",
       "  'other',\n",
       "  'people',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'two',\n",
       "  '-',\n",
       "  'party_system',\n",
       "  'is',\n",
       "  'cheaper',\n",
       "  'and',\n",
       "  'easier',\n",
       "  'to',\n",
       "  'operate',\n",
       "  'that',\n",
       "  'any',\n",
       "  'multi',\n",
       "  '-',\n",
       "  'party_system'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'adopt',\n",
       "  'atheism',\n",
       "  'because',\n",
       "  'it',\n",
       "  'would',\n",
       "  'be',\n",
       "  'easier',\n",
       "  'than',\n",
       "  'being',\n",
       "  'religious',\n",
       "  'and',\n",
       "  'having',\n",
       "  'so',\n",
       "  'many',\n",
       "  'different',\n",
       "  'beliefs'],\n",
       " ['human_cloning',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned',\n",
       "  'because',\n",
       "  'it',\n",
       "  'allows',\n",
       "  'designer',\n",
       "  'humans',\n",
       "  'to',\n",
       "  'be',\n",
       "  'grown',\n",
       "  'according',\n",
       "  'to',\n",
       "  'the',\n",
       "  'parents',\n",
       "  'wishes',\n",
       "  '.'],\n",
       " ['whaling',\n",
       "  'is',\n",
       "  'inhumane',\n",
       "  'and',\n",
       "  'unnecessary',\n",
       "  'and',\n",
       "  'killing',\n",
       "  'the',\n",
       "  'whale',\n",
       "  'population',\n",
       "  '.'],\n",
       " ['an',\n",
       "  'austerity_regime',\n",
       "  'will',\n",
       "  'help',\n",
       "  'to',\n",
       "  'reduce',\n",
       "  'the',\n",
       "  'deficit',\n",
       "  'of',\n",
       "  'the',\n",
       "  'country'],\n",
       " ['people',\n",
       "  'should',\n",
       "  'not',\n",
       "  'have',\n",
       "  'to',\n",
       "  'endure',\n",
       "  'higher',\n",
       "  'taxes',\n",
       "  'to',\n",
       "  'pay',\n",
       "  'for',\n",
       "  'the',\n",
       "  'government',\n",
       "  \"'s\",\n",
       "  'inefficiency',\n",
       "  '.'],\n",
       " ['there',\n",
       "  'is',\n",
       "  'so',\n",
       "  'much',\n",
       "  'more',\n",
       "  'to',\n",
       "  'explore',\n",
       "  'and',\n",
       "  'learn',\n",
       "  'about',\n",
       "  'space',\n",
       "  'that',\n",
       "  'subsidising',\n",
       "  'space_exploration',\n",
       "  'would',\n",
       "  'bring',\n",
       "  'us',\n",
       "  'closer',\n",
       "  'to',\n",
       "  'learning',\n",
       "  'and',\n",
       "  'understanding',\n",
       "  'what',\n",
       "  'is',\n",
       "  'beyond',\n",
       "  'our',\n",
       "  'planet',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'subsidize',\n",
       "  'journalism',\n",
       "  'because',\n",
       "  'there',\n",
       "  'is',\n",
       "  'already',\n",
       "  'sufficient',\n",
       "  'coverage',\n",
       "  'of',\n",
       "  'major',\n",
       "  'issues',\n",
       "  'from',\n",
       "  'different',\n",
       "  'viewpoints',\n",
       "  'without',\n",
       "  'government',\n",
       "  'action',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'ban',\n",
       "  'telemarketing',\n",
       "  'as',\n",
       "  'it',\n",
       "  'it',\n",
       "  'allows',\n",
       "  'people',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'about',\n",
       "  'new',\n",
       "  'products',\n",
       "  'or',\n",
       "  'services',\n",
       "  'from',\n",
       "  'the',\n",
       "  'comfort',\n",
       "  'of',\n",
       "  'their',\n",
       "  'own',\n",
       "  'homes',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'abolish',\n",
       "  'capital_punishment',\n",
       "  'because',\n",
       "  'if',\n",
       "  'the',\n",
       "  'criminal',\n",
       "  'done',\n",
       "  'with',\n",
       "  'their',\n",
       "  'time',\n",
       "  'in',\n",
       "  'jail',\n",
       "  'they',\n",
       "  'may',\n",
       "  'commit',\n",
       "  'far',\n",
       "  'more',\n",
       "  'serious',\n",
       "  'crime',\n",
       "  'again',\n",
       "  'because',\n",
       "  'some',\n",
       "  'criminal',\n",
       "  'can',\n",
       "  'not',\n",
       "  'be',\n",
       "  'rehabilitated'],\n",
       " ['algorithmic_trading',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned',\n",
       "  'because',\n",
       "  'it',\n",
       "  'gives',\n",
       "  'some',\n",
       "  'people',\n",
       "  'an',\n",
       "  'unfair',\n",
       "  'advantage',\n",
       "  '.'],\n",
       " ['legalising',\n",
       "  'prostitution',\n",
       "  'will',\n",
       "  'ensure',\n",
       "  'the',\n",
       "  'safety',\n",
       "  'of',\n",
       "  'both',\n",
       "  'the',\n",
       "  'sex',\n",
       "  'trade',\n",
       "  'worker',\n",
       "  'and',\n",
       "  'client'],\n",
       " ['telemarketing',\n",
       "  'is',\n",
       "  'intrusive',\n",
       "  ',',\n",
       "  'annoying',\n",
       "  'and',\n",
       "  'violates',\n",
       "  'privacy'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'end',\n",
       "  'mandatory_retirement',\n",
       "  'because',\n",
       "  'it',\n",
       "  'removes',\n",
       "  'people',\n",
       "  'who',\n",
       "  'are',\n",
       "  'knowledgeable',\n",
       "  'and',\n",
       "  'skilled',\n",
       "  'from',\n",
       "  'jobs',\n",
       "  'that',\n",
       "  'they',\n",
       "  'are',\n",
       "  'good',\n",
       "  'at',\n",
       "  '.'],\n",
       " ['if',\n",
       "  'you',\n",
       "  'are',\n",
       "  'not',\n",
       "  'required',\n",
       "  'to',\n",
       "  'wear',\n",
       "  'a',\n",
       "  'uniform',\n",
       "  ',',\n",
       "  'you',\n",
       "  'are',\n",
       "  'free',\n",
       "  'to',\n",
       "  'choose',\n",
       "  'clothing',\n",
       "  'styles',\n",
       "  'that',\n",
       "  'are',\n",
       "  'more',\n",
       "  'favorable',\n",
       "  'to',\n",
       "  'your',\n",
       "  'body',\n",
       "  'type',\n",
       "  'and',\n",
       "  'coloring',\n",
       "  ',',\n",
       "  'which',\n",
       "  'allows',\n",
       "  'you',\n",
       "  'to',\n",
       "  'look',\n",
       "  'your',\n",
       "  'best'],\n",
       " ['missionary_work',\n",
       "  'is',\n",
       "  'beneficial',\n",
       "  'for',\n",
       "  'those',\n",
       "  'receiving',\n",
       "  'aid',\n",
       "  '.'],\n",
       " ['forcing',\n",
       "  'children',\n",
       "  'into',\n",
       "  'wearing',\n",
       "  'school_uniforms',\n",
       "  'shows',\n",
       "  'our',\n",
       "  'children',\n",
       "  'that',\n",
       "  'they',\n",
       "  'can',\n",
       "  'not',\n",
       "  'think',\n",
       "  'as',\n",
       "  'individuals',\n",
       "  'and',\n",
       "  'must',\n",
       "  'conform',\n",
       "  'to',\n",
       "  'societies',\n",
       "  'way',\n",
       "  'of',\n",
       "  'thinking',\n",
       "  '.'],\n",
       " ['nuclear_weapons',\n",
       "  'can',\n",
       "  'bring',\n",
       "  'about',\n",
       "  'a',\n",
       "  'certain',\n",
       "  'level',\n",
       "  'of',\n",
       "  'respect'],\n",
       " ['scientology',\n",
       "  'is',\n",
       "  'actually',\n",
       "  'a',\n",
       "  'wealthy',\n",
       "  'cult',\n",
       "  'and',\n",
       "  'members',\n",
       "  'are',\n",
       "  'abused',\n",
       "  'physically',\n",
       "  'and',\n",
       "  'financially',\n",
       "  '.'],\n",
       " ['child_actors',\n",
       "  'lose',\n",
       "  'the',\n",
       "  'sense',\n",
       "  'of',\n",
       "  'a',\n",
       "  'proper',\n",
       "  'childhood',\n",
       "  '.'],\n",
       " ['we', 'need', 'the', 'three', 'strikes', 'as', 'a', 'deterrent'],\n",
       " ['a',\n",
       "  'non',\n",
       "  '-',\n",
       "  'denominational',\n",
       "  'school',\n",
       "  'prayer',\n",
       "  'is',\n",
       "  'about',\n",
       "  'as',\n",
       "  'bad',\n",
       "  'as',\n",
       "  'reciting',\n",
       "  'the',\n",
       "  'pledge',\n",
       "  'of',\n",
       "  'allegiance',\n",
       "  'in',\n",
       "  'school',\n",
       "  ',',\n",
       "  'and',\n",
       "  'should',\n",
       "  'be',\n",
       "  'allowed',\n",
       "  '.'],\n",
       " ['children',\n",
       "  'need',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'boundaries',\n",
       "  'and',\n",
       "  'consequences',\n",
       "  'for',\n",
       "  'their',\n",
       "  'actions',\n",
       "  '.',\n",
       "  'they',\n",
       "  'learn',\n",
       "  'faster',\n",
       "  'if',\n",
       "  'there',\n",
       "  'is',\n",
       "  'immediate',\n",
       "  'repercussions',\n",
       "  'than',\n",
       "  'if',\n",
       "  'you',\n",
       "  'let',\n",
       "  'them',\n",
       "  'do',\n",
       "  'it',\n",
       "  'over',\n",
       "  'and',\n",
       "  'over',\n",
       "  'again',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'limit',\n",
       "  'executive_compensation',\n",
       "  'as',\n",
       "  'they',\n",
       "  'should',\n",
       "  'get',\n",
       "  'the',\n",
       "  'salary',\n",
       "  'equal',\n",
       "  'to',\n",
       "  'their',\n",
       "  'contribution',\n",
       "  'to',\n",
       "  'the',\n",
       "  'organisation',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'will',\n",
       "  'decrease',\n",
       "  'the',\n",
       "  'number',\n",
       "  'of',\n",
       "  'crimes',\n",
       "  'and',\n",
       "  'violence',\n",
       "  'on',\n",
       "  'the',\n",
       "  'streets'],\n",
       " ['economic_sanctions', 'are', 'often', 'a', 'proportional', 'punishment'],\n",
       " ['autonomous_cars', 'are', 'prohibitively', 'expensive'],\n",
       " ['school_uniforms',\n",
       "  'cost',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'and',\n",
       "  'might',\n",
       "  'not',\n",
       "  'be',\n",
       "  'affordable',\n",
       "  'for',\n",
       "  'everyone'],\n",
       " ['mandatory_retirement',\n",
       "  'lets',\n",
       "  'companies',\n",
       "  'more',\n",
       "  'easily',\n",
       "  'make',\n",
       "  'space',\n",
       "  'for',\n",
       "  'new',\n",
       "  'workers',\n",
       "  'that',\n",
       "  'have',\n",
       "  'more',\n",
       "  'of',\n",
       "  'an',\n",
       "  'incentive',\n",
       "  'to',\n",
       "  'work',\n",
       "  'hard',\n",
       "  'at',\n",
       "  'a',\n",
       "  'new',\n",
       "  'job',\n",
       "  '.'],\n",
       " ['a',\n",
       "  'zero',\n",
       "  'tolerance_policy',\n",
       "  'at',\n",
       "  'school',\n",
       "  'is',\n",
       "  'a',\n",
       "  'good',\n",
       "  'idea',\n",
       "  'because',\n",
       "  'children',\n",
       "  'need',\n",
       "  'to',\n",
       "  'be',\n",
       "  'disciplined',\n",
       "  'as',\n",
       "  'it',\n",
       "  'might',\n",
       "  'cut',\n",
       "  'crime',\n",
       "  'in',\n",
       "  'the',\n",
       "  'future',\n",
       "  '.'],\n",
       " ['safe_spaces',\n",
       "  'stifle',\n",
       "  'dialogue',\n",
       "  'about',\n",
       "  'controversial',\n",
       "  'topics',\n",
       "  ',',\n",
       "  'such',\n",
       "  'as',\n",
       "  'race',\n",
       "  ',',\n",
       "  'gender',\n",
       "  'and',\n",
       "  'religion',\n",
       "  '.'],\n",
       " ['economic_sanctions',\n",
       "  'are',\n",
       "  'unethical',\n",
       "  'to',\n",
       "  'the',\n",
       "  'economies',\n",
       "  'of',\n",
       "  'smaller',\n",
       "  ',',\n",
       "  'underdeveloped',\n",
       "  'countries',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'ban',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'child_actors',\n",
       "  'since',\n",
       "  'it',\n",
       "  'puts',\n",
       "  'so',\n",
       "  'much',\n",
       "  'pressure',\n",
       "  'on',\n",
       "  'them',\n",
       "  '.',\n",
       "  'they',\n",
       "  'should',\n",
       "  'be',\n",
       "  'growing',\n",
       "  'up',\n",
       "  'with',\n",
       "  'a',\n",
       "  'stable',\n",
       "  'life',\n",
       "  'and',\n",
       "  'just',\n",
       "  'enjoy',\n",
       "  'being',\n",
       "  'a',\n",
       "  'kid',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'subsidize',\n",
       "  'student_loans',\n",
       "  'as',\n",
       "  'these',\n",
       "  'are',\n",
       "  'our',\n",
       "  'future',\n",
       "  'leaders',\n",
       "  'and',\n",
       "  'workers',\n",
       "  'and',\n",
       "  'we',\n",
       "  'want',\n",
       "  'to',\n",
       "  'ensure',\n",
       "  'their',\n",
       "  'success',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'secure',\n",
       "  'the',\n",
       "  'countries',\n",
       "  'success',\n",
       "  '.'],\n",
       " ['prostitution',\n",
       "  'should',\n",
       "  'be',\n",
       "  'legal',\n",
       "  'as',\n",
       "  'it',\n",
       "  'can',\n",
       "  'be',\n",
       "  'controlled',\n",
       "  '&',\n",
       "  'monitored',\n",
       "  'easier',\n",
       "  '&',\n",
       "  'be',\n",
       "  'less',\n",
       "  'dangerous'],\n",
       " ['pride',\n",
       "  'marches',\n",
       "  'are',\n",
       "  'a',\n",
       "  'crucial',\n",
       "  'part',\n",
       "  'of',\n",
       "  'gay',\n",
       "  'visibility',\n",
       "  'and',\n",
       "  'the',\n",
       "  'fight',\n",
       "  'for',\n",
       "  'equality',\n",
       "  '.',\n",
       "  'ensuring',\n",
       "  'that',\n",
       "  'the',\n",
       "  'fight',\n",
       "  'against',\n",
       "  'injustice',\n",
       "  'continues',\n",
       "  ',',\n",
       "  'especially',\n",
       "  'in',\n",
       "  'countries',\n",
       "  'where',\n",
       "  'homosexuality',\n",
       "  'is',\n",
       "  'still',\n",
       "  'a',\n",
       "  'criminal',\n",
       "  'offense',\n",
       "  '.'],\n",
       " ['pride_parades',\n",
       "  'allow',\n",
       "  'people',\n",
       "  'to',\n",
       "  'make',\n",
       "  'connections',\n",
       "  'and',\n",
       "  'widen',\n",
       "  'their',\n",
       "  'social',\n",
       "  'circles',\n",
       "  '.'],\n",
       " ['people', 'should', 'keep', 'their', 'religion', 'to', 'themselves'],\n",
       " ['not',\n",
       "  'everybody',\n",
       "  'believes',\n",
       "  'in',\n",
       "  'or',\n",
       "  'practices',\n",
       "  'a',\n",
       "  'religion',\n",
       "  'so',\n",
       "  'we',\n",
       "  'should',\n",
       "  'adopt',\n",
       "  'atheism',\n",
       "  'for',\n",
       "  'them'],\n",
       " ['economic_sanctions',\n",
       "  'are',\n",
       "  'used',\n",
       "  'to',\n",
       "  'bully',\n",
       "  'other',\n",
       "  'nations',\n",
       "  'to',\n",
       "  'act',\n",
       "  'in',\n",
       "  'your',\n",
       "  'own',\n",
       "  'interest',\n",
       "  ',',\n",
       "  'by',\n",
       "  'harming',\n",
       "  'the',\n",
       "  'innocent',\n",
       "  'citizens',\n",
       "  'no',\n",
       "  'less'],\n",
       " ['only',\n",
       "  'governments',\n",
       "  'can',\n",
       "  'be',\n",
       "  'trusted',\n",
       "  'with',\n",
       "  'armies',\n",
       "  'so',\n",
       "  'we',\n",
       "  'should',\n",
       "  'ban',\n",
       "  'private_military',\n",
       "  'companies',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'sets',\n",
       "  'a',\n",
       "  'bad',\n",
       "  'example',\n",
       "  'for',\n",
       "  'younger',\n",
       "  'generation',\n",
       "  'and',\n",
       "  'takes',\n",
       "  'them',\n",
       "  'away',\n",
       "  'from',\n",
       "  'the',\n",
       "  'ethics',\n",
       "  'of',\n",
       "  'the',\n",
       "  'society'],\n",
       " ['there',\n",
       "  'are',\n",
       "  'much',\n",
       "  'more',\n",
       "  'important',\n",
       "  'things',\n",
       "  'to',\n",
       "  'spend',\n",
       "  'money',\n",
       "  'on',\n",
       "  ';',\n",
       "  'space_exploration',\n",
       "  'is',\n",
       "  'a',\n",
       "  'low',\n",
       "  'priority',\n",
       "  'and',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'subsidized'],\n",
       " ['journalism',\n",
       "  'is',\n",
       "  'more',\n",
       "  'important',\n",
       "  'than',\n",
       "  'ever',\n",
       "  'in',\n",
       "  'an',\n",
       "  'era',\n",
       "  'of',\n",
       "  'fake',\n",
       "  'news',\n",
       "  'and',\n",
       "  'social',\n",
       "  'media',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'abolish',\n",
       "  'the',\n",
       "  'olympic_games',\n",
       "  'because',\n",
       "  'bring',\n",
       "  'together',\n",
       "  'different',\n",
       "  'nations',\n",
       "  'with',\n",
       "  'radically',\n",
       "  'different',\n",
       "  'governments',\n",
       "  'is',\n",
       "  'dangerous',\n",
       "  '.'],\n",
       " ['factory_farming',\n",
       "  'treats',\n",
       "  'animals',\n",
       "  'inhumanely',\n",
       "  ',',\n",
       "  'which',\n",
       "  'is',\n",
       "  'wrong',\n",
       "  'and',\n",
       "  'immoral',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'need',\n",
       "  'to',\n",
       "  'prohibit',\n",
       "  'school',\n",
       "  'prayer',\n",
       "  ',',\n",
       "  'as',\n",
       "  'not',\n",
       "  'all',\n",
       "  'people',\n",
       "  'agree',\n",
       "  'with',\n",
       "  'it',\n",
       "  'and',\n",
       "  'it',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'forced',\n",
       "  'on',\n",
       "  'anyone'],\n",
       " ['setting',\n",
       "  'a',\n",
       "  'mandatory_retirement',\n",
       "  'age',\n",
       "  'allows',\n",
       "  'for',\n",
       "  'the',\n",
       "  'younger',\n",
       "  'generations',\n",
       "  'to',\n",
       "  'move',\n",
       "  'up',\n",
       "  'the',\n",
       "  'ladder',\n",
       "  'and',\n",
       "  'to',\n",
       "  'better',\n",
       "  'support',\n",
       "  'their',\n",
       "  'own',\n",
       "  'families',\n",
       "  '.'],\n",
       " ['the', 'olympic_games', 'encourage', 'animosity', 'between', 'countries'],\n",
       " ['austerity',\n",
       "  'only',\n",
       "  'leads',\n",
       "  'to',\n",
       "  'economic',\n",
       "  'contraction',\n",
       "  'that',\n",
       "  'endangers',\n",
       "  'the',\n",
       "  'chance',\n",
       "  'of',\n",
       "  'reducing',\n",
       "  'the',\n",
       "  'debt',\n",
       "  '.'],\n",
       " ['there',\n",
       "  'are',\n",
       "  'far',\n",
       "  'more',\n",
       "  'than',\n",
       "  'two',\n",
       "  'genders',\n",
       "  'today',\n",
       "  ',',\n",
       "  'and',\n",
       "  'thus',\n",
       "  ',',\n",
       "  'gender',\n",
       "  '-',\n",
       "  'neutral_language',\n",
       "  'only',\n",
       "  'makes',\n",
       "  'sense',\n",
       "  '.'],\n",
       " ['safe',\n",
       "  'places',\n",
       "  'are',\n",
       "  'not',\n",
       "  'needed',\n",
       "  '.',\n",
       "  'people',\n",
       "  'need',\n",
       "  'to',\n",
       "  'adjust',\n",
       "  'to',\n",
       "  'the',\n",
       "  'world',\n",
       "  'in',\n",
       "  'which',\n",
       "  'they',\n",
       "  'live',\n",
       "  'in',\n",
       "  'and',\n",
       "  'stop',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'always',\n",
       "  'seek',\n",
       "  'protection',\n",
       "  'from',\n",
       "  'the',\n",
       "  'things',\n",
       "  'they',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'like',\n",
       "  '.'],\n",
       " ['there',\n",
       "  'are',\n",
       "  'too',\n",
       "  'many',\n",
       "  'historical',\n",
       "  'cases',\n",
       "  'where',\n",
       "  'innocent',\n",
       "  'people',\n",
       "  'have',\n",
       "  'been',\n",
       "  'put',\n",
       "  'to',\n",
       "  'death',\n",
       "  '.'],\n",
       " ['multi',\n",
       "  '-',\n",
       "  'party',\n",
       "  'systems',\n",
       "  'offer',\n",
       "  'voters',\n",
       "  'more',\n",
       "  'choices',\n",
       "  'and',\n",
       "  'more',\n",
       "  'representation',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'can',\n",
       "  'not',\n",
       "  'abolish',\n",
       "  'intellectual_property',\n",
       "  'rights',\n",
       "  'because',\n",
       "  'artists',\n",
       "  'and',\n",
       "  'scientists',\n",
       "  'need',\n",
       "  'to',\n",
       "  'have',\n",
       "  'their',\n",
       "  'ideas',\n",
       "  'and',\n",
       "  'innovations',\n",
       "  'protected',\n",
       "  'so',\n",
       "  'that',\n",
       "  'they',\n",
       "  'can',\n",
       "  'earn',\n",
       "  'a',\n",
       "  'living',\n",
       "  'in',\n",
       "  'their',\n",
       "  'fields'],\n",
       " ['with',\n",
       "  'so',\n",
       "  'much',\n",
       "  'sexual',\n",
       "  'freedom',\n",
       "  'these',\n",
       "  'days',\n",
       "  'prostitution',\n",
       "  'should',\n",
       "  'now',\n",
       "  'be',\n",
       "  'legal',\n",
       "  '.'],\n",
       " ['they', 'can', 'cause', 'accidents', 'if', 'the', 'equipment', 'fails', '.'],\n",
       " ['cannabis',\n",
       "  'especially',\n",
       "  'the',\n",
       "  'skunk',\n",
       "  'variety',\n",
       "  'can',\n",
       "  'be',\n",
       "  'very',\n",
       "  'harmful',\n",
       "  'to',\n",
       "  'people',\n",
       "  'and',\n",
       "  'can',\n",
       "  'lead',\n",
       "  'on',\n",
       "  'to',\n",
       "  'them',\n",
       "  'using',\n",
       "  'harder',\n",
       "  'drugs',\n",
       "  'so',\n",
       "  'therefore',\n",
       "  'it',\n",
       "  'should',\n",
       "  'be',\n",
       "  'illegal',\n",
       "  '.'],\n",
       " ['judicial_activism',\n",
       "  'relies',\n",
       "  'too',\n",
       "  'heavily',\n",
       "  'upon',\n",
       "  'personal',\n",
       "  'opinion',\n",
       "  'and',\n",
       "  'leads',\n",
       "  'to',\n",
       "  'bias',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'all',\n",
       "  'have',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'eat',\n",
       "  'what',\n",
       "  'we',\n",
       "  'want',\n",
       "  ',',\n",
       "  'to',\n",
       "  'prohibit',\n",
       "  'a',\n",
       "  'specific',\n",
       "  'type',\n",
       "  'of',\n",
       "  'food',\n",
       "  'is',\n",
       "  'an',\n",
       "  'abuse',\n",
       "  'of',\n",
       "  'power'],\n",
       " ['allowing',\n",
       "  'students',\n",
       "  'to',\n",
       "  'make',\n",
       "  'their',\n",
       "  'own',\n",
       "  'choices',\n",
       "  'regarding',\n",
       "  'the',\n",
       "  'clothes',\n",
       "  'they',\n",
       "  'wear',\n",
       "  'prepares',\n",
       "  'them',\n",
       "  'for',\n",
       "  'the',\n",
       "  'adult',\n",
       "  'world',\n",
       "  '.'],\n",
       " ['missionaries',\n",
       "  'are',\n",
       "  'intrusive',\n",
       "  'to',\n",
       "  'other',\n",
       "  'countries',\n",
       "  'and',\n",
       "  'very',\n",
       "  'invasive',\n",
       "  'to',\n",
       "  'the',\n",
       "  'culture',\n",
       "  '.'],\n",
       " ['cosmetic_surgery',\n",
       "  'exists',\n",
       "  'for',\n",
       "  'vanity',\n",
       "  'purposes',\n",
       "  'doctors',\n",
       "  'who',\n",
       "  'offer',\n",
       "  'the',\n",
       "  'service',\n",
       "  'should',\n",
       "  'focus',\n",
       "  'on',\n",
       "  'treating',\n",
       "  'people',\n",
       "  'with',\n",
       "  'real',\n",
       "  'illnesses'],\n",
       " ['the',\n",
       "  'church',\n",
       "  'of',\n",
       "  'scientology',\n",
       "  'is',\n",
       "  'a',\n",
       "  'cult',\n",
       "  'that',\n",
       "  'is',\n",
       "  'harming',\n",
       "  'society',\n",
       "  '.'],\n",
       " ['there',\n",
       "  'is',\n",
       "  'no',\n",
       "  'need',\n",
       "  'to',\n",
       "  'subsidize',\n",
       "  'a',\n",
       "  'site',\n",
       "  'that',\n",
       "  'is',\n",
       "  \"n't\",\n",
       "  'necessary'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'adopt',\n",
       "  'libertarianism',\n",
       "  'because',\n",
       "  'we',\n",
       "  'need',\n",
       "  'the',\n",
       "  'government',\n",
       "  'to',\n",
       "  'provide',\n",
       "  'essential',\n",
       "  'services',\n",
       "  'that',\n",
       "  'are',\n",
       "  'unprofitable',\n",
       "  '.'],\n",
       " ['a',\n",
       "  'person',\n",
       "  \"'s\",\n",
       "  'education',\n",
       "  'should',\n",
       "  'be',\n",
       "  'the',\n",
       "  'responsibility',\n",
       "  'of',\n",
       "  'themselves'],\n",
       " ['the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'and',\n",
       "  'bear_arms',\n",
       "  'is',\n",
       "  'protected',\n",
       "  'by',\n",
       "  'our',\n",
       "  'government',\n",
       "  'and',\n",
       "  'should',\n",
       "  'be',\n",
       "  'like',\n",
       "  'that',\n",
       "  'so',\n",
       "  'people',\n",
       "  'can',\n",
       "  'defend',\n",
       "  'their',\n",
       "  'self',\n",
       "  '.'],\n",
       " ['cannabis',\n",
       "  'should',\n",
       "  'be',\n",
       "  'legalized',\n",
       "  'because',\n",
       "  'it',\n",
       "  'is',\n",
       "  'no',\n",
       "  'worse',\n",
       "  'than',\n",
       "  'alchohol',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'support',\n",
       "  'pride_parades',\n",
       "  'because',\n",
       "  'everyone',\n",
       "  'has',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'do',\n",
       "  'what',\n",
       "  'they',\n",
       "  'want',\n",
       "  'as',\n",
       "  'long',\n",
       "  'as',\n",
       "  'it',\n",
       "  'does',\n",
       "  'not',\n",
       "  'harm',\n",
       "  'others',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'support',\n",
       "  'algorithmic_trading',\n",
       "  'as',\n",
       "  'it',\n",
       "  'gives',\n",
       "  'orders',\n",
       "  'a',\n",
       "  'jump',\n",
       "  'start',\n",
       "  'rather_than',\n",
       "  'waiting',\n",
       "  'until',\n",
       "  'the',\n",
       "  'complete',\n",
       "  'order',\n",
       "  'has',\n",
       "  'been',\n",
       "  'produced',\n",
       "  '.'],\n",
       " ['if',\n",
       "  'we',\n",
       "  'end',\n",
       "  'economic_sanctions',\n",
       "  ',',\n",
       "  'then',\n",
       "  'it',\n",
       "  'would',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'a',\n",
       "  'more',\n",
       "  'fair',\n",
       "  'trade',\n",
       "  'market',\n",
       "  '.'],\n",
       " ['school_uniforms',\n",
       "  'are',\n",
       "  'a',\n",
       "  'good',\n",
       "  'way',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'our',\n",
       "  'kids',\n",
       "  'from',\n",
       "  'looking',\n",
       "  'too',\n",
       "  'sexualized',\n",
       "  'from',\n",
       "  'what',\n",
       "  'they',\n",
       "  'wear'],\n",
       " ['gender', 'selection', 'is', 'essentially', 'playing', 'god', '.'],\n",
       " ['the',\n",
       "  'church',\n",
       "  'of',\n",
       "  'scientology',\n",
       "  'is',\n",
       "  'a',\n",
       "  'predatory',\n",
       "  ',',\n",
       "  'litigation',\n",
       "  '-',\n",
       "  'happy',\n",
       "  'organization',\n",
       "  'that',\n",
       "  'serves',\n",
       "  'no',\n",
       "  'good',\n",
       "  'purpose',\n",
       "  'in',\n",
       "  'the',\n",
       "  'world',\n",
       "  '.'],\n",
       " ['animals',\n",
       "  'in',\n",
       "  'zoos',\n",
       "  'have',\n",
       "  'been',\n",
       "  'repeatedly',\n",
       "  'found',\n",
       "  'to',\n",
       "  'be',\n",
       "  'malnourished',\n",
       "  'and',\n",
       "  'mistreated',\n",
       "  '.'],\n",
       " ['organ',\n",
       "  'sales',\n",
       "  'increase',\n",
       "  'the',\n",
       "  'likelihood',\n",
       "  'that',\n",
       "  'people',\n",
       "  'with',\n",
       "  'rare',\n",
       "  'blood',\n",
       "  'types',\n",
       "  'or',\n",
       "  'conditions',\n",
       "  'can',\n",
       "  'find',\n",
       "  'an',\n",
       "  'organ',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'bear_arms',\n",
       "  'is',\n",
       "  'a',\n",
       "  'fundamental',\n",
       "  'right',\n",
       "  'since',\n",
       "  'the',\n",
       "  'creation',\n",
       "  'of',\n",
       "  ' ',\n",
       "  'this',\n",
       "  'country',\n",
       "  ',',\n",
       "  'and',\n",
       "  'should',\n",
       "  'be',\n",
       "  'protected',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'number',\n",
       "  'of',\n",
       "  'fatalities',\n",
       "  'that',\n",
       "  'can',\n",
       "  'be',\n",
       "  'prevented',\n",
       "  'with',\n",
       "  'autonomous_cars',\n",
       "  'makes',\n",
       "  'the',\n",
       "  'development',\n",
       "  'a',\n",
       "  'moral',\n",
       "  'imperative',\n",
       "  '.'],\n",
       " ['adopting',\n",
       "  'a',\n",
       "  'multi',\n",
       "  '-',\n",
       "  'party_system',\n",
       "  'leads',\n",
       "  'to',\n",
       "  'the',\n",
       "  'formation',\n",
       "  'weak',\n",
       "  'and',\n",
       "  'unstable',\n",
       "  'coalition',\n",
       "  'governments'],\n",
       " ['not',\n",
       "  'all',\n",
       "  'tv',\n",
       "  'and',\n",
       "  'movies',\n",
       "  'is',\n",
       "  'going',\n",
       "  'to',\n",
       "  'be',\n",
       "  'adults',\n",
       "  'only',\n",
       "  'we',\n",
       "  'need',\n",
       "  'child_actors',\n",
       "  'to',\n",
       "  'shows',\n",
       "  'the',\n",
       "  'world',\n",
       "  'as',\n",
       "  'it',\n",
       "  'is'],\n",
       " ['judicial_activism',\n",
       "  'allows',\n",
       "  'for',\n",
       "  'common',\n",
       "  'sense',\n",
       "  'to',\n",
       "  'be',\n",
       "  'applied',\n",
       "  'where',\n",
       "  'necessary'],\n",
       " ['executives',\n",
       "  'provide',\n",
       "  'profits',\n",
       "  'to',\n",
       "  'shareholders',\n",
       "  'and',\n",
       "  'should',\n",
       "  'be',\n",
       "  'compensated',\n",
       "  'accordingly'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'against',\n",
       "  'certain',\n",
       "  'religious',\n",
       "  'beliefs',\n",
       "  'and',\n",
       "  'can',\n",
       "  'be',\n",
       "  'seen',\n",
       "  'as',\n",
       "  'immoral'],\n",
       " ['sex_selection',\n",
       "  'is',\n",
       "  'the',\n",
       "  'perfect',\n",
       "  'solution',\n",
       "  'to',\n",
       "  'a',\n",
       "  'family',\n",
       "  'that',\n",
       "  'has',\n",
       "  'a',\n",
       "  'history',\n",
       "  'of',\n",
       "  'all',\n",
       "  'one',\n",
       "  'gender',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'many',\n",
       "  'families',\n",
       "  'want',\n",
       "  'the',\n",
       "  'perfect',\n",
       "  'one',\n",
       "  'and',\n",
       "  'one',\n",
       "  'so',\n",
       "  'it',\n",
       "  \"'s\",\n",
       "  'perfect',\n",
       "  'for',\n",
       "  'those',\n",
       "  'as',\n",
       "  'well',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'it',\n",
       "  \"'s\",\n",
       "  'a',\n",
       "  'win',\n",
       "  'no',\n",
       "  'matter',\n",
       "  'how',\n",
       "  'you',\n",
       "  'look',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'ban',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'child_actors',\n",
       "  'because',\n",
       "  'we',\n",
       "  'would',\n",
       "  'not',\n",
       "  'have',\n",
       "  'the',\n",
       "  'shows',\n",
       "  'and',\n",
       "  'movies',\n",
       "  'that',\n",
       "  'are',\n",
       "  'otherwise',\n",
       "  'available',\n",
       "  '.'],\n",
       " ['non',\n",
       "  '-',\n",
       "  'trustworthy',\n",
       "  'news',\n",
       "  'sources',\n",
       "  'and',\n",
       "  'fake',\n",
       "  'news',\n",
       "  'stories',\n",
       "  'abound',\n",
       "  '.',\n",
       "  'we',\n",
       "  'must',\n",
       "  'subsidize',\n",
       "  'investigative',\n",
       "  'journalism',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'ensure',\n",
       "  'we',\n",
       "  'have',\n",
       "  'reliable',\n",
       "  'news',\n",
       "  'sources',\n",
       "  'that',\n",
       "  'report',\n",
       "  'real',\n",
       "  'facts',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'ban',\n",
       "  'cosmetic_surgery',\n",
       "  'for',\n",
       "  'minors',\n",
       "  'because',\n",
       "  'there',\n",
       "  'are',\n",
       "  'legitimate',\n",
       "  'cases',\n",
       "  'when',\n",
       "  'it',\n",
       "  'would',\n",
       "  'improve',\n",
       "  'a',\n",
       "  'young',\n",
       "  'person',\n",
       "  \"'s\",\n",
       "  'mental',\n",
       "  'health',\n",
       "  '.'],\n",
       " ['bullies',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'given',\n",
       "  'second',\n",
       "  'chances',\n",
       "  '.',\n",
       "  'being',\n",
       "  'victim',\n",
       "  'to',\n",
       "  'school',\n",
       "  'bullying',\n",
       "  'is',\n",
       "  'a',\n",
       "  'major',\n",
       "  'risk',\n",
       "  'factor',\n",
       "  'for',\n",
       "  'developing',\n",
       "  'mental',\n",
       "  'health',\n",
       "  'problems',\n",
       "  'like',\n",
       "  'depression',\n",
       "  ',',\n",
       "  'anxiety',\n",
       "  ',',\n",
       "  'and',\n",
       "  'even',\n",
       "  'suicidal',\n",
       "  'thoughts',\n",
       "  '.'],\n",
       " ['an',\n",
       "  'austerity_regime',\n",
       "  'would',\n",
       "  'eliminate',\n",
       "  'the',\n",
       "  'national',\n",
       "  'debt',\n",
       "  'by',\n",
       "  'directing',\n",
       "  'money',\n",
       "  'to',\n",
       "  'where',\n",
       "  'it',\n",
       "  'really',\n",
       "  'needs',\n",
       "  'to',\n",
       "  'go',\n",
       "  '.'],\n",
       " ['algorithmic_trading',\n",
       "  'gives',\n",
       "  'people',\n",
       "  'an',\n",
       "  'unfair',\n",
       "  'speed',\n",
       "  'advantage',\n",
       "  'over',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'the',\n",
       "  'field',\n",
       "  '.'],\n",
       " ['if',\n",
       "  'someone',\n",
       "  'has',\n",
       "  \"n't\",\n",
       "  'learned',\n",
       "  'by',\n",
       "  'the',\n",
       "  'first',\n",
       "  'two',\n",
       "  'chances',\n",
       "  'then',\n",
       "  'they',\n",
       "  'are',\n",
       "  \"n't\",\n",
       "  'going',\n",
       "  'to',\n",
       "  'stop',\n",
       "  'committing',\n",
       "  'crimes',\n",
       "  '.',\n",
       "  'it',\n",
       "  'makes',\n",
       "  'more',\n",
       "  'sense',\n",
       "  'to',\n",
       "  'lock',\n",
       "  'them',\n",
       "  'away',\n",
       "  'than',\n",
       "  'to',\n",
       "  'let',\n",
       "  'them',\n",
       "  'keep',\n",
       "  'committing',\n",
       "  'crimes',\n",
       "  'against',\n",
       "  'the',\n",
       "  'population',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'adopt',\n",
       "  'libertarianism',\n",
       "  'because',\n",
       "  'it',\n",
       "  'will',\n",
       "  'allow',\n",
       "  'people',\n",
       "  'to',\n",
       "  'take',\n",
       "  'advantage',\n",
       "  'of',\n",
       "  'the',\n",
       "  'freedoms',\n",
       "  'and',\n",
       "  'eventually',\n",
       "  'infringe',\n",
       "  'on',\n",
       "  'other',\n",
       "  'people',\n",
       "  \"'s\",\n",
       "  'freedoms',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'abolition',\n",
       "  'of',\n",
       "  'nuclear_weapons',\n",
       "  'is',\n",
       "  'a',\n",
       "  'hugely',\n",
       "  'important',\n",
       "  'goal',\n",
       "  'on',\n",
       "  'the',\n",
       "  'path',\n",
       "  'to',\n",
       "  'world',\n",
       "  'peace',\n",
       "  '.'],\n",
       " ['every',\n",
       "  'individual',\n",
       "  'should',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'choose',\n",
       "  'whether',\n",
       "  'or',\n",
       "  'not',\n",
       "  'they',\n",
       "  'want',\n",
       "  'to',\n",
       "  'vote'],\n",
       " ['banning',\n",
       "  'telemarketing',\n",
       "  'has',\n",
       "  'no',\n",
       "  'approval',\n",
       "  'anywhere',\n",
       "  'as',\n",
       "  'customers',\n",
       "  'will',\n",
       "  'not',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'see',\n",
       "  'new',\n",
       "  'products',\n",
       "  'available',\n",
       "  'to',\n",
       "  'buy',\n",
       "  '.'],\n",
       " ['targetted',\n",
       "  'killing',\n",
       "  'could',\n",
       "  'potentially',\n",
       "  'help',\n",
       "  'reduce',\n",
       "  'the',\n",
       "  'number',\n",
       "  'of',\n",
       "  'crimes',\n",
       "  'if',\n",
       "  'terrorists',\n",
       "  'are',\n",
       "  'killed',\n",
       "  'before',\n",
       "  'they',\n",
       "  'can',\n",
       "  'cause',\n",
       "  'more',\n",
       "  'harm'],\n",
       " ['we',\n",
       "  'have',\n",
       "  'seperation',\n",
       "  'of',\n",
       "  'church',\n",
       "  'and',\n",
       "  'state',\n",
       "  'for',\n",
       "  'a',\n",
       "  'reason',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'schools',\n",
       "  'are',\n",
       "  'a',\n",
       "  'government',\n",
       "  'entity',\n",
       "  'that',\n",
       "  'is',\n",
       "  'not',\n",
       "  'suppose',\n",
       "  'to',\n",
       "  'be',\n",
       "  'involved',\n",
       "  'with',\n",
       "  ',',\n",
       "  'or',\n",
       "  'support',\n",
       "  ',',\n",
       "  'any',\n",
       "  'particular',\n",
       "  'religion',\n",
       "  'and',\n",
       "  'the',\n",
       "  'two',\n",
       "  'need',\n",
       "  'to',\n",
       "  'stay',\n",
       "  'seperate',\n",
       "  '.'],\n",
       " ['though',\n",
       "  'it',\n",
       "  'may',\n",
       "  'sound',\n",
       "  'awful',\n",
       "  ',',\n",
       "  'human_cloning',\n",
       "  'can',\n",
       "  'provide',\n",
       "  'perfect',\n",
       "  'matches',\n",
       "  'for',\n",
       "  'organ',\n",
       "  'transplants',\n",
       "  'and',\n",
       "  'prolong',\n",
       "  'the',\n",
       "  'lives',\n",
       "  'of',\n",
       "  'people',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'abolish',\n",
       "  'intellectual_property',\n",
       "  'rights',\n",
       "  'to',\n",
       "  'break',\n",
       "  'to',\n",
       "  'the',\n",
       "  'barriers',\n",
       "  'if',\n",
       "  'innovation',\n",
       "  ',',\n",
       "  'barring',\n",
       "  'people',\n",
       "  'from',\n",
       "  'building',\n",
       "  'on',\n",
       "  'and',\n",
       "  'improving',\n",
       "  'ideas',\n",
       "  'is',\n",
       "  'counter',\n",
       "  'productive'],\n",
       " ['supporting',\n",
       "  'collectivism',\n",
       "  'is',\n",
       "  'important',\n",
       "  'because',\n",
       "  'groups',\n",
       "  'value',\n",
       "  'is',\n",
       "  'most',\n",
       "  'important',\n",
       "  'in',\n",
       "  'the',\n",
       "  'society',\n",
       "  'which',\n",
       "  'we',\n",
       "  'live',\n",
       "  'today',\n",
       "  '.'],\n",
       " ['yes',\n",
       "  'ban',\n",
       "  'it',\n",
       "  ',',\n",
       "  'if',\n",
       "  'i',\n",
       "  'wanted',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'something',\n",
       "  'i',\n",
       "  'would',\n",
       "  'know',\n",
       "  'where',\n",
       "  'to',\n",
       "  'look',\n",
       "  'for',\n",
       "  'it',\n",
       "  'without',\n",
       "  'being',\n",
       "  'bothered',\n",
       "  'with',\n",
       "  'constant',\n",
       "  'calls'],\n",
       " ['whaling',\n",
       "  'is',\n",
       "  'an',\n",
       "  'important',\n",
       "  'part',\n",
       "  'of',\n",
       "  'the',\n",
       "  'diet',\n",
       "  ',',\n",
       "  'tradition',\n",
       "  'and',\n",
       "  'economies',\n",
       "  'of',\n",
       "  'many',\n",
       "  'countries',\n",
       "  ',',\n",
       "  'and',\n",
       "  'it',\n",
       "  'is',\n",
       "  'not',\n",
       "  'our',\n",
       "  'place',\n",
       "  'to',\n",
       "  'dictate',\n",
       "  'terms',\n",
       "  'as',\n",
       "  'outsiders',\n",
       "  'to',\n",
       "  'their',\n",
       "  'culture',\n",
       "  '.'],\n",
       " ['wikipedia',\n",
       "  'is',\n",
       "  'valuable',\n",
       "  'knowledge',\n",
       "  'resource',\n",
       "  'that',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'allowed',\n",
       "  'to',\n",
       "  'go',\n",
       "  'under',\n",
       "  'due',\n",
       "  'to',\n",
       "  'lack',\n",
       "  'of',\n",
       "  'resources',\n",
       "  'and',\n",
       "  'so',\n",
       "  'should',\n",
       "  'be',\n",
       "  'subsidized'],\n",
       " ['a',\n",
       "  'zero',\n",
       "  'tolerance_policy',\n",
       "  'will',\n",
       "  'scare',\n",
       "  'the',\n",
       "  'children',\n",
       "  'into',\n",
       "  'behaving',\n",
       "  'and',\n",
       "  'following',\n",
       "  'the',\n",
       "  'rules',\n",
       "  '.'],\n",
       " ['people',\n",
       "  'have',\n",
       "  'to',\n",
       "  'right',\n",
       "  'to',\n",
       "  'their',\n",
       "  'own',\n",
       "  'religious',\n",
       "  'beliefs',\n",
       "  ',',\n",
       "  'no',\n",
       "  'matter',\n",
       "  'how',\n",
       "  'odd',\n",
       "  'others',\n",
       "  'find',\n",
       "  'it'],\n",
       " ['our',\n",
       "  'country',\n",
       "  'need',\n",
       "  'to',\n",
       "  'adopt',\n",
       "  'the',\n",
       "  'less',\n",
       "  'intervention',\n",
       "  'supported',\n",
       "  'by',\n",
       "  'libertarianism',\n",
       "  '.',\n",
       "  'people',\n",
       "  'need',\n",
       "  'to',\n",
       "  'make',\n",
       "  'their',\n",
       "  'own',\n",
       "  'choice',\n",
       "  'and',\n",
       "  'be',\n",
       "  'responsible',\n",
       "  'for',\n",
       "  'the',\n",
       "  'outcome',\n",
       "  '.'],\n",
       " ['a',\n",
       "  'judge',\n",
       "  'should',\n",
       "  'nt',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'show',\n",
       "  'their',\n",
       "  'personal',\n",
       "  'views',\n",
       "  '.'],\n",
       " ['libertarianism',\n",
       "  'is',\n",
       "  'the',\n",
       "  'true',\n",
       "  'path',\n",
       "  'to',\n",
       "  'real',\n",
       "  'freedom',\n",
       "  'and',\n",
       "  'autonomy',\n",
       "  'for',\n",
       "  'all'],\n",
       " ['the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'carry',\n",
       "  'firearms',\n",
       "  'is',\n",
       "  'a',\n",
       "  'legal',\n",
       "  'deterrent',\n",
       "  'for',\n",
       "  'politicians',\n",
       "  'with',\n",
       "  'tyrannical',\n",
       "  'or',\n",
       "  'dictatorial',\n",
       "  'tendencies'],\n",
       " ['safe_spaces',\n",
       "  'are',\n",
       "  'for',\n",
       "  'people',\n",
       "  'who',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'like',\n",
       "  'to',\n",
       "  'talk',\n",
       "  'about',\n",
       "  'the',\n",
       "  'issues',\n",
       "  'in',\n",
       "  'a',\n",
       "  'civilized',\n",
       "  'manner'],\n",
       " ['humans',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'have',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'play',\n",
       "  'god',\n",
       "  'with',\n",
       "  'genetics'],\n",
       " ['firearms',\n",
       "  'are',\n",
       "  'typically',\n",
       "  'far',\n",
       "  'more',\n",
       "  'dangerous',\n",
       "  'to',\n",
       "  'the',\n",
       "  'owner',\n",
       "  'and',\n",
       "  'his',\n",
       "  '/',\n",
       "  'her',\n",
       "  'family',\n",
       "  'than',\n",
       "  'any',\n",
       "  'intruder',\n",
       "  ',',\n",
       "  'due',\n",
       "  'to',\n",
       "  'misuse',\n",
       "  ',',\n",
       "  'murder',\n",
       "  ',',\n",
       "  'and',\n",
       "  'suicide',\n",
       "  '.'],\n",
       " ['without',\n",
       "  'a',\n",
       "  'mandatory_retirement',\n",
       "  'age',\n",
       "  'available',\n",
       "  'to',\n",
       "  'the',\n",
       "  'employer',\n",
       "  ',',\n",
       "  'dismissal',\n",
       "  'procedures',\n",
       "  'would',\n",
       "  'be',\n",
       "  'likely',\n",
       "  'to',\n",
       "  'begin',\n",
       "  'earlier'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'legalize',\n",
       "  'cannabis',\n",
       "  'then',\n",
       "  'more',\n",
       "  'children',\n",
       "  'will',\n",
       "  'get',\n",
       "  'a',\n",
       "  'hold',\n",
       "  'of',\n",
       "  'it'],\n",
       " ['the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'and',\n",
       "  'bear_arms',\n",
       "  'should',\n",
       "  'be',\n",
       "  'abolished',\n",
       "  'because',\n",
       "  'too',\n",
       "  'many',\n",
       "  'people',\n",
       "  'die',\n",
       "  'from',\n",
       "  'gun',\n",
       "  'violence',\n",
       "  'in',\n",
       "  'america',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'school',\n",
       "  'uniform',\n",
       "  'is',\n",
       "  'outdated',\n",
       "  'and',\n",
       "  'takes',\n",
       "  'away',\n",
       "  'individual',\n",
       "  'personalities',\n",
       "  '.'],\n",
       " ['three',\n",
       "  'strike',\n",
       "  'laws',\n",
       "  'perpetuate',\n",
       "  'the',\n",
       "  'for',\n",
       "  'profit',\n",
       "  'prison',\n",
       "  'industrial',\n",
       "  'complex',\n",
       "  'and',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'actually',\n",
       "  'address',\n",
       "  'the',\n",
       "  'underlying',\n",
       "  'issues',\n",
       "  'driving',\n",
       "  'people',\n",
       "  'to',\n",
       "  'commit',\n",
       "  'crimes'],\n",
       " ['is',\n",
       "  'leading',\n",
       "  'to',\n",
       "  'increased',\n",
       "  'obesity',\n",
       "  'and',\n",
       "  'many',\n",
       "  'health',\n",
       "  'problems',\n",
       "  '.'],\n",
       " ['as',\n",
       "  'a',\n",
       "  'non',\n",
       "  '-',\n",
       "  'addictive',\n",
       "  'natural',\n",
       "  'substance',\n",
       "  'that',\n",
       "  'is',\n",
       "  'less',\n",
       "  'harmful',\n",
       "  'than',\n",
       "  'currently',\n",
       "  'legal',\n",
       "  'ones',\n",
       "  'such',\n",
       "  'as',\n",
       "  'tobacco',\n",
       "  'and',\n",
       "  'alcohol',\n",
       "  ',',\n",
       "  'it',\n",
       "  'seems',\n",
       "  'that',\n",
       "  'cannabis',\n",
       "  'is',\n",
       "  'still',\n",
       "  'illegal',\n",
       "  'simply',\n",
       "  'due',\n",
       "  'to',\n",
       "  'old',\n",
       "  'prejudices',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'must',\n",
       "  'not',\n",
       "  'prohibit',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'child_actors',\n",
       "  'because',\n",
       "  'it',\n",
       "  'goes',\n",
       "  'against',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'work',\n",
       "  '.',\n",
       "  'children',\n",
       "  'under',\n",
       "  'the',\n",
       "  'supervision',\n",
       "  'of',\n",
       "  'their',\n",
       "  'parents',\n",
       "  'can',\n",
       "  'develop',\n",
       "  'their',\n",
       "  'artistic',\n",
       "  'talent',\n",
       "  'without',\n",
       "  'affecting',\n",
       "  'their',\n",
       "  'personal',\n",
       "  'growth'],\n",
       " ['fast_food',\n",
       "  'is',\n",
       "  'great',\n",
       "  'when',\n",
       "  'you',\n",
       "  'need',\n",
       "  'a',\n",
       "  'quick',\n",
       "  'meal',\n",
       "  'on',\n",
       "  'the',\n",
       "  'run',\n",
       "  'and',\n",
       "  'it',\n",
       "  'is',\n",
       "  'more',\n",
       "  'nutritious',\n",
       "  'than',\n",
       "  'snacking',\n",
       "  'on',\n",
       "  'chocolate',\n",
       "  'bars',\n",
       "  'or',\n",
       "  'unhealthy',\n",
       "  'snacks',\n",
       "  '.'],\n",
       " ['people',\n",
       "  'should',\n",
       "  'be',\n",
       "  'allowed',\n",
       "  'to',\n",
       "  'join',\n",
       "  'any',\n",
       "  'club',\n",
       "  ',',\n",
       "  'cult',\n",
       "  ',',\n",
       "  'religious',\n",
       "  'group',\n",
       "  'they',\n",
       "  'want',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'the',\n",
       "  'government',\n",
       "  'should',\n",
       "  'not',\n",
       "  'have',\n",
       "  'a',\n",
       "  'say',\n",
       "  'in',\n",
       "  'what',\n",
       "  'an',\n",
       "  'individual',\n",
       "  'wants',\n",
       "  'to',\n",
       "  'participate',\n",
       "  'in',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  \"n't\",\n",
       "  'abolish',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'and',\n",
       "  'bear_arms',\n",
       "  'because',\n",
       "  'it',\n",
       "  'can',\n",
       "  'help',\n",
       "  'stop',\n",
       "  'mass',\n",
       "  'shootings',\n",
       "  'if',\n",
       "  'everyone',\n",
       "  'has',\n",
       "  'a',\n",
       "  'gun'],\n",
       " ['language',\n",
       "  'changes',\n",
       "  'can',\n",
       "  'not',\n",
       "  'be',\n",
       "  'legislated',\n",
       "  ',',\n",
       "  'they',\n",
       "  'evolve',\n",
       "  'spontaneously',\n",
       "  'over',\n",
       "  'time',\n",
       "  '.',\n",
       "  'if',\n",
       "  'people',\n",
       "  'want',\n",
       "  'to',\n",
       "  'use',\n",
       "  'gender',\n",
       "  '-',\n",
       "  'neutral_language',\n",
       "  ',',\n",
       "  'it',\n",
       "  'will',\n",
       "  'slowly',\n",
       "  'become',\n",
       "  'part',\n",
       "  'of',\n",
       "  'their',\n",
       "  'vocabulary'],\n",
       " ['if',\n",
       "  'people',\n",
       "  'want',\n",
       "  'to',\n",
       "  'use',\n",
       "  'it',\n",
       "  'then',\n",
       "  'it',\n",
       "  'is',\n",
       "  'their',\n",
       "  'choice'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'legalize',\n",
       "  'organ_trade',\n",
       "  'because',\n",
       "  'then',\n",
       "  'people',\n",
       "  'would',\n",
       "  'be',\n",
       "  'selling',\n",
       "  'their',\n",
       "  'organs',\n",
       "  'just',\n",
       "  'for',\n",
       "  'money'],\n",
       " ['judges',\n",
       "  'should',\n",
       "  'follow',\n",
       "  'the',\n",
       "  'letter',\n",
       "  'of',\n",
       "  'the',\n",
       "  'law',\n",
       "  'when',\n",
       "  'making',\n",
       "  'rulings',\n",
       "  'and',\n",
       "  'not',\n",
       "  'make',\n",
       "  'up',\n",
       "  'things',\n",
       "  'based',\n",
       "  'on',\n",
       "  'how',\n",
       "  'they',\n",
       "  'feel',\n",
       "  '.'],\n",
       " ['three',\n",
       "  'strikes_laws',\n",
       "  'often',\n",
       "  'punish',\n",
       "  'those',\n",
       "  'who',\n",
       "  'have',\n",
       "  'been',\n",
       "  'pushed',\n",
       "  'into',\n",
       "  'crime',\n",
       "  'by',\n",
       "  'their',\n",
       "  'socioeconomic',\n",
       "  'background',\n",
       "  ',',\n",
       "  'which',\n",
       "  'is',\n",
       "  'unjust',\n",
       "  '.'],\n",
       " ['we', 'need', 'to', 'keep', 'our', 'country', 'safe', 'and', 'protected'],\n",
       " ['autonomous_cars',\n",
       "  'offer',\n",
       "  'the',\n",
       "  'opportunity',\n",
       "  'for',\n",
       "  'people',\n",
       "  ' ',\n",
       "  'to',\n",
       "  'spend',\n",
       "  'more',\n",
       "  'time',\n",
       "  'on',\n",
       "  'the',\n",
       "  'things',\n",
       "  'they',\n",
       "  'enjoy',\n",
       "  'doing',\n",
       "  'during',\n",
       "  'their',\n",
       "  'commute',\n",
       "  'rather_than',\n",
       "  'having',\n",
       "  'to',\n",
       "  'concentrate',\n",
       "  '.'],\n",
       " ['historically',\n",
       "  'missionaries',\n",
       "  'have',\n",
       "  'interfered',\n",
       "  'in',\n",
       "  'an',\n",
       "  'unhealthy',\n",
       "  'way',\n",
       "  'with',\n",
       "  'other',\n",
       "  'cultures',\n",
       "  'and',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'do',\n",
       "  'so',\n",
       "  '.'],\n",
       " ['libertarianism',\n",
       "  'does',\n",
       "  \"n't\",\n",
       "  'account',\n",
       "  'for',\n",
       "  'obvious',\n",
       "  'public',\n",
       "  'needs',\n",
       "  'that',\n",
       "  'are',\n",
       "  'better',\n",
       "  'served',\n",
       "  'through',\n",
       "  'collective',\n",
       "  'action',\n",
       "  'rather_than',\n",
       "  'each',\n",
       "  'individual',\n",
       "  'competing',\n",
       "  'for',\n",
       "  'resources',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'church',\n",
       "  'of',\n",
       "  'scientology',\n",
       "  'encourages',\n",
       "  'the',\n",
       "  'isolation',\n",
       "  'of',\n",
       "  'it',\n",
       "  \"'s\",\n",
       "  'members',\n",
       "  '.',\n",
       "  'this',\n",
       "  'may',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'some',\n",
       "  'members',\n",
       "  'essentially',\n",
       "  'being',\n",
       "  'help',\n",
       "  'against',\n",
       "  'their',\n",
       "  'will',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'adopt',\n",
       "  'atheism',\n",
       "  'because',\n",
       "  'organized',\n",
       "  'religion',\n",
       "  'instills',\n",
       "  'good',\n",
       "  'morals',\n",
       "  'into',\n",
       "  'people',\n",
       "  '.'],\n",
       " ['providing',\n",
       "  'subsidies',\n",
       "  'would',\n",
       "  'allow',\n",
       "  'more',\n",
       "  'money',\n",
       "  'to',\n",
       "  'be',\n",
       "  'spent',\n",
       "  'on',\n",
       "  'the',\n",
       "  'editing',\n",
       "  'process',\n",
       "  'thus',\n",
       "  'making',\n",
       "  'wikepedia',\n",
       "  'a',\n",
       "  'more',\n",
       "  'reliable',\n",
       "  'source',\n",
       "  'of',\n",
       "  'information'],\n",
       " ['safe_spaces',\n",
       "  'only',\n",
       "  'shield',\n",
       "  'people',\n",
       "  'from',\n",
       "  'the',\n",
       "  'realities',\n",
       "  'of',\n",
       "  'the',\n",
       "  'world',\n",
       "  'and',\n",
       "  'thus',\n",
       "  'leave',\n",
       "  'them',\n",
       "  'unprepared',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'world',\n",
       "  'of',\n",
       "  'acting',\n",
       "  'is',\n",
       "  'a',\n",
       "  'high',\n",
       "  'pressure',\n",
       "  ',',\n",
       "  'extremely',\n",
       "  'stressful',\n",
       "  'place',\n",
       "  'and',\n",
       "  'children',\n",
       "  'should',\n",
       "  'be',\n",
       "  'protected',\n",
       "  'from',\n",
       "  'it',\n",
       "  '.'],\n",
       " ['if',\n",
       "  'people',\n",
       "  'can',\n",
       "  'get',\n",
       "  'food',\n",
       "  'and',\n",
       "  'other',\n",
       "  'products',\n",
       "  'from',\n",
       "  'whaling',\n",
       "  'that',\n",
       "  'helps',\n",
       "  'sustain',\n",
       "  'them',\n",
       "  ',',\n",
       "  'then',\n",
       "  'it',\n",
       "  'should',\n",
       "  \"n't\",\n",
       "  'be',\n",
       "  'banned',\n",
       "  '.'],\n",
       " ['it',\n",
       "  \"'s\",\n",
       "  'the',\n",
       "  'only',\n",
       "  'way',\n",
       "  'most',\n",
       "  'people',\n",
       "  'can',\n",
       "  'afford',\n",
       "  'college'],\n",
       " ['intellectual_property',\n",
       "  'rights',\n",
       "  'enable',\n",
       "  'people',\n",
       "  'to',\n",
       "  'benefit',\n",
       "  'from',\n",
       "  'what',\n",
       "  'they',\n",
       "  'worked',\n",
       "  'so',\n",
       "  'hard',\n",
       "  'to',\n",
       "  'achieve',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'adopt',\n",
       "  'an',\n",
       "  'austerity_regime',\n",
       "  'because',\n",
       "  'people',\n",
       "  'would',\n",
       "  'end',\n",
       "  'up',\n",
       "  'with',\n",
       "  'less',\n",
       "  'money',\n",
       "  'to',\n",
       "  'pay',\n",
       "  'the',\n",
       "  'same',\n",
       "  'amount',\n",
       "  'of',\n",
       "  'bills',\n",
       "  'with',\n",
       "  '.'],\n",
       " ['many',\n",
       "  'people',\n",
       "  'do',\n",
       "  'not',\n",
       "  'feel',\n",
       "  'comfortable',\n",
       "  'with',\n",
       "  'their',\n",
       "  'gender',\n",
       "  'and',\n",
       "  'feel',\n",
       "  'offended',\n",
       "  'when',\n",
       "  'we',\n",
       "  'use',\n",
       "  'inappropriate',\n",
       "  'words'],\n",
       " ['private_military',\n",
       "  'companies',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned',\n",
       "  'because',\n",
       "  'it',\n",
       "  'is',\n",
       "  'immoral',\n",
       "  'to',\n",
       "  'make',\n",
       "  'money',\n",
       "  'off',\n",
       "  'of',\n",
       "  'war'],\n",
       " ['people',\n",
       "  'need',\n",
       "  'to',\n",
       "  'grow',\n",
       "  'up',\n",
       "  'and',\n",
       "  'realise',\n",
       "  'the',\n",
       "  'world',\n",
       "  'is',\n",
       "  'a',\n",
       "  'hard',\n",
       "  'place'],\n",
       " ['legalizing',\n",
       "  'prostitution',\n",
       "  'would',\n",
       "  'make',\n",
       "  'the',\n",
       "  'profession',\n",
       "  'less',\n",
       "  'dangerous',\n",
       "  'and',\n",
       "  'less',\n",
       "  'hazardous',\n",
       "  'to',\n",
       "  'one',\n",
       "  \"'s\",\n",
       "  'health',\n",
       "  '.'],\n",
       " ['collectivism',\n",
       "  'is',\n",
       "  'a',\n",
       "  'facet',\n",
       "  'of',\n",
       "  'socialism',\n",
       "  ',',\n",
       "  'communism',\n",
       "  ',',\n",
       "  'etc',\n",
       "  '.',\n",
       "  'and',\n",
       "  'eliminates',\n",
       "  'individual',\n",
       "  'worth'],\n",
       " ['the',\n",
       "  'olympic_games',\n",
       "  'provides',\n",
       "  'jobs',\n",
       "  'and',\n",
       "  'is',\n",
       "  'a',\n",
       "  'boost',\n",
       "  'for',\n",
       "  'the',\n",
       "  'economy',\n",
       "  'in',\n",
       "  'the',\n",
       "  'host',\n",
       "  'country',\n",
       "  '.'],\n",
       " ['factory_farming',\n",
       "  'helps',\n",
       "  'to',\n",
       "  'produce',\n",
       "  'meat',\n",
       "  'at',\n",
       "  'a',\n",
       "  'lower',\n",
       "  'cost',\n",
       "  'thus',\n",
       "  'enabling',\n",
       "  'those',\n",
       "  'on',\n",
       "  'a',\n",
       "  'lower',\n",
       "  'income',\n",
       "  'to',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'purchase',\n",
       "  'meats',\n",
       "  '.'],\n",
       " ['in',\n",
       "  'today',\n",
       "  \"'s\",\n",
       "  'hectic',\n",
       "  'fast',\n",
       "  '-',\n",
       "  'paced',\n",
       "  'society',\n",
       "  ',',\n",
       "  'it',\n",
       "  'is',\n",
       "  'freeing',\n",
       "  'to',\n",
       "  'take',\n",
       "  'time',\n",
       "  'to',\n",
       "  'sit',\n",
       "  'quietly',\n",
       "  'and',\n",
       "  'pray',\n",
       "  '.',\n",
       "  'it',\n",
       "  'should',\n",
       "  'be',\n",
       "  'encouraged',\n",
       "  'in',\n",
       "  'our',\n",
       "  'schools',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'introduce',\n",
       "  'compulsory_voting',\n",
       "  'as',\n",
       "  'all',\n",
       "  'citizens',\n",
       "  'need',\n",
       "  'to',\n",
       "  'have',\n",
       "  'their',\n",
       "  'voices',\n",
       "  'heard',\n",
       "  'to',\n",
       "  'make',\n",
       "  'the',\n",
       "  'outcomes',\n",
       "  'of',\n",
       "  'elections',\n",
       "  'more',\n",
       "  'credible',\n",
       "  'and',\n",
       "  'truly',\n",
       "  'representative',\n",
       "  'of',\n",
       "  'the',\n",
       "  'whole',\n",
       "  'population',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'ban',\n",
       "  'missionary_work',\n",
       "  'because',\n",
       "  'people',\n",
       "  'have',\n",
       "  'a',\n",
       "  'right',\n",
       "  'to',\n",
       "  'help',\n",
       "  'out',\n",
       "  'others',\n",
       "  'if',\n",
       "  'they',\n",
       "  'chose',\n",
       "  'to',\n",
       "  'do',\n",
       "  'so'],\n",
       " ['children',\n",
       "  'are',\n",
       "  'not',\n",
       "  'able',\n",
       "  'to',\n",
       "  'consent',\n",
       "  'or',\n",
       "  'conceptualize',\n",
       "  'permanent',\n",
       "  'changes',\n",
       "  'which',\n",
       "  'result',\n",
       "  'from',\n",
       "  'cosmetic_surgery',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'zero',\n",
       "  '-',\n",
       "  'tolerance_policy',\n",
       "  'is',\n",
       "  'not',\n",
       "  'a',\n",
       "  'good',\n",
       "  'thing',\n",
       "  'at',\n",
       "  'all',\n",
       "  ',',\n",
       "  'kids',\n",
       "  'getting',\n",
       "  'punished',\n",
       "  'for',\n",
       "  'their',\n",
       "  'actions',\n",
       "  'and',\n",
       "  'humiliated',\n",
       "  'in',\n",
       "  'front',\n",
       "  'of',\n",
       "  'a',\n",
       "  'audience',\n",
       "  'is',\n",
       "  'really',\n",
       "  'not',\n",
       "  'the',\n",
       "  'great',\n",
       "  'thing',\n",
       "  'to',\n",
       "  'do',\n",
       "  '.'],\n",
       " ['economic_sanctions',\n",
       "  'hurt',\n",
       "  'the',\n",
       "  'poorest',\n",
       "  'people',\n",
       "  'of',\n",
       "  'a',\n",
       "  'nation'],\n",
       " ['economic_sanctions',\n",
       "  'can',\n",
       "  'be',\n",
       "  'very',\n",
       "  'effective',\n",
       "  'in',\n",
       "  'bringing',\n",
       "  'about',\n",
       "  'social',\n",
       "  'change'],\n",
       " ['mandatory_retirement',\n",
       "  'should',\n",
       "  'be',\n",
       "  'ended',\n",
       "  'as',\n",
       "  'it',\n",
       "  'is',\n",
       "  'unfair',\n",
       "  'on',\n",
       "  'older',\n",
       "  'people',\n",
       "  '.'],\n",
       " ['in',\n",
       "  'multi',\n",
       "  '-',\n",
       "  'party',\n",
       "  'systems',\n",
       "  ',',\n",
       "  'there',\n",
       "  'are',\n",
       "  'many',\n",
       "  'types',\n",
       "  'of',\n",
       "  'ideologies',\n",
       "  '-',\n",
       "  'as',\n",
       "  'opposed',\n",
       "  'to',\n",
       "  'two',\n",
       "  '-',\n",
       "  'party',\n",
       "  'systems',\n",
       "  ',',\n",
       "  'where',\n",
       "  'the',\n",
       "  'nation',\n",
       "  'is',\n",
       "  'not',\n",
       "  'divided',\n",
       "  'into',\n",
       "  'two',\n",
       "  'rival',\n",
       "  'groups',\n",
       "  '.'],\n",
       " ['recent',\n",
       "  'dna',\n",
       "  'evidence',\n",
       "  'have',\n",
       "  'proved',\n",
       "  'that',\n",
       "  'some',\n",
       "  'death',\n",
       "  'penalty',\n",
       "  'inmates',\n",
       "  'to',\n",
       "  'be',\n",
       "  'innocent',\n",
       "  '.',\n",
       "  'executing',\n",
       "  'one',\n",
       "  'innocent',\n",
       "  'person',\n",
       "  'is',\n",
       "  'an',\n",
       "  'enough',\n",
       "  'proof',\n",
       "  'that',\n",
       "  'the',\n",
       "  'capital_punishment',\n",
       "  'should',\n",
       "  'be',\n",
       "  'abolished',\n",
       "  '.'],\n",
       " ['autonomous_cars',\n",
       "  'can',\n",
       "  'make',\n",
       "  'trips',\n",
       "  'more',\n",
       "  'relaxing',\n",
       "  'and',\n",
       "  'help',\n",
       "  'the',\n",
       "  'traveler',\n",
       "  'arrive',\n",
       "  'refreshed',\n",
       "  'and',\n",
       "  'happy',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'it',\n",
       "  'can',\n",
       "  'also',\n",
       "  'eliminate',\n",
       "  'road',\n",
       "  'rage',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'ban',\n",
       "  'human_cloning',\n",
       "  'because',\n",
       "  'it',\n",
       "  'causes',\n",
       "  'huge',\n",
       "  'issues',\n",
       "  'in',\n",
       "  'terms',\n",
       "  'of',\n",
       "  'rights',\n",
       "  'and',\n",
       "  'ownership'],\n",
       " ['the',\n",
       "  'olympic_games',\n",
       "  'allow',\n",
       "  'for',\n",
       "  'countries',\n",
       "  'around',\n",
       "  'the',\n",
       "  'world',\n",
       "  'to',\n",
       "  'compete',\n",
       "  'in',\n",
       "  'friendly',\n",
       "  'competition',\n",
       "  'and',\n",
       "  'is',\n",
       "  'a',\n",
       "  'healthy',\n",
       "  'outlet',\n",
       "  'for',\n",
       "  'national',\n",
       "  'pride',\n",
       "  '.'],\n",
       " ['freedom',\n",
       "  'to',\n",
       "  'choose',\n",
       "  'what',\n",
       "  'someone',\n",
       "  'believes',\n",
       "  'in',\n",
       "  'is',\n",
       "  'a',\n",
       "  'right'],\n",
       " ['college',\n",
       "  'is',\n",
       "  'getting',\n",
       "  'more',\n",
       "  'and',\n",
       "  'more',\n",
       "  'expensive',\n",
       "  'each',\n",
       "  'year',\n",
       "  'so',\n",
       "  'students',\n",
       "  'should',\n",
       "  'be',\n",
       "  'getting',\n",
       "  'as',\n",
       "  'much',\n",
       "  'help',\n",
       "  'as',\n",
       "  'they',\n",
       "  'need'],\n",
       " ['researchers',\n",
       "  'found',\n",
       "  'that',\n",
       "  'in',\n",
       "  'schools',\n",
       "  'across',\n",
       "  'the',\n",
       "  'world',\n",
       "  'with',\n",
       "  'uniform',\n",
       "  'policies',\n",
       "  'students',\n",
       "  'are',\n",
       "  'more',\n",
       "  'disciplined',\n",
       "  'and',\n",
       "  'concentrated'],\n",
       " ['abolishing', 'the', 'three', 'strikes', 'law', 'would', 'save', 'money'],\n",
       " ['capital_punishment',\n",
       "  'should',\n",
       "  'be',\n",
       "  'removed',\n",
       "  'from',\n",
       "  'society',\n",
       "  'as',\n",
       "  'it',\n",
       "  'is',\n",
       "  'a',\n",
       "  'backwards',\n",
       "  'and',\n",
       "  'medieval',\n",
       "  'solution',\n",
       "  'to',\n",
       "  'crime',\n",
       "  'that',\n",
       "  'has',\n",
       "  'no',\n",
       "  'place',\n",
       "  'in',\n",
       "  'a',\n",
       "  'modern',\n",
       "  'society',\n",
       "  '.'],\n",
       " ['judicial_activism', 'is', 'biased', 'and', 'should', 'be', 'trashed', '.'],\n",
       " ['they',\n",
       "  'serve',\n",
       "  'as',\n",
       "  'a',\n",
       "  'deterant',\n",
       "  'for',\n",
       "  'any',\n",
       "  'rogue',\n",
       "  'dictator',\n",
       "  'to',\n",
       "  'strike',\n",
       "  'an',\n",
       "  'enemy'],\n",
       " ['executive_compensation',\n",
       "  'should',\n",
       "  'be',\n",
       "  'limited',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'narrow',\n",
       "  'the',\n",
       "  'wage',\n",
       "  'gap',\n",
       "  'between',\n",
       "  'c',\n",
       "  '-',\n",
       "  'level',\n",
       "  'employees',\n",
       "  'and',\n",
       "  'line',\n",
       "  'workers'],\n",
       " ['state',\n",
       "  'subsidy',\n",
       "  'of',\n",
       "  'journalism',\n",
       "  'would',\n",
       "  'threaten',\n",
       "  'the',\n",
       "  'independence',\n",
       "  'and',\n",
       "  'objectivity',\n",
       "  'of',\n",
       "  'any',\n",
       "  'such',\n",
       "  'reporting',\n",
       "  '.',\n",
       "  'what',\n",
       "  'journalist',\n",
       "  'is',\n",
       "  'going',\n",
       "  'to',\n",
       "  'bite',\n",
       "  'the',\n",
       "  'hand',\n",
       "  'that',\n",
       "  'feeds',\n",
       "  'them',\n",
       "  '?'],\n",
       " ['zoos',\n",
       "  'are',\n",
       "  'a',\n",
       "  'great',\n",
       "  'and',\n",
       "  'cheap',\n",
       "  'way',\n",
       "  'for',\n",
       "  'children',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'about',\n",
       "  'animals',\n",
       "  'from',\n",
       "  'all',\n",
       "  'over',\n",
       "  'the',\n",
       "  'world',\n",
       "  '.'],\n",
       " ['cosmetic_surgery',\n",
       "  'is',\n",
       "  'important',\n",
       "  'to',\n",
       "  'repair',\n",
       "  'damaged',\n",
       "  'skin',\n",
       "  'or',\n",
       "  'member',\n",
       "  'of',\n",
       "  'people',\n",
       "  'involved',\n",
       "  'in',\n",
       "  'an',\n",
       "  'accident',\n",
       "  '.',\n",
       "  'this',\n",
       "  'will',\n",
       "  'help',\n",
       "  'them',\n",
       "  'regain',\n",
       "  'confidence',\n",
       "  'and',\n",
       "  'live',\n",
       "  'their',\n",
       "  'life',\n",
       "  'fully'],\n",
       " ['sex_selection',\n",
       "  'can',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'an',\n",
       "  'over',\n",
       "  'abundance',\n",
       "  'of',\n",
       "  'a',\n",
       "  'favored',\n",
       "  'gender',\n",
       "  'in',\n",
       "  'society'],\n",
       " ['a',\n",
       "  'person',\n",
       "  'uses',\n",
       "  'his',\n",
       "  'imagination',\n",
       "  'and',\n",
       "  'hard',\n",
       "  'work',\n",
       "  'to',\n",
       "  'write',\n",
       "  'as',\n",
       "  'book',\n",
       "  'or',\n",
       "  'music',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'they',\n",
       "  'should',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'benefit',\n",
       "  'from',\n",
       "  'their',\n",
       "  'work',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'it',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'in',\n",
       "  'the',\n",
       "  'public',\n",
       "  'domain',\n",
       "  '.'],\n",
       " ['pride_parades',\n",
       "  'are',\n",
       "  'a',\n",
       "  'platforms',\n",
       "  'for',\n",
       "  'minority',\n",
       "  'groups',\n",
       "  'to',\n",
       "  'spread',\n",
       "  'awareness',\n",
       "  'about',\n",
       "  'discrimination',\n",
       "  'and',\n",
       "  'abuse'],\n",
       " ['animals',\n",
       "  'should',\n",
       "  'not',\n",
       "  'have',\n",
       "  'to',\n",
       "  'suffer',\n",
       "  'to',\n",
       "  'save',\n",
       "  'a',\n",
       "  'few',\n",
       "  'dollars',\n",
       "  '.',\n",
       "  '  ',\n",
       "  'businesses',\n",
       "  'need',\n",
       "  'to',\n",
       "  'have',\n",
       "  'better',\n",
       "  'morals',\n",
       "  'and',\n",
       "  'treating',\n",
       "  'animals',\n",
       "  'with',\n",
       "  'care',\n",
       "  'should',\n",
       "  'be',\n",
       "  'a',\n",
       "  'top',\n",
       "  'priority',\n",
       "  'regardless',\n",
       "  'of',\n",
       "  'the',\n",
       "  'cost',\n",
       "  '.',\n",
       "  '  ',\n",
       "  'it',\n",
       "  'also',\n",
       "  'hurts',\n",
       "  'small',\n",
       "  'farmers',\n",
       "  '.'],\n",
       " ['telemarketing',\n",
       "  'preys',\n",
       "  'on',\n",
       "  'people',\n",
       "  'who',\n",
       "  'are',\n",
       "  'vulnerable',\n",
       "  'and',\n",
       "  'easily',\n",
       "  'conned',\n",
       "  ',',\n",
       "  'such',\n",
       "  'as',\n",
       "  'the',\n",
       "  'elderly',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'subsidize',\n",
       "  'embryonic_stem',\n",
       "  'cell_research',\n",
       "  'because',\n",
       "  'it',\n",
       "  'can',\n",
       "  'harm',\n",
       "  'life',\n",
       "  'of',\n",
       "  'a',\n",
       "  'person',\n",
       "  'once',\n",
       "  'it',\n",
       "  'is',\n",
       "  'not',\n",
       "  'done',\n",
       "  'successfully'],\n",
       " ['algorithmic_trading',\n",
       "  'provides',\n",
       "  'people',\n",
       "  'with',\n",
       "  'more',\n",
       "  'opportunities',\n",
       "  'when',\n",
       "  'it',\n",
       "  'comes',\n",
       "  'to',\n",
       "  'trading',\n",
       "  '.'],\n",
       " ['legalizing',\n",
       "  'organ_trade',\n",
       "  'would',\n",
       "  'being',\n",
       "  'about',\n",
       "  'more',\n",
       "  'healthy',\n",
       "  'organs',\n",
       "  'and',\n",
       "  'tissue',\n",
       "  'for',\n",
       "  'transplanting',\n",
       "  'then',\n",
       "  'currently',\n",
       "  'is',\n",
       "  'available',\n",
       "  '.'],\n",
       " ['living', 'within', 'one', \"'s\", 'fiscal', 'means', 'is', 'important'],\n",
       " ['you',\n",
       "  'do',\n",
       "  'not',\n",
       "  'become',\n",
       "  'unqualified',\n",
       "  'for',\n",
       "  'a',\n",
       "  'job',\n",
       "  'simply',\n",
       "  'because',\n",
       "  'you',\n",
       "  'reach',\n",
       "  'retirement',\n",
       "  'age',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'adopt',\n",
       "  'libertarianism',\n",
       "  'because',\n",
       "  'it',\n",
       "  'cause',\n",
       "  'less',\n",
       "  'outside',\n",
       "  'interference',\n",
       "  'in',\n",
       "  'your',\n",
       "  'personal',\n",
       "  'life'],\n",
       " ['space_exploration',\n",
       "  'is',\n",
       "  'a',\n",
       "  'waste',\n",
       "  'of',\n",
       "  'money',\n",
       "  'that',\n",
       "  'could',\n",
       "  'be',\n",
       "  'used',\n",
       "  'to',\n",
       "  'feed',\n",
       "  'people'],\n",
       " ['people',\n",
       "  'have',\n",
       "  'a',\n",
       "  'right',\n",
       "  'to',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'defend',\n",
       "  'themselves',\n",
       "  ' ',\n",
       "  'and',\n",
       "  'their',\n",
       "  'loved',\n",
       "  'ones'],\n",
       " ['it', 'is', 'really', 'just', 'another', 'name', 'for', 'assassination'],\n",
       " ['targeted_killing',\n",
       "  'is',\n",
       "  'like',\n",
       "  'hiring',\n",
       "  'a',\n",
       "  'hitman',\n",
       "  'except',\n",
       "  'the',\n",
       "  'government',\n",
       "  'gets',\n",
       "  'away',\n",
       "  'with',\n",
       "  'it',\n",
       "  '.'],\n",
       " ['minors',\n",
       "  'are',\n",
       "  'too',\n",
       "  'young',\n",
       "  'to',\n",
       "  'know',\n",
       "  'what',\n",
       "  'they',\n",
       "  'are',\n",
       "  'doing',\n",
       "  'so',\n",
       "  'make',\n",
       "  'them',\n",
       "  'wait',\n",
       "  'until',\n",
       "  'they',\n",
       "  'are',\n",
       "  'adults',\n",
       "  'and',\n",
       "  'better',\n",
       "  'able',\n",
       "  'to',\n",
       "  'make',\n",
       "  'these',\n",
       "  'types',\n",
       "  'of',\n",
       "  'decisions'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'end',\n",
       "  'all',\n",
       "  'economic_sanctions',\n",
       "  'because',\n",
       "  'they',\n",
       "  'cause',\n",
       "  'harm',\n",
       "  'to',\n",
       "  'both',\n",
       "  'countries',\n",
       "  'by',\n",
       "  'preventing',\n",
       "  'free',\n",
       "  'trade',\n",
       "  'which',\n",
       "  'in',\n",
       "  'turn',\n",
       "  'will',\n",
       "  'cause',\n",
       "  'an',\n",
       "  'economic',\n",
       "  'downturn',\n",
       "  '.'],\n",
       " ['are',\n",
       "  \"n't\",\n",
       "  'subsidies',\n",
       "  'opening',\n",
       "  'the',\n",
       "  'door',\n",
       "  'for',\n",
       "  'manipulating',\n",
       "  'journalists',\n",
       "  'and',\n",
       "  'inducing',\n",
       "  'media',\n",
       "  'bias',\n",
       "  'in',\n",
       "  'favor',\n",
       "  'of',\n",
       "  'the',\n",
       "  'government',\n",
       "  '?'],\n",
       " ['fast',\n",
       "  'foods',\n",
       "  'are',\n",
       "  'extremely',\n",
       "  'high',\n",
       "  'in',\n",
       "  'calories',\n",
       "  ',',\n",
       "  'and',\n",
       "  'it',\n",
       "  \"'s\",\n",
       "  'easy',\n",
       "  'for',\n",
       "  'a',\n",
       "  'person',\n",
       "  'to',\n",
       "  'exceed',\n",
       "  'the',\n",
       "  'recommended',\n",
       "  'number',\n",
       "  'of',\n",
       "  'calories',\n",
       "  'when',\n",
       "  'they',\n",
       "  'eat',\n",
       "  'fast',\n",
       "  'foods'],\n",
       " ['minors',\n",
       "  'should',\n",
       "  'be',\n",
       "  'allowed',\n",
       "  'to',\n",
       "  'have',\n",
       "  'cosmetic_surgery',\n",
       "  'as',\n",
       "  'long',\n",
       "  'as',\n",
       "  'their',\n",
       "  'parents',\n",
       "  'help',\n",
       "  'make',\n",
       "  'the',\n",
       "  'decision',\n",
       "  '.',\n",
       "  'some',\n",
       "  'cosmetic_surgery',\n",
       "  'would',\n",
       "  'make',\n",
       "  'a',\n",
       "  'child',\n",
       "  'with',\n",
       "  'a',\n",
       "  'deformity',\n",
       "  'have',\n",
       "  'better',\n",
       "  'self',\n",
       "  'esteem',\n",
       "  '.'],\n",
       " ['despite',\n",
       "  'the',\n",
       "  'propaganda',\n",
       "  ',',\n",
       "  'marijuana',\n",
       "  'is',\n",
       "  'actually',\n",
       "  'more',\n",
       "  'addictive',\n",
       "  'than',\n",
       "  'alcohol',\n",
       "  ',',\n",
       "  'the',\n",
       "  'latter',\n",
       "  'of',\n",
       "  'which',\n",
       "  'can',\n",
       "  'be',\n",
       "  'occasionally',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'rulings',\n",
       "  'offer',\n",
       "  'a',\n",
       "  'precedent',\n",
       "  'and',\n",
       "  'will',\n",
       "  'become',\n",
       "  'final',\n",
       "  ',',\n",
       "  'despite',\n",
       "  'it',\n",
       "  'potentially',\n",
       "  'overriding',\n",
       "  'any',\n",
       "  'laws',\n",
       "  '.'],\n",
       " ['they',\n",
       "  'should',\n",
       "  'not',\n",
       "  'abolish',\n",
       "  'zoos',\n",
       "  'since',\n",
       "  'many',\n",
       "  'are',\n",
       "  'in',\n",
       "  'danger',\n",
       "  'of',\n",
       "  'extinction',\n",
       "  ',',\n",
       "  'which',\n",
       "  'need',\n",
       "  'strategic',\n",
       "  'places',\n",
       "  'for',\n",
       "  'scientific',\n",
       "  'study',\n",
       "  'or',\n",
       "  'the',\n",
       "  'collection',\n",
       "  'of',\n",
       "  'funds',\n",
       "  'to',\n",
       "  'finance',\n",
       "  'projects',\n",
       "  '.'],\n",
       " ['capital_punishment',\n",
       "  'is',\n",
       "  'seen',\n",
       "  'as',\n",
       "  'a',\n",
       "  'cruel',\n",
       "  'and',\n",
       "  'inhumane',\n",
       "  'way',\n",
       "  'of',\n",
       "  'treating',\n",
       "  'prisoners',\n",
       "  '.'],\n",
       " ['zero',\n",
       "  '-',\n",
       "  'tolerance',\n",
       "  'policies',\n",
       "  'keep',\n",
       "  'schools',\n",
       "  'safer',\n",
       "  'by',\n",
       "  'immediately',\n",
       "  'removing',\n",
       "  'the',\n",
       "  'problem'],\n",
       " ['the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'and',\n",
       "  'bear_arms',\n",
       "  'is',\n",
       "  'enshrined',\n",
       "  'in',\n",
       "  'the',\n",
       "  'constitution',\n",
       "  'and',\n",
       "  'can',\n",
       "  'not',\n",
       "  'be',\n",
       "  'infringed',\n",
       "  'on',\n",
       "  'or',\n",
       "  'revoked',\n",
       "  '-',\n",
       "  'this',\n",
       "  'would',\n",
       "  'dilute',\n",
       "  'the',\n",
       "  'importance',\n",
       "  'and',\n",
       "  'sanctity',\n",
       "  'of',\n",
       "  'other',\n",
       "  'doctrines',\n",
       "  '.'],\n",
       " ['judicial_activism',\n",
       "  'should',\n",
       "  'be',\n",
       "  'limited',\n",
       "  'or',\n",
       "  'altogether',\n",
       "  'removed',\n",
       "  'based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'it',\n",
       "  'is',\n",
       "  'done',\n",
       "  'from',\n",
       "  'a',\n",
       "  'feeling',\n",
       "  'or',\n",
       "  'thought',\n",
       "  'rather_than',\n",
       "  'from',\n",
       "  'the',\n",
       "  'law'],\n",
       " ['we',\n",
       "  'should',\n",
       "  \"n't\",\n",
       "  'ban',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'child_actors',\n",
       "  'because',\n",
       "  'it',\n",
       "  'is',\n",
       "  'a',\n",
       "  'way',\n",
       "  'for',\n",
       "  'children',\n",
       "  'to',\n",
       "  'find',\n",
       "  'a',\n",
       "  'career',\n",
       "  'early',\n",
       "  'in',\n",
       "  'their',\n",
       "  'life'],\n",
       " ['some',\n",
       "  'older',\n",
       "  'workers',\n",
       "  'love',\n",
       "  'their',\n",
       "  'job',\n",
       "  'and',\n",
       "  'would',\n",
       "  'be',\n",
       "  'devastated',\n",
       "  'to',\n",
       "  'be',\n",
       "  'forced',\n",
       "  'to',\n",
       "  'stop',\n",
       "  'working'],\n",
       " ['capital_punishment',\n",
       "  'is',\n",
       "  'a',\n",
       "  'real',\n",
       "  'deterant',\n",
       "  'to',\n",
       "  'crime',\n",
       "  'and',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'abolished',\n",
       "  '.'],\n",
       " ['collectivism',\n",
       "  'reduces',\n",
       "  'productivity',\n",
       "  'from',\n",
       "  'individuals',\n",
       "  'as',\n",
       "  'they',\n",
       "  'have',\n",
       "  'no',\n",
       "  'incentive',\n",
       "  'to',\n",
       "  'do',\n",
       "  'better',\n",
       "  '.'],\n",
       " ['minors',\n",
       "  'should',\n",
       "  'be',\n",
       "  'allowed',\n",
       "  'plastic',\n",
       "  'surgery',\n",
       "  ',',\n",
       "  'so',\n",
       "  'long',\n",
       "  'as',\n",
       "  'they',\n",
       "  'get',\n",
       "  'consent',\n",
       "  'from',\n",
       "  'their',\n",
       "  'parents',\n",
       "  'and',\n",
       "  'the',\n",
       "  'plastic',\n",
       "  'surgeon',\n",
       "  '.'],\n",
       " ['students',\n",
       "  'should',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'pursue',\n",
       "  'higher',\n",
       "  'education',\n",
       "  'without',\n",
       "  'worrying',\n",
       "  'about',\n",
       "  'being',\n",
       "  'able',\n",
       "  'to',\n",
       "  'afford',\n",
       "  'it',\n",
       "  '.',\n",
       "  'subsidizing',\n",
       "  'students',\n",
       "  'loans',\n",
       "  'would',\n",
       "  'make',\n",
       "  'education',\n",
       "  'more',\n",
       "  'accessible',\n",
       "  '.'],\n",
       " ['economic_sanctions',\n",
       "  'is',\n",
       "  'bullying',\n",
       "  'and',\n",
       "  'it',\n",
       "  'will',\n",
       "  'not',\n",
       "  'result',\n",
       "  'in',\n",
       "  'the',\n",
       "  'country',\n",
       "  'complying',\n",
       "  'or',\n",
       "  'changing',\n",
       "  'their',\n",
       "  'policies',\n",
       "  '.'],\n",
       " ['there',\n",
       "  'is',\n",
       "  'no',\n",
       "  'justification',\n",
       "  'for',\n",
       "  'mass',\n",
       "  'destruction',\n",
       "  '.',\n",
       "  'therefore',\n",
       "  ',',\n",
       "  'nuclear_weapons',\n",
       "  'are',\n",
       "  'inherently',\n",
       "  'immoral',\n",
       "  '.',\n",
       "  'same',\n",
       "  'as',\n",
       "  'private',\n",
       "  'persons',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'own',\n",
       "  'assault',\n",
       "  'weapons',\n",
       "  ',',\n",
       "  'the',\n",
       "  'states',\n",
       "  'should',\n",
       "  'be',\n",
       "  'barred',\n",
       "  'from',\n",
       "  'creating',\n",
       "  'and',\n",
       "  'owning',\n",
       "  'nuclear_weapons',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'church',\n",
       "  'of',\n",
       "  'scientology',\n",
       "  'is',\n",
       "  'a',\n",
       "  'dangerous',\n",
       "  'cult',\n",
       "  'that',\n",
       "  'has',\n",
       "  'caused',\n",
       "  'psychological',\n",
       "  'harm',\n",
       "  'to',\n",
       "  'some',\n",
       "  'of',\n",
       "  'its',\n",
       "  'members',\n",
       "  'and',\n",
       "  'has',\n",
       "  'held',\n",
       "  'some',\n",
       "  'members',\n",
       "  'against',\n",
       "  'their',\n",
       "  'will'],\n",
       " ['without',\n",
       "  'being',\n",
       "  'able',\n",
       "  'to',\n",
       "  'completely',\n",
       "  'erradicate',\n",
       "  'drug',\n",
       "  'taking',\n",
       "  'the',\n",
       "  'olympic_games',\n",
       "  'is',\n",
       "  'not',\n",
       "  'an',\n",
       "  'accurate',\n",
       "  'representation',\n",
       "  'of',\n",
       "  'the',\n",
       "  'skill',\n",
       "  'of',\n",
       "  'the',\n",
       "  'sportsmen',\n",
       "  ',',\n",
       "  'making',\n",
       "  'it',\n",
       "  'an',\n",
       "  'outdated',\n",
       "  'and',\n",
       "  'irrelevant',\n",
       "  'competition',\n",
       "  '.'],\n",
       " ['no',\n",
       "  'one',\n",
       "  'wins',\n",
       "  'with',\n",
       "  'nuclear_weapons',\n",
       "  '.',\n",
       "  'if',\n",
       "  'two',\n",
       "  'or',\n",
       "  'more',\n",
       "  'countries',\n",
       "  'nuked',\n",
       "  'each',\n",
       "  'other',\n",
       "  'parts',\n",
       "  'of',\n",
       "  ',',\n",
       "  'if',\n",
       "  'not',\n",
       "  'all',\n",
       "  'of',\n",
       "  ',',\n",
       "  'the',\n",
       "  'entire',\n",
       "  'world',\n",
       "  'is',\n",
       "  'just',\n",
       "  'gone',\n",
       "  '.',\n",
       "  'it',\n",
       "  'destroys',\n",
       "  'everything',\n",
       "  'and',\n",
       "  'solves',\n",
       "  'nothing',\n",
       "  '.'],\n",
       " ['multi',\n",
       "  '-',\n",
       "  'party',\n",
       "  'systems',\n",
       "  'slow',\n",
       "  'down',\n",
       "  'what',\n",
       "  'gets',\n",
       "  'done',\n",
       "  'because',\n",
       "  'we',\n",
       "  'have',\n",
       "  'too',\n",
       "  'many',\n",
       "  'different',\n",
       "  'sides',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'come',\n",
       "  'to',\n",
       "  'an',\n",
       "  'agreement'],\n",
       " ['not',\n",
       "  'everyone',\n",
       "  'has',\n",
       "  'a',\n",
       "  'strong',\n",
       "  'opinion',\n",
       "  'on',\n",
       "  'every',\n",
       "  'topic',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'those',\n",
       "  'who',\n",
       "  'choose',\n",
       "  'not',\n",
       "  'to',\n",
       "  'participate',\n",
       "  'should',\n",
       "  'have',\n",
       "  'the',\n",
       "  'freedom',\n",
       "  'not',\n",
       "  'to',\n",
       "  '.'],\n",
       " ['embryonic_stem',\n",
       "  'cell_research',\n",
       "  'helps',\n",
       "  'to',\n",
       "  'provide',\n",
       "  'innovations',\n",
       "  'in',\n",
       "  'cancer',\n",
       "  'treatment',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'help',\n",
       "  'in',\n",
       "  'the',\n",
       "  'treatment',\n",
       "  'of',\n",
       "  'patient',\n",
       "  \"'s\",\n",
       "  'with',\n",
       "  'diseases',\n",
       "  'such',\n",
       "  'as',\n",
       "  'parkinson',\n",
       "  \"'s\",\n",
       "  'disease',\n",
       "  ',',\n",
       "  'subsidizing',\n",
       "  'would',\n",
       "  'allow',\n",
       "  'for',\n",
       "  'more',\n",
       "  'funding',\n",
       "  '.'],\n",
       " ['mandatory_retirement',\n",
       "  'creates',\n",
       "  'employment',\n",
       "  'opportunities',\n",
       "  'for',\n",
       "  'the',\n",
       "  'younger',\n",
       "  'generation',\n",
       "  'of',\n",
       "  'workers',\n",
       "  ',',\n",
       "  'who',\n",
       "  'would',\n",
       "  'otherwise',\n",
       "  'be',\n",
       "  'increasingly',\n",
       "  'shunted',\n",
       "  'out',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'olympics',\n",
       "  'have',\n",
       "  'long',\n",
       "  'been',\n",
       "  'the',\n",
       "  'goal',\n",
       "  'for',\n",
       "  'athletes',\n",
       "  'to',\n",
       "  'aim',\n",
       "  'for',\n",
       "  'to',\n",
       "  'be',\n",
       "  'the',\n",
       "  'very',\n",
       "  'best',\n",
       "  'so',\n",
       "  'abolishing',\n",
       "  'the',\n",
       "  'games',\n",
       "  'would',\n",
       "  'take',\n",
       "  'away',\n",
       "  'their',\n",
       "  'dreams',\n",
       "  'and',\n",
       "  'ambitions',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'legalize',\n",
       "  'sex_selection',\n",
       "  'because',\n",
       "  'the',\n",
       "  'parents',\n",
       "  'are',\n",
       "  'free',\n",
       "  'to',\n",
       "  'decide',\n",
       "  'what',\n",
       "  'gender',\n",
       "  'they',\n",
       "  'want'],\n",
       " ['judicial_activism',\n",
       "  'allows',\n",
       "  'for',\n",
       "  'a',\n",
       "  'check',\n",
       "  'on',\n",
       "  'decrees',\n",
       "  'made',\n",
       "  'by',\n",
       "  'one',\n",
       "  'branch',\n",
       "  'of',\n",
       "  'the',\n",
       "  'government',\n",
       "  'that',\n",
       "  'may',\n",
       "  'think',\n",
       "  'that',\n",
       "  'drastic',\n",
       "  'action',\n",
       "  'is',\n",
       "  'needed',\n",
       "  'for',\n",
       "  'every',\n",
       "  'situation',\n",
       "  '.'],\n",
       " ['people',\n",
       "  'should',\n",
       "  'be',\n",
       "  'allowed',\n",
       "  'to',\n",
       "  'get',\n",
       "  'organs',\n",
       "  'from',\n",
       "  'other',\n",
       "  'countries',\n",
       "  'by',\n",
       "  'buying',\n",
       "  'them',\n",
       "  'if',\n",
       "  'the',\n",
       "  'wait',\n",
       "  'list',\n",
       "  'for',\n",
       "  'their',\n",
       "  'transplant',\n",
       "  'is',\n",
       "  'too',\n",
       "  'long',\n",
       "  'and',\n",
       "  'they',\n",
       "  'are',\n",
       "  'at',\n",
       "  'risk',\n",
       "  'of',\n",
       "  'dying',\n",
       "  '.'],\n",
       " ['nuclear_weapons', 'are', 'destructive', 'and', 'unnecessary'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'allow',\n",
       "  'human_cloning',\n",
       "  'as',\n",
       "  'this',\n",
       "  'will',\n",
       "  'be',\n",
       "  'beneficial',\n",
       "  'to',\n",
       "  'scientific',\n",
       "  'advances',\n",
       "  'in',\n",
       "  'the',\n",
       "  'future',\n",
       "  '.'],\n",
       " ['intellectual_property',\n",
       "  'rights',\n",
       "  'keep',\n",
       "  'people',\n",
       "  'from',\n",
       "  'stealing',\n",
       "  'others',\n",
       "  \"'\",\n",
       "  'ideas',\n",
       "  'and',\n",
       "  'selling',\n",
       "  'them',\n",
       "  'as',\n",
       "  'their',\n",
       "  'own',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'olympic_games',\n",
       "  'are',\n",
       "  'usually',\n",
       "  'a',\n",
       "  'drain',\n",
       "  'on',\n",
       "  'the',\n",
       "  'economy',\n",
       "  'of',\n",
       "  'the',\n",
       "  'host',\n",
       "  'city'],\n",
       " ['there',\n",
       "  'are',\n",
       "  'things',\n",
       "  'at',\n",
       "  'pride_parades',\n",
       "  'that',\n",
       "  'young',\n",
       "  'children',\n",
       "  'should',\n",
       "  'not',\n",
       "  'see',\n",
       "  ',',\n",
       "  'regardless',\n",
       "  'of',\n",
       "  'one',\n",
       "  \"'s\",\n",
       "  'sexual',\n",
       "  'preferences',\n",
       "  '.'],\n",
       " ['students',\n",
       "  'should',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'state',\n",
       "  'their',\n",
       "  'opinions',\n",
       "  'and',\n",
       "  'by',\n",
       "  'so',\n",
       "  'learn',\n",
       "  'to',\n",
       "  'mature',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'by',\n",
       "  'punishing',\n",
       "  'at',\n",
       "  'first',\n",
       "  'sign',\n",
       "  'of',\n",
       "  'disobedience',\n",
       "  'we',\n",
       "  'are',\n",
       "  'just',\n",
       "  'have',\n",
       "  'conformity',\n",
       "  'not',\n",
       "  'learning',\n",
       "  '.'],\n",
       " ['ai',\n",
       "  'is',\n",
       "  'the',\n",
       "  'future',\n",
       "  'and',\n",
       "  'algorithmic_trading',\n",
       "  'is',\n",
       "  'simply',\n",
       "  'a',\n",
       "  'form',\n",
       "  'of',\n",
       "  'ai',\n",
       "  'that',\n",
       "  'makes',\n",
       "  'the',\n",
       "  'most',\n",
       "  'of',\n",
       "  'trading',\n",
       "  'opportunities',\n",
       "  'which',\n",
       "  'will',\n",
       "  'be',\n",
       "  'the',\n",
       "  'norm',\n",
       "  'in',\n",
       "  'the',\n",
       "  'not',\n",
       "  'to',\n",
       "  'distant',\n",
       "  'future',\n",
       "  '.'],\n",
       " ['pride_parades', 'are', 'important', 'to', 'understanding', 'others'],\n",
       " ['zoos',\n",
       "  'are',\n",
       "  'too',\n",
       "  'small',\n",
       "  'and',\n",
       "  'do',\n",
       "  'not',\n",
       "  'provide',\n",
       "  'animals',\n",
       "  'with',\n",
       "  'the',\n",
       "  'space',\n",
       "  'and',\n",
       "  'habitat',\n",
       "  'that',\n",
       "  'they',\n",
       "  'are',\n",
       "  'born',\n",
       "  'to',\n",
       "  '.'],\n",
       " ['we', 'are', 'exploiting', 'the', 'youth', 'purely', 'for', 'entertainment'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'abolish',\n",
       "  'safe_spaces',\n",
       "  'because',\n",
       "  'those',\n",
       "  'who',\n",
       "  'are',\n",
       "  'easily',\n",
       "  'offended',\n",
       "  'need',\n",
       "  'to',\n",
       "  'grow',\n",
       "  'up'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'abandon',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'school',\n",
       "  'uniform',\n",
       "  'because',\n",
       "  'people',\n",
       "  'need',\n",
       "  'to',\n",
       "  'be',\n",
       "  'free',\n",
       "  'to',\n",
       "  'express',\n",
       "  'their',\n",
       "  'thoughts',\n",
       "  'on',\n",
       "  'clothing'],\n",
       " ['adopting',\n",
       "  'atheism',\n",
       "  'would',\n",
       "  'put',\n",
       "  'a',\n",
       "  'stop',\n",
       "  'to',\n",
       "  'conflicts',\n",
       "  'that',\n",
       "  'arise',\n",
       "  'through',\n",
       "  'conflicting',\n",
       "  'religious',\n",
       "  'beliefs',\n",
       "  'making',\n",
       "  'the',\n",
       "  'world',\n",
       "  'a',\n",
       "  'safer',\n",
       "  'place',\n",
       "  '.'],\n",
       " ['factory_farming',\n",
       "  'is',\n",
       "  'efficient',\n",
       "  'and',\n",
       "  'lowers',\n",
       "  'food',\n",
       "  'production',\n",
       "  'costs',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'limit',\n",
       "  'executive_compensation',\n",
       "  'because',\n",
       "  'it',\n",
       "  'is',\n",
       "  'their',\n",
       "  'company',\n",
       "  'that',\n",
       "  'they',\n",
       "  'started',\n",
       "  ',',\n",
       "  'they',\n",
       "  'have',\n",
       "  'a',\n",
       "  'right',\n",
       "  'to',\n",
       "  'the',\n",
       "  'profits',\n",
       "  '.'],\n",
       " ['allowing',\n",
       "  'cosmetic_surgery',\n",
       "  'for',\n",
       "  'minors',\n",
       "  'makes',\n",
       "  'it',\n",
       "  'easy',\n",
       "  'for',\n",
       "  'minors',\n",
       "  'to',\n",
       "  'pressure',\n",
       "  'well',\n",
       "  '-',\n",
       "  'intentioned',\n",
       "  'parents',\n",
       "  'even',\n",
       "  'if',\n",
       "  'it',\n",
       "  'is',\n",
       "  'objectively',\n",
       "  'a',\n",
       "  'bad',\n",
       "  'decision',\n",
       "  '.',\n",
       "  'a',\n",
       "  'ban',\n",
       "  'prevents',\n",
       "  'parents',\n",
       "  'from',\n",
       "  'being',\n",
       "  'put',\n",
       "  'in',\n",
       "  'this',\n",
       "  'situation',\n",
       "  '.'],\n",
       " ['this',\n",
       "  'is',\n",
       "  'a',\n",
       "  'slippery',\n",
       "  'slope',\n",
       "  'and',\n",
       "  'cloning',\n",
       "  'could',\n",
       "  'be',\n",
       "  'used',\n",
       "  'for',\n",
       "  'terrible',\n",
       "  'purposes',\n",
       "  '.',\n",
       "  'it',\n",
       "  'is',\n",
       "  'dangerous',\n",
       "  'to',\n",
       "  'open',\n",
       "  'this',\n",
       "  'door',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'ban',\n",
       "  'factory_farming',\n",
       "  'because',\n",
       "  'it',\n",
       "  'helps',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'up',\n",
       "  'with',\n",
       "  'demand',\n",
       "  'for',\n",
       "  'food',\n",
       "  '.'],\n",
       " ['gender',\n",
       "  '-',\n",
       "  'neutral_language',\n",
       "  'is',\n",
       "  'simply',\n",
       "  'a',\n",
       "  'natural',\n",
       "  'progression',\n",
       "  'in',\n",
       "  'a',\n",
       "  'society',\n",
       "  'based',\n",
       "  'on',\n",
       "  'sexual',\n",
       "  'equality',\n",
       "  '-',\n",
       "  'there',\n",
       "  'is',\n",
       "  'no',\n",
       "  'reason',\n",
       "  'for',\n",
       "  'textual',\n",
       "  'dominance',\n",
       "  ',',\n",
       "  'and',\n",
       "  'such',\n",
       "  'neutrality',\n",
       "  'serves',\n",
       "  'to',\n",
       "  'gradually',\n",
       "  'temper',\n",
       "  'preconceptions',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'subsidize',\n",
       "  'embryonic_stem',\n",
       "  'cell_research',\n",
       "  'because',\n",
       "  'it',\n",
       "  'is',\n",
       "  'necessary',\n",
       "  'for',\n",
       "  'the',\n",
       "  'betterment',\n",
       "  'of',\n",
       "  'the',\n",
       "  'human',\n",
       "  'race',\n",
       "  '.',\n",
       "  'we',\n",
       "  'may',\n",
       "  'find',\n",
       "  'cures',\n",
       "  'for',\n",
       "  'aging',\n",
       "  ',',\n",
       "  'diseases',\n",
       "  ',',\n",
       "  'or',\n",
       "  'create',\n",
       "  'new',\n",
       "  'stronger',\n",
       "  'genes',\n",
       "  '.'],\n",
       " ['schools',\n",
       "  'now',\n",
       "  'contain',\n",
       "  'students',\n",
       "  'of',\n",
       "  'all',\n",
       "  'religions',\n",
       "  'and',\n",
       "  'of',\n",
       "  'none',\n",
       "  ',',\n",
       "  'by',\n",
       "  'forcing',\n",
       "  'these',\n",
       "  'students',\n",
       "  'to',\n",
       "  'pray',\n",
       "  'in',\n",
       "  'schools',\n",
       "  'you',\n",
       "  'are',\n",
       "  'infringing',\n",
       "  'on',\n",
       "  'their',\n",
       "  'human',\n",
       "  'rights',\n",
       "  ',',\n",
       "  'prayer',\n",
       "  'is',\n",
       "  'personal',\n",
       "  'not',\n",
       "  'public',\n",
       "  'in',\n",
       "  'school',\n",
       "  '.'],\n",
       " ['a',\n",
       "  'mandatory_retirement',\n",
       "  'age',\n",
       "  'helps',\n",
       "  'employers',\n",
       "  'regularly',\n",
       "  'refresh',\n",
       "  'the',\n",
       "  'workforce',\n",
       "  'with',\n",
       "  'fresh',\n",
       "  'talent'],\n",
       " ['there',\n",
       "  'is',\n",
       "  'never',\n",
       "  'a',\n",
       "  'justifiable',\n",
       "  'reason',\n",
       "  'to',\n",
       "  'kill',\n",
       "  'someone',\n",
       "  '.'],\n",
       " ['austerity',\n",
       "  'regimes',\n",
       "  'provide',\n",
       "  'an',\n",
       "  'avenue',\n",
       "  'for',\n",
       "  'the',\n",
       "  'government',\n",
       "  'to',\n",
       "  'balance',\n",
       "  'up',\n",
       "  'financial',\n",
       "  'deficits',\n",
       "  'and',\n",
       "  'save',\n",
       "  'the',\n",
       "  'country',\n",
       "  'from',\n",
       "  'economic',\n",
       "  'collapse'],\n",
       " ['supporting',\n",
       "  'embryonic_stem',\n",
       "  'cell_research',\n",
       "  'is',\n",
       "  'important',\n",
       "  'because',\n",
       "  'it',\n",
       "  'is',\n",
       "  'the',\n",
       "  'future',\n",
       "  'of',\n",
       "  'medicine',\n",
       "  'and',\n",
       "  'it',\n",
       "  'can',\n",
       "  'help',\n",
       "  'scientists',\n",
       "  'to',\n",
       "  'find',\n",
       "  'new',\n",
       "  'cures',\n",
       "  'for',\n",
       "  'diseases',\n",
       "  '.'],\n",
       " ['they', 'can', 'be', 'more', 'dangerous', 'than', 'human', 'drivers'],\n",
       " ['human_cloning',\n",
       "  'gives',\n",
       "  'the',\n",
       "  'chance',\n",
       "  'for',\n",
       "  'individuals',\n",
       "  'to',\n",
       "  'have',\n",
       "  'a',\n",
       "  'child',\n",
       "  'that',\n",
       "  'might',\n",
       "  'not',\n",
       "  'otherwise',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to'],\n",
       " ['zoos',\n",
       "  'should',\n",
       "  'be',\n",
       "  'abolished',\n",
       "  'so',\n",
       "  'that',\n",
       "  'animals',\n",
       "  'can',\n",
       "  'thrive',\n",
       "  'in',\n",
       "  'a',\n",
       "  'setting',\n",
       "  'that',\n",
       "  'allows',\n",
       "  'them',\n",
       "  'to',\n",
       "  'roam',\n",
       "  'free'],\n",
       " ['studen',\n",
       "  'loans',\n",
       "  'can',\n",
       "  'not',\n",
       "  'be',\n",
       "  'subsidised',\n",
       "  'as',\n",
       "  'not',\n",
       "  'only',\n",
       "  'is',\n",
       "  'it',\n",
       "  'unaffordable',\n",
       "  'in',\n",
       "  'the',\n",
       "  'current',\n",
       "  'climate',\n",
       "  ',',\n",
       "  'it',\n",
       "  'would',\n",
       "  'encourage',\n",
       "  'universities',\n",
       "  'offer',\n",
       "  'degree',\n",
       "  'courses',\n",
       "  'purely',\n",
       "  'for',\n",
       "  'financial',\n",
       "  'gain',\n",
       "  '.'],\n",
       " ['judicial_activism',\n",
       "  'is',\n",
       "  'sometimes',\n",
       "  'the',\n",
       "  'best',\n",
       "  'way',\n",
       "  'to',\n",
       "  'get',\n",
       "  'things',\n",
       "  'done'],\n",
       " ['whaling',\n",
       "  'should',\n",
       "  'be',\n",
       "  'allowed',\n",
       "  'when',\n",
       "  'it',\n",
       "  'will',\n",
       "  'help',\n",
       "  'to',\n",
       "  'revive',\n",
       "  'dwindling',\n",
       "  'fish',\n",
       "  'populations',\n",
       "  '.'],\n",
       " ['space_exploration', 'is', 'the', 'next', 'frontier', '.'],\n",
       " ['mandatory_retirement',\n",
       "  'is',\n",
       "  'needed',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'businesses',\n",
       "  'new',\n",
       "  'and',\n",
       "  'fresh',\n",
       "  'with',\n",
       "  'innovation',\n",
       "  'from',\n",
       "  'the',\n",
       "  'younger',\n",
       "  'generation',\n",
       "  '.'],\n",
       " ['there',\n",
       "  'is',\n",
       "  'ample',\n",
       "  'evidence',\n",
       "  'showing',\n",
       "  'that',\n",
       "  'capital_punishment',\n",
       "  'does',\n",
       "  'not',\n",
       "  'constitute',\n",
       "  'effective',\n",
       "  'deterrence',\n",
       "  '.'],\n",
       " ['there',\n",
       "  'are',\n",
       "  'other',\n",
       "  'ways',\n",
       "  'to',\n",
       "  'channel',\n",
       "  'student',\n",
       "  'aid',\n",
       "  'that',\n",
       "  'is',\n",
       "  'not',\n",
       "  'subsidizing',\n",
       "  'loans'],\n",
       " ['even',\n",
       "  'if',\n",
       "  'an',\n",
       "  'algorithm',\n",
       "  'can',\n",
       "  'react',\n",
       "  'quicker',\n",
       "  'than',\n",
       "  'a',\n",
       "  'person',\n",
       "  ',',\n",
       "  'it',\n",
       "  'ca',\n",
       "  \"n't\",\n",
       "  'predict',\n",
       "  'markets',\n",
       "  'accurately'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'ban',\n",
       "  'targeted_killing',\n",
       "  'since',\n",
       "  'they',\n",
       "  'are',\n",
       "  'effective',\n",
       "  'at',\n",
       "  'eliminating',\n",
       "  'terrorists',\n",
       "  'with',\n",
       "  'a',\n",
       "  'smaller',\n",
       "  'number',\n",
       "  'of',\n",
       "  'civilians',\n",
       "  'being',\n",
       "  'killed',\n",
       "  'than',\n",
       "  'most',\n",
       "  'other',\n",
       "  'military',\n",
       "  'weapon'],\n",
       " ['everyone',\n",
       "  'should',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'pray',\n",
       "  'if',\n",
       "  'they',\n",
       "  'want',\n",
       "  'to',\n",
       "  'weather',\n",
       "  'in',\n",
       "  'school',\n",
       "  'or',\n",
       "  'in',\n",
       "  'a',\n",
       "  'church'],\n",
       " ['wikipedia',\n",
       "  'is',\n",
       "  'a',\n",
       "  'wonderful',\n",
       "  'source',\n",
       "  'of',\n",
       "  'information',\n",
       "  'for',\n",
       "  'students',\n",
       "  'and',\n",
       "  'adults',\n",
       "  'alike',\n",
       "  '.'],\n",
       " ['telemarketing',\n",
       "  'should',\n",
       "  \"n't\",\n",
       "  'be',\n",
       "  'banned',\n",
       "  ',',\n",
       "  'this',\n",
       "  'is',\n",
       "  'a',\n",
       "  'free',\n",
       "  'country',\n",
       "  'and',\n",
       "  'people',\n",
       "  'have',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'call',\n",
       "  'others',\n",
       "  'and',\n",
       "  'solicit',\n",
       "  'items',\n",
       "  '.'],\n",
       " ['when',\n",
       "  'we',\n",
       "  'allow',\n",
       "  'abortion',\n",
       "  'for',\n",
       "  'any',\n",
       "  'reason',\n",
       "  'or',\n",
       "  'purpose',\n",
       "  ',',\n",
       "  'sex_selection',\n",
       "  'can',\n",
       "  'not',\n",
       "  'be',\n",
       "  'excluded',\n",
       "  '.',\n",
       "  'in',\n",
       "  'fact',\n",
       "  'illegal',\n",
       "  'sex_selection',\n",
       "  'only',\n",
       "  'increased',\n",
       "  'abortions',\n",
       "  'as',\n",
       "  'the',\n",
       "  'alternative',\n",
       "  'method',\n",
       "  'to',\n",
       "  'select',\n",
       "  'gender'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'subsidize',\n",
       "  'space_exploration',\n",
       "  'because',\n",
       "  'there',\n",
       "  'are',\n",
       "  'far',\n",
       "  'more',\n",
       "  'important',\n",
       "  'things',\n",
       "  'to',\n",
       "  'spend',\n",
       "  'public',\n",
       "  'money',\n",
       "  'on',\n",
       "  'closer',\n",
       "  'to',\n",
       "  'home',\n",
       "  'such',\n",
       "  'as',\n",
       "  'healthcare',\n",
       "  ',',\n",
       "  'education',\n",
       "  'and',\n",
       "  'transport',\n",
       "  'infrastructure'],\n",
       " ['a',\n",
       "  'multi',\n",
       "  '-',\n",
       "  'party_system',\n",
       "  'allows',\n",
       "  'for',\n",
       "  'more',\n",
       "  'options',\n",
       "  'and',\n",
       "  'candidates',\n",
       "  'that',\n",
       "  'are',\n",
       "  'more',\n",
       "  'in',\n",
       "  'line',\n",
       "  'with',\n",
       "  'certain',\n",
       "  'populations',\n",
       "  'as',\n",
       "  'not',\n",
       "  'everyone',\n",
       "  'has',\n",
       "  'the',\n",
       "  'same',\n",
       "  'political',\n",
       "  'views',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'death',\n",
       "  'penalty',\n",
       "  'is',\n",
       "  'an',\n",
       "  'old',\n",
       "  '-',\n",
       "  'fashioned',\n",
       "  ',',\n",
       "  'outdated',\n",
       "  ',',\n",
       "  'inhumane',\n",
       "  'practice',\n",
       "  'and',\n",
       "  'must',\n",
       "  'be',\n",
       "  'abolished'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'abolish',\n",
       "  'zoos',\n",
       "  'because',\n",
       "  'it',\n",
       "  'dangerous',\n",
       "  'and',\n",
       "  'not',\n",
       "  'good',\n",
       "  'for',\n",
       "  'the',\n",
       "  'animals',\n",
       "  'to',\n",
       "  'be',\n",
       "  'out',\n",
       "  'of',\n",
       "  'their',\n",
       "  'natural',\n",
       "  'habitat',\n",
       "  'just',\n",
       "  'for',\n",
       "  'the',\n",
       "  'purpose',\n",
       "  'of',\n",
       "  'human',\n",
       "  'entertainment'],\n",
       " ['parents',\n",
       "  'should',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'choose',\n",
       "  'what',\n",
       "  'sex',\n",
       "  'child',\n",
       "  'they',\n",
       "  'are',\n",
       "  'going',\n",
       "  'to',\n",
       "  'have',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'can',\n",
       "  'be',\n",
       "  'expensive',\n",
       "  'to',\n",
       "  'maintain',\n",
       "  'property_rights',\n",
       "  'and',\n",
       "  'therefore',\n",
       "  'it',\n",
       "  'should',\n",
       "  'be',\n",
       "  'abolished',\n",
       "  'so',\n",
       "  'that',\n",
       "  'everyone',\n",
       "  'has',\n",
       "  'an',\n",
       "  'even',\n",
       "  'chance',\n",
       "  '.'],\n",
       " ['algorithmic_trading',\n",
       "  'allows',\n",
       "  'for',\n",
       "  'greater',\n",
       "  'numbers',\n",
       "  'of',\n",
       "  'trades',\n",
       "  'to',\n",
       "  'happen',\n",
       "  ',',\n",
       "  'getting',\n",
       "  'more',\n",
       "  'people',\n",
       "  'involved',\n",
       "  'in',\n",
       "  'the',\n",
       "  'economy'],\n",
       " ['the',\n",
       "  'olympic_games',\n",
       "  'offer',\n",
       "  'a',\n",
       "  'friendly',\n",
       "  'competition',\n",
       "  'meeting',\n",
       "  'where',\n",
       "  'the',\n",
       "  'best',\n",
       "  'athletes',\n",
       "  'around',\n",
       "  'the',\n",
       "  'world',\n",
       "  'can',\n",
       "  'come',\n",
       "  'together',\n",
       "  'to',\n",
       "  'celebrate',\n",
       "  'the',\n",
       "  'best',\n",
       "  'of',\n",
       "  'human',\n",
       "  'physical',\n",
       "  'achievement',\n",
       "  '.'],\n",
       " ['when',\n",
       "  'you',\n",
       "  'subsidize',\n",
       "  'journalism',\n",
       "  'you',\n",
       "  'are',\n",
       "  'making',\n",
       "  'the',\n",
       "  'reporting',\n",
       "  'agency',\n",
       "  'less',\n",
       "  'likely',\n",
       "  'to',\n",
       "  'report',\n",
       "  'anything',\n",
       "  'bad',\n",
       "  'about',\n",
       "  'the',\n",
       "  'place',\n",
       "  'that',\n",
       "  'is',\n",
       "  'providing',\n",
       "  'the',\n",
       "  'funding',\n",
       "  '.',\n",
       "  'therefore',\n",
       "  'you',\n",
       "  'are',\n",
       "  'getting',\n",
       "  'less',\n",
       "  'accurate',\n",
       "  'news',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'companies',\n",
       "  'that',\n",
       "  'have',\n",
       "  'the',\n",
       "  'mandatory_retirement',\n",
       "  'policy',\n",
       "  'maintain',\n",
       "  'a',\n",
       "  'rotation',\n",
       "  'of',\n",
       "  'employees',\n",
       "  'fresher',\n",
       "  'and',\n",
       "  'updated',\n",
       "  'with',\n",
       "  'the',\n",
       "  'new',\n",
       "  'times'],\n",
       " ['pupils',\n",
       "  'having',\n",
       "  'to',\n",
       "  'dress',\n",
       "  'in',\n",
       "  'school',\n",
       "  'uniform',\n",
       "  'means',\n",
       "  'no',\n",
       "  'one',\n",
       "  'is',\n",
       "  'singled',\n",
       "  'out',\n",
       "  'for',\n",
       "  'not',\n",
       "  'being',\n",
       "  'able',\n",
       "  'to',\n",
       "  'afford',\n",
       "  'expensive',\n",
       "  'clothes',\n",
       "  '.'],\n",
       " ['cosmetic_surgery',\n",
       "  'has',\n",
       "  'too',\n",
       "  'many',\n",
       "  'risks',\n",
       "  'of',\n",
       "  'something',\n",
       "  'going',\n",
       "  'wrong',\n",
       "  'compared',\n",
       "  'to',\n",
       "  'the',\n",
       "  'benefit',\n",
       "  'of',\n",
       "  'looking',\n",
       "  'more',\n",
       "  'aesthetically',\n",
       "  'pleasing',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  \"n't\",\n",
       "  'ban',\n",
       "  'the',\n",
       "  'church',\n",
       "  'of',\n",
       "  'scientology',\n",
       "  'because',\n",
       "  'it',\n",
       "  'is',\n",
       "  'a',\n",
       "  'way',\n",
       "  'to',\n",
       "  'study',\n",
       "  'the',\n",
       "  'nature',\n",
       "  'of',\n",
       "  'life'],\n",
       " ['child_actors',\n",
       "  'should',\n",
       "  'be',\n",
       "  'allowed',\n",
       "  'to',\n",
       "  'work',\n",
       "  'and',\n",
       "  'contribute',\n",
       "  'their',\n",
       "  'talents',\n",
       "  'to',\n",
       "  'society',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'olympic_games',\n",
       "  'are',\n",
       "  'a',\n",
       "  'testament',\n",
       "  'to',\n",
       "  'the',\n",
       "  'spirit',\n",
       "  'of',\n",
       "  'amateur',\n",
       "  'athleticism',\n",
       "  '.'],\n",
       " ['libertarianism',\n",
       "  'removes',\n",
       "  'the',\n",
       "  'big',\n",
       "  'brother',\n",
       "  'tyranny',\n",
       "  'of',\n",
       "  'big',\n",
       "  'government',\n",
       "  'and',\n",
       "  'allows',\n",
       "  'more',\n",
       "  'freedom',\n",
       "  'for',\n",
       "  'the',\n",
       "  'people'],\n",
       " ['we',\n",
       "  'should',\n",
       "  \"n't\",\n",
       "  'have',\n",
       "  'to',\n",
       "  'adopt',\n",
       "  'a',\n",
       "  'gender',\n",
       "  'neutral_language',\n",
       "  ',',\n",
       "  'i',\n",
       "  'think',\n",
       "  'people',\n",
       "  'should',\n",
       "  'just',\n",
       "  'understand',\n",
       "  'that',\n",
       "  'people',\n",
       "  'speak',\n",
       "  'languages',\n",
       "  'in',\n",
       "  'different',\n",
       "  'ways',\n",
       "  'and',\n",
       "  'they',\n",
       "  'should',\n",
       "  'be',\n",
       "  'acceptable',\n",
       "  'of',\n",
       "  'that',\n",
       "  '.'],\n",
       " ['algorithmic_trading',\n",
       "  'is',\n",
       "  'cost',\n",
       "  'effective',\n",
       "  'because',\n",
       "  'it',\n",
       "  'is',\n",
       "  'timely',\n",
       "  'and',\n",
       "  'accurate',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  \"n't\",\n",
       "  'ban',\n",
       "  'fast_food',\n",
       "  'because',\n",
       "  'it',\n",
       "  'is',\n",
       "  'an',\n",
       "  'affordable',\n",
       "  'option',\n",
       "  'for',\n",
       "  'people',\n",
       "  'that',\n",
       "  'might',\n",
       "  'not',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'get',\n",
       "  'hot',\n",
       "  'food',\n",
       "  'otherways',\n",
       "  '.'],\n",
       " ['every',\n",
       "  'one',\n",
       "  'has',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'choose',\n",
       "  'what',\n",
       "  'they',\n",
       "  'want',\n",
       "  'to',\n",
       "  'do',\n",
       "  'with',\n",
       "  'their',\n",
       "  'bodies',\n",
       "  ',',\n",
       "  'it',\n",
       "  'is',\n",
       "  \"n't\",\n",
       "  'in',\n",
       "  'our',\n",
       "  'place',\n",
       "  'to',\n",
       "  'decide',\n",
       "  'if',\n",
       "  'cosmetic_surgery',\n",
       "  'is',\n",
       "  'bad',\n",
       "  'for',\n",
       "  'minors',\n",
       "  '.'],\n",
       " ['collectivism',\n",
       "  'takes',\n",
       "  'care',\n",
       "  'of',\n",
       "  'an',\n",
       "  'entire',\n",
       "  'group',\n",
       "  \"'s\",\n",
       "  'need',\n",
       "  'vs',\n",
       "  'just',\n",
       "  'one',\n",
       "  'persons',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'highway',\n",
       "  'loss',\n",
       "  'data',\n",
       "  'institute',\n",
       "  'found',\n",
       "  'an',\n",
       "  'increased',\n",
       "  'collision',\n",
       "  'and',\n",
       "  'crash',\n",
       "  'risk',\n",
       "  'in',\n",
       "  'legal',\n",
       "  'marijuana',\n",
       "  'states'],\n",
       " ['it',\n",
       "  'would',\n",
       "  'help',\n",
       "  'people',\n",
       "  'spend',\n",
       "  'less',\n",
       "  'money',\n",
       "  ',',\n",
       "  'which',\n",
       "  'would',\n",
       "  'be',\n",
       "  'good',\n",
       "  'for',\n",
       "  'the',\n",
       "  'economy',\n",
       "  '.'],\n",
       " ['nuclear_weapons',\n",
       "  'are',\n",
       "  'very',\n",
       "  'volatile',\n",
       "  'and',\n",
       "  'should',\n",
       "  'be',\n",
       "  'done',\n",
       "  'away',\n",
       "  'with',\n",
       "  '.'],\n",
       " ['selling',\n",
       "  'organs',\n",
       "  'is',\n",
       "  'dangerous',\n",
       "  ',',\n",
       "  'leading',\n",
       "  'to',\n",
       "  'many',\n",
       "  'deaths',\n",
       "  'on',\n",
       "  'the',\n",
       "  'operating',\n",
       "  'table',\n",
       "  '.'],\n",
       " ['allowing',\n",
       "  'sex_selection',\n",
       "  'could',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'an',\n",
       "  'imbalance',\n",
       "  'of',\n",
       "  'the',\n",
       "  'genders',\n",
       "  'in',\n",
       "  'the',\n",
       "  'population',\n",
       "  '.'],\n",
       " ['nuclear_weapons',\n",
       "  'help',\n",
       "  'keep',\n",
       "  'peace',\n",
       "  '.',\n",
       "  'it',\n",
       "  \"'s\",\n",
       "  'an',\n",
       "  'assurance',\n",
       "  'policy',\n",
       "  '.',\n",
       "  'everyone',\n",
       "  'knows',\n",
       "  'that',\n",
       "  'everyone',\n",
       "  'loses',\n",
       "  'if',\n",
       "  'nuclear',\n",
       "  'war',\n",
       "  'breaks',\n",
       "  'out',\n",
       "  '.',\n",
       "  'this',\n",
       "  'keeps',\n",
       "  'countries',\n",
       "  'in',\n",
       "  'line',\n",
       "  'so',\n",
       "  'as',\n",
       "  'not',\n",
       "  'to',\n",
       "  'provoke',\n",
       "  'a',\n",
       "  'nuclear',\n",
       "  'attack',\n",
       "  '.'],\n",
       " ['everyone',\n",
       "  'needs',\n",
       "  'a',\n",
       "  'place',\n",
       "  'where',\n",
       "  'they',\n",
       "  'can',\n",
       "  'be',\n",
       "  'accepted',\n",
       "  'without',\n",
       "  'judgment',\n",
       "  '.'],\n",
       " ['economic_sanctions',\n",
       "  'work',\n",
       "  'as',\n",
       "  'intended',\n",
       "  'and',\n",
       "  'getting',\n",
       "  'rid',\n",
       "  'of',\n",
       "  'them',\n",
       "  'would',\n",
       "  'make',\n",
       "  'it',\n",
       "  'more',\n",
       "  'difficult',\n",
       "  'to',\n",
       "  'punish',\n",
       "  'offending',\n",
       "  'countries',\n",
       "  '.'],\n",
       " ['cannabis',\n",
       "  'has',\n",
       "  'never',\n",
       "  'been',\n",
       "  'scientifically',\n",
       "  'proven',\n",
       "  'to',\n",
       "  'help',\n",
       "  'any',\n",
       "  'conditions',\n",
       "  '.'],\n",
       " ['intellectual_property',\n",
       "  'rights',\n",
       "  'should',\n",
       "  'be',\n",
       "  'abolished',\n",
       "  'since',\n",
       "  'it',\n",
       "  'does',\n",
       "  \"n't\",\n",
       "  'allow',\n",
       "  'the',\n",
       "  'sharing',\n",
       "  'of',\n",
       "  'ideas'],\n",
       " ['prostitution',\n",
       "  'is',\n",
       "  'linked',\n",
       "  'to',\n",
       "  'many',\n",
       "  'rapes',\n",
       "  ',',\n",
       "  'molestation',\n",
       "  'and',\n",
       "  'murders',\n",
       "  'of',\n",
       "  'young',\n",
       "  'women',\n",
       "  '.'],\n",
       " ['factory_farming', 'reduces', 'the', 'cost', 'of', 'food'],\n",
       " ['we',\n",
       "  'need',\n",
       "  'to',\n",
       "  'subsidize',\n",
       "  'space_exploration',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'find',\n",
       "  'an',\n",
       "  'inhabitable',\n",
       "  'planet',\n",
       "  'we',\n",
       "  'can',\n",
       "  'live',\n",
       "  'on',\n",
       "  'when',\n",
       "  'we',\n",
       "  'finally',\n",
       "  'destroy',\n",
       "  'the',\n",
       "  'one',\n",
       "  'we',\n",
       "  'live',\n",
       "  'on',\n",
       "  'now',\n",
       "  '.'],\n",
       " ['many',\n",
       "  'innocent',\n",
       "  'lives',\n",
       "  'were',\n",
       "  'being',\n",
       "  'taken',\n",
       "  'by',\n",
       "  'this',\n",
       "  'profoundly',\n",
       "  'flawed',\n",
       "  'practice'],\n",
       " ['some',\n",
       "  'people',\n",
       "  'can',\n",
       "  'not',\n",
       "  'be',\n",
       "  'rehabilitated',\n",
       "  'and',\n",
       "  'will',\n",
       "  'only',\n",
       "  'continue',\n",
       "  'their',\n",
       "  'violent',\n",
       "  'acts',\n",
       "  'unless',\n",
       "  'they',\n",
       "  'are',\n",
       "  'put',\n",
       "  'to',\n",
       "  'death',\n",
       "  '.'],\n",
       " ['if',\n",
       "  'people',\n",
       "  'feel',\n",
       "  'personal',\n",
       "  'satisfaction',\n",
       "  'within',\n",
       "  'scientology',\n",
       "  ',',\n",
       "  'i',\n",
       "  'do',\n",
       "  'not',\n",
       "  'see',\n",
       "  'why',\n",
       "  'we',\n",
       "  'have',\n",
       "  'to',\n",
       "  'prohibit',\n",
       "  'it',\n",
       "  '.'],\n",
       " ['too',\n",
       "  'many',\n",
       "  'students',\n",
       "  'have',\n",
       "  'defaulted',\n",
       "  'on',\n",
       "  'loans',\n",
       "  'or',\n",
       "  'are',\n",
       "  'paying',\n",
       "  'them',\n",
       "  'for',\n",
       "  'many',\n",
       "  'years',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'by',\n",
       "  'subsidizing',\n",
       "  'these',\n",
       "  'students',\n",
       "  'we',\n",
       "  'can',\n",
       "  'assist',\n",
       "  'in',\n",
       "  'stopping',\n",
       "  'this',\n",
       "  '.'],\n",
       " ['if',\n",
       "  'we',\n",
       "  'ban',\n",
       "  'missionary_work',\n",
       "  ',',\n",
       "  'then',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'less',\n",
       "  'people',\n",
       "  'would',\n",
       "  'be',\n",
       "  'seeing',\n",
       "  'propaganda',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'ban',\n",
       "  'the',\n",
       "  'church',\n",
       "  'of',\n",
       "  'scientology',\n",
       "  'because',\n",
       "  'they',\n",
       "  'brainwash',\n",
       "  'their',\n",
       "  'members',\n",
       "  'into',\n",
       "  'giving',\n",
       "  'them',\n",
       "  'huge',\n",
       "  'sums',\n",
       "  'of',\n",
       "  'money',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'ban',\n",
       "  'cosmetic_surgery',\n",
       "  'because',\n",
       "  'there',\n",
       "  'are',\n",
       "  'some',\n",
       "  'people',\n",
       "  'that',\n",
       "  'are',\n",
       "  'seriously',\n",
       "  'need',\n",
       "  'it',\n",
       "  'done',\n",
       "  'to',\n",
       "  'improve',\n",
       "  'their',\n",
       "  'lifestyles'],\n",
       " ['parents',\n",
       "  'have',\n",
       "  'every',\n",
       "  'right',\n",
       "  'to',\n",
       "  'decide',\n",
       "  'whether',\n",
       "  'they',\n",
       "  'give',\n",
       "  'birth',\n",
       "  'to',\n",
       "  'a',\n",
       "  'boy',\n",
       "  'or',\n",
       "  'a',\n",
       "  'girl',\n",
       "  '.'],\n",
       " ['based',\n",
       "  'on',\n",
       "  'the',\n",
       "  'reason',\n",
       "  'for',\n",
       "  'targeted_killing',\n",
       "  ',',\n",
       "  'in',\n",
       "  'some',\n",
       "  'cases',\n",
       "  'this',\n",
       "  'does',\n",
       "  'make',\n",
       "  'sense',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'if',\n",
       "  'a',\n",
       "  'person',\n",
       "  'is',\n",
       "  'a',\n",
       "  'serial',\n",
       "  'murderer',\n",
       "  ',',\n",
       "  'and',\n",
       "  'he',\n",
       "  'is',\n",
       "  'caught',\n",
       "  'in',\n",
       "  'gun',\n",
       "  'fire',\n",
       "  ',',\n",
       "  'this',\n",
       "  'type',\n",
       "  'of',\n",
       "  'killing',\n",
       "  'of',\n",
       "  'the',\n",
       "  'murderer',\n",
       "  'is',\n",
       "  'warranted',\n",
       "  '.'],\n",
       " ['human_cloning',\n",
       "  'is',\n",
       "  'unethical',\n",
       "  'and',\n",
       "  'has',\n",
       "  'repercussions',\n",
       "  'that',\n",
       "  'we',\n",
       "  'do',\n",
       "  'not',\n",
       "  'even',\n",
       "  'know',\n",
       "  'yet',\n",
       "  '.'],\n",
       " ['autonomous_cars',\n",
       "  'would',\n",
       "  'help',\n",
       "  'people',\n",
       "  'who',\n",
       "  'are',\n",
       "  'disabled',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'have',\n",
       "  'their',\n",
       "  'own',\n",
       "  'transportation',\n",
       "  '.'],\n",
       " ['child_actors',\n",
       "  'miss',\n",
       "  'out',\n",
       "  'on',\n",
       "  'socialization',\n",
       "  'with',\n",
       "  'kids',\n",
       "  'their',\n",
       "  'own',\n",
       "  'age',\n",
       "  'and',\n",
       "  'fall',\n",
       "  'behind',\n",
       "  'in',\n",
       "  'school'],\n",
       " ['capital_punishment',\n",
       "  'provides',\n",
       "  'closure',\n",
       "  'for',\n",
       "  'victim',\n",
       "  \"'s\",\n",
       "  'families',\n",
       "  'who',\n",
       "  'can',\n",
       "  'be',\n",
       "  'reassured',\n",
       "  'that',\n",
       "  'the',\n",
       "  'perpetrator',\n",
       "  'can',\n",
       "  'literally',\n",
       "  'never',\n",
       "  'harm',\n",
       "  'anyone',\n",
       "  'again',\n",
       "  '.'],\n",
       " ['school_uniforms',\n",
       "  'allow',\n",
       "  'children',\n",
       "  'to',\n",
       "  'attend',\n",
       "  'school',\n",
       "  'without',\n",
       "  'peer',\n",
       "  'pressure',\n",
       "  'on',\n",
       "  'clothing',\n",
       "  '.'],\n",
       " ['factory_farming',\n",
       "  'has',\n",
       "  'allowed',\n",
       "  'the',\n",
       "  'prices',\n",
       "  'of',\n",
       "  'food',\n",
       "  'to',\n",
       "  'drop',\n",
       "  'drastically',\n",
       "  '.'],\n",
       " ['a',\n",
       "  'criminal',\n",
       "  'will',\n",
       "  'think',\n",
       "  'twice',\n",
       "  'about',\n",
       "  'committing',\n",
       "  'a',\n",
       "  'crime',\n",
       "  'knowing',\n",
       "  'that',\n",
       "  'the',\n",
       "  'next',\n",
       "  'crime',\n",
       "  'he',\n",
       "  'commits',\n",
       "  'might',\n",
       "  'mean',\n",
       "  'life',\n",
       "  'imprisonment',\n",
       "  '.'],\n",
       " ['algorithmic_trading',\n",
       "  'is',\n",
       "  'faster',\n",
       "  'and',\n",
       "  'more',\n",
       "  'accurate',\n",
       "  'than',\n",
       "  'human',\n",
       "  'guesswork',\n",
       "  'and',\n",
       "  'so',\n",
       "  'provides',\n",
       "  'greater',\n",
       "  'value',\n",
       "  'to',\n",
       "  'shareholders',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'state',\n",
       "  'can',\n",
       "  'not',\n",
       "  'have',\n",
       "  'exclusivity',\n",
       "  'in',\n",
       "  'the',\n",
       "  'creation',\n",
       "  'of',\n",
       "  'weapons',\n",
       "  ',',\n",
       "  'leaving',\n",
       "  'aside',\n",
       "  'private',\n",
       "  'capital',\n",
       "  'as',\n",
       "  'a',\n",
       "  'source',\n",
       "  'of',\n",
       "  'technological',\n",
       "  'innovations',\n",
       "  'for',\n",
       "  'our',\n",
       "  'defense'],\n",
       " ['children',\n",
       "  \"'s\",\n",
       "  'brains',\n",
       "  'have',\n",
       "  'not',\n",
       "  'matured',\n",
       "  'and',\n",
       "  'developed',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'make',\n",
       "  'life',\n",
       "  'long',\n",
       "  'choices',\n",
       "  'with',\n",
       "  'regards',\n",
       "  'to',\n",
       "  'under',\n",
       "  'going',\n",
       "  'cosmetic_surgery',\n",
       "  '.'],\n",
       " ['legalising',\n",
       "  'prostitution',\n",
       "  'could',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'more',\n",
       "  'serious',\n",
       "  'crimes',\n",
       "  'such',\n",
       "  'as',\n",
       "  'women',\n",
       "  'becoming',\n",
       "  'involved',\n",
       "  'in',\n",
       "  'the',\n",
       "  'drug',\n",
       "  'trade',\n",
       "  'or',\n",
       "  'people',\n",
       "  'trafficking',\n",
       "  '.'],\n",
       " ['judicial_activism',\n",
       "  'is',\n",
       "  'an',\n",
       "  'important',\n",
       "  'part',\n",
       "  'of',\n",
       "  'our',\n",
       "  'country',\n",
       "  '.'],\n",
       " ['with',\n",
       "  'genders',\n",
       "  'now',\n",
       "  'being',\n",
       "  'more',\n",
       "  'equal',\n",
       "  'than',\n",
       "  'ever',\n",
       "  ',',\n",
       "  'and',\n",
       "  'gender',\n",
       "  'neutrality',\n",
       "  'growing',\n",
       "  'exponentially',\n",
       "  'the',\n",
       "  'old',\n",
       "  'gendered',\n",
       "  'language',\n",
       "  'is',\n",
       "  'just',\n",
       "  'a',\n",
       "  'historic',\n",
       "  'anachronism',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'unfair',\n",
       "  'to',\n",
       "  'convict',\n",
       "  'someone',\n",
       "  'for',\n",
       "  'a',\n",
       "  'third',\n",
       "  'crime',\n",
       "  'that',\n",
       "  'is',\n",
       "  \"n't\",\n",
       "  'dependent',\n",
       "  'of',\n",
       "  'the',\n",
       "  'crime',\n",
       "  \"'s\",\n",
       "  'magnitude'],\n",
       " ['pride_parades',\n",
       "  'are',\n",
       "  'a',\n",
       "  'necessary',\n",
       "  'step',\n",
       "  'towards',\n",
       "  'bringing',\n",
       "  'awareness',\n",
       "  'to',\n",
       "  'the',\n",
       "  'world',\n",
       "  'that',\n",
       "  'all',\n",
       "  'human',\n",
       "  'beings',\n",
       "  'deserve',\n",
       "  'respect',\n",
       "  'and',\n",
       "  'acceptance',\n",
       "  '.'],\n",
       " ['safe_spaces',\n",
       "  'are',\n",
       "  'essential',\n",
       "  'to',\n",
       "  'people',\n",
       "  'struggling',\n",
       "  'its',\n",
       "  'mental',\n",
       "  'health',\n",
       "  'problems',\n",
       "  'and',\n",
       "  'getting',\n",
       "  'rid',\n",
       "  'of',\n",
       "  'them',\n",
       "  'would',\n",
       "  'increase',\n",
       "  'their',\n",
       "  'likelihood',\n",
       "  'of',\n",
       "  'abusing',\n",
       "  'drugs',\n",
       "  'to',\n",
       "  'cope',\n",
       "  '.'],\n",
       " ['having',\n",
       "  'intellectual_property',\n",
       "  'rights',\n",
       "  'is',\n",
       "  'a',\n",
       "  'deterrent',\n",
       "  'for',\n",
       "  'those',\n",
       "  'that',\n",
       "  'would',\n",
       "  'steal',\n",
       "  'another',\n",
       "  'persons',\n",
       "  'ideas',\n",
       "  'and',\n",
       "  'creations',\n",
       "  'so',\n",
       "  'we',\n",
       "  'must',\n",
       "  'not',\n",
       "  'abolish',\n",
       "  'that',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'abolish',\n",
       "  'safe_spaces',\n",
       "  'because',\n",
       "  'they',\n",
       "  'put',\n",
       "  'public',\n",
       "  'funding',\n",
       "  'for',\n",
       "  'universities',\n",
       "  'at',\n",
       "  'risk',\n",
       "  ',',\n",
       "  'due',\n",
       "  'to',\n",
       "  'backlash',\n",
       "  'from',\n",
       "  'right',\n",
       "  'wing',\n",
       "  'legislatures',\n",
       "  '.'],\n",
       " ['making',\n",
       "  'a',\n",
       "  'child',\n",
       "  'work',\n",
       "  'as',\n",
       "  'an',\n",
       "  'actor',\n",
       "  'deprives',\n",
       "  'them',\n",
       "  'of',\n",
       "  'childhood',\n",
       "  'experiences',\n",
       "  'and',\n",
       "  'interactions',\n",
       "  '.'],\n",
       " ['collectivism',\n",
       "  'removes',\n",
       "  'an',\n",
       "  'individual',\n",
       "  \"'s\",\n",
       "  'right',\n",
       "  'to',\n",
       "  'promote',\n",
       "  'their',\n",
       "  'private',\n",
       "  'interests',\n",
       "  'and',\n",
       "  'exercise',\n",
       "  'autonomy'],\n",
       " ['if',\n",
       "  'prostitution',\n",
       "  'was',\n",
       "  'legal',\n",
       "  'then',\n",
       "  'the',\n",
       "  'people',\n",
       "  'would',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'be',\n",
       "  'better',\n",
       "  'protected',\n",
       "  'and',\n",
       "  'diseases',\n",
       "  'could',\n",
       "  'be',\n",
       "  'controlled',\n",
       "  'more',\n",
       "  '.'],\n",
       " ['private_military',\n",
       "  'companies',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned',\n",
       "  'as',\n",
       "  'they',\n",
       "  'are',\n",
       "  'not',\n",
       "  'subject',\n",
       "  'to',\n",
       "  'military',\n",
       "  'laws'],\n",
       " ['amulti',\n",
       "  '-',\n",
       "  'party_system',\n",
       "  'can',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'unstable',\n",
       "  'coalitions',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'get',\n",
       "  'into',\n",
       "  'power'],\n",
       " ['factory_farming',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned',\n",
       "  'as',\n",
       "  'the',\n",
       "  'animals',\n",
       "  'in',\n",
       "  'these',\n",
       "  'farms',\n",
       "  'are',\n",
       "  'held',\n",
       "  'in',\n",
       "  'bad',\n",
       "  'conditions',\n",
       "  '.'],\n",
       " ['judicial_activism',\n",
       "  'must',\n",
       "  'be',\n",
       "  'supported',\n",
       "  'by',\n",
       "  'all',\n",
       "  'means',\n",
       "  'because',\n",
       "  'judges',\n",
       "  ' ',\n",
       "  'knows',\n",
       "  'law',\n",
       "  'and',\n",
       "  'they',\n",
       "  'acting',\n",
       "  'inside',\n",
       "  'the',\n",
       "  'law',\n",
       "  'by',\n",
       "  'judicial_activism',\n",
       "  '.'],\n",
       " ['economic_sanctions',\n",
       "  'make',\n",
       "  'items',\n",
       "  'made',\n",
       "  'in',\n",
       "  'foreign',\n",
       "  'countries',\n",
       "  'and',\n",
       "  'shipped',\n",
       "  'here',\n",
       "  'more',\n",
       "  'affordable',\n",
       "  'for',\n",
       "  'struggling',\n",
       "  'americans',\n",
       "  '.'],\n",
       " ['cloning',\n",
       "  'humans',\n",
       "  'can',\n",
       "  'allow',\n",
       "  'us',\n",
       "  'to',\n",
       "  'advance',\n",
       "  'science',\n",
       "  'and',\n",
       "  'medicine',\n",
       "  'in',\n",
       "  'ways',\n",
       "  'which',\n",
       "  'could',\n",
       "  'save',\n",
       "  'millions',\n",
       "  'of',\n",
       "  'lives',\n",
       "  'by',\n",
       "  'producing',\n",
       "  'organs',\n",
       "  ',',\n",
       "  'stem',\n",
       "  'cells',\n",
       "  ',',\n",
       "  'etc',\n",
       "  '.',\n",
       "  ',',\n",
       "  'for',\n",
       "  'those',\n",
       "  'in',\n",
       "  'need',\n",
       "  '.'],\n",
       " ['factory_farming',\n",
       "  'creates',\n",
       "  'health',\n",
       "  'hazards',\n",
       "  'and',\n",
       "  'leads',\n",
       "  'to',\n",
       "  'an',\n",
       "  'increase',\n",
       "  'in',\n",
       "  'pollution',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'overall',\n",
       "  'it',\n",
       "  'is',\n",
       "  'bad',\n",
       "  'for',\n",
       "  'the',\n",
       "  'environment'],\n",
       " ['people',\n",
       "  'are',\n",
       "  'entitled',\n",
       "  'to',\n",
       "  'believe',\n",
       "  'in',\n",
       "  'any',\n",
       "  'god',\n",
       "  'that',\n",
       "  'they',\n",
       "  'choose',\n",
       "  'to',\n",
       "  'believe',\n",
       "  'in',\n",
       "  '.',\n",
       "  'as',\n",
       "  'religion',\n",
       "  'offers',\n",
       "  'comfort',\n",
       "  ',',\n",
       "  'aatheism',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'adopted',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'definitely',\n",
       "  'ban',\n",
       "  'targeted_killing',\n",
       "  'because',\n",
       "  'the',\n",
       "  'loss',\n",
       "  'of',\n",
       "  'life',\n",
       "  'should',\n",
       "  'never',\n",
       "  'be',\n",
       "  'a',\n",
       "  'planned',\n",
       "  'event',\n",
       "  '.'],\n",
       " ['whaling', 'is', 'part', 'of', 'a', 'great', 'number', 'of', 'cultures'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'ban',\n",
       "  'targeted_killing',\n",
       "  'as',\n",
       "  'it',\n",
       "  'is',\n",
       "  'the',\n",
       "  'only',\n",
       "  'way',\n",
       "  'to',\n",
       "  'deal',\n",
       "  'with',\n",
       "  'particular',\n",
       "  'criminals',\n",
       "  'who',\n",
       "  'are',\n",
       "  'otherwise',\n",
       "  'not',\n",
       "  'able',\n",
       "  'to',\n",
       "  'be',\n",
       "  'captured',\n",
       "  'or',\n",
       "  'killed',\n",
       "  '.'],\n",
       " ['human_cloning',\n",
       "  'is',\n",
       "  'very',\n",
       "  'open',\n",
       "  'to',\n",
       "  'abuse',\n",
       "  'and',\n",
       "  'could',\n",
       "  'be',\n",
       "  'used',\n",
       "  'for',\n",
       "  'the',\n",
       "  'wrong',\n",
       "  'things'],\n",
       " ['safe_spaces',\n",
       "  'should',\n",
       "  'be',\n",
       "  'abolished',\n",
       "  'as',\n",
       "  'this',\n",
       "  'it',\n",
       "  'just',\n",
       "  'makes',\n",
       "  'our',\n",
       "  'society',\n",
       "  'weak',\n",
       "  '.'],\n",
       " ['fast_food',\n",
       "  'is',\n",
       "  'known',\n",
       "  'to',\n",
       "  'contain',\n",
       "  'unhealthy',\n",
       "  'fats',\n",
       "  'and',\n",
       "  'no',\n",
       "  'necessary',\n",
       "  'nutrients'],\n",
       " ['collectivism',\n",
       "  'does',\n",
       "  \"n't\",\n",
       "  'allow',\n",
       "  'people',\n",
       "  'to',\n",
       "  'stand',\n",
       "  'up',\n",
       "  'on',\n",
       "  'their',\n",
       "  'own',\n",
       "  'for',\n",
       "  'what',\n",
       "  'they',\n",
       "  'believe',\n",
       "  'in'],\n",
       " ['zoos',\n",
       "  'force',\n",
       "  'animals',\n",
       "  'into',\n",
       "  'an',\n",
       "  'existence',\n",
       "  'outside',\n",
       "  'of',\n",
       "  'their',\n",
       "  'natural',\n",
       "  'habitat',\n",
       "  'for',\n",
       "  'our',\n",
       "  'viewing',\n",
       "  'pleasure',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'it',\n",
       "  'is',\n",
       "  'not',\n",
       "  'right',\n",
       "  'to',\n",
       "  'subject',\n",
       "  'them',\n",
       "  'to',\n",
       "  'such',\n",
       "  'an',\n",
       "  'environment',\n",
       "  '.'],\n",
       " ['judicial_activism',\n",
       "  'can',\n",
       "  'highlight',\n",
       "  'wrong',\n",
       "  'legislation',\n",
       "  ',',\n",
       "  'or',\n",
       "  'deliver',\n",
       "  'accurate',\n",
       "  'justice',\n",
       "  'that',\n",
       "  'can',\n",
       "  'not',\n",
       "  'be',\n",
       "  'addressed',\n",
       "  'through',\n",
       "  'the',\n",
       "  'existing',\n",
       "  'laws'],\n",
       " ['cosmetic_surgery',\n",
       "  'promotes',\n",
       "  'a',\n",
       "  'capitalistic',\n",
       "  'society',\n",
       "  'that',\n",
       "  'focuses',\n",
       "  'on',\n",
       "  'solving',\n",
       "  'problems',\n",
       "  'with',\n",
       "  'money',\n",
       "  'rather_than',\n",
       "  'personal',\n",
       "  'acceptance',\n",
       "  '.'],\n",
       " ['zero',\n",
       "  '-',\n",
       "  'tolerance',\n",
       "  'policies',\n",
       "  'are',\n",
       "  'helpful',\n",
       "  'as',\n",
       "  'they',\n",
       "  'stop',\n",
       "  'children',\n",
       "  'misbehaving'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'ban',\n",
       "  'whaling',\n",
       "  'because',\n",
       "  'there',\n",
       "  'is',\n",
       "  'very',\n",
       "  'little',\n",
       "  'profit',\n",
       "  'in',\n",
       "  'the',\n",
       "  'business',\n",
       "  'and',\n",
       "  'does',\n",
       "  'nothing',\n",
       "  'but',\n",
       "  'kill',\n",
       "  'fairly',\n",
       "  'rare',\n",
       "  'animals',\n",
       "  '.'],\n",
       " ['too',\n",
       "  'many',\n",
       "  'choices',\n",
       "  'in',\n",
       "  'political',\n",
       "  'parties',\n",
       "  'separates',\n",
       "  'people',\n",
       "  'in',\n",
       "  'a',\n",
       "  'country',\n",
       "  'instead',\n",
       "  'of',\n",
       "  'helping',\n",
       "  'them',\n",
       "  'to',\n",
       "  'unite',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'adopt',\n",
       "  'gender',\n",
       "  '-',\n",
       "  'neutral_language',\n",
       "  'because',\n",
       "  'no',\n",
       "  'reason',\n",
       "  'to',\n",
       "  'change',\n",
       "  'the',\n",
       "  'way',\n",
       "  'people',\n",
       "  'have',\n",
       "  'been',\n",
       "  'speaking',\n",
       "  'for',\n",
       "  'hundreds',\n",
       "  'of',\n",
       "  'years'],\n",
       " ['factory_farming',\n",
       "  'is',\n",
       "  'necessary',\n",
       "  'in',\n",
       "  'our',\n",
       "  'society',\n",
       "  'as',\n",
       "  'a',\n",
       "  'way',\n",
       "  'to',\n",
       "  'control',\n",
       "  'and',\n",
       "  'protect',\n",
       "  'the',\n",
       "  'environment',\n",
       "  'in',\n",
       "  'which',\n",
       "  'the',\n",
       "  'animals',\n",
       "  'are',\n",
       "  'living',\n",
       "  'so',\n",
       "  'they',\n",
       "  'are',\n",
       "  'not',\n",
       "  'subjected',\n",
       "  'to',\n",
       "  'disease',\n",
       "  'and',\n",
       "  'predators',\n",
       "  '.'],\n",
       " ['cannabis',\n",
       "  'is',\n",
       "  'no',\n",
       "  'more',\n",
       "  'harmful',\n",
       "  'than',\n",
       "  'cigarettes',\n",
       "  'or',\n",
       "  'alcohol',\n",
       "  ',',\n",
       "  'and',\n",
       "  'no',\n",
       "  'more',\n",
       "  'addictive',\n",
       "  'than',\n",
       "  'the',\n",
       "  'two',\n",
       "  '.'],\n",
       " ['it',\n",
       "  \"'s\",\n",
       "  'bad',\n",
       "  'enough',\n",
       "  'having',\n",
       "  'to',\n",
       "  'take',\n",
       "  'out',\n",
       "  'a',\n",
       "  'student',\n",
       "  'loan',\n",
       "  'in',\n",
       "  'the',\n",
       "  'first',\n",
       "  'place',\n",
       "  ',',\n",
       "  'but',\n",
       "  'even',\n",
       "  'more',\n",
       "  'students',\n",
       "  'from',\n",
       "  'poorer',\n",
       "  'backgrounds',\n",
       "  'will',\n",
       "  'be',\n",
       "  'reluctant',\n",
       "  'to',\n",
       "  'go',\n",
       "  'into',\n",
       "  'higher',\n",
       "  'education',\n",
       "  'if',\n",
       "  'their',\n",
       "  'student_loans',\n",
       "  'are',\n",
       "  \"n't\",\n",
       "  'subsidized',\n",
       "  '.'],\n",
       " ['autonomous_cars',\n",
       "  'will',\n",
       "  'reduce',\n",
       "  'the',\n",
       "  'human',\n",
       "  'margin',\n",
       "  'of',\n",
       "  'error',\n",
       "  'to',\n",
       "  'near',\n",
       "  'zero',\n",
       "  'and',\n",
       "  'make',\n",
       "  'for',\n",
       "  'a',\n",
       "  'safer',\n",
       "  'commute',\n",
       "  '.'],\n",
       " ['i',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'think',\n",
       "  'tax',\n",
       "  'dollars',\n",
       "  'should',\n",
       "  'be',\n",
       "  'going',\n",
       "  'towards',\n",
       "  'researching',\n",
       "  'embryonic_stem',\n",
       "  'cells',\n",
       "  '.',\n",
       "  '  ',\n",
       "  'there',\n",
       "  'is',\n",
       "  'much',\n",
       "  'better',\n",
       "  'usage',\n",
       "  'for',\n",
       "  'our',\n",
       "  'money',\n",
       "  'than',\n",
       "  'that',\n",
       "  '.',\n",
       "  '  ',\n",
       "  'we',\n",
       "  'do',\n",
       "  'not',\n",
       "  'need',\n",
       "  'to',\n",
       "  'subsidize',\n",
       "  'this',\n",
       "  '.'],\n",
       " ['telemarketing',\n",
       "  'targets',\n",
       "  'the',\n",
       "  'weak',\n",
       "  'and',\n",
       "  'encourages',\n",
       "  'them',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'what',\n",
       "  'they',\n",
       "  'ca',\n",
       "  \"n't\",\n",
       "  'afford',\n",
       "  '.'],\n",
       " ['private_military',\n",
       "  'companies',\n",
       "  'are',\n",
       "  'a',\n",
       "  'threat',\n",
       "  'to',\n",
       "  'our',\n",
       "  'democracy',\n",
       "  'and',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'tolerated',\n",
       "  'anymore'],\n",
       " ['journalism', 'has', 'been', 'an', 'important', 'profession', '.'],\n",
       " ['atheism',\n",
       "  'is',\n",
       "  'a',\n",
       "  'valid',\n",
       "  'form',\n",
       "  'of',\n",
       "  'thinking',\n",
       "  'just',\n",
       "  'as',\n",
       "  'many',\n",
       "  'controlled',\n",
       "  'religions',\n",
       "  '.',\n",
       "  'we',\n",
       "  'should',\n",
       "  'adopt',\n",
       "  'and',\n",
       "  'accept',\n",
       "  'it',\n",
       "  'as',\n",
       "  'we',\n",
       "  'do',\n",
       "  'with',\n",
       "  'other',\n",
       "  'beliefs',\n",
       "  '.'],\n",
       " ['all',\n",
       "  'avenues',\n",
       "  'should',\n",
       "  'be',\n",
       "  'looked',\n",
       "  'at',\n",
       "  ',',\n",
       "  'not',\n",
       "  'just',\n",
       "  'the',\n",
       "  'supposedly',\n",
       "  'straight',\n",
       "  'forward',\n",
       "  '.'],\n",
       " ['collectivism',\n",
       "  'gives',\n",
       "  'the',\n",
       "  'group',\n",
       "  'priority',\n",
       "  'over',\n",
       "  'individual',\n",
       "  'needs',\n",
       "  '-',\n",
       "  'this',\n",
       "  'would',\n",
       "  'be',\n",
       "  'very',\n",
       "  'unfair',\n",
       "  'for',\n",
       "  'some',\n",
       "  'individuals',\n",
       "  'who',\n",
       "  'may',\n",
       "  'have',\n",
       "  'a',\n",
       "  'higher',\n",
       "  'or',\n",
       "  'different',\n",
       "  'need',\n",
       "  'than',\n",
       "  'the',\n",
       "  'majority',\n",
       "  'of',\n",
       "  'the',\n",
       "  'group'],\n",
       " ['a',\n",
       "  'multi',\n",
       "  '-',\n",
       "  'party_system',\n",
       "  'allows',\n",
       "  'for',\n",
       "  'greater',\n",
       "  'choice',\n",
       "  'in',\n",
       "  'whom',\n",
       "  'to',\n",
       "  'vote',\n",
       "  'for',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'it',\n",
       "  'allows',\n",
       "  'each',\n",
       "  'citizen',\n",
       "  'to',\n",
       "  'vote',\n",
       "  'for',\n",
       "  'the',\n",
       "  'party',\n",
       "  'that',\n",
       "  'best',\n",
       "  'fits',\n",
       "  'their',\n",
       "  'beliefs',\n",
       "  'and',\n",
       "  'represents',\n",
       "  'their',\n",
       "  'ideology',\n",
       "  '.'],\n",
       " ['programmes',\n",
       "  'will',\n",
       "  'always',\n",
       "  'evolve',\n",
       "  'to',\n",
       "  'make',\n",
       "  'better',\n",
       "  'use',\n",
       "  'of',\n",
       "  'trading',\n",
       "  'practices',\n",
       "  ',',\n",
       "  'so',\n",
       "  'holding',\n",
       "  'people',\n",
       "  'back',\n",
       "  'from',\n",
       "  'using',\n",
       "  'algorithmic_trading',\n",
       "  'will',\n",
       "  'only',\n",
       "  'serve',\n",
       "  'to',\n",
       "  'slow',\n",
       "  'down',\n",
       "  'progress',\n",
       "  '.'],\n",
       " ['gay',\n",
       "  'people',\n",
       "  'have',\n",
       "  'suffered',\n",
       "  'alot',\n",
       "  'over',\n",
       "  'the',\n",
       "  'decades',\n",
       "  'and',\n",
       "  'should',\n",
       "  'be',\n",
       "  'entitled',\n",
       "  'to',\n",
       "  'have',\n",
       "  'a',\n",
       "  'parade',\n",
       "  'celebrating',\n",
       "  'their',\n",
       "  'sexuality',\n",
       "  '.'],\n",
       " ['if',\n",
       "  'everything',\n",
       "  'was',\n",
       "  'spoken',\n",
       "  'about',\n",
       "  'gender',\n",
       "  'neutrally',\n",
       "  'then',\n",
       "  'no',\n",
       "  'one',\n",
       "  'would',\n",
       "  'be',\n",
       "  'offended',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'open',\n",
       "  'source',\n",
       "  'nature',\n",
       "  'of',\n",
       "  'wikipedia',\n",
       "  'means',\n",
       "  'anyone',\n",
       "  'can',\n",
       "  'add',\n",
       "  'gibberish',\n",
       "  'and',\n",
       "  'falsehood',\n",
       "  'in',\n",
       "  'its',\n",
       "  'contents',\n",
       "  'thereby',\n",
       "  'making',\n",
       "  'it',\n",
       "  'unreliable',\n",
       "  '.'],\n",
       " ['missionary_work',\n",
       "  'has',\n",
       "  'helped',\n",
       "  'to',\n",
       "  'civilize',\n",
       "  'entire',\n",
       "  'socities',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'ability',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'and',\n",
       "  'use',\n",
       "  'firearms',\n",
       "  'is',\n",
       "  'instrumental',\n",
       "  'in',\n",
       "  'a',\n",
       "  'person',\n",
       "  \"'s\",\n",
       "  'ability',\n",
       "  'to',\n",
       "  'persue',\n",
       "  'safety',\n",
       "  ',',\n",
       "  'life',\n",
       "  'and',\n",
       "  'liberty'],\n",
       " ['many',\n",
       "  'people',\n",
       "  'use',\n",
       "  'religion',\n",
       "  'to',\n",
       "  'connect',\n",
       "  'with',\n",
       "  'their',\n",
       "  'family',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'loved',\n",
       "  'ones',\n",
       "  'that',\n",
       "  'are',\n",
       "  'no',\n",
       "  'longer',\n",
       "  'alive',\n",
       "  '-',\n",
       "  'losing',\n",
       "  'this',\n",
       "  'comforting',\n",
       "  'connection',\n",
       "  'would',\n",
       "  'be',\n",
       "  'devastating',\n",
       "  'for',\n",
       "  'some',\n",
       "  '.'],\n",
       " ['private_military',\n",
       "  'companies',\n",
       "  'provide',\n",
       "  'additional',\n",
       "  'soldiers',\n",
       "  'in',\n",
       "  'places',\n",
       "  'where',\n",
       "  'it',\n",
       "  'is',\n",
       "  'necessary'],\n",
       " ['adolescents',\n",
       "  'can',\n",
       "  'be',\n",
       "  'very',\n",
       "  'self',\n",
       "  '-',\n",
       "  'conscious',\n",
       "  'about',\n",
       "  'their',\n",
       "  'appearance',\n",
       "  '.',\n",
       "  'if',\n",
       "  'a',\n",
       "  'student',\n",
       "  'thinks',\n",
       "  'their',\n",
       "  'uniform',\n",
       "  'is',\n",
       "  'unflattering',\n",
       "  ',',\n",
       "  'it',\n",
       "  'may',\n",
       "  'cause',\n",
       "  'them',\n",
       "  'discomfort',\n",
       "  'and',\n",
       "  'embarrassment',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'legalize',\n",
       "  'organ_trade',\n",
       "  'because',\n",
       "  'many',\n",
       "  'people',\n",
       "  'who',\n",
       "  'are',\n",
       "  'in',\n",
       "  'need',\n",
       "  'of',\n",
       "  'organs',\n",
       "  'have',\n",
       "  'trouble',\n",
       "  'getting',\n",
       "  'good',\n",
       "  'organs',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'ban',\n",
       "  'private_military',\n",
       "  'companies',\n",
       "  'because',\n",
       "  'they',\n",
       "  'protect',\n",
       "  'people'],\n",
       " ['banning',\n",
       "  'fast_food',\n",
       "  'is',\n",
       "  'an',\n",
       "  'example',\n",
       "  'of',\n",
       "  'regulations',\n",
       "  'which',\n",
       "  'take',\n",
       "  'away',\n",
       "  'our',\n",
       "  'right',\n",
       "  'to',\n",
       "  'freedom',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'abolish',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'and',\n",
       "  'bear_arms',\n",
       "  'as',\n",
       "  'this',\n",
       "  'right',\n",
       "  'has',\n",
       "  'gotten',\n",
       "  'out',\n",
       "  'of',\n",
       "  'hand',\n",
       "  'with',\n",
       "  'too',\n",
       "  'many',\n",
       "  'mass',\n",
       "  'shootings',\n",
       "  '.'],\n",
       " ['the', 'olympic_games', 'are', 'too', 'expensive', 'to', 'be', 'held'],\n",
       " ['whaling',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned',\n",
       "  'because',\n",
       "  'it',\n",
       "  'harms',\n",
       "  'economic',\n",
       "  'activity',\n",
       "  'that',\n",
       "  \"'s\",\n",
       "  'generated',\n",
       "  'by',\n",
       "  'whale',\n",
       "  'watching'],\n",
       " ['certain',\n",
       "  'professions',\n",
       "  ',',\n",
       "  'such',\n",
       "  'as',\n",
       "  'police',\n",
       "  'officer',\n",
       "  'and',\n",
       "  'air',\n",
       "  'traffic',\n",
       "  'controller',\n",
       "  ',',\n",
       "  'have',\n",
       "  'mandatory_retirement',\n",
       "  'ages',\n",
       "  ' ',\n",
       "  'to',\n",
       "  'ensure',\n",
       "  'that',\n",
       "  'the',\n",
       "  'person',\n",
       "  'who',\n",
       "  'is',\n",
       "  'responsible',\n",
       "  'for',\n",
       "  'the',\n",
       "  'safety',\n",
       "  'of',\n",
       "  'others',\n",
       "  'remains',\n",
       "  'competent',\n",
       "  'to',\n",
       "  'do',\n",
       "  'his',\n",
       "  'job'],\n",
       " ['libertarianism',\n",
       "  'allows',\n",
       "  'the',\n",
       "  'expression',\n",
       "  'of',\n",
       "  'free',\n",
       "  'will',\n",
       "  'and',\n",
       "  'would',\n",
       "  'make',\n",
       "  'society',\n",
       "  'more',\n",
       "  'interesting',\n",
       "  'by',\n",
       "  'allowing',\n",
       "  'people',\n",
       "  'to',\n",
       "  'be',\n",
       "  'as',\n",
       "  'they',\n",
       "  'truly',\n",
       "  'are',\n",
       "  '.'],\n",
       " ['bannabis',\n",
       "  'should',\n",
       "  'be',\n",
       "  'legalized',\n",
       "  'as',\n",
       "  'it',\n",
       "  'has',\n",
       "  'been',\n",
       "  'proven',\n",
       "  'to',\n",
       "  'have',\n",
       "  'medical',\n",
       "  'benefits',\n",
       "  'that',\n",
       "  'outweigh',\n",
       "  'any',\n",
       "  'negative',\n",
       "  'effects',\n",
       "  '.',\n",
       "  'it',\n",
       "  'will',\n",
       "  'also',\n",
       "  'remove',\n",
       "  'it',\n",
       "  'from',\n",
       "  'the',\n",
       "  'control',\n",
       "  'of',\n",
       "  'criminals',\n",
       "  'and',\n",
       "  'gangsters'],\n",
       " ['cancelling',\n",
       "  'pride_parades',\n",
       "  'goes',\n",
       "  'against',\n",
       "  'what',\n",
       "  'they',\n",
       "  'stand',\n",
       "  'for',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'those',\n",
       "  'parades',\n",
       "  'are',\n",
       "  'vital',\n",
       "  'for',\n",
       "  'spreading',\n",
       "  'acceptance',\n",
       "  '.'],\n",
       " ['gender',\n",
       "  '-',\n",
       "  'neutral_language',\n",
       "  'will',\n",
       "  'cause',\n",
       "  'confusion',\n",
       "  'if',\n",
       "  'we',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'know',\n",
       "  'who',\n",
       "  'is',\n",
       "  'being',\n",
       "  'referred',\n",
       "  'to'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'unfair',\n",
       "  'on',\n",
       "  'those',\n",
       "  'being',\n",
       "  'bullied',\n",
       "  'to',\n",
       "  'punish',\n",
       "  'them',\n",
       "  'the',\n",
       "  'same',\n",
       "  'as',\n",
       "  'you',\n",
       "  'punish',\n",
       "  'the',\n",
       "  'bully'],\n",
       " ['some',\n",
       "  'people',\n",
       "  'do',\n",
       "  'not',\n",
       "  'feel',\n",
       "  'capable',\n",
       "  'of',\n",
       "  'exercising',\n",
       "  'such',\n",
       "  'a',\n",
       "  'responsibility'],\n",
       " ['zoos',\n",
       "  'trap',\n",
       "  'animals',\n",
       "  'into',\n",
       "  'a',\n",
       "  'meaningless',\n",
       "  'life',\n",
       "  'only',\n",
       "  'to',\n",
       "  'amuse',\n",
       "  'human',\n",
       "  'onlookers'],\n",
       " ['cosmetic_surgery', 'is', 'dangerous', 'and', 'should', 'be', 'banned', '.'],\n",
       " ['those',\n",
       "  'authoring',\n",
       "  'articles',\n",
       "  'on',\n",
       "  'wikipedia',\n",
       "  'are',\n",
       "  'not',\n",
       "  'necessarily',\n",
       "  'experts',\n",
       "  'on',\n",
       "  'the',\n",
       "  'topic',\n",
       "  'and',\n",
       "  'there',\n",
       "  'is',\n",
       "  'risk',\n",
       "  'of',\n",
       "  'inaccurate',\n",
       "  'information',\n",
       "  'being',\n",
       "  'broadcast',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'would',\n",
       "  'end',\n",
       "  'up',\n",
       "  'in',\n",
       "  'bidding',\n",
       "  'wars',\n",
       "  'where',\n",
       "  'only',\n",
       "  'the',\n",
       "  'rich',\n",
       "  'could',\n",
       "  'be',\n",
       "  'helped'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'ban',\n",
       "  'human_cloning',\n",
       "  'because',\n",
       "  'playing',\n",
       "  'god',\n",
       "  'can',\n",
       "  'be',\n",
       "  'dangerous',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'limit',\n",
       "  'executive_compensation',\n",
       "  'for',\n",
       "  'national',\n",
       "  'ecomics'],\n",
       " ['collectivism',\n",
       "  'is',\n",
       "  'unfair',\n",
       "  'to',\n",
       "  'large',\n",
       "  'populations',\n",
       "  'and',\n",
       "  'should',\n",
       "  'be',\n",
       "  'stopped'],\n",
       " ['ceo',\n",
       "  \"'s\",\n",
       "  'make',\n",
       "  '100',\n",
       "  'times',\n",
       "  'what',\n",
       "  'an',\n",
       "  'average',\n",
       "  'worker',\n",
       "  'make',\n",
       "  'and',\n",
       "  'they',\n",
       "  'do',\n",
       "  'not',\n",
       "  'actually',\n",
       "  'generate',\n",
       "  'any',\n",
       "  'capital',\n",
       "  '.'],\n",
       " ['turn',\n",
       "  'out',\n",
       "  'figures',\n",
       "  'are',\n",
       "  'unacceptably',\n",
       "  'low',\n",
       "  ',',\n",
       "  'we',\n",
       "  'need',\n",
       "  'to',\n",
       "  'motivate',\n",
       "  'people',\n",
       "  'to',\n",
       "  'be',\n",
       "  'active',\n",
       "  'voters',\n",
       "  'for',\n",
       "  'a',\n",
       "  'representative',\n",
       "  'democracy'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'ban',\n",
       "  'algorithmic_trading',\n",
       "  'because',\n",
       "  'most',\n",
       "  'people',\n",
       "  'have',\n",
       "  'no',\n",
       "  'idea',\n",
       "  'how',\n",
       "  'it',\n",
       "  'works',\n",
       "  'and',\n",
       "  'if',\n",
       "  'it',\n",
       "  'is',\n",
       "  'good',\n",
       "  'for',\n",
       "  'them',\n",
       "  'or',\n",
       "  'not'],\n",
       " ['zoos',\n",
       "  'are',\n",
       "  \"n't\",\n",
       "  'all',\n",
       "  'properly',\n",
       "  'regulated',\n",
       "  'and',\n",
       "  'some',\n",
       "  'animals',\n",
       "  'are',\n",
       "  'kept',\n",
       "  'in',\n",
       "  'appalling',\n",
       "  'conditions',\n",
       "  'they',\n",
       "  'should',\n",
       "  'be',\n",
       "  'left',\n",
       "  'in',\n",
       "  'their',\n",
       "  'natural',\n",
       "  'environment'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'limit',\n",
       "  'judicial_activism',\n",
       "  'as',\n",
       "  'it',\n",
       "  'goes',\n",
       "  'outside',\n",
       "  'the',\n",
       "  'set',\n",
       "  'laws',\n",
       "  'and',\n",
       "  'eventually',\n",
       "  'could',\n",
       "  'go',\n",
       "  'to',\n",
       "  'far',\n",
       "  'to',\n",
       "  'one',\n",
       "  'person',\n",
       "  'creating',\n",
       "  'their',\n",
       "  'own',\n",
       "  'agendas',\n",
       "  '.'],\n",
       " ['autonomous_cars',\n",
       "  'will',\n",
       "  'allow',\n",
       "  'people',\n",
       "  'to',\n",
       "  'do',\n",
       "  'more',\n",
       "  'instead',\n",
       "  'of',\n",
       "  'wasting',\n",
       "  'time',\n",
       "  'in',\n",
       "  'traffic'],\n",
       " ['compulsory_voting',\n",
       "  'would',\n",
       "  'make',\n",
       "  'the',\n",
       "  'election',\n",
       "  'practice',\n",
       "  'fairer',\n",
       "  '.'],\n",
       " ['fast_food',\n",
       "  'is',\n",
       "  'good',\n",
       "  'for',\n",
       "  'busy',\n",
       "  'people',\n",
       "  'allowing',\n",
       "  'the',\n",
       "  'to',\n",
       "  'pick',\n",
       "  'up',\n",
       "  'something',\n",
       "  'to',\n",
       "  'eat',\n",
       "  'on',\n",
       "  'the',\n",
       "  'go',\n",
       "  '.'],\n",
       " ['nuclear_weapons',\n",
       "  'create',\n",
       "  'such',\n",
       "  'irreversible',\n",
       "  'damage',\n",
       "  'that',\n",
       "  'we',\n",
       "  'should',\n",
       "  'all',\n",
       "  'agree',\n",
       "  'to',\n",
       "  'remove',\n",
       "  'them',\n",
       "  'as',\n",
       "  'an',\n",
       "  'option',\n",
       "  '.'],\n",
       " ['some',\n",
       "  'fast_food',\n",
       "  'restaurants',\n",
       "  'offer',\n",
       "  'healthy',\n",
       "  'alternatives',\n",
       "  'and',\n",
       "  'provide',\n",
       "  'a',\n",
       "  'quick',\n",
       "  ',',\n",
       "  'nutritious',\n",
       "  'meal',\n",
       "  'on',\n",
       "  '-',\n",
       "  'the',\n",
       "  '-',\n",
       "  'go',\n",
       "  '.'],\n",
       " ['most',\n",
       "  'whaling',\n",
       "  'is',\n",
       "  'done',\n",
       "  'under',\n",
       "  'controlled',\n",
       "  'situations',\n",
       "  ',',\n",
       "  'and',\n",
       "  'is',\n",
       "  'done',\n",
       "  'for',\n",
       "  'research',\n",
       "  'purposes',\n",
       "  '.'],\n",
       " ['strict',\n",
       "  'capital_punishment',\n",
       "  'brings',\n",
       "  'justice',\n",
       "  'and',\n",
       "  'closure',\n",
       "  'to',\n",
       "  'the',\n",
       "  'victim',\n",
       "  \"'s\",\n",
       "  'family'],\n",
       " ['zero',\n",
       "  'tolerance',\n",
       "  'leaves',\n",
       "  'no',\n",
       "  'room',\n",
       "  'for',\n",
       "  'individual',\n",
       "  'cases',\n",
       "  'where',\n",
       "  'it',\n",
       "  'may',\n",
       "  'do',\n",
       "  'more',\n",
       "  'harm',\n",
       "  'than',\n",
       "  'good'],\n",
       " ['excessive',\n",
       "  'wages',\n",
       "  'damage',\n",
       "  'company',\n",
       "  'profitabity',\n",
       "  'and',\n",
       "  'is',\n",
       "  'an',\n",
       "  'abuse',\n",
       "  'of',\n",
       "  'the',\n",
       "  'shareholders'],\n",
       " ['wikipedia',\n",
       "  'is',\n",
       "  'not',\n",
       "  'free',\n",
       "  'to',\n",
       "  'run',\n",
       "  'even',\n",
       "  'if',\n",
       "  'it',\n",
       "  'is',\n",
       "  'free',\n",
       "  'to',\n",
       "  'users',\n",
       "  '.',\n",
       "  'subsidization',\n",
       "  'would',\n",
       "  'help',\n",
       "  'keep',\n",
       "  'it',\n",
       "  'free',\n",
       "  'for',\n",
       "  'users',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'olympic_games',\n",
       "  'allow',\n",
       "  'for',\n",
       "  'true',\n",
       "  'amateur',\n",
       "  'athletes',\n",
       "  'to',\n",
       "  'live',\n",
       "  'out',\n",
       "  'their',\n",
       "  'dreams',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'costs',\n",
       "  'too',\n",
       "  'much',\n",
       "  'to',\n",
       "  'build',\n",
       "  'for',\n",
       "  'the',\n",
       "  'games',\n",
       "  'and',\n",
       "  'never',\n",
       "  'use',\n",
       "  'those',\n",
       "  'buildings',\n",
       "  'again'],\n",
       " ['sale',\n",
       "  'of',\n",
       "  'cannabis',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'legalized',\n",
       "  'because',\n",
       "  'it',\n",
       "  'is',\n",
       "  'a',\n",
       "  'dangerous',\n",
       "  'drug',\n",
       "  'and',\n",
       "  'as',\n",
       "  'such',\n",
       "  'is',\n",
       "  'a',\n",
       "  'public',\n",
       "  'health',\n",
       "  'concern'],\n",
       " ['libertarianism',\n",
       "  'promotes',\n",
       "  'political',\n",
       "  'freedom',\n",
       "  'of',\n",
       "  'choice',\n",
       "  'as',\n",
       "  'its',\n",
       "  'core',\n",
       "  'value',\n",
       "  ',',\n",
       "  'and',\n",
       "  'is',\n",
       "  'the',\n",
       "  'ultimate',\n",
       "  'expression',\n",
       "  'of',\n",
       "  'democracy',\n",
       "  '.'],\n",
       " ['missionary_work',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned',\n",
       "  'as',\n",
       "  'it',\n",
       "  'can',\n",
       "  'be',\n",
       "  'abused',\n",
       "  'and',\n",
       "  'vulnerable',\n",
       "  'people',\n",
       "  'can',\n",
       "  'be',\n",
       "  'taken',\n",
       "  'advantage',\n",
       "  'of'],\n",
       " ['people',\n",
       "  'should',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'go',\n",
       "  'to',\n",
       "  'school',\n",
       "  'and',\n",
       "  'better',\n",
       "  'themselves',\n",
       "  'without',\n",
       "  'having',\n",
       "  'to',\n",
       "  'pay',\n",
       "  'back',\n",
       "  'thousands',\n",
       "  'of',\n",
       "  'dollars',\n",
       "  'when',\n",
       "  'they',\n",
       "  'graduate',\n",
       "  '.'],\n",
       " ['as',\n",
       "  'americans',\n",
       "  'we',\n",
       "  'are',\n",
       "  'granted',\n",
       "  'the',\n",
       "  'right',\n",
       "  'of',\n",
       "  'due',\n",
       "  'process',\n",
       "  '.',\n",
       "  'sometimes',\n",
       "  'there',\n",
       "  'are',\n",
       "  'extenuating',\n",
       "  'circumstances',\n",
       "  'that',\n",
       "  'must',\n",
       "  'be',\n",
       "  'taken',\n",
       "  'into',\n",
       "  'account',\n",
       "  '.'],\n",
       " ['parades',\n",
       "  'bring',\n",
       "  'in',\n",
       "  'homophobic',\n",
       "  'people',\n",
       "  'that',\n",
       "  'bully',\n",
       "  'the',\n",
       "  'members',\n",
       "  'of',\n",
       "  'the',\n",
       "  'parade',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  \"n't\",\n",
       "  'ban',\n",
       "  'private_military',\n",
       "  'companies',\n",
       "  'as',\n",
       "  'they',\n",
       "  'are',\n",
       "  'doing',\n",
       "  'a',\n",
       "  'job',\n",
       "  'and',\n",
       "  'keeping',\n",
       "  'people',\n",
       "  'safe'],\n",
       " ['an',\n",
       "  'austerity_regime',\n",
       "  'is',\n",
       "  'the',\n",
       "  'most',\n",
       "  'effective',\n",
       "  'way',\n",
       "  'to',\n",
       "  'reduce',\n",
       "  'the',\n",
       "  'national',\n",
       "  'debt',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  \"n't\",\n",
       "  'abolish',\n",
       "  'the',\n",
       "  'three',\n",
       "  'strikes',\n",
       "  'law',\n",
       "  'because',\n",
       "  'it',\n",
       "  'is',\n",
       "  'necessary',\n",
       "  'to',\n",
       "  'ensure',\n",
       "  'society',\n",
       "  'understands',\n",
       "  'the',\n",
       "  'ramifications',\n",
       "  'of',\n",
       "  'repeated',\n",
       "  'ill',\n",
       "  'behavior',\n",
       "  '.',\n",
       "  'three',\n",
       "  'felonies',\n",
       "  'is',\n",
       "  'just',\n",
       "  'about',\n",
       "  'enough',\n",
       "  'as',\n",
       "  'far',\n",
       "  'as',\n",
       "  'i',\n",
       "  \"'m\",\n",
       "  'concerned',\n",
       "  '.'],\n",
       " ['zoos',\n",
       "  'bring',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'money',\n",
       "  'in',\n",
       "  'which',\n",
       "  'can',\n",
       "  'be',\n",
       "  'spent',\n",
       "  'on',\n",
       "  'animal',\n",
       "  'research',\n",
       "  'and',\n",
       "  'stop',\n",
       "  'their',\n",
       "  'extinction',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'place',\n",
       "  'any',\n",
       "  'restrictions',\n",
       "  'on',\n",
       "  'freedom',\n",
       "  'of',\n",
       "  'speech',\n",
       "  ',',\n",
       "  'many',\n",
       "  'of',\n",
       "  'the',\n",
       "  'restrictions',\n",
       "  'are',\n",
       "  'arbitrary',\n",
       "  'and',\n",
       "  'unnecessary',\n",
       "  'such',\n",
       "  'as',\n",
       "  'the',\n",
       "  '\"',\n",
       "  'gingerbread',\n",
       "  'man',\n",
       "  '\"',\n",
       "  'becoming',\n",
       "  'the',\n",
       "  '\"',\n",
       "  'gingerbread',\n",
       "  'person',\n",
       "  '\"'],\n",
       " ['the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'child_actors',\n",
       "  'exploits',\n",
       "  'a',\n",
       "  'child',\n",
       "  'and',\n",
       "  'can',\n",
       "  'have',\n",
       "  'negative',\n",
       "  'effects',\n",
       "  'on',\n",
       "  'them'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'abolish',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'and',\n",
       "  'bear_arms',\n",
       "  'because',\n",
       "  'it',\n",
       "  'is',\n",
       "  'a',\n",
       "  'constitutional',\n",
       "  'right',\n",
       "  'to',\n",
       "  'own',\n",
       "  'weapons',\n",
       "  'to',\n",
       "  'protect',\n",
       "  'ourselves',\n",
       "  '.'],\n",
       " ['telemarketing',\n",
       "  'is',\n",
       "  'annoying',\n",
       "  'for',\n",
       "  'people',\n",
       "  'as',\n",
       "  'they',\n",
       "  'do',\n",
       "  'not',\n",
       "  'request',\n",
       "  'a',\n",
       "  'phone',\n",
       "  'call',\n",
       "  'and',\n",
       "  'vunerable',\n",
       "  'people',\n",
       "  'such',\n",
       "  'as',\n",
       "  'the',\n",
       "  'elderly',\n",
       "  'often',\n",
       "  'feel',\n",
       "  'threatened',\n",
       "  'into',\n",
       "  'taking',\n",
       "  'part',\n",
       "  '.'],\n",
       " ['safe_spaces',\n",
       "  'allow',\n",
       "  'individuals',\n",
       "  'a',\n",
       "  'place',\n",
       "  'to',\n",
       "  'feel',\n",
       "  'comfortable',\n",
       "  'without',\n",
       "  'having',\n",
       "  'to',\n",
       "  'worry',\n",
       "  'about',\n",
       "  'feeling',\n",
       "  'judged',\n",
       "  'for',\n",
       "  'who',\n",
       "  'they',\n",
       "  'are',\n",
       "  'or',\n",
       "  'whom',\n",
       "  'they',\n",
       "  'love',\n",
       "  '.'],\n",
       " ['safe_spaces',\n",
       "  'equal',\n",
       "  'non',\n",
       "  '-',\n",
       "  'free',\n",
       "  'speech',\n",
       "  'spaces',\n",
       "  'and',\n",
       "  'that',\n",
       "  'is',\n",
       "  'against',\n",
       "  'the',\n",
       "  'law',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'definitely',\n",
       "  'oppose',\n",
       "  'collectivism',\n",
       "  'because',\n",
       "  'there',\n",
       "  'is',\n",
       "  'less',\n",
       "  'autonomy',\n",
       "  'in',\n",
       "  'terms',\n",
       "  'of',\n",
       "  'thoughts',\n",
       "  'and',\n",
       "  'ideas',\n",
       "  '.',\n",
       "  'everyone',\n",
       "  'will',\n",
       "  'just',\n",
       "  'go',\n",
       "  'along',\n",
       "  'with',\n",
       "  'the',\n",
       "  'group',\n",
       "  '.'],\n",
       " ['an',\n",
       "  'executive',\n",
       "  'has',\n",
       "  'worked',\n",
       "  'hard',\n",
       "  'to',\n",
       "  'get',\n",
       "  'to',\n",
       "  'that',\n",
       "  'position',\n",
       "  'through',\n",
       "  'study',\n",
       "  'and',\n",
       "  'prior',\n",
       "  'work',\n",
       "  'experience',\n",
       "  '.',\n",
       "  'they',\n",
       "  'should',\n",
       "  'be',\n",
       "  'compensated',\n",
       "  'for',\n",
       "  'their',\n",
       "  'value',\n",
       "  'to',\n",
       "  'the',\n",
       "  'company',\n",
       "  '.'],\n",
       " ['autonomous_cars',\n",
       "  'can',\n",
       "  'be',\n",
       "  'hacked',\n",
       "  'and',\n",
       "  'become',\n",
       "  'a',\n",
       "  'dangerous',\n",
       "  'weapon',\n",
       "  'for',\n",
       "  'evil',\n",
       "  'persons'],\n",
       " ['austerity',\n",
       "  'regimes',\n",
       "  'hurt',\n",
       "  'the',\n",
       "  'common',\n",
       "  'man',\n",
       "  'by',\n",
       "  'reducing',\n",
       "  'support',\n",
       "  'for',\n",
       "  'schools',\n",
       "  'and',\n",
       "  'health',\n",
       "  'care',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'legalize',\n",
       "  'prostitution',\n",
       "  'since',\n",
       "  'it',\n",
       "  'should',\n",
       "  'be',\n",
       "  'out',\n",
       "  'in',\n",
       "  'the',\n",
       "  'open',\n",
       "  '.',\n",
       "  'controlled',\n",
       "  'and',\n",
       "  'supervised-',\n",
       "  'instead',\n",
       "  'of',\n",
       "  'hidden',\n",
       "  '.',\n",
       "  'this',\n",
       "  'is',\n",
       "  'most',\n",
       "  'efficient',\n",
       "  'way',\n",
       "  'to',\n",
       "  'improve',\n",
       "  'sex',\n",
       "  'workers',\n",
       "  'conditions',\n",
       "  'and',\n",
       "  'pave',\n",
       "  'their',\n",
       "  'way',\n",
       "  'to',\n",
       "  'independence',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'possession',\n",
       "  'of',\n",
       "  'nuclear_weapons',\n",
       "  'is',\n",
       "  'illegal',\n",
       "  'under',\n",
       "  'international',\n",
       "  'humanitarian',\n",
       "  'law',\n",
       "  '.'],\n",
       " ['judicial_activism', 'undermines', 'the', 'rule', 'of', 'law'],\n",
       " ['collectivism',\n",
       "  'enables',\n",
       "  'communities',\n",
       "  'to',\n",
       "  'work',\n",
       "  'together',\n",
       "  'for',\n",
       "  'the',\n",
       "  'greater',\n",
       "  'good',\n",
       "  '.'],\n",
       " ['plastic',\n",
       "  'surgery',\n",
       "  'can',\n",
       "  'cause',\n",
       "  'many',\n",
       "  'complications',\n",
       "  'and',\n",
       "  'infections',\n",
       "  'and',\n",
       "  'does',\n",
       "  'not',\n",
       "  'address',\n",
       "  'the',\n",
       "  'underlying',\n",
       "  'self',\n",
       "  'esteem',\n",
       "  'issues',\n",
       "  'of',\n",
       "  'the',\n",
       "  'patient'],\n",
       " ['whaling',\n",
       "  'is',\n",
       "  'wiping',\n",
       "  'out',\n",
       "  'species',\n",
       "  'for',\n",
       "  'little',\n",
       "  'in',\n",
       "  'return',\n",
       "  '.'],\n",
       " ['people',\n",
       "  'should',\n",
       "  'be',\n",
       "  ' ',\n",
       "  'free',\n",
       "  'to',\n",
       "  'worship',\n",
       "  'who',\n",
       "  'they',\n",
       "  'want',\n",
       "  'religion',\n",
       "  'can',\n",
       "  'instill',\n",
       "  'good',\n",
       "  'values',\n",
       "  'and',\n",
       "  'morals',\n",
       "  'into',\n",
       "  'people'],\n",
       " ['subsidizing',\n",
       "  'journalism',\n",
       "  'could',\n",
       "  'raise',\n",
       "  'questions',\n",
       "  'about',\n",
       "  'bias',\n",
       "  'and',\n",
       "  'editorial',\n",
       "  'independence',\n",
       "  '.'],\n",
       " ['safe_spaces',\n",
       "  'are',\n",
       "  'necessary',\n",
       "  'so',\n",
       "  'that',\n",
       "  'traditionally',\n",
       "  'marginalised',\n",
       "  'groups',\n",
       "  'can',\n",
       "  'interact',\n",
       "  'freely',\n",
       "  'without',\n",
       "  'fear',\n",
       "  'of',\n",
       "  'harm',\n",
       "  'and',\n",
       "  'oppression',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'adopt',\n",
       "  'athiesm',\n",
       "  'because',\n",
       "  'no',\n",
       "  'religion',\n",
       "  'will',\n",
       "  'stop',\n",
       "  'lots',\n",
       "  'of',\n",
       "  'wars',\n",
       "  'and',\n",
       "  'arguements',\n",
       "  '.'],\n",
       " ['if',\n",
       "  'we',\n",
       "  'abolish',\n",
       "  'the',\n",
       "  'rights',\n",
       "  ',',\n",
       "  'then',\n",
       "  'companies',\n",
       "  'will',\n",
       "  'stop',\n",
       "  'developing',\n",
       "  'products',\n",
       "  'and',\n",
       "  'ideas',\n",
       "  'as',\n",
       "  'they',\n",
       "  'will',\n",
       "  'know',\n",
       "  'that',\n",
       "  'there',\n",
       "  'is',\n",
       "  'no',\n",
       "  'way',\n",
       "  'they',\n",
       "  'can',\n",
       "  'make',\n",
       "  'back',\n",
       "  'the',\n",
       "  'cost',\n",
       "  'of',\n",
       "  'r&d',\n",
       "  'and',\n",
       "  'so',\n",
       "  'will',\n",
       "  'run',\n",
       "  'at',\n",
       "  'losses'],\n",
       " ['three',\n",
       "  'strikes_laws',\n",
       "  'are',\n",
       "  'unnecessary',\n",
       "  'because',\n",
       "  'states',\n",
       "  'already',\n",
       "  'have',\n",
       "  'ways',\n",
       "  'of',\n",
       "  'punishing',\n",
       "  'recidivism',\n",
       "  'more',\n",
       "  'harshly',\n",
       "  '.'],\n",
       " ['space_exploration',\n",
       "  'does',\n",
       "  \"n't\",\n",
       "  'have',\n",
       "  'any',\n",
       "  'immediate',\n",
       "  'benefits',\n",
       "  'for',\n",
       "  'the',\n",
       "  'general',\n",
       "  'public'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'subsidize',\n",
       "  'wikipedia',\n",
       "  'because',\n",
       "  'wikipedia',\n",
       "  'helps',\n",
       "  'people',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'about',\n",
       "  'any',\n",
       "  'and',\n",
       "  'everything',\n",
       "  'they',\n",
       "  'want',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'about',\n",
       "  '.'],\n",
       " ['all',\n",
       "  'schools',\n",
       "  'should',\n",
       "  'adopt',\n",
       "  'a',\n",
       "  'zero',\n",
       "  '-',\n",
       "  'tolerance_policy',\n",
       "  'as',\n",
       "  'kids',\n",
       "  'need',\n",
       "  'to',\n",
       "  'know',\n",
       "  'they',\n",
       "  'can',\n",
       "  'not',\n",
       "  'act',\n",
       "  'inappropriately',\n",
       "  'at',\n",
       "  'any',\n",
       "  'given',\n",
       "  'moment',\n",
       "  'when',\n",
       "  'in',\n",
       "  'school',\n",
       "  '.'],\n",
       " ['a',\n",
       "  'multiparty',\n",
       "  'system',\n",
       "  'blurs',\n",
       "  'the',\n",
       "  'citizenship',\n",
       "  'of',\n",
       "  'a',\n",
       "  'vision',\n",
       "  'and',\n",
       "  'model',\n",
       "  'of',\n",
       "  'country',\n",
       "  '.',\n",
       "  'we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'adopt',\n",
       "  'a',\n",
       "  'multiparty',\n",
       "  'system',\n",
       "  'because',\n",
       "  'it',\n",
       "  'would',\n",
       "  'waste',\n",
       "  'valuable',\n",
       "  'time',\n",
       "  'to',\n",
       "  'agree'],\n",
       " ['if',\n",
       "  'capital_punishment',\n",
       "  'is',\n",
       "  'unfairly',\n",
       "  'applied',\n",
       "  'we',\n",
       "  'should',\n",
       "  'focus',\n",
       "  'on',\n",
       "  'fixing',\n",
       "  'that',\n",
       "  ',',\n",
       "  'not',\n",
       "  'abolishing',\n",
       "  'it',\n",
       "  'entirely',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'ban',\n",
       "  'cosmetic_surgery',\n",
       "  'because',\n",
       "  'it',\n",
       "  'could',\n",
       "  'help',\n",
       "  'a',\n",
       "  'disfigured',\n",
       "  'person',\n",
       "  'regain',\n",
       "  'confidence',\n",
       "  '.'],\n",
       " ['tax',\n",
       "  'payers',\n",
       "  'should',\n",
       "  \"n't\",\n",
       "  'have',\n",
       "  'to',\n",
       "  'pay',\n",
       "  'for',\n",
       "  'other',\n",
       "  'people',\n",
       "  'to',\n",
       "  'have',\n",
       "  'an',\n",
       "  'education',\n",
       "  'when',\n",
       "  'they',\n",
       "  'dint',\n",
       "  'get',\n",
       "  'the',\n",
       "  'same',\n",
       "  'chances',\n",
       "  '.'],\n",
       " ['in',\n",
       "  'the',\n",
       "  'interest',\n",
       "  'of',\n",
       "  'world',\n",
       "  'peace',\n",
       "  'we',\n",
       "  'should',\n",
       "  'adopt',\n",
       "  'atheism',\n",
       "  'and',\n",
       "  'would',\n",
       "  'then',\n",
       "  'avoid',\n",
       "  'religious',\n",
       "  'wars'],\n",
       " ['too',\n",
       "  'much',\n",
       "  'drugs',\n",
       "  'depend',\n",
       "  'on',\n",
       "  'the',\n",
       "  'availability',\n",
       "  'of',\n",
       "  'cannabis',\n",
       "  '.',\n",
       "  'legalizing',\n",
       "  'it',\n",
       "  'will',\n",
       "  'make',\n",
       "  'development',\n",
       "  'of',\n",
       "  'these',\n",
       "  'drugs',\n",
       "  'quicker'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'subsidize',\n",
       "  'journalism',\n",
       "  'because',\n",
       "  'it',\n",
       "  'is',\n",
       "  'a',\n",
       "  'poor',\n",
       "  'use',\n",
       "  'of',\n",
       "  'public',\n",
       "  'money',\n",
       "  'when',\n",
       "  'things',\n",
       "  'like',\n",
       "  'healthcare',\n",
       "  'and',\n",
       "  'education',\n",
       "  'are',\n",
       "  'short',\n",
       "  'of',\n",
       "  'funding'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'adopt',\n",
       "  'libertarianism',\n",
       "  'because',\n",
       "  'people',\n",
       "  \"'s\",\n",
       "  'lives',\n",
       "  'are',\n",
       "  'better',\n",
       "  'when',\n",
       "  'they',\n",
       "  'know',\n",
       "  'they',\n",
       "  'have',\n",
       "  'a',\n",
       "  'social',\n",
       "  'safety',\n",
       "  'net',\n",
       "  'to',\n",
       "  'fall',\n",
       "  'back',\n",
       "  'on',\n",
       "  ',',\n",
       "  'and',\n",
       "  'that',\n",
       "  'they',\n",
       "  'wo',\n",
       "  \"n't\",\n",
       "  'starve',\n",
       "  'if',\n",
       "  'they',\n",
       "  'lose',\n",
       "  'their',\n",
       "  'job',\n",
       "  '.'],\n",
       " ['subsidizing',\n",
       "  'journalism',\n",
       "  'would',\n",
       "  'bring',\n",
       "  'more',\n",
       "  'accurate',\n",
       "  'reporting',\n",
       "  'because',\n",
       "  'it',\n",
       "  'would',\n",
       "  'allow',\n",
       "  'for',\n",
       "  'the',\n",
       "  'hiring',\n",
       "  'of',\n",
       "  'more',\n",
       "  'qualified',\n",
       "  'reporters',\n",
       "  '.'],\n",
       " ['gun',\n",
       "  'violence',\n",
       "  'is',\n",
       "  'out',\n",
       "  'of',\n",
       "  'control',\n",
       "  'and',\n",
       "  'the',\n",
       "  'only',\n",
       "  'solution',\n",
       "  'is',\n",
       "  'to',\n",
       "  'take',\n",
       "  'away',\n",
       "  'guns'],\n",
       " ['the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'and',\n",
       "  'bear_arms',\n",
       "  'is',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'tenets',\n",
       "  'of',\n",
       "  'our',\n",
       "  'country'],\n",
       " ['missionary_work', 'is', 'risky', 'to', 'participate', 'in', '.'],\n",
       " ['whale',\n",
       "  'meat',\n",
       "  'has',\n",
       "  'high',\n",
       "  'levels',\n",
       "  'of',\n",
       "  'mercury',\n",
       "  'and',\n",
       "  'is',\n",
       "  'unhealthy',\n",
       "  'as',\n",
       "  'part',\n",
       "  'of',\n",
       "  'a',\n",
       "  'diet',\n",
       "  '.'],\n",
       " ['zero',\n",
       "  'tolerance',\n",
       "  'sets',\n",
       "  'a',\n",
       "  'clear',\n",
       "  'and',\n",
       "  'specific',\n",
       "  'guideline',\n",
       "  'for',\n",
       "  'all',\n",
       "  'to',\n",
       "  'adhere',\n",
       "  'to'],\n",
       " ['a',\n",
       "  'three',\n",
       "  '-',\n",
       "  'strikes',\n",
       "  'system',\n",
       "  'does',\n",
       "  'not',\n",
       "  'allow',\n",
       "  'for',\n",
       "  'people',\n",
       "  'to',\n",
       "  'be',\n",
       "  'treated',\n",
       "  'fairly',\n",
       "  'as',\n",
       "  'individuals',\n",
       "  'and',\n",
       "  'instead',\n",
       "  'is',\n",
       "  'used',\n",
       "  'as',\n",
       "  'a',\n",
       "  '\"',\n",
       "  'one',\n",
       "  '-',\n",
       "  'size',\n",
       "  '-',\n",
       "  'fits',\n",
       "  '-',\n",
       "  'all',\n",
       "  '\"',\n",
       "  'control',\n",
       "  'method',\n",
       "  'for',\n",
       "  'minority',\n",
       "  'populations',\n",
       "  '.'],\n",
       " ['it', 'could', 'become', 'partial', 'to', 'whoever', 'pays'],\n",
       " ['targeted_killing',\n",
       "  'may',\n",
       "  'help',\n",
       "  'avoiding',\n",
       "  'terrorists',\n",
       "  'attacks',\n",
       "  'and',\n",
       "  'is',\n",
       "  'a',\n",
       "  'very',\n",
       "  'useful',\n",
       "  'thing'],\n",
       " ['three',\n",
       "  'strikes_laws',\n",
       "  'reduce',\n",
       "  'the',\n",
       "  'power',\n",
       "  'of',\n",
       "  'judges',\n",
       "  'and',\n",
       "  'discretion',\n",
       "  'in',\n",
       "  'the',\n",
       "  'court',\n",
       "  'room',\n",
       "  ',',\n",
       "  'making',\n",
       "  'judgments',\n",
       "  'shallower',\n",
       "  '.'],\n",
       " ['economic_sanctions',\n",
       "  'can',\n",
       "  'help',\n",
       "  'force',\n",
       "  'countries',\n",
       "  'to',\n",
       "  'provide',\n",
       "  'better',\n",
       "  'treatment',\n",
       "  'for',\n",
       "  'the',\n",
       "  'common',\n",
       "  'people',\n",
       "  'of',\n",
       "  'that',\n",
       "  'country',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'three',\n",
       "  'strike',\n",
       "  'law',\n",
       "  'prohibits',\n",
       "  'reform',\n",
       "  'of',\n",
       "  'offenders',\n",
       "  '.'],\n",
       " ['embryonic_stem',\n",
       "  'cell_research',\n",
       "  ' ',\n",
       "  'can',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'new',\n",
       "  'cures',\n",
       "  'for',\n",
       "  'diseases',\n",
       "  '.'],\n",
       " ['space',\n",
       "  'travel',\n",
       "  'has',\n",
       "  'health',\n",
       "  'dangers',\n",
       "  '.',\n",
       "  'astronauts',\n",
       "  'and',\n",
       "  'space',\n",
       "  'tourists',\n",
       "  'face',\n",
       "  'risks',\n",
       "  'from',\n",
       "  'radiation',\n",
       "  ',',\n",
       "  'which',\n",
       "  'can',\n",
       "  'cause',\n",
       "  'illness',\n",
       "  'and',\n",
       "  'injure',\n",
       "  'organs',\n",
       "  '.'],\n",
       " ['economic_sanctions', 'can', 'help', 'control', 'financial', 'situations'],\n",
       " ['libertarianism',\n",
       "  'would',\n",
       "  'be',\n",
       "  'a',\n",
       "  'huge',\n",
       "  'mistake',\n",
       "  ',',\n",
       "  'especially',\n",
       "  'for',\n",
       "  'the',\n",
       "  'poor',\n",
       "  'in',\n",
       "  'our',\n",
       "  'nation',\n",
       "  '.'],\n",
       " ['prayer',\n",
       "  'is',\n",
       "  'a',\n",
       "  'personal',\n",
       "  'choice',\n",
       "  '.',\n",
       "  'enforcing',\n",
       "  'school',\n",
       "  'prayer',\n",
       "  'may',\n",
       "  'expose',\n",
       "  'students',\n",
       "  'to',\n",
       "  'ideas',\n",
       "  'they',\n",
       "  'are',\n",
       "  'not',\n",
       "  'comfortable',\n",
       "  'with',\n",
       "  '.'],\n",
       " ['three',\n",
       "  'strikes_laws',\n",
       "  'destroy',\n",
       "  'families',\n",
       "  'by',\n",
       "  'taking',\n",
       "  'away',\n",
       "  'parents',\n",
       "  'and',\n",
       "  'children',\n",
       "  'for',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'their',\n",
       "  'lives',\n",
       "  'with',\n",
       "  'no',\n",
       "  'chance',\n",
       "  'of',\n",
       "  'parole',\n",
       "  '.'],\n",
       " ['economic_sanctions',\n",
       "  'do',\n",
       "  'help',\n",
       "  'western',\n",
       "  'countries',\n",
       "  'to',\n",
       "  ' ',\n",
       "  'avoid',\n",
       "  'the',\n",
       "  'spread',\n",
       "  'of',\n",
       "  'terrorism',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'countries',\n",
       "  'regular',\n",
       "  'citizens',\n",
       "  'are',\n",
       "  'the',\n",
       "  'ones',\n",
       "  'who',\n",
       "  'are',\n",
       "  'hurt',\n",
       "  'the',\n",
       "  'most',\n",
       "  'by',\n",
       "  'sanctions',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'ban',\n",
       "  'missionary_work',\n",
       "  'because',\n",
       "  'if',\n",
       "  'people',\n",
       "  'want',\n",
       "  'to',\n",
       "  'help',\n",
       "  'out',\n",
       "  'others',\n",
       "  'that',\n",
       "  'is',\n",
       "  'their',\n",
       "  'business',\n",
       "  'and',\n",
       "  'no',\n",
       "  'one',\n",
       "  'elses'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'ban',\n",
       "  'the',\n",
       "  'church',\n",
       "  'of',\n",
       "  'scientology',\n",
       "  'as',\n",
       "  'many',\n",
       "  'ex',\n",
       "  '-',\n",
       "  'members',\n",
       "  'report',\n",
       "  'manipulation',\n",
       "  'and',\n",
       "  'bullying',\n",
       "  'and',\n",
       "  'it',\n",
       "  'has',\n",
       "  'been',\n",
       "  'reported',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  'cult',\n",
       "  'which',\n",
       "  'has',\n",
       "  'seperated',\n",
       "  'families',\n",
       "  '.'],\n",
       " ['telemarketing',\n",
       "  'is',\n",
       "  'a',\n",
       "  'job',\n",
       "  'for',\n",
       "  'some',\n",
       "  'and',\n",
       "  'banning',\n",
       "  'it',\n",
       "  'would',\n",
       "  'take',\n",
       "  'jobs',\n",
       "  'away',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'subsidize',\n",
       "  'space_exploration',\n",
       "  'because',\n",
       "  'someday',\n",
       "  'we',\n",
       "  'may',\n",
       "  'have',\n",
       "  'to',\n",
       "  'leave',\n",
       "  'earth',\n",
       "  'behind',\n",
       "  'once',\n",
       "  'we',\n",
       "  'deplete',\n",
       "  'all',\n",
       "  'our',\n",
       "  'resources',\n",
       "  'or',\n",
       "  'because',\n",
       "  'of',\n",
       "  'a',\n",
       "  'nuclear',\n",
       "  'war',\n",
       "  '.'],\n",
       " ['compulsory_voting',\n",
       "  'ensures',\n",
       "  'that',\n",
       "  'our',\n",
       "  'leaders',\n",
       "  'reflect',\n",
       "  'the',\n",
       "  'will',\n",
       "  'of',\n",
       "  'all',\n",
       "  'people',\n",
       "  ',',\n",
       "  'not',\n",
       "  'just',\n",
       "  'those',\n",
       "  'who',\n",
       "  'were',\n",
       "  'able',\n",
       "  '/',\n",
       "  'motivated',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'make',\n",
       "  'it',\n",
       "  'to',\n",
       "  'the',\n",
       "  'polls',\n",
       "  '.'],\n",
       " ['if',\n",
       "  'parents',\n",
       "  'agree',\n",
       "  'for',\n",
       "  'their',\n",
       "  'kids',\n",
       "  'to',\n",
       "  'do',\n",
       "  'acting',\n",
       "  ',',\n",
       "  'i',\n",
       "  'can`t',\n",
       "  'see',\n",
       "  'any',\n",
       "  'problem',\n",
       "  'with',\n",
       "  'it',\n",
       "  '.'],\n",
       " ['there',\n",
       "  'is',\n",
       "  'nothing',\n",
       "  'that',\n",
       "  'can',\n",
       "  'come',\n",
       "  'from',\n",
       "  'space',\n",
       "  'research',\n",
       "  'that',\n",
       "  'will',\n",
       "  'help',\n",
       "  'the',\n",
       "  'country',\n",
       "  'so',\n",
       "  'why',\n",
       "  'waste',\n",
       "  'so',\n",
       "  'much',\n",
       "  'money',\n",
       "  '?'],\n",
       " ['the',\n",
       "  'school',\n",
       "  'uniform',\n",
       "  'generates',\n",
       "  'in',\n",
       "  'the',\n",
       "  'student',\n",
       "  'respect',\n",
       "  'and',\n",
       "  'adherence',\n",
       "  'to',\n",
       "  'the',\n",
       "  'rules',\n",
       "  '.',\n",
       "  'eliminating',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'school',\n",
       "  'uniform',\n",
       "  'goes',\n",
       "  'against',\n",
       "  'the',\n",
       "  'establishment',\n",
       "  'of',\n",
       "  'routine',\n",
       "  'and',\n",
       "  'responsibility',\n",
       "  'towards',\n",
       "  'the',\n",
       "  'institution'],\n",
       " ['minors',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'allowed',\n",
       "  'to',\n",
       "  'have',\n",
       "  'an',\n",
       "  'elective',\n",
       "  'cosmetic_surgery',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'their',\n",
       "  'bodies',\n",
       "  'are',\n",
       "  'still',\n",
       "  'growing',\n",
       "  'and',\n",
       "  'changing',\n",
       "  'and',\n",
       "  'should',\n",
       "  'be',\n",
       "  'allowed',\n",
       "  'to',\n",
       "  'mature',\n",
       "  'before',\n",
       "  'going',\n",
       "  'under',\n",
       "  'the',\n",
       "  'knife',\n",
       "  '.'],\n",
       " ['algirithmic',\n",
       "  'trading',\n",
       "  'reduces',\n",
       "  'the',\n",
       "  'possibilty',\n",
       "  'of',\n",
       "  'error',\n",
       "  'and',\n",
       "  'just',\n",
       "  'furthers',\n",
       "  'profit',\n",
       "  'for',\n",
       "  'finance',\n",
       "  'companies'],\n",
       " ['pride_parades',\n",
       "  'can',\n",
       "  'cause',\n",
       "  'increased',\n",
       "  'tensions',\n",
       "  'which',\n",
       "  'requires',\n",
       "  'more',\n",
       "  'police',\n",
       "  'protection',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'this',\n",
       "  'can',\n",
       "  'also',\n",
       "  'cause',\n",
       "  'fighting',\n",
       "  'to',\n",
       "  'break',\n",
       "  'out',\n",
       "  '.'],\n",
       " ['this',\n",
       "  'is',\n",
       "  'absolutely',\n",
       "  'something',\n",
       "  'we',\n",
       "  'should',\n",
       "  'ban',\n",
       "  'because',\n",
       "  'children',\n",
       "  'should',\n",
       "  \"n't\",\n",
       "  'be',\n",
       "  'encouraged',\n",
       "  'to',\n",
       "  'be',\n",
       "  'dissatisfied',\n",
       "  'with',\n",
       "  'their',\n",
       "  'bodies'],\n",
       " ['working',\n",
       "  'together',\n",
       "  'for',\n",
       "  'a',\n",
       "  'greater',\n",
       "  'good',\n",
       "  'favouring',\n",
       "  'the',\n",
       "  'less',\n",
       "  'well',\n",
       "  'off',\n",
       "  'and',\n",
       "  'giving',\n",
       "  'freedom',\n",
       "  'of',\n",
       "  'choice',\n",
       "  'can',\n",
       "  'only',\n",
       "  'benefit',\n",
       "  'society',\n",
       "  'as',\n",
       "  'a',\n",
       "  'whole',\n",
       "  '.'],\n",
       " ['prayer',\n",
       "  'in',\n",
       "  'school',\n",
       "  'should',\n",
       "  'be',\n",
       "  'prohibited',\n",
       "  'because',\n",
       "  'it',\n",
       "  'violates',\n",
       "  'the',\n",
       "  'separation',\n",
       "  'of',\n",
       "  'prayer',\n",
       "  'and',\n",
       "  'state'],\n",
       " ['autonomous_cars',\n",
       "  'leave',\n",
       "  'both',\n",
       "  'passengers',\n",
       "  'and',\n",
       "  'pedestrians',\n",
       "  'vulnerable',\n",
       "  'to',\n",
       "  'malicious',\n",
       "  'hacking',\n",
       "  'which',\n",
       "  'could',\n",
       "  'cause',\n",
       "  'wide',\n",
       "  'scale',\n",
       "  'destruction',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'end',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'economic_sanctions',\n",
       "  'because',\n",
       "  'it',\n",
       "  'causes',\n",
       "  'more',\n",
       "  'conflict',\n",
       "  '.'],\n",
       " ['school',\n",
       "  'prayer',\n",
       "  'encourages',\n",
       "  'children',\n",
       "  'to',\n",
       "  'be',\n",
       "  'open',\n",
       "  'minded',\n",
       "  'and',\n",
       "  'learn',\n",
       "  'about',\n",
       "  'other',\n",
       "  'cultures',\n",
       "  'and',\n",
       "  'religions'],\n",
       " ['uniforms',\n",
       "  'allow',\n",
       "  'students',\n",
       "  'to',\n",
       "  'look',\n",
       "  'the',\n",
       "  'same',\n",
       "  'and',\n",
       "  'not',\n",
       "  'have',\n",
       "  'to',\n",
       "  'follow',\n",
       "  'the',\n",
       "  'fashion',\n",
       "  'while',\n",
       "  'at',\n",
       "  'school'],\n",
       " ['adopting',\n",
       "  'atheism',\n",
       "  'takes',\n",
       "  'away',\n",
       "  'the',\n",
       "  'freedom',\n",
       "  'of',\n",
       "  'worship',\n",
       "  'that',\n",
       "  'people',\n",
       "  'are',\n",
       "  'promised',\n",
       "  'in',\n",
       "  'this',\n",
       "  'country',\n",
       "  '.'],\n",
       " ['pride_parades',\n",
       "  'allow',\n",
       "  'marginalized',\n",
       "  'groups',\n",
       "  'to',\n",
       "  'have',\n",
       "  'a',\n",
       "  'space',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'gather',\n",
       "  'and',\n",
       "  'celebrate',\n",
       "  'and',\n",
       "  'boost',\n",
       "  'their',\n",
       "  'self',\n",
       "  '-',\n",
       "  'esteem',\n",
       "  '.'],\n",
       " ['very',\n",
       "  'often',\n",
       "  'prostitutes',\n",
       "  'are',\n",
       "  'the',\n",
       "  'most',\n",
       "  'vulnerable',\n",
       "  'in',\n",
       "  'society',\n",
       "  'and',\n",
       "  'have',\n",
       "  'drug',\n",
       "  'and',\n",
       "  'alcohol',\n",
       "  'problems',\n",
       "  '.',\n",
       "  'they',\n",
       "  'need',\n",
       "  'to',\n",
       "  'be',\n",
       "  'properly',\n",
       "  'protected',\n",
       "  '.'],\n",
       " ['if',\n",
       "  'an',\n",
       "  'individual',\n",
       "  'has',\n",
       "  'created',\n",
       "  'any',\n",
       "  'property',\n",
       "  'it',\n",
       "  'is',\n",
       "  'his',\n",
       "  'to',\n",
       "  'determine',\n",
       "  'it',\n",
       "  \"'s\",\n",
       "  'use'],\n",
       " ['legal', 'organ_trade', 'would', 'help', 'prevent', 'wait', 'lists'],\n",
       " ['the',\n",
       "  'true',\n",
       "  'purposes',\n",
       "  'of',\n",
       "  'telemarketing',\n",
       "  'are',\n",
       "  'to',\n",
       "  'pressure',\n",
       "  'feeble',\n",
       "  '-',\n",
       "  'minded',\n",
       "  'people',\n",
       "  'into',\n",
       "  'buying',\n",
       "  'things',\n",
       "  'they',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'really',\n",
       "  'want',\n",
       "  ',',\n",
       "  'and',\n",
       "  'to',\n",
       "  'make',\n",
       "  'it',\n",
       "  'easier',\n",
       "  'to',\n",
       "  'get',\n",
       "  'away',\n",
       "  'with',\n",
       "  'fraud'],\n",
       " ['legalising',\n",
       "  'prostitution',\n",
       "  'can',\n",
       "  'only',\n",
       "  'be',\n",
       "  'beneficial',\n",
       "  'to',\n",
       "  'the',\n",
       "  'sex',\n",
       "  'workers',\n",
       "  'and',\n",
       "  'their',\n",
       "  'clients',\n",
       "  'from',\n",
       "  'a',\n",
       "  'safety',\n",
       "  'and',\n",
       "  'health',\n",
       "  'point',\n",
       "  'of',\n",
       "  'view',\n",
       "  '.'],\n",
       " ['more', 'voters', 'would', 'boost', 'voter', 'turnout', '.'],\n",
       " ['if',\n",
       "  'a',\n",
       "  'person',\n",
       "  'wants',\n",
       "  'to',\n",
       "  'continue',\n",
       "  'working',\n",
       "  ',',\n",
       "  'that',\n",
       "  'is',\n",
       "  'their',\n",
       "  'right',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'they',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'forced',\n",
       "  'to',\n",
       "  'stop',\n",
       "  'based',\n",
       "  'on',\n",
       "  'some',\n",
       "  'arbitrary',\n",
       "  'rule',\n",
       "  'made',\n",
       "  'up',\n",
       "  'by',\n",
       "  'someone',\n",
       "  '.'],\n",
       " ['being',\n",
       "  'a',\n",
       "  'citizen',\n",
       "  'of',\n",
       "  'your',\n",
       "  'country',\n",
       "  'requires',\n",
       "  'you',\n",
       "  'to',\n",
       "  'have',\n",
       "  'at',\n",
       "  'least',\n",
       "  'some',\n",
       "  'duty',\n",
       "  'to',\n",
       "  'the',\n",
       "  'nation',\n",
       "  '.'],\n",
       " ['legalizing',\n",
       "  'prostitution',\n",
       "  'could',\n",
       "  'allow',\n",
       "  'for',\n",
       "  'regulations',\n",
       "  'that',\n",
       "  'make',\n",
       "  'prostitutes',\n",
       "  'and',\n",
       "  'the',\n",
       "  'people',\n",
       "  'that',\n",
       "  'use',\n",
       "  'their',\n",
       "  'services',\n",
       "  'safer',\n",
       "  'and',\n",
       "  'healthier',\n",
       "  '.'],\n",
       " ['citizens',\n",
       "  'should',\n",
       "  'be',\n",
       "  'allowed',\n",
       "  'to',\n",
       "  'defend',\n",
       "  'themselves',\n",
       "  'with',\n",
       "  'lethal',\n",
       "  'force',\n",
       "  'in',\n",
       "  'a',\n",
       "  'life',\n",
       "  '-',\n",
       "  'or',\n",
       "  '-',\n",
       "  'death',\n",
       "  'situation',\n",
       "  'because',\n",
       "  'the',\n",
       "  'police',\n",
       "  'are',\n",
       "  'typically',\n",
       "  'slow',\n",
       "  'to',\n",
       "  'respond',\n",
       "  'to',\n",
       "  'such',\n",
       "  'situations',\n",
       "  '.'],\n",
       " ['child_actors',\n",
       "  'are',\n",
       "  'necessary',\n",
       "  'and',\n",
       "  'children',\n",
       "  'can',\n",
       "  'learn',\n",
       "  'how',\n",
       "  'to',\n",
       "  'work',\n",
       "  'even',\n",
       "  'from',\n",
       "  'an',\n",
       "  'early',\n",
       "  'age'],\n",
       " ['companies',\n",
       "  'should',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'pay',\n",
       "  'as',\n",
       "  'much',\n",
       "  'as',\n",
       "  'they',\n",
       "  'like',\n",
       "  'as',\n",
       "  'long',\n",
       "  'as',\n",
       "  'it',\n",
       "  \"'s\",\n",
       "  'above',\n",
       "  'minimum',\n",
       "  'wahe'],\n",
       " ['student_loans',\n",
       "  'should',\n",
       "  'be',\n",
       "  'subsidized',\n",
       "  'as',\n",
       "  'this',\n",
       "  'allows',\n",
       "  'those',\n",
       "  'from',\n",
       "  'marginalized',\n",
       "  'or',\n",
       "  'poorer',\n",
       "  'sections',\n",
       "  'of',\n",
       "  'society',\n",
       "  'to',\n",
       "  'access',\n",
       "  'good',\n",
       "  'education'],\n",
       " ['legalizing',\n",
       "  'prostitution',\n",
       "  'can',\n",
       "  'many',\n",
       "  'women',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'children',\n",
       "  'vulnerable',\n",
       "  'to',\n",
       "  'the',\n",
       "  'dangerous',\n",
       "  'and',\n",
       "  'immoral',\n",
       "  'legal',\n",
       "  'acceptance',\n",
       "  'of',\n",
       "  'prostitution',\n",
       "  '.'],\n",
       " ['cosmetic_surgery',\n",
       "  'makes',\n",
       "  'people',\n",
       "  'feel',\n",
       "  'self',\n",
       "  '-',\n",
       "  'conscious',\n",
       "  'about',\n",
       "  'themselves',\n",
       "  ',',\n",
       "  'providing',\n",
       "  'false',\n",
       "  'imagery',\n",
       "  'of',\n",
       "  'natural',\n",
       "  'beauty'],\n",
       " ['people',\n",
       "  'should',\n",
       "  'receive',\n",
       "  'benefits',\n",
       "  'for',\n",
       "  'achieving',\n",
       "  'higher',\n",
       "  'goals',\n",
       "  'and',\n",
       "  'executives',\n",
       "  'should',\n",
       "  'also',\n",
       "  'receive',\n",
       "  'those',\n",
       "  'compensations',\n",
       "  '.'],\n",
       " ['zoos',\n",
       "  'maintain',\n",
       "  'animals',\n",
       "  'in',\n",
       "  'unnatural',\n",
       "  ',',\n",
       "  'cramped',\n",
       "  'conditions',\n",
       "  '-',\n",
       "  'they',\n",
       "  'are',\n",
       "  'exploited',\n",
       "  'for',\n",
       "  'the',\n",
       "  'benefit',\n",
       "  'of',\n",
       "  'a',\n",
       "  'paying',\n",
       "  'public',\n",
       "  ',',\n",
       "  'with',\n",
       "  'little',\n",
       "  'concern',\n",
       "  'about',\n",
       "  'their',\n",
       "  'happiness',\n",
       "  'of',\n",
       "  'welfare',\n",
       "  '.'],\n",
       " ['since',\n",
       "  'intellectual_property',\n",
       "  'is',\n",
       "  'such',\n",
       "  'covers',\n",
       "  'such',\n",
       "  'a',\n",
       "  'broad',\n",
       "  'spectrum',\n",
       "  ',',\n",
       "  'it',\n",
       "  'is',\n",
       "  'difficult',\n",
       "  'to',\n",
       "  'prove',\n",
       "  'that',\n",
       "  'rights',\n",
       "  'have',\n",
       "  'been',\n",
       "  'infringed',\n",
       "  'leading',\n",
       "  'to',\n",
       "  'lengthy',\n",
       "  'legal',\n",
       "  'cases',\n",
       "  'and',\n",
       "  'should',\n",
       "  ',',\n",
       "  'therefore',\n",
       "  'be',\n",
       "  'abolished',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'would',\n",
       "  'make',\n",
       "  'people',\n",
       "  'who',\n",
       "  'are',\n",
       "  'gender',\n",
       "  'challenged',\n",
       "  'feel',\n",
       "  'better',\n",
       "  '.'],\n",
       " ['everyone',\n",
       "  'should',\n",
       "  'have',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'and',\n",
       "  'bear_arms',\n",
       "  'for',\n",
       "  'protection'],\n",
       " ['embryonic_stem',\n",
       "  'cell_research',\n",
       "  'is',\n",
       "  'an',\n",
       "  'advanced',\n",
       "  'medicine',\n",
       "  'progress',\n",
       "  'that',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'stopped'],\n",
       " ['human_cloning',\n",
       "  'can',\n",
       "  'provide',\n",
       "  'a',\n",
       "  'way',\n",
       "  'for',\n",
       "  'science',\n",
       "  'to',\n",
       "  'overcome',\n",
       "  'negative',\n",
       "  'qualities',\n",
       "  'in',\n",
       "  'humans',\n",
       "  ',',\n",
       "  'such',\n",
       "  'as',\n",
       "  'birth',\n",
       "  'defects',\n",
       "  ',',\n",
       "  'so',\n",
       "  'overall',\n",
       "  'it',\n",
       "  'is',\n",
       "  'a',\n",
       "  'positive',\n",
       "  'technology',\n",
       "  'that',\n",
       "  'should',\n",
       "  'be',\n",
       "  'allowed',\n",
       "  'to',\n",
       "  'flourish',\n",
       "  '.'],\n",
       " ['tywo',\n",
       "  'party',\n",
       "  'systems',\n",
       "  'no',\n",
       "  'longer',\n",
       "  'reflect',\n",
       "  'the',\n",
       "  'growing',\n",
       "  'diversity',\n",
       "  'of',\n",
       "  'political',\n",
       "  'views',\n",
       "  ',',\n",
       "  'only',\n",
       "  'a',\n",
       "  'multi',\n",
       "  'party_system',\n",
       "  'can',\n",
       "  'do',\n",
       "  'this',\n",
       "  '.'],\n",
       " ['scientology',\n",
       "  'is',\n",
       "  'just',\n",
       "  'a',\n",
       "  'business',\n",
       "  'that',\n",
       "  'is',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'scam',\n",
       "  'people',\n",
       "  'out',\n",
       "  'of',\n",
       "  'money',\n",
       "  '.'],\n",
       " ['killing',\n",
       "  'someone',\n",
       "  'is',\n",
       "  'never',\n",
       "  'okay',\n",
       "  'even',\n",
       "  'if',\n",
       "  'they',\n",
       "  'are',\n",
       "  'a',\n",
       "  'killer',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  ' ',\n",
       "  'fund',\n",
       "  'journalism',\n",
       "  'to',\n",
       "  'serve',\n",
       "  'the',\n",
       "  'public',\n",
       "  'interest',\n",
       "  '.'],\n",
       " ['without',\n",
       "  'intellection',\n",
       "  'property_rights',\n",
       "  'there',\n",
       "  'is',\n",
       "  'no',\n",
       "  'incentive',\n",
       "  'to',\n",
       "  'research',\n",
       "  'and',\n",
       "  'develop',\n",
       "  'new',\n",
       "  'products'],\n",
       " ['telemarketing',\n",
       "  'can',\n",
       "  'harm',\n",
       "  'vulnerable',\n",
       "  'people',\n",
       "  'who',\n",
       "  'are',\n",
       "  'less',\n",
       "  'able',\n",
       "  'to',\n",
       "  'say',\n",
       "  'no',\n",
       "  '.'],\n",
       " ['targeted_killing',\n",
       "  'is',\n",
       "  'often',\n",
       "  'the',\n",
       "  'only',\n",
       "  'way',\n",
       "  'to',\n",
       "  'get',\n",
       "  'to',\n",
       "  'the',\n",
       "  'enemy',\n",
       "  '.'],\n",
       " ['whaling',\n",
       "  'is',\n",
       "  'an',\n",
       "  'important',\n",
       "  'cultural',\n",
       "  'tradition',\n",
       "  'in',\n",
       "  'countries',\n",
       "  'such',\n",
       "  'as',\n",
       "  'japan',\n",
       "  ';',\n",
       "  'therefore',\n",
       "  'we',\n",
       "  'should',\n",
       "  'allow',\n",
       "  'it',\n",
       "  'to',\n",
       "  'continue',\n",
       "  '.'],\n",
       " ['targeted_killing',\n",
       "  'can',\n",
       "  'be',\n",
       "  'misused',\n",
       "  'by',\n",
       "  'a',\n",
       "  'despotic',\n",
       "  'regime',\n",
       "  ';',\n",
       "  'it',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned',\n",
       "  '.'],\n",
       " ['subsidizing',\n",
       "  'wikipedia',\n",
       "  'will',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'bias',\n",
       "  'in',\n",
       "  'the',\n",
       "  'contents',\n",
       "  '.',\n",
       "  'content',\n",
       "  'creators',\n",
       "  'and',\n",
       "  'moderators',\n",
       "  'will',\n",
       "  'be',\n",
       "  'afraid',\n",
       "  'to',\n",
       "  'criticize',\n",
       "  'the',\n",
       "  'people',\n",
       "  'who',\n",
       "  'contribute',\n",
       "  'money',\n",
       "  'to',\n",
       "  'wikipedia'],\n",
       " ['factory_farming',\n",
       "  'is',\n",
       "  'needed',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'feed',\n",
       "  'our',\n",
       "  'ever',\n",
       "  'increasing',\n",
       "  'population',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'and',\n",
       "  'bear_arms',\n",
       "  'should',\n",
       "  'be',\n",
       "  'abolished',\n",
       "  'because',\n",
       "  'countries',\n",
       "  'with',\n",
       "  'strict',\n",
       "  'gun',\n",
       "  'control',\n",
       "  'are',\n",
       "  'far',\n",
       "  'safer',\n",
       "  'because',\n",
       "  'they',\n",
       "  'have',\n",
       "  'far',\n",
       "  'fewer',\n",
       "  'incidents',\n",
       "  'of',\n",
       "  'violent',\n",
       "  'gun',\n",
       "  'crime'],\n",
       " ['fast_food',\n",
       "  'should',\n",
       "  \"n't\",\n",
       "  'be',\n",
       "  'banned',\n",
       "  'because',\n",
       "  'it',\n",
       "  'helps',\n",
       "  'people',\n",
       "  'save',\n",
       "  'times'],\n",
       " ['sex_selection',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'legalized',\n",
       "  'as',\n",
       "  'it',\n",
       "  'is',\n",
       "  'unethical'],\n",
       " ['missionaries',\n",
       "  'try',\n",
       "  'to',\n",
       "  'force',\n",
       "  'their',\n",
       "  'religion',\n",
       "  'or',\n",
       "  'ideas',\n",
       "  'on',\n",
       "  'people',\n",
       "  'that',\n",
       "  'are',\n",
       "  'already',\n",
       "  'happy',\n",
       "  'the',\n",
       "  'way',\n",
       "  'they',\n",
       "  'are',\n",
       "  '.'],\n",
       " ['space_exploration',\n",
       "  'has',\n",
       "  'the',\n",
       "  'ability',\n",
       "  'to',\n",
       "  'solve',\n",
       "  'the',\n",
       "  'problem',\n",
       "  'of',\n",
       "  'limited',\n",
       "  'materials',\n",
       "  'on',\n",
       "  'earth'],\n",
       " ['the',\n",
       "  'government',\n",
       "  'must',\n",
       "  'use',\n",
       "  'least',\n",
       "  'restrictive',\n",
       "  'means',\n",
       "  'to',\n",
       "  'avoid',\n",
       "  'encroaching',\n",
       "  'on',\n",
       "  'people',\n",
       "  \"'s\",\n",
       "  'freedoms',\n",
       "  '.',\n",
       "  'as',\n",
       "  'such',\n",
       "  'they',\n",
       "  'should',\n",
       "  'educate',\n",
       "  'and',\n",
       "  'regulate',\n",
       "  'cosmetic_surgery',\n",
       "  'for',\n",
       "  'minors',\n",
       "  'instead',\n",
       "  'of',\n",
       "  'banning',\n",
       "  'it',\n",
       "  '.'],\n",
       " ['compulsory_voting',\n",
       "  'will',\n",
       "  'eliminate',\n",
       "  'voter',\n",
       "  'suppression',\n",
       "  'which',\n",
       "  'is',\n",
       "  'a',\n",
       "  'big',\n",
       "  'problem',\n",
       "  'in',\n",
       "  'this',\n",
       "  'country'],\n",
       " ['adopting',\n",
       "  'libertarianism',\n",
       "  'would',\n",
       "  'eliminate',\n",
       "  'many',\n",
       "  'social',\n",
       "  'programs',\n",
       "  ',',\n",
       "  'reducing',\n",
       "  'access',\n",
       "  't',\n",
       "  'food',\n",
       "  'and',\n",
       "  'health',\n",
       "  'care',\n",
       "  'to',\n",
       "  'those',\n",
       "  'in',\n",
       "  'need'],\n",
       " ['legalizing',\n",
       "  'the',\n",
       "  'organ_trade',\n",
       "  'would',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'people',\n",
       "  'forcing',\n",
       "  'or',\n",
       "  'coercing',\n",
       "  'other',\n",
       "  'into',\n",
       "  'giving',\n",
       "  'their',\n",
       "  'organs',\n",
       "  '.',\n",
       "  'this',\n",
       "  'would',\n",
       "  'increase',\n",
       "  'death',\n",
       "  'and',\n",
       "  'suffering',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'ban',\n",
       "  'the',\n",
       "  'church',\n",
       "  'of',\n",
       "  'scientology',\n",
       "  'because',\n",
       "  'in',\n",
       "  'this',\n",
       "  'country',\n",
       "  'everyone',\n",
       "  'has',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'freely',\n",
       "  'practice',\n",
       "  'whatever',\n",
       "  'religion',\n",
       "  'they',\n",
       "  ' ',\n",
       "  'want',\n",
       "  '.'],\n",
       " ['olympic_games',\n",
       "  'gives',\n",
       "  'the',\n",
       "  'world',\n",
       "  'a',\n",
       "  'chance',\n",
       "  'to',\n",
       "  'see',\n",
       "  'the',\n",
       "  'talent',\n",
       "  'of',\n",
       "  'many',\n",
       "  'athletes',\n",
       "  'from',\n",
       "  'around',\n",
       "  'the',\n",
       "  'world'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'abolish',\n",
       "  'intellectual_property',\n",
       "  'rights',\n",
       "  'because',\n",
       "  'we',\n",
       "  'never',\n",
       "  'can',\n",
       "  'truly',\n",
       "  'know',\n",
       "  'that',\n",
       "  'someone',\n",
       "  'came',\n",
       "  'up',\n",
       "  'with',\n",
       "  'something',\n",
       "  '.'],\n",
       " ['subsidizing',\n",
       "  'space_exploration',\n",
       "  'takes',\n",
       "  'money',\n",
       "  'away',\n",
       "  'from',\n",
       "  'more',\n",
       "  'important',\n",
       "  'issues',\n",
       "  '.'],\n",
       " ['missionary_work',\n",
       "  'puts',\n",
       "  'people',\n",
       "  'in',\n",
       "  'intrusive',\n",
       "  'positions',\n",
       "  'against',\n",
       "  'those',\n",
       "  'who',\n",
       "  'have',\n",
       "  'inhabited',\n",
       "  'the',\n",
       "  'same',\n",
       "  'land',\n",
       "  'and',\n",
       "  'have',\n",
       "  'had',\n",
       "  'the',\n",
       "  'same',\n",
       "  'customs',\n",
       "  'for',\n",
       "  'centuries',\n",
       "  '.'],\n",
       " ['algorithmic_trading',\n",
       "  'allows',\n",
       "  'for',\n",
       "  'more',\n",
       "  'timely',\n",
       "  ',',\n",
       "  'accurate',\n",
       "  ',',\n",
       "  'and',\n",
       "  'efficient',\n",
       "  'trading',\n",
       "  '.'],\n",
       " ['capital_punishment',\n",
       "  'might',\n",
       "  'be',\n",
       "  'the',\n",
       "  'only',\n",
       "  'way',\n",
       "  'to',\n",
       "  'fairly',\n",
       "  'punish',\n",
       "  'a',\n",
       "  'criminal',\n",
       "  'for',\n",
       "  'an',\n",
       "  'exceedingly',\n",
       "  'awful',\n",
       "  'crime',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'value',\n",
       "  'of',\n",
       "  'a',\n",
       "  'group',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'deemed',\n",
       "  'more',\n",
       "  'important',\n",
       "  'just',\n",
       "  'because',\n",
       "  'of',\n",
       "  'the',\n",
       "  'amount',\n",
       "  'of',\n",
       "  'people',\n",
       "  '.',\n",
       "  'it',\n",
       "  'does',\n",
       "  'not',\n",
       "  'increase',\n",
       "  'their',\n",
       "  'value',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'adopt',\n",
       "  'atheism',\n",
       "  'as',\n",
       "  'government',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'dictate',\n",
       "  'people',\n",
       "  \"'s\",\n",
       "  'religious',\n",
       "  'freedom',\n",
       "  '.'],\n",
       " ['as',\n",
       "  'people',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'have',\n",
       "  'children',\n",
       "  'later',\n",
       "  'and',\n",
       "  'later',\n",
       "  ',',\n",
       "  'mandatory_retirement',\n",
       "  'prevents',\n",
       "  'people',\n",
       "  'from',\n",
       "  'being',\n",
       "  'able',\n",
       "  'to',\n",
       "  'provide',\n",
       "  'for',\n",
       "  'their',\n",
       "  'family',\n",
       "  'and',\n",
       "  'dependents',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'stop',\n",
       "  'the',\n",
       "  'development',\n",
       "  'of',\n",
       "  'autonomous_cars',\n",
       "  'because',\n",
       "  'it',\n",
       "  'will',\n",
       "  'help',\n",
       "  'the',\n",
       "  'people',\n",
       "  'more',\n",
       "  'easily',\n",
       "  'on',\n",
       "  'driving',\n",
       "  'and',\n",
       "  'will',\n",
       "  'provide',\n",
       "  'more',\n",
       "  'safety',\n",
       "  '.'],\n",
       " ['some',\n",
       "  'species',\n",
       "  'are',\n",
       "  'endangered',\n",
       "  'and',\n",
       "  'threatened',\n",
       "  'by',\n",
       "  'poaching',\n",
       "  '.',\n",
       "  'zoos',\n",
       "  'are',\n",
       "  'a',\n",
       "  'place',\n",
       "  'were',\n",
       "  'we',\n",
       "  'can',\n",
       "  'guarantee',\n",
       "  'their',\n",
       "  'safety',\n",
       "  'and',\n",
       "  'survival',\n",
       "  '.'],\n",
       " ['safe_spaces',\n",
       "  'prevent',\n",
       "  'people',\n",
       "  'from',\n",
       "  'challenging',\n",
       "  'ideas',\n",
       "  'different',\n",
       "  'than',\n",
       "  'their',\n",
       "  'own',\n",
       "  '.'],\n",
       " ['banning',\n",
       "  'this',\n",
       "  'is',\n",
       "  'a',\n",
       "  'slippery',\n",
       "  'slope',\n",
       "  'to',\n",
       "  'all',\n",
       "  'sorts',\n",
       "  'of',\n",
       "  'objectively',\n",
       "  'unhealthy',\n",
       "  'food',\n",
       "  'on',\n",
       "  'the',\n",
       "  'market'],\n",
       " ['fallout',\n",
       "  'from',\n",
       "  'nuclear_weapons',\n",
       "  'gets',\n",
       "  'carried',\n",
       "  'across',\n",
       "  'the',\n",
       "  'world',\n",
       "  'by',\n",
       "  'the',\n",
       "  'wind',\n",
       "  ',',\n",
       "  'we',\n",
       "  'must',\n",
       "  'abolish',\n",
       "  'nuclear_weapons',\n",
       "  'so',\n",
       "  'that',\n",
       "  'conflicts',\n",
       "  'between',\n",
       "  'individual',\n",
       "  'states',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'cause',\n",
       "  'nuclear',\n",
       "  'damage',\n",
       "  'in',\n",
       "  'neighboring',\n",
       "  'states',\n",
       "  '.'],\n",
       " ['factory_farming',\n",
       "  'is',\n",
       "  'an',\n",
       "  'efficient',\n",
       "  'way',\n",
       "  'to',\n",
       "  'grow',\n",
       "  'mass',\n",
       "  'amounts',\n",
       "  'of',\n",
       "  'food',\n",
       "  'for',\n",
       "  'the',\n",
       "  'food',\n",
       "  'supply',\n",
       "  'chain',\n",
       "  '.',\n",
       "  'it',\n",
       "  'pushes',\n",
       "  'innovation',\n",
       "  'and',\n",
       "  'makes',\n",
       "  'farming',\n",
       "  'more',\n",
       "  'efficient',\n",
       "  'and',\n",
       "  'safer',\n",
       "  'outcomes',\n",
       "  'for',\n",
       "  'the',\n",
       "  'food',\n",
       "  'supply',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'subsidize',\n",
       "  'embryonic_stem',\n",
       "  'cell_research',\n",
       "  'as',\n",
       "  'that',\n",
       "  'is',\n",
       "  'done',\n",
       "  'by',\n",
       "  'private',\n",
       "  'companies',\n",
       "  'and',\n",
       "  'they',\n",
       "  'can',\n",
       "  'raiser',\n",
       "  'their',\n",
       "  'own',\n",
       "  'money',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'have',\n",
       "  'a',\n",
       "  'tremendous',\n",
       "  'amount',\n",
       "  'of',\n",
       "  'highly',\n",
       "  'intelligent',\n",
       "  '/students',\n",
       "  'who',\n",
       "  'could',\n",
       "  'not',\n",
       "  'go',\n",
       "  'to',\n",
       "  'college',\n",
       "  'without',\n",
       "  'subsidizes',\n",
       "  '.',\n",
       "  'these',\n",
       "  'students',\n",
       "  'could',\n",
       "  'find',\n",
       "  'cures',\n",
       "  'to',\n",
       "  'fatal',\n",
       "  'illnesses',\n",
       "  'and',\n",
       "  'should',\n",
       "  'be',\n",
       "  'subsidized',\n",
       "  'to',\n",
       "  'benefit',\n",
       "  'all',\n",
       "  'of',\n",
       "  'society',\n",
       "  '.'],\n",
       " ['an', 'austerity_regime', 'would', 'be', 'good', 'for', 'the', 'economy'],\n",
       " ['sex_selection',\n",
       "  'is',\n",
       "  'unnatural',\n",
       "  'and',\n",
       "  'will',\n",
       "  'have',\n",
       "  'long',\n",
       "  'term',\n",
       "  'negative',\n",
       "  'consequences',\n",
       "  'on',\n",
       "  'society',\n",
       "  '.',\n",
       "  'we',\n",
       "  'will',\n",
       "  'become',\n",
       "  'overpopulated',\n",
       "  'with',\n",
       "  'male',\n",
       "  'children',\n",
       "  'and',\n",
       "  'females',\n",
       "  'will',\n",
       "  'become',\n",
       "  'targets',\n",
       "  'of',\n",
       "  'sexual',\n",
       "  'crimes',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'abused',\n",
       "  'have',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'have',\n",
       "  'spaces',\n",
       "  'where',\n",
       "  'they',\n",
       "  'can',\n",
       "  'have',\n",
       "  'tolerance',\n",
       "  'and',\n",
       "  'not',\n",
       "  'suffer',\n",
       "  'abuse'],\n",
       " ['economic_sanctions',\n",
       "  'hurt',\n",
       "  'the',\n",
       "  'poor',\n",
       "  ',',\n",
       "  'working',\n",
       "  'class',\n",
       "  'and',\n",
       "  'has',\n",
       "  'little',\n",
       "  'affect',\n",
       "  'on',\n",
       "  'the',\n",
       "  'ruling',\n",
       "  'party',\n",
       "  '.'],\n",
       " ['missionary_work',\n",
       "  'allows',\n",
       "  'people',\n",
       "  'in',\n",
       "  'developing',\n",
       "  'countries',\n",
       "  'access',\n",
       "  'to',\n",
       "  'new',\n",
       "  'ways',\n",
       "  'of',\n",
       "  'thinking',\n",
       "  'and',\n",
       "  'possibilities',\n",
       "  'for',\n",
       "  'how',\n",
       "  'they',\n",
       "  'live',\n",
       "  'their',\n",
       "  'life',\n",
       "  '.'],\n",
       " ['intellectual_property',\n",
       "  'rights',\n",
       "  'are',\n",
       "  'expensive',\n",
       "  'to',\n",
       "  'maintain',\n",
       "  'and',\n",
       "  'hold',\n",
       "  'back',\n",
       "  'the',\n",
       "  'spread',\n",
       "  'of',\n",
       "  'new',\n",
       "  'ideas'],\n",
       " ['stop',\n",
       "  'the',\n",
       "  'development',\n",
       "  'of',\n",
       "  'autonomous_cars',\n",
       "  'because',\n",
       "  'it',\n",
       "  'can',\n",
       "  'cause',\n",
       "  'accidents',\n",
       "  'due',\n",
       "  'to',\n",
       "  'the',\n",
       "  'laws',\n",
       "  'in',\n",
       "  'different',\n",
       "  'countries',\n",
       "  'being',\n",
       "  'different'],\n",
       " ['school_uniforms',\n",
       "  'are',\n",
       "  'a',\n",
       "  'way',\n",
       "  'of',\n",
       "  'stifling',\n",
       "  'the',\n",
       "  'creativity',\n",
       "  'and',\n",
       "  'individuality',\n",
       "  'of',\n",
       "  'students',\n",
       "  '.'],\n",
       " ['fast_food',\n",
       "  'is',\n",
       "  'the',\n",
       "  'cause',\n",
       "  'of',\n",
       "  'the',\n",
       "  'ever',\n",
       "  'increasing',\n",
       "  'chronic',\n",
       "  'conditions',\n",
       "  'and',\n",
       "  'obesity',\n",
       "  'in',\n",
       "  'our',\n",
       "  'nation',\n",
       "  '.'],\n",
       " ['safe_spaces',\n",
       "  'are',\n",
       "  'a',\n",
       "  'place',\n",
       "  'where',\n",
       "  'minorities',\n",
       "  'of',\n",
       "  'any',\n",
       "  'sort',\n",
       "  'are',\n",
       "  'safe',\n",
       "  'to',\n",
       "  'be',\n",
       "  'who',\n",
       "  'they',\n",
       "  'are',\n",
       "  'and',\n",
       "  'are',\n",
       "  'safe',\n",
       "  'from',\n",
       "  'discrimination',\n",
       "  ',',\n",
       "  'negative',\n",
       "  'comments',\n",
       "  'and',\n",
       "  'harassment',\n",
       "  'and',\n",
       "  'in',\n",
       "  'today',\n",
       "  \"'s\",\n",
       "  'intolerant',\n",
       "  'society',\n",
       "  'are',\n",
       "  'much',\n",
       "  'needed',\n",
       "  '.'],\n",
       " ['people', 'should', 'be', 'encouraged', 'to', 'individuals'],\n",
       " ['the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'bear_arms',\n",
       "  'had',\n",
       "  'and',\n",
       "  'will',\n",
       "  'only',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'people',\n",
       "  'killing',\n",
       "  'innocent',\n",
       "  'people',\n",
       "  '.'],\n",
       " ['private_military',\n",
       "  'companies',\n",
       "  'have',\n",
       "  'no',\n",
       "  'governmental',\n",
       "  'controls',\n",
       "  'and',\n",
       "  'can',\n",
       "  'do',\n",
       "  'more',\n",
       "  'harm',\n",
       "  'then',\n",
       "  'good',\n",
       "  '.'],\n",
       " ['there',\n",
       "  'is',\n",
       "  'no',\n",
       "  'certainty',\n",
       "  'that',\n",
       "  'the',\n",
       "  'process',\n",
       "  'will',\n",
       "  'be',\n",
       "  'a',\n",
       "  'success',\n",
       "  ',',\n",
       "  'and',\n",
       "  'couples',\n",
       "  'may',\n",
       "  'end',\n",
       "  'up',\n",
       "  'wasting',\n",
       "  'time',\n",
       "  'and',\n",
       "  'money',\n",
       "  '.'],\n",
       " ['capital_punishment',\n",
       "  'can',\n",
       "  'be',\n",
       "  'replaced',\n",
       "  'by',\n",
       "  'more',\n",
       "  'ethical',\n",
       "  'but',\n",
       "  'equally',\n",
       "  'punishing',\n",
       "  'alternatives',\n",
       "  ',',\n",
       "  'like',\n",
       "  'life',\n",
       "  'without',\n",
       "  'parole',\n",
       "  '.'],\n",
       " ['telemarketing',\n",
       "  'is',\n",
       "  'very',\n",
       "  'economical',\n",
       "  'and',\n",
       "  'it',\n",
       "  'provides',\n",
       "  'an',\n",
       "  'easy',\n",
       "  'way',\n",
       "  'for',\n",
       "  'companies',\n",
       "  'to',\n",
       "  'offer',\n",
       "  'their',\n",
       "  'products',\n",
       "  'and',\n",
       "  'services',\n",
       "  'to',\n",
       "  'people',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'telemarketers',\n",
       "  'are',\n",
       "  'merely',\n",
       "  'asking',\n",
       "  'whether',\n",
       "  'someone',\n",
       "  'wants',\n",
       "  'something',\n",
       "  'or',\n",
       "  'not',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'need',\n",
       "  'to',\n",
       "  'subsidize',\n",
       "  'space_exploration',\n",
       "  'so',\n",
       "  'we',\n",
       "  'can',\n",
       "  'find',\n",
       "  'somewhere',\n",
       "  'for',\n",
       "  'the',\n",
       "  'human',\n",
       "  'race',\n",
       "  'to',\n",
       "  'go',\n",
       "  'when',\n",
       "  'we',\n",
       "  'finally',\n",
       "  'get',\n",
       "  'done',\n",
       "  'destroying',\n",
       "  'our',\n",
       "  'planet',\n",
       "  '.'],\n",
       " ['wikipedia',\n",
       "  'is',\n",
       "  'a',\n",
       "  'valuable',\n",
       "  'source',\n",
       "  'of',\n",
       "  'information',\n",
       "  'in',\n",
       "  'all',\n",
       "  'things',\n",
       "  'and',\n",
       "  'would',\n",
       "  'be',\n",
       "  'missed',\n",
       "  'if',\n",
       "  'it',\n",
       "  'were',\n",
       "  'not',\n",
       "  'able',\n",
       "  'to',\n",
       "  'continue',\n",
       "  'due',\n",
       "  'to',\n",
       "  'lack',\n",
       "  'of',\n",
       "  'support'],\n",
       " ['targeted_killing',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned',\n",
       "  'because',\n",
       "  'the',\n",
       "  'individual',\n",
       "  'does',\n",
       "  \"n't\",\n",
       "  'stand',\n",
       "  'a',\n",
       "  'chance',\n",
       "  'against',\n",
       "  'government',\n",
       "  'hired',\n",
       "  'hitmen',\n",
       "  '.',\n",
       "  'instead',\n",
       "  ',',\n",
       "  'a',\n",
       "  'fair',\n",
       "  'trial',\n",
       "  'should',\n",
       "  'be',\n",
       "  'carried',\n",
       "  'out',\n",
       "  '.'],\n",
       " ['cannabis',\n",
       "  'use',\n",
       "  'has',\n",
       "  'been',\n",
       "  'linked',\n",
       "  'to',\n",
       "  'mental',\n",
       "  'problems',\n",
       "  'in',\n",
       "  'youth',\n",
       "  'and',\n",
       "  'should',\n",
       "  \"n't\",\n",
       "  'be',\n",
       "  'legalized',\n",
       "  '.'],\n",
       " ['intellectual_property',\n",
       "  'rights',\n",
       "  'mean',\n",
       "  'that',\n",
       "  'the',\n",
       "  'people',\n",
       "  'who',\n",
       "  'come',\n",
       "  'up',\n",
       "  'with',\n",
       "  'ideas',\n",
       "  'or',\n",
       "  'products',\n",
       "  'get',\n",
       "  'the',\n",
       "  'financial',\n",
       "  'gains',\n",
       "  'from',\n",
       "  'said',\n",
       "  'product',\n",
       "  'and',\n",
       "  'so',\n",
       "  'makes',\n",
       "  'people',\n",
       "  'more',\n",
       "  'likely',\n",
       "  'to',\n",
       "  'innovate'],\n",
       " ['schools',\n",
       "  'already',\n",
       "  'have',\n",
       "  'systems',\n",
       "  'and',\n",
       "  'hierarchies',\n",
       "  ',',\n",
       "  'there',\n",
       "  'is',\n",
       "  'no',\n",
       "  'need',\n",
       "  'to',\n",
       "  'employ',\n",
       "  'further',\n",
       "  'policies',\n",
       "  '.'],\n",
       " ['thepride',\n",
       "  'parades',\n",
       "  'are',\n",
       "  'part',\n",
       "  'of',\n",
       "  'the',\n",
       "  'empowerment',\n",
       "  'of',\n",
       "  'the',\n",
       "  'lgbt',\n",
       "  'community'],\n",
       " ['zoos',\n",
       "  'allow',\n",
       "  'people',\n",
       "  'to',\n",
       "  'see',\n",
       "  'many',\n",
       "  'animals',\n",
       "  'in',\n",
       "  'their',\n",
       "  'natural',\n",
       "  'habitat',\n",
       "  'that',\n",
       "  'most',\n",
       "  'people',\n",
       "  'would',\n",
       "  'never',\n",
       "  'see',\n",
       "  '.'],\n",
       " ['each',\n",
       "  'case',\n",
       "  'has',\n",
       "  'different',\n",
       "  'circumstances',\n",
       "  'and',\n",
       "  'certain',\n",
       "  'things',\n",
       "  'need',\n",
       "  'to',\n",
       "  'be',\n",
       "  'taken',\n",
       "  'into',\n",
       "  'consideration',\n",
       "  'for',\n",
       "  'each',\n",
       "  'one',\n",
       "  '.',\n",
       "  'judicial_activism',\n",
       "  'allow',\n",
       "  'the',\n",
       "  'court',\n",
       "  'to',\n",
       "  'consider',\n",
       "  'the',\n",
       "  'circumstances',\n",
       "  'of',\n",
       "  'each',\n",
       "  'crime',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'just',\n",
       "  'another',\n",
       "  'way',\n",
       "  'for',\n",
       "  'lazy',\n",
       "  'people',\n",
       "  'to',\n",
       "  'do',\n",
       "  'as',\n",
       "  'little',\n",
       "  'as',\n",
       "  'possible',\n",
       "  '.'],\n",
       " ['autonomous_cars',\n",
       "  'reduce',\n",
       "  'the',\n",
       "  'risk',\n",
       "  'of',\n",
       "  'human',\n",
       "  'error',\n",
       "  ',',\n",
       "  'thus',\n",
       "  'leading',\n",
       "  'to',\n",
       "  'safer',\n",
       "  'roads',\n",
       "  '.'],\n",
       " ['autonomous_cars',\n",
       "  'can',\n",
       "  'help',\n",
       "  'transport',\n",
       "  'those',\n",
       "  'unable',\n",
       "  'to',\n",
       "  'drive',\n",
       "  'themselves'],\n",
       " ['libertarianism',\n",
       "  'allows',\n",
       "  'people',\n",
       "  'to',\n",
       "  'make',\n",
       "  'their',\n",
       "  'own',\n",
       "  'choices',\n",
       "  'without',\n",
       "  'government',\n",
       "  'interference',\n",
       "  '.'],\n",
       " ['algorithmic_trading',\n",
       "  'can',\n",
       "  'cause',\n",
       "  'unnatural',\n",
       "  'market',\n",
       "  'movements',\n",
       "  '.'],\n",
       " ['judges',\n",
       "  'should',\n",
       "  'be',\n",
       "  'limited',\n",
       "  'to',\n",
       "  'upholding',\n",
       "  'law',\n",
       "  'rather_than',\n",
       "  'making',\n",
       "  'it',\n",
       "  '.',\n",
       "  'that',\n",
       "  'job',\n",
       "  'is',\n",
       "  'politicians',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'ban',\n",
       "  'the',\n",
       "  'church',\n",
       "  'of',\n",
       "  'scientology',\n",
       "  'as',\n",
       "  'people',\n",
       "  'have',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'support',\n",
       "  'any',\n",
       "  'religion',\n",
       "  'they',\n",
       "  'choose',\n",
       "  'and',\n",
       "  'the',\n",
       "  'church',\n",
       "  'contributes',\n",
       "  'money',\n",
       "  'to',\n",
       "  'good',\n",
       "  'causes',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'ban',\n",
       "  'human_cloning',\n",
       "  'as',\n",
       "  'we',\n",
       "  'need',\n",
       "  'to',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'work',\n",
       "  'to',\n",
       "  'the',\n",
       "  'betterment',\n",
       "  'of',\n",
       "  'the',\n",
       "  'health',\n",
       "  'and',\n",
       "  'welfare',\n",
       "  'of',\n",
       "  'the',\n",
       "  'people',\n",
       "  '.'],\n",
       " ['this',\n",
       "  'is',\n",
       "  'a',\n",
       "  'free',\n",
       "  'country',\n",
       "  'and',\n",
       "  'citizens',\n",
       "  'should',\n",
       "  'have',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'vote',\n",
       "  'or',\n",
       "  'not',\n",
       "  'to',\n",
       "  'vote',\n",
       "  '.'],\n",
       " ['zoos',\n",
       "  'are',\n",
       "  'a',\n",
       "  'great',\n",
       "  'way',\n",
       "  'teach',\n",
       "  'people',\n",
       "  'about',\n",
       "  'animals',\n",
       "  'and',\n",
       "  'how',\n",
       "  'important',\n",
       "  'they',\n",
       "  'are'],\n",
       " ['a',\n",
       "  'zoo',\n",
       "  'is',\n",
       "  'a',\n",
       "  'safe',\n",
       "  'place',\n",
       "  'for',\n",
       "  'animals',\n",
       "  'who',\n",
       "  'lost',\n",
       "  'their',\n",
       "  'homes',\n",
       "  'and',\n",
       "  'are',\n",
       "  'not',\n",
       "  'able',\n",
       "  'to',\n",
       "  'care',\n",
       "  'for',\n",
       "  'themselves'],\n",
       " ['should',\n",
       "  'uniforms',\n",
       "  'are',\n",
       "  'costly',\n",
       "  'and',\n",
       "  'children',\n",
       "  'should',\n",
       "  'be',\n",
       "  'allowed',\n",
       "  'to',\n",
       "  'where',\n",
       "  'their',\n",
       "  'own',\n",
       "  'cheaper',\n",
       "  'clothes'],\n",
       " ['modern',\n",
       "  'days',\n",
       "  'require',\n",
       "  'modern',\n",
       "  'measures',\n",
       "  'and',\n",
       "  'judicial_activism',\n",
       "  'brings',\n",
       "  'present',\n",
       "  'day',\n",
       "  'thinking',\n",
       "  'and',\n",
       "  'opinions',\n",
       "  'into',\n",
       "  'important',\n",
       "  'cases',\n",
       "  'to',\n",
       "  'stay',\n",
       "  'up',\n",
       "  'to',\n",
       "  'date'],\n",
       " ['unwanted',\n",
       "  'telemarketing',\n",
       "  'is',\n",
       "  'a',\n",
       "  'form',\n",
       "  'of',\n",
       "  'harassment',\n",
       "  ',',\n",
       "  'it',\n",
       "  \"'s\",\n",
       "  'extremely',\n",
       "  'annoying',\n",
       "  'and',\n",
       "  'it',\n",
       "  \"'s\",\n",
       "  'got',\n",
       "  'so',\n",
       "  'out',\n",
       "  'of',\n",
       "  'hand',\n",
       "  'that',\n",
       "  'people',\n",
       "  'are',\n",
       "  'unable',\n",
       "  'to',\n",
       "  'avoid',\n",
       "  'or',\n",
       "  'opt',\n",
       "  'out',\n",
       "  'of',\n",
       "  'it',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'legalize',\n",
       "  'prostitution',\n",
       "  'because',\n",
       "  'if',\n",
       "  'someone',\n",
       "  'really',\n",
       "  'wants',\n",
       "  'to',\n",
       "  'use',\n",
       "  'those',\n",
       "  'services',\n",
       "  ',',\n",
       "  'they',\n",
       "  'should',\n",
       "  'have',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'do',\n",
       "  'so',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'we',\n",
       "  'can',\n",
       "  'just',\n",
       "  'regulate',\n",
       "  'it',\n",
       "  '.'],\n",
       " ['using',\n",
       "  'child_actors',\n",
       "  'keeps',\n",
       "  'the',\n",
       "  'children',\n",
       "  'out',\n",
       "  'of',\n",
       "  'school',\n",
       "  '.'],\n",
       " ['voting', 'should', 'be', 'a', 'choice', 'for', 'every', 'person'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'ban',\n",
       "  'fast_food',\n",
       "  'because',\n",
       "  'all',\n",
       "  'of',\n",
       "  'the',\n",
       "  'chemicals',\n",
       "  'it',\n",
       "  'is',\n",
       "  'made',\n",
       "  'with',\n",
       "  'is',\n",
       "  'unhealthy',\n",
       "  'and',\n",
       "  'makes',\n",
       "  'you',\n",
       "  'obese'],\n",
       " ['the',\n",
       "  'olympic_games',\n",
       "  'only',\n",
       "  'benefit',\n",
       "  'the',\n",
       "  'rich',\n",
       "  'as',\n",
       "  'they',\n",
       "  'are',\n",
       "  'the',\n",
       "  'only',\n",
       "  'people',\n",
       "  'who',\n",
       "  'can',\n",
       "  'afford',\n",
       "  'to',\n",
       "  'compete',\n",
       "  'or',\n",
       "  'attend',\n",
       "  'the',\n",
       "  'games',\n",
       "  '.'],\n",
       " ['telemarketing',\n",
       "  'is',\n",
       "  'an',\n",
       "  'excellent',\n",
       "  'tool',\n",
       "  'if',\n",
       "  'used',\n",
       "  'sensitively',\n",
       "  'and',\n",
       "  'with',\n",
       "  'caution'],\n",
       " ['private_military',\n",
       "  'companies',\n",
       "  'have',\n",
       "  'their',\n",
       "  'bottom',\n",
       "  'line',\n",
       "  'as',\n",
       "  'a',\n",
       "  'priority',\n",
       "  'rather_than',\n",
       "  'the',\n",
       "  'safety',\n",
       "  'of',\n",
       "  'the',\n",
       "  'country',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'abolish',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'and',\n",
       "  'bear_arms',\n",
       "  'because',\n",
       "  'people',\n",
       "  'would',\n",
       "  'be',\n",
       "  'left',\n",
       "  'defenseless',\n",
       "  'against',\n",
       "  'criminals',\n",
       "  'who',\n",
       "  'are',\n",
       "  'going',\n",
       "  'to',\n",
       "  'find',\n",
       "  'a',\n",
       "  'way',\n",
       "  'to',\n",
       "  'get',\n",
       "  'a',\n",
       "  'gun'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'not',\n",
       "  'right',\n",
       "  'to',\n",
       "  'legitimize',\n",
       "  'something',\n",
       "  'that',\n",
       "  'is',\n",
       "  'fundamentally',\n",
       "  'immoral',\n",
       "  'and',\n",
       "  'hurts',\n",
       "  'those',\n",
       "  'who',\n",
       "  'engage',\n",
       "  'in',\n",
       "  'it'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'subsidize',\n",
       "  'embryonic_stem',\n",
       "  'cell_research',\n",
       "  'because',\n",
       "  'it',\n",
       "  'will',\n",
       "  'help',\n",
       "  'many',\n",
       "  'people',\n",
       "  'as',\n",
       "  'long',\n",
       "  'as',\n",
       "  'it',\n",
       "  'is',\n",
       "  'successfully',\n",
       "  'done',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'makes',\n",
       "  'a',\n",
       "  'mockery',\n",
       "  'of',\n",
       "  'voting',\n",
       "  'for',\n",
       "  'your',\n",
       "  'political',\n",
       "  'party',\n",
       "  'of',\n",
       "  'choice',\n",
       "  'if',\n",
       "  'the',\n",
       "  'end',\n",
       "  'result',\n",
       "  'is',\n",
       "  'a',\n",
       "  'multi',\n",
       "  '-',\n",
       "  'party_system',\n",
       "  'which',\n",
       "  'will',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'people',\n",
       "  'not',\n",
       "  'voting',\n",
       "  'if',\n",
       "  'they',\n",
       "  'feel',\n",
       "  'they',\n",
       "  'do',\n",
       "  'not',\n",
       "  'have',\n",
       "  'a',\n",
       "  'say',\n",
       "  '.'],\n",
       " ['mandatory_retirement',\n",
       "  'leaves',\n",
       "  'openings',\n",
       "  'in',\n",
       "  'the',\n",
       "  'job',\n",
       "  'force',\n",
       "  'for',\n",
       "  'those',\n",
       "  'that',\n",
       "  'are',\n",
       "  'stronger',\n",
       "  'and',\n",
       "  'more',\n",
       "  'capable',\n",
       "  'of',\n",
       "  'doing',\n",
       "  'the',\n",
       "  'jobs',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'harmful',\n",
       "  'and',\n",
       "  'may',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'whale',\n",
       "  'extinction',\n",
       "  '.'],\n",
       " ['economic_sanctions',\n",
       "  'often',\n",
       "  'do',\n",
       "  'not',\n",
       "  'work',\n",
       "  'and',\n",
       "  'cutting',\n",
       "  'out',\n",
       "  'countries',\n",
       "  'from',\n",
       "  'the',\n",
       "  'world',\n",
       "  'economy',\n",
       "  'hurts',\n",
       "  'their',\n",
       "  'citizens',\n",
       "  ',',\n",
       "  'not',\n",
       "  'their',\n",
       "  'leaders',\n",
       "  '.'],\n",
       " ['intellectual_property',\n",
       "  'rights',\n",
       "  'should',\n",
       "  'be',\n",
       "  'abolished',\n",
       "  'as',\n",
       "  'they',\n",
       "  'stifle',\n",
       "  'innovation',\n",
       "  'and',\n",
       "  'allows',\n",
       "  'the',\n",
       "  'creation',\n",
       "  'of',\n",
       "  'monopolies',\n",
       "  'and',\n",
       "  'giant',\n",
       "  'corporations'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'cancel',\n",
       "  'pride_parades',\n",
       "  'because',\n",
       "  'it',\n",
       "  'is',\n",
       "  'forcing',\n",
       "  'views',\n",
       "  'some',\n",
       "  'people',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'agree',\n",
       "  'with',\n",
       "  'in',\n",
       "  'their',\n",
       "  'face'],\n",
       " ['also',\n",
       "  'called',\n",
       "  'intellectual',\n",
       "  'plagiarism',\n",
       "  'none',\n",
       "  'of',\n",
       "  'this',\n",
       "  'makes',\n",
       "  'sense',\n",
       "  'there',\n",
       "  'may',\n",
       "  'be',\n",
       "  'people',\n",
       "  'who',\n",
       "  'think',\n",
       "  'the',\n",
       "  'same',\n",
       "  'and',\n",
       "  'that',\n",
       "  'is',\n",
       "  'not',\n",
       "  'a',\n",
       "  'crime'],\n",
       " ['a',\n",
       "  'child',\n",
       "  'who',\n",
       "  'is',\n",
       "  'the',\n",
       "  'result',\n",
       "  'of',\n",
       "  'human_cloning',\n",
       "  'will',\n",
       "  'have',\n",
       "  'psychological',\n",
       "  'problems',\n",
       "  'because',\n",
       "  'they',\n",
       "  'are',\n",
       "  'not',\n",
       "  'allowed',\n",
       "  'to',\n",
       "  'be',\n",
       "  'their',\n",
       "  'own',\n",
       "  'person'],\n",
       " ['algorithmic_trading',\n",
       "  'gives',\n",
       "  'people',\n",
       "  'an',\n",
       "  'unfair',\n",
       "  'advantage',\n",
       "  'because',\n",
       "  'they',\n",
       "  'can',\n",
       "  'trade',\n",
       "  'so',\n",
       "  'much',\n",
       "  'more',\n",
       "  'quickly',\n",
       "  'and',\n",
       "  'therefore',\n",
       "  'it',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned',\n",
       "  '.'],\n",
       " ['animals',\n",
       "  'deserve',\n",
       "  'to',\n",
       "  'be',\n",
       "  'in',\n",
       "  'the',\n",
       "  'wild',\n",
       "  ',',\n",
       "  'with',\n",
       "  'access',\n",
       "  'to',\n",
       "  'large',\n",
       "  'open',\n",
       "  'spaces',\n",
       "  'not',\n",
       "  'available',\n",
       "  'at',\n",
       "  'a',\n",
       "  'zoo',\n",
       "  '.'],\n",
       " ['collectivism',\n",
       "  'is',\n",
       "  'a',\n",
       "  'communist',\n",
       "  'strategy',\n",
       "  'and',\n",
       "  'we',\n",
       "  'must',\n",
       "  'reject'],\n",
       " ['capital_punishment',\n",
       "  'is',\n",
       "  'absolutely',\n",
       "  'needed',\n",
       "  '.',\n",
       "  'it',\n",
       "  'acts',\n",
       "  'as',\n",
       "  'a',\n",
       "  'deterrent',\n",
       "  'to',\n",
       "  'prevent',\n",
       "  'future',\n",
       "  'crime',\n",
       "  '.',\n",
       "  'if',\n",
       "  'a',\n",
       "  'person',\n",
       "  'knows',\n",
       "  'they',\n",
       "  'can',\n",
       "  'be',\n",
       "  'killed',\n",
       "  'for',\n",
       "  'their',\n",
       "  'crime',\n",
       "  ',',\n",
       "  'it',\n",
       "  'deters',\n",
       "  'them',\n",
       "  'and',\n",
       "  'also',\n",
       "  'makes',\n",
       "  'sure',\n",
       "  'they',\n",
       "  'are',\n",
       "  \"n't\",\n",
       "  'released',\n",
       "  'from',\n",
       "  'prison'],\n",
       " ['school',\n",
       "  'uniform',\n",
       "  'helps',\n",
       "  'all',\n",
       "  'children',\n",
       "  'attend',\n",
       "  'on',\n",
       "  'a',\n",
       "  'level',\n",
       "  'playing',\n",
       "  'field',\n",
       "  ',',\n",
       "  'free',\n",
       "  'from',\n",
       "  'worry',\n",
       "  'about',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'up',\n",
       "  'with',\n",
       "  'expensive',\n",
       "  'fashion',\n",
       "  'trends',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'support',\n",
       "  'collectivism',\n",
       "  'because',\n",
       "  'it',\n",
       "  'helps',\n",
       "  'people',\n",
       "  'find',\n",
       "  'common',\n",
       "  'goals',\n",
       "  '.'],\n",
       " ['some',\n",
       "  'violent',\n",
       "  'and',\n",
       "  'extreme',\n",
       "  'behaviours',\n",
       "  'in',\n",
       "  'schools',\n",
       "  'deserve',\n",
       "  'a',\n",
       "  'fierce',\n",
       "  'and',\n",
       "  'sharp',\n",
       "  'reaction',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'may',\n",
       "  'effect',\n",
       "  'its',\n",
       "  'impartiality',\n",
       "  ',',\n",
       "  'governments',\n",
       "  ' ',\n",
       "  'may',\n",
       "  'use',\n",
       "  'their',\n",
       "  'funding',\n",
       "  'to',\n",
       "  'influence',\n",
       "  'editors',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  \"n't\",\n",
       "  'abolish',\n",
       "  'zoos',\n",
       "  'because',\n",
       "  'they',\n",
       "  'create',\n",
       "  'jobs',\n",
       "  'for',\n",
       "  'zookeepers',\n",
       "  'and',\n",
       "  'they',\n",
       "  'allow',\n",
       "  'children',\n",
       "  'to',\n",
       "  'view',\n",
       "  'wild',\n",
       "  'animals',\n",
       "  'which',\n",
       "  'is',\n",
       "  'fun',\n",
       "  'and',\n",
       "  'educational'],\n",
       " ['even',\n",
       "  'minors',\n",
       "  'have',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'bodily',\n",
       "  'autonomy',\n",
       "  'and',\n",
       "  'should',\n",
       "  'be',\n",
       "  'allowed',\n",
       "  'to',\n",
       "  'decide',\n",
       "  'for',\n",
       "  'themselves',\n",
       "  'whether',\n",
       "  'to',\n",
       "  'have',\n",
       "  'cosmetic_surgery',\n",
       "  '.'],\n",
       " ['nuclear_weapons',\n",
       "  'provide',\n",
       "  'us',\n",
       "  'security',\n",
       "  'in',\n",
       "  'times',\n",
       "  'of',\n",
       "  'war',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'adopt',\n",
       "  'gender',\n",
       "  '-',\n",
       "  'neutral_language',\n",
       "  'because',\n",
       "  'equal',\n",
       "  'rights',\n",
       "  'should',\n",
       "  'include',\n",
       "  'equal',\n",
       "  'language'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'abolish',\n",
       "  'the',\n",
       "  'olympic_games',\n",
       "  'because',\n",
       "  'they',\n",
       "  'have',\n",
       "  'not',\n",
       "  'done',\n",
       "  'what',\n",
       "  'they',\n",
       "  'were',\n",
       "  'meant',\n",
       "  'to',\n",
       "  'do',\n",
       "  'which',\n",
       "  'is',\n",
       "  'create',\n",
       "  'peace',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'they',\n",
       "  'have',\n",
       "  'created',\n",
       "  'more',\n",
       "  'problems',\n",
       "  'especially',\n",
       "  'to',\n",
       "  'those',\n",
       "  'hosting',\n",
       "  'them',\n",
       "  'and',\n",
       "  'are',\n",
       "  'just',\n",
       "  'beyond',\n",
       "  'their',\n",
       "  'time',\n",
       "  '.'],\n",
       " ['people',\n",
       "  'have',\n",
       "  'the',\n",
       "  'freedom',\n",
       "  'to',\n",
       "  'choose',\n",
       "  'any',\n",
       "  'religion',\n",
       "  ',',\n",
       "  'atheism',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'forced',\n",
       "  'upon',\n",
       "  'people'],\n",
       " ['fast_food',\n",
       "  'has',\n",
       "  'proven',\n",
       "  'to',\n",
       "  'be',\n",
       "  'detrimental',\n",
       "  'to',\n",
       "  'the',\n",
       "  'health',\n",
       "  'of',\n",
       "  'all',\n",
       "  'people',\n",
       "  'and',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned',\n",
       "  'immediately',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'need',\n",
       "  'the',\n",
       "  'cures',\n",
       "  'and',\n",
       "  'treatments',\n",
       "  'we',\n",
       "  'can',\n",
       "  'get',\n",
       "  'by',\n",
       "  'funding',\n",
       "  'stem_cell',\n",
       "  'research',\n",
       "  '.'],\n",
       " ['scientology',\n",
       "  'is',\n",
       "  'not',\n",
       "  'a',\n",
       "  'real',\n",
       "  'religion',\n",
       "  'and',\n",
       "  'you',\n",
       "  'ca',\n",
       "  \"n't\",\n",
       "  'just',\n",
       "  'take',\n",
       "  'a',\n",
       "  'work',\n",
       "  'of',\n",
       "  'sci',\n",
       "  '-',\n",
       "  'fi',\n",
       "  'and',\n",
       "  'make',\n",
       "  'your',\n",
       "  'own',\n",
       "  'religion'],\n",
       " ['whaling',\n",
       "  'is',\n",
       "  'cruel',\n",
       "  'and',\n",
       "  'inhumane',\n",
       "  ';',\n",
       "  'it',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned',\n",
       "  '.'],\n",
       " ['human_cloning', 'is', 'unnatural', 'and', 'should', 'be', 'banned'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'abolish',\n",
       "  'the',\n",
       "  'three',\n",
       "  '-',\n",
       "  'strikes_laws',\n",
       "  'because',\n",
       "  'they',\n",
       "  'discriminate',\n",
       "  'against',\n",
       "  'over',\n",
       "  '-',\n",
       "  'policed',\n",
       "  'communities',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  \"n't\",\n",
       "  'prohibit',\n",
       "  'school',\n",
       "  'prayer',\n",
       "  'because',\n",
       "  'is',\n",
       "  'important',\n",
       "  'for',\n",
       "  'religious',\n",
       "  'education'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'a',\n",
       "  'form',\n",
       "  'of',\n",
       "  'harassment',\n",
       "  'to',\n",
       "  'be',\n",
       "  'contacted',\n",
       "  'constantly',\n",
       "  'by',\n",
       "  'telemarketers',\n",
       "  '.'],\n",
       " ['autonomous_cars',\n",
       "  'could',\n",
       "  'help',\n",
       "  'people',\n",
       "  'make',\n",
       "  'better',\n",
       "  'use',\n",
       "  'of',\n",
       "  'their',\n",
       "  'time'],\n",
       " ['atheism',\n",
       "  'is',\n",
       "  'the',\n",
       "  'most',\n",
       "  'rational',\n",
       "  'outcome',\n",
       "  ' ',\n",
       "  'for',\n",
       "  'our',\n",
       "  'society',\n",
       "  'after',\n",
       "  'too',\n",
       "  'many',\n",
       "  'religions',\n",
       "  'have',\n",
       "  'ruined',\n",
       "  'our',\n",
       "  'lives'],\n",
       " ['organ_trade',\n",
       "  'between',\n",
       "  'consenting',\n",
       "  'parties',\n",
       "  'should',\n",
       "  'be',\n",
       "  'an',\n",
       "  'option',\n",
       "  'as',\n",
       "  'it',\n",
       "  'can',\n",
       "  'reduce',\n",
       "  'wait',\n",
       "  'times',\n",
       "  '.'],\n",
       " ['legal',\n",
       "  'marijuana',\n",
       "  'could',\n",
       "  'actually',\n",
       "  'improve',\n",
       "  'opportunities',\n",
       "  'for',\n",
       "  'the',\n",
       "  'black',\n",
       "  'market',\n",
       "  'because',\n",
       "  'cartels',\n",
       "  'can',\n",
       "  'easily',\n",
       "  'undermine',\n",
       "  'licensed',\n",
       "  'sellers',\n",
       "  'prices',\n",
       "  'and',\n",
       "  'the',\n",
       "  'black',\n",
       "  'market',\n",
       "  'will',\n",
       "  'thrive'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'abolish',\n",
       "  'zoos',\n",
       "  'because',\n",
       "  'it',\n",
       "  'is',\n",
       "  'cruel',\n",
       "  'to',\n",
       "  'cage',\n",
       "  'up',\n",
       "  'animals',\n",
       "  'like',\n",
       "  'that',\n",
       "  'in',\n",
       "  'one',\n",
       "  'area',\n",
       "  'and',\n",
       "  'is',\n",
       "  'not',\n",
       "  'their',\n",
       "  'natural',\n",
       "  'habitat',\n",
       "  'and',\n",
       "  'essentially',\n",
       "  'treat',\n",
       "  'them',\n",
       "  'like',\n",
       "  'pets',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'investigations',\n",
       "  'with',\n",
       "  'mother',\n",
       "  'cells',\n",
       "  'could',\n",
       "  'mean',\n",
       "  'the',\n",
       "  'definitive',\n",
       "  'advance',\n",
       "  'for',\n",
       "  'the',\n",
       "  'human',\n",
       "  'race'],\n",
       " ['people',\n",
       "  'should',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'work',\n",
       "  'hard',\n",
       "  'and',\n",
       "  'reap',\n",
       "  'the',\n",
       "  'benefits',\n",
       "  'of',\n",
       "  'their',\n",
       "  'labor',\n",
       "  '.',\n",
       "  'with',\n",
       "  'collectivism',\n",
       "  'you',\n",
       "  'will',\n",
       "  'always',\n",
       "  'have',\n",
       "  'some',\n",
       "  'people',\n",
       "  'doing',\n",
       "  'most',\n",
       "  'of',\n",
       "  'the',\n",
       "  'work',\n",
       "  'and',\n",
       "  'the',\n",
       "  'lazy',\n",
       "  'ones',\n",
       "  'will',\n",
       "  'benefit',\n",
       "  'from',\n",
       "  'it',\n",
       "  '.'],\n",
       " ['legalizing',\n",
       "  'marijuana',\n",
       "  'leads',\n",
       "  'to',\n",
       "  'more',\n",
       "  'marijuana',\n",
       "  '-',\n",
       "  'related',\n",
       "  'medical',\n",
       "  'emergencies',\n",
       "  'cases',\n",
       "  'and',\n",
       "  'unintentional',\n",
       "  'cannabis',\n",
       "  'overdose',\n",
       "  'injuries',\n",
       "  'among',\n",
       "  'children'],\n",
       " ['private_military',\n",
       "  'companies',\n",
       "  'can',\n",
       "  'provide',\n",
       "  'more',\n",
       "  'advanced',\n",
       "  'technology',\n",
       "  'because',\n",
       "  'they',\n",
       "  'are',\n",
       "  'not',\n",
       "  'restricted',\n",
       "  'by',\n",
       "  'governmental',\n",
       "  'red',\n",
       "  'tape',\n",
       "  '.'],\n",
       " ['cosmetic_surgery',\n",
       "  'teaches',\n",
       "  'our',\n",
       "  'daughters',\n",
       "  'that',\n",
       "  'they',\n",
       "  'need',\n",
       "  'to',\n",
       "  'look',\n",
       "  'perfect',\n",
       "  'and',\n",
       "  'never',\n",
       "  'age',\n",
       "  '.'],\n",
       " ['three',\n",
       "  '-',\n",
       "  'strike',\n",
       "  'laws',\n",
       "  'are',\n",
       "  'intolerant',\n",
       "  'of',\n",
       "  'special',\n",
       "  'circumstances',\n",
       "  '.'],\n",
       " ['allowing',\n",
       "  'people',\n",
       "  'to',\n",
       "  'use',\n",
       "  'a',\n",
       "  'gateway',\n",
       "  'drug',\n",
       "  'like',\n",
       "  'cannabis',\n",
       "  'is',\n",
       "  'steering',\n",
       "  'them',\n",
       "  'towards',\n",
       "  'a',\n",
       "  'life',\n",
       "  'of',\n",
       "  'addiction',\n",
       "  '.'],\n",
       " ['school',\n",
       "  'prayer',\n",
       "  'should',\n",
       "  'be',\n",
       "  'allowed',\n",
       "  'in',\n",
       "  'school',\n",
       "  'because',\n",
       "  'it',\n",
       "  'is',\n",
       "  'what',\n",
       "  'our',\n",
       "  'country',\n",
       "  'was',\n",
       "  'founded',\n",
       "  'on',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'those',\n",
       "  'who',\n",
       "  'disagree',\n",
       "  'could',\n",
       "  'just',\n",
       "  'abstain',\n",
       "  'from',\n",
       "  'the',\n",
       "  'prayer',\n",
       "  '.'],\n",
       " ['school',\n",
       "  'prayer',\n",
       "  'is',\n",
       "  'wrong',\n",
       "  'because',\n",
       "  'the',\n",
       "  'non',\n",
       "  'religious',\n",
       "  'are',\n",
       "  'expected',\n",
       "  'to',\n",
       "  'participate',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'development',\n",
       "  'of',\n",
       "  'autonomous_cars',\n",
       "  'should',\n",
       "  'be',\n",
       "  'halted',\n",
       "  'until',\n",
       "  'we',\n",
       "  'have',\n",
       "  'dealt',\n",
       "  'with',\n",
       "  'the',\n",
       "  'moral',\n",
       "  'question',\n",
       "  'of',\n",
       "  'who',\n",
       "  'would',\n",
       "  'be',\n",
       "  ' ',\n",
       "  'liable',\n",
       "  'in',\n",
       "  'the',\n",
       "  'case',\n",
       "  'of',\n",
       "  'an',\n",
       "  'accident',\n",
       "  ',',\n",
       "  'hacking',\n",
       "  'or',\n",
       "  'malfunction',\n",
       "  '.'],\n",
       " ['it', \"'s\", 'cruel', 'for', 'the', 'animals', 'to', 'be', 'caged'],\n",
       " ['the',\n",
       "  'long',\n",
       "  'term',\n",
       "  'effects',\n",
       "  'of',\n",
       "  'new',\n",
       "  'procedures',\n",
       "  'have',\n",
       "  'not',\n",
       "  'been',\n",
       "  'studied',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'know',\n",
       "  'if',\n",
       "  'they',\n",
       "  'are',\n",
       "  'safe',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'legalize',\n",
       "  'prostitution',\n",
       "  'because',\n",
       "  'they',\n",
       "  'spread',\n",
       "  'too',\n",
       "  'many',\n",
       "  'diseases'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'ban',\n",
       "  'because',\n",
       "  'it',\n",
       "  'has',\n",
       "  'been',\n",
       "  'proven',\n",
       "  'to',\n",
       "  'work',\n",
       "  'and',\n",
       "  'can',\n",
       "  'serve',\n",
       "  'specific',\n",
       "  'issues'],\n",
       " ['guns',\n",
       "  'are',\n",
       "  'already',\n",
       "  'ubiquitous',\n",
       "  'and',\n",
       "  'outlawing',\n",
       "  'them',\n",
       "  'will',\n",
       "  'only',\n",
       "  'keep',\n",
       "  'them',\n",
       "  'out',\n",
       "  'of',\n",
       "  'the',\n",
       "  'hands',\n",
       "  'of',\n",
       "  'lawful',\n",
       "  'owners',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'must',\n",
       "  'not',\n",
       "  'abolish',\n",
       "  'nuclear_weapons',\n",
       "  'because',\n",
       "  'they',\n",
       "  'can',\n",
       "  'be',\n",
       "  'used',\n",
       "  'in',\n",
       "  'situations',\n",
       "  'of',\n",
       "  'extreme',\n",
       "  'need',\n",
       "  'like',\n",
       "  'defending',\n",
       "  'a',\n",
       "  'country'],\n",
       " ['independent',\n",
       "  'religious',\n",
       "  'organisations',\n",
       "  'should',\n",
       "  'be',\n",
       "  'free',\n",
       "  'to',\n",
       "  'solicit',\n",
       "  'for',\n",
       "  'new',\n",
       "  'members',\n",
       "  'if',\n",
       "  'they',\n",
       "  'do',\n",
       "  'so',\n",
       "  'in',\n",
       "  'a',\n",
       "  'fair',\n",
       "  'and',\n",
       "  'open',\n",
       "  'manner',\n",
       "  '.'],\n",
       " ['austerity',\n",
       "  'regimes',\n",
       "  'needs',\n",
       "  'to',\n",
       "  'be',\n",
       "  'adopted',\n",
       "  'to',\n",
       "  'reduce',\n",
       "  'budget',\n",
       "  'deficits',\n",
       "  'and',\n",
       "  'debt',\n",
       "  'crises'],\n",
       " ['for',\n",
       "  'people',\n",
       "  'who',\n",
       "  'work',\n",
       "  'in',\n",
       "  'skilled',\n",
       "  'manual',\n",
       "  'jobs',\n",
       "  'it',\n",
       "  'comes',\n",
       "  'to',\n",
       "  'a',\n",
       "  'point',\n",
       "  'where',\n",
       "  'it',\n",
       "  'is',\n",
       "  'no',\n",
       "  'longer',\n",
       "  'safe',\n",
       "  'for',\n",
       "  'them',\n",
       "  'work',\n",
       "  ',',\n",
       "  'the',\n",
       "  'retirement',\n",
       "  'age',\n",
       "  'is',\n",
       "  'used',\n",
       "  'to',\n",
       "  'protect',\n",
       "  'people',\n",
       "  'of',\n",
       "  'a',\n",
       "  'certain',\n",
       "  'age',\n",
       "  'as',\n",
       "  'a',\n",
       "  'safety',\n",
       "  'precaution'],\n",
       " ['executive_compensation',\n",
       "  'should',\n",
       "  'be',\n",
       "  'limited',\n",
       "  'to',\n",
       "  'make',\n",
       "  'companies',\n",
       "  'more',\n",
       "  'profitable',\n",
       "  '.'],\n",
       " ['intellectual_property',\n",
       "  'rights',\n",
       "  'create',\n",
       "  'a',\n",
       "  'monopoly',\n",
       "  'position',\n",
       "  'for',\n",
       "  'a',\n",
       "  'company',\n",
       "  'which',\n",
       "  'enables',\n",
       "  'them',\n",
       "  'to',\n",
       "  'charge',\n",
       "  'whatever',\n",
       "  'they',\n",
       "  'like',\n",
       "  'for',\n",
       "  'a',\n",
       "  'product',\n",
       "  'without',\n",
       "  'fear',\n",
       "  'of',\n",
       "  'competition',\n",
       "  '.',\n",
       "  'it',\n",
       "  'prices',\n",
       "  'the',\n",
       "  'poor',\n",
       "  'out',\n",
       "  'of',\n",
       "  'markets'],\n",
       " ['some',\n",
       "  'states',\n",
       "  'have',\n",
       "  'already',\n",
       "  'done',\n",
       "  'it',\n",
       "  'so',\n",
       "  'we',\n",
       "  'might',\n",
       "  'as',\n",
       "  'well',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'and',\n",
       "  'bear_arms',\n",
       "  'is',\n",
       "  'important',\n",
       "  'in',\n",
       "  'keeping',\n",
       "  'people',\n",
       "  'safe',\n",
       "  'in',\n",
       "  'a',\n",
       "  'dangerous',\n",
       "  'and',\n",
       "  'uncertain',\n",
       "  'world'],\n",
       " ['three',\n",
       "  'strikes',\n",
       "  'is',\n",
       "  'enough',\n",
       "  'opportunity',\n",
       "  'for',\n",
       "  'a',\n",
       "  'person',\n",
       "  'to',\n",
       "  'reform',\n",
       "  'their',\n",
       "  'behavior',\n",
       "  'and',\n",
       "  'become',\n",
       "  'a',\n",
       "  'law',\n",
       "  'abiding',\n",
       "  'citizen',\n",
       "  '.',\n",
       "  'after',\n",
       "  'three',\n",
       "  'strikes',\n",
       "  'a',\n",
       "  'person',\n",
       "  'has',\n",
       "  'proven',\n",
       "  'they',\n",
       "  'are',\n",
       "  'not',\n",
       "  'interested',\n",
       "  'in',\n",
       "  'conforming',\n",
       "  'to',\n",
       "  'societal',\n",
       "  'rules',\n",
       "  '.'],\n",
       " ['maintaining',\n",
       "  'intellectual_property',\n",
       "  'rights',\n",
       "  'for',\n",
       "  'all',\n",
       "  'is',\n",
       "  'too',\n",
       "  'expensive',\n",
       "  ',',\n",
       "  'and',\n",
       "  'maintaining',\n",
       "  'these',\n",
       "  'rights',\n",
       "  'might',\n",
       "  'restrict',\n",
       "  'innovation',\n",
       "  'in',\n",
       "  'certain',\n",
       "  'sectors',\n",
       "  '.'],\n",
       " ['this', 'should', 'be', 'banned', 'as', 'it', 'is', 'immoral', '.'],\n",
       " ['athletes',\n",
       "  'train',\n",
       "  'their',\n",
       "  'whole',\n",
       "  'lives',\n",
       "  'in',\n",
       "  'hopes',\n",
       "  'that',\n",
       "  'they',\n",
       "  'can',\n",
       "  'represent',\n",
       "  'their',\n",
       "  'country',\n",
       "  'to',\n",
       "  'be',\n",
       "  'the',\n",
       "  'best',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'adopt',\n",
       "  'an',\n",
       "  'austerity_regime',\n",
       "  'so',\n",
       "  'that',\n",
       "  'future',\n",
       "  'generations',\n",
       "  'are',\n",
       "  'not',\n",
       "  'left',\n",
       "  't0',\n",
       "  'pay',\n",
       "  'the',\n",
       "  'debts',\n",
       "  'that',\n",
       "  'we',\n",
       "  'rack',\n",
       "  'up',\n",
       "  '.'],\n",
       " ['allowing',\n",
       "  'cosmetic_surgery',\n",
       "  'for',\n",
       "  'minors',\n",
       "  'would',\n",
       "  'simply',\n",
       "  'sweep',\n",
       "  'the',\n",
       "  'real',\n",
       "  'problem',\n",
       "  'under',\n",
       "  'the',\n",
       "  'rug',\n",
       "  ':',\n",
       "  'the',\n",
       "  'effect',\n",
       "  'of',\n",
       "  'toxic',\n",
       "  'appearance',\n",
       "  'standards',\n",
       "  '.'],\n",
       " ['other',\n",
       "  'languages',\n",
       "  'such',\n",
       "  'as',\n",
       "  'spanish',\n",
       "  'and',\n",
       "  'french',\n",
       "  'have',\n",
       "  'even',\n",
       "  'more',\n",
       "  'gendered',\n",
       "  'language',\n",
       "  'than',\n",
       "  'we',\n",
       "  'do',\n",
       "  ',',\n",
       "  'and',\n",
       "  'they',\n",
       "  'have',\n",
       "  'no',\n",
       "  'problems'],\n",
       " ['telemarketing',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned',\n",
       "  'because',\n",
       "  'it',\n",
       "  'is',\n",
       "  'disruptive',\n",
       "  'to',\n",
       "  'the',\n",
       "  'course',\n",
       "  'of',\n",
       "  'the',\n",
       "  'day',\n",
       "  'for',\n",
       "  'many',\n",
       "  'people',\n",
       "  '.'],\n",
       " ['wikipedia',\n",
       "  'would',\n",
       "  'be',\n",
       "  'more',\n",
       "  'accurate',\n",
       "  'if',\n",
       "  'it',\n",
       "  'was',\n",
       "  'subsidized',\n",
       "  '.'],\n",
       " ['missionary_work',\n",
       "  'can',\n",
       "  'sometimes',\n",
       "  'provide',\n",
       "  'communities',\n",
       "  'in',\n",
       "  'need',\n",
       "  'around',\n",
       "  'the',\n",
       "  'world',\n",
       "  'with',\n",
       "  'access',\n",
       "  'to',\n",
       "  'education',\n",
       "  'and',\n",
       "  'resources',\n",
       "  '.'],\n",
       " ['whaling', 'kills', 'whales', 'in', 'an', 'inhumane', 'way'],\n",
       " ['childrens',\n",
       "  \"'\",\n",
       "  'bodies',\n",
       "  'are',\n",
       "  'constantly',\n",
       "  'changing',\n",
       "  ' ',\n",
       "  'throughout',\n",
       "  'childhood',\n",
       "  'so',\n",
       "  'that',\n",
       "  ',',\n",
       "  'cosmetic_surgery',\n",
       "  'may',\n",
       "  'be',\n",
       "  'used',\n",
       "  'to',\n",
       "  'alter',\n",
       "  'an',\n",
       "  'disliked',\n",
       "  'part',\n",
       "  'of',\n",
       "  'the',\n",
       "  'body',\n",
       "  'when',\n",
       "  'it',\n",
       "  'may',\n",
       "  'change',\n",
       "  'anyway',\n",
       "  ',',\n",
       "  'resulting',\n",
       "  'in',\n",
       "  'unnecessary',\n",
       "  'surgery'],\n",
       " ['targeted_killing',\n",
       "  'surgically',\n",
       "  'removes',\n",
       "  'enemy',\n",
       "  'actors',\n",
       "  'with',\n",
       "  'no',\n",
       "  'collateral',\n",
       "  'damage',\n",
       "  ',',\n",
       "  'it',\n",
       "  'must',\n",
       "  'be',\n",
       "  'continued',\n",
       "  '.'],\n",
       " ['missionary_work', 'is', 'dangerous', 'and', 'not', 'necessary'],\n",
       " ['autonomous_cars',\n",
       "  'can',\n",
       "  'give',\n",
       "  'many',\n",
       "  'people',\n",
       "  'the',\n",
       "  'freedom',\n",
       "  'to',\n",
       "  'drive',\n",
       "  'without',\n",
       "  'actually',\n",
       "  'driving',\n",
       "  ',',\n",
       "  'so',\n",
       "  'we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'stop',\n",
       "  'making',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['this',\n",
       "  'is',\n",
       "  'a',\n",
       "  'free',\n",
       "  'country',\n",
       "  '.',\n",
       "  'people',\n",
       "  'are',\n",
       "  'free',\n",
       "  'to',\n",
       "  'make',\n",
       "  'bad',\n",
       "  'nutritional',\n",
       "  'decisions'],\n",
       " ['pride_parades',\n",
       "  'cause',\n",
       "  'more',\n",
       "  'trouble',\n",
       "  'by',\n",
       "  'singling',\n",
       "  'out',\n",
       "  'those',\n",
       "  'who',\n",
       "  'are',\n",
       "  'different',\n",
       "  '.'],\n",
       " ['development',\n",
       "  'of',\n",
       "  'autonomous',\n",
       "  'car',\n",
       "  'will',\n",
       "  'make',\n",
       "  'traffic',\n",
       "  'and',\n",
       "  'parking',\n",
       "  ' ',\n",
       "  'easier'],\n",
       " ['to',\n",
       "  'pick',\n",
       "  'out',\n",
       "  'one',\n",
       "  'religion',\n",
       "  'out',\n",
       "  'of',\n",
       "  'many',\n",
       "  'to',\n",
       "  'ban',\n",
       "  'would',\n",
       "  'be',\n",
       "  'an',\n",
       "  'infringement',\n",
       "  'of',\n",
       "  'the',\n",
       "  'freedom',\n",
       "  'to',\n",
       "  'practice',\n",
       "  'any',\n",
       "  'religion',\n",
       "  'of',\n",
       "  'your',\n",
       "  'choosing',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'adopt',\n",
       "  'libertarianism',\n",
       "  'for',\n",
       "  'fear',\n",
       "  'of',\n",
       "  'the',\n",
       "  'threat',\n",
       "  'to',\n",
       "  'law',\n",
       "  'and',\n",
       "  'order',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'olympic_games',\n",
       "  'brings',\n",
       "  'together',\n",
       "  'the',\n",
       "  'world',\n",
       "  'in',\n",
       "  'a',\n",
       "  'peaceful',\n",
       "  'environment'],\n",
       " ['banning',\n",
       "  'child_actors',\n",
       "  'would',\n",
       "  'limit',\n",
       "  'movies',\n",
       "  'and',\n",
       "  'tv',\n",
       "  'shows',\n",
       "  '.',\n",
       "  'anything',\n",
       "  'with',\n",
       "  'children',\n",
       "  'in',\n",
       "  'the',\n",
       "  'story',\n",
       "  'would',\n",
       "  'be',\n",
       "  'unable',\n",
       "  'to',\n",
       "  'be',\n",
       "  'made',\n",
       "  '.',\n",
       "  'television',\n",
       "  'and',\n",
       "  'movies',\n",
       "  'for',\n",
       "  'children',\n",
       "  'would',\n",
       "  'no',\n",
       "  'longer',\n",
       "  'exist',\n",
       "  'either',\n",
       "  '.'],\n",
       " ['private_military',\n",
       "  'companies',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned',\n",
       "  'they',\n",
       "  'often',\n",
       "  'act',\n",
       "  'as',\n",
       "  'mercenaries',\n",
       "  'and',\n",
       "  'ca',\n",
       "  'nt',\n",
       "  'be',\n",
       "  'regulated'],\n",
       " ['journalism',\n",
       "  'plays',\n",
       "  'an',\n",
       "  'essential',\n",
       "  'role',\n",
       "  'as',\n",
       "  'watchdog',\n",
       "  'of',\n",
       "  'democracy',\n",
       "  ',',\n",
       "  'and',\n",
       "  'keeping',\n",
       "  'citizens',\n",
       "  'informed',\n",
       "  '.',\n",
       "  'such',\n",
       "  'a',\n",
       "  'valuable',\n",
       "  'industry',\n",
       "  'deserves',\n",
       "  'government',\n",
       "  'subsidization',\n",
       "  '.'],\n",
       " ['people',\n",
       "  'are',\n",
       "  'more',\n",
       "  'likely',\n",
       "  'to',\n",
       "  'share',\n",
       "  'their',\n",
       "  'organs',\n",
       "  'if',\n",
       "  'there',\n",
       "  'is',\n",
       "  'financial',\n",
       "  'benefit',\n",
       "  'to',\n",
       "  'them',\n",
       "  ',',\n",
       "  'increasing',\n",
       "  'supply',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'cancel',\n",
       "  'pride_parades',\n",
       "  'because',\n",
       "  'people',\n",
       "  'should',\n",
       "  'have',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'express',\n",
       "  'what',\n",
       "  'they',\n",
       "  'want',\n",
       "  ',',\n",
       "  'and',\n",
       "  'how',\n",
       "  'they',\n",
       "  'feel',\n",
       "  'about',\n",
       "  'a',\n",
       "  'certain',\n",
       "  'issue',\n",
       "  '.'],\n",
       " ['student_loans',\n",
       "  'enable',\n",
       "  'poor',\n",
       "  'students',\n",
       "  'to',\n",
       "  'continue',\n",
       "  'with',\n",
       "  'their',\n",
       "  'education',\n",
       "  'and',\n",
       "  'graduate',\n",
       "  'from',\n",
       "  'the',\n",
       "  'university'],\n",
       " ['it', 'is', 'the', 'most', 'efficient', 'way', 'to', 'produce', 'food'],\n",
       " ['three',\n",
       "  'strikes_laws',\n",
       "  'ruin',\n",
       "  'young',\n",
       "  'people',\n",
       "  \"'s\",\n",
       "  'lives',\n",
       "  'by',\n",
       "  'preventing',\n",
       "  'them',\n",
       "  'from',\n",
       "  'being',\n",
       "  'accessing',\n",
       "  'education',\n",
       "  'and',\n",
       "  'jobs',\n",
       "  'that',\n",
       "  'would',\n",
       "  'pull',\n",
       "  'them',\n",
       "  'out',\n",
       "  'of',\n",
       "  'a',\n",
       "  'life',\n",
       "  'of',\n",
       "  'crime',\n",
       "  'by',\n",
       "  'prolonging',\n",
       "  'their',\n",
       "  'time',\n",
       "  'in',\n",
       "  'jail',\n",
       "  'during',\n",
       "  'their',\n",
       "  'formative',\n",
       "  'years',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'church',\n",
       "  'of',\n",
       "  'scientology',\n",
       "  'is',\n",
       "  'a',\n",
       "  'cult',\n",
       "  'and',\n",
       "  'it',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned',\n",
       "  '.'],\n",
       " ['safe_spaces',\n",
       "  'create',\n",
       "  'an',\n",
       "  'unrealistic',\n",
       "  'environment',\n",
       "  'that',\n",
       "  'does',\n",
       "  \"n't\",\n",
       "  'exist',\n",
       "  'in',\n",
       "  'the',\n",
       "  'real',\n",
       "  'world',\n",
       "  '.'],\n",
       " ['just',\n",
       "  'because',\n",
       "  'someone',\n",
       "  'has',\n",
       "  'reached',\n",
       "  'the',\n",
       "  'age',\n",
       "  'of',\n",
       "  'retirement',\n",
       "  ',',\n",
       "  'they',\n",
       "  'are',\n",
       "  'still',\n",
       "  'able',\n",
       "  'to',\n",
       "  'provide',\n",
       "  'a',\n",
       "  'vaulable',\n",
       "  'service',\n",
       "  'with',\n",
       "  'expertise',\n",
       "  'and',\n",
       "  'a',\n",
       "  'vast',\n",
       "  'knowledge',\n",
       "  'of',\n",
       "  'experience',\n",
       "  '.'],\n",
       " ['if',\n",
       "  'a',\n",
       "  'company',\n",
       "  'has',\n",
       "  'received',\n",
       "  'enough',\n",
       "  'profits',\n",
       "  'to',\n",
       "  'offer',\n",
       "  'bonuses',\n",
       "  'to',\n",
       "  'their',\n",
       "  'executives',\n",
       "  ',',\n",
       "  'the',\n",
       "  'money',\n",
       "  'could',\n",
       "  'be',\n",
       "  'better',\n",
       "  'spent',\n",
       "  'on',\n",
       "  'giving',\n",
       "  'bonuses',\n",
       "  'to',\n",
       "  'poorer',\n",
       "  'staff',\n",
       "  'members',\n",
       "  'at',\n",
       "  'the',\n",
       "  'bottom',\n",
       "  'of',\n",
       "  'the',\n",
       "  'chain',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  \"n't\",\n",
       "  'adopt',\n",
       "  'a',\n",
       "  'zero',\n",
       "  '-',\n",
       "  'tolerance_policy',\n",
       "  'in',\n",
       "  'schools',\n",
       "  'because',\n",
       "  'a',\n",
       "  'misunderstanding',\n",
       "  'can',\n",
       "  'cause',\n",
       "  'innocent',\n",
       "  'students',\n",
       "  'to',\n",
       "  'be',\n",
       "  'suspended',\n",
       "  'or',\n",
       "  'expelled'],\n",
       " ['sex_selection',\n",
       "  'should',\n",
       "  'be',\n",
       "  'allowed',\n",
       "  'to',\n",
       "  'those',\n",
       "  'who',\n",
       "  'want',\n",
       "  'a',\n",
       "  'certain',\n",
       "  'gender',\n",
       "  '.'],\n",
       " ['economic_sanctions',\n",
       "  'are',\n",
       "  'an',\n",
       "  'effective',\n",
       "  'way',\n",
       "  'to',\n",
       "  'signify',\n",
       "  'that',\n",
       "  'human',\n",
       "  'rights',\n",
       "  'abuses',\n",
       "  'will',\n",
       "  'not',\n",
       "  'be',\n",
       "  'tolerated',\n",
       "  '.'],\n",
       " ['a',\n",
       "  'multi',\n",
       "  '-',\n",
       "  'party_system',\n",
       "  'would',\n",
       "  'bring',\n",
       "  'in',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'more',\n",
       "  'choice',\n",
       "  'of',\n",
       "  'representation',\n",
       "  'for',\n",
       "  'the',\n",
       "  'people',\n",
       "  'living',\n",
       "  'in',\n",
       "  'the',\n",
       "  'country',\n",
       "  '.'],\n",
       " ['atheism',\n",
       "  'should',\n",
       "  'be',\n",
       "  'adopted',\n",
       "  'because',\n",
       "  'many',\n",
       "  'people',\n",
       "  'do',\n",
       "  'not',\n",
       "  'believe',\n",
       "  'in',\n",
       "  'god',\n",
       "  'or',\n",
       "  'a',\n",
       "  'higher',\n",
       "  'power',\n",
       "  ','],\n",
       " ['school',\n",
       "  'uniformlimits',\n",
       "  'a',\n",
       "  'childs',\n",
       "  'ability',\n",
       "  'to',\n",
       "  'express',\n",
       "  'themselves',\n",
       "  ',',\n",
       "  'experiment',\n",
       "  'and',\n",
       "  'develop',\n",
       "  'as',\n",
       "  'a',\n",
       "  'person'],\n",
       " ['zero',\n",
       "  '-',\n",
       "  'tolerance',\n",
       "  'must',\n",
       "  'be',\n",
       "  'mandatory',\n",
       "  'in',\n",
       "  'school',\n",
       "  'and',\n",
       "  'is',\n",
       "  'only',\n",
       "  'way',\n",
       "  'to',\n",
       "  'stop',\n",
       "  'negative',\n",
       "  'stuff',\n",
       "  'which',\n",
       "  'happens',\n",
       "  'so',\n",
       "  'often',\n",
       "  'in',\n",
       "  'schools',\n",
       "  '.'],\n",
       " ['algorithmic_trading',\n",
       "  'can',\n",
       "  'operate',\n",
       "  '24',\n",
       "  'hours',\n",
       "  'a',\n",
       "  'day',\n",
       "  '.',\n",
       "  'while',\n",
       "  'you',\n",
       "  'sleep',\n",
       "  ',',\n",
       "  'your',\n",
       "  'algorithms',\n",
       "  'are',\n",
       "  'making',\n",
       "  'you',\n",
       "  'money',\n",
       "  '.'],\n",
       " ['however',\n",
       "  'these',\n",
       "  'policies',\n",
       "  'can',\n",
       "  'impede',\n",
       "  'the',\n",
       "  'advancement',\n",
       "  'of',\n",
       "  'children',\n",
       "  'from',\n",
       "  'troubled',\n",
       "  'backgrounds',\n",
       "  'or',\n",
       "  'with',\n",
       "  'additional',\n",
       "  'needs',\n",
       "  '.',\n",
       "  'they',\n",
       "  'need',\n",
       "  'a',\n",
       "  'safe',\n",
       "  'place',\n",
       "  'to',\n",
       "  'learn',\n",
       "  'in',\n",
       "  'a',\n",
       "  'positive',\n",
       "  'behaviours',\n",
       "  'in',\n",
       "  'a',\n",
       "  'supportive',\n",
       "  'environment',\n",
       "  '.'],\n",
       " ['human',\n",
       "  'beings',\n",
       "  'were',\n",
       "  'created',\n",
       "  'to',\n",
       "  'be',\n",
       "  'individuals',\n",
       "  'unlike',\n",
       "  'no',\n",
       "  'other',\n",
       "  '.'],\n",
       " ['cosmetic_surgery',\n",
       "  'can',\n",
       "  'sometimes',\n",
       "  'cause',\n",
       "  'harm',\n",
       "  'and',\n",
       "  'disasterous',\n",
       "  'results',\n",
       "  '.'],\n",
       " ['cosmetic_surgery',\n",
       "  'only',\n",
       "  'serves',\n",
       "  'to',\n",
       "  'perpetuate',\n",
       "  'eurocentric',\n",
       "  'standards',\n",
       "  'of',\n",
       "  'beauty',\n",
       "  'and',\n",
       "  'makes',\n",
       "  'it',\n",
       "  'more',\n",
       "  'difficult',\n",
       "  'to',\n",
       "  'challenge',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['someone',\n",
       "  'should',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'continue',\n",
       "  'working',\n",
       "  'if',\n",
       "  'they',\n",
       "  'want',\n",
       "  ',',\n",
       "  'despite',\n",
       "  'their',\n",
       "  'age',\n",
       "  '.'],\n",
       " ['fast_food', 'threatens', 'the', 'health', 'of', 'many', 'americans', '.'],\n",
       " ['algorithmic_trading',\n",
       "  'is',\n",
       "  'unfair',\n",
       "  'and',\n",
       "  'does',\n",
       "  \"n't\",\n",
       "  'allow',\n",
       "  'for',\n",
       "  'the',\n",
       "  'individual',\n",
       "  'to',\n",
       "  'make',\n",
       "  'money',\n",
       "  'that',\n",
       "  'does',\n",
       "  \"n't\",\n",
       "  'have',\n",
       "  'the',\n",
       "  'algorithim',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'inaccurate',\n",
       "  'and',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'funded',\n",
       "  'by',\n",
       "  'government',\n",
       "  'money',\n",
       "  '.'],\n",
       " ['some',\n",
       "  'crimes',\n",
       "  'are',\n",
       "  'so',\n",
       "  'heinous',\n",
       "  'that',\n",
       "  'the',\n",
       "  'only',\n",
       "  'just',\n",
       "  'punishment',\n",
       "  'is',\n",
       "  'the',\n",
       "  'death',\n",
       "  'penalty',\n",
       "  '.'],\n",
       " ['ending',\n",
       "  'economic_sanctions',\n",
       "  'would',\n",
       "  'make',\n",
       "  'it',\n",
       "  'so',\n",
       "  'all',\n",
       "  'countries',\n",
       "  'could',\n",
       "  'trade',\n",
       "  'freely',\n",
       "  'with',\n",
       "  'anyone',\n",
       "  '.'],\n",
       " ['when',\n",
       "  'people',\n",
       "  'mess',\n",
       "  'with',\n",
       "  'mother',\n",
       "  'nature',\n",
       "  'by',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'select',\n",
       "  'the',\n",
       "  'sex',\n",
       "  'of',\n",
       "  'their',\n",
       "  'child',\n",
       "  ',',\n",
       "  'only',\n",
       "  'bad',\n",
       "  'things',\n",
       "  'can',\n",
       "  'happen',\n",
       "  '.'],\n",
       " ['safe_spaces',\n",
       "  'are',\n",
       "  'important',\n",
       "  'for',\n",
       "  'those',\n",
       "  'who',\n",
       "  'do',\n",
       "  'not',\n",
       "  'feel',\n",
       "  'included',\n",
       "  'or',\n",
       "  'feel',\n",
       "  'threatened'],\n",
       " ['the',\n",
       "  'three',\n",
       "  '-',\n",
       "  'strikes_laws',\n",
       "  'offer',\n",
       "  'clarity',\n",
       "  ',',\n",
       "  'and',\n",
       "  'their',\n",
       "  'mandatory',\n",
       "  'nature',\n",
       "  'makes',\n",
       "  'punishment',\n",
       "  'certain',\n",
       "  ',',\n",
       "  'these',\n",
       "  'laws',\n",
       "  'prevent',\n",
       "  'inconsistency',\n",
       "  'in',\n",
       "  'the',\n",
       "  'criminal',\n",
       "  'justice',\n",
       "  'system'],\n",
       " ['sex_selection', 'promotes', 'abortion', 'and', 'gender', 'inequality'],\n",
       " ['children',\n",
       "  'should',\n",
       "  'be',\n",
       "  'at',\n",
       "  'school',\n",
       "  'and',\n",
       "  'not',\n",
       "  'working',\n",
       "  '.',\n",
       "  'we',\n",
       "  'do',\n",
       "  'not',\n",
       "  'allow',\n",
       "  'children',\n",
       "  'to',\n",
       "  'work',\n",
       "  'in',\n",
       "  'any',\n",
       "  'other',\n",
       "  'way',\n",
       "  'and',\n",
       "  'acting',\n",
       "  'should',\n",
       "  'be',\n",
       "  'no',\n",
       "  'different',\n",
       "  '.'],\n",
       " ['zoos',\n",
       "  'are',\n",
       "  'inherently',\n",
       "  'cruel',\n",
       "  'to',\n",
       "  'the',\n",
       "  'animals',\n",
       "  ',',\n",
       "  'keeping',\n",
       "  'them',\n",
       "  'confined',\n",
       "  'in',\n",
       "  'unnatural',\n",
       "  'conditions',\n",
       "  'for',\n",
       "  'the',\n",
       "  'benefit',\n",
       "  'of',\n",
       "  'entertaining',\n",
       "  'human',\n",
       "  'visitors',\n",
       "  '-',\n",
       "  'they',\n",
       "  'are',\n",
       "  'miserable',\n",
       "  ',',\n",
       "  'and',\n",
       "  'more',\n",
       "  'prone',\n",
       "  'to',\n",
       "  'disease',\n",
       "  '.'],\n",
       " ['legalizing',\n",
       "  'prostitution',\n",
       "  'will',\n",
       "  'allow',\n",
       "  'prostitutes',\n",
       "  'to',\n",
       "  'push',\n",
       "  'for',\n",
       "  'equitable',\n",
       "  'contracts',\n",
       "  'and',\n",
       "  'conditions',\n",
       "  ',',\n",
       "  'something',\n",
       "  'they',\n",
       "  'ca',\n",
       "  \"n't\",\n",
       "  'do',\n",
       "  'in',\n",
       "  'the',\n",
       "  'status',\n",
       "  'quo',\n",
       "  'since',\n",
       "  'their',\n",
       "  'work',\n",
       "  'is',\n",
       "  'illegal',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'abolish',\n",
       "  'zoos',\n",
       "  'as',\n",
       "  'they',\n",
       "  'contribute',\n",
       "  'to',\n",
       "  'the',\n",
       "  'breeding',\n",
       "  'of',\n",
       "  'endangered',\n",
       "  'species',\n",
       "  'and',\n",
       "  'the',\n",
       "  'reintroduction',\n",
       "  'of',\n",
       "  'animals',\n",
       "  'to',\n",
       "  'the',\n",
       "  'wild'],\n",
       " ['promotes', 'peace', 'and', 'sportsmanship', 'amongst', 'countries'],\n",
       " ['cosmetic_surgery',\n",
       "  'creates',\n",
       "  'a',\n",
       "  'great',\n",
       "  'desire',\n",
       "  'for',\n",
       "  'physical',\n",
       "  'improvement',\n",
       "  'that',\n",
       "  'leads',\n",
       "  'to',\n",
       "  'an',\n",
       "  'endless',\n",
       "  'loop',\n",
       "  'of',\n",
       "  'body',\n",
       "  'adjustments',\n",
       "  'which',\n",
       "  'has',\n",
       "  'a',\n",
       "  'detrimental',\n",
       "  'effect',\n",
       "  'on',\n",
       "  'the',\n",
       "  'individual',\n",
       "  '.'],\n",
       " ['intellectual_property', 'rights', 'protect', 'inventors', '.'],\n",
       " ['judicial_activism',\n",
       "  ',',\n",
       "  ' ',\n",
       "  'bringing',\n",
       "  'a',\n",
       "  'personal',\n",
       "  'touch',\n",
       "  'of',\n",
       "  'the',\n",
       "  'judge',\n",
       "  ',',\n",
       "  ' ',\n",
       "  'is',\n",
       "  ' ',\n",
       "  'the',\n",
       "  'best',\n",
       "  'way',\n",
       "  'to',\n",
       "  'apply',\n",
       "  'laws',\n",
       "  'and',\n",
       "  'rules',\n",
       "  'for',\n",
       "  'our',\n",
       "  'society',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'not',\n",
       "  'humane',\n",
       "  'to',\n",
       "  'animals',\n",
       "  'and',\n",
       "  'needs',\n",
       "  'to',\n",
       "  'be',\n",
       "  'stopped',\n",
       "  '.'],\n",
       " ['human_cloning',\n",
       "  'is',\n",
       "  'simply',\n",
       "  'another',\n",
       "  'avenue',\n",
       "  'of',\n",
       "  'science',\n",
       "  'to',\n",
       "  'explore',\n",
       "  ',',\n",
       "  'and',\n",
       "  'it',\n",
       "  'is',\n",
       "  'vital',\n",
       "  'to',\n",
       "  'push',\n",
       "  'back',\n",
       "  'the',\n",
       "  'boundaries',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'open',\n",
       "  'up',\n",
       "  'possible',\n",
       "  'potential',\n",
       "  'cures',\n",
       "  'for',\n",
       "  'disease',\n",
       "  'and',\n",
       "  'medical',\n",
       "  'issues',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'subsidize',\n",
       "  'student_loans',\n",
       "  'to',\n",
       "  'ensure',\n",
       "  'all',\n",
       "  'who',\n",
       "  'seek',\n",
       "  'a',\n",
       "  'good',\n",
       "  'education',\n",
       "  'can',\n",
       "  'obtain',\n",
       "  'one',\n",
       "  '.',\n",
       "  'this',\n",
       "  'sets',\n",
       "  'up',\n",
       "  'success',\n",
       "  'for',\n",
       "  'life',\n",
       "  'which',\n",
       "  'also',\n",
       "  'saves',\n",
       "  'the',\n",
       "  'government',\n",
       "  'money',\n",
       "  'when',\n",
       "  'people',\n",
       "  'are',\n",
       "  'self',\n",
       "  'sufficient'],\n",
       " ['minors', 'are', 'too', 'immature', 'to', 'make', 'this', 'decision'],\n",
       " ['targeted_killing',\n",
       "  'may',\n",
       "  'be',\n",
       "  'necessary',\n",
       "  'in',\n",
       "  'very',\n",
       "  'limited',\n",
       "  'circumstances',\n",
       "  'where',\n",
       "  'there',\n",
       "  'is',\n",
       "  'an',\n",
       "  'immediate',\n",
       "  'threat',\n",
       "  'to',\n",
       "  'life',\n",
       "  'of',\n",
       "  'civilians',\n",
       "  'or',\n",
       "  'military',\n",
       "  'personnel'],\n",
       " ['executive_compensation',\n",
       "  'could',\n",
       "  'encourage',\n",
       "  'money',\n",
       "  'laundering',\n",
       "  'and',\n",
       "  'corruption'],\n",
       " ['we',\n",
       "  'should',\n",
       "  ' ',\n",
       "  'not',\n",
       "  'ban',\n",
       "  'targeted_killing',\n",
       "  ',',\n",
       "  'it',\n",
       "  'prevents',\n",
       "  'mass',\n",
       "  'military',\n",
       "  'campaigns',\n",
       "  'and',\n",
       "  'minimises',\n",
       "  'casualties'],\n",
       " ['people',\n",
       "  'should',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'choose',\n",
       "  'what',\n",
       "  'they',\n",
       "  'want',\n",
       "  'to',\n",
       "  'eat'],\n",
       " ['it',\n",
       "  'makes',\n",
       "  'a',\n",
       "  'school',\n",
       "  'a',\n",
       "  'safe',\n",
       "  'place',\n",
       "  'for',\n",
       "  'children',\n",
       "  'to',\n",
       "  'learn'],\n",
       " ['private_military',\n",
       "  'companies',\n",
       "  'are',\n",
       "  'a',\n",
       "  'risk',\n",
       "  'to',\n",
       "  'the',\n",
       "  'general',\n",
       "  'public',\n",
       "  'as',\n",
       "  'they',\n",
       "  'are',\n",
       "  'not',\n",
       "  'regulated',\n",
       "  'and',\n",
       "  'therefore',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned'],\n",
       " ['space_exploration',\n",
       "  'needs',\n",
       "  'our',\n",
       "  'support',\n",
       "  'to',\n",
       "  'help',\n",
       "  'us',\n",
       "  'understand',\n",
       "  'the',\n",
       "  'universe',\n",
       "  'and',\n",
       "  'our',\n",
       "  'place',\n",
       "  'in',\n",
       "  'it',\n",
       "  '.'],\n",
       " ['whaling', 'is', 'inhumane', 'and', 'should', 'be', 'banned', '.'],\n",
       " ['there',\n",
       "  'is',\n",
       "  'not',\n",
       "  'need',\n",
       "  'to',\n",
       "  'subsidize',\n",
       "  'wikipedia',\n",
       "  ',',\n",
       "  'it',\n",
       "  'does',\n",
       "  'not',\n",
       "  'serve',\n",
       "  'any',\n",
       "  'purpose',\n",
       "  'that',\n",
       "  'can',\n",
       "  'not',\n",
       "  'be',\n",
       "  'filled',\n",
       "  'elsewhere',\n",
       "  '.'],\n",
       " ['judges',\n",
       "  'who',\n",
       "  'rule',\n",
       "  'based',\n",
       "  'on',\n",
       "  'their',\n",
       "  'own',\n",
       "  'personal',\n",
       "  'and',\n",
       "  'political',\n",
       "  'beliefs',\n",
       "  'usurp',\n",
       "  'the',\n",
       "  'power',\n",
       "  'of',\n",
       "  'our',\n",
       "  'elected',\n",
       "  'officials',\n",
       "  'and',\n",
       "  'are',\n",
       "  'violating',\n",
       "  'our',\n",
       "  'constitutional',\n",
       "  'rights',\n",
       "  ','],\n",
       " ['targeted_killing',\n",
       "  'makes',\n",
       "  'the',\n",
       "  'world',\n",
       "  'a',\n",
       "  'safer',\n",
       "  'place',\n",
       "  'removing',\n",
       "  'those',\n",
       "  'people',\n",
       "  'who',\n",
       "  'aim',\n",
       "  'to',\n",
       "  'harm',\n",
       "  'others'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'ban',\n",
       "  'human_cloning',\n",
       "  'because',\n",
       "  'it',\n",
       "  'could',\n",
       "  'help',\n",
       "  'with',\n",
       "  'medical',\n",
       "  'research'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'legalize',\n",
       "  'sex_selection',\n",
       "  'as',\n",
       "  'this',\n",
       "  'is',\n",
       "  'playing',\n",
       "  'god',\n",
       "  'and',\n",
       "  'can',\n",
       "  'open',\n",
       "  'the',\n",
       "  'door',\n",
       "  'to',\n",
       "  'a',\n",
       "  'raft',\n",
       "  'of',\n",
       "  'other',\n",
       "  'genetic',\n",
       "  'selection',\n",
       "  'that',\n",
       "  'is',\n",
       "  'not',\n",
       "  'thoroughly',\n",
       "  'tested',\n",
       "  '.'],\n",
       " ['given',\n",
       "  'that',\n",
       "  'we',\n",
       "  'can',\n",
       "  'almost',\n",
       "  'never',\n",
       "  'guarantee',\n",
       "  'that',\n",
       "  'someone',\n",
       "  'is',\n",
       "  \"n't\",\n",
       "  'wrongly',\n",
       "  'convicted',\n",
       "  ',',\n",
       "  'we',\n",
       "  'should',\n",
       "  \"n't\",\n",
       "  'have',\n",
       "  'capital_punishment',\n",
       "  'because',\n",
       "  'it',\n",
       "  'ca',\n",
       "  \"n't\",\n",
       "  'be',\n",
       "  'undone',\n",
       "  'if',\n",
       "  'new',\n",
       "  'evidence',\n",
       "  'comes',\n",
       "  'out',\n",
       "  '.'],\n",
       " ['they',\n",
       "  'only',\n",
       "  'hurt',\n",
       "  'the',\n",
       "  'poorest',\n",
       "  'of',\n",
       "  'society',\n",
       "  'and',\n",
       "  'are',\n",
       "  'an',\n",
       "  'outdated',\n",
       "  'punishment',\n",
       "  '.'],\n",
       " ['so',\n",
       "  'often',\n",
       "  'these',\n",
       "  'creatures',\n",
       "  'are',\n",
       "  'butchered',\n",
       "  'to',\n",
       "  'death',\n",
       "  'for',\n",
       "  'one',\n",
       "  'small',\n",
       "  'part',\n",
       "  'of',\n",
       "  'their',\n",
       "  'anatomy',\n",
       "  'for',\n",
       "  'medicine',\n",
       "  'made',\n",
       "  'up',\n",
       "  'by',\n",
       "  'a',\n",
       "  'scam',\n",
       "  'doctor'],\n",
       " ['the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'school_uniforms',\n",
       "  'helps',\n",
       "  'the',\n",
       "  'poorest',\n",
       "  'to',\n",
       "  'attend',\n",
       "  'classes',\n",
       "  'without',\n",
       "  'the',\n",
       "  'problem',\n",
       "  'of',\n",
       "  'lack',\n",
       "  'of',\n",
       "  'clothing'],\n",
       " ['pride_parades',\n",
       "  'are',\n",
       "  'an',\n",
       "  'important',\n",
       "  'part',\n",
       "  'of',\n",
       "  'society',\n",
       "  'to',\n",
       "  'promote',\n",
       "  'freedom',\n",
       "  'of',\n",
       "  'choice',\n",
       "  ' ',\n",
       "  'and',\n",
       "  'acceptance',\n",
       "  '.'],\n",
       " ['space_exploration',\n",
       "  'is',\n",
       "  'a',\n",
       "  'waste',\n",
       "  'of',\n",
       "  'taxpayers',\n",
       "  'money',\n",
       "  'and',\n",
       "  'should',\n",
       "  'be',\n",
       "  'funded',\n",
       "  'by',\n",
       "  'private',\n",
       "  'enterprises',\n",
       "  '.'],\n",
       " ['zero',\n",
       "  '-',\n",
       "  'tolerance',\n",
       "  'policies',\n",
       "  'may',\n",
       "  'seem',\n",
       "  'unfair',\n",
       "  'to',\n",
       "  'the',\n",
       "  'individual',\n",
       "  'but',\n",
       "  'bad',\n",
       "  'and',\n",
       "  'risky',\n",
       "  'behavior',\n",
       "  'at',\n",
       "  'schools',\n",
       "  'spreads',\n",
       "  'faster',\n",
       "  'than',\n",
       "  'wildfire',\n",
       "  '.',\n",
       "  'sometimes',\n",
       "  'we',\n",
       "  'must',\n",
       "  'make',\n",
       "  'an',\n",
       "  'example',\n",
       "  'of',\n",
       "  'an',\n",
       "  'individual',\n",
       "  'for',\n",
       "  'the',\n",
       "  'greater',\n",
       "  'good',\n",
       "  '.'],\n",
       " ['everyone',\n",
       "  'has',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'alter',\n",
       "  'their',\n",
       "  'bodies',\n",
       "  'or',\n",
       "  'appearances',\n",
       "  'in',\n",
       "  'which',\n",
       "  'ever',\n",
       "  'way',\n",
       "  'makes',\n",
       "  'them',\n",
       "  'feel',\n",
       "  'comfortable',\n",
       "  'and',\n",
       "  'at',\n",
       "  'ease',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'ban',\n",
       "  'whaling',\n",
       "  'because',\n",
       "  'it',\n",
       "  'is',\n",
       "  'important',\n",
       "  'to',\n",
       "  'many',\n",
       "  'aboriginal',\n",
       "  'cultures',\n",
       "  'in',\n",
       "  'the',\n",
       "  'arctic',\n",
       "  ',',\n",
       "  'and',\n",
       "  'it',\n",
       "  'is',\n",
       "  'wrong',\n",
       "  'for',\n",
       "  'the',\n",
       "  'governments',\n",
       "  'of',\n",
       "  'countries',\n",
       "  'like',\n",
       "  'canada',\n",
       "  'and',\n",
       "  'russia',\n",
       "  'to',\n",
       "  'oppress',\n",
       "  'those',\n",
       "  'peoples',\n",
       "  '.'],\n",
       " ['humans',\n",
       "  'should',\n",
       "  \"n't\",\n",
       "  'colonize',\n",
       "  'space',\n",
       "  'until',\n",
       "  'we',\n",
       "  'learn',\n",
       "  'to',\n",
       "  'care',\n",
       "  'for',\n",
       "  'earth'],\n",
       " ['factory_farming',\n",
       "  'is',\n",
       "  'a',\n",
       "  'great',\n",
       "  'way',\n",
       "  'to',\n",
       "  'get',\n",
       "  'more',\n",
       "  'food',\n",
       "  'for',\n",
       "  'everyone'],\n",
       " ['mandatory_retirement',\n",
       "  'is',\n",
       "  'harsh',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'it',\n",
       "  'pushes',\n",
       "  'workers',\n",
       "  'who',\n",
       "  'might',\n",
       "  'still',\n",
       "  'be',\n",
       "  'viable',\n",
       "  'out',\n",
       "  'of',\n",
       "  'the',\n",
       "  'workforce',\n",
       "  'for',\n",
       "  'no',\n",
       "  'other',\n",
       "  'reason',\n",
       "  'than',\n",
       "  'their',\n",
       "  'age',\n",
       "  ',',\n",
       "  'often',\n",
       "  'leaving',\n",
       "  'them',\n",
       "  'to',\n",
       "  'struggle',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  ',',\n",
       "  'if',\n",
       "  'it',\n",
       "  \"'s\",\n",
       "  'subsidised',\n",
       "  'it',\n",
       "  'could',\n",
       "  'mean',\n",
       "  'better',\n",
       "  'journalism'],\n",
       " ['elections',\n",
       "  'are',\n",
       "  'supposed',\n",
       "  'to',\n",
       "  'be',\n",
       "  'won',\n",
       "  'by',\n",
       "  'the',\n",
       "  'opinion',\n",
       "  'of',\n",
       "  'the',\n",
       "  'people',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'if',\n",
       "  'only',\n",
       "  'a',\n",
       "  'select',\n",
       "  'few',\n",
       "  'people',\n",
       "  'vote',\n",
       "  ',',\n",
       "  'then',\n",
       "  'the',\n",
       "  'result',\n",
       "  'only',\n",
       "  'reflects',\n",
       "  'their',\n",
       "  'opinions',\n",
       "  ',',\n",
       "  'not',\n",
       "  'that',\n",
       "  'of',\n",
       "  'the',\n",
       "  'whole',\n",
       "  'population',\n",
       "  '.'],\n",
       " ['algorithmic_trading',\n",
       "  'allows',\n",
       "  'computers',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'and',\n",
       "  'sell',\n",
       "  'assets',\n",
       "  'suddenly',\n",
       "  'and',\n",
       "  'in',\n",
       "  'massive',\n",
       "  'quantities',\n",
       "  ',',\n",
       "  'creating',\n",
       "  'shifts',\n",
       "  'in',\n",
       "  'the',\n",
       "  'market',\n",
       "  'and',\n",
       "  'making',\n",
       "  'human',\n",
       "  'trading',\n",
       "  'difficult',\n",
       "  '.'],\n",
       " ['judicial_activism',\n",
       "  'should',\n",
       "  'be',\n",
       "  'limited',\n",
       "  'so',\n",
       "  'that',\n",
       "  'judgements',\n",
       "  'are',\n",
       "  'reached',\n",
       "  'based',\n",
       "  'on',\n",
       "  'factual',\n",
       "  'evidence',\n",
       "  'only',\n",
       "  '.',\n",
       "  'allowing',\n",
       "  'personal',\n",
       "  'opinions',\n",
       "  'to',\n",
       "  'cloud',\n",
       "  'the',\n",
       "  'issue',\n",
       "  'can',\n",
       "  'result',\n",
       "  'in',\n",
       "  'mis',\n",
       "  '-',\n",
       "  'trials',\n",
       "  'of',\n",
       "  'justice',\n",
       "  '.'],\n",
       " ['missionary_work',\n",
       "  'forces',\n",
       "  'the',\n",
       "  'opinions',\n",
       "  'of',\n",
       "  'others',\n",
       "  'onto',\n",
       "  'individuals',\n",
       "  'that',\n",
       "  'did',\n",
       "  \"n't\",\n",
       "  'consent',\n",
       "  'or',\n",
       "  'want',\n",
       "  'the',\n",
       "  'religion',\n",
       "  '.'],\n",
       " ['students',\n",
       "  'are',\n",
       "  'and',\n",
       "  'will',\n",
       "  'always',\n",
       "  'be',\n",
       "  'the',\n",
       "  'backbone',\n",
       "  'of',\n",
       "  'the',\n",
       "  'society',\n",
       "  '.',\n",
       "  'it',\n",
       "  \"'s\",\n",
       "  'compulsory',\n",
       "  'to',\n",
       "  'support',\n",
       "  'these',\n",
       "  'growing',\n",
       "  'students',\n",
       "  'in',\n",
       "  'becoming',\n",
       "  'true',\n",
       "  ',',\n",
       "  'well',\n",
       "  'educated',\n",
       "  'citizens',\n",
       "  'to',\n",
       "  'support',\n",
       "  'the',\n",
       "  'economy',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'abolish',\n",
       "  'safe_spaces',\n",
       "  'as',\n",
       "  'policing',\n",
       "  'these',\n",
       "  'areas',\n",
       "  'is',\n",
       "  'costly',\n",
       "  'and',\n",
       "  'it',\n",
       "  'is',\n",
       "  'against',\n",
       "  'human',\n",
       "  'rights',\n",
       "  'to',\n",
       "  'stop',\n",
       "  'freedom',\n",
       "  'of',\n",
       "  'movement',\n",
       "  'into',\n",
       "  'different',\n",
       "  'areas',\n",
       "  '.'],\n",
       " ['factory_farming',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned',\n",
       "  'as',\n",
       "  'it',\n",
       "  'is',\n",
       "  'an',\n",
       "  'unhealthy',\n",
       "  'and',\n",
       "  'uncaring',\n",
       "  'atmosphere',\n",
       "  'in',\n",
       "  'which',\n",
       "  'to',\n",
       "  'raise',\n",
       "  'animals',\n",
       "  'and',\n",
       "  'does',\n",
       "  \"n't\",\n",
       "  'result',\n",
       "  'in',\n",
       "  'a',\n",
       "  'good',\n",
       "  'quality',\n",
       "  'product',\n",
       "  'at',\n",
       "  'the',\n",
       "  'end',\n",
       "  '.'],\n",
       " ['students',\n",
       "  'that',\n",
       "  'work',\n",
       "  'hard',\n",
       "  'to',\n",
       "  'get',\n",
       "  'a',\n",
       "  'degree',\n",
       "  'should',\n",
       "  'not',\n",
       "  'start',\n",
       "  'out',\n",
       "  'their',\n",
       "  'journey',\n",
       "  'into',\n",
       "  'the',\n",
       "  'real',\n",
       "  'world',\n",
       "  ',',\n",
       "  'in',\n",
       "  'debt'],\n",
       " ['supporting',\n",
       "  'journalism',\n",
       "  'is',\n",
       "  'obligatory',\n",
       "  'in',\n",
       "  'our',\n",
       "  'democracy',\n",
       "  'society',\n",
       "  'and',\n",
       "  '`',\n",
       "  'free',\n",
       "  'speech',\n",
       "  '`',\n",
       "  'should',\n",
       "  'be',\n",
       "  'defended',\n",
       "  'and',\n",
       "  'approved',\n",
       "  'by',\n",
       "  'all',\n",
       "  'means',\n",
       "  '.'],\n",
       " ['targeted_killing',\n",
       "  'is',\n",
       "  'still',\n",
       "  'murder',\n",
       "  'even',\n",
       "  'if',\n",
       "  'it',\n",
       "  'is',\n",
       "  'sanctioned',\n",
       "  'by',\n",
       "  'a',\n",
       "  'country',\n",
       "  \"'s\",\n",
       "  'government'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'abolish',\n",
       "  'zoos',\n",
       "  'to',\n",
       "  'prevent',\n",
       "  'the',\n",
       "  'cruel',\n",
       "  'confinement',\n",
       "  'of',\n",
       "  'wild',\n",
       "  'animals'],\n",
       " ['when',\n",
       "  'prostitution',\n",
       "  'is',\n",
       "  'illegal',\n",
       "  ',',\n",
       "  'prostitutes',\n",
       "  'are',\n",
       "  'defenseless',\n",
       "  ',',\n",
       "  'and',\n",
       "  'are',\n",
       "  'often',\n",
       "  'harassed',\n",
       "  'and',\n",
       "  'abused',\n",
       "  '.'],\n",
       " ['lower',\n",
       "  'taxes',\n",
       "  'and',\n",
       "  'more',\n",
       "  'freedom',\n",
       "  'from',\n",
       "  'big',\n",
       "  'government',\n",
       "  'would',\n",
       "  'be',\n",
       "  'the',\n",
       "  'result',\n",
       "  'if',\n",
       "  'we',\n",
       "  'adopted',\n",
       "  'libertarianism',\n",
       "  '.'],\n",
       " ['embryonic_stem',\n",
       "  'cell_research',\n",
       "  'requires',\n",
       "  'the',\n",
       "  'destruction',\n",
       "  'of',\n",
       "  'human',\n",
       "  'embryos',\n",
       "  'and',\n",
       "  'so',\n",
       "  'is',\n",
       "  'considered',\n",
       "  'unethical',\n",
       "  'by',\n",
       "  'many',\n",
       "  'people'],\n",
       " ['everyone',\n",
       "  'has',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'bodily',\n",
       "  'autonomy',\n",
       "  '.',\n",
       "  'if',\n",
       "  'a',\n",
       "  'person',\n",
       "  'chooses',\n",
       "  'to',\n",
       "  'sell',\n",
       "  'his',\n",
       "  'or',\n",
       "  'her',\n",
       "  'body',\n",
       "  'for',\n",
       "  'sex',\n",
       "  ',',\n",
       "  'it',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'illegal',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'adopt',\n",
       "  'atheism',\n",
       "  'because',\n",
       "  'for',\n",
       "  'decades',\n",
       "  'we',\n",
       "  'have',\n",
       "  'proven',\n",
       "  'with',\n",
       "  'science',\n",
       "  'that',\n",
       "  'religious',\n",
       "  'explanations',\n",
       "  'are',\n",
       "  'incorrect'],\n",
       " ['zoos',\n",
       "  'provide',\n",
       "  'the',\n",
       "  'only',\n",
       "  'places',\n",
       "  'for',\n",
       "  'some',\n",
       "  'endangered',\n",
       "  'species',\n",
       "  'to',\n",
       "  'survive',\n",
       "  'that',\n",
       "  'they',\n",
       "  'are',\n",
       "  'essential',\n",
       "  'and',\n",
       "  'we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'abolish',\n",
       "  'them',\n",
       "  'we',\n",
       "  'need',\n",
       "  'to',\n",
       "  'support',\n",
       "  'them',\n",
       "  'and',\n",
       "  'their',\n",
       "  'breeding',\n",
       "  'programs',\n",
       "  '.'],\n",
       " ['pride_parades',\n",
       "  'have',\n",
       "  'now',\n",
       "  'grown',\n",
       "  'to',\n",
       "  'the',\n",
       "  'point',\n",
       "  'where',\n",
       "  'they',\n",
       "  'are',\n",
       "  'increasingly',\n",
       "  'difficult',\n",
       "  'to',\n",
       "  'police',\n",
       "  'and',\n",
       "  'the',\n",
       "  'scale',\n",
       "  'of',\n",
       "  'the',\n",
       "  'events',\n",
       "  'now',\n",
       "  'need',\n",
       "  'to',\n",
       "  'be',\n",
       "  'looked',\n",
       "  'at',\n",
       "  'to',\n",
       "  'ensure',\n",
       "  'the',\n",
       "  'safety',\n",
       "  'of',\n",
       "  'all',\n",
       "  'participants',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'ban',\n",
       "  'this',\n",
       "  'because',\n",
       "  'they',\n",
       "  'ca',\n",
       "  'nt',\n",
       "  'be',\n",
       "  'controlled',\n",
       "  'and',\n",
       "  'could',\n",
       "  'turn',\n",
       "  'against',\n",
       "  'the',\n",
       "  'government',\n",
       "  'or',\n",
       "  'people',\n",
       "  '.',\n",
       "  'they',\n",
       "  'also',\n",
       "  'might',\n",
       "  'cause',\n",
       "  'more',\n",
       "  'problems',\n",
       "  'then',\n",
       "  'help',\n",
       "  'solve',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['intellectual_property',\n",
       "  'rights',\n",
       "  'slows',\n",
       "  'down',\n",
       "  'the',\n",
       "  'speed',\n",
       "  'with',\n",
       "  'which',\n",
       "  'people',\n",
       "  'have',\n",
       "  'access',\n",
       "  'to',\n",
       "  'technology',\n",
       "  ',',\n",
       "  'goods',\n",
       "  'and',\n",
       "  'ideas',\n",
       "  'that',\n",
       "  'could',\n",
       "  'transfrom',\n",
       "  'their',\n",
       "  'lives',\n",
       "  'so',\n",
       "  'should',\n",
       "  'be',\n",
       "  'abolished',\n",
       "  '.'],\n",
       " ['collectivism',\n",
       "  'and',\n",
       "  'the',\n",
       "  'impingement',\n",
       "  'of',\n",
       "  'the',\n",
       "  'the',\n",
       "  'government',\n",
       "  'results',\n",
       "  'in',\n",
       "  'people',\n",
       "  'blaming',\n",
       "  'others',\n",
       "  'for',\n",
       "  'their',\n",
       "  'problems',\n",
       "  'rather_than',\n",
       "  'looking',\n",
       "  'for',\n",
       "  'solutions',\n",
       "  'themselves'],\n",
       " ['for',\n",
       "  'people',\n",
       "  'undergoing',\n",
       "  'chemotherapy',\n",
       "  ',',\n",
       "  'cannabis',\n",
       "  'can',\n",
       "  'be',\n",
       "  'extremely',\n",
       "  'helpful',\n",
       "  'in',\n",
       "  'regaining',\n",
       "  'appetite',\n",
       "  'for',\n",
       "  'food'],\n",
       " ['somebody',\n",
       "  'was',\n",
       "  'working',\n",
       "  'hard',\n",
       "  'to',\n",
       "  'make',\n",
       "  'something',\n",
       "  'and',\n",
       "  'then',\n",
       "  'should',\n",
       "  'be',\n",
       "  'rewarded',\n",
       "  'for',\n",
       "  'it',\n",
       "  '.',\n",
       "  'that`s',\n",
       "  'what',\n",
       "  'intellectual_property',\n",
       "  'rights',\n",
       "  'all',\n",
       "  'about',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'a',\n",
       "  'fundamental',\n",
       "  'right',\n",
       "  'of',\n",
       "  'american',\n",
       "  'citizens',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'and',\n",
       "  'bear_arms',\n",
       "  'and',\n",
       "  'to',\n",
       "  'remove',\n",
       "  'that',\n",
       "  'right',\n",
       "  'would',\n",
       "  'simply',\n",
       "  'drive',\n",
       "  'arms',\n",
       "  'trading',\n",
       "  'underground',\n",
       "  '.'],\n",
       " ['organs',\n",
       "  'are',\n",
       "  'expensive',\n",
       "  ',',\n",
       "  'and',\n",
       "  'a',\n",
       "  'legal',\n",
       "  'trade',\n",
       "  'can',\n",
       "  'allow',\n",
       "  'for',\n",
       "  'someone',\n",
       "  'in',\n",
       "  'desperate',\n",
       "  'need',\n",
       "  'to',\n",
       "  'get',\n",
       "  'an',\n",
       "  'organ',\n",
       "  'without',\n",
       "  'money',\n",
       "  'or',\n",
       "  'wait',\n",
       "  'times',\n",
       "  '.'],\n",
       " ['child_actors',\n",
       "  'are',\n",
       "  'forced',\n",
       "  'to',\n",
       "  'grow',\n",
       "  'up',\n",
       "  'way',\n",
       "  'too',\n",
       "  'fast',\n",
       "  ',',\n",
       "  'they',\n",
       "  'are',\n",
       "  'thrown',\n",
       "  'into',\n",
       "  'a',\n",
       "  'world',\n",
       "  'of',\n",
       "  'drugs',\n",
       "  'and',\n",
       "  'sex',\n",
       "  'at',\n",
       "  'an',\n",
       "  'early',\n",
       "  'age',\n",
       "  '.',\n",
       "  '  ',\n",
       "  'kids',\n",
       "  'should',\n",
       "  'be',\n",
       "  'away',\n",
       "  'from',\n",
       "  'all',\n",
       "  'that',\n",
       "  'until',\n",
       "  'hollywood',\n",
       "  'is',\n",
       "  'safe',\n",
       "  'for',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['gender',\n",
       "  '-',\n",
       "  'neutral_language',\n",
       "  'should',\n",
       "  'be',\n",
       "  'adopted',\n",
       "  'so',\n",
       "  'that',\n",
       "  'society',\n",
       "  'can',\n",
       "  'progress',\n",
       "  'and',\n",
       "  'advance',\n",
       "  '.',\n",
       "  'does',\n",
       "  'it',\n",
       "  'really',\n",
       "  'matter',\n",
       "  'if',\n",
       "  'you',\n",
       "  'are',\n",
       "  'a',\n",
       "  'man',\n",
       "  'or',\n",
       "  'woman',\n",
       "  'anymore',\n",
       "  '?',\n",
       "  'it',\n",
       "  'should',\n",
       "  \"n't\",\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'fight',\n",
       "  'for',\n",
       "  'the',\n",
       "  'abolition',\n",
       "  'of',\n",
       "  'nuclear_weapons',\n",
       "  'or',\n",
       "  'else',\n",
       "  'the',\n",
       "  'entire',\n",
       "  'world',\n",
       "  'will',\n",
       "  'destroy',\n",
       "  'itself',\n",
       "  '.'],\n",
       " ['they',\n",
       "  'are',\n",
       "  'a',\n",
       "  'waste',\n",
       "  'of',\n",
       "  'public',\n",
       "  'resources',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'policing',\n",
       "  'these',\n",
       "  'events',\n",
       "  'costs',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'money',\n",
       "  'and',\n",
       "  'to',\n",
       "  'what',\n",
       "  'end',\n",
       "  '?'],\n",
       " ['people',\n",
       "  'should',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'weapons',\n",
       "  'as',\n",
       "  'a',\n",
       "  'form',\n",
       "  'self',\n",
       "  'defence',\n",
       "  'to',\n",
       "  'defend',\n",
       "  'their',\n",
       "  'property',\n",
       "  'and',\n",
       "  'themselves'],\n",
       " ['absolutely',\n",
       "  'not',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'the',\n",
       "  'great',\n",
       "  'president',\n",
       "  'donald',\n",
       "  'trump',\n",
       "  'is',\n",
       "  'turning',\n",
       "  'the',\n",
       "  'country',\n",
       "  'around',\n",
       "  'and',\n",
       "  'saving',\n",
       "  'us',\n",
       "  'from',\n",
       "  'the',\n",
       "  'financial',\n",
       "  'disaster',\n",
       "  'that',\n",
       "  'the',\n",
       "  'last',\n",
       "  'eight',\n",
       "  'years',\n",
       "  'were',\n",
       "  'leading',\n",
       "  'the',\n",
       "  'united',\n",
       "  'states',\n",
       "  'towards',\n",
       "  '.'],\n",
       " ['legalizing',\n",
       "  'cannabis',\n",
       "  'will',\n",
       "  'make',\n",
       "  'it',\n",
       "  'easier',\n",
       "  'for',\n",
       "  'those',\n",
       "  'who',\n",
       "  'need',\n",
       "  'it',\n",
       "  'for',\n",
       "  'medical',\n",
       "  'reasons',\n",
       "  'to',\n",
       "  'acquire',\n",
       "  'it',\n",
       "  '.'],\n",
       " ['banning',\n",
       "  'cosmetic_surgery',\n",
       "  'would',\n",
       "  'take',\n",
       "  'the',\n",
       "  'pressure',\n",
       "  'off',\n",
       "  'people',\n",
       "  'to',\n",
       "  'look',\n",
       "  'a',\n",
       "  'certain',\n",
       "  'way',\n",
       "  'that',\n",
       "  'media',\n",
       "  'and',\n",
       "  'society',\n",
       "  'dictates',\n",
       "  '.'],\n",
       " ['gender',\n",
       "  'neutral_language',\n",
       "  'will',\n",
       "  'allow',\n",
       "  'both',\n",
       "  'genders',\n",
       "  'to',\n",
       "  'be',\n",
       "  'included',\n",
       "  'and',\n",
       "  'liberated',\n",
       "  'to',\n",
       "  'succeed',\n",
       "  'as',\n",
       "  'much',\n",
       "  'as',\n",
       "  'possible',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'removing',\n",
       "  'gender',\n",
       "  'benefits',\n",
       "  'all',\n",
       "  'and',\n",
       "  'reduces',\n",
       "  'discrimination',\n",
       "  'and',\n",
       "  'suppression',\n",
       "  '.'],\n",
       " ['legalising',\n",
       "  'cannabis',\n",
       "  'could',\n",
       "  'normalise',\n",
       "  'it',\n",
       "  'and',\n",
       "  'encourage',\n",
       "  'more',\n",
       "  'children',\n",
       "  'to',\n",
       "  'partake'],\n",
       " ['minorities',\n",
       "  'are',\n",
       "  'more',\n",
       "  'likely',\n",
       "  'to',\n",
       "  'be',\n",
       "  'prosecuted',\n",
       "  'and',\n",
       "  'therefore',\n",
       "  'have',\n",
       "  'prior',\n",
       "  'offences',\n",
       "  'so',\n",
       "  'this',\n",
       "  'is',\n",
       "  'unfairly',\n",
       "  'applied'],\n",
       " ['school_uniforms',\n",
       "  'keep',\n",
       "  'all',\n",
       "  'kids',\n",
       "  'equal',\n",
       "  'while',\n",
       "  'at',\n",
       "  'school',\n",
       "  'learning',\n",
       "  'and',\n",
       "  'that',\n",
       "  'is',\n",
       "  'a',\n",
       "  'great',\n",
       "  'thing',\n",
       "  'so',\n",
       "  'school_uniforms',\n",
       "  'should',\n",
       "  'remain',\n",
       "  '.'],\n",
       " ['state',\n",
       "  'subsidies',\n",
       "  'for',\n",
       "  'journalism',\n",
       "  'will',\n",
       "  'make',\n",
       "  'journals',\n",
       "  'financially',\n",
       "  'dependent',\n",
       "  'on',\n",
       "  'the',\n",
       "  'government',\n",
       "  ',',\n",
       "  'which',\n",
       "  'will',\n",
       "  'allow',\n",
       "  'the',\n",
       "  'government',\n",
       "  'to',\n",
       "  'influence',\n",
       "  'what',\n",
       "  'news',\n",
       "  'gets',\n",
       "  'reported',\n",
       "  'and',\n",
       "  'how',\n",
       "  'the',\n",
       "  'reporting',\n",
       "  'is',\n",
       "  'done',\n",
       "  '.'],\n",
       " ['executive_compensation',\n",
       "  'too',\n",
       "  'often',\n",
       "  'fails',\n",
       "  'to',\n",
       "  'deliver',\n",
       "  'and',\n",
       "  'as',\n",
       "  'such',\n",
       "  'causes',\n",
       "  'working',\n",
       "  'issues',\n",
       "  ',',\n",
       "  'therefore',\n",
       "  'it',\n",
       "  'should',\n",
       "  'not',\n",
       "  'only',\n",
       "  'be',\n",
       "  'limited',\n",
       "  'but',\n",
       "  'stopped',\n",
       "  'completely',\n",
       "  '.'],\n",
       " ['cosmetic_surgery',\n",
       "  'is',\n",
       "  'dangerous',\n",
       "  'for',\n",
       "  'all',\n",
       "  'ages',\n",
       "  'but',\n",
       "  'especially',\n",
       "  'so',\n",
       "  'for',\n",
       "  'minors',\n",
       "  'therefore',\n",
       "  'it',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned',\n",
       "  'for',\n",
       "  'their',\n",
       "  'age',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'adopt',\n",
       "  'an',\n",
       "  'austerity_regime',\n",
       "  'because',\n",
       "  'this',\n",
       "  'move',\n",
       "  'hurt',\n",
       "  'people',\n",
       "  'that',\n",
       "  'are',\n",
       "  'living',\n",
       "  'on',\n",
       "  'their',\n",
       "  'pensions',\n",
       "  'and',\n",
       "  'people',\n",
       "  'pay',\n",
       "  'more',\n",
       "  'taxes',\n",
       "  'and',\n",
       "  'this',\n",
       "  'hurt',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'people'],\n",
       " ['three',\n",
       "  'strikes_laws',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'prison',\n",
       "  'over',\n",
       "  '-',\n",
       "  'population',\n",
       "  'since',\n",
       "  'more',\n",
       "  'offenders',\n",
       "  'are',\n",
       "  'put',\n",
       "  'away',\n",
       "  'for',\n",
       "  'a',\n",
       "  'longer',\n",
       "  'time',\n",
       "  '.',\n",
       "  'this',\n",
       "  'leads',\n",
       "  'to',\n",
       "  'worse',\n",
       "  'prison',\n",
       "  'conditions',\n",
       "  'and',\n",
       "  'more',\n",
       "  'violence',\n",
       "  'in',\n",
       "  'prisons',\n",
       "  '.'],\n",
       " ['scientology',\n",
       "  'is',\n",
       "  'not',\n",
       "  'a',\n",
       "  'true',\n",
       "  'religion',\n",
       "  'it',\n",
       "  'is',\n",
       "  'a',\n",
       "  'sect',\n",
       "  'or',\n",
       "  'a',\n",
       "  'cult',\n",
       "  'which',\n",
       "  'brainwashes',\n",
       "  'it',\n",
       "  \"'s\",\n",
       "  'followers',\n",
       "  'and',\n",
       "  'makes',\n",
       "  'money',\n",
       "  'from',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'adopt',\n",
       "  'atheism',\n",
       "  'as',\n",
       "  'then',\n",
       "  'there',\n",
       "  'would',\n",
       "  'be',\n",
       "  'no',\n",
       "  'arguments',\n",
       "  'about',\n",
       "  'religion',\n",
       "  'which',\n",
       "  'seems',\n",
       "  'to',\n",
       "  'be',\n",
       "  'the',\n",
       "  'cause',\n",
       "  'of',\n",
       "  'most',\n",
       "  'wars',\n",
       "  'and',\n",
       "  'disagreements',\n",
       "  'in',\n",
       "  'society',\n",
       "  '.'],\n",
       " ['people',\n",
       "  'would',\n",
       "  'sell',\n",
       "  'organs',\n",
       "  'because',\n",
       "  'to',\n",
       "  'them',\n",
       "  'money',\n",
       "  'is',\n",
       "  'more',\n",
       "  'important',\n",
       "  'than',\n",
       "  'health',\n",
       "  ',',\n",
       "  'putting',\n",
       "  'them',\n",
       "  'at',\n",
       "  'risk',\n",
       "  '.'],\n",
       " ['a',\n",
       "  'person',\n",
       "  'should',\n",
       "  'be',\n",
       "  'allowed',\n",
       "  'to',\n",
       "  'choose',\n",
       "  'what',\n",
       "  'happens',\n",
       "  'to',\n",
       "  'their',\n",
       "  'bodies'],\n",
       " ['school_uniforms',\n",
       "  'limit',\n",
       "  'the',\n",
       "  'ability',\n",
       "  'to',\n",
       "  'express',\n",
       "  'one',\n",
       "  \"'s\",\n",
       "  'self',\n",
       "  '.'],\n",
       " ['gun', 'ownership', 'hurts', 'more', 'people', 'than', 'it', 'helps', '.'],\n",
       " ['keeping',\n",
       "  'journalist',\n",
       "  'in',\n",
       "  'work',\n",
       "  'helps',\n",
       "  'the',\n",
       "  'nation',\n",
       "  'keep',\n",
       "  'up',\n",
       "  'with',\n",
       "  'the',\n",
       "  'news'],\n",
       " ['its', 'the', 'only', 'way', 'to', 'send', 'a', 'hard', 'message'],\n",
       " ['targeted',\n",
       "  'killings',\n",
       "  'need',\n",
       "  'to',\n",
       "  'stop',\n",
       "  'because',\n",
       "  'the',\n",
       "  'bad',\n",
       "  'guys',\n",
       "  'need',\n",
       "  'to',\n",
       "  'be',\n",
       "  'caught',\n",
       "  'and',\n",
       "  'brought',\n",
       "  'to',\n",
       "  'trial',\n",
       "  'if',\n",
       "  'possible'],\n",
       " ['the',\n",
       "  'risk',\n",
       "  'of',\n",
       "  'nuclear',\n",
       "  'war',\n",
       "  'has',\n",
       "  'made',\n",
       "  'great',\n",
       "  'powers',\n",
       "  'more',\n",
       "  'likely',\n",
       "  'to',\n",
       "  'turn',\n",
       "  'to',\n",
       "  'negotiation',\n",
       "  'and',\n",
       "  'cooperation',\n",
       "  'to',\n",
       "  'settle',\n",
       "  'disputes',\n",
       "  ',',\n",
       "  'and',\n",
       "  'abolishing',\n",
       "  'nuclear_weapons',\n",
       "  'would',\n",
       "  'make',\n",
       "  'war',\n",
       "  'less',\n",
       "  'costly',\n",
       "  'and',\n",
       "  'more',\n",
       "  'likely',\n",
       "  '.'],\n",
       " ['mandatory_retirement',\n",
       "  'is',\n",
       "  'discriminatory',\n",
       "  'on',\n",
       "  'the',\n",
       "  'basis',\n",
       "  'of',\n",
       "  'age',\n",
       "  ',',\n",
       "  'which',\n",
       "  'is',\n",
       "  'an',\n",
       "  'immutable',\n",
       "  'characteristic',\n",
       "  'much',\n",
       "  'like',\n",
       "  'gender',\n",
       "  'or',\n",
       "  'race',\n",
       "  'in',\n",
       "  'that',\n",
       "  'one',\n",
       "  'has',\n",
       "  'no',\n",
       "  'control',\n",
       "  'over',\n",
       "  'it',\n",
       "  '.'],\n",
       " ['people',\n",
       "  'have',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'choose',\n",
       "  'any',\n",
       "  'religion',\n",
       "  'they',\n",
       "  'with',\n",
       "  ',',\n",
       "  'atheism',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'forced',\n",
       "  'upon',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['school',\n",
       "  'uniform',\n",
       "  'makes',\n",
       "  'all',\n",
       "  'children',\n",
       "  'on',\n",
       "  'a',\n",
       "  'level',\n",
       "  'at',\n",
       "  'school',\n",
       "  ',',\n",
       "  'reducing',\n",
       "  'their',\n",
       "  'differences',\n",
       "  'in',\n",
       "  'background',\n",
       "  'and',\n",
       "  'wealth',\n",
       "  'to',\n",
       "  'unify',\n",
       "  'the',\n",
       "  'class'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'prohibit',\n",
       "  'school',\n",
       "  'prayer',\n",
       "  'because',\n",
       "  'it',\n",
       "  'would',\n",
       "  'violate',\n",
       "  'rights',\n",
       "  'some',\n",
       "  'religions'],\n",
       " ['for',\n",
       "  'many',\n",
       "  ',',\n",
       "  'eating',\n",
       "  'factory',\n",
       "  'farmed',\n",
       "  'food',\n",
       "  ',',\n",
       "  'is',\n",
       "  'the',\n",
       "  'only',\n",
       "  'way',\n",
       "  'they',\n",
       "  'can',\n",
       "  'afford',\n",
       "  'to',\n",
       "  'eat',\n",
       "  'meat',\n",
       "  'so',\n",
       "  'to',\n",
       "  'ban',\n",
       "  'it',\n",
       "  'would',\n",
       "  'limit',\n",
       "  'the',\n",
       "  'food',\n",
       "  'types',\n",
       "  'poorer',\n",
       "  'people',\n",
       "  'could',\n",
       "  'eat',\n",
       "  '.'],\n",
       " ['sometimes',\n",
       "  ',',\n",
       "  'missionary',\n",
       "  'workers',\n",
       "  'condition',\n",
       "  'the',\n",
       "  'receipt',\n",
       "  'of',\n",
       "  'aid',\n",
       "  'on',\n",
       "  'a',\n",
       "  'community',\n",
       "  \"'s\",\n",
       "  'willingness',\n",
       "  'to',\n",
       "  'accept',\n",
       "  'or',\n",
       "  'be',\n",
       "  'taught',\n",
       "  'the',\n",
       "  'christian',\n",
       "  'religion',\n",
       "  '.'],\n",
       " ['this',\n",
       "  'country',\n",
       "  'was',\n",
       "  'founded',\n",
       "  'by',\n",
       "  'the',\n",
       "  'freedom',\n",
       "  'of',\n",
       "  'religion',\n",
       "  ',',\n",
       "  'so',\n",
       "  'people',\n",
       "  'should',\n",
       "  'have',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'follow',\n",
       "  'any',\n",
       "  'church',\n",
       "  'they',\n",
       "  'want',\n",
       "  '.'],\n",
       " ['autonomous_cars',\n",
       "  'have',\n",
       "  'already',\n",
       "  'caused',\n",
       "  'multiple',\n",
       "  'fatalities',\n",
       "  'and',\n",
       "  'are',\n",
       "  'being',\n",
       "  'used',\n",
       "  'on',\n",
       "  'public',\n",
       "  'roads',\n",
       "  'right',\n",
       "  'now',\n",
       "  'without',\n",
       "  'being',\n",
       "  'adequately',\n",
       "  'tested',\n",
       "  '.',\n",
       "  'the',\n",
       "  'makers',\n",
       "  'are',\n",
       "  'literally',\n",
       "  'using',\n",
       "  'human',\n",
       "  'lives',\n",
       "  'to',\n",
       "  'beta',\n",
       "  'test',\n",
       "  'their',\n",
       "  'products',\n",
       "  '.'],\n",
       " ['legalizing',\n",
       "  'the',\n",
       "  'organ_trade',\n",
       "  'would',\n",
       "  'allow',\n",
       "  'more',\n",
       "  'patients',\n",
       "  'to',\n",
       "  'receive',\n",
       "  'the',\n",
       "  'organ',\n",
       "  'transplant',\n",
       "  'they',\n",
       "  'need',\n",
       "  '.'],\n",
       " ['military',\n",
       "  'is',\n",
       "  'a',\n",
       "  'big',\n",
       "  'organization',\n",
       "  'that',\n",
       "  'needs',\n",
       "  'private',\n",
       "  'company',\n",
       "  'to',\n",
       "  'supply',\n",
       "  'their',\n",
       "  'needs'],\n",
       " ['human_cloning',\n",
       "  'should',\n",
       "  'be',\n",
       "  'banned',\n",
       "  'as',\n",
       "  'it',\n",
       "  'is',\n",
       "  'unnatural',\n",
       "  'and',\n",
       "  'serves',\n",
       "  'no',\n",
       "  'purpose',\n",
       "  'in',\n",
       "  'the',\n",
       "  'world',\n",
       "  '.',\n",
       "  'individuality',\n",
       "  'would',\n",
       "  'be',\n",
       "  'lost',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'nhs',\n",
       "  'has',\n",
       "  'limited',\n",
       "  'funding',\n",
       "  'and',\n",
       "  'this',\n",
       "  'should',\n",
       "  'be',\n",
       "  'spent',\n",
       "  'providing',\n",
       "  'care',\n",
       "  'for',\n",
       "  'those',\n",
       "  'that',\n",
       "  'need',\n",
       "  'it',\n",
       "  'rather_than',\n",
       "  'wasting',\n",
       "  'it',\n",
       "  'on',\n",
       "  'research',\n",
       "  'that',\n",
       "  'may',\n",
       "  'not',\n",
       "  'help',\n",
       "  'solve',\n",
       "  'anytihng'],\n",
       " ['let',\n",
       "  'the',\n",
       "  'free',\n",
       "  'market',\n",
       "  'decide',\n",
       "  'whether',\n",
       "  'or',\n",
       "  'not',\n",
       "  'we',\n",
       "  'should',\n",
       "  'allow',\n",
       "  'factory_farming'],\n",
       " ['we',\n",
       "  'live',\n",
       "  'in',\n",
       "  'a',\n",
       "  'capitalist',\n",
       "  'country',\n",
       "  'and',\n",
       "  'telemarketing',\n",
       "  ' ',\n",
       "  'is',\n",
       "  'how',\n",
       "  'many',\n",
       "  'businesses',\n",
       "  'grow',\n",
       "  'and',\n",
       "  'develop',\n",
       "  '.'],\n",
       " ['religious',\n",
       "  'beliefs',\n",
       "  'are',\n",
       "  'forced',\n",
       "  'upon',\n",
       "  'children',\n",
       "  'and',\n",
       "  'children',\n",
       "  'of',\n",
       "  'different',\n",
       "  'religions',\n",
       "  'may',\n",
       "  'feel',\n",
       "  'excluded'],\n",
       " ['capital_punishment',\n",
       "  'is',\n",
       "  'barbaric',\n",
       "  ',',\n",
       "  'what',\n",
       "  'if',\n",
       "  'an',\n",
       "  'innocent',\n",
       "  'person',\n",
       "  'is',\n",
       "  'killed',\n",
       "  'under',\n",
       "  'these',\n",
       "  'laws',\n",
       "  ',',\n",
       "  'you',\n",
       "  'can',\n",
       "  'not',\n",
       "  'release',\n",
       "  'them',\n",
       "  'and',\n",
       "  'make',\n",
       "  'restitution',\n",
       "  ',',\n",
       "  'capital_punishment',\n",
       "  'makes',\n",
       "  'authorities',\n",
       "  'as',\n",
       "  'guilty',\n",
       "  'of',\n",
       "  'crime',\n",
       "  'as',\n",
       "  'the',\n",
       "  'criminals',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'roles',\n",
       "  'of',\n",
       "  'child_actors',\n",
       "  'can',\n",
       "  'not',\n",
       "  'be',\n",
       "  'fulfilled',\n",
       "  'by',\n",
       "  'adults',\n",
       "  'so',\n",
       "  'it',\n",
       "  'would',\n",
       "  'be',\n",
       "  'impossible',\n",
       "  'to',\n",
       "  'ban',\n",
       "  'their',\n",
       "  'use',\n",
       "  '.'],\n",
       " ['safe_spaces',\n",
       "  'provide',\n",
       "  'a',\n",
       "  'valuable',\n",
       "  'service',\n",
       "  'to',\n",
       "  'those',\n",
       "  'who',\n",
       "  'may',\n",
       "  'be',\n",
       "  'suffering',\n",
       "  'from',\n",
       "  'ptsd'],\n",
       " ['it',\n",
       "  'is',\n",
       "  \"n't\",\n",
       "  'the',\n",
       "  'obligation',\n",
       "  'of',\n",
       "  'any',\n",
       "  'tax',\n",
       "  'payer',\n",
       "  'to',\n",
       "  'give',\n",
       "  'money',\n",
       "  'to',\n",
       "  'help',\n",
       "  'someone',\n",
       "  'else',\n",
       "  'get',\n",
       "  'an',\n",
       "  'education',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'that',\n",
       "  'is',\n",
       "  'a',\n",
       "  'personal',\n",
       "  'choice',\n",
       "  ',',\n",
       "  'and',\n",
       "  'if',\n",
       "  'they',\n",
       "  'want',\n",
       "  'to',\n",
       "  'go',\n",
       "  'to',\n",
       "  'college',\n",
       "  'they',\n",
       "  'need',\n",
       "  'to',\n",
       "  'pay',\n",
       "  'for',\n",
       "  'it',\n",
       "  'on',\n",
       "  'their',\n",
       "  'own',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'and',\n",
       "  'bear_arms',\n",
       "  'has',\n",
       "  'enabled',\n",
       "  'the',\n",
       "  'death',\n",
       "  'of',\n",
       "  'many',\n",
       "  'innocent',\n",
       "  'people',\n",
       "  '-',\n",
       "  'including',\n",
       "  'small',\n",
       "  'children',\n",
       "  '.',\n",
       "  'it',\n",
       "  'is',\n",
       "  'time',\n",
       "  'to',\n",
       "  'move',\n",
       "  'on',\n",
       "  '.'],\n",
       " ['algorithmic_trading',\n",
       "  'can',\n",
       "  'be',\n",
       "  'manipulated',\n",
       "  'and',\n",
       "  'used',\n",
       "  'for',\n",
       "  'nefarious',\n",
       "  'reasons'],\n",
       " ['compulsory_voting',\n",
       "  'could',\n",
       "  'be',\n",
       "  'used',\n",
       "  'as',\n",
       "  'a',\n",
       "  'way',\n",
       "  'to',\n",
       "  'check',\n",
       "  'population',\n",
       "  'and',\n",
       "  'make',\n",
       "  'sure',\n",
       "  'everyone',\n",
       "  'has',\n",
       "  'current',\n",
       "  'ids',\n",
       "  '.'],\n",
       " ['this',\n",
       "  'law',\n",
       "  'is',\n",
       "  'good',\n",
       "  'for',\n",
       "  'young',\n",
       "  'people',\n",
       "  'who',\n",
       "  'would',\n",
       "  'learn',\n",
       "  'their',\n",
       "  'lesson',\n",
       "  'and',\n",
       "  'become',\n",
       "  'good',\n",
       "  'adults'],\n",
       " ['gender', '-', 'neutral_language', 'is', 'unnecessary', '.'],\n",
       " ['ideas',\n",
       "  'and',\n",
       "  'products',\n",
       "  'need',\n",
       "  'to',\n",
       "  'be',\n",
       "  'available',\n",
       "  'at',\n",
       "  'a',\n",
       "  'fair',\n",
       "  'price',\n",
       "  'for',\n",
       "  'everyone',\n",
       "  ',',\n",
       "  'allowing',\n",
       "  'companies',\n",
       "  'to',\n",
       "  'have',\n",
       "  'their',\n",
       "  'intellectual',\n",
       "  'rights',\n",
       "  'means',\n",
       "  'they',\n",
       "  'can',\n",
       "  'charge',\n",
       "  'far',\n",
       "  'too',\n",
       "  'much',\n",
       "  'to',\n",
       "  'people',\n",
       "  'who',\n",
       "  'need',\n",
       "  'that',\n",
       "  'service',\n",
       "  'or',\n",
       "  'product',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'subsidize',\n",
       "  'wikipedia',\n",
       "  'because',\n",
       "  'it',\n",
       "  'already',\n",
       "  'receives',\n",
       "  'more',\n",
       "  'than',\n",
       "  'enough',\n",
       "  'money',\n",
       "  'through',\n",
       "  'voluntary',\n",
       "  'donations'],\n",
       " ['collectivism',\n",
       "  'takes',\n",
       "  'the',\n",
       "  'focus',\n",
       "  'off',\n",
       "  'the',\n",
       "  'individual',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'the',\n",
       "  'ways',\n",
       "  'in',\n",
       "  'which',\n",
       "  'each',\n",
       "  'of',\n",
       "  'us',\n",
       "  'is',\n",
       "  'unique',\n",
       "  '.',\n",
       "  'supporting',\n",
       "  'collectivism',\n",
       "  'means',\n",
       "  'wanting',\n",
       "  'the',\n",
       "  'individual',\n",
       "  'to',\n",
       "  'remain',\n",
       "  'subordinate',\n",
       "  'to',\n",
       "  'society',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'healing',\n",
       "  'properties',\n",
       "  'of',\n",
       "  'cannabis',\n",
       "  'are',\n",
       "  'necessary',\n",
       "  'to',\n",
       "  'alleviate',\n",
       "  'the',\n",
       "  'health',\n",
       "  'of',\n",
       "  'many',\n",
       "  'patients',\n",
       "  'who',\n",
       "  'do',\n",
       "  'not',\n",
       "  'have',\n",
       "  'access',\n",
       "  'to',\n",
       "  'it',\n",
       "  'due',\n",
       "  'to',\n",
       "  'its',\n",
       "  'restriction'],\n",
       " ['embryonic_stem',\n",
       "  'cell_research',\n",
       "  'may',\n",
       "  'in',\n",
       "  'the',\n",
       "  'future',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'the',\n",
       "  'discovery',\n",
       "  'of',\n",
       "  'treatments',\n",
       "  'for',\n",
       "  'many',\n",
       "  'debilitating',\n",
       "  'medical',\n",
       "  'conditions'],\n",
       " ['safe_spaces',\n",
       "  'are',\n",
       "  'often',\n",
       "  'used',\n",
       "  'to',\n",
       "  'stifle',\n",
       "  'free',\n",
       "  'expression',\n",
       "  'of',\n",
       "  'opinions'],\n",
       " ['libertarianism',\n",
       "  'is',\n",
       "  'a',\n",
       "  'selfish',\n",
       "  'and',\n",
       "  'dangerous',\n",
       "  'philosophy',\n",
       "  ',',\n",
       "  'devoid',\n",
       "  'of',\n",
       "  'empathy',\n",
       "  'and',\n",
       "  'charity',\n",
       "  '.',\n",
       "  'if',\n",
       "  'it',\n",
       "  'were',\n",
       "  'to',\n",
       "  'become',\n",
       "  'the',\n",
       "  'dominant',\n",
       "  'political',\n",
       "  'system',\n",
       "  ',',\n",
       "  'we',\n",
       "  'would',\n",
       "  'see',\n",
       "  'a',\n",
       "  'huge',\n",
       "  'increase',\n",
       "  'in',\n",
       "  'social',\n",
       "  'inequality',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'helps',\n",
       "  'small',\n",
       "  'third',\n",
       "  'world',\n",
       "  'countries',\n",
       "  'become',\n",
       "  'more',\n",
       "  'modernized',\n",
       "  '.'],\n",
       " ['without',\n",
       "  'further',\n",
       "  'research',\n",
       "  'we',\n",
       "  'wo',\n",
       "  \"n't\",\n",
       "  'know',\n",
       "  'what',\n",
       "  'amazing',\n",
       "  'potential',\n",
       "  'we',\n",
       "  'have',\n",
       "  'with',\n",
       "  'embryonic_stem',\n",
       "  'cells'],\n",
       " ['there',\n",
       "  'have',\n",
       "  'been',\n",
       "  'credible',\n",
       "  'witnesses',\n",
       "  'to',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'the',\n",
       "  'church',\n",
       "  'of',\n",
       "  'scientology',\n",
       "  'engages',\n",
       "  'in',\n",
       "  'physical',\n",
       "  'and',\n",
       "  'emotional',\n",
       "  'abuse'],\n",
       " ['neutral_language',\n",
       "  'is',\n",
       "  'an',\n",
       "  'alternative',\n",
       "  'at',\n",
       "  'the',\n",
       "  'time',\n",
       "  'of',\n",
       "  'speaking',\n",
       "  'that',\n",
       "  'serves',\n",
       "  'to',\n",
       "  'include',\n",
       "  'all',\n",
       "  'persons',\n",
       "  'without',\n",
       "  'gender',\n",
       "  'exclusion'],\n",
       " ['adopting',\n",
       "  'an',\n",
       "  'austerity_regime',\n",
       "  'is',\n",
       "  'the',\n",
       "  'best',\n",
       "  'way',\n",
       "  'to',\n",
       "  'reduce',\n",
       "  'the',\n",
       "  'budget',\n",
       "  'deficits',\n",
       "  'we',\n",
       "  'currently',\n",
       "  'are',\n",
       "  'faced',\n",
       "  'with'],\n",
       " ['people',\n",
       "  'have',\n",
       "  'the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'enhance',\n",
       "  'their',\n",
       "  'body',\n",
       "  'in',\n",
       "  'any',\n",
       "  'way',\n",
       "  'they',\n",
       "  'want',\n",
       "  'to',\n",
       "  '.'],\n",
       " ['wikipedia',\n",
       "  'is',\n",
       "  'a',\n",
       "  'private',\n",
       "  'entity',\n",
       "  'and',\n",
       "  'is',\n",
       "  'responsible',\n",
       "  'for',\n",
       "  'its',\n",
       "  'own',\n",
       "  'operating',\n",
       "  'costs'],\n",
       " ['missionaries',\n",
       "  'try',\n",
       "  'to',\n",
       "  'force',\n",
       "  'their',\n",
       "  'beliefs',\n",
       "  'and',\n",
       "  'values',\n",
       "  'on',\n",
       "  'people',\n",
       "  '.'],\n",
       " ['journalists',\n",
       "  'get',\n",
       "  'paid',\n",
       "  'enough',\n",
       "  ',',\n",
       "  'they',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'need',\n",
       "  'any',\n",
       "  'more',\n",
       "  'money',\n",
       "  '.'],\n",
       " ['the',\n",
       "  'usage',\n",
       "  'of',\n",
       "  'child_actors',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'banned',\n",
       "  'as',\n",
       "  'they',\n",
       "  'are',\n",
       "  'an',\n",
       "  'important',\n",
       "  'part',\n",
       "  'of',\n",
       "  'the',\n",
       "  'acting',\n",
       "  'field',\n",
       "  'they',\n",
       "  'have',\n",
       "  'adults',\n",
       "  'who',\n",
       "  'can',\n",
       "  'make',\n",
       "  'rationale',\n",
       "  'decisions',\n",
       "  'for',\n",
       "  'them',\n",
       "  '.'],\n",
       " ['if',\n",
       "  'someone',\n",
       "  'has',\n",
       "  'worked',\n",
       "  'hard',\n",
       "  'to',\n",
       "  'get',\n",
       "  'where',\n",
       "  'they',\n",
       "  'are',\n",
       "  'in',\n",
       "  'a',\n",
       "  'company',\n",
       "  'then',\n",
       "  'they',\n",
       "  'should',\n",
       "  'be',\n",
       "  'rewarded',\n",
       "  'accordingly',\n",
       "  '.'],\n",
       " ['people',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'forced',\n",
       "  'to',\n",
       "  'vote',\n",
       "  'if',\n",
       "  'they',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'feel',\n",
       "  'compelled',\n",
       "  'to',\n",
       "  'vote',\n",
       "  'for',\n",
       "  'a',\n",
       "  'candidate',\n",
       "  'or',\n",
       "  'issue',\n",
       "  '..'],\n",
       " ['the',\n",
       "  'right',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'and',\n",
       "  'bear_arms',\n",
       "  'is',\n",
       "  'an',\n",
       "  'constitutional',\n",
       "  'right',\n",
       "  'that',\n",
       "  'needs',\n",
       "  'to',\n",
       "  'be',\n",
       "  'upheld',\n",
       "  '.'],\n",
       " ['they', 'are', 'boring', 'and', 'cost', 'too', 'much', 'money'],\n",
       " ['introducing',\n",
       "  'a',\n",
       "  'multi',\n",
       "  '-',\n",
       "  'party_system',\n",
       "  'would',\n",
       "  'be',\n",
       "  'detrimental',\n",
       "  'to',\n",
       "  'stability',\n",
       "  'and',\n",
       "  'consistency',\n",
       "  'of',\n",
       "  'our',\n",
       "  'political',\n",
       "  'system'],\n",
       " ['economic_sanctions',\n",
       "  'cause',\n",
       "  'hard',\n",
       "  'feelings',\n",
       "  'between',\n",
       "  'nations',\n",
       "  'and',\n",
       "  'can',\n",
       "  'cause',\n",
       "  'war',\n",
       "  '.'],\n",
       " ['executive_compensation',\n",
       "  'should',\n",
       "  'be',\n",
       "  'limited',\n",
       "  'to',\n",
       "  'ensure',\n",
       "  'the',\n",
       "  'top',\n",
       "  'staff',\n",
       "  'is',\n",
       "  'not',\n",
       "  'taking',\n",
       "  'all',\n",
       "  'of',\n",
       "  'the',\n",
       "  'rewards',\n",
       "  'for',\n",
       "  'companies',\n",
       "  'that',\n",
       "  'are',\n",
       "  'supported',\n",
       "  'by',\n",
       "  'thousands',\n",
       "  'of',\n",
       "  'workers',\n",
       "  '.',\n",
       "  'all',\n",
       "  'employees',\n",
       "  'contribute',\n",
       "  'to',\n",
       "  'the',\n",
       "  'success',\n",
       "  'of',\n",
       "  'a',\n",
       "  'company',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'need',\n",
       "  'to',\n",
       "  'explore',\n",
       "  'space',\n",
       "  'so',\n",
       "  'we',\n",
       "  'can',\n",
       "  'find',\n",
       "  'minerals',\n",
       "  'that',\n",
       "  'are',\n",
       "  'getting',\n",
       "  'depleted',\n",
       "  'on',\n",
       "  'our',\n",
       "  'planet'],\n",
       " ['without',\n",
       "  'regulations',\n",
       "  'and',\n",
       "  'welfare',\n",
       "  ',',\n",
       "  'society',\n",
       "  'would',\n",
       "  'collapse',\n",
       "  'into',\n",
       "  'vast',\n",
       "  'pools',\n",
       "  'of',\n",
       "  'crime',\n",
       "  'and',\n",
       "  'poverty'],\n",
       " ['some',\n",
       "  'religions',\n",
       "  'do',\n",
       "  'not',\n",
       "  'believe',\n",
       "  'in',\n",
       "  'this',\n",
       "  'sort',\n",
       "  'of',\n",
       "  'research',\n",
       "  '.'],\n",
       " ['scientology',\n",
       "  'is',\n",
       "  'in',\n",
       "  'fact',\n",
       "  'a',\n",
       "  'cult',\n",
       "  ',',\n",
       "  'cults',\n",
       "  'need',\n",
       "  'to',\n",
       "  'be',\n",
       "  'stopped',\n",
       "  '.'],\n",
       " ['it',\n",
       "  'is',\n",
       "  'important',\n",
       "  'that',\n",
       "  'the',\n",
       "  'highly',\n",
       "  'experienced',\n",
       "  ',',\n",
       "  'well',\n",
       "  'trained',\n",
       "  'people',\n",
       "  'at',\n",
       "  'the',\n",
       "  'top',\n",
       "  'of',\n",
       "  'the',\n",
       "  'judicial',\n",
       "  'system',\n",
       "  'can',\n",
       "  'use',\n",
       "  'their',\n",
       "  'own',\n",
       "  'experiences',\n",
       "  'and',\n",
       "  'common',\n",
       "  'sense',\n",
       "  'when',\n",
       "  'passing',\n",
       "  'judgments',\n",
       "  '-',\n",
       "  'else',\n",
       "  'anyone',\n",
       "  'could',\n",
       "  'be',\n",
       "  'a',\n",
       "  'judge',\n",
       "  '.'],\n",
       " ['autonomous_cars',\n",
       "  'could',\n",
       "  'prevent',\n",
       "  'traffic',\n",
       "  'jams',\n",
       "  'and',\n",
       "  'accidents',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'adopt',\n",
       "  'atheism',\n",
       "  'because',\n",
       "  'everyone',\n",
       "  'should',\n",
       "  'have',\n",
       "  'something',\n",
       "  'to',\n",
       "  'believe',\n",
       "  'in',\n",
       "  '.'],\n",
       " ['using',\n",
       "  'child_actors',\n",
       "  'can',\n",
       "  'create',\n",
       "  'unimaginable',\n",
       "  'pressure',\n",
       "  'ans',\n",
       "  'stress',\n",
       "  'on',\n",
       "  'the',\n",
       "  'child',\n",
       "  'if',\n",
       "  'they',\n",
       "  'become',\n",
       "  'a',\n",
       "  'star',\n",
       "  'or',\n",
       "  'the',\n",
       "  'production',\n",
       "  'is',\n",
       "  'a',\n",
       "  'success',\n",
       "  'and',\n",
       "  'this',\n",
       "  'can',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'substance',\n",
       "  'abuse',\n",
       "  'problems',\n",
       "  'to',\n",
       "  'cope',\n",
       "  'with',\n",
       "  'said',\n",
       "  'pressure'],\n",
       " ['safe_spaces', 'act', 'to', 'stifle', 'free', 'speech'],\n",
       " ['cosmetic_surgery',\n",
       "  'might',\n",
       "  'be',\n",
       "  'the',\n",
       "  'only',\n",
       "  'hope',\n",
       "  'for',\n",
       "  'children',\n",
       "  'born',\n",
       "  'with',\n",
       "  'disfigurements',\n",
       "  'that',\n",
       "  'would',\n",
       "  'have',\n",
       "  'severe',\n",
       "  'impact',\n",
       "  'on',\n",
       "  'self',\n",
       "  '-',\n",
       "  'esteem',\n",
       "  'and',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'psychological',\n",
       "  'issues',\n",
       "  'and',\n",
       "  'childhood',\n",
       "  'trauma',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'not',\n",
       "  'ban',\n",
       "  'the',\n",
       "  'church',\n",
       "  'of',\n",
       "  'scientology',\n",
       "  'because',\n",
       "  'people',\n",
       "  'have',\n",
       "  'a',\n",
       "  'right',\n",
       "  'to',\n",
       "  'chose',\n",
       "  'their',\n",
       "  'believes'],\n",
       " ['abolishing',\n",
       "  'death',\n",
       "  'penalty',\n",
       "  'means',\n",
       "  'abandoning',\n",
       "  'the',\n",
       "  'poor',\n",
       "  '-who',\n",
       "  'suffer',\n",
       "  'the',\n",
       "  'most',\n",
       "  'from',\n",
       "  'high',\n",
       "  'crime',\n",
       "  'rates',\n",
       "  '-',\n",
       "  ' ',\n",
       "  'only',\n",
       "  'so',\n",
       "  'that',\n",
       "  'the',\n",
       "  'elites',\n",
       "  'could',\n",
       "  'feel',\n",
       "  'good',\n",
       "  'about',\n",
       "  'themselves',\n",
       "  '.'],\n",
       " ['subsidizing',\n",
       "  'space_exploration',\n",
       "  'is',\n",
       "  'a',\n",
       "  'positive',\n",
       "  'move',\n",
       "  'to',\n",
       "  'help',\n",
       "  'advance',\n",
       "  'our',\n",
       "  'space',\n",
       "  'program',\n",
       "  '.'],\n",
       " ['algorithmic_trading',\n",
       "  'can',\n",
       "  'do',\n",
       "  'a',\n",
       "  'job',\n",
       "  'that',\n",
       "  'humans',\n",
       "  'are',\n",
       "  'not',\n",
       "  'able',\n",
       "  'to',\n",
       "  'do'],\n",
       " ['they',\n",
       "  'increase',\n",
       "  'tourist',\n",
       "  'activities',\n",
       "  'and',\n",
       "  'are',\n",
       "  'a',\n",
       "  'boost',\n",
       "  'to',\n",
       "  'the',\n",
       "  'local',\n",
       "  'economy',\n",
       "  '.'],\n",
       " ['in',\n",
       "  'a',\n",
       "  'time',\n",
       "  'of',\n",
       "  'equality',\n",
       "  ',',\n",
       "  'knowing',\n",
       "  'the',\n",
       "  'gender',\n",
       "  'of',\n",
       "  'a',\n",
       "  'person',\n",
       "  'is',\n",
       "  \"n't\",\n",
       "  'important',\n",
       "  ',',\n",
       "  'salesperson',\n",
       "  'is',\n",
       "  'a',\n",
       "  'much',\n",
       "  'more',\n",
       "  'inclusive',\n",
       "  'term',\n",
       "  'than',\n",
       "  'saleswoman',\n",
       "  '.'],\n",
       " ['nuclear_weapons',\n",
       "  'will',\n",
       "  'someday',\n",
       "  'destroy',\n",
       "  'everyone',\n",
       "  'and',\n",
       "  'everything',\n",
       "  '.'],\n",
       " ['libertarianism',\n",
       "  'increases',\n",
       "  'individual',\n",
       "  'liberties',\n",
       "  'by',\n",
       "  'preventing',\n",
       "  'the',\n",
       "  'government',\n",
       "  'from',\n",
       "  'controlling',\n",
       "  'every',\n",
       "  'aspect',\n",
       "  'of',\n",
       "  'our',\n",
       "  'lives',\n",
       "  '.'],\n",
       " ['gender',\n",
       "  '-',\n",
       "  'neutral_language',\n",
       "  'does',\n",
       "  \"n't\",\n",
       "  'always',\n",
       "  'help',\n",
       "  'people',\n",
       "  'clearly',\n",
       "  'communicate',\n",
       "  'what',\n",
       "  'they',\n",
       "  'mean'],\n",
       " ['compulsory_voting',\n",
       "  'would',\n",
       "  'be',\n",
       "  'beneficial',\n",
       "  'because',\n",
       "  'more',\n",
       "  'people',\n",
       "  'would',\n",
       "  'take',\n",
       "  'an',\n",
       "  'interest',\n",
       "  'in',\n",
       "  'politics',\n",
       "  ',',\n",
       "  'creating',\n",
       "  'a',\n",
       "  'more',\n",
       "  'fair',\n",
       "  'representation',\n",
       "  'in',\n",
       "  'government',\n",
       "  '.'],\n",
       " ['developing',\n",
       "  'autonomous_cars',\n",
       "  'is',\n",
       "  'a',\n",
       "  'necessity',\n",
       "  '.',\n",
       "  'it',\n",
       "  'would',\n",
       "  'make',\n",
       "  'roads',\n",
       "  'and',\n",
       "  'travel',\n",
       "  'much',\n",
       "  'safer',\n",
       "  'as',\n",
       "  'car',\n",
       "  'accidents',\n",
       "  'account',\n",
       "  'for',\n",
       "  'an',\n",
       "  'incredible',\n",
       "  'amount',\n",
       "  'of',\n",
       "  'deaths',\n",
       "  '.',\n",
       "  'there',\n",
       "  'would',\n",
       "  'be',\n",
       "  'no',\n",
       "  'more',\n",
       "  'drunk',\n",
       "  'and',\n",
       "  'distracted',\n",
       "  'driving',\n",
       "  'accidents',\n",
       "  '.'],\n",
       " ['children',\n",
       "  'should',\n",
       "  'be',\n",
       "  'allowed',\n",
       "  'to',\n",
       "  'have',\n",
       "  'a',\n",
       "  'procedure',\n",
       "  'if',\n",
       "  'they',\n",
       "  'have',\n",
       "  'their',\n",
       "  'parents',\n",
       "  'permission'],\n",
       " ['student_loans',\n",
       "  'is',\n",
       "  'a',\n",
       "  'type',\n",
       "  'of',\n",
       "  'aid',\n",
       "  'that',\n",
       "  'is',\n",
       "  'given',\n",
       "  'to',\n",
       "  'them',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'help',\n",
       "  'lower',\n",
       "  'their',\n",
       "  'expenses',\n",
       "  'and',\n",
       "  'debts'],\n",
       " ['the',\n",
       "  'basic',\n",
       "  'message',\n",
       "  'in',\n",
       "  'prayer',\n",
       "  'is',\n",
       "  'universal',\n",
       "  ',',\n",
       "  'encouraging',\n",
       "  'people',\n",
       "  'to',\n",
       "  'be',\n",
       "  'considerate',\n",
       "  'and',\n",
       "  'love',\n",
       "  'one',\n",
       "  'another',\n",
       "  '-',\n",
       "  'this',\n",
       "  'is',\n",
       "  'a',\n",
       "  'basic',\n",
       "  'message',\n",
       "  'for',\n",
       "  'every',\n",
       "  'child',\n",
       "  'in',\n",
       "  'school',\n",
       "  ',',\n",
       "  'irrespective',\n",
       "  'of',\n",
       "  'their',\n",
       "  'religion',\n",
       "  ',',\n",
       "  'and',\n",
       "  'should',\n",
       "  'be',\n",
       "  'encouraged',\n",
       "  '.'],\n",
       " ['everyone',\n",
       "  'should',\n",
       "  'have',\n",
       "  'a',\n",
       "  'choice',\n",
       "  'about',\n",
       "  'what',\n",
       "  'they',\n",
       "  'want',\n",
       "  'to',\n",
       "  'do',\n",
       "  'with',\n",
       "  'their',\n",
       "  'bodies',\n",
       "  ',',\n",
       "  'and',\n",
       "  'if',\n",
       "  'selling',\n",
       "  'an',\n",
       "  'organ',\n",
       "  'is',\n",
       "  'one',\n",
       "  'of',\n",
       "  'them',\n",
       "  ',',\n",
       "  'they',\n",
       "  'should',\n",
       "  'be',\n",
       "  'free',\n",
       "  'to',\n",
       "  'decide',\n",
       "  '.'],\n",
       " ['collectivism',\n",
       "  'is',\n",
       "  'morally',\n",
       "  'wrong',\n",
       "  'and',\n",
       "  'a',\n",
       "  'form',\n",
       "  'of',\n",
       "  'slavery',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'must',\n",
       "  'have',\n",
       "  'more',\n",
       "  'options',\n",
       "  'to',\n",
       "  'choose',\n",
       "  'and',\n",
       "  'leave',\n",
       "  'this',\n",
       "  'bipartisan',\n",
       "  'dictatorship'],\n",
       " ['states',\n",
       "  'have',\n",
       "  'an',\n",
       "  'obligation',\n",
       "  'to',\n",
       "  'their',\n",
       "  'citizens',\n",
       "  'to',\n",
       "  'protect',\n",
       "  'them',\n",
       "  ',',\n",
       "  'the',\n",
       "  'existence',\n",
       "  'of',\n",
       "  'nuclear_weapons',\n",
       "  'anywhere',\n",
       "  'poses',\n",
       "  'an',\n",
       "  'existential',\n",
       "  'threat',\n",
       "  'to',\n",
       "  'citizens',\n",
       "  'everywhere',\n",
       "  ',',\n",
       "  'which',\n",
       "  'means',\n",
       "  'every',\n",
       "  'nation',\n",
       "  'has',\n",
       "  'an',\n",
       "  'obligation',\n",
       "  'to',\n",
       "  'fight',\n",
       "  'for',\n",
       "  'abolition',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'have',\n",
       "  'too',\n",
       "  'many',\n",
       "  'problems',\n",
       "  'here',\n",
       "  'on',\n",
       "  'our',\n",
       "  'own',\n",
       "  'planet',\n",
       "  'to',\n",
       "  'worry',\n",
       "  'about',\n",
       "  'putting',\n",
       "  'money',\n",
       "  'into',\n",
       "  'searching',\n",
       "  'space',\n",
       "  '.'],\n",
       " ['cloning',\n",
       "  'of',\n",
       "  'organs',\n",
       "  'can',\n",
       "  'and',\n",
       "  'will',\n",
       "  'save',\n",
       "  'many',\n",
       "  'lives',\n",
       "  ',',\n",
       "  'people',\n",
       "  'who',\n",
       "  'need',\n",
       "  'organ',\n",
       "  'transplants',\n",
       "  'could',\n",
       "  'be',\n",
       "  'saved',\n",
       "  'by',\n",
       "  'cloning',\n",
       "  'organs',\n",
       "  'for',\n",
       "  'them',\n",
       "  'rather_than',\n",
       "  'waiting',\n",
       "  'for',\n",
       "  'others',\n",
       "  'to',\n",
       "  'die',\n",
       "  ',',\n",
       "  'cloned',\n",
       "  'limbs',\n",
       "  'would',\n",
       "  'also',\n",
       "  'help',\n",
       "  'disabled',\n",
       "  'people',\n",
       "  '.'],\n",
       " ['this', 'helps', 'traders', 'make', 'more', 'informed', 'decisions'],\n",
       " ['judicial_activism',\n",
       "  'should',\n",
       "  'be',\n",
       "  'limited',\n",
       "  'because',\n",
       "  'a',\n",
       "  'judge',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'making',\n",
       "  'all',\n",
       "  'decisions',\n",
       "  '.'],\n",
       " ['collectivism',\n",
       "  'bands',\n",
       "  'people',\n",
       "  'together',\n",
       "  'to',\n",
       "  'solve',\n",
       "  'problems',\n",
       "  'in',\n",
       "  'their',\n",
       "  'communities'],\n",
       " ['capital_punishment',\n",
       "  'is',\n",
       "  'fair',\n",
       "  'if',\n",
       "  'the',\n",
       "  'person',\n",
       "  'had',\n",
       "  'killed',\n",
       "  'someone',\n",
       "  'as',\n",
       "  'they',\n",
       "  'are',\n",
       "  'only',\n",
       "  'getting',\n",
       "  'what',\n",
       "  'they',\n",
       "  'have',\n",
       "  'dealt',\n",
       "  '.'],\n",
       " ['libertarians', 'are', 'more', 'fair', 'than', 'other', 'politicians', '.'],\n",
       " ['out',\n",
       "  'of',\n",
       "  'control',\n",
       "  'executive_compensation',\n",
       "  'raises',\n",
       "  'the',\n",
       "  'disparity',\n",
       "  'between',\n",
       "  'the',\n",
       "  'haves',\n",
       "  'and',\n",
       "  'the',\n",
       "  'have',\n",
       "  'nots',\n",
       "  '.'],\n",
       " ['presentation',\n",
       "  'of',\n",
       "  'information',\n",
       "  'is',\n",
       "  'important',\n",
       "  'and',\n",
       "  'needs',\n",
       "  'help',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'it',\n",
       "  'viable',\n",
       "  'and',\n",
       "  'reliable',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'subsidize',\n",
       "  'journalism',\n",
       "  'because',\n",
       "  'we',\n",
       "  'need',\n",
       "  'to',\n",
       "  'keep',\n",
       "  'local',\n",
       "  'journalism',\n",
       "  'alive',\n",
       "  'so',\n",
       "  'people',\n",
       "  'are',\n",
       "  'aware',\n",
       "  'of',\n",
       "  'what',\n",
       "  'is',\n",
       "  'going',\n",
       "  'on',\n",
       "  'in',\n",
       "  'their',\n",
       "  'community',\n",
       "  ',',\n",
       "  'but',\n",
       "  'small',\n",
       "  'news',\n",
       "  'papers',\n",
       "  'are',\n",
       "  'struggling',\n",
       "  'the',\n",
       "  'most',\n",
       "  '.'],\n",
       " ['pride_parades',\n",
       "  'are',\n",
       "  'disruptive',\n",
       "  'and',\n",
       "  'cause',\n",
       "  'chaos',\n",
       "  'in',\n",
       "  'towns',\n",
       "  'where',\n",
       "  'they',\n",
       "  'are',\n",
       "  'held',\n",
       "  '.'],\n",
       " ['student_loans',\n",
       "  'should',\n",
       "  'be',\n",
       "  'subsidized',\n",
       "  'so',\n",
       "  'that',\n",
       "  'more',\n",
       "  'kids',\n",
       "  'can',\n",
       "  'go',\n",
       "  'to',\n",
       "  'school',\n",
       "  ',',\n",
       "  'get',\n",
       "  'a',\n",
       "  'better',\n",
       "  'education',\n",
       "  'and',\n",
       "  'contribute',\n",
       "  'to',\n",
       "  'the',\n",
       "  'advancement',\n",
       "  'of',\n",
       "  'society',\n",
       "  '.'],\n",
       " ['compulsory_voting',\n",
       "  'will',\n",
       "  'lead',\n",
       "  'to',\n",
       "  'a',\n",
       "  'far',\n",
       "  'more',\n",
       "  'representative',\n",
       "  'system',\n",
       "  'of',\n",
       "  'parliament',\n",
       "  'because',\n",
       "  'everyone',\n",
       "  \"'s\",\n",
       "  'vote',\n",
       "  'will',\n",
       "  'be',\n",
       "  'taken',\n",
       "  'into',\n",
       "  'consideration',\n",
       "  '.'],\n",
       " ['telemarketing',\n",
       "  'has',\n",
       "  'reached',\n",
       "  'epidemic',\n",
       "  'levels',\n",
       "  'with',\n",
       "  'unregulated',\n",
       "  'frequency',\n",
       "  'that',\n",
       "  'most',\n",
       "  'people',\n",
       "  'would',\n",
       "  'consider',\n",
       "  'a',\n",
       "  'public',\n",
       "  'nuisance',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'legalize',\n",
       "  'sex_selection',\n",
       "  'because',\n",
       "  'a',\n",
       "  'ban',\n",
       "  'leads',\n",
       "  'to',\n",
       "  'dangerous',\n",
       "  'back',\n",
       "  'alley',\n",
       "  'procedures',\n",
       "  ',',\n",
       "  'and',\n",
       "  'to',\n",
       "  'more',\n",
       "  'abortions',\n",
       "  'and',\n",
       "  'female',\n",
       "  'infanticide'],\n",
       " ['people',\n",
       "  'should',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'do',\n",
       "  'what',\n",
       "  'they',\n",
       "  'want',\n",
       "  'with',\n",
       "  'their',\n",
       "  'bodies',\n",
       "  '.'],\n",
       " ['if',\n",
       "  'retirees',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'work',\n",
       "  'past',\n",
       "  'retirement',\n",
       "  'age',\n",
       "  ',',\n",
       "  'there',\n",
       "  'will',\n",
       "  'never',\n",
       "  'be',\n",
       "  'a',\n",
       "  'natural',\n",
       "  'progression',\n",
       "  'through',\n",
       "  'the',\n",
       "  'workplace',\n",
       "  'for',\n",
       "  'the',\n",
       "  'younger',\n",
       "  'generation',\n",
       "  '.'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'subsidize',\n",
       "  'wikipedia',\n",
       "  'because',\n",
       "  'everyone',\n",
       "  'in',\n",
       "  'the',\n",
       "  'world',\n",
       "  'knows',\n",
       "  'it',\n",
       "  'as',\n",
       "  'a',\n",
       "  'household',\n",
       "  'name',\n",
       "  'and',\n",
       "  'if',\n",
       "  'the',\n",
       "  'government',\n",
       "  'pays',\n",
       "  'for',\n",
       "  'libraries',\n",
       "  'why',\n",
       "  'ca',\n",
       "  'nt',\n",
       "  'they',\n",
       "  'pay',\n",
       "  'for',\n",
       "  'wikipedia',\n",
       "  'which',\n",
       "  'contains',\n",
       "  'probably',\n",
       "  'more',\n",
       "  'information',\n",
       "  '.'],\n",
       " ['school_uniforms',\n",
       "  'will',\n",
       "  'stop',\n",
       "  'children',\n",
       "  'from',\n",
       "  'wearing',\n",
       "  'and',\n",
       "  'showing',\n",
       "  'offense',\n",
       "  'logos',\n",
       "  ',',\n",
       "  'words',\n",
       "  ',',\n",
       "  'etc',\n",
       "  '.',\n",
       "  ',',\n",
       "  'to',\n",
       "  'their',\n",
       "  'peers',\n",
       "  '.'],\n",
       " ['wikipedia',\n",
       "  'is',\n",
       "  'a',\n",
       "  'valuable',\n",
       "  'resource',\n",
       "  'that',\n",
       "  'deserves',\n",
       "  'funding'],\n",
       " ['we',\n",
       "  'should',\n",
       "  'ban',\n",
       "  'targeted',\n",
       "  'killings',\n",
       "  'because',\n",
       "  'it',\n",
       "  'is',\n",
       "  'in',\n",
       "  'essence',\n",
       "  'just',\n",
       "  'murder',\n",
       "  'when',\n",
       "  'done',\n",
       "  'outside',\n",
       "  'of',\n",
       "  'wartime',\n",
       "  '.',\n",
       "  ' ',\n",
       "  'it',\n",
       "  'is',\n",
       "  ',',\n",
       "  'in',\n",
       "  'fact',\n",
       "  ',',\n",
       "  'an',\n",
       "  'act',\n",
       "  'of',\n",
       "  'war',\n",
       "  'and',\n",
       "  'could',\n",
       "  'create',\n",
       "  'more',\n",
       "  'problems',\n",
       "  '.'],\n",
       " ['factory_farming',\n",
       "  'is',\n",
       "  'a',\n",
       "  'way',\n",
       "  'of',\n",
       "  'producing',\n",
       "  'cheap',\n",
       "  'meat',\n",
       "  '.',\n",
       "  'without',\n",
       "  'it',\n",
       "  'poorer',\n",
       "  'people',\n",
       "  'may',\n",
       "  'not',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'afford',\n",
       "  'it',\n",
       "  'and',\n",
       "  'may',\n",
       "  'become',\n",
       "  'malnourished',\n",
       "  '.'],\n",
       " ['some',\n",
       "  'people',\n",
       "  'choose',\n",
       "  'not',\n",
       "  'to',\n",
       "  'vote',\n",
       "  'for',\n",
       "  'ethical',\n",
       "  'reasons',\n",
       "  '.'],\n",
       " ['economic_sanctions',\n",
       "  'are',\n",
       "  'very',\n",
       "  'effective',\n",
       "  'in',\n",
       "  'dealing',\n",
       "  'with',\n",
       "  'countries',\n",
       "  'who',\n",
       "  'have',\n",
       "  'many',\n",
       "  'human',\n",
       "  'rights',\n",
       "  'abuses',\n",
       "  'on',\n",
       "  'their',\n",
       "  'record',\n",
       "  '.'],\n",
       " ...]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "# Train a bigram model\n",
    "bigram = Phrases(documents, min_count=20, threshold=100) \n",
    "# we tuned the parameters so that the bigrams are the most informative and formed mostly by full words\n",
    "bigram_mod = Phraser(bigram)\n",
    "\n",
    "# Apply the trained bigram model to each document\n",
    "documents_with_bigrams = [bigram_mod[doc] for doc in documents]\n",
    "documents_with_bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To evaluate the doc2vec vectors we will compute the cosine similarity between the arguments with the same value, but first we must generalize the labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Self-direction: thought</th>\n",
       "      <th>Self-direction: action</th>\n",
       "      <th>Stimulation</th>\n",
       "      <th>Hedonism</th>\n",
       "      <th>Achievement</th>\n",
       "      <th>Power: dominance</th>\n",
       "      <th>Power: resources</th>\n",
       "      <th>Face</th>\n",
       "      <th>Security: personal</th>\n",
       "      <th>...</th>\n",
       "      <th>Tradition</th>\n",
       "      <th>Conformity: rules</th>\n",
       "      <th>Conformity: interpersonal</th>\n",
       "      <th>Humility</th>\n",
       "      <th>Benevolence: caring</th>\n",
       "      <th>Benevolence: dependability</th>\n",
       "      <th>Universalism: concern</th>\n",
       "      <th>Universalism: nature</th>\n",
       "      <th>Universalism: tolerance</th>\n",
       "      <th>Universalism: objectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A01002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A01005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A01006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A01007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A01008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Argument ID  Self-direction: thought  Self-direction: action  Stimulation   \n",
       "0      A01002                        0                       0            0  \\\n",
       "1      A01005                        0                       0            0   \n",
       "2      A01006                        0                       0            0   \n",
       "3      A01007                        0                       0            0   \n",
       "4      A01008                        0                       0            0   \n",
       "\n",
       "   Hedonism  Achievement  Power: dominance  Power: resources  Face   \n",
       "0         0            0                 0                 0     0  \\\n",
       "1         0            0                 0                 0     0   \n",
       "2         0            0                 1                 0     0   \n",
       "3         0            0                 0                 0     0   \n",
       "4         0            0                 0                 0     0   \n",
       "\n",
       "   Security: personal  ...  Tradition  Conformity: rules   \n",
       "0                   0  ...          0                  0  \\\n",
       "1                   1  ...          0                  0   \n",
       "2                   0  ...          0                  0   \n",
       "3                   0  ...          0                  1   \n",
       "4                   1  ...          0                  0   \n",
       "\n",
       "   Conformity: interpersonal  Humility  Benevolence: caring   \n",
       "0                          0         0                    0  \\\n",
       "1                          0         0                    0   \n",
       "2                          0         0                    0   \n",
       "3                          0         0                    0   \n",
       "4                          0         0                    1   \n",
       "\n",
       "   Benevolence: dependability  Universalism: concern  Universalism: nature   \n",
       "0                           0                      0                     0  \\\n",
       "1                           0                      0                     0   \n",
       "2                           0                      0                     0   \n",
       "3                           0                      1                     0   \n",
       "4                           0                      1                     0   \n",
       "\n",
       "   Universalism: tolerance  Universalism: objectivity  \n",
       "0                        0                          0  \n",
       "1                        0                          0  \n",
       "2                        0                          0  \n",
       "3                        0                          0  \n",
       "4                        0                          0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"labels-training.tsv\"\n",
    "labels_df = pd.read_table(path, sep = \"\\t\")\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we drop the row with no labels\n",
    "labels_df.drop(index=3358, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the row indices\n",
    "labels_df=labels_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we generalize labels according to the following dictionary\n",
    "general_dictionary={\n",
    "    \"Self-direction: thought\":\"Openness to change\",\n",
    "    \"Self-direction: action\":\"Openness to change\",\n",
    "    \"Stimulation\":\"Openness to change\",\n",
    "    \"Hedonism\":\"Openness to change\",\n",
    "    \"Achievement\":\"Self-Enhancement\",\n",
    "    \"Power: dominance\":\"Self-Enhancement\",\n",
    "    \"Power: resources\":\"Self-Enhancement\",\n",
    "    \"Face\":\"Self-Enhancement\",\n",
    "    \"Security: personal\":\"Conservation\",\n",
    "    \"Security: societal\":\"Conservation\",\n",
    "    \"Tradition\":\"Conservation\",\n",
    "    \"Conformity: rules\":\"Conservation\",\n",
    "    \"Conformity: interpersonal\":\"Conservation\",\n",
    "    \"Humility\":\"Conservation\",\n",
    "    \"Benevolence: caring\":\"Self-Transcendence\",\n",
    "    \"Benevolence: dependability\":\"Self-Transcendence\",\n",
    "    \"Universalism: concern\":\"Self-Transcendence\",\n",
    "    \"Universalism: nature\":\"Self-Transcendence\",\n",
    "    \"Universalism: tolerance\":\"Self-Transcendence\",\n",
    "    \"Universalism: objectivity\":\"Self-Transcendence\"\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df[\"Openness to change\"]=labels_df[\"Self-direction: thought\"]+labels_df[\"Self-direction: action\"]+labels_df[\"Stimulation\"]+labels_df[\"Hedonism\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df[\"Self-Enhancement\"]=labels_df[\"Achievement\"]+labels_df[\"Power: dominance\"]+labels_df[\"Power: resources\"]+labels_df[\"Face\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df[\"Conservation\"]=labels_df[\"Security: personal\"]+labels_df[\"Security: societal\"]+labels_df[\"Tradition\"]+labels_df[\"Conformity: rules\"]+labels_df[\"Conformity: interpersonal\"]+labels_df[\"Humility\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df[\"Self-Transcendence\"]=labels_df[\"Benevolence: caring\"]+labels_df[\"Benevolence: dependability\"]+labels_df[\"Universalism: concern\"]+labels_df[\"Universalism: nature\"]+labels_df[\"Universalism: tolerance\"]+labels_df[\"Universalism: objectivity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the new features are created, the original ones can be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in general_dictionary:\n",
    "    if key!=general_dictionary[key]:\n",
    "        labels_df=labels_df.drop(key, axis=1)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Openness to change</th>\n",
       "      <th>Self-Enhancement</th>\n",
       "      <th>Conservation</th>\n",
       "      <th>Self-Transcendence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A01002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A01005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A01006</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A01007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A01008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>E08016</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388</th>\n",
       "      <td>E08017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5389</th>\n",
       "      <td>E08018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>E08019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391</th>\n",
       "      <td>E08020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5392 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Argument ID  Openness to change  Self-Enhancement  Conservation   \n",
       "0         A01002                   0                 0             1  \\\n",
       "1         A01005                   0                 0             1   \n",
       "2         A01006                   0                 1             1   \n",
       "3         A01007                   0                 0             2   \n",
       "4         A01008                   0                 0             1   \n",
       "...          ...                 ...               ...           ...   \n",
       "5387      E08016                   0                 2             1   \n",
       "5388      E08017                   0                 0             2   \n",
       "5389      E08018                   0                 0             0   \n",
       "5390      E08019                   0                 0             3   \n",
       "5391      E08020                   1                 1             1   \n",
       "\n",
       "      Self-Transcendence  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      1  \n",
       "4                      2  \n",
       "...                  ...  \n",
       "5387                   1  \n",
       "5388                   3  \n",
       "5389                   2  \n",
       "5390                   3  \n",
       "5391                   1  \n",
       "\n",
       "[5392 rows x 5 columns]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Openness to change</th>\n",
       "      <th>Self-Enhancement</th>\n",
       "      <th>Conservation</th>\n",
       "      <th>Self-Transcendence</th>\n",
       "      <th>general_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A01002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A01005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A01006</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A01007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 2, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A01008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>E08016</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 2, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388</th>\n",
       "      <td>E08017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5389</th>\n",
       "      <td>E08018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 0, 0, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>E08019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[0, 0, 3, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391</th>\n",
       "      <td>E08020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5392 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Argument ID  Openness to change  Self-Enhancement  Conservation   \n",
       "0         A01002                   0                 0             1  \\\n",
       "1         A01005                   0                 0             1   \n",
       "2         A01006                   0                 1             1   \n",
       "3         A01007                   0                 0             2   \n",
       "4         A01008                   0                 0             1   \n",
       "...          ...                 ...               ...           ...   \n",
       "5387      E08016                   0                 2             1   \n",
       "5388      E08017                   0                 0             2   \n",
       "5389      E08018                   0                 0             0   \n",
       "5390      E08019                   0                 0             3   \n",
       "5391      E08020                   1                 1             1   \n",
       "\n",
       "      Self-Transcendence general_label  \n",
       "0                      0  [0, 0, 1, 0]  \n",
       "1                      0  [0, 0, 1, 0]  \n",
       "2                      0  [0, 1, 1, 0]  \n",
       "3                      1  [0, 0, 2, 1]  \n",
       "4                      2  [0, 0, 1, 2]  \n",
       "...                  ...           ...  \n",
       "5387                   1  [0, 2, 1, 1]  \n",
       "5388                   3  [0, 0, 2, 3]  \n",
       "5389                   2  [0, 0, 0, 2]  \n",
       "5390                   3  [0, 0, 3, 3]  \n",
       "5391                   1  [1, 1, 1, 1]  \n",
       "\n",
       "[5392 rows x 6 columns]"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the generalized label columns and store them in a separate DataFrame\n",
    "label_columns=labels_df[[\n",
    "\"Openness to change\",\n",
    "\"Self-Enhancement\",\n",
    "\"Conservation\",\n",
    "\"Self-Transcendence\"]]\n",
    "\n",
    "# convert the label columns to a multi-class format (one-hot encoding)\n",
    "labels_df['general_label'] = label_columns.apply(lambda row: row.to_list(), axis=1)\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=[]\n",
    "\n",
    "for sublist in labels_df[\"general_label\"]:\n",
    "    sum_values=sum(sublist)\n",
    "    probability_distribution=[value/sum_values for value in sublist]\n",
    "    final.append(probability_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df[\"general_label\"]=final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Argument ID</th>\n",
       "      <th>Openness to change</th>\n",
       "      <th>Self-Enhancement</th>\n",
       "      <th>Conservation</th>\n",
       "      <th>Self-Transcendence</th>\n",
       "      <th>general_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A01002</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A01005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A01006</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0, 0.5, 0.5, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A01007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.0, 0.6666666666666666, 0.3333333333333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A01008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 0.3333333333333333, 0.6666666666666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>E08016</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 0.5, 0.25, 0.25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388</th>\n",
       "      <td>E08017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.4, 0.6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5389</th>\n",
       "      <td>E08018</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>E08019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.5, 0.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391</th>\n",
       "      <td>E08020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.25, 0.25, 0.25, 0.25]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5392 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Argument ID  Openness to change  Self-Enhancement  Conservation   \n",
       "0         A01002                   0                 0             1  \\\n",
       "1         A01005                   0                 0             1   \n",
       "2         A01006                   0                 1             1   \n",
       "3         A01007                   0                 0             2   \n",
       "4         A01008                   0                 0             1   \n",
       "...          ...                 ...               ...           ...   \n",
       "5387      E08016                   0                 2             1   \n",
       "5388      E08017                   0                 0             2   \n",
       "5389      E08018                   0                 0             0   \n",
       "5390      E08019                   0                 0             3   \n",
       "5391      E08020                   1                 1             1   \n",
       "\n",
       "      Self-Transcendence                                      general_label  \n",
       "0                      0                               [0.0, 0.0, 1.0, 0.0]  \n",
       "1                      0                               [0.0, 0.0, 1.0, 0.0]  \n",
       "2                      0                               [0.0, 0.5, 0.5, 0.0]  \n",
       "3                      1  [0.0, 0.0, 0.6666666666666666, 0.3333333333333...  \n",
       "4                      2  [0.0, 0.0, 0.3333333333333333, 0.6666666666666...  \n",
       "...                  ...                                                ...  \n",
       "5387                   1                             [0.0, 0.5, 0.25, 0.25]  \n",
       "5388                   3                               [0.0, 0.0, 0.4, 0.6]  \n",
       "5389                   2                               [0.0, 0.0, 0.0, 1.0]  \n",
       "5390                   3                               [0.0, 0.0, 0.5, 0.5]  \n",
       "5391                   1                           [0.25, 0.25, 0.25, 0.25]  \n",
       "\n",
       "[5392 rows x 6 columns]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can implement a gridsearch to find the best parameters for doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a list of labels that represent our values per argument\n",
    "values = [[l_values for l_values in row.general_label] for id, row in labels_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we split into training and test to find the best params for doc2vec\n",
    "train_docs, test_docs, train_values, test_values = train_test_split(documents_with_bigrams, values, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Function to evaluate similarity\n",
    "def evaluate_similarity(model, documents, values):\n",
    "    \"\"\"function that evaluates the mean similarity score, given a doc2vec model,\n",
    "    of the vectors that have the same labels\"\"\"\n",
    "    \n",
    "    doc_vectors = [model.infer_vector(doc) for doc in documents]\n",
    "    similarity_scores = []\n",
    "\n",
    "    for i in range(len(documents)):\n",
    "        for j in range(i + 1, len(documents)):\n",
    "            if values[i] == values[j]:\n",
    "                sim_score = cosine_similarity([doc_vectors[i]], [doc_vectors[j]])[0][0]\n",
    "                similarity_scores.append(sim_score)\n",
    "\n",
    "    return np.mean(similarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we implement a gridsearch for the parameters \n",
    "param_grid = {\n",
    "    'vector_size': [50, 100, 200],\n",
    "    'dm': [1, 0],\n",
    "    'window': [5, 7, 10],\n",
    "    'min_count': [5, 7, 9],\n",
    "    'epochs': [10, 30, 50],\n",
    "    \"negative\": [5, 10, 15]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate_doc2vec(params, train_docs, test_docs, test_values):\n",
    "    \"\"\"function that returns the evaluation of a doc2vec model, given the\n",
    "    parameters, the documents for the training, the documents for testing\n",
    "    and the test labels\"\"\"\n",
    "    \n",
    "    tagged_train_docs = [TaggedDocument(doc, [i]) for i, doc in enumerate(train_docs)]\n",
    "    model = Doc2Vec(documents=tagged_train_docs,\n",
    "                    vector_size=params['vector_size'],\n",
    "                    dm = params[\"dm\"], \n",
    "                    window=params['window'], \n",
    "                    min_count=params['min_count'], \n",
    "                    epochs=params['epochs'],\n",
    "                    negative = params[\"negative\"])\n",
    "\n",
    "    return evaluate_similarity(model, test_docs, test_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/486 [00:00<?, ?it/s]2023-12-06 14:13:41,362 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:13:41,363 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:13:41,384 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:13:41,385 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:13:41,390 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:13:41.390055', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:13:41,391 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:13:41.391054', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:13:41,398 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:13:41,399 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:13:41,399 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:13:41.399057', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:13:41,410 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:13:41,411 : INFO : resetting layer weights\n",
      "2023-12-06 14:13:41,414 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:13:41.414858', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:13:41,604 : INFO : EPOCH 0: training on 99524 raw words (65404 effective words) took 0.2s, 353053 effective words/s\n",
      "2023-12-06 14:13:41,789 : INFO : EPOCH 1: training on 99524 raw words (65591 effective words) took 0.2s, 361950 effective words/s\n",
      "2023-12-06 14:13:41,975 : INFO : EPOCH 2: training on 99524 raw words (65553 effective words) took 0.2s, 360772 effective words/s\n",
      "2023-12-06 14:13:42,159 : INFO : EPOCH 3: training on 99524 raw words (65624 effective words) took 0.2s, 365011 effective words/s\n",
      "2023-12-06 14:13:42,346 : INFO : EPOCH 4: training on 99524 raw words (65613 effective words) took 0.2s, 360083 effective words/s\n",
      "2023-12-06 14:13:42,538 : INFO : EPOCH 5: training on 99524 raw words (65663 effective words) took 0.2s, 349499 effective words/s\n",
      "2023-12-06 14:13:42,739 : INFO : EPOCH 6: training on 99524 raw words (65410 effective words) took 0.2s, 333079 effective words/s\n",
      "2023-12-06 14:13:42,938 : INFO : EPOCH 7: training on 99524 raw words (65583 effective words) took 0.2s, 336234 effective words/s\n",
      "2023-12-06 14:13:43,130 : INFO : EPOCH 8: training on 99524 raw words (65563 effective words) took 0.2s, 350887 effective words/s\n",
      "2023-12-06 14:13:43,322 : INFO : EPOCH 9: training on 99524 raw words (65613 effective words) took 0.2s, 349849 effective words/s\n",
      "2023-12-06 14:13:43,323 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655617 effective words) took 1.9s, 343667 effective words/s', 'datetime': '2023-12-06T14:13:43.323125', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:13:43,323 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:13:43.323125', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  0%|          | 1/486 [00:04<38:10,  4.72s/it]2023-12-06 14:13:46,081 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:13:46,081 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:13:46,102 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:13:46,102 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:13:46,109 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:13:46.109302', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:13:46,110 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:13:46.110299', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:13:46,116 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:13:46,117 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:13:46,117 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:13:46.117608', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:13:46,131 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:13:46,131 : INFO : resetting layer weights\n",
      "2023-12-06 14:13:46,134 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:13:46.134154', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:13:46,323 : INFO : EPOCH 0: training on 99524 raw words (65526 effective words) took 0.2s, 350798 effective words/s\n",
      "2023-12-06 14:13:46,514 : INFO : EPOCH 1: training on 99524 raw words (65580 effective words) took 0.2s, 353072 effective words/s\n",
      "2023-12-06 14:13:46,704 : INFO : EPOCH 2: training on 99524 raw words (65451 effective words) took 0.2s, 351814 effective words/s\n",
      "2023-12-06 14:13:46,894 : INFO : EPOCH 3: training on 99524 raw words (65594 effective words) took 0.2s, 353682 effective words/s\n",
      "2023-12-06 14:13:47,086 : INFO : EPOCH 4: training on 99524 raw words (65410 effective words) took 0.2s, 348836 effective words/s\n",
      "2023-12-06 14:13:47,276 : INFO : EPOCH 5: training on 99524 raw words (65545 effective words) took 0.2s, 352623 effective words/s\n",
      "2023-12-06 14:13:47,468 : INFO : EPOCH 6: training on 99524 raw words (65505 effective words) took 0.2s, 349631 effective words/s\n",
      "2023-12-06 14:13:47,659 : INFO : EPOCH 7: training on 99524 raw words (65596 effective words) took 0.2s, 353226 effective words/s\n",
      "2023-12-06 14:13:47,848 : INFO : EPOCH 8: training on 99524 raw words (65497 effective words) took 0.2s, 352904 effective words/s\n",
      "2023-12-06 14:13:48,037 : INFO : EPOCH 9: training on 99524 raw words (65708 effective words) took 0.2s, 353140 effective words/s\n",
      "2023-12-06 14:13:48,038 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655412 effective words) took 1.9s, 344184 effective words/s', 'datetime': '2023-12-06T14:13:48.038852', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:13:48,038 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:13:48.038852', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  0%|          | 2/486 [00:09<37:41,  4.67s/it]2023-12-06 14:13:50,722 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:13:50,722 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:13:50,743 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:13:50,743 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:13:50,748 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:13:50.748888', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:13:50,749 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:13:50.749888', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:13:50,757 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:13:50,757 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:13:50,758 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:13:50.758888', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:13:50,769 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:13:50,770 : INFO : resetting layer weights\n",
      "2023-12-06 14:13:50,772 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:13:50.772199', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:13:50,968 : INFO : EPOCH 0: training on 99524 raw words (65545 effective words) took 0.2s, 342418 effective words/s\n",
      "2023-12-06 14:13:51,161 : INFO : EPOCH 1: training on 99524 raw words (65608 effective words) took 0.2s, 346207 effective words/s\n",
      "2023-12-06 14:13:51,355 : INFO : EPOCH 2: training on 99524 raw words (65431 effective words) took 0.2s, 346238 effective words/s\n",
      "2023-12-06 14:13:51,548 : INFO : EPOCH 3: training on 99524 raw words (65483 effective words) took 0.2s, 346225 effective words/s\n",
      "2023-12-06 14:13:51,743 : INFO : EPOCH 4: training on 99524 raw words (65495 effective words) took 0.2s, 344255 effective words/s\n",
      "2023-12-06 14:13:51,937 : INFO : EPOCH 5: training on 99524 raw words (65665 effective words) took 0.2s, 346372 effective words/s\n",
      "2023-12-06 14:13:52,131 : INFO : EPOCH 6: training on 99524 raw words (65620 effective words) took 0.2s, 345752 effective words/s\n",
      "2023-12-06 14:13:52,326 : INFO : EPOCH 7: training on 99524 raw words (65595 effective words) took 0.2s, 342571 effective words/s\n",
      "2023-12-06 14:13:52,524 : INFO : EPOCH 8: training on 99524 raw words (65753 effective words) took 0.2s, 342034 effective words/s\n",
      "2023-12-06 14:13:52,717 : INFO : EPOCH 9: training on 99524 raw words (65546 effective words) took 0.2s, 346265 effective words/s\n",
      "2023-12-06 14:13:52,718 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655741 effective words) took 1.9s, 337131 effective words/s', 'datetime': '2023-12-06T14:13:52.718119', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:13:52,719 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:13:52.719118', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  1%|          | 3/486 [00:14<38:04,  4.73s/it]2023-12-06 14:13:55,518 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:13:55,519 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:13:55,542 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:13:55,543 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:13:55,549 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:13:55.549019', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:13:55,550 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:13:55.550020', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:13:55,557 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:13:55,558 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:13:55,559 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:13:55.559366', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:13:55,570 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:13:55,571 : INFO : resetting layer weights\n",
      "2023-12-06 14:13:55,573 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:13:55.573961', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:13:55,761 : INFO : EPOCH 0: training on 99524 raw words (65596 effective words) took 0.2s, 358595 effective words/s\n",
      "2023-12-06 14:13:55,958 : INFO : EPOCH 1: training on 99524 raw words (65599 effective words) took 0.2s, 340448 effective words/s\n",
      "2023-12-06 14:13:56,153 : INFO : EPOCH 2: training on 99524 raw words (65441 effective words) took 0.2s, 342627 effective words/s\n",
      "2023-12-06 14:13:56,349 : INFO : EPOCH 3: training on 99524 raw words (65408 effective words) took 0.2s, 342400 effective words/s\n",
      "2023-12-06 14:13:56,540 : INFO : EPOCH 4: training on 99524 raw words (65567 effective words) took 0.2s, 352371 effective words/s\n",
      "2023-12-06 14:13:56,727 : INFO : EPOCH 5: training on 99524 raw words (65560 effective words) took 0.2s, 357188 effective words/s\n",
      "2023-12-06 14:13:56,913 : INFO : EPOCH 6: training on 99524 raw words (65545 effective words) took 0.2s, 359349 effective words/s\n",
      "2023-12-06 14:13:57,101 : INFO : EPOCH 7: training on 99524 raw words (65602 effective words) took 0.2s, 358967 effective words/s\n",
      "2023-12-06 14:13:57,288 : INFO : EPOCH 8: training on 99524 raw words (65449 effective words) took 0.2s, 357430 effective words/s\n",
      "2023-12-06 14:13:57,476 : INFO : EPOCH 9: training on 99524 raw words (65590 effective words) took 0.2s, 355040 effective words/s\n",
      "2023-12-06 14:13:57,663 : INFO : EPOCH 10: training on 99524 raw words (65613 effective words) took 0.2s, 359212 effective words/s\n",
      "2023-12-06 14:13:57,851 : INFO : EPOCH 11: training on 99524 raw words (65467 effective words) took 0.2s, 356837 effective words/s\n",
      "2023-12-06 14:13:58,039 : INFO : EPOCH 12: training on 99524 raw words (65608 effective words) took 0.2s, 356772 effective words/s\n",
      "2023-12-06 14:13:58,226 : INFO : EPOCH 13: training on 99524 raw words (65414 effective words) took 0.2s, 357197 effective words/s\n",
      "2023-12-06 14:13:58,416 : INFO : EPOCH 14: training on 99524 raw words (65548 effective words) took 0.2s, 354323 effective words/s\n",
      "2023-12-06 14:13:58,603 : INFO : EPOCH 15: training on 99524 raw words (65530 effective words) took 0.2s, 359687 effective words/s\n",
      "2023-12-06 14:13:58,790 : INFO : EPOCH 16: training on 99524 raw words (65601 effective words) took 0.2s, 358648 effective words/s\n",
      "2023-12-06 14:13:58,977 : INFO : EPOCH 17: training on 99524 raw words (65506 effective words) took 0.2s, 357240 effective words/s\n",
      "2023-12-06 14:13:59,165 : INFO : EPOCH 18: training on 99524 raw words (65469 effective words) took 0.2s, 358046 effective words/s\n",
      "2023-12-06 14:13:59,353 : INFO : EPOCH 19: training on 99524 raw words (65417 effective words) took 0.2s, 355296 effective words/s\n",
      "2023-12-06 14:13:59,541 : INFO : EPOCH 20: training on 99524 raw words (65515 effective words) took 0.2s, 355453 effective words/s\n",
      "2023-12-06 14:13:59,728 : INFO : EPOCH 21: training on 99524 raw words (65729 effective words) took 0.2s, 359022 effective words/s\n",
      "2023-12-06 14:13:59,928 : INFO : EPOCH 22: training on 99524 raw words (65489 effective words) took 0.2s, 334555 effective words/s\n",
      "2023-12-06 14:14:00,123 : INFO : EPOCH 23: training on 99524 raw words (65456 effective words) took 0.2s, 344608 effective words/s\n",
      "2023-12-06 14:14:00,313 : INFO : EPOCH 24: training on 99524 raw words (65631 effective words) took 0.2s, 352904 effective words/s\n",
      "2023-12-06 14:14:00,503 : INFO : EPOCH 25: training on 99524 raw words (65573 effective words) took 0.2s, 353809 effective words/s\n",
      "2023-12-06 14:14:00,693 : INFO : EPOCH 26: training on 99524 raw words (65621 effective words) took 0.2s, 353346 effective words/s\n",
      "2023-12-06 14:14:00,882 : INFO : EPOCH 27: training on 99524 raw words (65509 effective words) took 0.2s, 354675 effective words/s\n",
      "2023-12-06 14:14:01,072 : INFO : EPOCH 28: training on 99524 raw words (65423 effective words) took 0.2s, 353596 effective words/s\n",
      "2023-12-06 14:14:01,261 : INFO : EPOCH 29: training on 99524 raw words (65453 effective words) took 0.2s, 354618 effective words/s\n",
      "2023-12-06 14:14:01,262 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965929 effective words) took 5.7s, 345668 effective words/s', 'datetime': '2023-12-06T14:14:01.262151', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:14:01,263 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:14:01.263154', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  1%|          | 4/486 [00:23<51:23,  6.40s/it]2023-12-06 14:14:04,474 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:14:04,474 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:14:04,497 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:14:04,498 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:14:04,504 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:14:04.504040', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:14:04,505 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:14:04.505040', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:14:04,512 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:14:04,513 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:14:04,514 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:14:04.513296', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:14:04,524 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:14:04,525 : INFO : resetting layer weights\n",
      "2023-12-06 14:14:04,527 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:14:04.527800', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:14:04,730 : INFO : EPOCH 0: training on 99524 raw words (65527 effective words) took 0.2s, 331338 effective words/s\n",
      "2023-12-06 14:14:04,934 : INFO : EPOCH 1: training on 99524 raw words (65601 effective words) took 0.2s, 330116 effective words/s\n",
      "2023-12-06 14:14:05,144 : INFO : EPOCH 2: training on 99524 raw words (65498 effective words) took 0.2s, 317276 effective words/s\n",
      "2023-12-06 14:14:05,343 : INFO : EPOCH 3: training on 99524 raw words (65591 effective words) took 0.2s, 337581 effective words/s\n",
      "2023-12-06 14:14:05,538 : INFO : EPOCH 4: training on 99524 raw words (65608 effective words) took 0.2s, 345450 effective words/s\n",
      "2023-12-06 14:14:05,731 : INFO : EPOCH 5: training on 99524 raw words (65418 effective words) took 0.2s, 345521 effective words/s\n",
      "2023-12-06 14:14:05,923 : INFO : EPOCH 6: training on 99524 raw words (65547 effective words) took 0.2s, 349707 effective words/s\n",
      "2023-12-06 14:14:06,116 : INFO : EPOCH 7: training on 99524 raw words (65445 effective words) took 0.2s, 346484 effective words/s\n",
      "2023-12-06 14:14:06,308 : INFO : EPOCH 8: training on 99524 raw words (65574 effective words) took 0.2s, 348402 effective words/s\n",
      "2023-12-06 14:14:06,501 : INFO : EPOCH 9: training on 99524 raw words (65276 effective words) took 0.2s, 346531 effective words/s\n",
      "2023-12-06 14:14:06,695 : INFO : EPOCH 10: training on 99524 raw words (65468 effective words) took 0.2s, 345419 effective words/s\n",
      "2023-12-06 14:14:06,888 : INFO : EPOCH 11: training on 99524 raw words (65570 effective words) took 0.2s, 346754 effective words/s\n",
      "2023-12-06 14:14:07,080 : INFO : EPOCH 12: training on 99524 raw words (65572 effective words) took 0.2s, 350414 effective words/s\n",
      "2023-12-06 14:14:07,270 : INFO : EPOCH 13: training on 99524 raw words (65377 effective words) took 0.2s, 351895 effective words/s\n",
      "2023-12-06 14:14:07,464 : INFO : EPOCH 14: training on 99524 raw words (65688 effective words) took 0.2s, 346396 effective words/s\n",
      "2023-12-06 14:14:07,655 : INFO : EPOCH 15: training on 99524 raw words (65445 effective words) took 0.2s, 350742 effective words/s\n",
      "2023-12-06 14:14:07,846 : INFO : EPOCH 16: training on 99524 raw words (65660 effective words) took 0.2s, 350285 effective words/s\n",
      "2023-12-06 14:14:08,041 : INFO : EPOCH 17: training on 99524 raw words (65426 effective words) took 0.2s, 343577 effective words/s\n",
      "2023-12-06 14:14:08,243 : INFO : EPOCH 18: training on 99524 raw words (65445 effective words) took 0.2s, 330189 effective words/s\n",
      "2023-12-06 14:14:08,433 : INFO : EPOCH 19: training on 99524 raw words (65720 effective words) took 0.2s, 354149 effective words/s\n",
      "2023-12-06 14:14:08,625 : INFO : EPOCH 20: training on 99524 raw words (65406 effective words) took 0.2s, 349915 effective words/s\n",
      "2023-12-06 14:14:08,816 : INFO : EPOCH 21: training on 99524 raw words (65545 effective words) took 0.2s, 350538 effective words/s\n",
      "2023-12-06 14:14:09,008 : INFO : EPOCH 22: training on 99524 raw words (65339 effective words) took 0.2s, 347498 effective words/s\n",
      "2023-12-06 14:14:09,200 : INFO : EPOCH 23: training on 99524 raw words (65642 effective words) took 0.2s, 348752 effective words/s\n",
      "2023-12-06 14:14:09,392 : INFO : EPOCH 24: training on 99524 raw words (65573 effective words) took 0.2s, 350777 effective words/s\n",
      "2023-12-06 14:14:09,602 : INFO : EPOCH 25: training on 99524 raw words (65452 effective words) took 0.2s, 316617 effective words/s\n",
      "2023-12-06 14:14:09,795 : INFO : EPOCH 26: training on 99524 raw words (65403 effective words) took 0.2s, 346558 effective words/s\n",
      "2023-12-06 14:14:09,987 : INFO : EPOCH 27: training on 99524 raw words (65373 effective words) took 0.2s, 349182 effective words/s\n",
      "2023-12-06 14:14:10,177 : INFO : EPOCH 28: training on 99524 raw words (65462 effective words) took 0.2s, 349701 effective words/s\n",
      "2023-12-06 14:14:10,371 : INFO : EPOCH 29: training on 99524 raw words (65500 effective words) took 0.2s, 347626 effective words/s\n",
      "2023-12-06 14:14:10,371 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965151 effective words) took 5.8s, 336319 effective words/s', 'datetime': '2023-12-06T14:14:10.371362', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:14:10,372 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:14:10.372374', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  1%|          | 5/486 [00:32<59:23,  7.41s/it]2023-12-06 14:14:13,677 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:14:13,677 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:14:13,698 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:14:13,698 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:14:13,704 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:14:13.704714', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:14:13,705 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:14:13.705715', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:14:13,713 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:14:13,714 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:14:13,714 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:14:13.714326', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:14:13,725 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:14:13,725 : INFO : resetting layer weights\n",
      "2023-12-06 14:14:13,728 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:14:13.728314', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:14:13,922 : INFO : EPOCH 0: training on 99524 raw words (65229 effective words) took 0.2s, 341819 effective words/s\n",
      "2023-12-06 14:14:14,117 : INFO : EPOCH 1: training on 99524 raw words (65569 effective words) took 0.2s, 344115 effective words/s\n",
      "2023-12-06 14:14:14,311 : INFO : EPOCH 2: training on 99524 raw words (65629 effective words) took 0.2s, 346688 effective words/s\n",
      "2023-12-06 14:14:14,505 : INFO : EPOCH 3: training on 99524 raw words (65539 effective words) took 0.2s, 345284 effective words/s\n",
      "2023-12-06 14:14:14,701 : INFO : EPOCH 4: training on 99524 raw words (65409 effective words) took 0.2s, 341495 effective words/s\n",
      "2023-12-06 14:14:14,896 : INFO : EPOCH 5: training on 99524 raw words (65566 effective words) took 0.2s, 344838 effective words/s\n",
      "2023-12-06 14:14:15,091 : INFO : EPOCH 6: training on 99524 raw words (65418 effective words) took 0.2s, 341200 effective words/s\n",
      "2023-12-06 14:14:15,286 : INFO : EPOCH 7: training on 99524 raw words (65541 effective words) took 0.2s, 343248 effective words/s\n",
      "2023-12-06 14:14:15,482 : INFO : EPOCH 8: training on 99524 raw words (65451 effective words) took 0.2s, 341626 effective words/s\n",
      "2023-12-06 14:14:15,677 : INFO : EPOCH 9: training on 99524 raw words (65588 effective words) took 0.2s, 343641 effective words/s\n",
      "2023-12-06 14:14:15,874 : INFO : EPOCH 10: training on 99524 raw words (65576 effective words) took 0.2s, 340853 effective words/s\n",
      "2023-12-06 14:14:16,071 : INFO : EPOCH 11: training on 99524 raw words (65635 effective words) took 0.2s, 339376 effective words/s\n",
      "2023-12-06 14:14:16,270 : INFO : EPOCH 12: training on 99524 raw words (65417 effective words) took 0.2s, 336155 effective words/s\n",
      "2023-12-06 14:14:16,467 : INFO : EPOCH 13: training on 99524 raw words (65652 effective words) took 0.2s, 341610 effective words/s\n",
      "2023-12-06 14:14:16,660 : INFO : EPOCH 14: training on 99524 raw words (65437 effective words) took 0.2s, 346545 effective words/s\n",
      "2023-12-06 14:14:16,854 : INFO : EPOCH 15: training on 99524 raw words (65518 effective words) took 0.2s, 345621 effective words/s\n",
      "2023-12-06 14:14:17,050 : INFO : EPOCH 16: training on 99524 raw words (65530 effective words) took 0.2s, 341947 effective words/s\n",
      "2023-12-06 14:14:17,244 : INFO : EPOCH 17: training on 99524 raw words (65695 effective words) took 0.2s, 346157 effective words/s\n",
      "2023-12-06 14:14:17,438 : INFO : EPOCH 18: training on 99524 raw words (65723 effective words) took 0.2s, 346079 effective words/s\n",
      "2023-12-06 14:14:17,632 : INFO : EPOCH 19: training on 99524 raw words (65279 effective words) took 0.2s, 342480 effective words/s\n",
      "2023-12-06 14:14:17,829 : INFO : EPOCH 20: training on 99524 raw words (65471 effective words) took 0.2s, 341356 effective words/s\n",
      "2023-12-06 14:14:18,025 : INFO : EPOCH 21: training on 99524 raw words (65330 effective words) took 0.2s, 340665 effective words/s\n",
      "2023-12-06 14:14:18,220 : INFO : EPOCH 22: training on 99524 raw words (65509 effective words) took 0.2s, 343855 effective words/s\n",
      "2023-12-06 14:14:18,417 : INFO : EPOCH 23: training on 99524 raw words (65483 effective words) took 0.2s, 339869 effective words/s\n",
      "2023-12-06 14:14:18,610 : INFO : EPOCH 24: training on 99524 raw words (65516 effective words) took 0.2s, 345516 effective words/s\n",
      "2023-12-06 14:14:18,804 : INFO : EPOCH 25: training on 99524 raw words (65696 effective words) took 0.2s, 346142 effective words/s\n",
      "2023-12-06 14:14:18,999 : INFO : EPOCH 26: training on 99524 raw words (65673 effective words) took 0.2s, 343216 effective words/s\n",
      "2023-12-06 14:14:19,193 : INFO : EPOCH 27: training on 99524 raw words (65532 effective words) took 0.2s, 345912 effective words/s\n",
      "2023-12-06 14:14:19,388 : INFO : EPOCH 28: training on 99524 raw words (65645 effective words) took 0.2s, 343721 effective words/s\n",
      "2023-12-06 14:14:19,585 : INFO : EPOCH 29: training on 99524 raw words (65525 effective words) took 0.2s, 341713 effective words/s\n",
      "2023-12-06 14:14:19,585 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965781 effective words) took 5.9s, 335613 effective words/s', 'datetime': '2023-12-06T14:14:19.585314', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:14:19,586 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:14:19.586473', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  1%|          | 6/486 [00:41<1:04:39,  8.08s/it]2023-12-06 14:14:23,061 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:14:23,061 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:14:23,082 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:14:23,083 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:14:23,088 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:14:23.088355', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:14:23,089 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:14:23.089355', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:14:23,096 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:14:23,096 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:14:23,097 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:14:23.097885', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:14:23,108 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:14:23,108 : INFO : resetting layer weights\n",
      "2023-12-06 14:14:23,110 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:14:23.110297', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:14:23,298 : INFO : EPOCH 0: training on 99524 raw words (65684 effective words) took 0.2s, 357775 effective words/s\n",
      "2023-12-06 14:14:23,487 : INFO : EPOCH 1: training on 99524 raw words (65691 effective words) took 0.2s, 355164 effective words/s\n",
      "2023-12-06 14:14:23,677 : INFO : EPOCH 2: training on 99524 raw words (65615 effective words) took 0.2s, 355282 effective words/s\n",
      "2023-12-06 14:14:23,874 : INFO : EPOCH 3: training on 99524 raw words (65490 effective words) took 0.2s, 337955 effective words/s\n",
      "2023-12-06 14:14:24,062 : INFO : EPOCH 4: training on 99524 raw words (65561 effective words) took 0.2s, 356184 effective words/s\n",
      "2023-12-06 14:14:24,250 : INFO : EPOCH 5: training on 99524 raw words (65528 effective words) took 0.2s, 355260 effective words/s\n",
      "2023-12-06 14:14:24,439 : INFO : EPOCH 6: training on 99524 raw words (65408 effective words) took 0.2s, 355210 effective words/s\n",
      "2023-12-06 14:14:24,629 : INFO : EPOCH 7: training on 99524 raw words (65578 effective words) took 0.2s, 353976 effective words/s\n",
      "2023-12-06 14:14:24,819 : INFO : EPOCH 8: training on 99524 raw words (65357 effective words) took 0.2s, 350978 effective words/s\n",
      "2023-12-06 14:14:25,009 : INFO : EPOCH 9: training on 99524 raw words (65428 effective words) took 0.2s, 352744 effective words/s\n",
      "2023-12-06 14:14:25,197 : INFO : EPOCH 10: training on 99524 raw words (65485 effective words) took 0.2s, 355583 effective words/s\n",
      "2023-12-06 14:14:25,387 : INFO : EPOCH 11: training on 99524 raw words (65521 effective words) took 0.2s, 353253 effective words/s\n",
      "2023-12-06 14:14:25,576 : INFO : EPOCH 12: training on 99524 raw words (65585 effective words) took 0.2s, 355148 effective words/s\n",
      "2023-12-06 14:14:25,765 : INFO : EPOCH 13: training on 99524 raw words (65549 effective words) took 0.2s, 355462 effective words/s\n",
      "2023-12-06 14:14:25,954 : INFO : EPOCH 14: training on 99524 raw words (65510 effective words) took 0.2s, 354006 effective words/s\n",
      "2023-12-06 14:14:26,143 : INFO : EPOCH 15: training on 99524 raw words (65573 effective words) took 0.2s, 355436 effective words/s\n",
      "2023-12-06 14:14:26,333 : INFO : EPOCH 16: training on 99524 raw words (65399 effective words) took 0.2s, 352673 effective words/s\n",
      "2023-12-06 14:14:26,523 : INFO : EPOCH 17: training on 99524 raw words (65516 effective words) took 0.2s, 350433 effective words/s\n",
      "2023-12-06 14:14:26,712 : INFO : EPOCH 18: training on 99524 raw words (65601 effective words) took 0.2s, 354627 effective words/s\n",
      "2023-12-06 14:14:26,901 : INFO : EPOCH 19: training on 99524 raw words (65485 effective words) took 0.2s, 355857 effective words/s\n",
      "2023-12-06 14:14:27,091 : INFO : EPOCH 20: training on 99524 raw words (65527 effective words) took 0.2s, 354145 effective words/s\n",
      "2023-12-06 14:14:27,279 : INFO : EPOCH 21: training on 99524 raw words (65491 effective words) took 0.2s, 354993 effective words/s\n",
      "2023-12-06 14:14:27,467 : INFO : EPOCH 22: training on 99524 raw words (65304 effective words) took 0.2s, 354981 effective words/s\n",
      "2023-12-06 14:14:27,658 : INFO : EPOCH 23: training on 99524 raw words (65510 effective words) took 0.2s, 352731 effective words/s\n",
      "2023-12-06 14:14:27,845 : INFO : EPOCH 24: training on 99524 raw words (65521 effective words) took 0.2s, 357750 effective words/s\n",
      "2023-12-06 14:14:28,034 : INFO : EPOCH 25: training on 99524 raw words (65545 effective words) took 0.2s, 354861 effective words/s\n",
      "2023-12-06 14:14:28,225 : INFO : EPOCH 26: training on 99524 raw words (65665 effective words) took 0.2s, 351751 effective words/s\n",
      "2023-12-06 14:14:28,414 : INFO : EPOCH 27: training on 99524 raw words (65456 effective words) took 0.2s, 354366 effective words/s\n",
      "2023-12-06 14:14:28,602 : INFO : EPOCH 28: training on 99524 raw words (65592 effective words) took 0.2s, 356253 effective words/s\n",
      "2023-12-06 14:14:28,792 : INFO : EPOCH 29: training on 99524 raw words (65574 effective words) took 0.2s, 354107 effective words/s\n",
      "2023-12-06 14:14:28,980 : INFO : EPOCH 30: training on 99524 raw words (65527 effective words) took 0.2s, 356796 effective words/s\n",
      "2023-12-06 14:14:29,168 : INFO : EPOCH 31: training on 99524 raw words (65645 effective words) took 0.2s, 356138 effective words/s\n",
      "2023-12-06 14:14:29,357 : INFO : EPOCH 32: training on 99524 raw words (65554 effective words) took 0.2s, 354098 effective words/s\n",
      "2023-12-06 14:14:29,545 : INFO : EPOCH 33: training on 99524 raw words (65352 effective words) took 0.2s, 355118 effective words/s\n",
      "2023-12-06 14:14:29,735 : INFO : EPOCH 34: training on 99524 raw words (65542 effective words) took 0.2s, 353451 effective words/s\n",
      "2023-12-06 14:14:29,925 : INFO : EPOCH 35: training on 99524 raw words (65519 effective words) took 0.2s, 351711 effective words/s\n",
      "2023-12-06 14:14:30,116 : INFO : EPOCH 36: training on 99524 raw words (65572 effective words) took 0.2s, 353814 effective words/s\n",
      "2023-12-06 14:14:30,306 : INFO : EPOCH 37: training on 99524 raw words (65574 effective words) took 0.2s, 352140 effective words/s\n",
      "2023-12-06 14:14:30,496 : INFO : EPOCH 38: training on 99524 raw words (65653 effective words) took 0.2s, 354644 effective words/s\n",
      "2023-12-06 14:14:30,682 : INFO : EPOCH 39: training on 99524 raw words (65395 effective words) took 0.2s, 356689 effective words/s\n",
      "2023-12-06 14:14:30,872 : INFO : EPOCH 40: training on 99524 raw words (65584 effective words) took 0.2s, 354742 effective words/s\n",
      "2023-12-06 14:14:31,061 : INFO : EPOCH 41: training on 99524 raw words (65617 effective words) took 0.2s, 355429 effective words/s\n",
      "2023-12-06 14:14:31,251 : INFO : EPOCH 42: training on 99524 raw words (65319 effective words) took 0.2s, 351973 effective words/s\n",
      "2023-12-06 14:14:31,441 : INFO : EPOCH 43: training on 99524 raw words (65605 effective words) took 0.2s, 352285 effective words/s\n",
      "2023-12-06 14:14:31,631 : INFO : EPOCH 44: training on 99524 raw words (65516 effective words) took 0.2s, 354030 effective words/s\n",
      "2023-12-06 14:14:31,830 : INFO : EPOCH 45: training on 99524 raw words (65398 effective words) took 0.2s, 335686 effective words/s\n",
      "2023-12-06 14:14:32,018 : INFO : EPOCH 46: training on 99524 raw words (65529 effective words) took 0.2s, 357415 effective words/s\n",
      "2023-12-06 14:14:32,208 : INFO : EPOCH 47: training on 99524 raw words (65450 effective words) took 0.2s, 353930 effective words/s\n",
      "2023-12-06 14:14:32,397 : INFO : EPOCH 48: training on 99524 raw words (65592 effective words) took 0.2s, 354869 effective words/s\n",
      "2023-12-06 14:14:32,585 : INFO : EPOCH 49: training on 99524 raw words (65493 effective words) took 0.2s, 355330 effective words/s\n",
      "2023-12-06 14:14:32,586 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276185 effective words) took 9.5s, 345769 effective words/s', 'datetime': '2023-12-06T14:14:32.586146', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:14:32,586 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:14:32.586146', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  1%|         | 7/486 [00:54<1:17:49,  9.75s/it]2023-12-06 14:14:36,244 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:14:36,245 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:14:36,265 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:14:36,267 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:14:36,272 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:14:36.272910', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:14:36,272 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:14:36.272910', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:14:36,280 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:14:36,281 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:14:36,281 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:14:36.281498', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:14:36,296 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:14:36,297 : INFO : resetting layer weights\n",
      "2023-12-06 14:14:36,299 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:14:36.299142', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:14:36,498 : INFO : EPOCH 0: training on 99524 raw words (65579 effective words) took 0.2s, 334663 effective words/s\n",
      "2023-12-06 14:14:36,695 : INFO : EPOCH 1: training on 99524 raw words (65639 effective words) took 0.2s, 339890 effective words/s\n",
      "2023-12-06 14:14:36,889 : INFO : EPOCH 2: training on 99524 raw words (65425 effective words) took 0.2s, 346471 effective words/s\n",
      "2023-12-06 14:14:37,081 : INFO : EPOCH 3: training on 99524 raw words (65657 effective words) took 0.2s, 348548 effective words/s\n",
      "2023-12-06 14:14:37,274 : INFO : EPOCH 4: training on 99524 raw words (65405 effective words) took 0.2s, 346758 effective words/s\n",
      "2023-12-06 14:14:37,469 : INFO : EPOCH 5: training on 99524 raw words (65598 effective words) took 0.2s, 344083 effective words/s\n",
      "2023-12-06 14:14:37,663 : INFO : EPOCH 6: training on 99524 raw words (65538 effective words) took 0.2s, 344654 effective words/s\n",
      "2023-12-06 14:14:37,858 : INFO : EPOCH 7: training on 99524 raw words (65610 effective words) took 0.2s, 345323 effective words/s\n",
      "2023-12-06 14:14:38,049 : INFO : EPOCH 8: training on 99524 raw words (65484 effective words) took 0.2s, 349197 effective words/s\n",
      "2023-12-06 14:14:38,243 : INFO : EPOCH 9: training on 99524 raw words (65562 effective words) took 0.2s, 346167 effective words/s\n",
      "2023-12-06 14:14:38,437 : INFO : EPOCH 10: training on 99524 raw words (65676 effective words) took 0.2s, 346242 effective words/s\n",
      "2023-12-06 14:14:38,632 : INFO : EPOCH 11: training on 99524 raw words (65649 effective words) took 0.2s, 345949 effective words/s\n",
      "2023-12-06 14:14:38,824 : INFO : EPOCH 12: training on 99524 raw words (65463 effective words) took 0.2s, 346420 effective words/s\n",
      "2023-12-06 14:14:39,018 : INFO : EPOCH 13: training on 99524 raw words (65612 effective words) took 0.2s, 348133 effective words/s\n",
      "2023-12-06 14:14:39,211 : INFO : EPOCH 14: training on 99524 raw words (65434 effective words) took 0.2s, 345649 effective words/s\n",
      "2023-12-06 14:14:39,405 : INFO : EPOCH 15: training on 99524 raw words (65626 effective words) took 0.2s, 347436 effective words/s\n",
      "2023-12-06 14:14:39,596 : INFO : EPOCH 16: training on 99524 raw words (65667 effective words) took 0.2s, 350785 effective words/s\n",
      "2023-12-06 14:14:39,788 : INFO : EPOCH 17: training on 99524 raw words (65600 effective words) took 0.2s, 349073 effective words/s\n",
      "2023-12-06 14:14:39,981 : INFO : EPOCH 18: training on 99524 raw words (65539 effective words) took 0.2s, 348379 effective words/s\n",
      "2023-12-06 14:14:40,171 : INFO : EPOCH 19: training on 99524 raw words (65489 effective words) took 0.2s, 350586 effective words/s\n",
      "2023-12-06 14:14:40,375 : INFO : EPOCH 20: training on 99524 raw words (65584 effective words) took 0.2s, 328895 effective words/s\n",
      "2023-12-06 14:14:40,568 : INFO : EPOCH 21: training on 99524 raw words (65488 effective words) took 0.2s, 347026 effective words/s\n",
      "2023-12-06 14:14:40,762 : INFO : EPOCH 22: training on 99524 raw words (65614 effective words) took 0.2s, 346135 effective words/s\n",
      "2023-12-06 14:14:40,955 : INFO : EPOCH 23: training on 99524 raw words (65659 effective words) took 0.2s, 347206 effective words/s\n",
      "2023-12-06 14:14:41,148 : INFO : EPOCH 24: training on 99524 raw words (65502 effective words) took 0.2s, 346815 effective words/s\n",
      "2023-12-06 14:14:41,340 : INFO : EPOCH 25: training on 99524 raw words (65488 effective words) took 0.2s, 348160 effective words/s\n",
      "2023-12-06 14:14:41,533 : INFO : EPOCH 26: training on 99524 raw words (65568 effective words) took 0.2s, 348641 effective words/s\n",
      "2023-12-06 14:14:41,727 : INFO : EPOCH 27: training on 99524 raw words (65600 effective words) took 0.2s, 345469 effective words/s\n",
      "2023-12-06 14:14:41,919 : INFO : EPOCH 28: training on 99524 raw words (65458 effective words) took 0.2s, 348043 effective words/s\n",
      "2023-12-06 14:14:42,111 : INFO : EPOCH 29: training on 99524 raw words (65557 effective words) took 0.2s, 349355 effective words/s\n",
      "2023-12-06 14:14:42,304 : INFO : EPOCH 30: training on 99524 raw words (65275 effective words) took 0.2s, 347112 effective words/s\n",
      "2023-12-06 14:14:42,495 : INFO : EPOCH 31: training on 99524 raw words (65516 effective words) took 0.2s, 350781 effective words/s\n",
      "2023-12-06 14:14:42,689 : INFO : EPOCH 32: training on 99524 raw words (65388 effective words) took 0.2s, 344518 effective words/s\n",
      "2023-12-06 14:14:42,886 : INFO : EPOCH 33: training on 99524 raw words (65626 effective words) took 0.2s, 341900 effective words/s\n",
      "2023-12-06 14:14:43,079 : INFO : EPOCH 34: training on 99524 raw words (65308 effective words) took 0.2s, 345119 effective words/s\n",
      "2023-12-06 14:14:43,274 : INFO : EPOCH 35: training on 99524 raw words (65427 effective words) took 0.2s, 343230 effective words/s\n",
      "2023-12-06 14:14:43,468 : INFO : EPOCH 36: training on 99524 raw words (65476 effective words) took 0.2s, 343209 effective words/s\n",
      "2023-12-06 14:14:43,663 : INFO : EPOCH 37: training on 99524 raw words (65599 effective words) took 0.2s, 345480 effective words/s\n",
      "2023-12-06 14:14:43,857 : INFO : EPOCH 38: training on 99524 raw words (65300 effective words) took 0.2s, 343820 effective words/s\n",
      "2023-12-06 14:14:44,053 : INFO : EPOCH 39: training on 99524 raw words (65438 effective words) took 0.2s, 342778 effective words/s\n",
      "2023-12-06 14:14:44,246 : INFO : EPOCH 40: training on 99524 raw words (65587 effective words) took 0.2s, 346656 effective words/s\n",
      "2023-12-06 14:14:44,439 : INFO : EPOCH 41: training on 99524 raw words (65462 effective words) took 0.2s, 347250 effective words/s\n",
      "2023-12-06 14:14:44,633 : INFO : EPOCH 42: training on 99524 raw words (65331 effective words) took 0.2s, 344011 effective words/s\n",
      "2023-12-06 14:14:44,825 : INFO : EPOCH 43: training on 99524 raw words (65496 effective words) took 0.2s, 348024 effective words/s\n",
      "2023-12-06 14:14:45,017 : INFO : EPOCH 44: training on 99524 raw words (65630 effective words) took 0.2s, 348943 effective words/s\n",
      "2023-12-06 14:14:45,211 : INFO : EPOCH 45: training on 99524 raw words (65524 effective words) took 0.2s, 346916 effective words/s\n",
      "2023-12-06 14:14:45,404 : INFO : EPOCH 46: training on 99524 raw words (65464 effective words) took 0.2s, 347264 effective words/s\n",
      "2023-12-06 14:14:45,595 : INFO : EPOCH 47: training on 99524 raw words (65441 effective words) took 0.2s, 348683 effective words/s\n",
      "2023-12-06 14:14:45,789 : INFO : EPOCH 48: training on 99524 raw words (65625 effective words) took 0.2s, 347819 effective words/s\n",
      "2023-12-06 14:14:45,992 : INFO : EPOCH 49: training on 99524 raw words (65417 effective words) took 0.2s, 327393 effective words/s\n",
      "2023-12-06 14:14:45,993 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276100 effective words) took 9.7s, 337927 effective words/s', 'datetime': '2023-12-06T14:14:45.993944', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:14:45,994 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:14:45.994945', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  2%|         | 8/486 [01:08<1:27:44, 11.01s/it]2023-12-06 14:14:49,964 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:14:49,964 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:14:49,985 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:14:49,986 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:14:49,991 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:14:49.991027', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:14:49,992 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:14:49.992030', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:14:50,000 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:14:50,001 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:14:50,001 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:14:50.001744', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:14:50,011 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:14:50,012 : INFO : resetting layer weights\n",
      "2023-12-06 14:14:50,015 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:14:50.015008', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:14:50,211 : INFO : EPOCH 0: training on 99524 raw words (65641 effective words) took 0.2s, 341324 effective words/s\n",
      "2023-12-06 14:14:50,409 : INFO : EPOCH 1: training on 99524 raw words (65600 effective words) took 0.2s, 339898 effective words/s\n",
      "2023-12-06 14:14:50,606 : INFO : EPOCH 2: training on 99524 raw words (65558 effective words) took 0.2s, 340792 effective words/s\n",
      "2023-12-06 14:14:50,804 : INFO : EPOCH 3: training on 99524 raw words (65450 effective words) took 0.2s, 336932 effective words/s\n",
      "2023-12-06 14:14:51,002 : INFO : EPOCH 4: training on 99524 raw words (65485 effective words) took 0.2s, 338484 effective words/s\n",
      "2023-12-06 14:14:51,198 : INFO : EPOCH 5: training on 99524 raw words (65570 effective words) took 0.2s, 341792 effective words/s\n",
      "2023-12-06 14:14:51,394 : INFO : EPOCH 6: training on 99524 raw words (65447 effective words) took 0.2s, 342319 effective words/s\n",
      "2023-12-06 14:14:51,591 : INFO : EPOCH 7: training on 99524 raw words (65538 effective words) took 0.2s, 340558 effective words/s\n",
      "2023-12-06 14:14:51,787 : INFO : EPOCH 8: training on 99524 raw words (65530 effective words) took 0.2s, 340251 effective words/s\n",
      "2023-12-06 14:14:51,985 : INFO : EPOCH 9: training on 99524 raw words (65572 effective words) took 0.2s, 339993 effective words/s\n",
      "2023-12-06 14:14:52,181 : INFO : EPOCH 10: training on 99524 raw words (65450 effective words) took 0.2s, 339280 effective words/s\n",
      "2023-12-06 14:14:52,376 : INFO : EPOCH 11: training on 99524 raw words (65548 effective words) took 0.2s, 343470 effective words/s\n",
      "2023-12-06 14:14:52,575 : INFO : EPOCH 12: training on 99524 raw words (65583 effective words) took 0.2s, 337263 effective words/s\n",
      "2023-12-06 14:14:52,771 : INFO : EPOCH 13: training on 99524 raw words (65686 effective words) took 0.2s, 343146 effective words/s\n",
      "2023-12-06 14:14:52,969 : INFO : EPOCH 14: training on 99524 raw words (65483 effective words) took 0.2s, 336651 effective words/s\n",
      "2023-12-06 14:14:53,167 : INFO : EPOCH 15: training on 99524 raw words (65483 effective words) took 0.2s, 339643 effective words/s\n",
      "2023-12-06 14:14:53,365 : INFO : EPOCH 16: training on 99524 raw words (65524 effective words) took 0.2s, 338222 effective words/s\n",
      "2023-12-06 14:14:53,560 : INFO : EPOCH 17: training on 99524 raw words (65353 effective words) took 0.2s, 342723 effective words/s\n",
      "2023-12-06 14:14:53,760 : INFO : EPOCH 18: training on 99524 raw words (65574 effective words) took 0.2s, 335450 effective words/s\n",
      "2023-12-06 14:14:53,957 : INFO : EPOCH 19: training on 99524 raw words (65487 effective words) took 0.2s, 339884 effective words/s\n",
      "2023-12-06 14:14:54,154 : INFO : EPOCH 20: training on 99524 raw words (65614 effective words) took 0.2s, 340383 effective words/s\n",
      "2023-12-06 14:14:54,362 : INFO : EPOCH 21: training on 99524 raw words (65591 effective words) took 0.2s, 322958 effective words/s\n",
      "2023-12-06 14:14:54,560 : INFO : EPOCH 22: training on 99524 raw words (65488 effective words) took 0.2s, 336814 effective words/s\n",
      "2023-12-06 14:14:54,757 : INFO : EPOCH 23: training on 99524 raw words (65427 effective words) took 0.2s, 340846 effective words/s\n",
      "2023-12-06 14:14:54,953 : INFO : EPOCH 24: training on 99524 raw words (65362 effective words) took 0.2s, 341095 effective words/s\n",
      "2023-12-06 14:14:55,151 : INFO : EPOCH 25: training on 99524 raw words (65529 effective words) took 0.2s, 338230 effective words/s\n",
      "2023-12-06 14:14:55,348 : INFO : EPOCH 26: training on 99524 raw words (65575 effective words) took 0.2s, 339927 effective words/s\n",
      "2023-12-06 14:14:55,545 : INFO : EPOCH 27: training on 99524 raw words (65432 effective words) took 0.2s, 339831 effective words/s\n",
      "2023-12-06 14:14:55,742 : INFO : EPOCH 28: training on 99524 raw words (65571 effective words) took 0.2s, 341146 effective words/s\n",
      "2023-12-06 14:14:55,937 : INFO : EPOCH 29: training on 99524 raw words (65461 effective words) took 0.2s, 342050 effective words/s\n",
      "2023-12-06 14:14:56,133 : INFO : EPOCH 30: training on 99524 raw words (65584 effective words) took 0.2s, 342465 effective words/s\n",
      "2023-12-06 14:14:56,332 : INFO : EPOCH 31: training on 99524 raw words (65542 effective words) took 0.2s, 337813 effective words/s\n",
      "2023-12-06 14:14:56,528 : INFO : EPOCH 32: training on 99524 raw words (65570 effective words) took 0.2s, 341755 effective words/s\n",
      "2023-12-06 14:14:56,725 : INFO : EPOCH 33: training on 99524 raw words (65366 effective words) took 0.2s, 339400 effective words/s\n",
      "2023-12-06 14:14:56,923 : INFO : EPOCH 34: training on 99524 raw words (65427 effective words) took 0.2s, 338187 effective words/s\n",
      "2023-12-06 14:14:57,122 : INFO : EPOCH 35: training on 99524 raw words (65454 effective words) took 0.2s, 336152 effective words/s\n",
      "2023-12-06 14:14:57,320 : INFO : EPOCH 36: training on 99524 raw words (65499 effective words) took 0.2s, 337552 effective words/s\n",
      "2023-12-06 14:14:57,518 : INFO : EPOCH 37: training on 99524 raw words (65396 effective words) took 0.2s, 337241 effective words/s\n",
      "2023-12-06 14:14:57,716 : INFO : EPOCH 38: training on 99524 raw words (65549 effective words) took 0.2s, 338194 effective words/s\n",
      "2023-12-06 14:14:57,914 : INFO : EPOCH 39: training on 99524 raw words (65494 effective words) took 0.2s, 338496 effective words/s\n",
      "2023-12-06 14:14:58,112 : INFO : EPOCH 40: training on 99524 raw words (65592 effective words) took 0.2s, 338276 effective words/s\n",
      "2023-12-06 14:14:58,309 : INFO : EPOCH 41: training on 99524 raw words (65425 effective words) took 0.2s, 339300 effective words/s\n",
      "2023-12-06 14:14:58,508 : INFO : EPOCH 42: training on 99524 raw words (65648 effective words) took 0.2s, 337584 effective words/s\n",
      "2023-12-06 14:14:58,710 : INFO : EPOCH 43: training on 99524 raw words (65406 effective words) took 0.2s, 332917 effective words/s\n",
      "2023-12-06 14:14:58,909 : INFO : EPOCH 44: training on 99524 raw words (65419 effective words) took 0.2s, 336420 effective words/s\n",
      "2023-12-06 14:14:59,116 : INFO : EPOCH 45: training on 99524 raw words (65370 effective words) took 0.2s, 322451 effective words/s\n",
      "2023-12-06 14:14:59,315 : INFO : EPOCH 46: training on 99524 raw words (65512 effective words) took 0.2s, 336079 effective words/s\n",
      "2023-12-06 14:14:59,510 : INFO : EPOCH 47: training on 99524 raw words (65618 effective words) took 0.2s, 343642 effective words/s\n",
      "2023-12-06 14:14:59,705 : INFO : EPOCH 48: training on 99524 raw words (65679 effective words) took 0.2s, 344626 effective words/s\n",
      "2023-12-06 14:14:59,905 : INFO : EPOCH 49: training on 99524 raw words (65488 effective words) took 0.2s, 337176 effective words/s\n",
      "2023-12-06 14:14:59,906 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3275650 effective words) took 9.9s, 331220 effective words/s', 'datetime': '2023-12-06T14:14:59.905082', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:14:59,906 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:14:59.906083', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  2%|         | 9/486 [01:22<1:35:32, 12.02s/it]2023-12-06 14:15:04,192 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:15:04,193 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:15:04,216 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:15:04,217 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:15:04,221 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:15:04.221050', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:15:04,222 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:15:04.222052', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:15:04,226 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:15:04,228 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:15:04,228 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:15:04.228790', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:15:04,236 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:15:04,237 : INFO : resetting layer weights\n",
      "2023-12-06 14:15:04,238 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:15:04.238938', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:15:04,430 : INFO : EPOCH 0: training on 99524 raw words (62703 effective words) took 0.2s, 336590 effective words/s\n",
      "2023-12-06 14:15:04,618 : INFO : EPOCH 1: training on 99524 raw words (62769 effective words) took 0.2s, 339549 effective words/s\n",
      "2023-12-06 14:15:04,810 : INFO : EPOCH 2: training on 99524 raw words (62583 effective words) took 0.2s, 335635 effective words/s\n",
      "2023-12-06 14:15:04,999 : INFO : EPOCH 3: training on 99524 raw words (62723 effective words) took 0.2s, 339352 effective words/s\n",
      "2023-12-06 14:15:05,188 : INFO : EPOCH 4: training on 99524 raw words (62623 effective words) took 0.2s, 338792 effective words/s\n",
      "2023-12-06 14:15:05,377 : INFO : EPOCH 5: training on 99524 raw words (62708 effective words) took 0.2s, 338068 effective words/s\n",
      "2023-12-06 14:15:05,567 : INFO : EPOCH 6: training on 99524 raw words (62785 effective words) took 0.2s, 338874 effective words/s\n",
      "2023-12-06 14:15:05,756 : INFO : EPOCH 7: training on 99524 raw words (62716 effective words) took 0.2s, 337636 effective words/s\n",
      "2023-12-06 14:15:05,946 : INFO : EPOCH 8: training on 99524 raw words (62671 effective words) took 0.2s, 338061 effective words/s\n",
      "2023-12-06 14:15:06,136 : INFO : EPOCH 9: training on 99524 raw words (62776 effective words) took 0.2s, 338596 effective words/s\n",
      "2023-12-06 14:15:06,137 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627057 effective words) took 1.9s, 330478 effective words/s', 'datetime': '2023-12-06T14:15:06.137669', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:15:06,137 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:15:06.137669', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  2%|         | 10/486 [01:27<1:17:09,  9.73s/it]2023-12-06 14:15:08,782 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:15:08,783 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:15:08,804 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:15:08,806 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:15:08,810 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:15:08.810769', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:15:08,810 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:15:08.810769', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:15:08,817 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:15:08,817 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:15:08,818 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:15:08.818629', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:15:08,826 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:15:08,827 : INFO : resetting layer weights\n",
      "2023-12-06 14:15:08,829 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:15:08.829289', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:15:09,033 : INFO : EPOCH 0: training on 99524 raw words (62901 effective words) took 0.2s, 314267 effective words/s\n",
      "2023-12-06 14:15:09,225 : INFO : EPOCH 1: training on 99524 raw words (62608 effective words) took 0.2s, 334624 effective words/s\n",
      "2023-12-06 14:15:09,415 : INFO : EPOCH 2: training on 99524 raw words (62752 effective words) took 0.2s, 336725 effective words/s\n",
      "2023-12-06 14:15:09,608 : INFO : EPOCH 3: training on 99524 raw words (62745 effective words) took 0.2s, 332234 effective words/s\n",
      "2023-12-06 14:15:09,799 : INFO : EPOCH 4: training on 99524 raw words (62650 effective words) took 0.2s, 335361 effective words/s\n",
      "2023-12-06 14:15:09,990 : INFO : EPOCH 5: training on 99524 raw words (62800 effective words) took 0.2s, 335914 effective words/s\n",
      "2023-12-06 14:15:10,184 : INFO : EPOCH 6: training on 99524 raw words (62882 effective words) took 0.2s, 332701 effective words/s\n",
      "2023-12-06 14:15:10,376 : INFO : EPOCH 7: training on 99524 raw words (62744 effective words) took 0.2s, 333776 effective words/s\n",
      "2023-12-06 14:15:10,566 : INFO : EPOCH 8: training on 99524 raw words (62593 effective words) took 0.2s, 336664 effective words/s\n",
      "2023-12-06 14:15:10,757 : INFO : EPOCH 9: training on 99524 raw words (62881 effective words) took 0.2s, 334938 effective words/s\n",
      "2023-12-06 14:15:10,758 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627556 effective words) took 1.9s, 325354 effective words/s', 'datetime': '2023-12-06T14:15:10.758937', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:15:10,758 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:15:10.758937', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  2%|         | 11/486 [01:32<1:04:53,  8.20s/it]2023-12-06 14:15:13,517 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:15:13,517 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:15:13,537 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:15:13,538 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:15:13,543 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:15:13.543236', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:15:13,543 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:15:13.543236', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:15:13,548 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:15:13,549 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:15:13,549 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:15:13.549752', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:15:13,558 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:15:13,558 : INFO : resetting layer weights\n",
      "2023-12-06 14:15:13,560 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:15:13.560984', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:15:13,758 : INFO : EPOCH 0: training on 99524 raw words (62741 effective words) took 0.2s, 324897 effective words/s\n",
      "2023-12-06 14:15:13,954 : INFO : EPOCH 1: training on 99524 raw words (62698 effective words) took 0.2s, 326497 effective words/s\n",
      "2023-12-06 14:15:14,151 : INFO : EPOCH 2: training on 99524 raw words (62781 effective words) took 0.2s, 327798 effective words/s\n",
      "2023-12-06 14:15:14,347 : INFO : EPOCH 3: training on 99524 raw words (62621 effective words) took 0.2s, 325927 effective words/s\n",
      "2023-12-06 14:15:14,544 : INFO : EPOCH 4: training on 99524 raw words (62744 effective words) took 0.2s, 325659 effective words/s\n",
      "2023-12-06 14:15:14,752 : INFO : EPOCH 5: training on 99524 raw words (62802 effective words) took 0.2s, 307728 effective words/s\n",
      "2023-12-06 14:15:14,947 : INFO : EPOCH 6: training on 99524 raw words (62684 effective words) took 0.2s, 328921 effective words/s\n",
      "2023-12-06 14:15:15,143 : INFO : EPOCH 7: training on 99524 raw words (62714 effective words) took 0.2s, 326795 effective words/s\n",
      "2023-12-06 14:15:15,339 : INFO : EPOCH 8: training on 99524 raw words (62653 effective words) took 0.2s, 326561 effective words/s\n",
      "2023-12-06 14:15:15,535 : INFO : EPOCH 9: training on 99524 raw words (62685 effective words) took 0.2s, 327027 effective words/s\n",
      "2023-12-06 14:15:15,537 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627123 effective words) took 2.0s, 317578 effective words/s', 'datetime': '2023-12-06T14:15:15.537002', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:15:15,537 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:15:15.537708', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  2%|         | 12/486 [01:36<56:34,  7.16s/it]  2023-12-06 14:15:18,307 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:15:18,308 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:15:18,330 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:15:18,331 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:15:18,336 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:15:18.336117', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:15:18,337 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:15:18.337116', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:15:18,342 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:15:18,343 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:15:18,343 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:15:18.343282', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:15:18,351 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:15:18,352 : INFO : resetting layer weights\n",
      "2023-12-06 14:15:18,355 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:15:18.355645', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:15:18,544 : INFO : EPOCH 0: training on 99524 raw words (62676 effective words) took 0.2s, 338264 effective words/s\n",
      "2023-12-06 14:15:18,734 : INFO : EPOCH 1: training on 99524 raw words (62745 effective words) took 0.2s, 337431 effective words/s\n",
      "2023-12-06 14:15:18,923 : INFO : EPOCH 2: training on 99524 raw words (62856 effective words) took 0.2s, 339789 effective words/s\n",
      "2023-12-06 14:15:19,113 : INFO : EPOCH 3: training on 99524 raw words (62835 effective words) took 0.2s, 339900 effective words/s\n",
      "2023-12-06 14:15:19,302 : INFO : EPOCH 4: training on 99524 raw words (62661 effective words) took 0.2s, 338718 effective words/s\n",
      "2023-12-06 14:15:19,491 : INFO : EPOCH 5: training on 99524 raw words (62779 effective words) took 0.2s, 340258 effective words/s\n",
      "2023-12-06 14:15:19,680 : INFO : EPOCH 6: training on 99524 raw words (62740 effective words) took 0.2s, 337485 effective words/s\n",
      "2023-12-06 14:15:19,869 : INFO : EPOCH 7: training on 99524 raw words (62745 effective words) took 0.2s, 338508 effective words/s\n",
      "2023-12-06 14:15:20,060 : INFO : EPOCH 8: training on 99524 raw words (62657 effective words) took 0.2s, 336985 effective words/s\n",
      "2023-12-06 14:15:20,258 : INFO : EPOCH 9: training on 99524 raw words (62770 effective words) took 0.2s, 323521 effective words/s\n",
      "2023-12-06 14:15:20,447 : INFO : EPOCH 10: training on 99524 raw words (62658 effective words) took 0.2s, 339916 effective words/s\n",
      "2023-12-06 14:15:20,637 : INFO : EPOCH 11: training on 99524 raw words (62860 effective words) took 0.2s, 337455 effective words/s\n",
      "2023-12-06 14:15:20,827 : INFO : EPOCH 12: training on 99524 raw words (62760 effective words) took 0.2s, 338286 effective words/s\n",
      "2023-12-06 14:15:21,017 : INFO : EPOCH 13: training on 99524 raw words (62795 effective words) took 0.2s, 339108 effective words/s\n",
      "2023-12-06 14:15:21,208 : INFO : EPOCH 14: training on 99524 raw words (62629 effective words) took 0.2s, 336014 effective words/s\n",
      "2023-12-06 14:15:21,395 : INFO : EPOCH 15: training on 99524 raw words (62610 effective words) took 0.2s, 341537 effective words/s\n",
      "2023-12-06 14:15:21,584 : INFO : EPOCH 16: training on 99524 raw words (62777 effective words) took 0.2s, 341788 effective words/s\n",
      "2023-12-06 14:15:21,774 : INFO : EPOCH 17: training on 99524 raw words (62619 effective words) took 0.2s, 336798 effective words/s\n",
      "2023-12-06 14:15:21,962 : INFO : EPOCH 18: training on 99524 raw words (62747 effective words) took 0.2s, 338773 effective words/s\n",
      "2023-12-06 14:15:22,151 : INFO : EPOCH 19: training on 99524 raw words (62772 effective words) took 0.2s, 341319 effective words/s\n",
      "2023-12-06 14:15:22,341 : INFO : EPOCH 20: training on 99524 raw words (62745 effective words) took 0.2s, 337154 effective words/s\n",
      "2023-12-06 14:15:22,532 : INFO : EPOCH 21: training on 99524 raw words (62779 effective words) took 0.2s, 335921 effective words/s\n",
      "2023-12-06 14:15:22,723 : INFO : EPOCH 22: training on 99524 raw words (62851 effective words) took 0.2s, 338707 effective words/s\n",
      "2023-12-06 14:15:22,912 : INFO : EPOCH 23: training on 99524 raw words (62679 effective words) took 0.2s, 337589 effective words/s\n",
      "2023-12-06 14:15:23,102 : INFO : EPOCH 24: training on 99524 raw words (62856 effective words) took 0.2s, 340246 effective words/s\n",
      "2023-12-06 14:15:23,290 : INFO : EPOCH 25: training on 99524 raw words (62751 effective words) took 0.2s, 339617 effective words/s\n",
      "2023-12-06 14:15:23,482 : INFO : EPOCH 26: training on 99524 raw words (62662 effective words) took 0.2s, 334519 effective words/s\n",
      "2023-12-06 14:15:23,680 : INFO : EPOCH 27: training on 99524 raw words (62719 effective words) took 0.2s, 323963 effective words/s\n",
      "2023-12-06 14:15:23,870 : INFO : EPOCH 28: training on 99524 raw words (62838 effective words) took 0.2s, 337266 effective words/s\n",
      "2023-12-06 14:15:24,061 : INFO : EPOCH 29: training on 99524 raw words (62661 effective words) took 0.2s, 336109 effective words/s\n",
      "2023-12-06 14:15:24,062 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1882232 effective words) took 5.7s, 329846 effective words/s', 'datetime': '2023-12-06T14:15:24.062351', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:15:24,063 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:15:24.063353', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  3%|         | 13/486 [01:45<1:00:46,  7.71s/it]2023-12-06 14:15:27,275 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:15:27,275 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:15:27,297 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:15:27,298 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:15:27,303 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:15:27.303047', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:15:27,304 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:15:27.304381', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:15:27,309 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:15:27,310 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:15:27,310 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:15:27.310604', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:15:27,319 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:15:27,321 : INFO : resetting layer weights\n",
      "2023-12-06 14:15:27,322 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:15:27.322503', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:15:27,513 : INFO : EPOCH 0: training on 99524 raw words (62872 effective words) took 0.2s, 335831 effective words/s\n",
      "2023-12-06 14:15:27,703 : INFO : EPOCH 1: training on 99524 raw words (62780 effective words) took 0.2s, 337096 effective words/s\n",
      "2023-12-06 14:15:27,896 : INFO : EPOCH 2: training on 99524 raw words (62606 effective words) took 0.2s, 333237 effective words/s\n",
      "2023-12-06 14:15:28,086 : INFO : EPOCH 3: training on 99524 raw words (62749 effective words) took 0.2s, 336934 effective words/s\n",
      "2023-12-06 14:15:28,278 : INFO : EPOCH 4: training on 99524 raw words (62681 effective words) took 0.2s, 334965 effective words/s\n",
      "2023-12-06 14:15:28,470 : INFO : EPOCH 5: training on 99524 raw words (62745 effective words) took 0.2s, 334292 effective words/s\n",
      "2023-12-06 14:15:28,661 : INFO : EPOCH 6: training on 99524 raw words (62634 effective words) took 0.2s, 334743 effective words/s\n",
      "2023-12-06 14:15:28,852 : INFO : EPOCH 7: training on 99524 raw words (62613 effective words) took 0.2s, 335450 effective words/s\n",
      "2023-12-06 14:15:29,044 : INFO : EPOCH 8: training on 99524 raw words (62755 effective words) took 0.2s, 333390 effective words/s\n",
      "2023-12-06 14:15:29,236 : INFO : EPOCH 9: training on 99524 raw words (62809 effective words) took 0.2s, 335642 effective words/s\n",
      "2023-12-06 14:15:29,428 : INFO : EPOCH 10: training on 99524 raw words (62672 effective words) took 0.2s, 332628 effective words/s\n",
      "2023-12-06 14:15:29,631 : INFO : EPOCH 11: training on 99524 raw words (62639 effective words) took 0.2s, 316805 effective words/s\n",
      "2023-12-06 14:15:29,821 : INFO : EPOCH 12: training on 99524 raw words (62754 effective words) took 0.2s, 336148 effective words/s\n",
      "2023-12-06 14:15:30,013 : INFO : EPOCH 13: training on 99524 raw words (62672 effective words) took 0.2s, 333743 effective words/s\n",
      "2023-12-06 14:15:30,205 : INFO : EPOCH 14: training on 99524 raw words (62565 effective words) took 0.2s, 332071 effective words/s\n",
      "2023-12-06 14:15:30,398 : INFO : EPOCH 15: training on 99524 raw words (62777 effective words) took 0.2s, 334699 effective words/s\n",
      "2023-12-06 14:15:30,590 : INFO : EPOCH 16: training on 99524 raw words (62749 effective words) took 0.2s, 335419 effective words/s\n",
      "2023-12-06 14:15:30,781 : INFO : EPOCH 17: training on 99524 raw words (62718 effective words) took 0.2s, 335102 effective words/s\n",
      "2023-12-06 14:15:30,975 : INFO : EPOCH 18: training on 99524 raw words (62848 effective words) took 0.2s, 332366 effective words/s\n",
      "2023-12-06 14:15:31,167 : INFO : EPOCH 19: training on 99524 raw words (62719 effective words) took 0.2s, 333215 effective words/s\n",
      "2023-12-06 14:15:31,360 : INFO : EPOCH 20: training on 99524 raw words (62730 effective words) took 0.2s, 333133 effective words/s\n",
      "2023-12-06 14:15:31,551 : INFO : EPOCH 21: training on 99524 raw words (62710 effective words) took 0.2s, 335767 effective words/s\n",
      "2023-12-06 14:15:31,743 : INFO : EPOCH 22: training on 99524 raw words (62754 effective words) took 0.2s, 333635 effective words/s\n",
      "2023-12-06 14:15:31,934 : INFO : EPOCH 23: training on 99524 raw words (62629 effective words) took 0.2s, 334062 effective words/s\n",
      "2023-12-06 14:15:32,125 : INFO : EPOCH 24: training on 99524 raw words (62771 effective words) took 0.2s, 336349 effective words/s\n",
      "2023-12-06 14:15:32,317 : INFO : EPOCH 25: training on 99524 raw words (62556 effective words) took 0.2s, 333790 effective words/s\n",
      "2023-12-06 14:15:32,511 : INFO : EPOCH 26: training on 99524 raw words (62725 effective words) took 0.2s, 331364 effective words/s\n",
      "2023-12-06 14:15:32,701 : INFO : EPOCH 27: training on 99524 raw words (62749 effective words) took 0.2s, 337511 effective words/s\n",
      "2023-12-06 14:15:32,892 : INFO : EPOCH 28: training on 99524 raw words (62679 effective words) took 0.2s, 336565 effective words/s\n",
      "2023-12-06 14:15:33,094 : INFO : EPOCH 29: training on 99524 raw words (62779 effective words) took 0.2s, 316326 effective words/s\n",
      "2023-12-06 14:15:33,095 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881439 effective words) took 5.8s, 325954 effective words/s', 'datetime': '2023-12-06T14:15:33.095455', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:15:33,095 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:15:33.095455', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  3%|         | 14/486 [01:55<1:04:15,  8.17s/it]2023-12-06 14:15:36,505 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:15:36,506 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:15:36,527 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:15:36,528 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:15:36,532 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:15:36.532065', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:15:36,533 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:15:36.533064', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:15:36,539 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:15:36,540 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:15:36,540 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:15:36.540088', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:15:36,549 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:15:36,550 : INFO : resetting layer weights\n",
      "2023-12-06 14:15:36,552 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:15:36.552598', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:15:36,770 : INFO : EPOCH 0: training on 99524 raw words (62861 effective words) took 0.2s, 297515 effective words/s\n",
      "2023-12-06 14:15:36,968 : INFO : EPOCH 1: training on 99524 raw words (62624 effective words) took 0.2s, 323158 effective words/s\n",
      "2023-12-06 14:15:37,164 : INFO : EPOCH 2: training on 99524 raw words (62821 effective words) took 0.2s, 329012 effective words/s\n",
      "2023-12-06 14:15:37,358 : INFO : EPOCH 3: training on 99524 raw words (62637 effective words) took 0.2s, 328866 effective words/s\n",
      "2023-12-06 14:15:37,555 : INFO : EPOCH 4: training on 99524 raw words (62723 effective words) took 0.2s, 326796 effective words/s\n",
      "2023-12-06 14:15:37,751 : INFO : EPOCH 5: training on 99524 raw words (62870 effective words) took 0.2s, 326339 effective words/s\n",
      "2023-12-06 14:15:37,944 : INFO : EPOCH 6: training on 99524 raw words (62620 effective words) took 0.2s, 331786 effective words/s\n",
      "2023-12-06 14:15:38,139 : INFO : EPOCH 7: training on 99524 raw words (62745 effective words) took 0.2s, 328394 effective words/s\n",
      "2023-12-06 14:15:38,334 : INFO : EPOCH 8: training on 99524 raw words (62794 effective words) took 0.2s, 329613 effective words/s\n",
      "2023-12-06 14:15:38,527 : INFO : EPOCH 9: training on 99524 raw words (62581 effective words) took 0.2s, 330675 effective words/s\n",
      "2023-12-06 14:15:38,721 : INFO : EPOCH 10: training on 99524 raw words (62729 effective words) took 0.2s, 330101 effective words/s\n",
      "2023-12-06 14:15:38,928 : INFO : EPOCH 11: training on 99524 raw words (62677 effective words) took 0.2s, 309092 effective words/s\n",
      "2023-12-06 14:15:39,126 : INFO : EPOCH 12: training on 99524 raw words (62730 effective words) took 0.2s, 324885 effective words/s\n",
      "2023-12-06 14:15:39,328 : INFO : EPOCH 13: training on 99524 raw words (62597 effective words) took 0.2s, 315479 effective words/s\n",
      "2023-12-06 14:15:39,525 : INFO : EPOCH 14: training on 99524 raw words (62593 effective words) took 0.2s, 324266 effective words/s\n",
      "2023-12-06 14:15:39,719 : INFO : EPOCH 15: training on 99524 raw words (62733 effective words) took 0.2s, 330661 effective words/s\n",
      "2023-12-06 14:15:39,914 : INFO : EPOCH 16: training on 99524 raw words (62812 effective words) took 0.2s, 330015 effective words/s\n",
      "2023-12-06 14:15:40,110 : INFO : EPOCH 17: training on 99524 raw words (62664 effective words) took 0.2s, 326495 effective words/s\n",
      "2023-12-06 14:15:40,304 : INFO : EPOCH 18: training on 99524 raw words (62735 effective words) took 0.2s, 330135 effective words/s\n",
      "2023-12-06 14:15:40,498 : INFO : EPOCH 19: training on 99524 raw words (62840 effective words) took 0.2s, 327727 effective words/s\n",
      "2023-12-06 14:15:40,694 : INFO : EPOCH 20: training on 99524 raw words (62831 effective words) took 0.2s, 328393 effective words/s\n",
      "2023-12-06 14:15:40,890 : INFO : EPOCH 21: training on 99524 raw words (62685 effective words) took 0.2s, 327610 effective words/s\n",
      "2023-12-06 14:15:41,087 : INFO : EPOCH 22: training on 99524 raw words (62650 effective words) took 0.2s, 324111 effective words/s\n",
      "2023-12-06 14:15:41,282 : INFO : EPOCH 23: training on 99524 raw words (62752 effective words) took 0.2s, 329819 effective words/s\n",
      "2023-12-06 14:15:41,477 : INFO : EPOCH 24: training on 99524 raw words (62910 effective words) took 0.2s, 328960 effective words/s\n",
      "2023-12-06 14:15:41,673 : INFO : EPOCH 25: training on 99524 raw words (62684 effective words) took 0.2s, 327272 effective words/s\n",
      "2023-12-06 14:15:41,868 : INFO : EPOCH 26: training on 99524 raw words (62758 effective words) took 0.2s, 328070 effective words/s\n",
      "2023-12-06 14:15:42,076 : INFO : EPOCH 27: training on 99524 raw words (62685 effective words) took 0.2s, 307795 effective words/s\n",
      "2023-12-06 14:15:42,273 : INFO : EPOCH 28: training on 99524 raw words (62783 effective words) took 0.2s, 325811 effective words/s\n",
      "2023-12-06 14:15:42,471 : INFO : EPOCH 29: training on 99524 raw words (62841 effective words) took 0.2s, 323616 effective words/s\n",
      "2023-12-06 14:15:42,472 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881965 effective words) took 5.9s, 317911 effective words/s', 'datetime': '2023-12-06T14:15:42.472614', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:15:42,473 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:15:42.473616', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  3%|         | 15/486 [02:04<1:07:08,  8.55s/it]2023-12-06 14:15:45,950 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:15:45,950 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:15:45,973 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:15:45,974 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:15:45,978 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:15:45.978896', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:15:45,979 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:15:45.979908', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:15:45,986 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:15:45,986 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:15:45,987 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:15:45.987587', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:15:45,996 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:15:45,996 : INFO : resetting layer weights\n",
      "2023-12-06 14:15:45,998 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:15:45.998421', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:15:46,200 : INFO : EPOCH 0: training on 99524 raw words (62647 effective words) took 0.2s, 316500 effective words/s\n",
      "2023-12-06 14:15:46,398 : INFO : EPOCH 1: training on 99524 raw words (62751 effective words) took 0.2s, 325796 effective words/s\n",
      "2023-12-06 14:15:46,597 : INFO : EPOCH 2: training on 99524 raw words (62827 effective words) took 0.2s, 323167 effective words/s\n",
      "2023-12-06 14:15:46,791 : INFO : EPOCH 3: training on 99524 raw words (62768 effective words) took 0.2s, 331313 effective words/s\n",
      "2023-12-06 14:15:46,983 : INFO : EPOCH 4: training on 99524 raw words (62740 effective words) took 0.2s, 333029 effective words/s\n",
      "2023-12-06 14:15:47,174 : INFO : EPOCH 5: training on 99524 raw words (62753 effective words) took 0.2s, 338840 effective words/s\n",
      "2023-12-06 14:15:47,365 : INFO : EPOCH 6: training on 99524 raw words (62825 effective words) took 0.2s, 334937 effective words/s\n",
      "2023-12-06 14:15:47,556 : INFO : EPOCH 7: training on 99524 raw words (62756 effective words) took 0.2s, 334642 effective words/s\n",
      "2023-12-06 14:15:47,767 : INFO : EPOCH 8: training on 99524 raw words (62678 effective words) took 0.2s, 303647 effective words/s\n",
      "2023-12-06 14:15:47,979 : INFO : EPOCH 9: training on 99524 raw words (62744 effective words) took 0.2s, 301434 effective words/s\n",
      "2023-12-06 14:15:48,297 : INFO : EPOCH 10: training on 99524 raw words (62844 effective words) took 0.3s, 200892 effective words/s\n",
      "2023-12-06 14:15:48,519 : INFO : EPOCH 11: training on 99524 raw words (62582 effective words) took 0.2s, 290100 effective words/s\n",
      "2023-12-06 14:15:48,724 : INFO : EPOCH 12: training on 99524 raw words (62715 effective words) took 0.2s, 311772 effective words/s\n",
      "2023-12-06 14:15:48,919 : INFO : EPOCH 13: training on 99524 raw words (62832 effective words) took 0.2s, 329736 effective words/s\n",
      "2023-12-06 14:15:49,122 : INFO : EPOCH 14: training on 99524 raw words (62678 effective words) took 0.2s, 316543 effective words/s\n",
      "2023-12-06 14:15:49,314 : INFO : EPOCH 15: training on 99524 raw words (62889 effective words) took 0.2s, 334888 effective words/s\n",
      "2023-12-06 14:15:49,502 : INFO : EPOCH 16: training on 99524 raw words (62726 effective words) took 0.2s, 340682 effective words/s\n",
      "2023-12-06 14:15:49,692 : INFO : EPOCH 17: training on 99524 raw words (62732 effective words) took 0.2s, 337661 effective words/s\n",
      "2023-12-06 14:15:49,881 : INFO : EPOCH 18: training on 99524 raw words (62785 effective words) took 0.2s, 340021 effective words/s\n",
      "2023-12-06 14:15:50,073 : INFO : EPOCH 19: training on 99524 raw words (62777 effective words) took 0.2s, 335769 effective words/s\n",
      "2023-12-06 14:15:50,262 : INFO : EPOCH 20: training on 99524 raw words (62699 effective words) took 0.2s, 339789 effective words/s\n",
      "2023-12-06 14:15:50,449 : INFO : EPOCH 21: training on 99524 raw words (62759 effective words) took 0.2s, 341418 effective words/s\n",
      "2023-12-06 14:15:50,686 : INFO : EPOCH 22: training on 99524 raw words (62627 effective words) took 0.2s, 269623 effective words/s\n",
      "2023-12-06 14:15:50,884 : INFO : EPOCH 23: training on 99524 raw words (62703 effective words) took 0.2s, 324028 effective words/s\n",
      "2023-12-06 14:15:51,084 : INFO : EPOCH 24: training on 99524 raw words (62717 effective words) took 0.2s, 319821 effective words/s\n",
      "2023-12-06 14:15:51,273 : INFO : EPOCH 25: training on 99524 raw words (62856 effective words) took 0.2s, 341622 effective words/s\n",
      "2023-12-06 14:15:51,463 : INFO : EPOCH 26: training on 99524 raw words (62618 effective words) took 0.2s, 336581 effective words/s\n",
      "2023-12-06 14:15:51,654 : INFO : EPOCH 27: training on 99524 raw words (62707 effective words) took 0.2s, 334374 effective words/s\n",
      "2023-12-06 14:15:51,853 : INFO : EPOCH 28: training on 99524 raw words (62699 effective words) took 0.2s, 321325 effective words/s\n",
      "2023-12-06 14:15:52,049 : INFO : EPOCH 29: training on 99524 raw words (62630 effective words) took 0.2s, 327731 effective words/s\n",
      "2023-12-06 14:15:52,238 : INFO : EPOCH 30: training on 99524 raw words (62738 effective words) took 0.2s, 339384 effective words/s\n",
      "2023-12-06 14:15:52,428 : INFO : EPOCH 31: training on 99524 raw words (62803 effective words) took 0.2s, 338061 effective words/s\n",
      "2023-12-06 14:15:52,632 : INFO : EPOCH 32: training on 99524 raw words (62704 effective words) took 0.2s, 317449 effective words/s\n",
      "2023-12-06 14:15:52,860 : INFO : EPOCH 33: training on 99524 raw words (62726 effective words) took 0.2s, 280715 effective words/s\n",
      "2023-12-06 14:15:53,094 : INFO : EPOCH 34: training on 99524 raw words (62780 effective words) took 0.2s, 274696 effective words/s\n",
      "2023-12-06 14:15:53,324 : INFO : EPOCH 35: training on 99524 raw words (62663 effective words) took 0.2s, 279119 effective words/s\n",
      "2023-12-06 14:15:53,562 : INFO : EPOCH 36: training on 99524 raw words (62764 effective words) took 0.2s, 268746 effective words/s\n",
      "2023-12-06 14:15:53,795 : INFO : EPOCH 37: training on 99524 raw words (62675 effective words) took 0.2s, 274065 effective words/s\n",
      "2023-12-06 14:15:54,029 : INFO : EPOCH 38: training on 99524 raw words (63030 effective words) took 0.2s, 274274 effective words/s\n",
      "2023-12-06 14:15:54,259 : INFO : EPOCH 39: training on 99524 raw words (62795 effective words) took 0.2s, 278385 effective words/s\n",
      "2023-12-06 14:15:54,489 : INFO : EPOCH 40: training on 99524 raw words (62851 effective words) took 0.2s, 280040 effective words/s\n",
      "2023-12-06 14:15:54,721 : INFO : EPOCH 41: training on 99524 raw words (62765 effective words) took 0.2s, 275152 effective words/s\n",
      "2023-12-06 14:15:54,954 : INFO : EPOCH 42: training on 99524 raw words (62773 effective words) took 0.2s, 275112 effective words/s\n",
      "2023-12-06 14:15:55,188 : INFO : EPOCH 43: training on 99524 raw words (62764 effective words) took 0.2s, 272920 effective words/s\n",
      "2023-12-06 14:15:55,421 : INFO : EPOCH 44: training on 99524 raw words (62816 effective words) took 0.2s, 276066 effective words/s\n",
      "2023-12-06 14:15:55,651 : INFO : EPOCH 45: training on 99524 raw words (62786 effective words) took 0.2s, 277391 effective words/s\n",
      "2023-12-06 14:15:55,882 : INFO : EPOCH 46: training on 99524 raw words (62788 effective words) took 0.2s, 277955 effective words/s\n",
      "2023-12-06 14:15:56,113 : INFO : EPOCH 47: training on 99524 raw words (62779 effective words) took 0.2s, 275777 effective words/s\n",
      "2023-12-06 14:15:56,351 : INFO : EPOCH 48: training on 99524 raw words (62500 effective words) took 0.2s, 268036 effective words/s\n",
      "2023-12-06 14:15:56,591 : INFO : EPOCH 49: training on 99524 raw words (62810 effective words) took 0.2s, 266826 effective words/s\n",
      "2023-12-06 14:15:56,592 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3137374 effective words) took 10.6s, 296167 effective words/s', 'datetime': '2023-12-06T14:15:56.592146', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:15:56,593 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:15:56.593621', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  3%|         | 16/486 [02:19<1:21:25, 10.39s/it]2023-12-06 14:16:00,621 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:16:00,621 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:16:00,647 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:16:00,648 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:16:00,652 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:16:00.652961', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:16:00,653 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:16:00.653961', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:16:00,662 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:16:00,663 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:16:00,663 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:16:00.663367', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:16:00,677 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:16:00,678 : INFO : resetting layer weights\n",
      "2023-12-06 14:16:00,680 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:16:00.680461', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:16:00,929 : INFO : EPOCH 0: training on 99524 raw words (62752 effective words) took 0.2s, 255528 effective words/s\n",
      "2023-12-06 14:16:01,176 : INFO : EPOCH 1: training on 99524 raw words (62608 effective words) took 0.2s, 258131 effective words/s\n",
      "2023-12-06 14:16:01,428 : INFO : EPOCH 2: training on 99524 raw words (62723 effective words) took 0.2s, 253879 effective words/s\n",
      "2023-12-06 14:16:01,672 : INFO : EPOCH 3: training on 99524 raw words (62785 effective words) took 0.2s, 262251 effective words/s\n",
      "2023-12-06 14:16:01,919 : INFO : EPOCH 4: training on 99524 raw words (62763 effective words) took 0.2s, 258837 effective words/s\n",
      "2023-12-06 14:16:02,169 : INFO : EPOCH 5: training on 99524 raw words (62695 effective words) took 0.2s, 254799 effective words/s\n",
      "2023-12-06 14:16:02,428 : INFO : EPOCH 6: training on 99524 raw words (62764 effective words) took 0.3s, 247435 effective words/s\n",
      "2023-12-06 14:16:02,690 : INFO : EPOCH 7: training on 99524 raw words (62732 effective words) took 0.3s, 244875 effective words/s\n",
      "2023-12-06 14:16:02,938 : INFO : EPOCH 8: training on 99524 raw words (62698 effective words) took 0.2s, 258417 effective words/s\n",
      "2023-12-06 14:16:03,206 : INFO : EPOCH 9: training on 99524 raw words (62692 effective words) took 0.3s, 238126 effective words/s\n",
      "2023-12-06 14:16:03,463 : INFO : EPOCH 10: training on 99524 raw words (62890 effective words) took 0.3s, 251342 effective words/s\n",
      "2023-12-06 14:16:03,719 : INFO : EPOCH 11: training on 99524 raw words (62644 effective words) took 0.3s, 249314 effective words/s\n",
      "2023-12-06 14:16:03,969 : INFO : EPOCH 12: training on 99524 raw words (62891 effective words) took 0.2s, 256502 effective words/s\n",
      "2023-12-06 14:16:04,218 : INFO : EPOCH 13: training on 99524 raw words (62665 effective words) took 0.2s, 256168 effective words/s\n",
      "2023-12-06 14:16:04,476 : INFO : EPOCH 14: training on 99524 raw words (62759 effective words) took 0.3s, 247863 effective words/s\n",
      "2023-12-06 14:16:04,731 : INFO : EPOCH 15: training on 99524 raw words (62540 effective words) took 0.3s, 249231 effective words/s\n",
      "2023-12-06 14:16:04,988 : INFO : EPOCH 16: training on 99524 raw words (62869 effective words) took 0.3s, 249066 effective words/s\n",
      "2023-12-06 14:16:05,228 : INFO : EPOCH 17: training on 99524 raw words (62606 effective words) took 0.2s, 266244 effective words/s\n",
      "2023-12-06 14:16:05,433 : INFO : EPOCH 18: training on 99524 raw words (62553 effective words) took 0.2s, 310868 effective words/s\n",
      "2023-12-06 14:16:05,634 : INFO : EPOCH 19: training on 99524 raw words (62643 effective words) took 0.2s, 320241 effective words/s\n",
      "2023-12-06 14:16:05,833 : INFO : EPOCH 20: training on 99524 raw words (62650 effective words) took 0.2s, 319384 effective words/s\n",
      "2023-12-06 14:16:06,038 : INFO : EPOCH 21: training on 99524 raw words (62943 effective words) took 0.2s, 314037 effective words/s\n",
      "2023-12-06 14:16:06,239 : INFO : EPOCH 22: training on 99524 raw words (62831 effective words) took 0.2s, 321632 effective words/s\n",
      "2023-12-06 14:16:06,447 : INFO : EPOCH 23: training on 99524 raw words (62835 effective words) took 0.2s, 309193 effective words/s\n",
      "2023-12-06 14:16:06,643 : INFO : EPOCH 24: training on 99524 raw words (62726 effective words) took 0.2s, 325242 effective words/s\n",
      "2023-12-06 14:16:06,845 : INFO : EPOCH 25: training on 99524 raw words (62704 effective words) took 0.2s, 317819 effective words/s\n",
      "2023-12-06 14:16:07,044 : INFO : EPOCH 26: training on 99524 raw words (62934 effective words) took 0.2s, 323983 effective words/s\n",
      "2023-12-06 14:16:07,239 : INFO : EPOCH 27: training on 99524 raw words (62697 effective words) took 0.2s, 327615 effective words/s\n",
      "2023-12-06 14:16:07,433 : INFO : EPOCH 28: training on 99524 raw words (62656 effective words) took 0.2s, 330368 effective words/s\n",
      "2023-12-06 14:16:07,626 : INFO : EPOCH 29: training on 99524 raw words (62562 effective words) took 0.2s, 331334 effective words/s\n",
      "2023-12-06 14:16:07,822 : INFO : EPOCH 30: training on 99524 raw words (62712 effective words) took 0.2s, 329431 effective words/s\n",
      "2023-12-06 14:16:08,014 : INFO : EPOCH 31: training on 99524 raw words (62902 effective words) took 0.2s, 333419 effective words/s\n",
      "2023-12-06 14:16:08,207 : INFO : EPOCH 32: training on 99524 raw words (62653 effective words) took 0.2s, 331644 effective words/s\n",
      "2023-12-06 14:16:08,402 : INFO : EPOCH 33: training on 99524 raw words (62745 effective words) took 0.2s, 330241 effective words/s\n",
      "2023-12-06 14:16:08,596 : INFO : EPOCH 34: training on 99524 raw words (62617 effective words) took 0.2s, 330528 effective words/s\n",
      "2023-12-06 14:16:08,790 : INFO : EPOCH 35: training on 99524 raw words (62774 effective words) took 0.2s, 330780 effective words/s\n",
      "2023-12-06 14:16:08,986 : INFO : EPOCH 36: training on 99524 raw words (62683 effective words) took 0.2s, 327430 effective words/s\n",
      "2023-12-06 14:16:09,189 : INFO : EPOCH 37: training on 99524 raw words (62787 effective words) took 0.2s, 314076 effective words/s\n",
      "2023-12-06 14:16:09,386 : INFO : EPOCH 38: training on 99524 raw words (62739 effective words) took 0.2s, 326519 effective words/s\n",
      "2023-12-06 14:16:09,580 : INFO : EPOCH 39: training on 99524 raw words (62777 effective words) took 0.2s, 331254 effective words/s\n",
      "2023-12-06 14:16:09,772 : INFO : EPOCH 40: training on 99524 raw words (62784 effective words) took 0.2s, 334664 effective words/s\n",
      "2023-12-06 14:16:09,965 : INFO : EPOCH 41: training on 99524 raw words (62763 effective words) took 0.2s, 331054 effective words/s\n",
      "2023-12-06 14:16:10,162 : INFO : EPOCH 42: training on 99524 raw words (62860 effective words) took 0.2s, 328504 effective words/s\n",
      "2023-12-06 14:16:10,358 : INFO : EPOCH 43: training on 99524 raw words (62852 effective words) took 0.2s, 327484 effective words/s\n",
      "2023-12-06 14:16:10,551 : INFO : EPOCH 44: training on 99524 raw words (62600 effective words) took 0.2s, 331295 effective words/s\n",
      "2023-12-06 14:16:10,745 : INFO : EPOCH 45: training on 99524 raw words (62758 effective words) took 0.2s, 330115 effective words/s\n",
      "2023-12-06 14:16:10,941 : INFO : EPOCH 46: training on 99524 raw words (62793 effective words) took 0.2s, 328602 effective words/s\n",
      "2023-12-06 14:16:11,133 : INFO : EPOCH 47: training on 99524 raw words (62734 effective words) took 0.2s, 333382 effective words/s\n",
      "2023-12-06 14:16:11,327 : INFO : EPOCH 48: training on 99524 raw words (62724 effective words) took 0.2s, 329377 effective words/s\n",
      "2023-12-06 14:16:11,544 : INFO : EPOCH 49: training on 99524 raw words (62641 effective words) took 0.2s, 294325 effective words/s\n",
      "2023-12-06 14:16:11,545 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136708 effective words) took 10.9s, 288686 effective words/s', 'datetime': '2023-12-06T14:16:11.545947', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:16:11,546 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:16:11.546947', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  3%|         | 17/486 [02:34<1:32:00, 11.77s/it]2023-12-06 14:16:15,590 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:16:15,590 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:16:15,611 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:16:15,612 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:16:15,617 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:16:15.617782', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:16:15,618 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:16:15.618782', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:16:15,628 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:16:15,630 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:16:15,631 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:16:15.631844', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:16:15,656 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:16:15,658 : INFO : resetting layer weights\n",
      "2023-12-06 14:16:15,660 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:16:15.660862', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:16:15,885 : INFO : EPOCH 0: training on 99524 raw words (62706 effective words) took 0.2s, 309313 effective words/s\n",
      "2023-12-06 14:16:16,084 : INFO : EPOCH 1: training on 99524 raw words (62633 effective words) took 0.2s, 321001 effective words/s\n",
      "2023-12-06 14:16:16,284 : INFO : EPOCH 2: training on 99524 raw words (62784 effective words) took 0.2s, 321984 effective words/s\n",
      "2023-12-06 14:16:16,481 : INFO : EPOCH 3: training on 99524 raw words (62902 effective words) took 0.2s, 323747 effective words/s\n",
      "2023-12-06 14:16:16,679 : INFO : EPOCH 4: training on 99524 raw words (62792 effective words) took 0.2s, 325616 effective words/s\n",
      "2023-12-06 14:16:16,873 : INFO : EPOCH 5: training on 99524 raw words (62739 effective words) took 0.2s, 330872 effective words/s\n",
      "2023-12-06 14:16:17,068 : INFO : EPOCH 6: training on 99524 raw words (62457 effective words) took 0.2s, 327542 effective words/s\n",
      "2023-12-06 14:16:17,265 : INFO : EPOCH 7: training on 99524 raw words (62470 effective words) took 0.2s, 323766 effective words/s\n",
      "2023-12-06 14:16:17,458 : INFO : EPOCH 8: training on 99524 raw words (62594 effective words) took 0.2s, 330856 effective words/s\n",
      "2023-12-06 14:16:17,654 : INFO : EPOCH 9: training on 99524 raw words (62629 effective words) took 0.2s, 327824 effective words/s\n",
      "2023-12-06 14:16:17,849 : INFO : EPOCH 10: training on 99524 raw words (62711 effective words) took 0.2s, 327159 effective words/s\n",
      "2023-12-06 14:16:18,043 : INFO : EPOCH 11: training on 99524 raw words (62694 effective words) took 0.2s, 329123 effective words/s\n",
      "2023-12-06 14:16:18,250 : INFO : EPOCH 12: training on 99524 raw words (62654 effective words) took 0.2s, 309781 effective words/s\n",
      "2023-12-06 14:16:18,448 : INFO : EPOCH 13: training on 99524 raw words (62521 effective words) took 0.2s, 322174 effective words/s\n",
      "2023-12-06 14:16:18,646 : INFO : EPOCH 14: training on 99524 raw words (62674 effective words) took 0.2s, 323898 effective words/s\n",
      "2023-12-06 14:16:18,839 : INFO : EPOCH 15: training on 99524 raw words (62893 effective words) took 0.2s, 331611 effective words/s\n",
      "2023-12-06 14:16:19,036 : INFO : EPOCH 16: training on 99524 raw words (62689 effective words) took 0.2s, 326316 effective words/s\n",
      "2023-12-06 14:16:19,231 : INFO : EPOCH 17: training on 99524 raw words (62754 effective words) took 0.2s, 329764 effective words/s\n",
      "2023-12-06 14:16:19,426 : INFO : EPOCH 18: training on 99524 raw words (62665 effective words) took 0.2s, 328544 effective words/s\n",
      "2023-12-06 14:16:19,621 : INFO : EPOCH 19: training on 99524 raw words (62690 effective words) took 0.2s, 328561 effective words/s\n",
      "2023-12-06 14:16:19,815 : INFO : EPOCH 20: training on 99524 raw words (62781 effective words) took 0.2s, 330083 effective words/s\n",
      "2023-12-06 14:16:20,010 : INFO : EPOCH 21: training on 99524 raw words (62597 effective words) took 0.2s, 328066 effective words/s\n",
      "2023-12-06 14:16:20,208 : INFO : EPOCH 22: training on 99524 raw words (62749 effective words) took 0.2s, 324366 effective words/s\n",
      "2023-12-06 14:16:20,405 : INFO : EPOCH 23: training on 99524 raw words (62634 effective words) took 0.2s, 326748 effective words/s\n",
      "2023-12-06 14:16:20,598 : INFO : EPOCH 24: training on 99524 raw words (62743 effective words) took 0.2s, 330206 effective words/s\n",
      "2023-12-06 14:16:20,794 : INFO : EPOCH 25: training on 99524 raw words (62723 effective words) took 0.2s, 328727 effective words/s\n",
      "2023-12-06 14:16:21,000 : INFO : EPOCH 26: training on 99524 raw words (62746 effective words) took 0.2s, 310389 effective words/s\n",
      "2023-12-06 14:16:21,198 : INFO : EPOCH 27: training on 99524 raw words (62717 effective words) took 0.2s, 324022 effective words/s\n",
      "2023-12-06 14:16:21,394 : INFO : EPOCH 28: training on 99524 raw words (62696 effective words) took 0.2s, 325158 effective words/s\n",
      "2023-12-06 14:16:21,589 : INFO : EPOCH 29: training on 99524 raw words (62679 effective words) took 0.2s, 328729 effective words/s\n",
      "2023-12-06 14:16:21,785 : INFO : EPOCH 30: training on 99524 raw words (62663 effective words) took 0.2s, 327642 effective words/s\n",
      "2023-12-06 14:16:21,982 : INFO : EPOCH 31: training on 99524 raw words (62851 effective words) took 0.2s, 326886 effective words/s\n",
      "2023-12-06 14:16:22,176 : INFO : EPOCH 32: training on 99524 raw words (62707 effective words) took 0.2s, 328564 effective words/s\n",
      "2023-12-06 14:16:22,372 : INFO : EPOCH 33: training on 99524 raw words (62688 effective words) took 0.2s, 328383 effective words/s\n",
      "2023-12-06 14:16:22,569 : INFO : EPOCH 34: training on 99524 raw words (62835 effective words) took 0.2s, 325731 effective words/s\n",
      "2023-12-06 14:16:22,766 : INFO : EPOCH 35: training on 99524 raw words (62672 effective words) took 0.2s, 326155 effective words/s\n",
      "2023-12-06 14:16:22,963 : INFO : EPOCH 36: training on 99524 raw words (62921 effective words) took 0.2s, 325370 effective words/s\n",
      "2023-12-06 14:16:23,158 : INFO : EPOCH 37: training on 99524 raw words (62745 effective words) took 0.2s, 328100 effective words/s\n",
      "2023-12-06 14:16:23,353 : INFO : EPOCH 38: training on 99524 raw words (62660 effective words) took 0.2s, 329190 effective words/s\n",
      "2023-12-06 14:16:23,561 : INFO : EPOCH 39: training on 99524 raw words (62764 effective words) took 0.2s, 308747 effective words/s\n",
      "2023-12-06 14:16:23,759 : INFO : EPOCH 40: training on 99524 raw words (62691 effective words) took 0.2s, 323379 effective words/s\n",
      "2023-12-06 14:16:23,953 : INFO : EPOCH 41: training on 99524 raw words (62655 effective words) took 0.2s, 330541 effective words/s\n",
      "2023-12-06 14:16:24,149 : INFO : EPOCH 42: training on 99524 raw words (62740 effective words) took 0.2s, 326386 effective words/s\n",
      "2023-12-06 14:16:24,345 : INFO : EPOCH 43: training on 99524 raw words (62715 effective words) took 0.2s, 328070 effective words/s\n",
      "2023-12-06 14:16:24,540 : INFO : EPOCH 44: training on 99524 raw words (62705 effective words) took 0.2s, 328308 effective words/s\n",
      "2023-12-06 14:16:24,735 : INFO : EPOCH 45: training on 99524 raw words (62767 effective words) took 0.2s, 329139 effective words/s\n",
      "2023-12-06 14:16:24,933 : INFO : EPOCH 46: training on 99524 raw words (62690 effective words) took 0.2s, 322891 effective words/s\n",
      "2023-12-06 14:16:25,127 : INFO : EPOCH 47: training on 99524 raw words (62773 effective words) took 0.2s, 329916 effective words/s\n",
      "2023-12-06 14:16:25,324 : INFO : EPOCH 48: training on 99524 raw words (62723 effective words) took 0.2s, 327368 effective words/s\n",
      "2023-12-06 14:16:25,519 : INFO : EPOCH 49: training on 99524 raw words (62641 effective words) took 0.2s, 327487 effective words/s\n",
      "2023-12-06 14:16:25,520 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3135322 effective words) took 9.9s, 318017 effective words/s', 'datetime': '2023-12-06T14:16:25.520877', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:16:25,521 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:16:25.521892', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  4%|         | 18/486 [02:48<1:37:37, 12.52s/it]2023-12-06 14:16:29,842 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:16:29,842 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:16:29,863 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:16:29,863 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:16:29,867 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:16:29.867832', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:16:29,867 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:16:29.867832', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:16:29,872 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:16:29,873 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:16:29,874 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:16:29.874637', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:16:29,885 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:16:29,886 : INFO : resetting layer weights\n",
      "2023-12-06 14:16:29,890 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:16:29.889752', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:16:30,089 : INFO : EPOCH 0: training on 99524 raw words (60464 effective words) took 0.2s, 315736 effective words/s\n",
      "2023-12-06 14:16:30,285 : INFO : EPOCH 1: training on 99524 raw words (60435 effective words) took 0.2s, 317285 effective words/s\n",
      "2023-12-06 14:16:30,487 : INFO : EPOCH 2: training on 99524 raw words (60459 effective words) took 0.2s, 303794 effective words/s\n",
      "2023-12-06 14:16:30,679 : INFO : EPOCH 3: training on 99524 raw words (60486 effective words) took 0.2s, 323164 effective words/s\n",
      "2023-12-06 14:16:30,878 : INFO : EPOCH 4: training on 99524 raw words (60309 effective words) took 0.2s, 309662 effective words/s\n",
      "2023-12-06 14:16:31,081 : INFO : EPOCH 5: training on 99524 raw words (60496 effective words) took 0.2s, 305191 effective words/s\n",
      "2023-12-06 14:16:31,274 : INFO : EPOCH 6: training on 99524 raw words (60470 effective words) took 0.2s, 320282 effective words/s\n",
      "2023-12-06 14:16:31,463 : INFO : EPOCH 7: training on 99524 raw words (60304 effective words) took 0.2s, 326573 effective words/s\n",
      "2023-12-06 14:16:31,654 : INFO : EPOCH 8: training on 99524 raw words (60489 effective words) took 0.2s, 323757 effective words/s\n",
      "2023-12-06 14:16:31,842 : INFO : EPOCH 9: training on 99524 raw words (60397 effective words) took 0.2s, 329210 effective words/s\n",
      "2023-12-06 14:16:31,843 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604309 effective words) took 2.0s, 309712 effective words/s', 'datetime': '2023-12-06T14:16:31.843237', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:16:31,843 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:16:31.843237', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  4%|         | 19/486 [02:53<1:19:13, 10.18s/it]2023-12-06 14:16:34,579 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:16:34,579 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:16:34,601 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:16:34,602 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:16:34,608 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:16:34.608212', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:16:34,609 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:16:34.609420', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:16:34,614 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:16:34,614 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:16:34,614 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:16:34.614645', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:16:34,622 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:16:34,624 : INFO : resetting layer weights\n",
      "2023-12-06 14:16:34,625 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:16:34.625207', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:16:34,829 : INFO : EPOCH 0: training on 99524 raw words (60289 effective words) took 0.2s, 301524 effective words/s\n",
      "2023-12-06 14:16:35,022 : INFO : EPOCH 1: training on 99524 raw words (60309 effective words) took 0.2s, 318352 effective words/s\n",
      "2023-12-06 14:16:35,215 : INFO : EPOCH 2: training on 99524 raw words (60520 effective words) took 0.2s, 321371 effective words/s\n",
      "2023-12-06 14:16:35,409 : INFO : EPOCH 3: training on 99524 raw words (60320 effective words) took 0.2s, 317914 effective words/s\n",
      "2023-12-06 14:16:35,603 : INFO : EPOCH 4: training on 99524 raw words (60364 effective words) took 0.2s, 319545 effective words/s\n",
      "2023-12-06 14:16:35,794 : INFO : EPOCH 5: training on 99524 raw words (60383 effective words) took 0.2s, 321367 effective words/s\n",
      "2023-12-06 14:16:35,985 : INFO : EPOCH 6: training on 99524 raw words (60428 effective words) took 0.2s, 323692 effective words/s\n",
      "2023-12-06 14:16:36,178 : INFO : EPOCH 7: training on 99524 raw words (60391 effective words) took 0.2s, 320965 effective words/s\n",
      "2023-12-06 14:16:36,369 : INFO : EPOCH 8: training on 99524 raw words (60265 effective words) took 0.2s, 322824 effective words/s\n",
      "2023-12-06 14:16:36,560 : INFO : EPOCH 9: training on 99524 raw words (60160 effective words) took 0.2s, 322933 effective words/s\n",
      "2023-12-06 14:16:36,561 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603429 effective words) took 1.9s, 311879 effective words/s', 'datetime': '2023-12-06T14:16:36.561020', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:16:36,561 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:16:36.561020', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  4%|         | 20/486 [02:58<1:06:30,  8.56s/it]2023-12-06 14:16:39,373 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:16:39,374 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:16:39,395 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:16:39,396 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:16:39,401 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:16:39.401481', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:16:39,401 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:16:39.401481', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:16:39,409 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:16:39,411 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:16:39,412 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:16:39.412006', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:16:39,423 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:16:39,425 : INFO : resetting layer weights\n",
      "2023-12-06 14:16:39,426 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:16:39.426804', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:16:39,629 : INFO : EPOCH 0: training on 99524 raw words (60512 effective words) took 0.2s, 306252 effective words/s\n",
      "2023-12-06 14:16:39,826 : INFO : EPOCH 1: training on 99524 raw words (60447 effective words) took 0.2s, 313310 effective words/s\n",
      "2023-12-06 14:16:40,026 : INFO : EPOCH 2: training on 99524 raw words (60299 effective words) took 0.2s, 308419 effective words/s\n",
      "2023-12-06 14:16:40,228 : INFO : EPOCH 3: training on 99524 raw words (60383 effective words) took 0.2s, 305647 effective words/s\n",
      "2023-12-06 14:16:40,424 : INFO : EPOCH 4: training on 99524 raw words (60332 effective words) took 0.2s, 314802 effective words/s\n",
      "2023-12-06 14:16:40,629 : INFO : EPOCH 5: training on 99524 raw words (60295 effective words) took 0.2s, 298020 effective words/s\n",
      "2023-12-06 14:16:40,834 : INFO : EPOCH 6: training on 99524 raw words (60457 effective words) took 0.2s, 303048 effective words/s\n",
      "2023-12-06 14:16:41,038 : INFO : EPOCH 7: training on 99524 raw words (60463 effective words) took 0.2s, 302152 effective words/s\n",
      "2023-12-06 14:16:41,243 : INFO : EPOCH 8: training on 99524 raw words (60357 effective words) took 0.2s, 301747 effective words/s\n",
      "2023-12-06 14:16:41,449 : INFO : EPOCH 9: training on 99524 raw words (60301 effective words) took 0.2s, 298945 effective words/s\n",
      "2023-12-06 14:16:41,449 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603846 effective words) took 2.0s, 298516 effective words/s', 'datetime': '2023-12-06T14:16:41.449948', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:16:41,450 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:16:41.450948', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  4%|         | 21/486 [03:02<57:49,  7.46s/it]  2023-12-06 14:16:44,269 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:16:44,270 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:16:44,291 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:16:44,292 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:16:44,296 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:16:44.296470', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:16:44,296 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:16:44.296470', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:16:44,303 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:16:44,304 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:16:44,304 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:16:44.304472', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:16:44,317 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:16:44,319 : INFO : resetting layer weights\n",
      "2023-12-06 14:16:44,322 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:16:44.322892', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:16:44,520 : INFO : EPOCH 0: training on 99524 raw words (60367 effective words) took 0.2s, 314996 effective words/s\n",
      "2023-12-06 14:16:44,715 : INFO : EPOCH 1: training on 99524 raw words (60312 effective words) took 0.2s, 315712 effective words/s\n",
      "2023-12-06 14:16:44,910 : INFO : EPOCH 2: training on 99524 raw words (60398 effective words) took 0.2s, 316761 effective words/s\n",
      "2023-12-06 14:16:45,106 : INFO : EPOCH 3: training on 99524 raw words (60394 effective words) took 0.2s, 315468 effective words/s\n",
      "2023-12-06 14:16:45,299 : INFO : EPOCH 4: training on 99524 raw words (60487 effective words) took 0.2s, 320093 effective words/s\n",
      "2023-12-06 14:16:45,491 : INFO : EPOCH 5: training on 99524 raw words (60436 effective words) took 0.2s, 320933 effective words/s\n",
      "2023-12-06 14:16:45,680 : INFO : EPOCH 6: training on 99524 raw words (60438 effective words) took 0.2s, 328276 effective words/s\n",
      "2023-12-06 14:16:45,868 : INFO : EPOCH 7: training on 99524 raw words (60410 effective words) took 0.2s, 327803 effective words/s\n",
      "2023-12-06 14:16:46,057 : INFO : EPOCH 8: training on 99524 raw words (60361 effective words) took 0.2s, 325799 effective words/s\n",
      "2023-12-06 14:16:46,246 : INFO : EPOCH 9: training on 99524 raw words (60288 effective words) took 0.2s, 327075 effective words/s\n",
      "2023-12-06 14:16:46,444 : INFO : EPOCH 10: training on 99524 raw words (60573 effective words) took 0.2s, 313739 effective words/s\n",
      "2023-12-06 14:16:46,634 : INFO : EPOCH 11: training on 99524 raw words (60489 effective words) took 0.2s, 326440 effective words/s\n",
      "2023-12-06 14:16:46,821 : INFO : EPOCH 12: training on 99524 raw words (60431 effective words) took 0.2s, 329222 effective words/s\n",
      "2023-12-06 14:16:47,010 : INFO : EPOCH 13: training on 99524 raw words (60326 effective words) took 0.2s, 326676 effective words/s\n",
      "2023-12-06 14:16:47,199 : INFO : EPOCH 14: training on 99524 raw words (60465 effective words) took 0.2s, 327581 effective words/s\n",
      "2023-12-06 14:16:47,388 : INFO : EPOCH 15: training on 99524 raw words (60437 effective words) took 0.2s, 327278 effective words/s\n",
      "2023-12-06 14:16:47,578 : INFO : EPOCH 16: training on 99524 raw words (60354 effective words) took 0.2s, 325728 effective words/s\n",
      "2023-12-06 14:16:47,768 : INFO : EPOCH 17: training on 99524 raw words (60458 effective words) took 0.2s, 324460 effective words/s\n",
      "2023-12-06 14:16:47,959 : INFO : EPOCH 18: training on 99524 raw words (60453 effective words) took 0.2s, 321972 effective words/s\n",
      "2023-12-06 14:16:48,155 : INFO : EPOCH 19: training on 99524 raw words (60485 effective words) took 0.2s, 317131 effective words/s\n",
      "2023-12-06 14:16:48,371 : INFO : EPOCH 20: training on 99524 raw words (60356 effective words) took 0.2s, 284689 effective words/s\n",
      "2023-12-06 14:16:48,562 : INFO : EPOCH 21: training on 99524 raw words (60454 effective words) took 0.2s, 326103 effective words/s\n",
      "2023-12-06 14:16:48,749 : INFO : EPOCH 22: training on 99524 raw words (60443 effective words) took 0.2s, 328558 effective words/s\n",
      "2023-12-06 14:16:48,938 : INFO : EPOCH 23: training on 99524 raw words (60323 effective words) took 0.2s, 325939 effective words/s\n",
      "2023-12-06 14:16:49,128 : INFO : EPOCH 24: training on 99524 raw words (60264 effective words) took 0.2s, 325752 effective words/s\n",
      "2023-12-06 14:16:49,322 : INFO : EPOCH 25: training on 99524 raw words (60450 effective words) took 0.2s, 317872 effective words/s\n",
      "2023-12-06 14:16:49,515 : INFO : EPOCH 26: training on 99524 raw words (60535 effective words) took 0.2s, 321491 effective words/s\n",
      "2023-12-06 14:16:49,714 : INFO : EPOCH 27: training on 99524 raw words (60361 effective words) took 0.2s, 310158 effective words/s\n",
      "2023-12-06 14:16:49,921 : INFO : EPOCH 28: training on 99524 raw words (60369 effective words) took 0.2s, 297989 effective words/s\n",
      "2023-12-06 14:16:50,114 : INFO : EPOCH 29: training on 99524 raw words (60339 effective words) took 0.2s, 319717 effective words/s\n",
      "2023-12-06 14:16:50,115 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812256 effective words) took 5.8s, 312914 effective words/s', 'datetime': '2023-12-06T14:16:50.115553', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:16:50,115 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:16:50.115553', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  5%|         | 22/486 [03:11<1:01:23,  7.94s/it]2023-12-06 14:16:53,317 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:16:53,318 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:16:53,349 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:16:53,350 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:16:53,355 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:16:53.355703', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:16:53,355 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:16:53.355703', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:16:53,360 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:16:53,361 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:16:53,361 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:16:53.361710', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:16:53,369 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:16:53,370 : INFO : resetting layer weights\n",
      "2023-12-06 14:16:53,372 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:16:53.372110', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:16:53,563 : INFO : EPOCH 0: training on 99524 raw words (60359 effective words) took 0.2s, 322673 effective words/s\n",
      "2023-12-06 14:16:53,754 : INFO : EPOCH 1: training on 99524 raw words (60444 effective words) took 0.2s, 322993 effective words/s\n",
      "2023-12-06 14:16:53,947 : INFO : EPOCH 2: training on 99524 raw words (60295 effective words) took 0.2s, 321213 effective words/s\n",
      "2023-12-06 14:16:54,140 : INFO : EPOCH 3: training on 99524 raw words (60496 effective words) took 0.2s, 319184 effective words/s\n",
      "2023-12-06 14:16:54,335 : INFO : EPOCH 4: training on 99524 raw words (60295 effective words) took 0.2s, 317054 effective words/s\n",
      "2023-12-06 14:16:54,526 : INFO : EPOCH 5: training on 99524 raw words (60479 effective words) took 0.2s, 322505 effective words/s\n",
      "2023-12-06 14:16:54,749 : INFO : EPOCH 6: training on 99524 raw words (60356 effective words) took 0.2s, 277360 effective words/s\n",
      "2023-12-06 14:16:55,000 : INFO : EPOCH 7: training on 99524 raw words (60423 effective words) took 0.2s, 244171 effective words/s\n",
      "2023-12-06 14:16:55,253 : INFO : EPOCH 8: training on 99524 raw words (60423 effective words) took 0.2s, 243536 effective words/s\n",
      "2023-12-06 14:16:55,503 : INFO : EPOCH 9: training on 99524 raw words (60181 effective words) took 0.2s, 244775 effective words/s\n",
      "2023-12-06 14:16:55,753 : INFO : EPOCH 10: training on 99524 raw words (60328 effective words) took 0.2s, 245701 effective words/s\n",
      "2023-12-06 14:16:56,005 : INFO : EPOCH 11: training on 99524 raw words (60394 effective words) took 0.2s, 244142 effective words/s\n",
      "2023-12-06 14:16:56,255 : INFO : EPOCH 12: training on 99524 raw words (60359 effective words) took 0.2s, 246023 effective words/s\n",
      "2023-12-06 14:16:56,497 : INFO : EPOCH 13: training on 99524 raw words (60462 effective words) took 0.2s, 255286 effective words/s\n",
      "2023-12-06 14:16:56,744 : INFO : EPOCH 14: training on 99524 raw words (60398 effective words) took 0.2s, 248442 effective words/s\n",
      "2023-12-06 14:16:56,987 : INFO : EPOCH 15: training on 99524 raw words (60334 effective words) took 0.2s, 251614 effective words/s\n",
      "2023-12-06 14:16:57,236 : INFO : EPOCH 16: training on 99524 raw words (60349 effective words) took 0.2s, 247583 effective words/s\n",
      "2023-12-06 14:16:57,485 : INFO : EPOCH 17: training on 99524 raw words (60361 effective words) took 0.2s, 247508 effective words/s\n",
      "2023-12-06 14:16:57,733 : INFO : EPOCH 18: training on 99524 raw words (60285 effective words) took 0.2s, 248098 effective words/s\n",
      "2023-12-06 14:16:57,983 : INFO : EPOCH 19: training on 99524 raw words (60474 effective words) took 0.2s, 245154 effective words/s\n",
      "2023-12-06 14:16:58,231 : INFO : EPOCH 20: training on 99524 raw words (60405 effective words) took 0.2s, 248290 effective words/s\n",
      "2023-12-06 14:16:58,479 : INFO : EPOCH 21: training on 99524 raw words (60445 effective words) took 0.2s, 246901 effective words/s\n",
      "2023-12-06 14:16:58,729 : INFO : EPOCH 22: training on 99524 raw words (60372 effective words) took 0.2s, 246062 effective words/s\n",
      "2023-12-06 14:16:58,979 : INFO : EPOCH 23: training on 99524 raw words (60272 effective words) took 0.2s, 245431 effective words/s\n",
      "2023-12-06 14:16:59,231 : INFO : EPOCH 24: training on 99524 raw words (60289 effective words) took 0.2s, 244132 effective words/s\n",
      "2023-12-06 14:16:59,493 : INFO : EPOCH 25: training on 99524 raw words (60517 effective words) took 0.3s, 233736 effective words/s\n",
      "2023-12-06 14:16:59,767 : INFO : EPOCH 26: training on 99524 raw words (60247 effective words) took 0.3s, 224259 effective words/s\n",
      "2023-12-06 14:17:00,029 : INFO : EPOCH 27: training on 99524 raw words (60269 effective words) took 0.3s, 235208 effective words/s\n",
      "2023-12-06 14:17:00,276 : INFO : EPOCH 28: training on 99524 raw words (60386 effective words) took 0.2s, 248948 effective words/s\n",
      "2023-12-06 14:17:00,536 : INFO : EPOCH 29: training on 99524 raw words (60318 effective words) took 0.3s, 236460 effective words/s\n",
      "2023-12-06 14:17:00,537 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811015 effective words) took 7.2s, 252789 effective words/s', 'datetime': '2023-12-06T14:17:00.537179', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:17:00,538 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:17:00.538221', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  5%|         | 23/486 [03:22<1:07:56,  8.80s/it]2023-12-06 14:17:04,145 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:17:04,145 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:17:04,169 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:17:04,170 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:17:04,177 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:17:04.177241', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:17:04,177 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:17:04.177241', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:17:04,183 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:17:04,183 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:17:04,184 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:17:04.184578', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:17:04,193 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:17:04,194 : INFO : resetting layer weights\n",
      "2023-12-06 14:17:04,196 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:17:04.196956', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:17:04,457 : INFO : EPOCH 0: training on 99524 raw words (60378 effective words) took 0.3s, 235998 effective words/s\n",
      "2023-12-06 14:17:04,715 : INFO : EPOCH 1: training on 99524 raw words (60261 effective words) took 0.3s, 236752 effective words/s\n",
      "2023-12-06 14:17:04,973 : INFO : EPOCH 2: training on 99524 raw words (60405 effective words) took 0.3s, 239676 effective words/s\n",
      "2023-12-06 14:17:05,231 : INFO : EPOCH 3: training on 99524 raw words (60338 effective words) took 0.3s, 236849 effective words/s\n",
      "2023-12-06 14:17:05,488 : INFO : EPOCH 4: training on 99524 raw words (60447 effective words) took 0.3s, 239907 effective words/s\n",
      "2023-12-06 14:17:05,743 : INFO : EPOCH 5: training on 99524 raw words (60493 effective words) took 0.3s, 240451 effective words/s\n",
      "2023-12-06 14:17:05,998 : INFO : EPOCH 6: training on 99524 raw words (60498 effective words) took 0.3s, 241254 effective words/s\n",
      "2023-12-06 14:17:06,259 : INFO : EPOCH 7: training on 99524 raw words (60232 effective words) took 0.3s, 236350 effective words/s\n",
      "2023-12-06 14:17:06,518 : INFO : EPOCH 8: training on 99524 raw words (60408 effective words) took 0.3s, 236810 effective words/s\n",
      "2023-12-06 14:17:06,773 : INFO : EPOCH 9: training on 99524 raw words (60366 effective words) took 0.3s, 240444 effective words/s\n",
      "2023-12-06 14:17:07,029 : INFO : EPOCH 10: training on 99524 raw words (60258 effective words) took 0.3s, 239657 effective words/s\n",
      "2023-12-06 14:17:07,284 : INFO : EPOCH 11: training on 99524 raw words (60423 effective words) took 0.3s, 241592 effective words/s\n",
      "2023-12-06 14:17:07,566 : INFO : EPOCH 12: training on 99524 raw words (60305 effective words) took 0.3s, 216362 effective words/s\n",
      "2023-12-06 14:17:07,836 : INFO : EPOCH 13: training on 99524 raw words (60379 effective words) took 0.3s, 228510 effective words/s\n",
      "2023-12-06 14:17:08,105 : INFO : EPOCH 14: training on 99524 raw words (60239 effective words) took 0.3s, 227129 effective words/s\n",
      "2023-12-06 14:17:08,365 : INFO : EPOCH 15: training on 99524 raw words (60358 effective words) took 0.3s, 236863 effective words/s\n",
      "2023-12-06 14:17:08,622 : INFO : EPOCH 16: training on 99524 raw words (60150 effective words) took 0.3s, 237679 effective words/s\n",
      "2023-12-06 14:17:08,880 : INFO : EPOCH 17: training on 99524 raw words (60402 effective words) took 0.3s, 238290 effective words/s\n",
      "2023-12-06 14:17:09,138 : INFO : EPOCH 18: training on 99524 raw words (60484 effective words) took 0.3s, 237952 effective words/s\n",
      "2023-12-06 14:17:09,395 : INFO : EPOCH 19: training on 99524 raw words (60486 effective words) took 0.3s, 240045 effective words/s\n",
      "2023-12-06 14:17:09,654 : INFO : EPOCH 20: training on 99524 raw words (60294 effective words) took 0.3s, 237112 effective words/s\n",
      "2023-12-06 14:17:09,912 : INFO : EPOCH 21: training on 99524 raw words (60413 effective words) took 0.3s, 237083 effective words/s\n",
      "2023-12-06 14:17:10,172 : INFO : EPOCH 22: training on 99524 raw words (60363 effective words) took 0.3s, 237889 effective words/s\n",
      "2023-12-06 14:17:10,428 : INFO : EPOCH 23: training on 99524 raw words (60453 effective words) took 0.3s, 239462 effective words/s\n",
      "2023-12-06 14:17:10,687 : INFO : EPOCH 24: training on 99524 raw words (60346 effective words) took 0.3s, 237322 effective words/s\n",
      "2023-12-06 14:17:10,946 : INFO : EPOCH 25: training on 99524 raw words (60459 effective words) took 0.3s, 237124 effective words/s\n",
      "2023-12-06 14:17:11,205 : INFO : EPOCH 26: training on 99524 raw words (60390 effective words) took 0.3s, 238082 effective words/s\n",
      "2023-12-06 14:17:11,471 : INFO : EPOCH 27: training on 99524 raw words (60356 effective words) took 0.3s, 229804 effective words/s\n",
      "2023-12-06 14:17:11,729 : INFO : EPOCH 28: training on 99524 raw words (60616 effective words) took 0.3s, 240836 effective words/s\n",
      "2023-12-06 14:17:11,990 : INFO : EPOCH 29: training on 99524 raw words (60446 effective words) took 0.3s, 235612 effective words/s\n",
      "2023-12-06 14:17:11,991 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811446 effective words) took 7.8s, 232407 effective words/s', 'datetime': '2023-12-06T14:17:11.991455', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:17:11,992 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:17:11.992455', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  5%|         | 24/486 [03:34<1:14:17,  9.65s/it]2023-12-06 14:17:15,762 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:17:15,762 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:17:15,798 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:17:15,799 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:17:15,805 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:17:15.805968', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:17:15,807 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:17:15.806968', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:17:15,822 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:17:15,824 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:17:15,825 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:17:15.825246', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:17:15,838 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:17:15,839 : INFO : resetting layer weights\n",
      "2023-12-06 14:17:15,842 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:17:15.842790', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:17:16,097 : INFO : EPOCH 0: training on 99524 raw words (60443 effective words) took 0.2s, 243276 effective words/s\n",
      "2023-12-06 14:17:16,345 : INFO : EPOCH 1: training on 99524 raw words (60262 effective words) took 0.2s, 247413 effective words/s\n",
      "2023-12-06 14:17:16,589 : INFO : EPOCH 2: training on 99524 raw words (60567 effective words) took 0.2s, 257270 effective words/s\n",
      "2023-12-06 14:17:16,839 : INFO : EPOCH 3: training on 99524 raw words (60373 effective words) took 0.2s, 245855 effective words/s\n",
      "2023-12-06 14:17:17,086 : INFO : EPOCH 4: training on 99524 raw words (60254 effective words) took 0.2s, 248067 effective words/s\n",
      "2023-12-06 14:17:17,333 : INFO : EPOCH 5: training on 99524 raw words (60332 effective words) took 0.2s, 249212 effective words/s\n",
      "2023-12-06 14:17:17,576 : INFO : EPOCH 6: training on 99524 raw words (60412 effective words) took 0.2s, 253562 effective words/s\n",
      "2023-12-06 14:17:17,815 : INFO : EPOCH 7: training on 99524 raw words (60405 effective words) took 0.2s, 257511 effective words/s\n",
      "2023-12-06 14:17:18,067 : INFO : EPOCH 8: training on 99524 raw words (60357 effective words) took 0.2s, 243888 effective words/s\n",
      "2023-12-06 14:17:18,310 : INFO : EPOCH 9: training on 99524 raw words (60392 effective words) took 0.2s, 253807 effective words/s\n",
      "2023-12-06 14:17:18,563 : INFO : EPOCH 10: training on 99524 raw words (60414 effective words) took 0.2s, 243771 effective words/s\n",
      "2023-12-06 14:17:18,807 : INFO : EPOCH 11: training on 99524 raw words (60343 effective words) took 0.2s, 251866 effective words/s\n",
      "2023-12-06 14:17:19,061 : INFO : EPOCH 12: training on 99524 raw words (60402 effective words) took 0.2s, 242613 effective words/s\n",
      "2023-12-06 14:17:19,303 : INFO : EPOCH 13: training on 99524 raw words (60395 effective words) took 0.2s, 254205 effective words/s\n",
      "2023-12-06 14:17:19,543 : INFO : EPOCH 14: training on 99524 raw words (60345 effective words) took 0.2s, 256269 effective words/s\n",
      "2023-12-06 14:17:19,781 : INFO : EPOCH 15: training on 99524 raw words (60316 effective words) took 0.2s, 257868 effective words/s\n",
      "2023-12-06 14:17:20,019 : INFO : EPOCH 16: training on 99524 raw words (60400 effective words) took 0.2s, 259475 effective words/s\n",
      "2023-12-06 14:17:20,259 : INFO : EPOCH 17: training on 99524 raw words (60517 effective words) took 0.2s, 256807 effective words/s\n",
      "2023-12-06 14:17:20,497 : INFO : EPOCH 18: training on 99524 raw words (60163 effective words) took 0.2s, 256550 effective words/s\n",
      "2023-12-06 14:17:20,736 : INFO : EPOCH 19: training on 99524 raw words (60489 effective words) took 0.2s, 258491 effective words/s\n",
      "2023-12-06 14:17:20,975 : INFO : EPOCH 20: training on 99524 raw words (60326 effective words) took 0.2s, 257436 effective words/s\n",
      "2023-12-06 14:17:21,211 : INFO : EPOCH 21: training on 99524 raw words (60415 effective words) took 0.2s, 261058 effective words/s\n",
      "2023-12-06 14:17:21,461 : INFO : EPOCH 22: training on 99524 raw words (60246 effective words) took 0.2s, 245053 effective words/s\n",
      "2023-12-06 14:17:21,703 : INFO : EPOCH 23: training on 99524 raw words (60417 effective words) took 0.2s, 254609 effective words/s\n",
      "2023-12-06 14:17:21,941 : INFO : EPOCH 24: training on 99524 raw words (60437 effective words) took 0.2s, 258820 effective words/s\n",
      "2023-12-06 14:17:22,181 : INFO : EPOCH 25: training on 99524 raw words (60275 effective words) took 0.2s, 256262 effective words/s\n",
      "2023-12-06 14:17:22,415 : INFO : EPOCH 26: training on 99524 raw words (60476 effective words) took 0.2s, 263842 effective words/s\n",
      "2023-12-06 14:17:22,650 : INFO : EPOCH 27: training on 99524 raw words (60582 effective words) took 0.2s, 261405 effective words/s\n",
      "2023-12-06 14:17:22,892 : INFO : EPOCH 28: training on 99524 raw words (60234 effective words) took 0.2s, 253791 effective words/s\n",
      "2023-12-06 14:17:23,129 : INFO : EPOCH 29: training on 99524 raw words (60482 effective words) took 0.2s, 260841 effective words/s\n",
      "2023-12-06 14:17:23,368 : INFO : EPOCH 30: training on 99524 raw words (60413 effective words) took 0.2s, 256619 effective words/s\n",
      "2023-12-06 14:17:23,605 : INFO : EPOCH 31: training on 99524 raw words (60343 effective words) took 0.2s, 259366 effective words/s\n",
      "2023-12-06 14:17:23,848 : INFO : EPOCH 32: training on 99524 raw words (60541 effective words) took 0.2s, 253947 effective words/s\n",
      "2023-12-06 14:17:24,085 : INFO : EPOCH 33: training on 99524 raw words (60460 effective words) took 0.2s, 261255 effective words/s\n",
      "2023-12-06 14:17:24,323 : INFO : EPOCH 34: training on 99524 raw words (60153 effective words) took 0.2s, 256001 effective words/s\n",
      "2023-12-06 14:17:24,558 : INFO : EPOCH 35: training on 99524 raw words (60435 effective words) took 0.2s, 261683 effective words/s\n",
      "2023-12-06 14:17:24,794 : INFO : EPOCH 36: training on 99524 raw words (60564 effective words) took 0.2s, 261646 effective words/s\n",
      "2023-12-06 14:17:25,027 : INFO : EPOCH 37: training on 99524 raw words (60414 effective words) took 0.2s, 265366 effective words/s\n",
      "2023-12-06 14:17:25,262 : INFO : EPOCH 38: training on 99524 raw words (60417 effective words) took 0.2s, 262067 effective words/s\n",
      "2023-12-06 14:17:25,497 : INFO : EPOCH 39: training on 99524 raw words (60414 effective words) took 0.2s, 260694 effective words/s\n",
      "2023-12-06 14:17:25,734 : INFO : EPOCH 40: training on 99524 raw words (60366 effective words) took 0.2s, 260126 effective words/s\n",
      "2023-12-06 14:17:25,968 : INFO : EPOCH 41: training on 99524 raw words (60448 effective words) took 0.2s, 263438 effective words/s\n",
      "2023-12-06 14:17:26,214 : INFO : EPOCH 42: training on 99524 raw words (60314 effective words) took 0.2s, 250285 effective words/s\n",
      "2023-12-06 14:17:26,449 : INFO : EPOCH 43: training on 99524 raw words (60262 effective words) took 0.2s, 261088 effective words/s\n",
      "2023-12-06 14:17:26,681 : INFO : EPOCH 44: training on 99524 raw words (60487 effective words) took 0.2s, 266004 effective words/s\n",
      "2023-12-06 14:17:26,912 : INFO : EPOCH 45: training on 99524 raw words (60497 effective words) took 0.2s, 266251 effective words/s\n",
      "2023-12-06 14:17:27,148 : INFO : EPOCH 46: training on 99524 raw words (60371 effective words) took 0.2s, 261565 effective words/s\n",
      "2023-12-06 14:17:27,381 : INFO : EPOCH 47: training on 99524 raw words (60328 effective words) took 0.2s, 263398 effective words/s\n",
      "2023-12-06 14:17:27,614 : INFO : EPOCH 48: training on 99524 raw words (60499 effective words) took 0.2s, 263554 effective words/s\n",
      "2023-12-06 14:17:27,853 : INFO : EPOCH 49: training on 99524 raw words (60159 effective words) took 0.2s, 256953 effective words/s\n",
      "2023-12-06 14:17:27,854 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3019356 effective words) took 12.0s, 251388 effective words/s', 'datetime': '2023-12-06T14:17:27.854957', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:17:27,854 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:17:27.854957', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  5%|         | 25/486 [03:50<1:28:48, 11.56s/it]2023-12-06 14:17:31,777 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:17:31,777 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:17:31,798 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:17:31,798 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:17:31,805 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:17:31.805754', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:17:31,806 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:17:31.806762', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:17:31,813 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:17:31,815 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:17:31,816 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:17:31.816765', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:17:31,828 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:17:31,829 : INFO : resetting layer weights\n",
      "2023-12-06 14:17:31,831 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:17:31.831366', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:17:32,082 : INFO : EPOCH 0: training on 99524 raw words (60427 effective words) took 0.2s, 246872 effective words/s\n",
      "2023-12-06 14:17:32,333 : INFO : EPOCH 1: training on 99524 raw words (60329 effective words) took 0.2s, 245334 effective words/s\n",
      "2023-12-06 14:17:32,580 : INFO : EPOCH 2: training on 99524 raw words (60407 effective words) took 0.2s, 248738 effective words/s\n",
      "2023-12-06 14:17:32,826 : INFO : EPOCH 3: training on 99524 raw words (60493 effective words) took 0.2s, 250493 effective words/s\n",
      "2023-12-06 14:17:33,073 : INFO : EPOCH 4: training on 99524 raw words (60154 effective words) took 0.2s, 248617 effective words/s\n",
      "2023-12-06 14:17:33,319 : INFO : EPOCH 5: training on 99524 raw words (60305 effective words) took 0.2s, 249894 effective words/s\n",
      "2023-12-06 14:17:33,565 : INFO : EPOCH 6: training on 99524 raw words (60487 effective words) took 0.2s, 249316 effective words/s\n",
      "2023-12-06 14:17:33,815 : INFO : EPOCH 7: training on 99524 raw words (60387 effective words) took 0.2s, 246132 effective words/s\n",
      "2023-12-06 14:17:34,059 : INFO : EPOCH 8: training on 99524 raw words (60365 effective words) took 0.2s, 252289 effective words/s\n",
      "2023-12-06 14:17:34,312 : INFO : EPOCH 9: training on 99524 raw words (60277 effective words) took 0.2s, 242069 effective words/s\n",
      "2023-12-06 14:17:34,562 : INFO : EPOCH 10: training on 99524 raw words (60139 effective words) took 0.2s, 245457 effective words/s\n",
      "2023-12-06 14:17:34,807 : INFO : EPOCH 11: training on 99524 raw words (60467 effective words) took 0.2s, 250654 effective words/s\n",
      "2023-12-06 14:17:35,059 : INFO : EPOCH 12: training on 99524 raw words (60389 effective words) took 0.2s, 244987 effective words/s\n",
      "2023-12-06 14:17:35,305 : INFO : EPOCH 13: training on 99524 raw words (60300 effective words) took 0.2s, 249505 effective words/s\n",
      "2023-12-06 14:17:35,553 : INFO : EPOCH 14: training on 99524 raw words (60258 effective words) took 0.2s, 247510 effective words/s\n",
      "2023-12-06 14:17:35,797 : INFO : EPOCH 15: training on 99524 raw words (60530 effective words) took 0.2s, 251317 effective words/s\n",
      "2023-12-06 14:17:36,046 : INFO : EPOCH 16: training on 99524 raw words (60359 effective words) took 0.2s, 247834 effective words/s\n",
      "2023-12-06 14:17:36,291 : INFO : EPOCH 17: training on 99524 raw words (60494 effective words) took 0.2s, 250613 effective words/s\n",
      "2023-12-06 14:17:36,543 : INFO : EPOCH 18: training on 99524 raw words (60445 effective words) took 0.2s, 244137 effective words/s\n",
      "2023-12-06 14:17:36,789 : INFO : EPOCH 19: training on 99524 raw words (60354 effective words) took 0.2s, 250315 effective words/s\n",
      "2023-12-06 14:17:37,037 : INFO : EPOCH 20: training on 99524 raw words (60444 effective words) took 0.2s, 248821 effective words/s\n",
      "2023-12-06 14:17:37,287 : INFO : EPOCH 21: training on 99524 raw words (60554 effective words) took 0.2s, 245905 effective words/s\n",
      "2023-12-06 14:17:37,533 : INFO : EPOCH 22: training on 99524 raw words (60361 effective words) took 0.2s, 250188 effective words/s\n",
      "2023-12-06 14:17:37,782 : INFO : EPOCH 23: training on 99524 raw words (60407 effective words) took 0.2s, 247115 effective words/s\n",
      "2023-12-06 14:17:38,028 : INFO : EPOCH 24: training on 99524 raw words (60338 effective words) took 0.2s, 248505 effective words/s\n",
      "2023-12-06 14:17:38,276 : INFO : EPOCH 25: training on 99524 raw words (60335 effective words) took 0.2s, 249003 effective words/s\n",
      "2023-12-06 14:17:38,525 : INFO : EPOCH 26: training on 99524 raw words (60391 effective words) took 0.2s, 246883 effective words/s\n",
      "2023-12-06 14:17:38,776 : INFO : EPOCH 27: training on 99524 raw words (60498 effective words) took 0.2s, 245044 effective words/s\n",
      "2023-12-06 14:17:39,027 : INFO : EPOCH 28: training on 99524 raw words (60458 effective words) took 0.2s, 244907 effective words/s\n",
      "2023-12-06 14:17:39,277 : INFO : EPOCH 29: training on 99524 raw words (60355 effective words) took 0.2s, 246534 effective words/s\n",
      "2023-12-06 14:17:39,524 : INFO : EPOCH 30: training on 99524 raw words (60636 effective words) took 0.2s, 249686 effective words/s\n",
      "2023-12-06 14:17:39,773 : INFO : EPOCH 31: training on 99524 raw words (60469 effective words) took 0.2s, 248128 effective words/s\n",
      "2023-12-06 14:17:40,023 : INFO : EPOCH 32: training on 99524 raw words (60437 effective words) took 0.2s, 246614 effective words/s\n",
      "2023-12-06 14:17:40,268 : INFO : EPOCH 33: training on 99524 raw words (60384 effective words) took 0.2s, 250699 effective words/s\n",
      "2023-12-06 14:17:40,514 : INFO : EPOCH 34: training on 99524 raw words (60395 effective words) took 0.2s, 250088 effective words/s\n",
      "2023-12-06 14:17:40,763 : INFO : EPOCH 35: training on 99524 raw words (60252 effective words) took 0.2s, 246674 effective words/s\n",
      "2023-12-06 14:17:41,012 : INFO : EPOCH 36: training on 99524 raw words (60400 effective words) took 0.2s, 245556 effective words/s\n",
      "2023-12-06 14:17:41,260 : INFO : EPOCH 37: training on 99524 raw words (60228 effective words) took 0.2s, 247634 effective words/s\n",
      "2023-12-06 14:17:41,503 : INFO : EPOCH 38: training on 99524 raw words (60418 effective words) took 0.2s, 253455 effective words/s\n",
      "2023-12-06 14:17:41,749 : INFO : EPOCH 39: training on 99524 raw words (60385 effective words) took 0.2s, 250305 effective words/s\n",
      "2023-12-06 14:17:41,993 : INFO : EPOCH 40: training on 99524 raw words (60297 effective words) took 0.2s, 251132 effective words/s\n",
      "2023-12-06 14:17:42,240 : INFO : EPOCH 41: training on 99524 raw words (60457 effective words) took 0.2s, 249955 effective words/s\n",
      "2023-12-06 14:17:42,486 : INFO : EPOCH 42: training on 99524 raw words (60457 effective words) took 0.2s, 249351 effective words/s\n",
      "2023-12-06 14:17:42,736 : INFO : EPOCH 43: training on 99524 raw words (60369 effective words) took 0.2s, 245878 effective words/s\n",
      "2023-12-06 14:17:42,985 : INFO : EPOCH 44: training on 99524 raw words (60271 effective words) took 0.2s, 245912 effective words/s\n",
      "2023-12-06 14:17:43,235 : INFO : EPOCH 45: training on 99524 raw words (60464 effective words) took 0.2s, 246226 effective words/s\n",
      "2023-12-06 14:17:43,484 : INFO : EPOCH 46: training on 99524 raw words (60313 effective words) took 0.2s, 246394 effective words/s\n",
      "2023-12-06 14:17:43,733 : INFO : EPOCH 47: training on 99524 raw words (60341 effective words) took 0.2s, 247406 effective words/s\n",
      "2023-12-06 14:17:43,981 : INFO : EPOCH 48: training on 99524 raw words (60268 effective words) took 0.2s, 247667 effective words/s\n",
      "2023-12-06 14:17:44,228 : INFO : EPOCH 49: training on 99524 raw words (60340 effective words) took 0.2s, 248356 effective words/s\n",
      "2023-12-06 14:17:44,229 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3019088 effective words) took 12.4s, 243547 effective words/s', 'datetime': '2023-12-06T14:17:44.229463', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:17:44,229 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:17:44.229463', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  5%|         | 26/486 [04:06<1:40:09, 13.06s/it]2023-12-06 14:17:48,355 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:17:48,356 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:17:48,381 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:17:48,382 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:17:48,388 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:17:48.388463', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:17:48,388 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:17:48.388463', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:17:48,395 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:17:48,396 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:17:48,396 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:17:48.396483', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:17:48,405 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:17:48,406 : INFO : resetting layer weights\n",
      "2023-12-06 14:17:48,408 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:17:48.408899', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:17:48,663 : INFO : EPOCH 0: training on 99524 raw words (60511 effective words) took 0.2s, 242649 effective words/s\n",
      "2023-12-06 14:17:48,916 : INFO : EPOCH 1: training on 99524 raw words (60483 effective words) took 0.2s, 242043 effective words/s\n",
      "2023-12-06 14:17:49,178 : INFO : EPOCH 2: training on 99524 raw words (60396 effective words) took 0.3s, 235315 effective words/s\n",
      "2023-12-06 14:17:49,433 : INFO : EPOCH 3: training on 99524 raw words (60360 effective words) took 0.3s, 241257 effective words/s\n",
      "2023-12-06 14:17:49,690 : INFO : EPOCH 4: training on 99524 raw words (60205 effective words) took 0.3s, 238386 effective words/s\n",
      "2023-12-06 14:17:49,943 : INFO : EPOCH 5: training on 99524 raw words (60365 effective words) took 0.2s, 242774 effective words/s\n",
      "2023-12-06 14:17:50,198 : INFO : EPOCH 6: training on 99524 raw words (60485 effective words) took 0.2s, 242209 effective words/s\n",
      "2023-12-06 14:17:50,452 : INFO : EPOCH 7: training on 99524 raw words (60465 effective words) took 0.2s, 241962 effective words/s\n",
      "2023-12-06 14:17:50,707 : INFO : EPOCH 8: training on 99524 raw words (60392 effective words) took 0.3s, 241404 effective words/s\n",
      "2023-12-06 14:17:50,960 : INFO : EPOCH 9: training on 99524 raw words (60353 effective words) took 0.2s, 241956 effective words/s\n",
      "2023-12-06 14:17:51,219 : INFO : EPOCH 10: training on 99524 raw words (60534 effective words) took 0.3s, 238001 effective words/s\n",
      "2023-12-06 14:17:51,470 : INFO : EPOCH 11: training on 99524 raw words (60361 effective words) took 0.2s, 245610 effective words/s\n",
      "2023-12-06 14:17:51,725 : INFO : EPOCH 12: training on 99524 raw words (60343 effective words) took 0.3s, 241056 effective words/s\n",
      "2023-12-06 14:17:51,981 : INFO : EPOCH 13: training on 99524 raw words (60248 effective words) took 0.3s, 239751 effective words/s\n",
      "2023-12-06 14:17:52,234 : INFO : EPOCH 14: training on 99524 raw words (60478 effective words) took 0.2s, 242818 effective words/s\n",
      "2023-12-06 14:17:52,490 : INFO : EPOCH 15: training on 99524 raw words (60567 effective words) took 0.3s, 241229 effective words/s\n",
      "2023-12-06 14:17:52,746 : INFO : EPOCH 16: training on 99524 raw words (60353 effective words) took 0.3s, 240550 effective words/s\n",
      "2023-12-06 14:17:52,998 : INFO : EPOCH 17: training on 99524 raw words (60502 effective words) took 0.2s, 243767 effective words/s\n",
      "2023-12-06 14:17:53,257 : INFO : EPOCH 18: training on 99524 raw words (60548 effective words) took 0.3s, 237329 effective words/s\n",
      "2023-12-06 14:17:53,512 : INFO : EPOCH 19: training on 99524 raw words (60393 effective words) took 0.3s, 240251 effective words/s\n",
      "2023-12-06 14:17:53,766 : INFO : EPOCH 20: training on 99524 raw words (60417 effective words) took 0.2s, 241988 effective words/s\n",
      "2023-12-06 14:17:54,019 : INFO : EPOCH 21: training on 99524 raw words (60504 effective words) took 0.2s, 243771 effective words/s\n",
      "2023-12-06 14:17:54,277 : INFO : EPOCH 22: training on 99524 raw words (60184 effective words) took 0.3s, 238231 effective words/s\n",
      "2023-12-06 14:17:54,529 : INFO : EPOCH 23: training on 99524 raw words (60286 effective words) took 0.2s, 243455 effective words/s\n",
      "2023-12-06 14:17:54,782 : INFO : EPOCH 24: training on 99524 raw words (60574 effective words) took 0.2s, 242754 effective words/s\n",
      "2023-12-06 14:17:55,045 : INFO : EPOCH 25: training on 99524 raw words (60383 effective words) took 0.3s, 235236 effective words/s\n",
      "2023-12-06 14:17:55,298 : INFO : EPOCH 26: training on 99524 raw words (60489 effective words) took 0.2s, 242956 effective words/s\n",
      "2023-12-06 14:17:55,554 : INFO : EPOCH 27: training on 99524 raw words (60495 effective words) took 0.3s, 241134 effective words/s\n",
      "2023-12-06 14:17:55,806 : INFO : EPOCH 28: training on 99524 raw words (60470 effective words) took 0.2s, 244174 effective words/s\n",
      "2023-12-06 14:17:56,061 : INFO : EPOCH 29: training on 99524 raw words (60352 effective words) took 0.3s, 240382 effective words/s\n",
      "2023-12-06 14:17:56,312 : INFO : EPOCH 30: training on 99524 raw words (60210 effective words) took 0.2s, 243658 effective words/s\n",
      "2023-12-06 14:17:56,567 : INFO : EPOCH 31: training on 99524 raw words (60325 effective words) took 0.3s, 241277 effective words/s\n",
      "2023-12-06 14:17:56,820 : INFO : EPOCH 32: training on 99524 raw words (60450 effective words) took 0.2s, 242404 effective words/s\n",
      "2023-12-06 14:17:57,074 : INFO : EPOCH 33: training on 99524 raw words (60277 effective words) took 0.2s, 241957 effective words/s\n",
      "2023-12-06 14:17:57,329 : INFO : EPOCH 34: training on 99524 raw words (60064 effective words) took 0.3s, 240105 effective words/s\n",
      "2023-12-06 14:17:57,586 : INFO : EPOCH 35: training on 99524 raw words (60240 effective words) took 0.3s, 237878 effective words/s\n",
      "2023-12-06 14:17:57,841 : INFO : EPOCH 36: training on 99524 raw words (60305 effective words) took 0.2s, 241871 effective words/s\n",
      "2023-12-06 14:17:58,096 : INFO : EPOCH 37: training on 99524 raw words (60440 effective words) took 0.3s, 240098 effective words/s\n",
      "2023-12-06 14:17:58,350 : INFO : EPOCH 38: training on 99524 raw words (60237 effective words) took 0.2s, 242429 effective words/s\n",
      "2023-12-06 14:17:58,602 : INFO : EPOCH 39: training on 99524 raw words (60371 effective words) took 0.2s, 244425 effective words/s\n",
      "2023-12-06 14:17:58,855 : INFO : EPOCH 40: training on 99524 raw words (60456 effective words) took 0.2s, 243370 effective words/s\n",
      "2023-12-06 14:17:59,110 : INFO : EPOCH 41: training on 99524 raw words (60374 effective words) took 0.3s, 240412 effective words/s\n",
      "2023-12-06 14:17:59,359 : INFO : EPOCH 42: training on 99524 raw words (60538 effective words) took 0.2s, 247370 effective words/s\n",
      "2023-12-06 14:17:59,612 : INFO : EPOCH 43: training on 99524 raw words (60428 effective words) took 0.2s, 242859 effective words/s\n",
      "2023-12-06 14:17:59,872 : INFO : EPOCH 44: training on 99524 raw words (60329 effective words) took 0.3s, 236608 effective words/s\n",
      "2023-12-06 14:18:00,126 : INFO : EPOCH 45: training on 99524 raw words (60306 effective words) took 0.2s, 241258 effective words/s\n",
      "2023-12-06 14:18:00,382 : INFO : EPOCH 46: training on 99524 raw words (60342 effective words) took 0.3s, 240844 effective words/s\n",
      "2023-12-06 14:18:00,635 : INFO : EPOCH 47: training on 99524 raw words (60305 effective words) took 0.2s, 241644 effective words/s\n",
      "2023-12-06 14:18:00,888 : INFO : EPOCH 48: training on 99524 raw words (60317 effective words) took 0.2s, 242107 effective words/s\n",
      "2023-12-06 14:18:01,142 : INFO : EPOCH 49: training on 99524 raw words (60505 effective words) took 0.2s, 243390 effective words/s\n",
      "2023-12-06 14:18:01,142 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3019315 effective words) took 12.7s, 237128 effective words/s', 'datetime': '2023-12-06T14:18:01.142270', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:18:01,143 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:18:01.143271', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  6%|         | 27/486 [04:24<1:49:29, 14.31s/it]2023-12-06 14:18:05,582 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:18:05,583 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:18:05,606 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:18:05,608 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:18:05,616 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:18:05.616320', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:18:05,616 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:18:05.616320', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:18:05,625 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:18:05,626 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:18:05,626 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:18:05.626910', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:18:05,645 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:18:05,647 : INFO : resetting layer weights\n",
      "2023-12-06 14:18:05,650 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:18:05.650157', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:18:05,891 : INFO : EPOCH 0: training on 99524 raw words (65720 effective words) took 0.2s, 278710 effective words/s\n",
      "2023-12-06 14:18:06,125 : INFO : EPOCH 1: training on 99524 raw words (65513 effective words) took 0.2s, 285335 effective words/s\n",
      "2023-12-06 14:18:06,359 : INFO : EPOCH 2: training on 99524 raw words (65528 effective words) took 0.2s, 286257 effective words/s\n",
      "2023-12-06 14:18:06,596 : INFO : EPOCH 3: training on 99524 raw words (65494 effective words) took 0.2s, 279705 effective words/s\n",
      "2023-12-06 14:18:06,834 : INFO : EPOCH 4: training on 99524 raw words (65379 effective words) took 0.2s, 280618 effective words/s\n",
      "2023-12-06 14:18:07,072 : INFO : EPOCH 5: training on 99524 raw words (65433 effective words) took 0.2s, 279782 effective words/s\n",
      "2023-12-06 14:18:07,314 : INFO : EPOCH 6: training on 99524 raw words (65555 effective words) took 0.2s, 276343 effective words/s\n",
      "2023-12-06 14:18:07,551 : INFO : EPOCH 7: training on 99524 raw words (65452 effective words) took 0.2s, 280865 effective words/s\n",
      "2023-12-06 14:18:07,788 : INFO : EPOCH 8: training on 99524 raw words (65543 effective words) took 0.2s, 281364 effective words/s\n",
      "2023-12-06 14:18:08,028 : INFO : EPOCH 9: training on 99524 raw words (65515 effective words) took 0.2s, 278751 effective words/s\n",
      "2023-12-06 14:18:08,029 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655132 effective words) took 2.4s, 275383 effective words/s', 'datetime': '2023-12-06T14:18:08.029997', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:18:08,030 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:18:08.030502', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  6%|         | 28/486 [04:29<1:28:31, 11.60s/it]2023-12-06 14:18:10,842 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:18:10,843 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:18:10,866 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:18:10,867 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:18:10,875 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:18:10.874081', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:18:10,875 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:18:10.875081', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:18:10,885 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:18:10,886 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:18:10,887 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:18:10.887591', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:18:10,906 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:18:10,907 : INFO : resetting layer weights\n",
      "2023-12-06 14:18:10,909 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:18:10.909591', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:18:11,205 : INFO : EPOCH 0: training on 99524 raw words (65571 effective words) took 0.3s, 260241 effective words/s\n",
      "2023-12-06 14:18:11,456 : INFO : EPOCH 1: training on 99524 raw words (65485 effective words) took 0.2s, 265113 effective words/s\n",
      "2023-12-06 14:18:11,713 : INFO : EPOCH 2: training on 99524 raw words (65530 effective words) took 0.3s, 260014 effective words/s\n",
      "2023-12-06 14:18:11,966 : INFO : EPOCH 3: training on 99524 raw words (65417 effective words) took 0.2s, 263971 effective words/s\n",
      "2023-12-06 14:18:12,222 : INFO : EPOCH 4: training on 99524 raw words (65448 effective words) took 0.3s, 258734 effective words/s\n",
      "2023-12-06 14:18:12,474 : INFO : EPOCH 5: training on 99524 raw words (65626 effective words) took 0.2s, 266257 effective words/s\n",
      "2023-12-06 14:18:12,730 : INFO : EPOCH 6: training on 99524 raw words (65616 effective words) took 0.3s, 260823 effective words/s\n",
      "2023-12-06 14:18:12,980 : INFO : EPOCH 7: training on 99524 raw words (65333 effective words) took 0.2s, 265710 effective words/s\n",
      "2023-12-06 14:18:13,231 : INFO : EPOCH 8: training on 99524 raw words (65546 effective words) took 0.2s, 266231 effective words/s\n",
      "2023-12-06 14:18:13,485 : INFO : EPOCH 9: training on 99524 raw words (65414 effective words) took 0.2s, 262328 effective words/s\n",
      "2023-12-06 14:18:13,486 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (654986 effective words) took 2.6s, 254601 effective words/s', 'datetime': '2023-12-06T14:18:13.486241', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:18:13,487 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:18:13.487240', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  6%|         | 29/486 [04:35<1:14:28,  9.78s/it]2023-12-06 14:18:16,372 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:18:16,372 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:18:16,392 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:18:16,394 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:18:16,403 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:18:16.403332', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:18:16,405 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:18:16.404332', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:18:16,417 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:18:16,418 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:18:16,419 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:18:16.419331', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:18:16,437 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:18:16,438 : INFO : resetting layer weights\n",
      "2023-12-06 14:18:16,439 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:18:16.439365', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:18:16,695 : INFO : EPOCH 0: training on 99524 raw words (65624 effective words) took 0.3s, 261860 effective words/s\n",
      "2023-12-06 14:18:16,950 : INFO : EPOCH 1: training on 99524 raw words (65584 effective words) took 0.2s, 263077 effective words/s\n",
      "2023-12-06 14:18:17,205 : INFO : EPOCH 2: training on 99524 raw words (65742 effective words) took 0.3s, 261706 effective words/s\n",
      "2023-12-06 14:18:17,468 : INFO : EPOCH 3: training on 99524 raw words (65588 effective words) took 0.3s, 253999 effective words/s\n",
      "2023-12-06 14:18:17,723 : INFO : EPOCH 4: training on 99524 raw words (65387 effective words) took 0.3s, 261396 effective words/s\n",
      "2023-12-06 14:18:17,976 : INFO : EPOCH 5: training on 99524 raw words (65538 effective words) took 0.2s, 262586 effective words/s\n",
      "2023-12-06 14:18:18,254 : INFO : EPOCH 6: training on 99524 raw words (65619 effective words) took 0.3s, 240730 effective words/s\n",
      "2023-12-06 14:18:18,512 : INFO : EPOCH 7: training on 99524 raw words (65428 effective words) took 0.3s, 258460 effective words/s\n",
      "2023-12-06 14:18:18,765 : INFO : EPOCH 8: training on 99524 raw words (65596 effective words) took 0.2s, 264165 effective words/s\n",
      "2023-12-06 14:18:19,016 : INFO : EPOCH 9: training on 99524 raw words (65546 effective words) took 0.2s, 265753 effective words/s\n",
      "2023-12-06 14:18:19,017 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655652 effective words) took 2.6s, 254466 effective words/s', 'datetime': '2023-12-06T14:18:19.017548', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:18:19,017 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:18:19.017548', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  6%|         | 30/486 [04:40<1:04:37,  8.50s/it]2023-12-06 14:18:21,905 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:18:21,905 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:18:21,925 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:18:21,926 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:18:21,933 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:18:21.933545', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:18:21,934 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:18:21.934546', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:18:21,943 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:18:21,944 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:18:21,945 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:18:21.945607', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:18:21,962 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:18:21,962 : INFO : resetting layer weights\n",
      "2023-12-06 14:18:21,964 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:18:21.964555', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:18:22,209 : INFO : EPOCH 0: training on 99524 raw words (65573 effective words) took 0.2s, 272326 effective words/s\n",
      "2023-12-06 14:18:22,447 : INFO : EPOCH 1: training on 99524 raw words (65671 effective words) took 0.2s, 280835 effective words/s\n",
      "2023-12-06 14:18:22,690 : INFO : EPOCH 2: training on 99524 raw words (65547 effective words) took 0.2s, 274560 effective words/s\n",
      "2023-12-06 14:18:22,929 : INFO : EPOCH 3: training on 99524 raw words (65666 effective words) took 0.2s, 278877 effective words/s\n",
      "2023-12-06 14:18:23,169 : INFO : EPOCH 4: training on 99524 raw words (65570 effective words) took 0.2s, 278433 effective words/s\n",
      "2023-12-06 14:18:23,409 : INFO : EPOCH 5: training on 99524 raw words (65557 effective words) took 0.2s, 278932 effective words/s\n",
      "2023-12-06 14:18:23,645 : INFO : EPOCH 6: training on 99524 raw words (65564 effective words) took 0.2s, 282060 effective words/s\n",
      "2023-12-06 14:18:23,882 : INFO : EPOCH 7: training on 99524 raw words (65564 effective words) took 0.2s, 281662 effective words/s\n",
      "2023-12-06 14:18:24,129 : INFO : EPOCH 8: training on 99524 raw words (65478 effective words) took 0.2s, 272256 effective words/s\n",
      "2023-12-06 14:18:24,373 : INFO : EPOCH 9: training on 99524 raw words (65475 effective words) took 0.2s, 273102 effective words/s\n",
      "2023-12-06 14:18:24,610 : INFO : EPOCH 10: training on 99524 raw words (65667 effective words) took 0.2s, 281168 effective words/s\n",
      "2023-12-06 14:18:24,850 : INFO : EPOCH 11: training on 99524 raw words (65530 effective words) took 0.2s, 278748 effective words/s\n",
      "2023-12-06 14:18:25,090 : INFO : EPOCH 12: training on 99524 raw words (65470 effective words) took 0.2s, 277627 effective words/s\n",
      "2023-12-06 14:18:25,328 : INFO : EPOCH 13: training on 99524 raw words (65582 effective words) took 0.2s, 280863 effective words/s\n",
      "2023-12-06 14:18:25,562 : INFO : EPOCH 14: training on 99524 raw words (65396 effective words) took 0.2s, 284714 effective words/s\n",
      "2023-12-06 14:18:25,801 : INFO : EPOCH 15: training on 99524 raw words (65507 effective words) took 0.2s, 278894 effective words/s\n",
      "2023-12-06 14:18:26,038 : INFO : EPOCH 16: training on 99524 raw words (65630 effective words) took 0.2s, 282775 effective words/s\n",
      "2023-12-06 14:18:26,276 : INFO : EPOCH 17: training on 99524 raw words (65520 effective words) took 0.2s, 280616 effective words/s\n",
      "2023-12-06 14:18:26,520 : INFO : EPOCH 18: training on 99524 raw words (65485 effective words) took 0.2s, 273790 effective words/s\n",
      "2023-12-06 14:18:26,760 : INFO : EPOCH 19: training on 99524 raw words (65598 effective words) took 0.2s, 278174 effective words/s\n",
      "2023-12-06 14:18:26,998 : INFO : EPOCH 20: training on 99524 raw words (65514 effective words) took 0.2s, 280963 effective words/s\n",
      "2023-12-06 14:18:27,261 : INFO : EPOCH 21: training on 99524 raw words (65481 effective words) took 0.3s, 254753 effective words/s\n",
      "2023-12-06 14:18:27,501 : INFO : EPOCH 22: training on 99524 raw words (65676 effective words) took 0.2s, 277865 effective words/s\n",
      "2023-12-06 14:18:27,748 : INFO : EPOCH 23: training on 99524 raw words (65600 effective words) took 0.2s, 270861 effective words/s\n",
      "2023-12-06 14:18:28,012 : INFO : EPOCH 24: training on 99524 raw words (65558 effective words) took 0.3s, 253892 effective words/s\n",
      "2023-12-06 14:18:28,256 : INFO : EPOCH 25: training on 99524 raw words (65277 effective words) took 0.2s, 272911 effective words/s\n",
      "2023-12-06 14:18:28,520 : INFO : EPOCH 26: training on 99524 raw words (65590 effective words) took 0.3s, 253325 effective words/s\n",
      "2023-12-06 14:18:28,760 : INFO : EPOCH 27: training on 99524 raw words (65529 effective words) took 0.2s, 279202 effective words/s\n",
      "2023-12-06 14:18:29,002 : INFO : EPOCH 28: training on 99524 raw words (65575 effective words) took 0.2s, 276365 effective words/s\n",
      "2023-12-06 14:18:29,242 : INFO : EPOCH 29: training on 99524 raw words (65620 effective words) took 0.2s, 278921 effective words/s\n",
      "2023-12-06 14:18:29,243 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1966470 effective words) took 7.3s, 270192 effective words/s', 'datetime': '2023-12-06T14:18:29.243772', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:18:29,243 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:18:29.243772', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  6%|         | 31/486 [04:51<1:09:30,  9.17s/it]2023-12-06 14:18:32,617 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:18:32,618 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:18:32,638 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:18:32,639 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:18:32,645 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:18:32.645370', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:18:32,645 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:18:32.645370', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:18:32,658 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:18:32,659 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:18:32,659 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:18:32.659459', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:18:32,671 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:18:32,672 : INFO : resetting layer weights\n",
      "2023-12-06 14:18:32,674 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:18:32.674083', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:18:32,934 : INFO : EPOCH 0: training on 99524 raw words (65557 effective words) took 0.3s, 255968 effective words/s\n",
      "2023-12-06 14:18:33,185 : INFO : EPOCH 1: training on 99524 raw words (65629 effective words) took 0.2s, 266667 effective words/s\n",
      "2023-12-06 14:18:33,438 : INFO : EPOCH 2: training on 99524 raw words (65434 effective words) took 0.2s, 263277 effective words/s\n",
      "2023-12-06 14:18:33,688 : INFO : EPOCH 3: training on 99524 raw words (65589 effective words) took 0.2s, 267375 effective words/s\n",
      "2023-12-06 14:18:33,941 : INFO : EPOCH 4: training on 99524 raw words (65518 effective words) took 0.2s, 264112 effective words/s\n",
      "2023-12-06 14:18:34,190 : INFO : EPOCH 5: training on 99524 raw words (65515 effective words) took 0.2s, 266998 effective words/s\n",
      "2023-12-06 14:18:34,442 : INFO : EPOCH 6: training on 99524 raw words (65381 effective words) took 0.2s, 264869 effective words/s\n",
      "2023-12-06 14:18:34,690 : INFO : EPOCH 7: training on 99524 raw words (65449 effective words) took 0.2s, 269625 effective words/s\n",
      "2023-12-06 14:18:34,950 : INFO : EPOCH 8: training on 99524 raw words (65354 effective words) took 0.3s, 255507 effective words/s\n",
      "2023-12-06 14:18:35,198 : INFO : EPOCH 9: training on 99524 raw words (65454 effective words) took 0.2s, 268795 effective words/s\n",
      "2023-12-06 14:18:35,453 : INFO : EPOCH 10: training on 99524 raw words (65436 effective words) took 0.3s, 260928 effective words/s\n",
      "2023-12-06 14:18:35,706 : INFO : EPOCH 11: training on 99524 raw words (65611 effective words) took 0.2s, 264952 effective words/s\n",
      "2023-12-06 14:18:35,957 : INFO : EPOCH 12: training on 99524 raw words (65501 effective words) took 0.2s, 264605 effective words/s\n",
      "2023-12-06 14:18:36,212 : INFO : EPOCH 13: training on 99524 raw words (65566 effective words) took 0.2s, 264416 effective words/s\n",
      "2023-12-06 14:18:36,461 : INFO : EPOCH 14: training on 99524 raw words (65603 effective words) took 0.2s, 267372 effective words/s\n",
      "2023-12-06 14:18:36,708 : INFO : EPOCH 15: training on 99524 raw words (65366 effective words) took 0.2s, 270231 effective words/s\n",
      "2023-12-06 14:18:36,962 : INFO : EPOCH 16: training on 99524 raw words (65644 effective words) took 0.3s, 262239 effective words/s\n",
      "2023-12-06 14:18:37,212 : INFO : EPOCH 17: training on 99524 raw words (65692 effective words) took 0.2s, 267923 effective words/s\n",
      "2023-12-06 14:18:37,461 : INFO : EPOCH 18: training on 99524 raw words (65620 effective words) took 0.2s, 268739 effective words/s\n",
      "2023-12-06 14:18:37,711 : INFO : EPOCH 19: training on 99524 raw words (65474 effective words) took 0.2s, 267282 effective words/s\n",
      "2023-12-06 14:18:37,960 : INFO : EPOCH 20: training on 99524 raw words (65490 effective words) took 0.2s, 267300 effective words/s\n",
      "2023-12-06 14:18:38,216 : INFO : EPOCH 21: training on 99524 raw words (65514 effective words) took 0.3s, 260783 effective words/s\n",
      "2023-12-06 14:18:38,468 : INFO : EPOCH 22: training on 99524 raw words (65422 effective words) took 0.2s, 264785 effective words/s\n",
      "2023-12-06 14:18:38,721 : INFO : EPOCH 23: training on 99524 raw words (65549 effective words) took 0.2s, 264353 effective words/s\n",
      "2023-12-06 14:18:38,978 : INFO : EPOCH 24: training on 99524 raw words (65646 effective words) took 0.3s, 260046 effective words/s\n",
      "2023-12-06 14:18:39,226 : INFO : EPOCH 25: training on 99524 raw words (65497 effective words) took 0.2s, 268605 effective words/s\n",
      "2023-12-06 14:18:39,476 : INFO : EPOCH 26: training on 99524 raw words (65508 effective words) took 0.2s, 266683 effective words/s\n",
      "2023-12-06 14:18:39,727 : INFO : EPOCH 27: training on 99524 raw words (65566 effective words) took 0.2s, 264837 effective words/s\n",
      "2023-12-06 14:18:39,980 : INFO : EPOCH 28: training on 99524 raw words (65505 effective words) took 0.2s, 264931 effective words/s\n",
      "2023-12-06 14:18:40,232 : INFO : EPOCH 29: training on 99524 raw words (65585 effective words) took 0.2s, 263443 effective words/s\n",
      "2023-12-06 14:18:40,234 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965675 effective words) took 7.6s, 260022 effective words/s', 'datetime': '2023-12-06T14:18:40.234999', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:18:40,234 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:18:40.234999', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  7%|         | 32/486 [05:02<1:13:55,  9.77s/it]2023-12-06 14:18:43,795 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:18:43,796 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:18:43,818 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:18:43,819 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:18:43,825 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:18:43.825988', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:18:43,825 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:18:43.825988', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:18:43,836 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:18:43,837 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:18:43,837 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:18:43.837990', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:18:43,853 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:18:43,854 : INFO : resetting layer weights\n",
      "2023-12-06 14:18:43,856 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:18:43.856387', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:18:44,119 : INFO : EPOCH 0: training on 99524 raw words (65497 effective words) took 0.3s, 254381 effective words/s\n",
      "2023-12-06 14:18:44,371 : INFO : EPOCH 1: training on 99524 raw words (65643 effective words) took 0.2s, 264629 effective words/s\n",
      "2023-12-06 14:18:44,623 : INFO : EPOCH 2: training on 99524 raw words (65719 effective words) took 0.2s, 266498 effective words/s\n",
      "2023-12-06 14:18:44,877 : INFO : EPOCH 3: training on 99524 raw words (65551 effective words) took 0.2s, 262258 effective words/s\n",
      "2023-12-06 14:18:45,130 : INFO : EPOCH 4: training on 99524 raw words (65404 effective words) took 0.2s, 263277 effective words/s\n",
      "2023-12-06 14:18:45,384 : INFO : EPOCH 5: training on 99524 raw words (65746 effective words) took 0.2s, 263752 effective words/s\n",
      "2023-12-06 14:18:45,640 : INFO : EPOCH 6: training on 99524 raw words (65520 effective words) took 0.3s, 260972 effective words/s\n",
      "2023-12-06 14:18:45,894 : INFO : EPOCH 7: training on 99524 raw words (65366 effective words) took 0.3s, 261382 effective words/s\n",
      "2023-12-06 14:18:46,149 : INFO : EPOCH 8: training on 99524 raw words (65491 effective words) took 0.3s, 261518 effective words/s\n",
      "2023-12-06 14:18:46,404 : INFO : EPOCH 9: training on 99524 raw words (65452 effective words) took 0.2s, 262368 effective words/s\n",
      "2023-12-06 14:18:46,656 : INFO : EPOCH 10: training on 99524 raw words (65580 effective words) took 0.2s, 263907 effective words/s\n",
      "2023-12-06 14:18:46,914 : INFO : EPOCH 11: training on 99524 raw words (65481 effective words) took 0.3s, 258745 effective words/s\n",
      "2023-12-06 14:18:47,166 : INFO : EPOCH 12: training on 99524 raw words (65366 effective words) took 0.2s, 263106 effective words/s\n",
      "2023-12-06 14:18:47,419 : INFO : EPOCH 13: training on 99524 raw words (65613 effective words) took 0.2s, 265324 effective words/s\n",
      "2023-12-06 14:18:47,675 : INFO : EPOCH 14: training on 99524 raw words (65438 effective words) took 0.3s, 259552 effective words/s\n",
      "2023-12-06 14:18:47,935 : INFO : EPOCH 15: training on 99524 raw words (65378 effective words) took 0.3s, 255033 effective words/s\n",
      "2023-12-06 14:18:48,192 : INFO : EPOCH 16: training on 99524 raw words (65576 effective words) took 0.3s, 261393 effective words/s\n",
      "2023-12-06 14:18:48,445 : INFO : EPOCH 17: training on 99524 raw words (65558 effective words) took 0.2s, 263591 effective words/s\n",
      "2023-12-06 14:18:48,695 : INFO : EPOCH 18: training on 99524 raw words (65317 effective words) took 0.2s, 265252 effective words/s\n",
      "2023-12-06 14:18:48,944 : INFO : EPOCH 19: training on 99524 raw words (65621 effective words) took 0.2s, 269051 effective words/s\n",
      "2023-12-06 14:18:49,201 : INFO : EPOCH 20: training on 99524 raw words (65415 effective words) took 0.3s, 258840 effective words/s\n",
      "2023-12-06 14:18:49,458 : INFO : EPOCH 21: training on 99524 raw words (65583 effective words) took 0.3s, 259619 effective words/s\n",
      "2023-12-06 14:18:49,709 : INFO : EPOCH 22: training on 99524 raw words (65679 effective words) took 0.2s, 265654 effective words/s\n",
      "2023-12-06 14:18:49,964 : INFO : EPOCH 23: training on 99524 raw words (65543 effective words) took 0.3s, 260573 effective words/s\n",
      "2023-12-06 14:18:50,223 : INFO : EPOCH 24: training on 99524 raw words (65453 effective words) took 0.3s, 257330 effective words/s\n",
      "2023-12-06 14:18:50,479 : INFO : EPOCH 25: training on 99524 raw words (65546 effective words) took 0.3s, 260112 effective words/s\n",
      "2023-12-06 14:18:50,735 : INFO : EPOCH 26: training on 99524 raw words (65408 effective words) took 0.3s, 259985 effective words/s\n",
      "2023-12-06 14:18:50,994 : INFO : EPOCH 27: training on 99524 raw words (65606 effective words) took 0.3s, 258954 effective words/s\n",
      "2023-12-06 14:18:51,255 : INFO : EPOCH 28: training on 99524 raw words (65315 effective words) took 0.3s, 253377 effective words/s\n",
      "2023-12-06 14:18:51,523 : INFO : EPOCH 29: training on 99524 raw words (65486 effective words) took 0.3s, 248920 effective words/s\n",
      "2023-12-06 14:18:51,524 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965351 effective words) took 7.7s, 256318 effective words/s', 'datetime': '2023-12-06T14:18:51.524746', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:18:51,524 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:18:51.524746', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  7%|         | 33/486 [05:13<1:17:39, 10.29s/it]2023-12-06 14:18:55,282 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:18:55,282 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:18:55,302 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:18:55,303 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:18:55,310 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:18:55.310235', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:18:55,311 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:18:55.311235', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:18:55,321 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:18:55,322 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:18:55,322 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:18:55.322235', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:18:55,339 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:18:55,343 : INFO : resetting layer weights\n",
      "2023-12-06 14:18:55,346 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:18:55.346787', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:18:55,592 : INFO : EPOCH 0: training on 99524 raw words (65349 effective words) took 0.2s, 275533 effective words/s\n",
      "2023-12-06 14:18:55,828 : INFO : EPOCH 1: training on 99524 raw words (65534 effective words) took 0.2s, 282707 effective words/s\n",
      "2023-12-06 14:18:56,064 : INFO : EPOCH 2: training on 99524 raw words (65541 effective words) took 0.2s, 283250 effective words/s\n",
      "2023-12-06 14:18:56,305 : INFO : EPOCH 3: training on 99524 raw words (65500 effective words) took 0.2s, 276649 effective words/s\n",
      "2023-12-06 14:18:56,545 : INFO : EPOCH 4: training on 99524 raw words (65649 effective words) took 0.2s, 279051 effective words/s\n",
      "2023-12-06 14:18:56,780 : INFO : EPOCH 5: training on 99524 raw words (65701 effective words) took 0.2s, 283873 effective words/s\n",
      "2023-12-06 14:18:57,018 : INFO : EPOCH 6: training on 99524 raw words (65342 effective words) took 0.2s, 280607 effective words/s\n",
      "2023-12-06 14:18:57,257 : INFO : EPOCH 7: training on 99524 raw words (65577 effective words) took 0.2s, 278813 effective words/s\n",
      "2023-12-06 14:18:57,497 : INFO : EPOCH 8: training on 99524 raw words (65422 effective words) took 0.2s, 277815 effective words/s\n",
      "2023-12-06 14:18:57,735 : INFO : EPOCH 9: training on 99524 raw words (65441 effective words) took 0.2s, 282029 effective words/s\n",
      "2023-12-06 14:18:57,969 : INFO : EPOCH 10: training on 99524 raw words (65655 effective words) took 0.2s, 286222 effective words/s\n",
      "2023-12-06 14:18:58,203 : INFO : EPOCH 11: training on 99524 raw words (65441 effective words) took 0.2s, 284853 effective words/s\n",
      "2023-12-06 14:18:58,439 : INFO : EPOCH 12: training on 99524 raw words (65579 effective words) took 0.2s, 282622 effective words/s\n",
      "2023-12-06 14:18:58,682 : INFO : EPOCH 13: training on 99524 raw words (65422 effective words) took 0.2s, 273394 effective words/s\n",
      "2023-12-06 14:18:58,927 : INFO : EPOCH 14: training on 99524 raw words (65586 effective words) took 0.2s, 272057 effective words/s\n",
      "2023-12-06 14:18:59,166 : INFO : EPOCH 15: training on 99524 raw words (65611 effective words) took 0.2s, 279661 effective words/s\n",
      "2023-12-06 14:18:59,402 : INFO : EPOCH 16: training on 99524 raw words (65506 effective words) took 0.2s, 284296 effective words/s\n",
      "2023-12-06 14:18:59,641 : INFO : EPOCH 17: training on 99524 raw words (65529 effective words) took 0.2s, 278201 effective words/s\n",
      "2023-12-06 14:18:59,887 : INFO : EPOCH 18: training on 99524 raw words (65542 effective words) took 0.2s, 271401 effective words/s\n",
      "2023-12-06 14:19:00,129 : INFO : EPOCH 19: training on 99524 raw words (65501 effective words) took 0.2s, 277075 effective words/s\n",
      "2023-12-06 14:19:00,366 : INFO : EPOCH 20: training on 99524 raw words (65448 effective words) took 0.2s, 280519 effective words/s\n",
      "2023-12-06 14:19:00,606 : INFO : EPOCH 21: training on 99524 raw words (65526 effective words) took 0.2s, 278623 effective words/s\n",
      "2023-12-06 14:19:00,850 : INFO : EPOCH 22: training on 99524 raw words (65700 effective words) took 0.2s, 273663 effective words/s\n",
      "2023-12-06 14:19:01,087 : INFO : EPOCH 23: training on 99524 raw words (65570 effective words) took 0.2s, 282668 effective words/s\n",
      "2023-12-06 14:19:01,325 : INFO : EPOCH 24: training on 99524 raw words (65356 effective words) took 0.2s, 278079 effective words/s\n",
      "2023-12-06 14:19:01,564 : INFO : EPOCH 25: training on 99524 raw words (65596 effective words) took 0.2s, 280986 effective words/s\n",
      "2023-12-06 14:19:01,806 : INFO : EPOCH 26: training on 99524 raw words (65412 effective words) took 0.2s, 274105 effective words/s\n",
      "2023-12-06 14:19:02,044 : INFO : EPOCH 27: training on 99524 raw words (65426 effective words) took 0.2s, 280706 effective words/s\n",
      "2023-12-06 14:19:02,281 : INFO : EPOCH 28: training on 99524 raw words (65645 effective words) took 0.2s, 280601 effective words/s\n",
      "2023-12-06 14:19:02,519 : INFO : EPOCH 29: training on 99524 raw words (65593 effective words) took 0.2s, 283047 effective words/s\n",
      "2023-12-06 14:19:02,764 : INFO : EPOCH 30: training on 99524 raw words (65630 effective words) took 0.2s, 271698 effective words/s\n",
      "2023-12-06 14:19:03,004 : INFO : EPOCH 31: training on 99524 raw words (65392 effective words) took 0.2s, 277949 effective words/s\n",
      "2023-12-06 14:19:03,244 : INFO : EPOCH 32: training on 99524 raw words (65521 effective words) took 0.2s, 278341 effective words/s\n",
      "2023-12-06 14:19:03,489 : INFO : EPOCH 33: training on 99524 raw words (65499 effective words) took 0.2s, 271151 effective words/s\n",
      "2023-12-06 14:19:03,731 : INFO : EPOCH 34: training on 99524 raw words (65629 effective words) took 0.2s, 277709 effective words/s\n",
      "2023-12-06 14:19:03,991 : INFO : EPOCH 35: training on 99524 raw words (65607 effective words) took 0.3s, 256094 effective words/s\n",
      "2023-12-06 14:19:04,237 : INFO : EPOCH 36: training on 99524 raw words (65506 effective words) took 0.2s, 272948 effective words/s\n",
      "2023-12-06 14:19:04,476 : INFO : EPOCH 37: training on 99524 raw words (65563 effective words) took 0.2s, 280443 effective words/s\n",
      "2023-12-06 14:19:04,741 : INFO : EPOCH 38: training on 99524 raw words (65516 effective words) took 0.3s, 251412 effective words/s\n",
      "2023-12-06 14:19:04,978 : INFO : EPOCH 39: training on 99524 raw words (65516 effective words) took 0.2s, 281279 effective words/s\n",
      "2023-12-06 14:19:05,225 : INFO : EPOCH 40: training on 99524 raw words (65528 effective words) took 0.2s, 270672 effective words/s\n",
      "2023-12-06 14:19:05,468 : INFO : EPOCH 41: training on 99524 raw words (65467 effective words) took 0.2s, 274433 effective words/s\n",
      "2023-12-06 14:19:05,733 : INFO : EPOCH 42: training on 99524 raw words (65610 effective words) took 0.3s, 251832 effective words/s\n",
      "2023-12-06 14:19:05,970 : INFO : EPOCH 43: training on 99524 raw words (65489 effective words) took 0.2s, 281763 effective words/s\n",
      "2023-12-06 14:19:06,228 : INFO : EPOCH 44: training on 99524 raw words (65661 effective words) took 0.3s, 257981 effective words/s\n",
      "2023-12-06 14:19:06,469 : INFO : EPOCH 45: training on 99524 raw words (65799 effective words) took 0.2s, 279344 effective words/s\n",
      "2023-12-06 14:19:06,716 : INFO : EPOCH 46: training on 99524 raw words (65638 effective words) took 0.2s, 270921 effective words/s\n",
      "2023-12-06 14:19:06,975 : INFO : EPOCH 47: training on 99524 raw words (65296 effective words) took 0.3s, 258378 effective words/s\n",
      "2023-12-06 14:19:07,219 : INFO : EPOCH 48: training on 99524 raw words (65600 effective words) took 0.2s, 275259 effective words/s\n",
      "2023-12-06 14:19:07,462 : INFO : EPOCH 49: training on 99524 raw words (65640 effective words) took 0.2s, 273719 effective words/s\n",
      "2023-12-06 14:19:07,465 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276807 effective words) took 12.1s, 270428 effective words/s', 'datetime': '2023-12-06T14:19:07.464197', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:19:07,465 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:19:07.465413', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  7%|         | 34/486 [05:30<1:30:44, 12.04s/it]2023-12-06 14:19:11,433 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:19:11,434 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:19:11,457 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:19:11,458 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:19:11,465 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:19:11.465713', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:19:11,466 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:19:11.466743', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:19:11,477 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:19:11,478 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:19:11,479 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:19:11.479955', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:19:11,492 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:19:11,493 : INFO : resetting layer weights\n",
      "2023-12-06 14:19:11,496 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:19:11.496385', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:19:11,764 : INFO : EPOCH 0: training on 99524 raw words (65501 effective words) took 0.3s, 258613 effective words/s\n",
      "2023-12-06 14:19:12,017 : INFO : EPOCH 1: training on 99524 raw words (65422 effective words) took 0.2s, 262734 effective words/s\n",
      "2023-12-06 14:19:12,267 : INFO : EPOCH 2: training on 99524 raw words (65323 effective words) took 0.2s, 266003 effective words/s\n",
      "2023-12-06 14:19:12,520 : INFO : EPOCH 3: training on 99524 raw words (65564 effective words) took 0.2s, 263727 effective words/s\n",
      "2023-12-06 14:19:12,768 : INFO : EPOCH 4: training on 99524 raw words (65414 effective words) took 0.2s, 268824 effective words/s\n",
      "2023-12-06 14:19:13,018 : INFO : EPOCH 5: training on 99524 raw words (65457 effective words) took 0.2s, 266361 effective words/s\n",
      "2023-12-06 14:19:13,274 : INFO : EPOCH 6: training on 99524 raw words (65581 effective words) took 0.3s, 262224 effective words/s\n",
      "2023-12-06 14:19:13,526 : INFO : EPOCH 7: training on 99524 raw words (65575 effective words) took 0.2s, 264109 effective words/s\n",
      "2023-12-06 14:19:13,775 : INFO : EPOCH 8: training on 99524 raw words (65707 effective words) took 0.2s, 268613 effective words/s\n",
      "2023-12-06 14:19:14,028 : INFO : EPOCH 9: training on 99524 raw words (65414 effective words) took 0.2s, 264487 effective words/s\n",
      "2023-12-06 14:19:14,281 : INFO : EPOCH 10: training on 99524 raw words (65474 effective words) took 0.3s, 261496 effective words/s\n",
      "2023-12-06 14:19:14,534 : INFO : EPOCH 11: training on 99524 raw words (65493 effective words) took 0.2s, 264198 effective words/s\n",
      "2023-12-06 14:19:14,789 : INFO : EPOCH 12: training on 99524 raw words (65537 effective words) took 0.3s, 262098 effective words/s\n",
      "2023-12-06 14:19:15,043 : INFO : EPOCH 13: training on 99524 raw words (65608 effective words) took 0.2s, 262718 effective words/s\n",
      "2023-12-06 14:19:15,301 : INFO : EPOCH 14: training on 99524 raw words (65489 effective words) took 0.3s, 257744 effective words/s\n",
      "2023-12-06 14:19:15,555 : INFO : EPOCH 15: training on 99524 raw words (65572 effective words) took 0.2s, 263890 effective words/s\n",
      "2023-12-06 14:19:15,813 : INFO : EPOCH 16: training on 99524 raw words (65279 effective words) took 0.3s, 257408 effective words/s\n",
      "2023-12-06 14:19:16,081 : INFO : EPOCH 17: training on 99524 raw words (65331 effective words) took 0.3s, 248787 effective words/s\n",
      "2023-12-06 14:19:16,335 : INFO : EPOCH 18: training on 99524 raw words (65541 effective words) took 0.3s, 261908 effective words/s\n",
      "2023-12-06 14:19:16,588 : INFO : EPOCH 19: training on 99524 raw words (65516 effective words) took 0.2s, 264349 effective words/s\n",
      "2023-12-06 14:19:16,838 : INFO : EPOCH 20: training on 99524 raw words (65424 effective words) took 0.2s, 267259 effective words/s\n",
      "2023-12-06 14:19:17,084 : INFO : EPOCH 21: training on 99524 raw words (65573 effective words) took 0.2s, 270860 effective words/s\n",
      "2023-12-06 14:19:17,334 : INFO : EPOCH 22: training on 99524 raw words (65614 effective words) took 0.2s, 266230 effective words/s\n",
      "2023-12-06 14:19:17,595 : INFO : EPOCH 23: training on 99524 raw words (65658 effective words) took 0.3s, 256729 effective words/s\n",
      "2023-12-06 14:19:17,846 : INFO : EPOCH 24: training on 99524 raw words (65493 effective words) took 0.2s, 266162 effective words/s\n",
      "2023-12-06 14:19:18,094 : INFO : EPOCH 25: training on 99524 raw words (65470 effective words) took 0.2s, 267117 effective words/s\n",
      "2023-12-06 14:19:18,345 : INFO : EPOCH 26: training on 99524 raw words (65509 effective words) took 0.2s, 266496 effective words/s\n",
      "2023-12-06 14:19:18,595 : INFO : EPOCH 27: training on 99524 raw words (65441 effective words) took 0.2s, 265295 effective words/s\n",
      "2023-12-06 14:19:18,846 : INFO : EPOCH 28: training on 99524 raw words (65341 effective words) took 0.2s, 266598 effective words/s\n",
      "2023-12-06 14:19:19,096 : INFO : EPOCH 29: training on 99524 raw words (65447 effective words) took 0.2s, 267196 effective words/s\n",
      "2023-12-06 14:19:19,348 : INFO : EPOCH 30: training on 99524 raw words (65619 effective words) took 0.2s, 264443 effective words/s\n",
      "2023-12-06 14:19:19,602 : INFO : EPOCH 31: training on 99524 raw words (65554 effective words) took 0.2s, 263318 effective words/s\n",
      "2023-12-06 14:19:19,851 : INFO : EPOCH 32: training on 99524 raw words (65437 effective words) took 0.2s, 267632 effective words/s\n",
      "2023-12-06 14:19:20,102 : INFO : EPOCH 33: training on 99524 raw words (65538 effective words) took 0.2s, 266416 effective words/s\n",
      "2023-12-06 14:19:20,348 : INFO : EPOCH 34: training on 99524 raw words (65436 effective words) took 0.2s, 270012 effective words/s\n",
      "2023-12-06 14:19:20,599 : INFO : EPOCH 35: training on 99524 raw words (65597 effective words) took 0.2s, 266707 effective words/s\n",
      "2023-12-06 14:19:20,849 : INFO : EPOCH 36: training on 99524 raw words (65545 effective words) took 0.2s, 267334 effective words/s\n",
      "2023-12-06 14:19:21,106 : INFO : EPOCH 37: training on 99524 raw words (65522 effective words) took 0.3s, 260654 effective words/s\n",
      "2023-12-06 14:19:21,354 : INFO : EPOCH 38: training on 99524 raw words (65563 effective words) took 0.2s, 267887 effective words/s\n",
      "2023-12-06 14:19:21,610 : INFO : EPOCH 39: training on 99524 raw words (65472 effective words) took 0.3s, 260355 effective words/s\n",
      "2023-12-06 14:19:21,862 : INFO : EPOCH 40: training on 99524 raw words (65436 effective words) took 0.2s, 264062 effective words/s\n",
      "2023-12-06 14:19:22,110 : INFO : EPOCH 41: training on 99524 raw words (65480 effective words) took 0.2s, 268042 effective words/s\n",
      "2023-12-06 14:19:22,361 : INFO : EPOCH 42: training on 99524 raw words (65361 effective words) took 0.2s, 265873 effective words/s\n",
      "2023-12-06 14:19:22,612 : INFO : EPOCH 43: training on 99524 raw words (65567 effective words) took 0.2s, 266104 effective words/s\n",
      "2023-12-06 14:19:22,863 : INFO : EPOCH 44: training on 99524 raw words (65629 effective words) took 0.2s, 266228 effective words/s\n",
      "2023-12-06 14:19:23,116 : INFO : EPOCH 45: training on 99524 raw words (65560 effective words) took 0.2s, 264804 effective words/s\n",
      "2023-12-06 14:19:23,369 : INFO : EPOCH 46: training on 99524 raw words (65562 effective words) took 0.2s, 263432 effective words/s\n",
      "2023-12-06 14:19:23,627 : INFO : EPOCH 47: training on 99524 raw words (65618 effective words) took 0.3s, 259012 effective words/s\n",
      "2023-12-06 14:19:23,882 : INFO : EPOCH 48: training on 99524 raw words (65687 effective words) took 0.3s, 262145 effective words/s\n",
      "2023-12-06 14:19:24,136 : INFO : EPOCH 49: training on 99524 raw words (65585 effective words) took 0.2s, 263973 effective words/s\n",
      "2023-12-06 14:19:24,136 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3275536 effective words) took 12.6s, 259153 effective words/s', 'datetime': '2023-12-06T14:19:24.136165', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:19:24,137 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:19:24.137165', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  7%|         | 35/486 [05:47<1:41:40, 13.53s/it]2023-12-06 14:19:28,420 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:19:28,420 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:19:28,452 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:19:28,453 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:19:28,462 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:19:28.462852', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:19:28,463 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:19:28.463855', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:19:28,475 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:19:28,476 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:19:28,477 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:19:28.477772', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:19:28,495 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:19:28,495 : INFO : resetting layer weights\n",
      "2023-12-06 14:19:28,498 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:19:28.498227', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:19:28,787 : INFO : EPOCH 0: training on 99524 raw words (65751 effective words) took 0.3s, 234046 effective words/s\n",
      "2023-12-06 14:19:29,041 : INFO : EPOCH 1: training on 99524 raw words (65450 effective words) took 0.3s, 260941 effective words/s\n",
      "2023-12-06 14:19:29,310 : INFO : EPOCH 2: training on 99524 raw words (65600 effective words) took 0.3s, 248878 effective words/s\n",
      "2023-12-06 14:19:29,561 : INFO : EPOCH 3: training on 99524 raw words (65492 effective words) took 0.2s, 266728 effective words/s\n",
      "2023-12-06 14:19:29,829 : INFO : EPOCH 4: training on 99524 raw words (65591 effective words) took 0.3s, 248737 effective words/s\n",
      "2023-12-06 14:19:30,083 : INFO : EPOCH 5: training on 99524 raw words (65641 effective words) took 0.2s, 262753 effective words/s\n",
      "2023-12-06 14:19:30,334 : INFO : EPOCH 6: training on 99524 raw words (65618 effective words) took 0.2s, 265373 effective words/s\n",
      "2023-12-06 14:19:30,593 : INFO : EPOCH 7: training on 99524 raw words (65416 effective words) took 0.3s, 257657 effective words/s\n",
      "2023-12-06 14:19:30,860 : INFO : EPOCH 8: training on 99524 raw words (65617 effective words) took 0.3s, 250196 effective words/s\n",
      "2023-12-06 14:19:31,117 : INFO : EPOCH 9: training on 99524 raw words (65453 effective words) took 0.3s, 260216 effective words/s\n",
      "2023-12-06 14:19:31,370 : INFO : EPOCH 10: training on 99524 raw words (65543 effective words) took 0.2s, 264059 effective words/s\n",
      "2023-12-06 14:19:31,624 : INFO : EPOCH 11: training on 99524 raw words (65307 effective words) took 0.2s, 261746 effective words/s\n",
      "2023-12-06 14:19:31,883 : INFO : EPOCH 12: training on 99524 raw words (65406 effective words) took 0.3s, 257048 effective words/s\n",
      "2023-12-06 14:19:32,138 : INFO : EPOCH 13: training on 99524 raw words (65645 effective words) took 0.3s, 261934 effective words/s\n",
      "2023-12-06 14:19:32,391 : INFO : EPOCH 14: training on 99524 raw words (65702 effective words) took 0.2s, 265178 effective words/s\n",
      "2023-12-06 14:19:32,652 : INFO : EPOCH 15: training on 99524 raw words (65708 effective words) took 0.3s, 256670 effective words/s\n",
      "2023-12-06 14:19:32,905 : INFO : EPOCH 16: training on 99524 raw words (65550 effective words) took 0.2s, 262988 effective words/s\n",
      "2023-12-06 14:19:33,225 : INFO : EPOCH 17: training on 99524 raw words (65561 effective words) took 0.3s, 208799 effective words/s\n",
      "2023-12-06 14:19:33,494 : INFO : EPOCH 18: training on 99524 raw words (65662 effective words) took 0.3s, 254287 effective words/s\n",
      "2023-12-06 14:19:33,747 : INFO : EPOCH 19: training on 99524 raw words (65568 effective words) took 0.2s, 264695 effective words/s\n",
      "2023-12-06 14:19:34,019 : INFO : EPOCH 20: training on 99524 raw words (65678 effective words) took 0.3s, 245650 effective words/s\n",
      "2023-12-06 14:19:34,294 : INFO : EPOCH 21: training on 99524 raw words (65583 effective words) took 0.3s, 242691 effective words/s\n",
      "2023-12-06 14:19:34,557 : INFO : EPOCH 22: training on 99524 raw words (65462 effective words) took 0.3s, 253572 effective words/s\n",
      "2023-12-06 14:19:34,814 : INFO : EPOCH 23: training on 99524 raw words (65574 effective words) took 0.3s, 259758 effective words/s\n",
      "2023-12-06 14:19:35,070 : INFO : EPOCH 24: training on 99524 raw words (65443 effective words) took 0.3s, 260086 effective words/s\n",
      "2023-12-06 14:19:35,328 : INFO : EPOCH 25: training on 99524 raw words (65478 effective words) took 0.3s, 258405 effective words/s\n",
      "2023-12-06 14:19:35,583 : INFO : EPOCH 26: training on 99524 raw words (65546 effective words) took 0.3s, 261224 effective words/s\n",
      "2023-12-06 14:19:35,837 : INFO : EPOCH 27: training on 99524 raw words (65484 effective words) took 0.2s, 262455 effective words/s\n",
      "2023-12-06 14:19:36,097 : INFO : EPOCH 28: training on 99524 raw words (65513 effective words) took 0.3s, 256926 effective words/s\n",
      "2023-12-06 14:19:36,354 : INFO : EPOCH 29: training on 99524 raw words (65570 effective words) took 0.3s, 258300 effective words/s\n",
      "2023-12-06 14:19:36,607 : INFO : EPOCH 30: training on 99524 raw words (65476 effective words) took 0.2s, 264436 effective words/s\n",
      "2023-12-06 14:19:36,860 : INFO : EPOCH 31: training on 99524 raw words (65368 effective words) took 0.2s, 263290 effective words/s\n",
      "2023-12-06 14:19:37,113 : INFO : EPOCH 32: training on 99524 raw words (65464 effective words) took 0.2s, 263718 effective words/s\n",
      "2023-12-06 14:19:37,364 : INFO : EPOCH 33: training on 99524 raw words (65582 effective words) took 0.2s, 265932 effective words/s\n",
      "2023-12-06 14:19:37,619 : INFO : EPOCH 34: training on 99524 raw words (65624 effective words) took 0.3s, 261513 effective words/s\n",
      "2023-12-06 14:19:37,872 : INFO : EPOCH 35: training on 99524 raw words (65548 effective words) took 0.2s, 263283 effective words/s\n",
      "2023-12-06 14:19:38,149 : INFO : EPOCH 36: training on 99524 raw words (65395 effective words) took 0.3s, 240593 effective words/s\n",
      "2023-12-06 14:19:38,416 : INFO : EPOCH 37: training on 99524 raw words (65382 effective words) took 0.3s, 249329 effective words/s\n",
      "2023-12-06 14:19:38,673 : INFO : EPOCH 38: training on 99524 raw words (65584 effective words) took 0.3s, 258538 effective words/s\n",
      "2023-12-06 14:19:38,982 : INFO : EPOCH 39: training on 99524 raw words (65452 effective words) took 0.3s, 216376 effective words/s\n",
      "2023-12-06 14:19:39,247 : INFO : EPOCH 40: training on 99524 raw words (65511 effective words) took 0.3s, 253091 effective words/s\n",
      "2023-12-06 14:19:39,505 : INFO : EPOCH 41: training on 99524 raw words (65619 effective words) took 0.3s, 258429 effective words/s\n",
      "2023-12-06 14:19:39,769 : INFO : EPOCH 42: training on 99524 raw words (65538 effective words) took 0.3s, 253954 effective words/s\n",
      "2023-12-06 14:19:40,025 : INFO : EPOCH 43: training on 99524 raw words (65474 effective words) took 0.3s, 260272 effective words/s\n",
      "2023-12-06 14:19:40,282 : INFO : EPOCH 44: training on 99524 raw words (65623 effective words) took 0.3s, 260041 effective words/s\n",
      "2023-12-06 14:19:40,536 : INFO : EPOCH 45: training on 99524 raw words (65429 effective words) took 0.3s, 260755 effective words/s\n",
      "2023-12-06 14:19:40,788 : INFO : EPOCH 46: training on 99524 raw words (65374 effective words) took 0.2s, 265392 effective words/s\n",
      "2023-12-06 14:19:41,041 : INFO : EPOCH 47: training on 99524 raw words (65445 effective words) took 0.2s, 263543 effective words/s\n",
      "2023-12-06 14:19:41,297 : INFO : EPOCH 48: training on 99524 raw words (65467 effective words) took 0.3s, 260726 effective words/s\n",
      "2023-12-06 14:19:41,550 : INFO : EPOCH 49: training on 99524 raw words (65588 effective words) took 0.2s, 263063 effective words/s\n",
      "2023-12-06 14:19:41,551 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276555 effective words) took 13.1s, 251048 effective words/s', 'datetime': '2023-12-06T14:19:41.551978', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:19:41,551 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:19:41.551978', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  7%|         | 36/486 [06:04<1:50:39, 14.75s/it]2023-12-06 14:19:46,036 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:19:46,037 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:19:46,060 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:19:46,061 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:19:46,065 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:19:46.065793', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:19:46,066 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:19:46.066798', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:19:46,074 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:19:46,074 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:19:46,075 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:19:46.075436', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:19:46,084 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:19:46,085 : INFO : resetting layer weights\n",
      "2023-12-06 14:19:46,087 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:19:46.087756', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:19:46,321 : INFO : EPOCH 0: training on 99524 raw words (62683 effective words) took 0.2s, 272709 effective words/s\n",
      "2023-12-06 14:19:46,558 : INFO : EPOCH 1: training on 99524 raw words (62800 effective words) took 0.2s, 270379 effective words/s\n",
      "2023-12-06 14:19:46,791 : INFO : EPOCH 2: training on 99524 raw words (62779 effective words) took 0.2s, 275112 effective words/s\n",
      "2023-12-06 14:19:47,025 : INFO : EPOCH 3: training on 99524 raw words (62783 effective words) took 0.2s, 272780 effective words/s\n",
      "2023-12-06 14:19:47,275 : INFO : EPOCH 4: training on 99524 raw words (62770 effective words) took 0.2s, 255891 effective words/s\n",
      "2023-12-06 14:19:47,511 : INFO : EPOCH 5: training on 99524 raw words (62964 effective words) took 0.2s, 271053 effective words/s\n",
      "2023-12-06 14:19:47,746 : INFO : EPOCH 6: training on 99524 raw words (62724 effective words) took 0.2s, 271997 effective words/s\n",
      "2023-12-06 14:19:47,975 : INFO : EPOCH 7: training on 99524 raw words (62572 effective words) took 0.2s, 277989 effective words/s\n",
      "2023-12-06 14:19:48,210 : INFO : EPOCH 8: training on 99524 raw words (62767 effective words) took 0.2s, 272539 effective words/s\n",
      "2023-12-06 14:19:48,446 : INFO : EPOCH 9: training on 99524 raw words (62660 effective words) took 0.2s, 271043 effective words/s\n",
      "2023-12-06 14:19:48,447 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627502 effective words) took 2.4s, 266024 effective words/s', 'datetime': '2023-12-06T14:19:48.447375', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:19:48,447 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:19:48.447375', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  8%|         | 37/486 [06:09<1:29:02, 11.90s/it]2023-12-06 14:19:51,273 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:19:51,274 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:19:51,298 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:19:51,299 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:19:51,306 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:19:51.306850', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:19:51,307 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:19:51.307850', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:19:51,314 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:19:51,315 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:19:51,315 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:19:51.315868', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:19:51,328 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:19:51,337 : INFO : resetting layer weights\n",
      "2023-12-06 14:19:51,341 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:19:51.341676', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:19:51,596 : INFO : EPOCH 0: training on 99524 raw words (62633 effective words) took 0.2s, 251627 effective words/s\n",
      "2023-12-06 14:19:51,850 : INFO : EPOCH 1: training on 99524 raw words (62645 effective words) took 0.2s, 251165 effective words/s\n",
      "2023-12-06 14:19:52,096 : INFO : EPOCH 2: training on 99524 raw words (62818 effective words) took 0.2s, 259752 effective words/s\n",
      "2023-12-06 14:19:52,344 : INFO : EPOCH 3: training on 99524 raw words (62747 effective words) took 0.2s, 257999 effective words/s\n",
      "2023-12-06 14:19:52,591 : INFO : EPOCH 4: training on 99524 raw words (62798 effective words) took 0.2s, 258256 effective words/s\n",
      "2023-12-06 14:19:52,839 : INFO : EPOCH 5: training on 99524 raw words (62669 effective words) took 0.2s, 258138 effective words/s\n",
      "2023-12-06 14:19:53,089 : INFO : EPOCH 6: training on 99524 raw words (62606 effective words) took 0.2s, 254558 effective words/s\n",
      "2023-12-06 14:19:53,343 : INFO : EPOCH 7: training on 99524 raw words (62616 effective words) took 0.3s, 250091 effective words/s\n",
      "2023-12-06 14:19:53,588 : INFO : EPOCH 8: training on 99524 raw words (62668 effective words) took 0.2s, 259818 effective words/s\n",
      "2023-12-06 14:19:53,841 : INFO : EPOCH 9: training on 99524 raw words (62810 effective words) took 0.2s, 253379 effective words/s\n",
      "2023-12-06 14:19:53,842 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627010 effective words) took 2.5s, 250749 effective words/s', 'datetime': '2023-12-06T14:19:53.842819', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:19:53,843 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:19:53.843843', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  8%|         | 38/486 [06:15<1:14:25,  9.97s/it]2023-12-06 14:19:56,734 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:19:56,735 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:19:56,757 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:19:56,758 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:19:56,764 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:19:56.764911', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:19:56,765 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:19:56.765907', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:19:56,773 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:19:56,774 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:19:56,774 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:19:56.774906', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:19:56,786 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:19:56,787 : INFO : resetting layer weights\n",
      "2023-12-06 14:19:56,789 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:19:56.789059', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:19:57,051 : INFO : EPOCH 0: training on 99524 raw words (62618 effective words) took 0.2s, 251093 effective words/s\n",
      "2023-12-06 14:19:57,301 : INFO : EPOCH 1: training on 99524 raw words (62795 effective words) took 0.2s, 255465 effective words/s\n",
      "2023-12-06 14:19:57,550 : INFO : EPOCH 2: training on 99524 raw words (62713 effective words) took 0.2s, 256456 effective words/s\n",
      "2023-12-06 14:19:57,802 : INFO : EPOCH 3: training on 99524 raw words (62732 effective words) took 0.2s, 253363 effective words/s\n",
      "2023-12-06 14:19:58,055 : INFO : EPOCH 4: training on 99524 raw words (62782 effective words) took 0.2s, 251694 effective words/s\n",
      "2023-12-06 14:19:58,303 : INFO : EPOCH 5: training on 99524 raw words (62619 effective words) took 0.2s, 256086 effective words/s\n",
      "2023-12-06 14:19:58,554 : INFO : EPOCH 6: training on 99524 raw words (62688 effective words) took 0.2s, 254327 effective words/s\n",
      "2023-12-06 14:19:58,806 : INFO : EPOCH 7: training on 99524 raw words (62486 effective words) took 0.2s, 252059 effective words/s\n",
      "2023-12-06 14:19:59,059 : INFO : EPOCH 8: training on 99524 raw words (62682 effective words) took 0.2s, 251818 effective words/s\n",
      "2023-12-06 14:19:59,313 : INFO : EPOCH 9: training on 99524 raw words (62560 effective words) took 0.2s, 251498 effective words/s\n",
      "2023-12-06 14:19:59,314 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (626675 effective words) took 2.5s, 248347 effective words/s', 'datetime': '2023-12-06T14:19:59.314037', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:19:59,314 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:19:59.314037', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  8%|         | 39/486 [06:20<1:04:20,  8.64s/it]2023-12-06 14:20:02,266 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:20:02,266 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:20:02,289 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:20:02,289 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:20:02,294 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:20:02.294370', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:20:02,295 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:20:02.295376', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:20:02,302 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:20:02,303 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:20:02,303 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:20:02.303885', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:20:02,313 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:20:02,315 : INFO : resetting layer weights\n",
      "2023-12-06 14:20:02,317 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:20:02.317498', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:20:02,551 : INFO : EPOCH 0: training on 99524 raw words (62791 effective words) took 0.2s, 273120 effective words/s\n",
      "2023-12-06 14:20:02,782 : INFO : EPOCH 1: training on 99524 raw words (62735 effective words) took 0.2s, 278043 effective words/s\n",
      "2023-12-06 14:20:03,017 : INFO : EPOCH 2: training on 99524 raw words (62686 effective words) took 0.2s, 270370 effective words/s\n",
      "2023-12-06 14:20:03,251 : INFO : EPOCH 3: training on 99524 raw words (62875 effective words) took 0.2s, 273402 effective words/s\n",
      "2023-12-06 14:20:03,485 : INFO : EPOCH 4: training on 99524 raw words (62709 effective words) took 0.2s, 273700 effective words/s\n",
      "2023-12-06 14:20:03,721 : INFO : EPOCH 5: training on 99524 raw words (62780 effective words) took 0.2s, 270523 effective words/s\n",
      "2023-12-06 14:20:03,959 : INFO : EPOCH 6: training on 99524 raw words (62585 effective words) took 0.2s, 268472 effective words/s\n",
      "2023-12-06 14:20:04,196 : INFO : EPOCH 7: training on 99524 raw words (62705 effective words) took 0.2s, 270021 effective words/s\n",
      "2023-12-06 14:20:04,436 : INFO : EPOCH 8: training on 99524 raw words (62665 effective words) took 0.2s, 264537 effective words/s\n",
      "2023-12-06 14:20:04,705 : INFO : EPOCH 9: training on 99524 raw words (62633 effective words) took 0.3s, 237797 effective words/s\n",
      "2023-12-06 14:20:04,941 : INFO : EPOCH 10: training on 99524 raw words (62728 effective words) took 0.2s, 271258 effective words/s\n",
      "2023-12-06 14:20:05,178 : INFO : EPOCH 11: training on 99524 raw words (62587 effective words) took 0.2s, 268871 effective words/s\n",
      "2023-12-06 14:20:05,417 : INFO : EPOCH 12: training on 99524 raw words (62718 effective words) took 0.2s, 267650 effective words/s\n",
      "2023-12-06 14:20:05,654 : INFO : EPOCH 13: training on 99524 raw words (62720 effective words) took 0.2s, 269202 effective words/s\n",
      "2023-12-06 14:20:05,890 : INFO : EPOCH 14: training on 99524 raw words (62912 effective words) took 0.2s, 272494 effective words/s\n",
      "2023-12-06 14:20:06,125 : INFO : EPOCH 15: training on 99524 raw words (62812 effective words) took 0.2s, 274411 effective words/s\n",
      "2023-12-06 14:20:06,363 : INFO : EPOCH 16: training on 99524 raw words (62831 effective words) took 0.2s, 268868 effective words/s\n",
      "2023-12-06 14:20:06,601 : INFO : EPOCH 17: training on 99524 raw words (62622 effective words) took 0.2s, 267181 effective words/s\n",
      "2023-12-06 14:20:06,837 : INFO : EPOCH 18: training on 99524 raw words (62550 effective words) took 0.2s, 270879 effective words/s\n",
      "2023-12-06 14:20:07,068 : INFO : EPOCH 19: training on 99524 raw words (62700 effective words) took 0.2s, 276751 effective words/s\n",
      "2023-12-06 14:20:07,300 : INFO : EPOCH 20: training on 99524 raw words (62749 effective words) took 0.2s, 275593 effective words/s\n",
      "2023-12-06 14:20:07,535 : INFO : EPOCH 21: training on 99524 raw words (62589 effective words) took 0.2s, 271481 effective words/s\n",
      "2023-12-06 14:20:07,770 : INFO : EPOCH 22: training on 99524 raw words (62671 effective words) took 0.2s, 272564 effective words/s\n",
      "2023-12-06 14:20:08,005 : INFO : EPOCH 23: training on 99524 raw words (62704 effective words) took 0.2s, 272128 effective words/s\n",
      "2023-12-06 14:20:08,244 : INFO : EPOCH 24: training on 99524 raw words (62654 effective words) took 0.2s, 266646 effective words/s\n",
      "2023-12-06 14:20:08,482 : INFO : EPOCH 25: training on 99524 raw words (62778 effective words) took 0.2s, 269314 effective words/s\n",
      "2023-12-06 14:20:08,717 : INFO : EPOCH 26: training on 99524 raw words (62663 effective words) took 0.2s, 271488 effective words/s\n",
      "2023-12-06 14:20:08,951 : INFO : EPOCH 27: training on 99524 raw words (62693 effective words) took 0.2s, 273641 effective words/s\n",
      "2023-12-06 14:20:09,183 : INFO : EPOCH 28: training on 99524 raw words (62662 effective words) took 0.2s, 275107 effective words/s\n",
      "2023-12-06 14:20:09,415 : INFO : EPOCH 29: training on 99524 raw words (62598 effective words) took 0.2s, 274149 effective words/s\n",
      "2023-12-06 14:20:09,416 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881105 effective words) took 7.1s, 264975 effective words/s', 'datetime': '2023-12-06T14:20:09.416874', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:20:09,417 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:20:09.417875', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  8%|         | 40/486 [06:31<1:08:24,  9.20s/it]2023-12-06 14:20:13,479 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:20:13,480 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:20:13,501 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:20:13,502 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:20:13,506 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:20:13.506932', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:20:13,507 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:20:13.507932', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:20:13,514 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:20:13,514 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:20:13,515 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:20:13.515439', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:20:13,525 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:20:13,527 : INFO : resetting layer weights\n",
      "2023-12-06 14:20:13,529 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:20:13.529839', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:20:13,782 : INFO : EPOCH 0: training on 99524 raw words (62793 effective words) took 0.2s, 255113 effective words/s\n",
      "2023-12-06 14:20:14,034 : INFO : EPOCH 1: training on 99524 raw words (62802 effective words) took 0.2s, 254710 effective words/s\n",
      "2023-12-06 14:20:14,285 : INFO : EPOCH 2: training on 99524 raw words (62712 effective words) took 0.2s, 255200 effective words/s\n",
      "2023-12-06 14:20:14,536 : INFO : EPOCH 3: training on 99524 raw words (62798 effective words) took 0.2s, 254437 effective words/s\n",
      "2023-12-06 14:20:14,783 : INFO : EPOCH 4: training on 99524 raw words (62857 effective words) took 0.2s, 258851 effective words/s\n",
      "2023-12-06 14:20:15,032 : INFO : EPOCH 5: training on 99524 raw words (62657 effective words) took 0.2s, 256804 effective words/s\n",
      "2023-12-06 14:20:15,279 : INFO : EPOCH 6: training on 99524 raw words (62553 effective words) took 0.2s, 257661 effective words/s\n",
      "2023-12-06 14:20:15,528 : INFO : EPOCH 7: training on 99524 raw words (62756 effective words) took 0.2s, 256681 effective words/s\n",
      "2023-12-06 14:20:15,778 : INFO : EPOCH 8: training on 99524 raw words (62823 effective words) took 0.2s, 255223 effective words/s\n",
      "2023-12-06 14:20:16,026 : INFO : EPOCH 9: training on 99524 raw words (62813 effective words) took 0.2s, 258132 effective words/s\n",
      "2023-12-06 14:20:16,282 : INFO : EPOCH 10: training on 99524 raw words (62618 effective words) took 0.3s, 250368 effective words/s\n",
      "2023-12-06 14:20:16,533 : INFO : EPOCH 11: training on 99524 raw words (62774 effective words) took 0.2s, 254006 effective words/s\n",
      "2023-12-06 14:20:16,780 : INFO : EPOCH 12: training on 99524 raw words (62832 effective words) took 0.2s, 259009 effective words/s\n",
      "2023-12-06 14:20:17,032 : INFO : EPOCH 13: training on 99524 raw words (62613 effective words) took 0.2s, 252967 effective words/s\n",
      "2023-12-06 14:20:17,278 : INFO : EPOCH 14: training on 99524 raw words (62735 effective words) took 0.2s, 259959 effective words/s\n",
      "2023-12-06 14:20:17,533 : INFO : EPOCH 15: training on 99524 raw words (62738 effective words) took 0.3s, 249873 effective words/s\n",
      "2023-12-06 14:20:17,786 : INFO : EPOCH 16: training on 99524 raw words (62751 effective words) took 0.2s, 253177 effective words/s\n",
      "2023-12-06 14:20:18,032 : INFO : EPOCH 17: training on 99524 raw words (62710 effective words) took 0.2s, 259173 effective words/s\n",
      "2023-12-06 14:20:18,281 : INFO : EPOCH 18: training on 99524 raw words (62659 effective words) took 0.2s, 256221 effective words/s\n",
      "2023-12-06 14:20:18,534 : INFO : EPOCH 19: training on 99524 raw words (62782 effective words) took 0.2s, 252664 effective words/s\n",
      "2023-12-06 14:20:18,787 : INFO : EPOCH 20: training on 99524 raw words (62609 effective words) took 0.2s, 252703 effective words/s\n",
      "2023-12-06 14:20:19,038 : INFO : EPOCH 21: training on 99524 raw words (62898 effective words) took 0.2s, 255312 effective words/s\n",
      "2023-12-06 14:20:19,294 : INFO : EPOCH 22: training on 99524 raw words (62812 effective words) took 0.3s, 250084 effective words/s\n",
      "2023-12-06 14:20:19,567 : INFO : EPOCH 23: training on 99524 raw words (62684 effective words) took 0.3s, 233369 effective words/s\n",
      "2023-12-06 14:20:19,837 : INFO : EPOCH 24: training on 99524 raw words (62662 effective words) took 0.3s, 238648 effective words/s\n",
      "2023-12-06 14:20:20,099 : INFO : EPOCH 25: training on 99524 raw words (62656 effective words) took 0.3s, 243887 effective words/s\n",
      "2023-12-06 14:20:20,344 : INFO : EPOCH 26: training on 99524 raw words (62730 effective words) took 0.2s, 259301 effective words/s\n",
      "2023-12-06 14:20:20,596 : INFO : EPOCH 27: training on 99524 raw words (62656 effective words) took 0.2s, 253625 effective words/s\n",
      "2023-12-06 14:20:20,848 : INFO : EPOCH 28: training on 99524 raw words (62718 effective words) took 0.2s, 254115 effective words/s\n",
      "2023-12-06 14:20:21,096 : INFO : EPOCH 29: training on 99524 raw words (62633 effective words) took 0.2s, 256789 effective words/s\n",
      "2023-12-06 14:20:21,097 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881834 effective words) took 7.6s, 248697 effective words/s', 'datetime': '2023-12-06T14:20:21.097664', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:20:21,098 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:20:21.098819', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  8%|         | 41/486 [06:43<1:14:14, 10.01s/it]2023-12-06 14:20:24,681 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:20:24,682 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:20:24,703 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:20:24,704 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:20:24,711 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:20:24.711230', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:20:24,711 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:20:24.711230', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:20:24,719 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:20:24,719 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:20:24,720 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:20:24.720484', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:20:24,729 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:20:24,730 : INFO : resetting layer weights\n",
      "2023-12-06 14:20:24,734 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:20:24.734748', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:20:24,988 : INFO : EPOCH 0: training on 99524 raw words (62784 effective words) took 0.2s, 252072 effective words/s\n",
      "2023-12-06 14:20:25,240 : INFO : EPOCH 1: training on 99524 raw words (62800 effective words) took 0.2s, 253486 effective words/s\n",
      "2023-12-06 14:20:25,497 : INFO : EPOCH 2: training on 99524 raw words (62666 effective words) took 0.3s, 247314 effective words/s\n",
      "2023-12-06 14:20:25,749 : INFO : EPOCH 3: training on 99524 raw words (62687 effective words) took 0.2s, 253241 effective words/s\n",
      "2023-12-06 14:20:26,007 : INFO : EPOCH 4: training on 99524 raw words (62834 effective words) took 0.3s, 248218 effective words/s\n",
      "2023-12-06 14:20:26,264 : INFO : EPOCH 5: training on 99524 raw words (62759 effective words) took 0.3s, 248920 effective words/s\n",
      "2023-12-06 14:20:26,532 : INFO : EPOCH 6: training on 99524 raw words (62674 effective words) took 0.3s, 238397 effective words/s\n",
      "2023-12-06 14:20:26,793 : INFO : EPOCH 7: training on 99524 raw words (62704 effective words) took 0.3s, 244909 effective words/s\n",
      "2023-12-06 14:20:27,049 : INFO : EPOCH 8: training on 99524 raw words (62626 effective words) took 0.3s, 250271 effective words/s\n",
      "2023-12-06 14:20:27,305 : INFO : EPOCH 9: training on 99524 raw words (62615 effective words) took 0.3s, 248632 effective words/s\n",
      "2023-12-06 14:20:27,559 : INFO : EPOCH 10: training on 99524 raw words (62704 effective words) took 0.2s, 251505 effective words/s\n",
      "2023-12-06 14:20:27,815 : INFO : EPOCH 11: training on 99524 raw words (62635 effective words) took 0.3s, 248575 effective words/s\n",
      "2023-12-06 14:20:28,069 : INFO : EPOCH 12: training on 99524 raw words (62845 effective words) took 0.2s, 251651 effective words/s\n",
      "2023-12-06 14:20:28,322 : INFO : EPOCH 13: training on 99524 raw words (62629 effective words) took 0.2s, 252616 effective words/s\n",
      "2023-12-06 14:20:28,573 : INFO : EPOCH 14: training on 99524 raw words (62683 effective words) took 0.2s, 253951 effective words/s\n",
      "2023-12-06 14:20:28,825 : INFO : EPOCH 15: training on 99524 raw words (62606 effective words) took 0.2s, 253529 effective words/s\n",
      "2023-12-06 14:20:29,077 : INFO : EPOCH 16: training on 99524 raw words (62624 effective words) took 0.2s, 251829 effective words/s\n",
      "2023-12-06 14:20:29,338 : INFO : EPOCH 17: training on 99524 raw words (62759 effective words) took 0.3s, 244815 effective words/s\n",
      "2023-12-06 14:20:29,592 : INFO : EPOCH 18: training on 99524 raw words (62688 effective words) took 0.2s, 251381 effective words/s\n",
      "2023-12-06 14:20:29,843 : INFO : EPOCH 19: training on 99524 raw words (62796 effective words) took 0.2s, 254621 effective words/s\n",
      "2023-12-06 14:20:30,095 : INFO : EPOCH 20: training on 99524 raw words (62876 effective words) took 0.2s, 254449 effective words/s\n",
      "2023-12-06 14:20:30,349 : INFO : EPOCH 21: training on 99524 raw words (62608 effective words) took 0.2s, 251611 effective words/s\n",
      "2023-12-06 14:20:30,605 : INFO : EPOCH 22: training on 99524 raw words (62817 effective words) took 0.3s, 248709 effective words/s\n",
      "2023-12-06 14:20:30,861 : INFO : EPOCH 23: training on 99524 raw words (62707 effective words) took 0.3s, 249476 effective words/s\n",
      "2023-12-06 14:20:31,117 : INFO : EPOCH 24: training on 99524 raw words (62597 effective words) took 0.3s, 249080 effective words/s\n",
      "2023-12-06 14:20:31,369 : INFO : EPOCH 25: training on 99524 raw words (62728 effective words) took 0.2s, 252894 effective words/s\n",
      "2023-12-06 14:20:31,622 : INFO : EPOCH 26: training on 99524 raw words (62759 effective words) took 0.2s, 251676 effective words/s\n",
      "2023-12-06 14:20:31,878 : INFO : EPOCH 27: training on 99524 raw words (62683 effective words) took 0.2s, 251059 effective words/s\n",
      "2023-12-06 14:20:32,130 : INFO : EPOCH 28: training on 99524 raw words (62633 effective words) took 0.2s, 251632 effective words/s\n",
      "2023-12-06 14:20:32,384 : INFO : EPOCH 29: training on 99524 raw words (62642 effective words) took 0.2s, 251125 effective words/s\n",
      "2023-12-06 14:20:32,385 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881168 effective words) took 7.7s, 245868 effective words/s', 'datetime': '2023-12-06T14:20:32.385845', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:20:32,387 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:20:32.387096', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  9%|         | 42/486 [06:54<1:17:18, 10.45s/it]2023-12-06 14:20:36,150 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:20:36,151 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:20:36,171 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:20:36,173 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:20:36,179 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:20:36.179860', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:20:36,179 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:20:36.179860', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:20:36,185 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:20:36,185 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:20:36,186 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:20:36.186860', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:20:36,196 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:20:36,197 : INFO : resetting layer weights\n",
      "2023-12-06 14:20:36,200 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:20:36.200406', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:20:36,437 : INFO : EPOCH 0: training on 99524 raw words (62777 effective words) took 0.2s, 271141 effective words/s\n",
      "2023-12-06 14:20:36,669 : INFO : EPOCH 1: training on 99524 raw words (62582 effective words) took 0.2s, 274157 effective words/s\n",
      "2023-12-06 14:20:36,906 : INFO : EPOCH 2: training on 99524 raw words (62787 effective words) took 0.2s, 271036 effective words/s\n",
      "2023-12-06 14:20:37,139 : INFO : EPOCH 3: training on 99524 raw words (62810 effective words) took 0.2s, 274291 effective words/s\n",
      "2023-12-06 14:20:37,376 : INFO : EPOCH 4: training on 99524 raw words (62770 effective words) took 0.2s, 270884 effective words/s\n",
      "2023-12-06 14:20:37,614 : INFO : EPOCH 5: training on 99524 raw words (62870 effective words) took 0.2s, 269117 effective words/s\n",
      "2023-12-06 14:20:37,851 : INFO : EPOCH 6: training on 99524 raw words (62793 effective words) took 0.2s, 269605 effective words/s\n",
      "2023-12-06 14:20:38,081 : INFO : EPOCH 7: training on 99524 raw words (62654 effective words) took 0.2s, 277369 effective words/s\n",
      "2023-12-06 14:20:38,317 : INFO : EPOCH 8: training on 99524 raw words (62675 effective words) took 0.2s, 272031 effective words/s\n",
      "2023-12-06 14:20:38,548 : INFO : EPOCH 9: training on 99524 raw words (62676 effective words) took 0.2s, 275343 effective words/s\n",
      "2023-12-06 14:20:38,784 : INFO : EPOCH 10: training on 99524 raw words (62845 effective words) took 0.2s, 272373 effective words/s\n",
      "2023-12-06 14:20:39,023 : INFO : EPOCH 11: training on 99524 raw words (62675 effective words) took 0.2s, 267354 effective words/s\n",
      "2023-12-06 14:20:39,255 : INFO : EPOCH 12: training on 99524 raw words (62725 effective words) took 0.2s, 275304 effective words/s\n",
      "2023-12-06 14:20:39,489 : INFO : EPOCH 13: training on 99524 raw words (62762 effective words) took 0.2s, 273419 effective words/s\n",
      "2023-12-06 14:20:39,727 : INFO : EPOCH 14: training on 99524 raw words (62664 effective words) took 0.2s, 268288 effective words/s\n",
      "2023-12-06 14:20:39,963 : INFO : EPOCH 15: training on 99524 raw words (62718 effective words) took 0.2s, 271051 effective words/s\n",
      "2023-12-06 14:20:40,193 : INFO : EPOCH 16: training on 99524 raw words (62758 effective words) took 0.2s, 277653 effective words/s\n",
      "2023-12-06 14:20:40,433 : INFO : EPOCH 17: training on 99524 raw words (62619 effective words) took 0.2s, 266142 effective words/s\n",
      "2023-12-06 14:20:40,675 : INFO : EPOCH 18: training on 99524 raw words (62610 effective words) took 0.2s, 265662 effective words/s\n",
      "2023-12-06 14:20:40,906 : INFO : EPOCH 19: training on 99524 raw words (62554 effective words) took 0.2s, 275043 effective words/s\n",
      "2023-12-06 14:20:41,144 : INFO : EPOCH 20: training on 99524 raw words (62801 effective words) took 0.2s, 268529 effective words/s\n",
      "2023-12-06 14:20:41,391 : INFO : EPOCH 21: training on 99524 raw words (62775 effective words) took 0.2s, 259709 effective words/s\n",
      "2023-12-06 14:20:41,630 : INFO : EPOCH 22: training on 99524 raw words (62696 effective words) took 0.2s, 268998 effective words/s\n",
      "2023-12-06 14:20:41,863 : INFO : EPOCH 23: training on 99524 raw words (62785 effective words) took 0.2s, 274755 effective words/s\n",
      "2023-12-06 14:20:42,115 : INFO : EPOCH 24: training on 99524 raw words (62687 effective words) took 0.2s, 252415 effective words/s\n",
      "2023-12-06 14:20:42,367 : INFO : EPOCH 25: training on 99524 raw words (62598 effective words) took 0.2s, 254613 effective words/s\n",
      "2023-12-06 14:20:42,602 : INFO : EPOCH 26: training on 99524 raw words (62786 effective words) took 0.2s, 270976 effective words/s\n",
      "2023-12-06 14:20:42,839 : INFO : EPOCH 27: training on 99524 raw words (62788 effective words) took 0.2s, 271778 effective words/s\n",
      "2023-12-06 14:20:43,087 : INFO : EPOCH 28: training on 99524 raw words (62708 effective words) took 0.2s, 257528 effective words/s\n",
      "2023-12-06 14:20:43,320 : INFO : EPOCH 29: training on 99524 raw words (62840 effective words) took 0.2s, 273459 effective words/s\n",
      "2023-12-06 14:20:43,558 : INFO : EPOCH 30: training on 99524 raw words (62711 effective words) took 0.2s, 269277 effective words/s\n",
      "2023-12-06 14:20:43,789 : INFO : EPOCH 31: training on 99524 raw words (62818 effective words) took 0.2s, 276876 effective words/s\n",
      "2023-12-06 14:20:44,023 : INFO : EPOCH 32: training on 99524 raw words (62599 effective words) took 0.2s, 272348 effective words/s\n",
      "2023-12-06 14:20:44,260 : INFO : EPOCH 33: training on 99524 raw words (62730 effective words) took 0.2s, 270639 effective words/s\n",
      "2023-12-06 14:20:44,498 : INFO : EPOCH 34: training on 99524 raw words (62694 effective words) took 0.2s, 269100 effective words/s\n",
      "2023-12-06 14:20:44,743 : INFO : EPOCH 35: training on 99524 raw words (62877 effective words) took 0.2s, 262780 effective words/s\n",
      "2023-12-06 14:20:44,982 : INFO : EPOCH 36: training on 99524 raw words (62764 effective words) took 0.2s, 267664 effective words/s\n",
      "2023-12-06 14:20:45,216 : INFO : EPOCH 37: training on 99524 raw words (62795 effective words) took 0.2s, 273775 effective words/s\n",
      "2023-12-06 14:20:45,450 : INFO : EPOCH 38: training on 99524 raw words (62707 effective words) took 0.2s, 272609 effective words/s\n",
      "2023-12-06 14:20:45,686 : INFO : EPOCH 39: training on 99524 raw words (62875 effective words) took 0.2s, 272133 effective words/s\n",
      "2023-12-06 14:20:45,917 : INFO : EPOCH 40: training on 99524 raw words (62712 effective words) took 0.2s, 275703 effective words/s\n",
      "2023-12-06 14:20:46,155 : INFO : EPOCH 41: training on 99524 raw words (62699 effective words) took 0.2s, 269287 effective words/s\n",
      "2023-12-06 14:20:46,396 : INFO : EPOCH 42: training on 99524 raw words (62665 effective words) took 0.2s, 264907 effective words/s\n",
      "2023-12-06 14:20:46,629 : INFO : EPOCH 43: training on 99524 raw words (62657 effective words) took 0.2s, 274525 effective words/s\n",
      "2023-12-06 14:20:46,884 : INFO : EPOCH 44: training on 99524 raw words (62734 effective words) took 0.3s, 250518 effective words/s\n",
      "2023-12-06 14:20:47,132 : INFO : EPOCH 45: training on 99524 raw words (62768 effective words) took 0.2s, 261133 effective words/s\n",
      "2023-12-06 14:20:47,374 : INFO : EPOCH 46: training on 99524 raw words (62851 effective words) took 0.2s, 263986 effective words/s\n",
      "2023-12-06 14:20:47,609 : INFO : EPOCH 47: training on 99524 raw words (62703 effective words) took 0.2s, 272676 effective words/s\n",
      "2023-12-06 14:20:47,841 : INFO : EPOCH 48: training on 99524 raw words (62802 effective words) took 0.2s, 275200 effective words/s\n",
      "2023-12-06 14:20:48,078 : INFO : EPOCH 49: training on 99524 raw words (62589 effective words) took 0.2s, 269263 effective words/s\n",
      "2023-12-06 14:20:48,080 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136538 effective words) took 11.9s, 264044 effective words/s', 'datetime': '2023-12-06T14:20:48.080126', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:20:48,081 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:20:48.081143', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  9%|         | 43/486 [07:10<1:29:16, 12.09s/it]2023-12-06 14:20:52,075 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:20:52,076 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:20:52,097 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:20:52,098 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:20:52,102 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:20:52.102863', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:20:52,104 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:20:52.102863', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:20:52,109 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:20:52,110 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:20:52,111 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:20:52.111822', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:20:52,125 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:20:52,129 : INFO : resetting layer weights\n",
      "2023-12-06 14:20:52,131 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:20:52.131315', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:20:52,386 : INFO : EPOCH 0: training on 99524 raw words (62583 effective words) took 0.2s, 254153 effective words/s\n",
      "2023-12-06 14:20:52,634 : INFO : EPOCH 1: training on 99524 raw words (62796 effective words) took 0.2s, 256790 effective words/s\n",
      "2023-12-06 14:20:52,884 : INFO : EPOCH 2: training on 99524 raw words (62841 effective words) took 0.2s, 257494 effective words/s\n",
      "2023-12-06 14:20:53,130 : INFO : EPOCH 3: training on 99524 raw words (62697 effective words) took 0.2s, 258281 effective words/s\n",
      "2023-12-06 14:20:53,380 : INFO : EPOCH 4: training on 99524 raw words (62775 effective words) took 0.2s, 256445 effective words/s\n",
      "2023-12-06 14:20:53,628 : INFO : EPOCH 5: training on 99524 raw words (62630 effective words) took 0.2s, 256481 effective words/s\n",
      "2023-12-06 14:20:53,885 : INFO : EPOCH 6: training on 99524 raw words (62720 effective words) took 0.3s, 248532 effective words/s\n",
      "2023-12-06 14:20:54,135 : INFO : EPOCH 7: training on 99524 raw words (62577 effective words) took 0.2s, 255959 effective words/s\n",
      "2023-12-06 14:20:54,385 : INFO : EPOCH 8: training on 99524 raw words (62910 effective words) took 0.2s, 256417 effective words/s\n",
      "2023-12-06 14:20:54,629 : INFO : EPOCH 9: training on 99524 raw words (62764 effective words) took 0.2s, 261900 effective words/s\n",
      "2023-12-06 14:20:54,880 : INFO : EPOCH 10: training on 99524 raw words (62687 effective words) took 0.2s, 254260 effective words/s\n",
      "2023-12-06 14:20:55,127 : INFO : EPOCH 11: training on 99524 raw words (62675 effective words) took 0.2s, 259098 effective words/s\n",
      "2023-12-06 14:20:55,377 : INFO : EPOCH 12: training on 99524 raw words (62740 effective words) took 0.2s, 255383 effective words/s\n",
      "2023-12-06 14:20:55,622 : INFO : EPOCH 13: training on 99524 raw words (62734 effective words) took 0.2s, 261139 effective words/s\n",
      "2023-12-06 14:20:55,872 : INFO : EPOCH 14: training on 99524 raw words (62672 effective words) took 0.2s, 256485 effective words/s\n",
      "2023-12-06 14:20:56,121 : INFO : EPOCH 15: training on 99524 raw words (62577 effective words) took 0.2s, 256521 effective words/s\n",
      "2023-12-06 14:20:56,374 : INFO : EPOCH 16: training on 99524 raw words (62654 effective words) took 0.2s, 251926 effective words/s\n",
      "2023-12-06 14:20:56,629 : INFO : EPOCH 17: training on 99524 raw words (62718 effective words) took 0.2s, 251052 effective words/s\n",
      "2023-12-06 14:20:56,878 : INFO : EPOCH 18: training on 99524 raw words (62920 effective words) took 0.2s, 257389 effective words/s\n",
      "2023-12-06 14:20:57,125 : INFO : EPOCH 19: training on 99524 raw words (62786 effective words) took 0.2s, 257031 effective words/s\n",
      "2023-12-06 14:20:57,376 : INFO : EPOCH 20: training on 99524 raw words (62713 effective words) took 0.2s, 255142 effective words/s\n",
      "2023-12-06 14:20:57,623 : INFO : EPOCH 21: training on 99524 raw words (62734 effective words) took 0.2s, 258557 effective words/s\n",
      "2023-12-06 14:20:57,871 : INFO : EPOCH 22: training on 99524 raw words (62777 effective words) took 0.2s, 258556 effective words/s\n",
      "2023-12-06 14:20:58,122 : INFO : EPOCH 23: training on 99524 raw words (62751 effective words) took 0.2s, 255292 effective words/s\n",
      "2023-12-06 14:20:58,374 : INFO : EPOCH 24: training on 99524 raw words (62653 effective words) took 0.2s, 253016 effective words/s\n",
      "2023-12-06 14:20:58,641 : INFO : EPOCH 25: training on 99524 raw words (62750 effective words) took 0.3s, 240460 effective words/s\n",
      "2023-12-06 14:20:58,887 : INFO : EPOCH 26: training on 99524 raw words (62655 effective words) took 0.2s, 258604 effective words/s\n",
      "2023-12-06 14:20:59,148 : INFO : EPOCH 27: training on 99524 raw words (62695 effective words) took 0.3s, 245663 effective words/s\n",
      "2023-12-06 14:20:59,397 : INFO : EPOCH 28: training on 99524 raw words (62818 effective words) took 0.2s, 256265 effective words/s\n",
      "2023-12-06 14:20:59,645 : INFO : EPOCH 29: training on 99524 raw words (62906 effective words) took 0.2s, 258450 effective words/s\n",
      "2023-12-06 14:20:59,900 : INFO : EPOCH 30: training on 99524 raw words (62677 effective words) took 0.3s, 250227 effective words/s\n",
      "2023-12-06 14:21:00,156 : INFO : EPOCH 31: training on 99524 raw words (62682 effective words) took 0.3s, 248844 effective words/s\n",
      "2023-12-06 14:21:00,410 : INFO : EPOCH 32: training on 99524 raw words (62671 effective words) took 0.2s, 254756 effective words/s\n",
      "2023-12-06 14:21:00,660 : INFO : EPOCH 33: training on 99524 raw words (62723 effective words) took 0.2s, 255306 effective words/s\n",
      "2023-12-06 14:21:00,908 : INFO : EPOCH 34: training on 99524 raw words (62706 effective words) took 0.2s, 257014 effective words/s\n",
      "2023-12-06 14:21:01,156 : INFO : EPOCH 35: training on 99524 raw words (62701 effective words) took 0.2s, 256812 effective words/s\n",
      "2023-12-06 14:21:01,404 : INFO : EPOCH 36: training on 99524 raw words (62847 effective words) took 0.2s, 258621 effective words/s\n",
      "2023-12-06 14:21:01,652 : INFO : EPOCH 37: training on 99524 raw words (62787 effective words) took 0.2s, 258585 effective words/s\n",
      "2023-12-06 14:21:01,901 : INFO : EPOCH 38: training on 99524 raw words (62854 effective words) took 0.2s, 257219 effective words/s\n",
      "2023-12-06 14:21:02,151 : INFO : EPOCH 39: training on 99524 raw words (62840 effective words) took 0.2s, 255915 effective words/s\n",
      "2023-12-06 14:21:02,402 : INFO : EPOCH 40: training on 99524 raw words (62618 effective words) took 0.2s, 253398 effective words/s\n",
      "2023-12-06 14:21:02,654 : INFO : EPOCH 41: training on 99524 raw words (62750 effective words) took 0.2s, 255067 effective words/s\n",
      "2023-12-06 14:21:02,919 : INFO : EPOCH 42: training on 99524 raw words (62759 effective words) took 0.3s, 241863 effective words/s\n",
      "2023-12-06 14:21:03,170 : INFO : EPOCH 43: training on 99524 raw words (62751 effective words) took 0.2s, 253957 effective words/s\n",
      "2023-12-06 14:21:03,418 : INFO : EPOCH 44: training on 99524 raw words (62742 effective words) took 0.2s, 258005 effective words/s\n",
      "2023-12-06 14:21:03,670 : INFO : EPOCH 45: training on 99524 raw words (62778 effective words) took 0.2s, 254505 effective words/s\n",
      "2023-12-06 14:21:03,916 : INFO : EPOCH 46: training on 99524 raw words (62861 effective words) took 0.2s, 259765 effective words/s\n",
      "2023-12-06 14:21:04,168 : INFO : EPOCH 47: training on 99524 raw words (62583 effective words) took 0.2s, 253777 effective words/s\n",
      "2023-12-06 14:21:04,418 : INFO : EPOCH 48: training on 99524 raw words (62650 effective words) took 0.2s, 256059 effective words/s\n",
      "2023-12-06 14:21:04,664 : INFO : EPOCH 49: training on 99524 raw words (62891 effective words) took 0.2s, 261762 effective words/s\n",
      "2023-12-06 14:21:04,665 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136779 effective words) took 12.5s, 250294 effective words/s', 'datetime': '2023-12-06T14:21:04.665153', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:21:04,666 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:21:04.665153', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  9%|         | 44/486 [07:27<1:39:29, 13.51s/it]2023-12-06 14:21:08,881 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:21:08,881 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:21:08,904 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:21:08,905 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:21:08,911 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:21:08.911276', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:21:08,912 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:21:08.912276', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:21:08,919 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:21:08,920 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:21:08,920 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:21:08.920394', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:21:08,930 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:21:08,931 : INFO : resetting layer weights\n",
      "2023-12-06 14:21:08,933 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:21:08.933401', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:21:09,189 : INFO : EPOCH 0: training on 99524 raw words (62779 effective words) took 0.3s, 249267 effective words/s\n",
      "2023-12-06 14:21:09,440 : INFO : EPOCH 1: training on 99524 raw words (62833 effective words) took 0.2s, 254514 effective words/s\n",
      "2023-12-06 14:21:09,695 : INFO : EPOCH 2: training on 99524 raw words (62750 effective words) took 0.3s, 250553 effective words/s\n",
      "2023-12-06 14:21:09,948 : INFO : EPOCH 3: training on 99524 raw words (62750 effective words) took 0.2s, 252228 effective words/s\n",
      "2023-12-06 14:21:10,206 : INFO : EPOCH 4: training on 99524 raw words (62859 effective words) took 0.3s, 250258 effective words/s\n",
      "2023-12-06 14:21:10,464 : INFO : EPOCH 5: training on 99524 raw words (62687 effective words) took 0.3s, 246100 effective words/s\n",
      "2023-12-06 14:21:10,715 : INFO : EPOCH 6: training on 99524 raw words (62756 effective words) took 0.2s, 254887 effective words/s\n",
      "2023-12-06 14:21:10,969 : INFO : EPOCH 7: training on 99524 raw words (62697 effective words) took 0.2s, 252664 effective words/s\n",
      "2023-12-06 14:21:11,219 : INFO : EPOCH 8: training on 99524 raw words (62690 effective words) took 0.2s, 254631 effective words/s\n",
      "2023-12-06 14:21:11,473 : INFO : EPOCH 9: training on 99524 raw words (62750 effective words) took 0.2s, 251202 effective words/s\n",
      "2023-12-06 14:21:11,725 : INFO : EPOCH 10: training on 99524 raw words (62877 effective words) took 0.2s, 254438 effective words/s\n",
      "2023-12-06 14:21:11,977 : INFO : EPOCH 11: training on 99524 raw words (62802 effective words) took 0.2s, 253630 effective words/s\n",
      "2023-12-06 14:21:12,236 : INFO : EPOCH 12: training on 99524 raw words (62673 effective words) took 0.3s, 246185 effective words/s\n",
      "2023-12-06 14:21:12,491 : INFO : EPOCH 13: training on 99524 raw words (62754 effective words) took 0.3s, 250100 effective words/s\n",
      "2023-12-06 14:21:12,744 : INFO : EPOCH 14: training on 99524 raw words (62591 effective words) took 0.2s, 250773 effective words/s\n",
      "2023-12-06 14:21:12,996 : INFO : EPOCH 15: training on 99524 raw words (62698 effective words) took 0.2s, 254303 effective words/s\n",
      "2023-12-06 14:21:13,249 : INFO : EPOCH 16: training on 99524 raw words (62726 effective words) took 0.2s, 251276 effective words/s\n",
      "2023-12-06 14:21:13,503 : INFO : EPOCH 17: training on 99524 raw words (62776 effective words) took 0.2s, 252568 effective words/s\n",
      "2023-12-06 14:21:13,756 : INFO : EPOCH 18: training on 99524 raw words (62662 effective words) took 0.2s, 251652 effective words/s\n",
      "2023-12-06 14:21:14,008 : INFO : EPOCH 19: training on 99524 raw words (62608 effective words) took 0.2s, 253183 effective words/s\n",
      "2023-12-06 14:21:14,263 : INFO : EPOCH 20: training on 99524 raw words (62799 effective words) took 0.3s, 249749 effective words/s\n",
      "2023-12-06 14:21:14,513 : INFO : EPOCH 21: training on 99524 raw words (62621 effective words) took 0.2s, 255832 effective words/s\n",
      "2023-12-06 14:21:14,766 : INFO : EPOCH 22: training on 99524 raw words (62830 effective words) took 0.2s, 252834 effective words/s\n",
      "2023-12-06 14:21:15,019 : INFO : EPOCH 23: training on 99524 raw words (62601 effective words) took 0.2s, 251445 effective words/s\n",
      "2023-12-06 14:21:15,271 : INFO : EPOCH 24: training on 99524 raw words (62705 effective words) took 0.2s, 254178 effective words/s\n",
      "2023-12-06 14:21:15,526 : INFO : EPOCH 25: training on 99524 raw words (62610 effective words) took 0.3s, 248801 effective words/s\n",
      "2023-12-06 14:21:15,777 : INFO : EPOCH 26: training on 99524 raw words (62675 effective words) took 0.2s, 254987 effective words/s\n",
      "2023-12-06 14:21:16,029 : INFO : EPOCH 27: training on 99524 raw words (62822 effective words) took 0.2s, 253920 effective words/s\n",
      "2023-12-06 14:21:16,281 : INFO : EPOCH 28: training on 99524 raw words (62824 effective words) took 0.2s, 253201 effective words/s\n",
      "2023-12-06 14:21:16,533 : INFO : EPOCH 29: training on 99524 raw words (62616 effective words) took 0.2s, 253077 effective words/s\n",
      "2023-12-06 14:21:16,792 : INFO : EPOCH 30: training on 99524 raw words (62715 effective words) took 0.3s, 246390 effective words/s\n",
      "2023-12-06 14:21:17,047 : INFO : EPOCH 31: training on 99524 raw words (62871 effective words) took 0.3s, 250988 effective words/s\n",
      "2023-12-06 14:21:17,298 : INFO : EPOCH 32: training on 99524 raw words (62759 effective words) took 0.2s, 254566 effective words/s\n",
      "2023-12-06 14:21:17,550 : INFO : EPOCH 33: training on 99524 raw words (62687 effective words) took 0.2s, 253851 effective words/s\n",
      "2023-12-06 14:21:17,802 : INFO : EPOCH 34: training on 99524 raw words (62898 effective words) took 0.2s, 253919 effective words/s\n",
      "2023-12-06 14:21:18,053 : INFO : EPOCH 35: training on 99524 raw words (62806 effective words) took 0.2s, 254512 effective words/s\n",
      "2023-12-06 14:21:18,300 : INFO : EPOCH 36: training on 99524 raw words (62552 effective words) took 0.2s, 257722 effective words/s\n",
      "2023-12-06 14:21:18,555 : INFO : EPOCH 37: training on 99524 raw words (62702 effective words) took 0.3s, 250069 effective words/s\n",
      "2023-12-06 14:21:18,813 : INFO : EPOCH 38: training on 99524 raw words (62945 effective words) took 0.3s, 247786 effective words/s\n",
      "2023-12-06 14:21:19,065 : INFO : EPOCH 39: training on 99524 raw words (62734 effective words) took 0.2s, 254292 effective words/s\n",
      "2023-12-06 14:21:19,322 : INFO : EPOCH 40: training on 99524 raw words (62609 effective words) took 0.3s, 247100 effective words/s\n",
      "2023-12-06 14:21:19,582 : INFO : EPOCH 41: training on 99524 raw words (62706 effective words) took 0.3s, 245805 effective words/s\n",
      "2023-12-06 14:21:19,844 : INFO : EPOCH 42: training on 99524 raw words (62823 effective words) took 0.3s, 244121 effective words/s\n",
      "2023-12-06 14:21:20,102 : INFO : EPOCH 43: training on 99524 raw words (62584 effective words) took 0.3s, 246621 effective words/s\n",
      "2023-12-06 14:21:20,359 : INFO : EPOCH 44: training on 99524 raw words (62688 effective words) took 0.3s, 248422 effective words/s\n",
      "2023-12-06 14:21:20,615 : INFO : EPOCH 45: training on 99524 raw words (62684 effective words) took 0.3s, 250278 effective words/s\n",
      "2023-12-06 14:21:20,877 : INFO : EPOCH 46: training on 99524 raw words (62653 effective words) took 0.3s, 243203 effective words/s\n",
      "2023-12-06 14:21:21,132 : INFO : EPOCH 47: training on 99524 raw words (62815 effective words) took 0.3s, 250525 effective words/s\n",
      "2023-12-06 14:21:21,390 : INFO : EPOCH 48: training on 99524 raw words (62801 effective words) took 0.3s, 248470 effective words/s\n",
      "2023-12-06 14:21:21,652 : INFO : EPOCH 49: training on 99524 raw words (62816 effective words) took 0.3s, 244054 effective words/s\n",
      "2023-12-06 14:21:21,653 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136669 effective words) took 12.7s, 246617 effective words/s', 'datetime': '2023-12-06T14:21:21.653105', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:21:21,654 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:21:21.654199', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  9%|         | 45/486 [07:44<1:47:52, 14.68s/it]2023-12-06 14:21:26,292 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:21:26,293 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:21:26,315 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:21:26,316 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:21:26,321 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:21:26.321910', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:21:26,323 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:21:26.323028', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:21:26,329 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:21:26,329 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:21:26,330 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:21:26.330551', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:21:26,339 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:21:26,339 : INFO : resetting layer weights\n",
      "2023-12-06 14:21:26,342 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:21:26.342503', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:21:26,589 : INFO : EPOCH 0: training on 99524 raw words (60472 effective words) took 0.2s, 251219 effective words/s\n",
      "2023-12-06 14:21:26,823 : INFO : EPOCH 1: training on 99524 raw words (60514 effective words) took 0.2s, 261945 effective words/s\n",
      "2023-12-06 14:21:27,053 : INFO : EPOCH 2: training on 99524 raw words (60294 effective words) took 0.2s, 268907 effective words/s\n",
      "2023-12-06 14:21:27,247 : INFO : EPOCH 3: training on 99524 raw words (60378 effective words) took 0.2s, 318878 effective words/s\n",
      "2023-12-06 14:21:27,435 : INFO : EPOCH 4: training on 99524 raw words (60350 effective words) took 0.2s, 328238 effective words/s\n",
      "2023-12-06 14:21:27,626 : INFO : EPOCH 5: training on 99524 raw words (60401 effective words) took 0.2s, 322252 effective words/s\n",
      "2023-12-06 14:21:27,815 : INFO : EPOCH 6: training on 99524 raw words (60154 effective words) took 0.2s, 325403 effective words/s\n",
      "2023-12-06 14:21:28,015 : INFO : EPOCH 7: training on 99524 raw words (60459 effective words) took 0.2s, 309775 effective words/s\n",
      "2023-12-06 14:21:28,202 : INFO : EPOCH 8: training on 99524 raw words (60505 effective words) took 0.2s, 328832 effective words/s\n",
      "2023-12-06 14:21:28,391 : INFO : EPOCH 9: training on 99524 raw words (60321 effective words) took 0.2s, 326412 effective words/s\n",
      "2023-12-06 14:21:28,392 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603848 effective words) took 2.0s, 294655 effective words/s', 'datetime': '2023-12-06T14:21:28.392730', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:21:28,393 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:21:28.393731', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "  9%|         | 46/486 [07:49<1:25:52, 11.71s/it]2023-12-06 14:21:31,082 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:21:31,083 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:21:31,104 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:21:31,105 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:21:31,109 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:21:31.109296', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:21:31,110 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:21:31.110297', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:21:31,114 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:21:31,115 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:21:31,115 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:21:31.115296', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:21:31,122 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:21:31,123 : INFO : resetting layer weights\n",
      "2023-12-06 14:21:31,125 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:21:31.125795', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:21:31,329 : INFO : EPOCH 0: training on 99524 raw words (60262 effective words) took 0.2s, 301262 effective words/s\n",
      "2023-12-06 14:21:31,521 : INFO : EPOCH 1: training on 99524 raw words (60451 effective words) took 0.2s, 321511 effective words/s\n",
      "2023-12-06 14:21:31,712 : INFO : EPOCH 2: training on 99524 raw words (60229 effective words) took 0.2s, 322506 effective words/s\n",
      "2023-12-06 14:21:31,903 : INFO : EPOCH 3: training on 99524 raw words (60424 effective words) took 0.2s, 324624 effective words/s\n",
      "2023-12-06 14:21:32,095 : INFO : EPOCH 4: training on 99524 raw words (60465 effective words) took 0.2s, 322446 effective words/s\n",
      "2023-12-06 14:21:32,297 : INFO : EPOCH 5: training on 99524 raw words (60277 effective words) took 0.2s, 304692 effective words/s\n",
      "2023-12-06 14:21:32,488 : INFO : EPOCH 6: training on 99524 raw words (60584 effective words) took 0.2s, 325381 effective words/s\n",
      "2023-12-06 14:21:32,681 : INFO : EPOCH 7: training on 99524 raw words (60474 effective words) took 0.2s, 320093 effective words/s\n",
      "2023-12-06 14:21:32,873 : INFO : EPOCH 8: training on 99524 raw words (60431 effective words) took 0.2s, 322716 effective words/s\n",
      "2023-12-06 14:21:33,063 : INFO : EPOCH 9: training on 99524 raw words (60168 effective words) took 0.2s, 322460 effective words/s\n",
      "2023-12-06 14:21:33,065 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603765 effective words) took 1.9s, 311388 effective words/s', 'datetime': '2023-12-06T14:21:33.065190', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:21:33,065 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:21:33.065190', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 10%|         | 47/486 [07:54<1:10:37,  9.65s/it]2023-12-06 14:21:35,935 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:21:35,936 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:21:35,958 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:21:35,959 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:21:35,964 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:21:35.964463', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:21:35,964 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:21:35.964463', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:21:35,969 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:21:35,969 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:21:35,970 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:21:35.970472', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:21:35,976 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:21:35,977 : INFO : resetting layer weights\n",
      "2023-12-06 14:21:35,980 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:21:35.980049', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:21:36,182 : INFO : EPOCH 0: training on 99524 raw words (60257 effective words) took 0.2s, 304598 effective words/s\n",
      "2023-12-06 14:21:36,375 : INFO : EPOCH 1: training on 99524 raw words (60236 effective words) took 0.2s, 318059 effective words/s\n",
      "2023-12-06 14:21:36,581 : INFO : EPOCH 2: training on 99524 raw words (60250 effective words) took 0.2s, 299591 effective words/s\n",
      "2023-12-06 14:21:36,777 : INFO : EPOCH 3: training on 99524 raw words (60259 effective words) took 0.2s, 314533 effective words/s\n",
      "2023-12-06 14:21:36,976 : INFO : EPOCH 4: training on 99524 raw words (60501 effective words) took 0.2s, 311187 effective words/s\n",
      "2023-12-06 14:21:37,172 : INFO : EPOCH 5: training on 99524 raw words (60377 effective words) took 0.2s, 314319 effective words/s\n",
      "2023-12-06 14:21:37,369 : INFO : EPOCH 6: training on 99524 raw words (60292 effective words) took 0.2s, 314201 effective words/s\n",
      "2023-12-06 14:21:37,561 : INFO : EPOCH 7: training on 99524 raw words (60416 effective words) took 0.2s, 319186 effective words/s\n",
      "2023-12-06 14:21:37,772 : INFO : EPOCH 8: training on 99524 raw words (60487 effective words) took 0.2s, 293918 effective words/s\n",
      "2023-12-06 14:21:37,968 : INFO : EPOCH 9: training on 99524 raw words (60253 effective words) took 0.2s, 313937 effective words/s\n",
      "2023-12-06 14:21:37,969 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603328 effective words) took 2.0s, 303359 effective words/s', 'datetime': '2023-12-06T14:21:37.969851', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:21:37,970 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:21:37.970362', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 10%|         | 48/486 [07:59<59:55,  8.21s/it]  2023-12-06 14:21:40,771 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:21:40,772 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:21:40,792 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:21:40,794 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:21:40,797 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:21:40.797211', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:21:40,798 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:21:40.798947', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:21:40,803 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:21:40,804 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:21:40,804 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:21:40.804134', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:21:40,810 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:21:40,811 : INFO : resetting layer weights\n",
      "2023-12-06 14:21:40,812 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:21:40.812642', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:21:41,003 : INFO : EPOCH 0: training on 99524 raw words (60596 effective words) took 0.2s, 325916 effective words/s\n",
      "2023-12-06 14:21:41,191 : INFO : EPOCH 1: training on 99524 raw words (60438 effective words) took 0.2s, 326925 effective words/s\n",
      "2023-12-06 14:21:41,395 : INFO : EPOCH 2: training on 99524 raw words (60388 effective words) took 0.2s, 303286 effective words/s\n",
      "2023-12-06 14:21:41,593 : INFO : EPOCH 3: training on 99524 raw words (60352 effective words) took 0.2s, 312047 effective words/s\n",
      "2023-12-06 14:21:41,791 : INFO : EPOCH 4: training on 99524 raw words (60438 effective words) took 0.2s, 311510 effective words/s\n",
      "2023-12-06 14:21:41,985 : INFO : EPOCH 5: training on 99524 raw words (60380 effective words) took 0.2s, 318206 effective words/s\n",
      "2023-12-06 14:21:42,173 : INFO : EPOCH 6: training on 99524 raw words (60257 effective words) took 0.2s, 329111 effective words/s\n",
      "2023-12-06 14:21:42,365 : INFO : EPOCH 7: training on 99524 raw words (60344 effective words) took 0.2s, 320238 effective words/s\n",
      "2023-12-06 14:21:42,558 : INFO : EPOCH 8: training on 99524 raw words (60336 effective words) took 0.2s, 320546 effective words/s\n",
      "2023-12-06 14:21:42,757 : INFO : EPOCH 9: training on 99524 raw words (60438 effective words) took 0.2s, 310704 effective words/s\n",
      "2023-12-06 14:21:42,944 : INFO : EPOCH 10: training on 99524 raw words (60116 effective words) took 0.2s, 327629 effective words/s\n",
      "2023-12-06 14:21:43,134 : INFO : EPOCH 11: training on 99524 raw words (60366 effective words) took 0.2s, 328121 effective words/s\n",
      "2023-12-06 14:21:43,320 : INFO : EPOCH 12: training on 99524 raw words (60350 effective words) took 0.2s, 330478 effective words/s\n",
      "2023-12-06 14:21:43,508 : INFO : EPOCH 13: training on 99524 raw words (60338 effective words) took 0.2s, 327981 effective words/s\n",
      "2023-12-06 14:21:43,705 : INFO : EPOCH 14: training on 99524 raw words (60554 effective words) took 0.2s, 313258 effective words/s\n",
      "2023-12-06 14:21:43,895 : INFO : EPOCH 15: training on 99524 raw words (60722 effective words) took 0.2s, 328046 effective words/s\n",
      "2023-12-06 14:21:44,085 : INFO : EPOCH 16: training on 99524 raw words (60328 effective words) took 0.2s, 324973 effective words/s\n",
      "2023-12-06 14:21:44,288 : INFO : EPOCH 17: training on 99524 raw words (60333 effective words) took 0.2s, 304593 effective words/s\n",
      "2023-12-06 14:21:44,477 : INFO : EPOCH 18: training on 99524 raw words (60434 effective words) took 0.2s, 326978 effective words/s\n",
      "2023-12-06 14:21:44,675 : INFO : EPOCH 19: training on 99524 raw words (60281 effective words) took 0.2s, 311108 effective words/s\n",
      "2023-12-06 14:21:44,865 : INFO : EPOCH 20: training on 99524 raw words (60589 effective words) took 0.2s, 325452 effective words/s\n",
      "2023-12-06 14:21:45,070 : INFO : EPOCH 21: training on 99524 raw words (60374 effective words) took 0.2s, 299776 effective words/s\n",
      "2023-12-06 14:21:45,261 : INFO : EPOCH 22: training on 99524 raw words (60404 effective words) took 0.2s, 324430 effective words/s\n",
      "2023-12-06 14:21:45,453 : INFO : EPOCH 23: training on 99524 raw words (60239 effective words) took 0.2s, 322430 effective words/s\n",
      "2023-12-06 14:21:45,641 : INFO : EPOCH 24: training on 99524 raw words (60338 effective words) took 0.2s, 327087 effective words/s\n",
      "2023-12-06 14:21:45,829 : INFO : EPOCH 25: training on 99524 raw words (60346 effective words) took 0.2s, 328354 effective words/s\n",
      "2023-12-06 14:21:46,027 : INFO : EPOCH 26: training on 99524 raw words (60518 effective words) took 0.2s, 313073 effective words/s\n",
      "2023-12-06 14:21:46,216 : INFO : EPOCH 27: training on 99524 raw words (60362 effective words) took 0.2s, 327981 effective words/s\n",
      "2023-12-06 14:21:46,403 : INFO : EPOCH 28: training on 99524 raw words (60424 effective words) took 0.2s, 329397 effective words/s\n",
      "2023-12-06 14:21:46,592 : INFO : EPOCH 29: training on 99524 raw words (60366 effective words) took 0.2s, 325787 effective words/s\n",
      "2023-12-06 14:21:46,593 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811749 effective words) took 5.8s, 313444 effective words/s', 'datetime': '2023-12-06T14:21:46.593971', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:21:46,593 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:21:46.593971', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 10%|         | 49/486 [08:08<1:01:36,  8.46s/it]2023-12-06 14:21:49,818 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:21:49,818 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:21:49,838 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:21:49,839 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:21:49,843 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:21:49.843003', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:21:49,844 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:21:49.844005', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:21:49,848 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:21:49,848 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:21:49,849 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:21:49.849512', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:21:49,856 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:21:49,856 : INFO : resetting layer weights\n",
      "2023-12-06 14:21:49,857 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:21:49.857835', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:21:50,056 : INFO : EPOCH 0: training on 99524 raw words (60669 effective words) took 0.2s, 311694 effective words/s\n",
      "2023-12-06 14:21:50,241 : INFO : EPOCH 1: training on 99524 raw words (60549 effective words) took 0.2s, 335129 effective words/s\n",
      "2023-12-06 14:21:50,427 : INFO : EPOCH 2: training on 99524 raw words (60359 effective words) took 0.2s, 333309 effective words/s\n",
      "2023-12-06 14:21:50,611 : INFO : EPOCH 3: training on 99524 raw words (60553 effective words) took 0.2s, 334879 effective words/s\n",
      "2023-12-06 14:21:50,795 : INFO : EPOCH 4: training on 99524 raw words (60344 effective words) took 0.2s, 335128 effective words/s\n",
      "2023-12-06 14:21:50,980 : INFO : EPOCH 5: training on 99524 raw words (60437 effective words) took 0.2s, 332562 effective words/s\n",
      "2023-12-06 14:21:51,165 : INFO : EPOCH 6: training on 99524 raw words (60433 effective words) took 0.2s, 336241 effective words/s\n",
      "2023-12-06 14:21:51,357 : INFO : EPOCH 7: training on 99524 raw words (60249 effective words) took 0.2s, 319995 effective words/s\n",
      "2023-12-06 14:21:51,544 : INFO : EPOCH 8: training on 99524 raw words (60364 effective words) took 0.2s, 329925 effective words/s\n",
      "2023-12-06 14:21:51,735 : INFO : EPOCH 9: training on 99524 raw words (60410 effective words) took 0.2s, 324578 effective words/s\n",
      "2023-12-06 14:21:51,927 : INFO : EPOCH 10: training on 99524 raw words (60355 effective words) took 0.2s, 322135 effective words/s\n",
      "2023-12-06 14:21:52,114 : INFO : EPOCH 11: training on 99524 raw words (60318 effective words) took 0.2s, 330075 effective words/s\n",
      "2023-12-06 14:21:52,308 : INFO : EPOCH 12: training on 99524 raw words (60356 effective words) took 0.2s, 316009 effective words/s\n",
      "2023-12-06 14:21:52,495 : INFO : EPOCH 13: training on 99524 raw words (60417 effective words) took 0.2s, 330148 effective words/s\n",
      "2023-12-06 14:21:52,681 : INFO : EPOCH 14: training on 99524 raw words (60346 effective words) took 0.2s, 331258 effective words/s\n",
      "2023-12-06 14:21:52,865 : INFO : EPOCH 15: training on 99524 raw words (60510 effective words) took 0.2s, 336384 effective words/s\n",
      "2023-12-06 14:21:53,051 : INFO : EPOCH 16: training on 99524 raw words (60529 effective words) took 0.2s, 334575 effective words/s\n",
      "2023-12-06 14:21:53,236 : INFO : EPOCH 17: training on 99524 raw words (60371 effective words) took 0.2s, 332178 effective words/s\n",
      "2023-12-06 14:21:53,429 : INFO : EPOCH 18: training on 99524 raw words (60391 effective words) took 0.2s, 319349 effective words/s\n",
      "2023-12-06 14:21:53,614 : INFO : EPOCH 19: training on 99524 raw words (60387 effective words) took 0.2s, 334162 effective words/s\n",
      "2023-12-06 14:21:53,799 : INFO : EPOCH 20: training on 99524 raw words (60414 effective words) took 0.2s, 333904 effective words/s\n",
      "2023-12-06 14:21:53,984 : INFO : EPOCH 21: training on 99524 raw words (60396 effective words) took 0.2s, 333989 effective words/s\n",
      "2023-12-06 14:21:54,169 : INFO : EPOCH 22: training on 99524 raw words (60469 effective words) took 0.2s, 335883 effective words/s\n",
      "2023-12-06 14:21:54,353 : INFO : EPOCH 23: training on 99524 raw words (60307 effective words) took 0.2s, 333601 effective words/s\n",
      "2023-12-06 14:21:54,547 : INFO : EPOCH 24: training on 99524 raw words (60342 effective words) took 0.2s, 317892 effective words/s\n",
      "2023-12-06 14:21:54,733 : INFO : EPOCH 25: training on 99524 raw words (60344 effective words) took 0.2s, 331047 effective words/s\n",
      "2023-12-06 14:21:54,920 : INFO : EPOCH 26: training on 99524 raw words (60439 effective words) took 0.2s, 332241 effective words/s\n",
      "2023-12-06 14:21:55,106 : INFO : EPOCH 27: training on 99524 raw words (60353 effective words) took 0.2s, 331441 effective words/s\n",
      "2023-12-06 14:21:55,293 : INFO : EPOCH 28: training on 99524 raw words (60372 effective words) took 0.2s, 329409 effective words/s\n",
      "2023-12-06 14:21:55,490 : INFO : EPOCH 29: training on 99524 raw words (60488 effective words) took 0.2s, 314833 effective words/s\n",
      "2023-12-06 14:21:55,491 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812271 effective words) took 5.6s, 321793 effective words/s', 'datetime': '2023-12-06T14:21:55.491009', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:21:55,491 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:21:55.491009', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 10%|         | 50/486 [08:17<1:02:34,  8.61s/it]2023-12-06 14:21:58,785 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:21:58,785 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:21:58,805 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:21:58,806 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:21:58,811 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:21:58.811105', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:21:58,811 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:21:58.811105', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:21:58,816 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:21:58,816 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:21:58,817 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:21:58.817104', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:21:58,823 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:21:58,823 : INFO : resetting layer weights\n",
      "2023-12-06 14:21:58,826 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:21:58.826737', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:21:59,071 : INFO : EPOCH 0: training on 99524 raw words (60410 effective words) took 0.2s, 251313 effective words/s\n",
      "2023-12-06 14:21:59,311 : INFO : EPOCH 1: training on 99524 raw words (60385 effective words) took 0.2s, 255773 effective words/s\n",
      "2023-12-06 14:21:59,562 : INFO : EPOCH 2: training on 99524 raw words (60431 effective words) took 0.2s, 245459 effective words/s\n",
      "2023-12-06 14:21:59,807 : INFO : EPOCH 3: training on 99524 raw words (60592 effective words) took 0.2s, 251043 effective words/s\n",
      "2023-12-06 14:22:00,053 : INFO : EPOCH 4: training on 99524 raw words (60348 effective words) took 0.2s, 248974 effective words/s\n",
      "2023-12-06 14:22:00,304 : INFO : EPOCH 5: training on 99524 raw words (60342 effective words) took 0.2s, 245447 effective words/s\n",
      "2023-12-06 14:22:00,549 : INFO : EPOCH 6: training on 99524 raw words (60482 effective words) took 0.2s, 251944 effective words/s\n",
      "2023-12-06 14:22:00,793 : INFO : EPOCH 7: training on 99524 raw words (60347 effective words) took 0.2s, 252093 effective words/s\n",
      "2023-12-06 14:22:01,039 : INFO : EPOCH 8: training on 99524 raw words (60449 effective words) took 0.2s, 249201 effective words/s\n",
      "2023-12-06 14:22:01,284 : INFO : EPOCH 9: training on 99524 raw words (60324 effective words) took 0.2s, 250967 effective words/s\n",
      "2023-12-06 14:22:01,532 : INFO : EPOCH 10: training on 99524 raw words (60329 effective words) took 0.2s, 247289 effective words/s\n",
      "2023-12-06 14:22:01,779 : INFO : EPOCH 11: training on 99524 raw words (60430 effective words) took 0.2s, 250022 effective words/s\n",
      "2023-12-06 14:22:02,025 : INFO : EPOCH 12: training on 99524 raw words (60475 effective words) took 0.2s, 249800 effective words/s\n",
      "2023-12-06 14:22:02,265 : INFO : EPOCH 13: training on 99524 raw words (60373 effective words) took 0.2s, 255366 effective words/s\n",
      "2023-12-06 14:22:02,514 : INFO : EPOCH 14: training on 99524 raw words (60395 effective words) took 0.2s, 247738 effective words/s\n",
      "2023-12-06 14:22:02,761 : INFO : EPOCH 15: training on 99524 raw words (60376 effective words) took 0.2s, 247910 effective words/s\n",
      "2023-12-06 14:22:03,004 : INFO : EPOCH 16: training on 99524 raw words (60400 effective words) took 0.2s, 253420 effective words/s\n",
      "2023-12-06 14:22:03,247 : INFO : EPOCH 17: training on 99524 raw words (60346 effective words) took 0.2s, 252331 effective words/s\n",
      "2023-12-06 14:22:03,495 : INFO : EPOCH 18: training on 99524 raw words (60347 effective words) took 0.2s, 247878 effective words/s\n",
      "2023-12-06 14:22:03,743 : INFO : EPOCH 19: training on 99524 raw words (60385 effective words) took 0.2s, 247194 effective words/s\n",
      "2023-12-06 14:22:03,991 : INFO : EPOCH 20: training on 99524 raw words (60441 effective words) took 0.2s, 248582 effective words/s\n",
      "2023-12-06 14:22:04,231 : INFO : EPOCH 21: training on 99524 raw words (60132 effective words) took 0.2s, 254238 effective words/s\n",
      "2023-12-06 14:22:04,474 : INFO : EPOCH 22: training on 99524 raw words (60387 effective words) took 0.2s, 254119 effective words/s\n",
      "2023-12-06 14:22:04,722 : INFO : EPOCH 23: training on 99524 raw words (60319 effective words) took 0.2s, 247512 effective words/s\n",
      "2023-12-06 14:22:04,967 : INFO : EPOCH 24: training on 99524 raw words (60197 effective words) took 0.2s, 249844 effective words/s\n",
      "2023-12-06 14:22:05,212 : INFO : EPOCH 25: training on 99524 raw words (60498 effective words) took 0.2s, 251951 effective words/s\n",
      "2023-12-06 14:22:05,458 : INFO : EPOCH 26: training on 99524 raw words (60479 effective words) took 0.2s, 250002 effective words/s\n",
      "2023-12-06 14:22:05,705 : INFO : EPOCH 27: training on 99524 raw words (60378 effective words) took 0.2s, 249478 effective words/s\n",
      "2023-12-06 14:22:05,948 : INFO : EPOCH 28: training on 99524 raw words (60238 effective words) took 0.2s, 252381 effective words/s\n",
      "2023-12-06 14:22:06,192 : INFO : EPOCH 29: training on 99524 raw words (60375 effective words) took 0.2s, 251686 effective words/s\n",
      "2023-12-06 14:22:06,193 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811410 effective words) took 7.4s, 245903 effective words/s', 'datetime': '2023-12-06T14:22:06.193946', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:22:06,194 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:22:06.194450', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 10%|         | 51/486 [08:28<1:07:15,  9.28s/it]2023-12-06 14:22:09,612 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:22:09,612 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:22:09,632 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:22:09,633 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:22:09,638 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:22:09.638976', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:22:09,638 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:22:09.638976', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:22:09,646 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:22:09,646 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:22:09,647 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:22:09.647485', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:22:09,658 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:22:09,659 : INFO : resetting layer weights\n",
      "2023-12-06 14:22:09,661 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:22:09.661384', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:22:09,897 : INFO : EPOCH 0: training on 99524 raw words (60292 effective words) took 0.2s, 262265 effective words/s\n",
      "2023-12-06 14:22:10,121 : INFO : EPOCH 1: training on 99524 raw words (60503 effective words) took 0.2s, 274610 effective words/s\n",
      "2023-12-06 14:22:10,355 : INFO : EPOCH 2: training on 99524 raw words (60413 effective words) took 0.2s, 262742 effective words/s\n",
      "2023-12-06 14:22:10,582 : INFO : EPOCH 3: training on 99524 raw words (60556 effective words) took 0.2s, 273168 effective words/s\n",
      "2023-12-06 14:22:10,805 : INFO : EPOCH 4: training on 99524 raw words (60475 effective words) took 0.2s, 276384 effective words/s\n",
      "2023-12-06 14:22:11,029 : INFO : EPOCH 5: training on 99524 raw words (60393 effective words) took 0.2s, 274750 effective words/s\n",
      "2023-12-06 14:22:11,253 : INFO : EPOCH 6: training on 99524 raw words (60452 effective words) took 0.2s, 273871 effective words/s\n",
      "2023-12-06 14:22:11,485 : INFO : EPOCH 7: training on 99524 raw words (60310 effective words) took 0.2s, 265950 effective words/s\n",
      "2023-12-06 14:22:11,713 : INFO : EPOCH 8: training on 99524 raw words (60340 effective words) took 0.2s, 269462 effective words/s\n",
      "2023-12-06 14:22:11,935 : INFO : EPOCH 9: training on 99524 raw words (60239 effective words) took 0.2s, 275968 effective words/s\n",
      "2023-12-06 14:22:12,157 : INFO : EPOCH 10: training on 99524 raw words (60233 effective words) took 0.2s, 278156 effective words/s\n",
      "2023-12-06 14:22:12,388 : INFO : EPOCH 11: training on 99524 raw words (60494 effective words) took 0.2s, 265748 effective words/s\n",
      "2023-12-06 14:22:12,615 : INFO : EPOCH 12: training on 99524 raw words (60331 effective words) took 0.2s, 271120 effective words/s\n",
      "2023-12-06 14:22:12,837 : INFO : EPOCH 13: training on 99524 raw words (60406 effective words) took 0.2s, 277102 effective words/s\n",
      "2023-12-06 14:22:13,059 : INFO : EPOCH 14: training on 99524 raw words (60484 effective words) took 0.2s, 277325 effective words/s\n",
      "2023-12-06 14:22:13,286 : INFO : EPOCH 15: training on 99524 raw words (60135 effective words) took 0.2s, 269884 effective words/s\n",
      "2023-12-06 14:22:13,517 : INFO : EPOCH 16: training on 99524 raw words (60309 effective words) took 0.2s, 266371 effective words/s\n",
      "2023-12-06 14:22:13,743 : INFO : EPOCH 17: training on 99524 raw words (60449 effective words) took 0.2s, 272659 effective words/s\n",
      "2023-12-06 14:22:13,974 : INFO : EPOCH 18: training on 99524 raw words (60458 effective words) took 0.2s, 266905 effective words/s\n",
      "2023-12-06 14:22:14,198 : INFO : EPOCH 19: training on 99524 raw words (60451 effective words) took 0.2s, 275662 effective words/s\n",
      "2023-12-06 14:22:14,428 : INFO : EPOCH 20: training on 99524 raw words (60462 effective words) took 0.2s, 267950 effective words/s\n",
      "2023-12-06 14:22:14,650 : INFO : EPOCH 21: training on 99524 raw words (60235 effective words) took 0.2s, 275799 effective words/s\n",
      "2023-12-06 14:22:14,870 : INFO : EPOCH 22: training on 99524 raw words (60361 effective words) took 0.2s, 280119 effective words/s\n",
      "2023-12-06 14:22:15,093 : INFO : EPOCH 23: training on 99524 raw words (60385 effective words) took 0.2s, 276548 effective words/s\n",
      "2023-12-06 14:22:15,322 : INFO : EPOCH 24: training on 99524 raw words (60287 effective words) took 0.2s, 268152 effective words/s\n",
      "2023-12-06 14:22:15,545 : INFO : EPOCH 25: training on 99524 raw words (60399 effective words) took 0.2s, 276000 effective words/s\n",
      "2023-12-06 14:22:15,769 : INFO : EPOCH 26: training on 99524 raw words (60426 effective words) took 0.2s, 275875 effective words/s\n",
      "2023-12-06 14:22:15,994 : INFO : EPOCH 27: training on 99524 raw words (60592 effective words) took 0.2s, 274813 effective words/s\n",
      "2023-12-06 14:22:16,226 : INFO : EPOCH 28: training on 99524 raw words (60181 effective words) took 0.2s, 263616 effective words/s\n",
      "2023-12-06 14:22:16,452 : INFO : EPOCH 29: training on 99524 raw words (60293 effective words) took 0.2s, 272116 effective words/s\n",
      "2023-12-06 14:22:16,677 : INFO : EPOCH 30: training on 99524 raw words (60311 effective words) took 0.2s, 272382 effective words/s\n",
      "2023-12-06 14:22:16,901 : INFO : EPOCH 31: training on 99524 raw words (60390 effective words) took 0.2s, 275741 effective words/s\n",
      "2023-12-06 14:22:17,132 : INFO : EPOCH 32: training on 99524 raw words (60522 effective words) took 0.2s, 266682 effective words/s\n",
      "2023-12-06 14:22:17,359 : INFO : EPOCH 33: training on 99524 raw words (60409 effective words) took 0.2s, 272043 effective words/s\n",
      "2023-12-06 14:22:17,585 : INFO : EPOCH 34: training on 99524 raw words (60293 effective words) took 0.2s, 270559 effective words/s\n",
      "2023-12-06 14:22:17,808 : INFO : EPOCH 35: training on 99524 raw words (60444 effective words) took 0.2s, 277696 effective words/s\n",
      "2023-12-06 14:22:18,038 : INFO : EPOCH 36: training on 99524 raw words (60559 effective words) took 0.2s, 267409 effective words/s\n",
      "2023-12-06 14:22:18,261 : INFO : EPOCH 37: training on 99524 raw words (60342 effective words) took 0.2s, 275753 effective words/s\n",
      "2023-12-06 14:22:18,488 : INFO : EPOCH 38: training on 99524 raw words (60399 effective words) took 0.2s, 272118 effective words/s\n",
      "2023-12-06 14:22:18,714 : INFO : EPOCH 39: training on 99524 raw words (60411 effective words) took 0.2s, 272372 effective words/s\n",
      "2023-12-06 14:22:18,944 : INFO : EPOCH 40: training on 99524 raw words (60250 effective words) took 0.2s, 266180 effective words/s\n",
      "2023-12-06 14:22:19,170 : INFO : EPOCH 41: training on 99524 raw words (60490 effective words) took 0.2s, 273841 effective words/s\n",
      "2023-12-06 14:22:19,396 : INFO : EPOCH 42: training on 99524 raw words (60374 effective words) took 0.2s, 272034 effective words/s\n",
      "2023-12-06 14:22:19,620 : INFO : EPOCH 43: training on 99524 raw words (60341 effective words) took 0.2s, 274008 effective words/s\n",
      "2023-12-06 14:22:19,859 : INFO : EPOCH 44: training on 99524 raw words (60436 effective words) took 0.2s, 257667 effective words/s\n",
      "2023-12-06 14:22:20,084 : INFO : EPOCH 45: training on 99524 raw words (60460 effective words) took 0.2s, 275175 effective words/s\n",
      "2023-12-06 14:22:20,309 : INFO : EPOCH 46: training on 99524 raw words (60284 effective words) took 0.2s, 272336 effective words/s\n",
      "2023-12-06 14:22:20,540 : INFO : EPOCH 47: training on 99524 raw words (60415 effective words) took 0.2s, 265664 effective words/s\n",
      "2023-12-06 14:22:20,771 : INFO : EPOCH 48: training on 99524 raw words (60488 effective words) took 0.2s, 267614 effective words/s\n",
      "2023-12-06 14:22:20,997 : INFO : EPOCH 49: training on 99524 raw words (60363 effective words) took 0.2s, 272770 effective words/s\n",
      "2023-12-06 14:22:20,998 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3019325 effective words) took 11.3s, 266340 effective words/s', 'datetime': '2023-12-06T14:22:20.998770', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:22:20,998 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:22:20.998770', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 11%|         | 52/486 [08:43<1:19:30, 10.99s/it]2023-12-06 14:22:24,604 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:22:24,605 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:22:24,625 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:22:24,626 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:22:24,630 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:22:24.630306', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:22:24,631 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:22:24.631306', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:22:24,638 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:22:24,638 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:22:24,639 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:22:24.639307', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:22:24,646 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:22:24,647 : INFO : resetting layer weights\n",
      "2023-12-06 14:22:24,648 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:22:24.648229', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:22:24,896 : INFO : EPOCH 0: training on 99524 raw words (60455 effective words) took 0.2s, 248020 effective words/s\n",
      "2023-12-06 14:22:25,137 : INFO : EPOCH 1: training on 99524 raw words (60315 effective words) took 0.2s, 254646 effective words/s\n",
      "2023-12-06 14:22:25,376 : INFO : EPOCH 2: training on 99524 raw words (60327 effective words) took 0.2s, 257499 effective words/s\n",
      "2023-12-06 14:22:25,623 : INFO : EPOCH 3: training on 99524 raw words (60478 effective words) took 0.2s, 249345 effective words/s\n",
      "2023-12-06 14:22:25,864 : INFO : EPOCH 4: training on 99524 raw words (60344 effective words) took 0.2s, 254646 effective words/s\n",
      "2023-12-06 14:22:26,107 : INFO : EPOCH 5: training on 99524 raw words (60395 effective words) took 0.2s, 252915 effective words/s\n",
      "2023-12-06 14:22:26,349 : INFO : EPOCH 6: training on 99524 raw words (60263 effective words) took 0.2s, 254746 effective words/s\n",
      "2023-12-06 14:22:26,586 : INFO : EPOCH 7: training on 99524 raw words (60404 effective words) took 0.2s, 258887 effective words/s\n",
      "2023-12-06 14:22:26,823 : INFO : EPOCH 8: training on 99524 raw words (60413 effective words) took 0.2s, 259910 effective words/s\n",
      "2023-12-06 14:22:27,067 : INFO : EPOCH 9: training on 99524 raw words (60474 effective words) took 0.2s, 252580 effective words/s\n",
      "2023-12-06 14:22:27,312 : INFO : EPOCH 10: training on 99524 raw words (60258 effective words) took 0.2s, 251160 effective words/s\n",
      "2023-12-06 14:22:27,552 : INFO : EPOCH 11: training on 99524 raw words (60307 effective words) took 0.2s, 255760 effective words/s\n",
      "2023-12-06 14:22:27,797 : INFO : EPOCH 12: training on 99524 raw words (60469 effective words) took 0.2s, 251130 effective words/s\n",
      "2023-12-06 14:22:28,040 : INFO : EPOCH 13: training on 99524 raw words (60277 effective words) took 0.2s, 253404 effective words/s\n",
      "2023-12-06 14:22:28,278 : INFO : EPOCH 14: training on 99524 raw words (60304 effective words) took 0.2s, 258092 effective words/s\n",
      "2023-12-06 14:22:28,517 : INFO : EPOCH 15: training on 99524 raw words (60446 effective words) took 0.2s, 256637 effective words/s\n",
      "2023-12-06 14:22:28,757 : INFO : EPOCH 16: training on 99524 raw words (60358 effective words) took 0.2s, 256653 effective words/s\n",
      "2023-12-06 14:22:29,002 : INFO : EPOCH 17: training on 99524 raw words (60584 effective words) took 0.2s, 252021 effective words/s\n",
      "2023-12-06 14:22:29,239 : INFO : EPOCH 18: training on 99524 raw words (60304 effective words) took 0.2s, 258575 effective words/s\n",
      "2023-12-06 14:22:29,477 : INFO : EPOCH 19: training on 99524 raw words (60413 effective words) took 0.2s, 259662 effective words/s\n",
      "2023-12-06 14:22:29,717 : INFO : EPOCH 20: training on 99524 raw words (60399 effective words) took 0.2s, 256636 effective words/s\n",
      "2023-12-06 14:22:29,962 : INFO : EPOCH 21: training on 99524 raw words (60451 effective words) took 0.2s, 251309 effective words/s\n",
      "2023-12-06 14:22:30,206 : INFO : EPOCH 22: training on 99524 raw words (60368 effective words) took 0.2s, 252477 effective words/s\n",
      "2023-12-06 14:22:30,444 : INFO : EPOCH 23: training on 99524 raw words (60371 effective words) took 0.2s, 258005 effective words/s\n",
      "2023-12-06 14:22:30,682 : INFO : EPOCH 24: training on 99524 raw words (60294 effective words) took 0.2s, 257715 effective words/s\n",
      "2023-12-06 14:22:30,924 : INFO : EPOCH 25: training on 99524 raw words (60381 effective words) took 0.2s, 254040 effective words/s\n",
      "2023-12-06 14:22:31,167 : INFO : EPOCH 26: training on 99524 raw words (60412 effective words) took 0.2s, 253512 effective words/s\n",
      "2023-12-06 14:22:31,406 : INFO : EPOCH 27: training on 99524 raw words (60318 effective words) took 0.2s, 257762 effective words/s\n",
      "2023-12-06 14:22:31,647 : INFO : EPOCH 28: training on 99524 raw words (60423 effective words) took 0.2s, 255586 effective words/s\n",
      "2023-12-06 14:22:31,887 : INFO : EPOCH 29: training on 99524 raw words (60184 effective words) took 0.2s, 254224 effective words/s\n",
      "2023-12-06 14:22:32,124 : INFO : EPOCH 30: training on 99524 raw words (60627 effective words) took 0.2s, 261026 effective words/s\n",
      "2023-12-06 14:22:32,366 : INFO : EPOCH 31: training on 99524 raw words (60283 effective words) took 0.2s, 253896 effective words/s\n",
      "2023-12-06 14:22:32,605 : INFO : EPOCH 32: training on 99524 raw words (60433 effective words) took 0.2s, 257274 effective words/s\n",
      "2023-12-06 14:22:32,854 : INFO : EPOCH 33: training on 99524 raw words (60319 effective words) took 0.2s, 246839 effective words/s\n",
      "2023-12-06 14:22:33,099 : INFO : EPOCH 34: training on 99524 raw words (60415 effective words) took 0.2s, 250899 effective words/s\n",
      "2023-12-06 14:22:33,339 : INFO : EPOCH 35: training on 99524 raw words (60529 effective words) took 0.2s, 257245 effective words/s\n",
      "2023-12-06 14:22:33,581 : INFO : EPOCH 36: training on 99524 raw words (60393 effective words) took 0.2s, 253706 effective words/s\n",
      "2023-12-06 14:22:33,829 : INFO : EPOCH 37: training on 99524 raw words (60285 effective words) took 0.2s, 246825 effective words/s\n",
      "2023-12-06 14:22:34,069 : INFO : EPOCH 38: training on 99524 raw words (60427 effective words) took 0.2s, 257598 effective words/s\n",
      "2023-12-06 14:22:34,308 : INFO : EPOCH 39: training on 99524 raw words (60267 effective words) took 0.2s, 255993 effective words/s\n",
      "2023-12-06 14:22:34,547 : INFO : EPOCH 40: training on 99524 raw words (60418 effective words) took 0.2s, 257293 effective words/s\n",
      "2023-12-06 14:22:34,789 : INFO : EPOCH 41: training on 99524 raw words (60424 effective words) took 0.2s, 254776 effective words/s\n",
      "2023-12-06 14:22:35,029 : INFO : EPOCH 42: training on 99524 raw words (60466 effective words) took 0.2s, 257094 effective words/s\n",
      "2023-12-06 14:22:35,269 : INFO : EPOCH 43: training on 99524 raw words (60512 effective words) took 0.2s, 255709 effective words/s\n",
      "2023-12-06 14:22:35,508 : INFO : EPOCH 44: training on 99524 raw words (60444 effective words) took 0.2s, 258560 effective words/s\n",
      "2023-12-06 14:22:35,754 : INFO : EPOCH 45: training on 99524 raw words (60450 effective words) took 0.2s, 250126 effective words/s\n",
      "2023-12-06 14:22:35,990 : INFO : EPOCH 46: training on 99524 raw words (60232 effective words) took 0.2s, 259676 effective words/s\n",
      "2023-12-06 14:22:36,227 : INFO : EPOCH 47: training on 99524 raw words (60366 effective words) took 0.2s, 259330 effective words/s\n",
      "2023-12-06 14:22:36,468 : INFO : EPOCH 48: training on 99524 raw words (60420 effective words) took 0.2s, 255600 effective words/s\n",
      "2023-12-06 14:22:36,712 : INFO : EPOCH 49: training on 99524 raw words (60301 effective words) took 0.2s, 250838 effective words/s\n",
      "2023-12-06 14:22:36,713 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3019200 effective words) took 12.1s, 250251 effective words/s', 'datetime': '2023-12-06T14:22:36.713988', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:22:36,713 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:22:36.713988', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 11%|         | 53/486 [08:59<1:30:11, 12.50s/it]2023-12-06 14:22:40,622 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:22:40,622 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:22:40,643 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:22:40,643 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:22:40,647 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:22:40.647562', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:22:40,648 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:22:40.648573', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:22:40,654 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:22:40,655 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:22:40,655 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:22:40.655866', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:22:40,667 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:22:40,667 : INFO : resetting layer weights\n",
      "2023-12-06 14:22:40,670 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:22:40.670877', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:22:40,925 : INFO : EPOCH 0: training on 99524 raw words (60450 effective words) took 0.2s, 242774 effective words/s\n",
      "2023-12-06 14:22:41,168 : INFO : EPOCH 1: training on 99524 raw words (60195 effective words) took 0.2s, 252803 effective words/s\n",
      "2023-12-06 14:22:41,411 : INFO : EPOCH 2: training on 99524 raw words (60359 effective words) took 0.2s, 251586 effective words/s\n",
      "2023-12-06 14:22:41,659 : INFO : EPOCH 3: training on 99524 raw words (60475 effective words) took 0.2s, 249448 effective words/s\n",
      "2023-12-06 14:22:41,908 : INFO : EPOCH 4: training on 99524 raw words (60388 effective words) took 0.2s, 246168 effective words/s\n",
      "2023-12-06 14:22:42,153 : INFO : EPOCH 5: training on 99524 raw words (60410 effective words) took 0.2s, 251865 effective words/s\n",
      "2023-12-06 14:22:42,395 : INFO : EPOCH 6: training on 99524 raw words (60435 effective words) took 0.2s, 254064 effective words/s\n",
      "2023-12-06 14:22:42,642 : INFO : EPOCH 7: training on 99524 raw words (60217 effective words) took 0.2s, 247909 effective words/s\n",
      "2023-12-06 14:22:42,891 : INFO : EPOCH 8: training on 99524 raw words (60473 effective words) took 0.2s, 247568 effective words/s\n",
      "2023-12-06 14:22:43,134 : INFO : EPOCH 9: training on 99524 raw words (60222 effective words) took 0.2s, 251975 effective words/s\n",
      "2023-12-06 14:22:43,379 : INFO : EPOCH 10: training on 99524 raw words (60636 effective words) took 0.2s, 251495 effective words/s\n",
      "2023-12-06 14:22:43,624 : INFO : EPOCH 11: training on 99524 raw words (60428 effective words) took 0.2s, 251973 effective words/s\n",
      "2023-12-06 14:22:43,872 : INFO : EPOCH 12: training on 99524 raw words (60438 effective words) took 0.2s, 247341 effective words/s\n",
      "2023-12-06 14:22:44,117 : INFO : EPOCH 13: training on 99524 raw words (60461 effective words) took 0.2s, 251585 effective words/s\n",
      "2023-12-06 14:22:44,358 : INFO : EPOCH 14: training on 99524 raw words (60498 effective words) took 0.2s, 255491 effective words/s\n",
      "2023-12-06 14:22:44,602 : INFO : EPOCH 15: training on 99524 raw words (60358 effective words) took 0.2s, 252995 effective words/s\n",
      "2023-12-06 14:22:44,845 : INFO : EPOCH 16: training on 99524 raw words (60385 effective words) took 0.2s, 253094 effective words/s\n",
      "2023-12-06 14:22:45,092 : INFO : EPOCH 17: training on 99524 raw words (60262 effective words) took 0.2s, 248740 effective words/s\n",
      "2023-12-06 14:22:45,336 : INFO : EPOCH 18: training on 99524 raw words (60478 effective words) took 0.2s, 251528 effective words/s\n",
      "2023-12-06 14:22:45,582 : INFO : EPOCH 19: training on 99524 raw words (60550 effective words) took 0.2s, 251015 effective words/s\n",
      "2023-12-06 14:22:45,825 : INFO : EPOCH 20: training on 99524 raw words (60398 effective words) took 0.2s, 252826 effective words/s\n",
      "2023-12-06 14:22:46,071 : INFO : EPOCH 21: training on 99524 raw words (60460 effective words) took 0.2s, 250399 effective words/s\n",
      "2023-12-06 14:22:46,315 : INFO : EPOCH 22: training on 99524 raw words (60454 effective words) took 0.2s, 253359 effective words/s\n",
      "2023-12-06 14:22:46,557 : INFO : EPOCH 23: training on 99524 raw words (60304 effective words) took 0.2s, 252534 effective words/s\n",
      "2023-12-06 14:22:46,800 : INFO : EPOCH 24: training on 99524 raw words (60290 effective words) took 0.2s, 252094 effective words/s\n",
      "2023-12-06 14:22:47,045 : INFO : EPOCH 25: training on 99524 raw words (60464 effective words) took 0.2s, 252258 effective words/s\n",
      "2023-12-06 14:22:47,288 : INFO : EPOCH 26: training on 99524 raw words (60311 effective words) took 0.2s, 251477 effective words/s\n",
      "2023-12-06 14:22:47,531 : INFO : EPOCH 27: training on 99524 raw words (60434 effective words) took 0.2s, 253802 effective words/s\n",
      "2023-12-06 14:22:47,779 : INFO : EPOCH 28: training on 99524 raw words (60494 effective words) took 0.2s, 249330 effective words/s\n",
      "2023-12-06 14:22:48,031 : INFO : EPOCH 29: training on 99524 raw words (60339 effective words) took 0.2s, 244004 effective words/s\n",
      "2023-12-06 14:22:48,279 : INFO : EPOCH 30: training on 99524 raw words (60412 effective words) took 0.2s, 248467 effective words/s\n",
      "2023-12-06 14:22:48,524 : INFO : EPOCH 31: training on 99524 raw words (60572 effective words) took 0.2s, 251512 effective words/s\n",
      "2023-12-06 14:22:48,770 : INFO : EPOCH 32: training on 99524 raw words (60424 effective words) took 0.2s, 249841 effective words/s\n",
      "2023-12-06 14:22:49,023 : INFO : EPOCH 33: training on 99524 raw words (60276 effective words) took 0.2s, 242774 effective words/s\n",
      "2023-12-06 14:22:49,265 : INFO : EPOCH 34: training on 99524 raw words (60449 effective words) took 0.2s, 253765 effective words/s\n",
      "2023-12-06 14:22:49,511 : INFO : EPOCH 35: training on 99524 raw words (60220 effective words) took 0.2s, 249358 effective words/s\n",
      "2023-12-06 14:22:49,761 : INFO : EPOCH 36: training on 99524 raw words (60449 effective words) took 0.2s, 246643 effective words/s\n",
      "2023-12-06 14:22:50,011 : INFO : EPOCH 37: training on 99524 raw words (60508 effective words) took 0.2s, 246085 effective words/s\n",
      "2023-12-06 14:22:50,258 : INFO : EPOCH 38: training on 99524 raw words (60425 effective words) took 0.2s, 249003 effective words/s\n",
      "2023-12-06 14:22:50,499 : INFO : EPOCH 39: training on 99524 raw words (60479 effective words) took 0.2s, 255383 effective words/s\n",
      "2023-12-06 14:22:50,743 : INFO : EPOCH 40: training on 99524 raw words (60360 effective words) took 0.2s, 253114 effective words/s\n",
      "2023-12-06 14:22:50,987 : INFO : EPOCH 41: training on 99524 raw words (60466 effective words) took 0.2s, 251204 effective words/s\n",
      "2023-12-06 14:22:51,229 : INFO : EPOCH 42: training on 99524 raw words (60393 effective words) took 0.2s, 254798 effective words/s\n",
      "2023-12-06 14:22:51,470 : INFO : EPOCH 43: training on 99524 raw words (60479 effective words) took 0.2s, 255774 effective words/s\n",
      "2023-12-06 14:22:51,718 : INFO : EPOCH 44: training on 99524 raw words (60466 effective words) took 0.2s, 248308 effective words/s\n",
      "2023-12-06 14:22:51,965 : INFO : EPOCH 45: training on 99524 raw words (60310 effective words) took 0.2s, 249339 effective words/s\n",
      "2023-12-06 14:22:52,216 : INFO : EPOCH 46: training on 99524 raw words (60376 effective words) took 0.2s, 244350 effective words/s\n",
      "2023-12-06 14:22:52,462 : INFO : EPOCH 47: training on 99524 raw words (60358 effective words) took 0.2s, 250436 effective words/s\n",
      "2023-12-06 14:22:52,706 : INFO : EPOCH 48: training on 99524 raw words (60237 effective words) took 0.2s, 250176 effective words/s\n",
      "2023-12-06 14:22:52,951 : INFO : EPOCH 49: training on 99524 raw words (60329 effective words) took 0.2s, 251069 effective words/s\n",
      "2023-12-06 14:22:52,951 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3020054 effective words) took 12.3s, 245924 effective words/s', 'datetime': '2023-12-06T14:22:52.951866', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:22:52,953 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:22:52.953297', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 11%|         | 54/486 [09:15<1:38:31, 13.68s/it]2023-12-06 14:22:57,074 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:22:57,075 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:22:57,094 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:22:57,095 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:22:57,102 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:22:57.102582', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:22:57,102 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:22:57.102582', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:22:57,113 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:22:57,114 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:22:57,114 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:22:57.114492', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:22:57,125 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:22:57,125 : INFO : resetting layer weights\n",
      "2023-12-06 14:22:57,127 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:22:57.127495', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:22:57,372 : INFO : EPOCH 0: training on 99524 raw words (65419 effective words) took 0.2s, 273307 effective words/s\n",
      "2023-12-06 14:22:57,605 : INFO : EPOCH 1: training on 99524 raw words (65639 effective words) took 0.2s, 287595 effective words/s\n",
      "2023-12-06 14:22:57,837 : INFO : EPOCH 2: training on 99524 raw words (65654 effective words) took 0.2s, 287031 effective words/s\n",
      "2023-12-06 14:22:58,071 : INFO : EPOCH 3: training on 99524 raw words (65476 effective words) took 0.2s, 286055 effective words/s\n",
      "2023-12-06 14:22:58,309 : INFO : EPOCH 4: training on 99524 raw words (65445 effective words) took 0.2s, 279965 effective words/s\n",
      "2023-12-06 14:22:58,552 : INFO : EPOCH 5: training on 99524 raw words (65591 effective words) took 0.2s, 275283 effective words/s\n",
      "2023-12-06 14:22:58,785 : INFO : EPOCH 6: training on 99524 raw words (65462 effective words) took 0.2s, 285121 effective words/s\n",
      "2023-12-06 14:22:59,019 : INFO : EPOCH 7: training on 99524 raw words (65554 effective words) took 0.2s, 285661 effective words/s\n",
      "2023-12-06 14:22:59,257 : INFO : EPOCH 8: training on 99524 raw words (65571 effective words) took 0.2s, 281134 effective words/s\n",
      "2023-12-06 14:22:59,487 : INFO : EPOCH 9: training on 99524 raw words (65471 effective words) took 0.2s, 290162 effective words/s\n",
      "2023-12-06 14:22:59,488 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655282 effective words) took 2.4s, 277680 effective words/s', 'datetime': '2023-12-06T14:22:59.488395', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:22:59,488 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:22:59.488395', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 11%|        | 55/486 [09:20<1:19:44, 11.10s/it]2023-12-06 14:23:02,149 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:23:02,150 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:23:02,170 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:23:02,171 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:23:02,175 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:23:02.175201', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:23:02,176 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:23:02.176200', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:23:02,184 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:23:02,184 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:23:02,185 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:23:02.185197', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:23:02,199 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:23:02,201 : INFO : resetting layer weights\n",
      "2023-12-06 14:23:02,204 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:23:02.204122', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:23:02,462 : INFO : EPOCH 0: training on 99524 raw words (65483 effective words) took 0.3s, 259416 effective words/s\n",
      "2023-12-06 14:23:02,707 : INFO : EPOCH 1: training on 99524 raw words (65584 effective words) took 0.2s, 271474 effective words/s\n",
      "2023-12-06 14:23:02,952 : INFO : EPOCH 2: training on 99524 raw words (65410 effective words) took 0.2s, 272573 effective words/s\n",
      "2023-12-06 14:23:03,200 : INFO : EPOCH 3: training on 99524 raw words (65546 effective words) took 0.2s, 268871 effective words/s\n",
      "2023-12-06 14:23:03,449 : INFO : EPOCH 4: training on 99524 raw words (65466 effective words) took 0.2s, 267008 effective words/s\n",
      "2023-12-06 14:23:03,698 : INFO : EPOCH 5: training on 99524 raw words (65588 effective words) took 0.2s, 268567 effective words/s\n",
      "2023-12-06 14:23:03,942 : INFO : EPOCH 6: training on 99524 raw words (65413 effective words) took 0.2s, 272239 effective words/s\n",
      "2023-12-06 14:23:04,190 : INFO : EPOCH 7: training on 99524 raw words (65672 effective words) took 0.2s, 270373 effective words/s\n",
      "2023-12-06 14:23:04,441 : INFO : EPOCH 8: training on 99524 raw words (65504 effective words) took 0.2s, 265076 effective words/s\n",
      "2023-12-06 14:23:04,686 : INFO : EPOCH 9: training on 99524 raw words (65612 effective words) took 0.2s, 271670 effective words/s\n",
      "2023-12-06 14:23:04,688 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655278 effective words) took 2.5s, 263861 effective words/s', 'datetime': '2023-12-06T14:23:04.688270', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:23:04,688 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:23:04.688270', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 12%|        | 56/486 [09:26<1:06:59,  9.35s/it]2023-12-06 14:23:07,401 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:23:07,402 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:23:07,422 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:23:07,423 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:23:07,428 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:23:07.428329', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:23:07,429 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:23:07.429329', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:23:07,436 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:23:07,437 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:23:07,438 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:23:07.437331', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:23:07,451 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:23:07,452 : INFO : resetting layer weights\n",
      "2023-12-06 14:23:07,454 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:23:07.454601', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:23:07,707 : INFO : EPOCH 0: training on 99524 raw words (65510 effective words) took 0.2s, 263109 effective words/s\n",
      "2023-12-06 14:23:07,957 : INFO : EPOCH 1: training on 99524 raw words (65379 effective words) took 0.2s, 266841 effective words/s\n",
      "2023-12-06 14:23:08,204 : INFO : EPOCH 2: training on 99524 raw words (65465 effective words) took 0.2s, 269932 effective words/s\n",
      "2023-12-06 14:23:08,454 : INFO : EPOCH 3: training on 99524 raw words (65438 effective words) took 0.2s, 266316 effective words/s\n",
      "2023-12-06 14:23:08,704 : INFO : EPOCH 4: training on 99524 raw words (65497 effective words) took 0.2s, 267129 effective words/s\n",
      "2023-12-06 14:23:08,952 : INFO : EPOCH 5: training on 99524 raw words (65615 effective words) took 0.2s, 268879 effective words/s\n",
      "2023-12-06 14:23:09,203 : INFO : EPOCH 6: training on 99524 raw words (65549 effective words) took 0.2s, 266563 effective words/s\n",
      "2023-12-06 14:23:09,452 : INFO : EPOCH 7: training on 99524 raw words (65386 effective words) took 0.2s, 266733 effective words/s\n",
      "2023-12-06 14:23:09,703 : INFO : EPOCH 8: training on 99524 raw words (65560 effective words) took 0.2s, 265450 effective words/s\n",
      "2023-12-06 14:23:09,953 : INFO : EPOCH 9: training on 99524 raw words (65501 effective words) took 0.2s, 267842 effective words/s\n",
      "2023-12-06 14:23:09,954 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (654900 effective words) took 2.5s, 262025 effective words/s', 'datetime': '2023-12-06T14:23:09.954257', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:23:09,954 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:23:09.954257', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 12%|        | 57/486 [09:31<58:06,  8.13s/it]  2023-12-06 14:23:12,683 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:23:12,683 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:23:12,704 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:23:12,705 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:23:12,712 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:23:12.712924', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:23:12,713 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:23:12.713929', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:23:12,724 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:23:12,724 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:23:12,725 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:23:12.725930', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:23:12,740 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:23:12,741 : INFO : resetting layer weights\n",
      "2023-12-06 14:23:12,743 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:23:12.743442', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:23:12,998 : INFO : EPOCH 0: training on 99524 raw words (65571 effective words) took 0.2s, 263751 effective words/s\n",
      "2023-12-06 14:23:13,232 : INFO : EPOCH 1: training on 99524 raw words (65547 effective words) took 0.2s, 285194 effective words/s\n",
      "2023-12-06 14:23:13,466 : INFO : EPOCH 2: training on 99524 raw words (65752 effective words) took 0.2s, 285950 effective words/s\n",
      "2023-12-06 14:23:13,699 : INFO : EPOCH 3: training on 99524 raw words (65452 effective words) took 0.2s, 286244 effective words/s\n",
      "2023-12-06 14:23:13,932 : INFO : EPOCH 4: training on 99524 raw words (65619 effective words) took 0.2s, 287092 effective words/s\n",
      "2023-12-06 14:23:14,173 : INFO : EPOCH 5: training on 99524 raw words (65390 effective words) took 0.2s, 276913 effective words/s\n",
      "2023-12-06 14:23:14,406 : INFO : EPOCH 6: training on 99524 raw words (65530 effective words) took 0.2s, 287178 effective words/s\n",
      "2023-12-06 14:23:14,633 : INFO : EPOCH 7: training on 99524 raw words (65497 effective words) took 0.2s, 293142 effective words/s\n",
      "2023-12-06 14:23:14,862 : INFO : EPOCH 8: training on 99524 raw words (65582 effective words) took 0.2s, 291010 effective words/s\n",
      "2023-12-06 14:23:15,099 : INFO : EPOCH 9: training on 99524 raw words (65469 effective words) took 0.2s, 283526 effective words/s\n",
      "2023-12-06 14:23:15,337 : INFO : EPOCH 10: training on 99524 raw words (65411 effective words) took 0.2s, 279747 effective words/s\n",
      "2023-12-06 14:23:15,570 : INFO : EPOCH 11: training on 99524 raw words (65504 effective words) took 0.2s, 286298 effective words/s\n",
      "2023-12-06 14:23:15,804 : INFO : EPOCH 12: training on 99524 raw words (65427 effective words) took 0.2s, 284384 effective words/s\n",
      "2023-12-06 14:23:16,034 : INFO : EPOCH 13: training on 99524 raw words (65396 effective words) took 0.2s, 290877 effective words/s\n",
      "2023-12-06 14:23:16,269 : INFO : EPOCH 14: training on 99524 raw words (65555 effective words) took 0.2s, 283582 effective words/s\n",
      "2023-12-06 14:23:16,508 : INFO : EPOCH 15: training on 99524 raw words (65383 effective words) took 0.2s, 278458 effective words/s\n",
      "2023-12-06 14:23:16,742 : INFO : EPOCH 16: training on 99524 raw words (65393 effective words) took 0.2s, 284995 effective words/s\n",
      "2023-12-06 14:23:16,975 : INFO : EPOCH 17: training on 99524 raw words (65567 effective words) took 0.2s, 286797 effective words/s\n",
      "2023-12-06 14:23:17,211 : INFO : EPOCH 18: training on 99524 raw words (65527 effective words) took 0.2s, 282173 effective words/s\n",
      "2023-12-06 14:23:17,447 : INFO : EPOCH 19: training on 99524 raw words (65575 effective words) took 0.2s, 283387 effective words/s\n",
      "2023-12-06 14:23:17,682 : INFO : EPOCH 20: training on 99524 raw words (65512 effective words) took 0.2s, 283854 effective words/s\n",
      "2023-12-06 14:23:17,919 : INFO : EPOCH 21: training on 99524 raw words (65435 effective words) took 0.2s, 281801 effective words/s\n",
      "2023-12-06 14:23:18,149 : INFO : EPOCH 22: training on 99524 raw words (65532 effective words) took 0.2s, 290136 effective words/s\n",
      "2023-12-06 14:23:18,387 : INFO : EPOCH 23: training on 99524 raw words (65519 effective words) took 0.2s, 279128 effective words/s\n",
      "2023-12-06 14:23:18,619 : INFO : EPOCH 24: training on 99524 raw words (65407 effective words) took 0.2s, 287939 effective words/s\n",
      "2023-12-06 14:23:18,850 : INFO : EPOCH 25: training on 99524 raw words (65572 effective words) took 0.2s, 289685 effective words/s\n",
      "2023-12-06 14:23:19,083 : INFO : EPOCH 26: training on 99524 raw words (65485 effective words) took 0.2s, 286288 effective words/s\n",
      "2023-12-06 14:23:19,325 : INFO : EPOCH 27: training on 99524 raw words (65505 effective words) took 0.2s, 275042 effective words/s\n",
      "2023-12-06 14:23:19,556 : INFO : EPOCH 28: training on 99524 raw words (65565 effective words) took 0.2s, 289013 effective words/s\n",
      "2023-12-06 14:23:19,797 : INFO : EPOCH 29: training on 99524 raw words (65554 effective words) took 0.2s, 277716 effective words/s\n",
      "2023-12-06 14:23:19,798 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965233 effective words) took 7.1s, 278636 effective words/s', 'datetime': '2023-12-06T14:23:19.798127', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:23:19,798 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:23:19.798127', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 12%|        | 58/486 [09:41<1:02:33,  8.77s/it]2023-12-06 14:23:22,955 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:23:22,956 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:23:22,976 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:23:22,977 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:23:22,982 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:23:22.982728', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:23:22,982 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:23:22.982728', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:23:22,990 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:23:22,991 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:23:22,992 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:23:22.992046', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:23:23,007 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:23:23,008 : INFO : resetting layer weights\n",
      "2023-12-06 14:23:23,010 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:23:23.010854', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:23:23,268 : INFO : EPOCH 0: training on 99524 raw words (65499 effective words) took 0.3s, 260848 effective words/s\n",
      "2023-12-06 14:23:23,513 : INFO : EPOCH 1: training on 99524 raw words (65608 effective words) took 0.2s, 272453 effective words/s\n",
      "2023-12-06 14:23:23,760 : INFO : EPOCH 2: training on 99524 raw words (65518 effective words) took 0.2s, 269216 effective words/s\n",
      "2023-12-06 14:23:24,008 : INFO : EPOCH 3: training on 99524 raw words (65622 effective words) took 0.2s, 269291 effective words/s\n",
      "2023-12-06 14:23:24,256 : INFO : EPOCH 4: training on 99524 raw words (65572 effective words) took 0.2s, 270204 effective words/s\n",
      "2023-12-06 14:23:24,508 : INFO : EPOCH 5: training on 99524 raw words (65542 effective words) took 0.2s, 264054 effective words/s\n",
      "2023-12-06 14:23:24,758 : INFO : EPOCH 6: training on 99524 raw words (65553 effective words) took 0.2s, 265931 effective words/s\n",
      "2023-12-06 14:23:25,006 : INFO : EPOCH 7: training on 99524 raw words (65588 effective words) took 0.2s, 269386 effective words/s\n",
      "2023-12-06 14:23:25,252 : INFO : EPOCH 8: training on 99524 raw words (65476 effective words) took 0.2s, 271344 effective words/s\n",
      "2023-12-06 14:23:25,499 : INFO : EPOCH 9: training on 99524 raw words (65607 effective words) took 0.2s, 270236 effective words/s\n",
      "2023-12-06 14:23:25,750 : INFO : EPOCH 10: training on 99524 raw words (65657 effective words) took 0.2s, 266647 effective words/s\n",
      "2023-12-06 14:23:26,000 : INFO : EPOCH 11: training on 99524 raw words (65603 effective words) took 0.2s, 267171 effective words/s\n",
      "2023-12-06 14:23:26,246 : INFO : EPOCH 12: training on 99524 raw words (65574 effective words) took 0.2s, 271257 effective words/s\n",
      "2023-12-06 14:23:26,489 : INFO : EPOCH 13: training on 99524 raw words (65505 effective words) took 0.2s, 275595 effective words/s\n",
      "2023-12-06 14:23:26,738 : INFO : EPOCH 14: training on 99524 raw words (65469 effective words) took 0.2s, 266670 effective words/s\n",
      "2023-12-06 14:23:26,986 : INFO : EPOCH 15: training on 99524 raw words (65540 effective words) took 0.2s, 269132 effective words/s\n",
      "2023-12-06 14:23:27,246 : INFO : EPOCH 16: training on 99524 raw words (65373 effective words) took 0.3s, 255900 effective words/s\n",
      "2023-12-06 14:23:27,493 : INFO : EPOCH 17: training on 99524 raw words (65387 effective words) took 0.2s, 269661 effective words/s\n",
      "2023-12-06 14:23:27,746 : INFO : EPOCH 18: training on 99524 raw words (65428 effective words) took 0.2s, 263718 effective words/s\n",
      "2023-12-06 14:23:27,995 : INFO : EPOCH 19: training on 99524 raw words (65428 effective words) took 0.2s, 267969 effective words/s\n",
      "2023-12-06 14:23:28,239 : INFO : EPOCH 20: training on 99524 raw words (65760 effective words) took 0.2s, 272796 effective words/s\n",
      "2023-12-06 14:23:28,485 : INFO : EPOCH 21: training on 99524 raw words (65407 effective words) took 0.2s, 271463 effective words/s\n",
      "2023-12-06 14:23:28,732 : INFO : EPOCH 22: training on 99524 raw words (65447 effective words) took 0.2s, 270039 effective words/s\n",
      "2023-12-06 14:23:28,978 : INFO : EPOCH 23: training on 99524 raw words (65743 effective words) took 0.2s, 271150 effective words/s\n",
      "2023-12-06 14:23:29,224 : INFO : EPOCH 24: training on 99524 raw words (65501 effective words) took 0.2s, 272161 effective words/s\n",
      "2023-12-06 14:23:29,467 : INFO : EPOCH 25: training on 99524 raw words (65490 effective words) took 0.2s, 274457 effective words/s\n",
      "2023-12-06 14:23:29,712 : INFO : EPOCH 26: training on 99524 raw words (65470 effective words) took 0.2s, 270969 effective words/s\n",
      "2023-12-06 14:23:29,959 : INFO : EPOCH 27: training on 99524 raw words (65440 effective words) took 0.2s, 270053 effective words/s\n",
      "2023-12-06 14:23:30,206 : INFO : EPOCH 28: training on 99524 raw words (65420 effective words) took 0.2s, 269215 effective words/s\n",
      "2023-12-06 14:23:30,453 : INFO : EPOCH 29: training on 99524 raw words (65486 effective words) took 0.2s, 269449 effective words/s\n",
      "2023-12-06 14:23:30,454 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965713 effective words) took 7.4s, 264104 effective words/s', 'datetime': '2023-12-06T14:23:30.454753', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:23:30,454 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:23:30.454753', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 12%|        | 59/486 [09:52<1:06:55,  9.40s/it]2023-12-06 14:23:33,835 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:23:33,836 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:23:33,856 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:23:33,857 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:23:33,864 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:23:33.864988', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:23:33,864 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:23:33.864988', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:23:33,872 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:23:33,872 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:23:33,873 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:23:33.873997', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:23:33,883 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:23:33,884 : INFO : resetting layer weights\n",
      "2023-12-06 14:23:33,886 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:23:33.886854', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:23:34,140 : INFO : EPOCH 0: training on 99524 raw words (65574 effective words) took 0.2s, 263010 effective words/s\n",
      "2023-12-06 14:23:34,386 : INFO : EPOCH 1: training on 99524 raw words (65470 effective words) took 0.2s, 270967 effective words/s\n",
      "2023-12-06 14:23:34,637 : INFO : EPOCH 2: training on 99524 raw words (65500 effective words) took 0.2s, 264609 effective words/s\n",
      "2023-12-06 14:23:34,890 : INFO : EPOCH 3: training on 99524 raw words (65507 effective words) took 0.2s, 264003 effective words/s\n",
      "2023-12-06 14:23:35,142 : INFO : EPOCH 4: training on 99524 raw words (65646 effective words) took 0.2s, 265194 effective words/s\n",
      "2023-12-06 14:23:35,392 : INFO : EPOCH 5: training on 99524 raw words (65696 effective words) took 0.2s, 267156 effective words/s\n",
      "2023-12-06 14:23:35,640 : INFO : EPOCH 6: training on 99524 raw words (65370 effective words) took 0.2s, 268047 effective words/s\n",
      "2023-12-06 14:23:35,887 : INFO : EPOCH 7: training on 99524 raw words (65500 effective words) took 0.2s, 271131 effective words/s\n",
      "2023-12-06 14:23:36,141 : INFO : EPOCH 8: training on 99524 raw words (65528 effective words) took 0.3s, 261892 effective words/s\n",
      "2023-12-06 14:23:36,391 : INFO : EPOCH 9: training on 99524 raw words (65383 effective words) took 0.2s, 266315 effective words/s\n",
      "2023-12-06 14:23:36,640 : INFO : EPOCH 10: training on 99524 raw words (65648 effective words) took 0.2s, 269281 effective words/s\n",
      "2023-12-06 14:23:36,887 : INFO : EPOCH 11: training on 99524 raw words (65540 effective words) took 0.2s, 270323 effective words/s\n",
      "2023-12-06 14:23:37,135 : INFO : EPOCH 12: training on 99524 raw words (65474 effective words) took 0.2s, 268345 effective words/s\n",
      "2023-12-06 14:23:37,382 : INFO : EPOCH 13: training on 99524 raw words (65407 effective words) took 0.2s, 269766 effective words/s\n",
      "2023-12-06 14:23:37,634 : INFO : EPOCH 14: training on 99524 raw words (65469 effective words) took 0.2s, 266078 effective words/s\n",
      "2023-12-06 14:23:37,885 : INFO : EPOCH 15: training on 99524 raw words (65446 effective words) took 0.2s, 265184 effective words/s\n",
      "2023-12-06 14:23:38,134 : INFO : EPOCH 16: training on 99524 raw words (65380 effective words) took 0.2s, 266171 effective words/s\n",
      "2023-12-06 14:23:38,385 : INFO : EPOCH 17: training on 99524 raw words (65555 effective words) took 0.2s, 266069 effective words/s\n",
      "2023-12-06 14:23:38,635 : INFO : EPOCH 18: training on 99524 raw words (65456 effective words) took 0.2s, 266199 effective words/s\n",
      "2023-12-06 14:23:38,885 : INFO : EPOCH 19: training on 99524 raw words (65466 effective words) took 0.2s, 267421 effective words/s\n",
      "2023-12-06 14:23:39,140 : INFO : EPOCH 20: training on 99524 raw words (65545 effective words) took 0.3s, 261497 effective words/s\n",
      "2023-12-06 14:23:39,387 : INFO : EPOCH 21: training on 99524 raw words (65435 effective words) took 0.2s, 270085 effective words/s\n",
      "2023-12-06 14:23:39,634 : INFO : EPOCH 22: training on 99524 raw words (65422 effective words) took 0.2s, 270546 effective words/s\n",
      "2023-12-06 14:23:39,881 : INFO : EPOCH 23: training on 99524 raw words (65260 effective words) took 0.2s, 267324 effective words/s\n",
      "2023-12-06 14:23:40,132 : INFO : EPOCH 24: training on 99524 raw words (65540 effective words) took 0.2s, 266243 effective words/s\n",
      "2023-12-06 14:23:40,384 : INFO : EPOCH 25: training on 99524 raw words (65589 effective words) took 0.2s, 265493 effective words/s\n",
      "2023-12-06 14:23:40,632 : INFO : EPOCH 26: training on 99524 raw words (65490 effective words) took 0.2s, 268938 effective words/s\n",
      "2023-12-06 14:23:40,882 : INFO : EPOCH 27: training on 99524 raw words (65616 effective words) took 0.2s, 266311 effective words/s\n",
      "2023-12-06 14:23:41,137 : INFO : EPOCH 28: training on 99524 raw words (65374 effective words) took 0.3s, 261264 effective words/s\n",
      "2023-12-06 14:23:41,388 : INFO : EPOCH 29: training on 99524 raw words (65612 effective words) took 0.2s, 265756 effective words/s\n",
      "2023-12-06 14:23:41,389 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1964898 effective words) took 7.5s, 261908 effective words/s', 'datetime': '2023-12-06T14:23:41.389696', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:23:41,389 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:23:41.389696', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 12%|        | 60/486 [10:03<1:10:26,  9.92s/it]2023-12-06 14:23:44,965 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:23:44,965 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:23:44,985 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:23:44,986 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:23:44,993 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:23:44.993503', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:23:44,994 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:23:44.994504', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:23:45,001 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:23:45,001 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:23:45,002 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:23:45.002505', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:23:45,015 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:23:45,016 : INFO : resetting layer weights\n",
      "2023-12-06 14:23:45,019 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:23:45.019510', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:23:45,269 : INFO : EPOCH 0: training on 99524 raw words (65574 effective words) took 0.2s, 268303 effective words/s\n",
      "2023-12-06 14:23:45,504 : INFO : EPOCH 1: training on 99524 raw words (65583 effective words) took 0.2s, 285444 effective words/s\n",
      "2023-12-06 14:23:45,743 : INFO : EPOCH 2: training on 99524 raw words (65589 effective words) took 0.2s, 278632 effective words/s\n",
      "2023-12-06 14:23:45,983 : INFO : EPOCH 3: training on 99524 raw words (65759 effective words) took 0.2s, 279032 effective words/s\n",
      "2023-12-06 14:23:46,264 : INFO : EPOCH 4: training on 99524 raw words (65506 effective words) took 0.3s, 240054 effective words/s\n",
      "2023-12-06 14:23:46,504 : INFO : EPOCH 5: training on 99524 raw words (65481 effective words) took 0.2s, 279181 effective words/s\n",
      "2023-12-06 14:23:46,745 : INFO : EPOCH 6: training on 99524 raw words (65439 effective words) took 0.2s, 276681 effective words/s\n",
      "2023-12-06 14:23:46,989 : INFO : EPOCH 7: training on 99524 raw words (65415 effective words) took 0.2s, 272636 effective words/s\n",
      "2023-12-06 14:23:47,232 : INFO : EPOCH 8: training on 99524 raw words (65555 effective words) took 0.2s, 275182 effective words/s\n",
      "2023-12-06 14:23:47,468 : INFO : EPOCH 9: training on 99524 raw words (65616 effective words) took 0.2s, 282932 effective words/s\n",
      "2023-12-06 14:23:47,701 : INFO : EPOCH 10: training on 99524 raw words (65420 effective words) took 0.2s, 285921 effective words/s\n",
      "2023-12-06 14:23:47,933 : INFO : EPOCH 11: training on 99524 raw words (65327 effective words) took 0.2s, 287928 effective words/s\n",
      "2023-12-06 14:23:48,173 : INFO : EPOCH 12: training on 99524 raw words (65561 effective words) took 0.2s, 277602 effective words/s\n",
      "2023-12-06 14:23:48,411 : INFO : EPOCH 13: training on 99524 raw words (65660 effective words) took 0.2s, 281398 effective words/s\n",
      "2023-12-06 14:23:48,647 : INFO : EPOCH 14: training on 99524 raw words (65483 effective words) took 0.2s, 282666 effective words/s\n",
      "2023-12-06 14:23:48,878 : INFO : EPOCH 15: training on 99524 raw words (65535 effective words) took 0.2s, 288873 effective words/s\n",
      "2023-12-06 14:23:49,127 : INFO : EPOCH 16: training on 99524 raw words (65598 effective words) took 0.2s, 269004 effective words/s\n",
      "2023-12-06 14:23:49,372 : INFO : EPOCH 17: training on 99524 raw words (65322 effective words) took 0.2s, 272529 effective words/s\n",
      "2023-12-06 14:23:49,609 : INFO : EPOCH 18: training on 99524 raw words (65369 effective words) took 0.2s, 279566 effective words/s\n",
      "2023-12-06 14:23:49,843 : INFO : EPOCH 19: training on 99524 raw words (65523 effective words) took 0.2s, 286465 effective words/s\n",
      "2023-12-06 14:23:50,087 : INFO : EPOCH 20: training on 99524 raw words (65439 effective words) took 0.2s, 271824 effective words/s\n",
      "2023-12-06 14:23:50,323 : INFO : EPOCH 21: training on 99524 raw words (65547 effective words) took 0.2s, 284140 effective words/s\n",
      "2023-12-06 14:23:50,558 : INFO : EPOCH 22: training on 99524 raw words (65551 effective words) took 0.2s, 284239 effective words/s\n",
      "2023-12-06 14:23:50,795 : INFO : EPOCH 23: training on 99524 raw words (65527 effective words) took 0.2s, 280592 effective words/s\n",
      "2023-12-06 14:23:51,035 : INFO : EPOCH 24: training on 99524 raw words (65392 effective words) took 0.2s, 278493 effective words/s\n",
      "2023-12-06 14:23:51,270 : INFO : EPOCH 25: training on 99524 raw words (65639 effective words) took 0.2s, 284820 effective words/s\n",
      "2023-12-06 14:23:51,508 : INFO : EPOCH 26: training on 99524 raw words (65367 effective words) took 0.2s, 279498 effective words/s\n",
      "2023-12-06 14:23:51,747 : INFO : EPOCH 27: training on 99524 raw words (65507 effective words) took 0.2s, 278720 effective words/s\n",
      "2023-12-06 14:23:51,994 : INFO : EPOCH 28: training on 99524 raw words (65492 effective words) took 0.2s, 271114 effective words/s\n",
      "2023-12-06 14:23:52,230 : INFO : EPOCH 29: training on 99524 raw words (65469 effective words) took 0.2s, 282504 effective words/s\n",
      "2023-12-06 14:23:52,469 : INFO : EPOCH 30: training on 99524 raw words (65390 effective words) took 0.2s, 279546 effective words/s\n",
      "2023-12-06 14:23:52,704 : INFO : EPOCH 31: training on 99524 raw words (65516 effective words) took 0.2s, 282643 effective words/s\n",
      "2023-12-06 14:23:52,940 : INFO : EPOCH 32: training on 99524 raw words (65415 effective words) took 0.2s, 282709 effective words/s\n",
      "2023-12-06 14:23:53,186 : INFO : EPOCH 33: training on 99524 raw words (65507 effective words) took 0.2s, 271738 effective words/s\n",
      "2023-12-06 14:23:53,426 : INFO : EPOCH 34: training on 99524 raw words (65541 effective words) took 0.2s, 277134 effective words/s\n",
      "2023-12-06 14:23:53,670 : INFO : EPOCH 35: training on 99524 raw words (65745 effective words) took 0.2s, 274703 effective words/s\n",
      "2023-12-06 14:23:53,907 : INFO : EPOCH 36: training on 99524 raw words (65348 effective words) took 0.2s, 281631 effective words/s\n",
      "2023-12-06 14:23:54,150 : INFO : EPOCH 37: training on 99524 raw words (65538 effective words) took 0.2s, 274358 effective words/s\n",
      "2023-12-06 14:23:54,389 : INFO : EPOCH 38: training on 99524 raw words (65475 effective words) took 0.2s, 279250 effective words/s\n",
      "2023-12-06 14:23:54,621 : INFO : EPOCH 39: training on 99524 raw words (65550 effective words) took 0.2s, 288553 effective words/s\n",
      "2023-12-06 14:23:54,853 : INFO : EPOCH 40: training on 99524 raw words (65541 effective words) took 0.2s, 287507 effective words/s\n",
      "2023-12-06 14:23:55,094 : INFO : EPOCH 41: training on 99524 raw words (65541 effective words) took 0.2s, 277093 effective words/s\n",
      "2023-12-06 14:23:55,332 : INFO : EPOCH 42: training on 99524 raw words (65518 effective words) took 0.2s, 279821 effective words/s\n",
      "2023-12-06 14:23:55,564 : INFO : EPOCH 43: training on 99524 raw words (65349 effective words) took 0.2s, 287189 effective words/s\n",
      "2023-12-06 14:23:55,795 : INFO : EPOCH 44: training on 99524 raw words (65446 effective words) took 0.2s, 289070 effective words/s\n",
      "2023-12-06 14:23:56,033 : INFO : EPOCH 45: training on 99524 raw words (65575 effective words) took 0.2s, 280802 effective words/s\n",
      "2023-12-06 14:23:56,268 : INFO : EPOCH 46: training on 99524 raw words (65504 effective words) took 0.2s, 285312 effective words/s\n",
      "2023-12-06 14:23:56,508 : INFO : EPOCH 47: training on 99524 raw words (65568 effective words) took 0.2s, 277545 effective words/s\n",
      "2023-12-06 14:23:56,745 : INFO : EPOCH 48: training on 99524 raw words (65605 effective words) took 0.2s, 282642 effective words/s\n",
      "2023-12-06 14:23:56,987 : INFO : EPOCH 49: training on 99524 raw words (65581 effective words) took 0.2s, 276576 effective words/s\n",
      "2023-12-06 14:23:56,988 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3275498 effective words) took 12.0s, 273697 effective words/s', 'datetime': '2023-12-06T14:23:56.988243', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:23:56,989 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:23:56.989266', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 13%|        | 61/486 [10:19<1:22:56, 11.71s/it]2023-12-06 14:24:00,848 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:24:00,848 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:24:00,870 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:24:00,871 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:24:00,878 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:24:00.878994', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:24:00,879 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:24:00.879997', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:24:00,886 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:24:00,887 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:24:00,887 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:24:00.887268', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:24:00,905 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:24:00,906 : INFO : resetting layer weights\n",
      "2023-12-06 14:24:00,908 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:24:00.908508', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:24:01,170 : INFO : EPOCH 0: training on 99524 raw words (65586 effective words) took 0.3s, 256048 effective words/s\n",
      "2023-12-06 14:24:01,419 : INFO : EPOCH 1: training on 99524 raw words (65544 effective words) took 0.2s, 268391 effective words/s\n",
      "2023-12-06 14:24:01,665 : INFO : EPOCH 2: training on 99524 raw words (65599 effective words) took 0.2s, 271700 effective words/s\n",
      "2023-12-06 14:24:01,908 : INFO : EPOCH 3: training on 99524 raw words (65595 effective words) took 0.2s, 274607 effective words/s\n",
      "2023-12-06 14:24:02,157 : INFO : EPOCH 4: training on 99524 raw words (65666 effective words) took 0.2s, 269365 effective words/s\n",
      "2023-12-06 14:24:02,408 : INFO : EPOCH 5: training on 99524 raw words (65393 effective words) took 0.2s, 264969 effective words/s\n",
      "2023-12-06 14:24:02,654 : INFO : EPOCH 6: training on 99524 raw words (65417 effective words) took 0.2s, 269843 effective words/s\n",
      "2023-12-06 14:24:02,901 : INFO : EPOCH 7: training on 99524 raw words (65490 effective words) took 0.2s, 270440 effective words/s\n",
      "2023-12-06 14:24:03,149 : INFO : EPOCH 8: training on 99524 raw words (65454 effective words) took 0.2s, 268084 effective words/s\n",
      "2023-12-06 14:24:03,402 : INFO : EPOCH 9: training on 99524 raw words (65619 effective words) took 0.2s, 263523 effective words/s\n",
      "2023-12-06 14:24:03,650 : INFO : EPOCH 10: training on 99524 raw words (65494 effective words) took 0.2s, 269341 effective words/s\n",
      "2023-12-06 14:24:03,897 : INFO : EPOCH 11: training on 99524 raw words (65482 effective words) took 0.2s, 270480 effective words/s\n",
      "2023-12-06 14:24:04,136 : INFO : EPOCH 12: training on 99524 raw words (65591 effective words) took 0.2s, 278731 effective words/s\n",
      "2023-12-06 14:24:04,382 : INFO : EPOCH 13: training on 99524 raw words (65602 effective words) took 0.2s, 272408 effective words/s\n",
      "2023-12-06 14:24:04,645 : INFO : EPOCH 14: training on 99524 raw words (65439 effective words) took 0.3s, 252361 effective words/s\n",
      "2023-12-06 14:24:04,899 : INFO : EPOCH 15: training on 99524 raw words (65614 effective words) took 0.2s, 264294 effective words/s\n",
      "2023-12-06 14:24:05,149 : INFO : EPOCH 16: training on 99524 raw words (65627 effective words) took 0.2s, 267344 effective words/s\n",
      "2023-12-06 14:24:05,401 : INFO : EPOCH 17: training on 99524 raw words (65514 effective words) took 0.2s, 264065 effective words/s\n",
      "2023-12-06 14:24:05,647 : INFO : EPOCH 18: training on 99524 raw words (65542 effective words) took 0.2s, 270777 effective words/s\n",
      "2023-12-06 14:24:05,898 : INFO : EPOCH 19: training on 99524 raw words (65585 effective words) took 0.2s, 265785 effective words/s\n",
      "2023-12-06 14:24:06,150 : INFO : EPOCH 20: training on 99524 raw words (65574 effective words) took 0.2s, 265183 effective words/s\n",
      "2023-12-06 14:24:06,397 : INFO : EPOCH 21: training on 99524 raw words (65557 effective words) took 0.2s, 269540 effective words/s\n",
      "2023-12-06 14:24:06,648 : INFO : EPOCH 22: training on 99524 raw words (65497 effective words) took 0.2s, 267344 effective words/s\n",
      "2023-12-06 14:24:06,891 : INFO : EPOCH 23: training on 99524 raw words (65425 effective words) took 0.2s, 272671 effective words/s\n",
      "2023-12-06 14:24:07,143 : INFO : EPOCH 24: training on 99524 raw words (65613 effective words) took 0.2s, 266701 effective words/s\n",
      "2023-12-06 14:24:07,396 : INFO : EPOCH 25: training on 99524 raw words (65551 effective words) took 0.2s, 262942 effective words/s\n",
      "2023-12-06 14:24:07,643 : INFO : EPOCH 26: training on 99524 raw words (65601 effective words) took 0.2s, 270629 effective words/s\n",
      "2023-12-06 14:24:07,887 : INFO : EPOCH 27: training on 99524 raw words (65442 effective words) took 0.2s, 272794 effective words/s\n",
      "2023-12-06 14:24:08,140 : INFO : EPOCH 28: training on 99524 raw words (65686 effective words) took 0.2s, 264576 effective words/s\n",
      "2023-12-06 14:24:08,393 : INFO : EPOCH 29: training on 99524 raw words (65433 effective words) took 0.2s, 263525 effective words/s\n",
      "2023-12-06 14:24:08,644 : INFO : EPOCH 30: training on 99524 raw words (65505 effective words) took 0.2s, 265828 effective words/s\n",
      "2023-12-06 14:24:08,891 : INFO : EPOCH 31: training on 99524 raw words (65494 effective words) took 0.2s, 269716 effective words/s\n",
      "2023-12-06 14:24:09,137 : INFO : EPOCH 32: training on 99524 raw words (65637 effective words) took 0.2s, 271788 effective words/s\n",
      "2023-12-06 14:24:09,388 : INFO : EPOCH 33: training on 99524 raw words (65717 effective words) took 0.2s, 266425 effective words/s\n",
      "2023-12-06 14:24:09,637 : INFO : EPOCH 34: training on 99524 raw words (65657 effective words) took 0.2s, 269724 effective words/s\n",
      "2023-12-06 14:24:09,884 : INFO : EPOCH 35: training on 99524 raw words (65636 effective words) took 0.2s, 270580 effective words/s\n",
      "2023-12-06 14:24:10,133 : INFO : EPOCH 36: training on 99524 raw words (65541 effective words) took 0.2s, 267501 effective words/s\n",
      "2023-12-06 14:24:10,378 : INFO : EPOCH 37: training on 99524 raw words (65564 effective words) took 0.2s, 271901 effective words/s\n",
      "2023-12-06 14:24:10,625 : INFO : EPOCH 38: training on 99524 raw words (65463 effective words) took 0.2s, 269936 effective words/s\n",
      "2023-12-06 14:24:10,871 : INFO : EPOCH 39: training on 99524 raw words (65440 effective words) took 0.2s, 272151 effective words/s\n",
      "2023-12-06 14:24:11,133 : INFO : EPOCH 40: training on 99524 raw words (65403 effective words) took 0.3s, 253270 effective words/s\n",
      "2023-12-06 14:24:11,388 : INFO : EPOCH 41: training on 99524 raw words (65634 effective words) took 0.3s, 262221 effective words/s\n",
      "2023-12-06 14:24:11,635 : INFO : EPOCH 42: training on 99524 raw words (65367 effective words) took 0.2s, 269241 effective words/s\n",
      "2023-12-06 14:24:11,878 : INFO : EPOCH 43: training on 99524 raw words (65369 effective words) took 0.2s, 274493 effective words/s\n",
      "2023-12-06 14:24:12,122 : INFO : EPOCH 44: training on 99524 raw words (65513 effective words) took 0.2s, 272931 effective words/s\n",
      "2023-12-06 14:24:12,376 : INFO : EPOCH 45: training on 99524 raw words (65421 effective words) took 0.2s, 262213 effective words/s\n",
      "2023-12-06 14:24:12,626 : INFO : EPOCH 46: training on 99524 raw words (65463 effective words) took 0.2s, 265922 effective words/s\n",
      "2023-12-06 14:24:12,873 : INFO : EPOCH 47: training on 99524 raw words (65671 effective words) took 0.2s, 270861 effective words/s\n",
      "2023-12-06 14:24:13,123 : INFO : EPOCH 48: training on 99524 raw words (65568 effective words) took 0.2s, 266972 effective words/s\n",
      "2023-12-06 14:24:13,372 : INFO : EPOCH 49: training on 99524 raw words (65519 effective words) took 0.2s, 267334 effective words/s\n",
      "2023-12-06 14:24:13,373 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276814 effective words) took 12.5s, 262904 effective words/s', 'datetime': '2023-12-06T14:24:13.373312', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:24:13,374 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:24:13.374314', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 13%|        | 62/486 [10:36<1:32:58, 13.16s/it]2023-12-06 14:24:17,383 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:24:17,384 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:24:17,404 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:24:17,404 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:24:17,412 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:24:17.412726', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:24:17,412 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:24:17.412726', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:24:17,422 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:24:17,423 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:24:17,423 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:24:17.423653', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:24:17,436 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:24:17,437 : INFO : resetting layer weights\n",
      "2023-12-06 14:24:17,439 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:24:17.439656', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:24:17,704 : INFO : EPOCH 0: training on 99524 raw words (65502 effective words) took 0.3s, 252434 effective words/s\n",
      "2023-12-06 14:24:17,955 : INFO : EPOCH 1: training on 99524 raw words (65617 effective words) took 0.2s, 266435 effective words/s\n",
      "2023-12-06 14:24:18,202 : INFO : EPOCH 2: training on 99524 raw words (65623 effective words) took 0.2s, 270956 effective words/s\n",
      "2023-12-06 14:24:18,449 : INFO : EPOCH 3: training on 99524 raw words (65441 effective words) took 0.2s, 269187 effective words/s\n",
      "2023-12-06 14:24:18,704 : INFO : EPOCH 4: training on 99524 raw words (65717 effective words) took 0.3s, 262415 effective words/s\n",
      "2023-12-06 14:24:18,954 : INFO : EPOCH 5: training on 99524 raw words (65606 effective words) took 0.2s, 268569 effective words/s\n",
      "2023-12-06 14:24:19,200 : INFO : EPOCH 6: training on 99524 raw words (65490 effective words) took 0.2s, 269821 effective words/s\n",
      "2023-12-06 14:24:19,452 : INFO : EPOCH 7: training on 99524 raw words (65438 effective words) took 0.2s, 264461 effective words/s\n",
      "2023-12-06 14:24:19,709 : INFO : EPOCH 8: training on 99524 raw words (65430 effective words) took 0.3s, 259924 effective words/s\n",
      "2023-12-06 14:24:19,959 : INFO : EPOCH 9: training on 99524 raw words (65713 effective words) took 0.2s, 267559 effective words/s\n",
      "2023-12-06 14:24:20,210 : INFO : EPOCH 10: training on 99524 raw words (65563 effective words) took 0.2s, 265321 effective words/s\n",
      "2023-12-06 14:24:20,457 : INFO : EPOCH 11: training on 99524 raw words (65409 effective words) took 0.2s, 269399 effective words/s\n",
      "2023-12-06 14:24:20,709 : INFO : EPOCH 12: training on 99524 raw words (65405 effective words) took 0.2s, 263839 effective words/s\n",
      "2023-12-06 14:24:20,962 : INFO : EPOCH 13: training on 99524 raw words (65463 effective words) took 0.2s, 263561 effective words/s\n",
      "2023-12-06 14:24:21,210 : INFO : EPOCH 14: training on 99524 raw words (65702 effective words) took 0.2s, 269095 effective words/s\n",
      "2023-12-06 14:24:21,466 : INFO : EPOCH 15: training on 99524 raw words (65515 effective words) took 0.3s, 260945 effective words/s\n",
      "2023-12-06 14:24:21,724 : INFO : EPOCH 16: training on 99524 raw words (65405 effective words) took 0.3s, 257977 effective words/s\n",
      "2023-12-06 14:24:21,973 : INFO : EPOCH 17: training on 99524 raw words (65514 effective words) took 0.2s, 268004 effective words/s\n",
      "2023-12-06 14:24:22,224 : INFO : EPOCH 18: training on 99524 raw words (65412 effective words) took 0.2s, 265736 effective words/s\n",
      "2023-12-06 14:24:22,476 : INFO : EPOCH 19: training on 99524 raw words (65429 effective words) took 0.2s, 263484 effective words/s\n",
      "2023-12-06 14:24:22,738 : INFO : EPOCH 20: training on 99524 raw words (65497 effective words) took 0.3s, 255546 effective words/s\n",
      "2023-12-06 14:24:22,987 : INFO : EPOCH 21: training on 99524 raw words (65589 effective words) took 0.2s, 268780 effective words/s\n",
      "2023-12-06 14:24:23,235 : INFO : EPOCH 22: training on 99524 raw words (65603 effective words) took 0.2s, 269494 effective words/s\n",
      "2023-12-06 14:24:23,486 : INFO : EPOCH 23: training on 99524 raw words (65388 effective words) took 0.2s, 265399 effective words/s\n",
      "2023-12-06 14:24:23,739 : INFO : EPOCH 24: training on 99524 raw words (65339 effective words) took 0.2s, 261469 effective words/s\n",
      "2023-12-06 14:24:23,993 : INFO : EPOCH 25: training on 99524 raw words (65348 effective words) took 0.2s, 262661 effective words/s\n",
      "2023-12-06 14:24:24,244 : INFO : EPOCH 26: training on 99524 raw words (65547 effective words) took 0.2s, 266854 effective words/s\n",
      "2023-12-06 14:24:24,495 : INFO : EPOCH 27: training on 99524 raw words (65360 effective words) took 0.2s, 263462 effective words/s\n",
      "2023-12-06 14:24:24,751 : INFO : EPOCH 28: training on 99524 raw words (65581 effective words) took 0.3s, 261360 effective words/s\n",
      "2023-12-06 14:24:25,004 : INFO : EPOCH 29: training on 99524 raw words (65358 effective words) took 0.2s, 263338 effective words/s\n",
      "2023-12-06 14:24:25,253 : INFO : EPOCH 30: training on 99524 raw words (65531 effective words) took 0.2s, 267429 effective words/s\n",
      "2023-12-06 14:24:25,504 : INFO : EPOCH 31: training on 99524 raw words (65419 effective words) took 0.2s, 265503 effective words/s\n",
      "2023-12-06 14:24:25,756 : INFO : EPOCH 32: training on 99524 raw words (65612 effective words) took 0.2s, 264028 effective words/s\n",
      "2023-12-06 14:24:26,005 : INFO : EPOCH 33: training on 99524 raw words (65654 effective words) took 0.2s, 268446 effective words/s\n",
      "2023-12-06 14:24:26,259 : INFO : EPOCH 34: training on 99524 raw words (65495 effective words) took 0.2s, 263108 effective words/s\n",
      "2023-12-06 14:24:26,509 : INFO : EPOCH 35: training on 99524 raw words (65454 effective words) took 0.2s, 265310 effective words/s\n",
      "2023-12-06 14:24:26,763 : INFO : EPOCH 36: training on 99524 raw words (65400 effective words) took 0.2s, 262631 effective words/s\n",
      "2023-12-06 14:24:27,012 : INFO : EPOCH 37: training on 99524 raw words (65596 effective words) took 0.2s, 268685 effective words/s\n",
      "2023-12-06 14:24:27,265 : INFO : EPOCH 38: training on 99524 raw words (65423 effective words) took 0.2s, 262958 effective words/s\n",
      "2023-12-06 14:24:27,517 : INFO : EPOCH 39: training on 99524 raw words (65581 effective words) took 0.2s, 264621 effective words/s\n",
      "2023-12-06 14:24:27,773 : INFO : EPOCH 40: training on 99524 raw words (65460 effective words) took 0.3s, 261530 effective words/s\n",
      "2023-12-06 14:24:28,022 : INFO : EPOCH 41: training on 99524 raw words (65574 effective words) took 0.2s, 266403 effective words/s\n",
      "2023-12-06 14:24:28,273 : INFO : EPOCH 42: training on 99524 raw words (65452 effective words) took 0.2s, 265146 effective words/s\n",
      "2023-12-06 14:24:28,525 : INFO : EPOCH 43: training on 99524 raw words (65428 effective words) took 0.2s, 265332 effective words/s\n",
      "2023-12-06 14:24:28,782 : INFO : EPOCH 44: training on 99524 raw words (65628 effective words) took 0.3s, 259682 effective words/s\n",
      "2023-12-06 14:24:29,033 : INFO : EPOCH 45: training on 99524 raw words (65513 effective words) took 0.2s, 264952 effective words/s\n",
      "2023-12-06 14:24:29,284 : INFO : EPOCH 46: training on 99524 raw words (65543 effective words) took 0.2s, 266900 effective words/s\n",
      "2023-12-06 14:24:29,534 : INFO : EPOCH 47: training on 99524 raw words (65498 effective words) took 0.2s, 266191 effective words/s\n",
      "2023-12-06 14:24:29,784 : INFO : EPOCH 48: training on 99524 raw words (65495 effective words) took 0.2s, 266759 effective words/s\n",
      "2023-12-06 14:24:30,037 : INFO : EPOCH 49: training on 99524 raw words (65697 effective words) took 0.2s, 264323 effective words/s\n",
      "2023-12-06 14:24:30,038 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3275457 effective words) took 12.6s, 259996 effective words/s', 'datetime': '2023-12-06T14:24:30.038374', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:24:30,039 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:24:30.039373', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 13%|        | 63/486 [10:52<1:40:42, 14.28s/it]2023-12-06 14:24:34,298 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:24:34,299 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:24:34,319 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:24:34,320 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:24:34,325 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:24:34.325713', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:24:34,326 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:24:34.326713', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:24:34,331 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:24:34,332 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:24:34,332 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:24:34.332710', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:24:34,342 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:24:34,342 : INFO : resetting layer weights\n",
      "2023-12-06 14:24:34,344 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:24:34.344976', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:24:34,583 : INFO : EPOCH 0: training on 99524 raw words (62817 effective words) took 0.2s, 269871 effective words/s\n",
      "2023-12-06 14:24:34,808 : INFO : EPOCH 1: training on 99524 raw words (62575 effective words) took 0.2s, 283803 effective words/s\n",
      "2023-12-06 14:24:35,039 : INFO : EPOCH 2: training on 99524 raw words (62856 effective words) took 0.2s, 277783 effective words/s\n",
      "2023-12-06 14:24:35,277 : INFO : EPOCH 3: training on 99524 raw words (62575 effective words) took 0.2s, 266824 effective words/s\n",
      "2023-12-06 14:24:35,507 : INFO : EPOCH 4: training on 99524 raw words (62707 effective words) took 0.2s, 279354 effective words/s\n",
      "2023-12-06 14:24:35,738 : INFO : EPOCH 5: training on 99524 raw words (62642 effective words) took 0.2s, 275561 effective words/s\n",
      "2023-12-06 14:24:35,983 : INFO : EPOCH 6: training on 99524 raw words (62653 effective words) took 0.2s, 260124 effective words/s\n",
      "2023-12-06 14:24:36,223 : INFO : EPOCH 7: training on 99524 raw words (62664 effective words) took 0.2s, 267567 effective words/s\n",
      "2023-12-06 14:24:36,450 : INFO : EPOCH 8: training on 99524 raw words (62690 effective words) took 0.2s, 280884 effective words/s\n",
      "2023-12-06 14:24:36,688 : INFO : EPOCH 9: training on 99524 raw words (62863 effective words) took 0.2s, 270191 effective words/s\n",
      "2023-12-06 14:24:36,689 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627042 effective words) took 2.3s, 267635 effective words/s', 'datetime': '2023-12-06T14:24:36.689250', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:24:36,689 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:24:36.689250', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 13%|        | 64/486 [10:58<1:21:09, 11.54s/it]2023-12-06 14:24:39,433 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:24:39,434 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:24:39,454 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:24:39,454 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:24:39,460 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:24:39.460237', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:24:39,460 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:24:39.460237', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:24:39,465 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:24:39,466 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:24:39,466 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:24:39.466624', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:24:39,479 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:24:39,480 : INFO : resetting layer weights\n",
      "2023-12-06 14:24:39,481 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:24:39.481446', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:24:39,744 : INFO : EPOCH 0: training on 99524 raw words (62672 effective words) took 0.3s, 242569 effective words/s\n",
      "2023-12-06 14:24:39,993 : INFO : EPOCH 1: training on 99524 raw words (62738 effective words) took 0.2s, 255859 effective words/s\n",
      "2023-12-06 14:24:40,244 : INFO : EPOCH 2: training on 99524 raw words (62643 effective words) took 0.2s, 254033 effective words/s\n",
      "2023-12-06 14:24:40,487 : INFO : EPOCH 3: training on 99524 raw words (62742 effective words) took 0.2s, 263607 effective words/s\n",
      "2023-12-06 14:24:40,737 : INFO : EPOCH 4: training on 99524 raw words (62700 effective words) took 0.2s, 254385 effective words/s\n",
      "2023-12-06 14:24:40,989 : INFO : EPOCH 5: training on 99524 raw words (62690 effective words) took 0.2s, 253982 effective words/s\n",
      "2023-12-06 14:24:41,234 : INFO : EPOCH 6: training on 99524 raw words (62706 effective words) took 0.2s, 260572 effective words/s\n",
      "2023-12-06 14:24:41,481 : INFO : EPOCH 7: training on 99524 raw words (62789 effective words) took 0.2s, 260169 effective words/s\n",
      "2023-12-06 14:24:41,728 : INFO : EPOCH 8: training on 99524 raw words (62599 effective words) took 0.2s, 257578 effective words/s\n",
      "2023-12-06 14:24:41,976 : INFO : EPOCH 9: training on 99524 raw words (62636 effective words) took 0.2s, 257672 effective words/s\n",
      "2023-12-06 14:24:41,977 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (626915 effective words) took 2.5s, 251298 effective words/s', 'datetime': '2023-12-06T14:24:41.977296', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:24:41,977 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:24:41.977296', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 13%|        | 65/486 [11:03<1:07:52,  9.67s/it]2023-12-06 14:24:44,749 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:24:44,749 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:24:44,770 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:24:44,771 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:24:44,777 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:24:44.777182', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:24:44,778 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:24:44.778184', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:24:44,784 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:24:44,784 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:24:44,784 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:24:44.784527', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:24:44,796 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:24:44,797 : INFO : resetting layer weights\n",
      "2023-12-06 14:24:44,800 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:24:44.800004', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:24:45,068 : INFO : EPOCH 0: training on 99524 raw words (62736 effective words) took 0.3s, 238067 effective words/s\n",
      "2023-12-06 14:24:45,322 : INFO : EPOCH 1: training on 99524 raw words (62707 effective words) took 0.2s, 251469 effective words/s\n",
      "2023-12-06 14:24:45,568 : INFO : EPOCH 2: training on 99524 raw words (62757 effective words) took 0.2s, 259310 effective words/s\n",
      "2023-12-06 14:24:45,816 : INFO : EPOCH 3: training on 99524 raw words (62916 effective words) took 0.2s, 258948 effective words/s\n",
      "2023-12-06 14:24:46,071 : INFO : EPOCH 4: training on 99524 raw words (62732 effective words) took 0.3s, 249695 effective words/s\n",
      "2023-12-06 14:24:46,320 : INFO : EPOCH 5: training on 99524 raw words (62759 effective words) took 0.2s, 257016 effective words/s\n",
      "2023-12-06 14:24:46,564 : INFO : EPOCH 6: training on 99524 raw words (62769 effective words) took 0.2s, 260542 effective words/s\n",
      "2023-12-06 14:24:46,810 : INFO : EPOCH 7: training on 99524 raw words (62761 effective words) took 0.2s, 260381 effective words/s\n",
      "2023-12-06 14:24:47,064 : INFO : EPOCH 8: training on 99524 raw words (62751 effective words) took 0.2s, 251091 effective words/s\n",
      "2023-12-06 14:24:47,316 : INFO : EPOCH 9: training on 99524 raw words (62767 effective words) took 0.2s, 254247 effective words/s\n",
      "2023-12-06 14:24:47,317 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627655 effective words) took 2.5s, 249438 effective words/s', 'datetime': '2023-12-06T14:24:47.317142', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:24:47,317 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:24:47.317142', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 14%|        | 66/486 [11:08<58:35,  8.37s/it]  2023-12-06 14:24:50,083 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:24:50,083 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:24:50,112 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:24:50,113 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:24:50,120 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:24:50.120944', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:24:50,121 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:24:50.121951', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:24:50,130 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:24:50,131 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:24:50,133 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:24:50.133012', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:24:50,141 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:24:50,142 : INFO : resetting layer weights\n",
      "2023-12-06 14:24:50,144 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:24:50.144476', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:24:50,382 : INFO : EPOCH 0: training on 99524 raw words (62669 effective words) took 0.2s, 268426 effective words/s\n",
      "2023-12-06 14:24:50,623 : INFO : EPOCH 1: training on 99524 raw words (62681 effective words) took 0.2s, 265177 effective words/s\n",
      "2023-12-06 14:24:50,861 : INFO : EPOCH 2: training on 99524 raw words (62848 effective words) took 0.2s, 268002 effective words/s\n",
      "2023-12-06 14:24:51,090 : INFO : EPOCH 3: training on 99524 raw words (62548 effective words) took 0.2s, 278195 effective words/s\n",
      "2023-12-06 14:24:51,329 : INFO : EPOCH 4: training on 99524 raw words (62765 effective words) took 0.2s, 267987 effective words/s\n",
      "2023-12-06 14:24:51,556 : INFO : EPOCH 5: training on 99524 raw words (62627 effective words) took 0.2s, 280400 effective words/s\n",
      "2023-12-06 14:24:51,803 : INFO : EPOCH 6: training on 99524 raw words (62617 effective words) took 0.2s, 259548 effective words/s\n",
      "2023-12-06 14:24:52,030 : INFO : EPOCH 7: training on 99524 raw words (62676 effective words) took 0.2s, 280742 effective words/s\n",
      "2023-12-06 14:24:52,264 : INFO : EPOCH 8: training on 99524 raw words (62693 effective words) took 0.2s, 273454 effective words/s\n",
      "2023-12-06 14:24:52,492 : INFO : EPOCH 9: training on 99524 raw words (62726 effective words) took 0.2s, 280084 effective words/s\n",
      "2023-12-06 14:24:52,723 : INFO : EPOCH 10: training on 99524 raw words (62779 effective words) took 0.2s, 277170 effective words/s\n",
      "2023-12-06 14:24:52,954 : INFO : EPOCH 11: training on 99524 raw words (62765 effective words) took 0.2s, 276536 effective words/s\n",
      "2023-12-06 14:24:53,188 : INFO : EPOCH 12: training on 99524 raw words (63027 effective words) took 0.2s, 275424 effective words/s\n",
      "2023-12-06 14:24:53,419 : INFO : EPOCH 13: training on 99524 raw words (62743 effective words) took 0.2s, 275336 effective words/s\n",
      "2023-12-06 14:24:53,655 : INFO : EPOCH 14: training on 99524 raw words (62675 effective words) took 0.2s, 271430 effective words/s\n",
      "2023-12-06 14:24:53,884 : INFO : EPOCH 15: training on 99524 raw words (62619 effective words) took 0.2s, 277981 effective words/s\n",
      "2023-12-06 14:24:54,120 : INFO : EPOCH 16: training on 99524 raw words (62752 effective words) took 0.2s, 271317 effective words/s\n",
      "2023-12-06 14:24:54,351 : INFO : EPOCH 17: training on 99524 raw words (62627 effective words) took 0.2s, 275697 effective words/s\n",
      "2023-12-06 14:24:54,580 : INFO : EPOCH 18: training on 99524 raw words (62894 effective words) took 0.2s, 280696 effective words/s\n",
      "2023-12-06 14:24:54,811 : INFO : EPOCH 19: training on 99524 raw words (62792 effective words) took 0.2s, 276954 effective words/s\n",
      "2023-12-06 14:24:55,048 : INFO : EPOCH 20: training on 99524 raw words (62741 effective words) took 0.2s, 270663 effective words/s\n",
      "2023-12-06 14:24:55,275 : INFO : EPOCH 21: training on 99524 raw words (62847 effective words) took 0.2s, 280958 effective words/s\n",
      "2023-12-06 14:24:55,504 : INFO : EPOCH 22: training on 99524 raw words (62747 effective words) took 0.2s, 279493 effective words/s\n",
      "2023-12-06 14:24:55,738 : INFO : EPOCH 23: training on 99524 raw words (62744 effective words) took 0.2s, 272438 effective words/s\n",
      "2023-12-06 14:24:55,975 : INFO : EPOCH 24: training on 99524 raw words (62530 effective words) took 0.2s, 269395 effective words/s\n",
      "2023-12-06 14:24:56,206 : INFO : EPOCH 25: training on 99524 raw words (62762 effective words) took 0.2s, 276229 effective words/s\n",
      "2023-12-06 14:24:56,434 : INFO : EPOCH 26: training on 99524 raw words (62703 effective words) took 0.2s, 280145 effective words/s\n",
      "2023-12-06 14:24:56,667 : INFO : EPOCH 27: training on 99524 raw words (62657 effective words) took 0.2s, 275523 effective words/s\n",
      "2023-12-06 14:24:56,900 : INFO : EPOCH 28: training on 99524 raw words (62789 effective words) took 0.2s, 274110 effective words/s\n",
      "2023-12-06 14:24:57,128 : INFO : EPOCH 29: training on 99524 raw words (62650 effective words) took 0.2s, 280000 effective words/s\n",
      "2023-12-06 14:24:57,129 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881693 effective words) took 7.0s, 269421 effective words/s', 'datetime': '2023-12-06T14:24:57.129776', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:24:57,130 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:24:57.130777', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 14%|        | 67/486 [11:18<1:02:17,  8.92s/it]2023-12-06 14:25:00,283 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:25:00,284 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:25:00,314 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:25:00,315 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:25:00,322 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:25:00.322015', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:25:00,323 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:25:00.323016', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:25:00,328 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:25:00,329 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:25:00,330 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:25:00.330272', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:25:00,339 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:25:00,339 : INFO : resetting layer weights\n",
      "2023-12-06 14:25:00,343 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:25:00.343202', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:25:00,596 : INFO : EPOCH 0: training on 99524 raw words (62836 effective words) took 0.2s, 253119 effective words/s\n",
      "2023-12-06 14:25:00,839 : INFO : EPOCH 1: training on 99524 raw words (62687 effective words) took 0.2s, 263585 effective words/s\n",
      "2023-12-06 14:25:01,087 : INFO : EPOCH 2: training on 99524 raw words (62848 effective words) took 0.2s, 257681 effective words/s\n",
      "2023-12-06 14:25:01,330 : INFO : EPOCH 3: training on 99524 raw words (62698 effective words) took 0.2s, 261695 effective words/s\n",
      "2023-12-06 14:25:01,577 : INFO : EPOCH 4: training on 99524 raw words (62783 effective words) took 0.2s, 258913 effective words/s\n",
      "2023-12-06 14:25:01,823 : INFO : EPOCH 5: training on 99524 raw words (62682 effective words) took 0.2s, 260079 effective words/s\n",
      "2023-12-06 14:25:02,064 : INFO : EPOCH 6: training on 99524 raw words (62743 effective words) took 0.2s, 264417 effective words/s\n",
      "2023-12-06 14:25:02,306 : INFO : EPOCH 7: training on 99524 raw words (62644 effective words) took 0.2s, 264125 effective words/s\n",
      "2023-12-06 14:25:02,554 : INFO : EPOCH 8: training on 99524 raw words (62792 effective words) took 0.2s, 257348 effective words/s\n",
      "2023-12-06 14:25:02,798 : INFO : EPOCH 9: training on 99524 raw words (62594 effective words) took 0.2s, 261081 effective words/s\n",
      "2023-12-06 14:25:03,038 : INFO : EPOCH 10: training on 99524 raw words (62853 effective words) took 0.2s, 266605 effective words/s\n",
      "2023-12-06 14:25:03,279 : INFO : EPOCH 11: training on 99524 raw words (62875 effective words) took 0.2s, 265165 effective words/s\n",
      "2023-12-06 14:25:03,525 : INFO : EPOCH 12: training on 99524 raw words (62679 effective words) took 0.2s, 259452 effective words/s\n",
      "2023-12-06 14:25:03,766 : INFO : EPOCH 13: training on 99524 raw words (62694 effective words) took 0.2s, 264665 effective words/s\n",
      "2023-12-06 14:25:04,008 : INFO : EPOCH 14: training on 99524 raw words (62687 effective words) took 0.2s, 263603 effective words/s\n",
      "2023-12-06 14:25:04,250 : INFO : EPOCH 15: training on 99524 raw words (62848 effective words) took 0.2s, 265323 effective words/s\n",
      "2023-12-06 14:25:04,494 : INFO : EPOCH 16: training on 99524 raw words (62835 effective words) took 0.2s, 261520 effective words/s\n",
      "2023-12-06 14:25:04,737 : INFO : EPOCH 17: training on 99524 raw words (62905 effective words) took 0.2s, 264208 effective words/s\n",
      "2023-12-06 14:25:04,977 : INFO : EPOCH 18: training on 99524 raw words (62805 effective words) took 0.2s, 265830 effective words/s\n",
      "2023-12-06 14:25:05,217 : INFO : EPOCH 19: training on 99524 raw words (62867 effective words) took 0.2s, 266051 effective words/s\n",
      "2023-12-06 14:25:05,466 : INFO : EPOCH 20: training on 99524 raw words (62696 effective words) took 0.2s, 257017 effective words/s\n",
      "2023-12-06 14:25:05,708 : INFO : EPOCH 21: training on 99524 raw words (62777 effective words) took 0.2s, 264360 effective words/s\n",
      "2023-12-06 14:25:05,952 : INFO : EPOCH 22: training on 99524 raw words (62786 effective words) took 0.2s, 261459 effective words/s\n",
      "2023-12-06 14:25:06,199 : INFO : EPOCH 23: training on 99524 raw words (62652 effective words) took 0.2s, 259501 effective words/s\n",
      "2023-12-06 14:25:06,451 : INFO : EPOCH 24: training on 99524 raw words (62747 effective words) took 0.2s, 253598 effective words/s\n",
      "2023-12-06 14:25:06,696 : INFO : EPOCH 25: training on 99524 raw words (62839 effective words) took 0.2s, 260265 effective words/s\n",
      "2023-12-06 14:25:06,946 : INFO : EPOCH 26: training on 99524 raw words (62727 effective words) took 0.2s, 255904 effective words/s\n",
      "2023-12-06 14:25:07,191 : INFO : EPOCH 27: training on 99524 raw words (62848 effective words) took 0.2s, 261448 effective words/s\n",
      "2023-12-06 14:25:07,441 : INFO : EPOCH 28: training on 99524 raw words (62815 effective words) took 0.2s, 254346 effective words/s\n",
      "2023-12-06 14:25:07,693 : INFO : EPOCH 29: training on 99524 raw words (62626 effective words) took 0.2s, 253908 effective words/s\n",
      "2023-12-06 14:25:07,694 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1882868 effective words) took 7.4s, 256137 effective words/s', 'datetime': '2023-12-06T14:25:07.694339', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:25:07,695 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:25:07.695353', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 14%|        | 68/486 [11:30<1:06:53,  9.60s/it]2023-12-06 14:25:11,477 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:25:11,477 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:25:11,499 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:25:11,500 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:25:11,506 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:25:11.506681', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:25:11,507 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:25:11.507682', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:25:11,512 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:25:11,513 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:25:11,513 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:25:11.513680', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:25:11,522 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:25:11,523 : INFO : resetting layer weights\n",
      "2023-12-06 14:25:11,525 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:25:11.525347', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:25:11,787 : INFO : EPOCH 0: training on 99524 raw words (62694 effective words) took 0.3s, 244139 effective words/s\n",
      "2023-12-06 14:25:12,054 : INFO : EPOCH 1: training on 99524 raw words (62598 effective words) took 0.3s, 238997 effective words/s\n",
      "2023-12-06 14:25:12,318 : INFO : EPOCH 2: training on 99524 raw words (62729 effective words) took 0.3s, 243064 effective words/s\n",
      "2023-12-06 14:25:12,572 : INFO : EPOCH 3: training on 99524 raw words (62716 effective words) took 0.2s, 251280 effective words/s\n",
      "2023-12-06 14:25:12,827 : INFO : EPOCH 4: training on 99524 raw words (62763 effective words) took 0.3s, 250001 effective words/s\n",
      "2023-12-06 14:25:13,059 : INFO : EPOCH 5: training on 99524 raw words (62798 effective words) took 0.2s, 276361 effective words/s\n",
      "2023-12-06 14:25:13,265 : INFO : EPOCH 6: training on 99524 raw words (62597 effective words) took 0.2s, 310182 effective words/s\n",
      "2023-12-06 14:25:13,466 : INFO : EPOCH 7: training on 99524 raw words (62757 effective words) took 0.2s, 317632 effective words/s\n",
      "2023-12-06 14:25:13,676 : INFO : EPOCH 8: training on 99524 raw words (62511 effective words) took 0.2s, 306143 effective words/s\n",
      "2023-12-06 14:25:13,881 : INFO : EPOCH 9: training on 99524 raw words (62573 effective words) took 0.2s, 310976 effective words/s\n",
      "2023-12-06 14:25:14,106 : INFO : EPOCH 10: training on 99524 raw words (62808 effective words) took 0.2s, 286018 effective words/s\n",
      "2023-12-06 14:25:14,315 : INFO : EPOCH 11: training on 99524 raw words (62719 effective words) took 0.2s, 307169 effective words/s\n",
      "2023-12-06 14:25:14,516 : INFO : EPOCH 12: training on 99524 raw words (62714 effective words) took 0.2s, 318949 effective words/s\n",
      "2023-12-06 14:25:14,714 : INFO : EPOCH 13: training on 99524 raw words (62796 effective words) took 0.2s, 325300 effective words/s\n",
      "2023-12-06 14:25:14,922 : INFO : EPOCH 14: training on 99524 raw words (62770 effective words) took 0.2s, 306546 effective words/s\n",
      "2023-12-06 14:25:15,120 : INFO : EPOCH 15: training on 99524 raw words (62611 effective words) took 0.2s, 324321 effective words/s\n",
      "2023-12-06 14:25:15,314 : INFO : EPOCH 16: training on 99524 raw words (62781 effective words) took 0.2s, 330785 effective words/s\n",
      "2023-12-06 14:25:15,508 : INFO : EPOCH 17: training on 99524 raw words (62943 effective words) took 0.2s, 331813 effective words/s\n",
      "2023-12-06 14:25:15,713 : INFO : EPOCH 18: training on 99524 raw words (62798 effective words) took 0.2s, 312842 effective words/s\n",
      "2023-12-06 14:25:15,909 : INFO : EPOCH 19: training on 99524 raw words (62682 effective words) took 0.2s, 324841 effective words/s\n",
      "2023-12-06 14:25:16,103 : INFO : EPOCH 20: training on 99524 raw words (62552 effective words) took 0.2s, 330028 effective words/s\n",
      "2023-12-06 14:25:16,301 : INFO : EPOCH 21: training on 99524 raw words (62606 effective words) took 0.2s, 324050 effective words/s\n",
      "2023-12-06 14:25:16,509 : INFO : EPOCH 22: training on 99524 raw words (62642 effective words) took 0.2s, 306835 effective words/s\n",
      "2023-12-06 14:25:16,711 : INFO : EPOCH 23: training on 99524 raw words (62747 effective words) took 0.2s, 317329 effective words/s\n",
      "2023-12-06 14:25:16,906 : INFO : EPOCH 24: training on 99524 raw words (62644 effective words) took 0.2s, 326172 effective words/s\n",
      "2023-12-06 14:25:17,121 : INFO : EPOCH 25: training on 99524 raw words (62693 effective words) took 0.2s, 298715 effective words/s\n",
      "2023-12-06 14:25:17,326 : INFO : EPOCH 26: training on 99524 raw words (62804 effective words) took 0.2s, 312854 effective words/s\n",
      "2023-12-06 14:25:17,547 : INFO : EPOCH 27: training on 99524 raw words (62759 effective words) took 0.2s, 289386 effective words/s\n",
      "2023-12-06 14:25:17,756 : INFO : EPOCH 28: training on 99524 raw words (62707 effective words) took 0.2s, 307387 effective words/s\n",
      "2023-12-06 14:25:17,964 : INFO : EPOCH 29: training on 99524 raw words (62712 effective words) took 0.2s, 308377 effective words/s\n",
      "2023-12-06 14:25:17,965 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881224 effective words) took 6.4s, 292170 effective words/s', 'datetime': '2023-12-06T14:25:17.965536', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:25:17,965 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:25:17.965536', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 14%|        | 69/486 [11:40<1:07:44,  9.75s/it]2023-12-06 14:25:21,563 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:25:21,563 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:25:21,585 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:25:21,586 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:25:21,590 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:25:21.590286', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:25:21,591 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:25:21.591478', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:25:21,596 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:25:21,596 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:25:21,597 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:25:21.597782', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:25:21,606 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:25:21,607 : INFO : resetting layer weights\n",
      "2023-12-06 14:25:21,608 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:25:21.608835', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:25:21,858 : INFO : EPOCH 0: training on 99524 raw words (62810 effective words) took 0.2s, 256062 effective words/s\n",
      "2023-12-06 14:25:22,064 : INFO : EPOCH 1: training on 99524 raw words (62697 effective words) took 0.2s, 312670 effective words/s\n",
      "2023-12-06 14:25:22,264 : INFO : EPOCH 2: training on 99524 raw words (62733 effective words) took 0.2s, 320737 effective words/s\n",
      "2023-12-06 14:25:22,459 : INFO : EPOCH 3: training on 99524 raw words (62857 effective words) took 0.2s, 330308 effective words/s\n",
      "2023-12-06 14:25:22,651 : INFO : EPOCH 4: training on 99524 raw words (62669 effective words) took 0.2s, 333518 effective words/s\n",
      "2023-12-06 14:25:22,853 : INFO : EPOCH 5: training on 99524 raw words (62677 effective words) took 0.2s, 316840 effective words/s\n",
      "2023-12-06 14:25:23,041 : INFO : EPOCH 6: training on 99524 raw words (62709 effective words) took 0.2s, 339980 effective words/s\n",
      "2023-12-06 14:25:23,232 : INFO : EPOCH 7: training on 99524 raw words (62555 effective words) took 0.2s, 337241 effective words/s\n",
      "2023-12-06 14:25:23,422 : INFO : EPOCH 8: training on 99524 raw words (62652 effective words) took 0.2s, 335904 effective words/s\n",
      "2023-12-06 14:25:23,620 : INFO : EPOCH 9: training on 99524 raw words (62650 effective words) took 0.2s, 324251 effective words/s\n",
      "2023-12-06 14:25:23,815 : INFO : EPOCH 10: training on 99524 raw words (62664 effective words) took 0.2s, 326809 effective words/s\n",
      "2023-12-06 14:25:24,006 : INFO : EPOCH 11: training on 99524 raw words (62633 effective words) took 0.2s, 336232 effective words/s\n",
      "2023-12-06 14:25:24,195 : INFO : EPOCH 12: training on 99524 raw words (62774 effective words) took 0.2s, 339915 effective words/s\n",
      "2023-12-06 14:25:24,397 : INFO : EPOCH 13: training on 99524 raw words (62832 effective words) took 0.2s, 319455 effective words/s\n",
      "2023-12-06 14:25:24,589 : INFO : EPOCH 14: training on 99524 raw words (62736 effective words) took 0.2s, 333155 effective words/s\n",
      "2023-12-06 14:25:24,778 : INFO : EPOCH 15: training on 99524 raw words (62729 effective words) took 0.2s, 338773 effective words/s\n",
      "2023-12-06 14:25:24,969 : INFO : EPOCH 16: training on 99524 raw words (62817 effective words) took 0.2s, 336289 effective words/s\n",
      "2023-12-06 14:25:25,171 : INFO : EPOCH 17: training on 99524 raw words (62796 effective words) took 0.2s, 319139 effective words/s\n",
      "2023-12-06 14:25:25,361 : INFO : EPOCH 18: training on 99524 raw words (62795 effective words) took 0.2s, 335522 effective words/s\n",
      "2023-12-06 14:25:25,554 : INFO : EPOCH 19: training on 99524 raw words (62742 effective words) took 0.2s, 332932 effective words/s\n",
      "2023-12-06 14:25:25,754 : INFO : EPOCH 20: training on 99524 raw words (62629 effective words) took 0.2s, 321855 effective words/s\n",
      "2023-12-06 14:25:25,965 : INFO : EPOCH 21: training on 99524 raw words (62867 effective words) took 0.2s, 302626 effective words/s\n",
      "2023-12-06 14:25:26,160 : INFO : EPOCH 22: training on 99524 raw words (62702 effective words) took 0.2s, 330621 effective words/s\n",
      "2023-12-06 14:25:26,365 : INFO : EPOCH 23: training on 99524 raw words (62869 effective words) took 0.2s, 312965 effective words/s\n",
      "2023-12-06 14:25:26,575 : INFO : EPOCH 24: training on 99524 raw words (62898 effective words) took 0.2s, 306429 effective words/s\n",
      "2023-12-06 14:25:26,790 : INFO : EPOCH 25: training on 99524 raw words (62819 effective words) took 0.2s, 298768 effective words/s\n",
      "2023-12-06 14:25:26,997 : INFO : EPOCH 26: training on 99524 raw words (62677 effective words) took 0.2s, 308552 effective words/s\n",
      "2023-12-06 14:25:27,208 : INFO : EPOCH 27: training on 99524 raw words (62840 effective words) took 0.2s, 304294 effective words/s\n",
      "2023-12-06 14:25:27,402 : INFO : EPOCH 28: training on 99524 raw words (62669 effective words) took 0.2s, 331285 effective words/s\n",
      "2023-12-06 14:25:27,616 : INFO : EPOCH 29: training on 99524 raw words (62468 effective words) took 0.2s, 296948 effective words/s\n",
      "2023-12-06 14:25:27,813 : INFO : EPOCH 30: training on 99524 raw words (62725 effective words) took 0.2s, 325769 effective words/s\n",
      "2023-12-06 14:25:28,002 : INFO : EPOCH 31: training on 99524 raw words (62711 effective words) took 0.2s, 340378 effective words/s\n",
      "2023-12-06 14:25:28,209 : INFO : EPOCH 32: training on 99524 raw words (62624 effective words) took 0.2s, 308431 effective words/s\n",
      "2023-12-06 14:25:28,424 : INFO : EPOCH 33: training on 99524 raw words (62664 effective words) took 0.2s, 299359 effective words/s\n",
      "2023-12-06 14:25:28,631 : INFO : EPOCH 34: training on 99524 raw words (62752 effective words) took 0.2s, 309543 effective words/s\n",
      "2023-12-06 14:25:28,826 : INFO : EPOCH 35: training on 99524 raw words (62673 effective words) took 0.2s, 328509 effective words/s\n",
      "2023-12-06 14:25:29,013 : INFO : EPOCH 36: training on 99524 raw words (62694 effective words) took 0.2s, 341386 effective words/s\n",
      "2023-12-06 14:25:29,217 : INFO : EPOCH 37: training on 99524 raw words (62715 effective words) took 0.2s, 314782 effective words/s\n",
      "2023-12-06 14:25:29,415 : INFO : EPOCH 38: training on 99524 raw words (62642 effective words) took 0.2s, 323508 effective words/s\n",
      "2023-12-06 14:25:29,624 : INFO : EPOCH 39: training on 99524 raw words (62762 effective words) took 0.2s, 306330 effective words/s\n",
      "2023-12-06 14:25:29,829 : INFO : EPOCH 40: training on 99524 raw words (62731 effective words) took 0.2s, 313141 effective words/s\n",
      "2023-12-06 14:25:30,033 : INFO : EPOCH 41: training on 99524 raw words (62742 effective words) took 0.2s, 314048 effective words/s\n",
      "2023-12-06 14:25:30,223 : INFO : EPOCH 42: training on 99524 raw words (62758 effective words) took 0.2s, 336413 effective words/s\n",
      "2023-12-06 14:25:30,414 : INFO : EPOCH 43: training on 99524 raw words (62824 effective words) took 0.2s, 336494 effective words/s\n",
      "2023-12-06 14:25:30,605 : INFO : EPOCH 44: training on 99524 raw words (62573 effective words) took 0.2s, 336943 effective words/s\n",
      "2023-12-06 14:25:30,806 : INFO : EPOCH 45: training on 99524 raw words (62841 effective words) took 0.2s, 318179 effective words/s\n",
      "2023-12-06 14:25:30,999 : INFO : EPOCH 46: training on 99524 raw words (62872 effective words) took 0.2s, 334644 effective words/s\n",
      "2023-12-06 14:25:31,191 : INFO : EPOCH 47: training on 99524 raw words (62645 effective words) took 0.2s, 332988 effective words/s\n",
      "2023-12-06 14:25:31,384 : INFO : EPOCH 48: training on 99524 raw words (62839 effective words) took 0.2s, 334665 effective words/s\n",
      "2023-12-06 14:25:31,577 : INFO : EPOCH 49: training on 99524 raw words (62617 effective words) took 0.2s, 332062 effective words/s\n",
      "2023-12-06 14:25:31,578 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136369 effective words) took 10.0s, 314635 effective words/s', 'datetime': '2023-12-06T14:25:31.578306', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:25:31,578 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:25:31.578306', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 14%|        | 70/486 [11:54<1:16:01, 10.97s/it]2023-12-06 14:25:35,372 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:25:35,373 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:25:35,393 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:25:35,394 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:25:35,399 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:25:35.399454', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:25:35,399 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:25:35.399454', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:25:35,405 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:25:35,406 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:25:35,406 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:25:35.406081', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:25:35,414 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:25:35,414 : INFO : resetting layer weights\n",
      "2023-12-06 14:25:35,416 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:25:35.416256', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:25:35,630 : INFO : EPOCH 0: training on 99524 raw words (62704 effective words) took 0.2s, 297392 effective words/s\n",
      "2023-12-06 14:25:35,824 : INFO : EPOCH 1: training on 99524 raw words (62694 effective words) took 0.2s, 330371 effective words/s\n",
      "2023-12-06 14:25:36,016 : INFO : EPOCH 2: training on 99524 raw words (62751 effective words) took 0.2s, 334658 effective words/s\n",
      "2023-12-06 14:25:36,210 : INFO : EPOCH 3: training on 99524 raw words (62629 effective words) took 0.2s, 330624 effective words/s\n",
      "2023-12-06 14:25:36,413 : INFO : EPOCH 4: training on 99524 raw words (62718 effective words) took 0.2s, 314597 effective words/s\n",
      "2023-12-06 14:25:36,606 : INFO : EPOCH 5: training on 99524 raw words (62656 effective words) took 0.2s, 332434 effective words/s\n",
      "2023-12-06 14:25:36,815 : INFO : EPOCH 6: training on 99524 raw words (62771 effective words) took 0.2s, 306840 effective words/s\n",
      "2023-12-06 14:25:37,019 : INFO : EPOCH 7: training on 99524 raw words (62690 effective words) took 0.2s, 315383 effective words/s\n",
      "2023-12-06 14:25:37,249 : INFO : EPOCH 8: training on 99524 raw words (62642 effective words) took 0.2s, 278277 effective words/s\n",
      "2023-12-06 14:25:37,459 : INFO : EPOCH 9: training on 99524 raw words (62624 effective words) took 0.2s, 304245 effective words/s\n",
      "2023-12-06 14:25:37,657 : INFO : EPOCH 10: training on 99524 raw words (62932 effective words) took 0.2s, 325292 effective words/s\n",
      "2023-12-06 14:25:37,855 : INFO : EPOCH 11: training on 99524 raw words (62783 effective words) took 0.2s, 325119 effective words/s\n",
      "2023-12-06 14:25:38,079 : INFO : EPOCH 12: training on 99524 raw words (62640 effective words) took 0.2s, 284333 effective words/s\n",
      "2023-12-06 14:25:38,288 : INFO : EPOCH 13: training on 99524 raw words (62886 effective words) took 0.2s, 309005 effective words/s\n",
      "2023-12-06 14:25:38,483 : INFO : EPOCH 14: training on 99524 raw words (62733 effective words) took 0.2s, 328734 effective words/s\n",
      "2023-12-06 14:25:38,675 : INFO : EPOCH 15: training on 99524 raw words (62765 effective words) took 0.2s, 333650 effective words/s\n",
      "2023-12-06 14:25:38,882 : INFO : EPOCH 16: training on 99524 raw words (62741 effective words) took 0.2s, 311067 effective words/s\n",
      "2023-12-06 14:25:39,087 : INFO : EPOCH 17: training on 99524 raw words (62679 effective words) took 0.2s, 310838 effective words/s\n",
      "2023-12-06 14:25:39,290 : INFO : EPOCH 18: training on 99524 raw words (62712 effective words) took 0.2s, 315938 effective words/s\n",
      "2023-12-06 14:25:39,482 : INFO : EPOCH 19: training on 99524 raw words (62835 effective words) took 0.2s, 334250 effective words/s\n",
      "2023-12-06 14:25:39,684 : INFO : EPOCH 20: training on 99524 raw words (62723 effective words) took 0.2s, 318174 effective words/s\n",
      "2023-12-06 14:25:39,878 : INFO : EPOCH 21: training on 99524 raw words (62520 effective words) took 0.2s, 330406 effective words/s\n",
      "2023-12-06 14:25:40,072 : INFO : EPOCH 22: training on 99524 raw words (62669 effective words) took 0.2s, 329872 effective words/s\n",
      "2023-12-06 14:25:40,266 : INFO : EPOCH 23: training on 99524 raw words (62726 effective words) took 0.2s, 331638 effective words/s\n",
      "2023-12-06 14:25:40,471 : INFO : EPOCH 24: training on 99524 raw words (62732 effective words) took 0.2s, 312001 effective words/s\n",
      "2023-12-06 14:25:40,664 : INFO : EPOCH 25: training on 99524 raw words (62748 effective words) took 0.2s, 332919 effective words/s\n",
      "2023-12-06 14:25:40,858 : INFO : EPOCH 26: training on 99524 raw words (62694 effective words) took 0.2s, 329647 effective words/s\n",
      "2023-12-06 14:25:41,054 : INFO : EPOCH 27: training on 99524 raw words (62598 effective words) took 0.2s, 327948 effective words/s\n",
      "2023-12-06 14:25:41,255 : INFO : EPOCH 28: training on 99524 raw words (62547 effective words) took 0.2s, 317926 effective words/s\n",
      "2023-12-06 14:25:41,447 : INFO : EPOCH 29: training on 99524 raw words (62663 effective words) took 0.2s, 332050 effective words/s\n",
      "2023-12-06 14:25:41,640 : INFO : EPOCH 30: training on 99524 raw words (62713 effective words) took 0.2s, 333291 effective words/s\n",
      "2023-12-06 14:25:41,832 : INFO : EPOCH 31: training on 99524 raw words (62667 effective words) took 0.2s, 333839 effective words/s\n",
      "2023-12-06 14:25:42,037 : INFO : EPOCH 32: training on 99524 raw words (62674 effective words) took 0.2s, 313358 effective words/s\n",
      "2023-12-06 14:25:42,229 : INFO : EPOCH 33: training on 99524 raw words (62567 effective words) took 0.2s, 332115 effective words/s\n",
      "2023-12-06 14:25:42,423 : INFO : EPOCH 34: training on 99524 raw words (62859 effective words) took 0.2s, 331170 effective words/s\n",
      "2023-12-06 14:25:42,627 : INFO : EPOCH 35: training on 99524 raw words (62799 effective words) took 0.2s, 315041 effective words/s\n",
      "2023-12-06 14:25:42,832 : INFO : EPOCH 36: training on 99524 raw words (62648 effective words) took 0.2s, 311762 effective words/s\n",
      "2023-12-06 14:25:43,023 : INFO : EPOCH 37: training on 99524 raw words (62789 effective words) took 0.2s, 334300 effective words/s\n",
      "2023-12-06 14:25:43,219 : INFO : EPOCH 38: training on 99524 raw words (62658 effective words) took 0.2s, 329912 effective words/s\n",
      "2023-12-06 14:25:43,431 : INFO : EPOCH 39: training on 99524 raw words (62572 effective words) took 0.2s, 300068 effective words/s\n",
      "2023-12-06 14:25:43,634 : INFO : EPOCH 40: training on 99524 raw words (62762 effective words) took 0.2s, 315777 effective words/s\n",
      "2023-12-06 14:25:43,828 : INFO : EPOCH 41: training on 99524 raw words (62675 effective words) took 0.2s, 331771 effective words/s\n",
      "2023-12-06 14:25:44,022 : INFO : EPOCH 42: training on 99524 raw words (62738 effective words) took 0.2s, 329756 effective words/s\n",
      "2023-12-06 14:25:44,217 : INFO : EPOCH 43: training on 99524 raw words (62700 effective words) took 0.2s, 330410 effective words/s\n",
      "2023-12-06 14:25:44,421 : INFO : EPOCH 44: training on 99524 raw words (62662 effective words) took 0.2s, 312636 effective words/s\n",
      "2023-12-06 14:25:44,617 : INFO : EPOCH 45: training on 99524 raw words (62724 effective words) took 0.2s, 328023 effective words/s\n",
      "2023-12-06 14:25:44,808 : INFO : EPOCH 46: training on 99524 raw words (62669 effective words) took 0.2s, 334925 effective words/s\n",
      "2023-12-06 14:25:45,002 : INFO : EPOCH 47: training on 99524 raw words (62784 effective words) took 0.2s, 330921 effective words/s\n",
      "2023-12-06 14:25:45,209 : INFO : EPOCH 48: training on 99524 raw words (62637 effective words) took 0.2s, 308538 effective words/s\n",
      "2023-12-06 14:25:45,403 : INFO : EPOCH 49: training on 99524 raw words (62820 effective words) took 0.2s, 329833 effective words/s\n",
      "2023-12-06 14:25:45,404 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3135322 effective words) took 10.0s, 313901 effective words/s', 'datetime': '2023-12-06T14:25:45.404921', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:25:45,405 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:25:45.405922', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 15%|        | 71/486 [12:08<1:22:37, 11.95s/it]2023-12-06 14:25:49,603 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:25:49,603 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:25:49,625 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:25:49,626 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:25:49,630 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:25:49.630177', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:25:49,630 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:25:49.630177', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:25:49,636 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:25:49,637 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:25:49,637 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:25:49.637303', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:25:49,645 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:25:49,645 : INFO : resetting layer weights\n",
      "2023-12-06 14:25:49,648 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:25:49.648073', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:25:49,859 : INFO : EPOCH 0: training on 99524 raw words (62739 effective words) took 0.2s, 301469 effective words/s\n",
      "2023-12-06 14:25:50,060 : INFO : EPOCH 1: training on 99524 raw words (62625 effective words) took 0.2s, 319282 effective words/s\n",
      "2023-12-06 14:25:50,257 : INFO : EPOCH 2: training on 99524 raw words (62901 effective words) took 0.2s, 325675 effective words/s\n",
      "2023-12-06 14:25:50,473 : INFO : EPOCH 3: training on 99524 raw words (62565 effective words) took 0.2s, 295802 effective words/s\n",
      "2023-12-06 14:25:50,682 : INFO : EPOCH 4: training on 99524 raw words (62799 effective words) took 0.2s, 307377 effective words/s\n",
      "2023-12-06 14:25:50,880 : INFO : EPOCH 5: training on 99524 raw words (62754 effective words) took 0.2s, 324201 effective words/s\n",
      "2023-12-06 14:25:51,093 : INFO : EPOCH 6: training on 99524 raw words (62699 effective words) took 0.2s, 300028 effective words/s\n",
      "2023-12-06 14:25:51,303 : INFO : EPOCH 7: training on 99524 raw words (62758 effective words) took 0.2s, 306704 effective words/s\n",
      "2023-12-06 14:25:51,518 : INFO : EPOCH 8: training on 99524 raw words (62563 effective words) took 0.2s, 296805 effective words/s\n",
      "2023-12-06 14:25:51,721 : INFO : EPOCH 9: training on 99524 raw words (62863 effective words) took 0.2s, 315025 effective words/s\n",
      "2023-12-06 14:25:51,920 : INFO : EPOCH 10: training on 99524 raw words (62671 effective words) took 0.2s, 321365 effective words/s\n",
      "2023-12-06 14:25:52,120 : INFO : EPOCH 11: training on 99524 raw words (62637 effective words) took 0.2s, 319799 effective words/s\n",
      "2023-12-06 14:25:52,330 : INFO : EPOCH 12: training on 99524 raw words (62772 effective words) took 0.2s, 305980 effective words/s\n",
      "2023-12-06 14:25:52,531 : INFO : EPOCH 13: training on 99524 raw words (62714 effective words) took 0.2s, 320330 effective words/s\n",
      "2023-12-06 14:25:52,731 : INFO : EPOCH 14: training on 99524 raw words (62756 effective words) took 0.2s, 321255 effective words/s\n",
      "2023-12-06 14:25:52,929 : INFO : EPOCH 15: training on 99524 raw words (62815 effective words) took 0.2s, 323067 effective words/s\n",
      "2023-12-06 14:25:53,139 : INFO : EPOCH 16: training on 99524 raw words (62667 effective words) took 0.2s, 305644 effective words/s\n",
      "2023-12-06 14:25:53,342 : INFO : EPOCH 17: training on 99524 raw words (62507 effective words) took 0.2s, 313269 effective words/s\n",
      "2023-12-06 14:25:53,540 : INFO : EPOCH 18: training on 99524 raw words (62649 effective words) took 0.2s, 323215 effective words/s\n",
      "2023-12-06 14:25:53,740 : INFO : EPOCH 19: training on 99524 raw words (62563 effective words) took 0.2s, 322749 effective words/s\n",
      "2023-12-06 14:25:53,948 : INFO : EPOCH 20: training on 99524 raw words (62668 effective words) took 0.2s, 307629 effective words/s\n",
      "2023-12-06 14:25:54,146 : INFO : EPOCH 21: training on 99524 raw words (62745 effective words) took 0.2s, 325379 effective words/s\n",
      "2023-12-06 14:25:54,343 : INFO : EPOCH 22: training on 99524 raw words (62713 effective words) took 0.2s, 324216 effective words/s\n",
      "2023-12-06 14:25:54,541 : INFO : EPOCH 23: training on 99524 raw words (62846 effective words) took 0.2s, 326722 effective words/s\n",
      "2023-12-06 14:25:54,747 : INFO : EPOCH 24: training on 99524 raw words (62661 effective words) took 0.2s, 309323 effective words/s\n",
      "2023-12-06 14:25:54,948 : INFO : EPOCH 25: training on 99524 raw words (62690 effective words) took 0.2s, 319555 effective words/s\n",
      "2023-12-06 14:25:55,145 : INFO : EPOCH 26: training on 99524 raw words (62918 effective words) took 0.2s, 327037 effective words/s\n",
      "2023-12-06 14:25:55,342 : INFO : EPOCH 27: training on 99524 raw words (62544 effective words) took 0.2s, 324578 effective words/s\n",
      "2023-12-06 14:25:55,549 : INFO : EPOCH 28: training on 99524 raw words (62725 effective words) took 0.2s, 309168 effective words/s\n",
      "2023-12-06 14:25:55,746 : INFO : EPOCH 29: training on 99524 raw words (62687 effective words) took 0.2s, 325092 effective words/s\n",
      "2023-12-06 14:25:55,941 : INFO : EPOCH 30: training on 99524 raw words (62688 effective words) took 0.2s, 328319 effective words/s\n",
      "2023-12-06 14:25:56,147 : INFO : EPOCH 31: training on 99524 raw words (62713 effective words) took 0.2s, 310187 effective words/s\n",
      "2023-12-06 14:25:56,345 : INFO : EPOCH 32: training on 99524 raw words (62635 effective words) took 0.2s, 324413 effective words/s\n",
      "2023-12-06 14:25:56,545 : INFO : EPOCH 33: training on 99524 raw words (62622 effective words) took 0.2s, 321287 effective words/s\n",
      "2023-12-06 14:25:56,744 : INFO : EPOCH 34: training on 99524 raw words (62511 effective words) took 0.2s, 319919 effective words/s\n",
      "2023-12-06 14:25:56,955 : INFO : EPOCH 35: training on 99524 raw words (62792 effective words) took 0.2s, 302810 effective words/s\n",
      "2023-12-06 14:25:57,157 : INFO : EPOCH 36: training on 99524 raw words (62897 effective words) took 0.2s, 320503 effective words/s\n",
      "2023-12-06 14:25:57,356 : INFO : EPOCH 37: training on 99524 raw words (62591 effective words) took 0.2s, 322280 effective words/s\n",
      "2023-12-06 14:25:57,553 : INFO : EPOCH 38: training on 99524 raw words (62665 effective words) took 0.2s, 326344 effective words/s\n",
      "2023-12-06 14:25:57,763 : INFO : EPOCH 39: training on 99524 raw words (62732 effective words) took 0.2s, 303648 effective words/s\n",
      "2023-12-06 14:25:57,979 : INFO : EPOCH 40: training on 99524 raw words (62695 effective words) took 0.2s, 297714 effective words/s\n",
      "2023-12-06 14:25:58,177 : INFO : EPOCH 41: training on 99524 raw words (62676 effective words) took 0.2s, 324554 effective words/s\n",
      "2023-12-06 14:25:58,375 : INFO : EPOCH 42: training on 99524 raw words (62587 effective words) took 0.2s, 322766 effective words/s\n",
      "2023-12-06 14:25:58,583 : INFO : EPOCH 43: training on 99524 raw words (62680 effective words) took 0.2s, 306177 effective words/s\n",
      "2023-12-06 14:25:58,783 : INFO : EPOCH 44: training on 99524 raw words (62757 effective words) took 0.2s, 321116 effective words/s\n",
      "2023-12-06 14:25:58,981 : INFO : EPOCH 45: training on 99524 raw words (62704 effective words) took 0.2s, 324230 effective words/s\n",
      "2023-12-06 14:25:59,200 : INFO : EPOCH 46: training on 99524 raw words (62789 effective words) took 0.2s, 292558 effective words/s\n",
      "2023-12-06 14:25:59,411 : INFO : EPOCH 47: training on 99524 raw words (62775 effective words) took 0.2s, 303054 effective words/s\n",
      "2023-12-06 14:25:59,612 : INFO : EPOCH 48: training on 99524 raw words (62805 effective words) took 0.2s, 320801 effective words/s\n",
      "2023-12-06 14:25:59,811 : INFO : EPOCH 49: training on 99524 raw words (62676 effective words) took 0.2s, 321543 effective words/s\n",
      "2023-12-06 14:25:59,811 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3135204 effective words) took 10.2s, 308487 effective words/s', 'datetime': '2023-12-06T14:25:59.811928', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:25:59,811 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:25:59.811928', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 15%|        | 72/486 [12:22<1:27:46, 12.72s/it]2023-12-06 14:26:04,134 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:26:04,134 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:26:04,155 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:26:04,157 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:26:04,161 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:26:04.161269', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:26:04,162 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:26:04.162275', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:26:04,166 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:26:04,167 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:26:04,167 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:26:04.167056', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:26:04,172 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:26:04,174 : INFO : resetting layer weights\n",
      "2023-12-06 14:26:04,175 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:26:04.175276', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:26:04,376 : INFO : EPOCH 0: training on 99524 raw words (60638 effective words) took 0.2s, 307686 effective words/s\n",
      "2023-12-06 14:26:04,559 : INFO : EPOCH 1: training on 99524 raw words (60369 effective words) took 0.2s, 337359 effective words/s\n",
      "2023-12-06 14:26:04,747 : INFO : EPOCH 2: training on 99524 raw words (60344 effective words) took 0.2s, 329935 effective words/s\n",
      "2023-12-06 14:26:04,931 : INFO : EPOCH 3: training on 99524 raw words (60371 effective words) took 0.2s, 334881 effective words/s\n",
      "2023-12-06 14:26:05,124 : INFO : EPOCH 4: training on 99524 raw words (60472 effective words) took 0.2s, 320323 effective words/s\n",
      "2023-12-06 14:26:05,311 : INFO : EPOCH 5: training on 99524 raw words (60305 effective words) took 0.2s, 330842 effective words/s\n",
      "2023-12-06 14:26:05,496 : INFO : EPOCH 6: training on 99524 raw words (60416 effective words) took 0.2s, 332739 effective words/s\n",
      "2023-12-06 14:26:05,690 : INFO : EPOCH 7: training on 99524 raw words (60254 effective words) took 0.2s, 318673 effective words/s\n",
      "2023-12-06 14:26:05,874 : INFO : EPOCH 8: training on 99524 raw words (60615 effective words) took 0.2s, 336191 effective words/s\n",
      "2023-12-06 14:26:06,077 : INFO : EPOCH 9: training on 99524 raw words (60343 effective words) took 0.2s, 303711 effective words/s\n",
      "2023-12-06 14:26:06,078 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604127 effective words) took 1.9s, 317516 effective words/s', 'datetime': '2023-12-06T14:26:06.078581', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:26:06,079 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:26:06.079598', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 15%|        | 73/486 [12:27<1:10:43, 10.27s/it]2023-12-06 14:26:08,698 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:26:08,698 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:26:08,718 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:26:08,719 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:26:08,723 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:26:08.723052', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:26:08,724 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:26:08.724052', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:26:08,728 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:26:08,729 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:26:08,729 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:26:08.729050', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:26:08,736 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:26:08,737 : INFO : resetting layer weights\n",
      "2023-12-06 14:26:08,739 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:26:08.739085', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:26:08,957 : INFO : EPOCH 0: training on 99524 raw words (60413 effective words) took 0.2s, 280731 effective words/s\n",
      "2023-12-06 14:26:09,145 : INFO : EPOCH 1: training on 99524 raw words (60287 effective words) took 0.2s, 327829 effective words/s\n",
      "2023-12-06 14:26:09,333 : INFO : EPOCH 2: training on 99524 raw words (60457 effective words) took 0.2s, 329667 effective words/s\n",
      "2023-12-06 14:26:09,520 : INFO : EPOCH 3: training on 99524 raw words (60449 effective words) took 0.2s, 330463 effective words/s\n",
      "2023-12-06 14:26:09,721 : INFO : EPOCH 4: training on 99524 raw words (60381 effective words) took 0.2s, 306699 effective words/s\n",
      "2023-12-06 14:26:09,908 : INFO : EPOCH 5: training on 99524 raw words (60258 effective words) took 0.2s, 328301 effective words/s\n",
      "2023-12-06 14:26:10,096 : INFO : EPOCH 6: training on 99524 raw words (60458 effective words) took 0.2s, 330397 effective words/s\n",
      "2023-12-06 14:26:10,284 : INFO : EPOCH 7: training on 99524 raw words (60457 effective words) took 0.2s, 329382 effective words/s\n",
      "2023-12-06 14:26:10,477 : INFO : EPOCH 8: training on 99524 raw words (60391 effective words) took 0.2s, 318904 effective words/s\n",
      "2023-12-06 14:26:10,664 : INFO : EPOCH 9: training on 99524 raw words (60515 effective words) took 0.2s, 330920 effective words/s\n",
      "2023-12-06 14:26:10,665 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604066 effective words) took 1.9s, 313564 effective words/s', 'datetime': '2023-12-06T14:26:10.665619', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:26:10,666 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:26:10.666619', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 15%|        | 74/486 [12:31<58:54,  8.58s/it]  2023-12-06 14:26:13,324 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:26:13,325 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:26:13,345 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:26:13,346 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:26:13,351 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:26:13.351074', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:26:13,352 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:26:13.352078', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:26:13,358 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:26:13,358 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:26:13,359 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:26:13.359854', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:26:13,366 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:26:13,367 : INFO : resetting layer weights\n",
      "2023-12-06 14:26:13,369 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:26:13.369075', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:26:13,633 : INFO : EPOCH 0: training on 99524 raw words (60462 effective words) took 0.3s, 232427 effective words/s\n",
      "2023-12-06 14:26:13,882 : INFO : EPOCH 1: training on 99524 raw words (60306 effective words) took 0.2s, 247267 effective words/s\n",
      "2023-12-06 14:26:14,130 : INFO : EPOCH 2: training on 99524 raw words (60565 effective words) took 0.2s, 247890 effective words/s\n",
      "2023-12-06 14:26:14,378 : INFO : EPOCH 3: training on 99524 raw words (60610 effective words) took 0.2s, 248906 effective words/s\n",
      "2023-12-06 14:26:14,629 : INFO : EPOCH 4: training on 99524 raw words (60304 effective words) took 0.2s, 244616 effective words/s\n",
      "2023-12-06 14:26:14,876 : INFO : EPOCH 5: training on 99524 raw words (60377 effective words) took 0.2s, 249706 effective words/s\n",
      "2023-12-06 14:26:15,123 : INFO : EPOCH 6: training on 99524 raw words (60365 effective words) took 0.2s, 248676 effective words/s\n",
      "2023-12-06 14:26:15,370 : INFO : EPOCH 7: training on 99524 raw words (60422 effective words) took 0.2s, 248101 effective words/s\n",
      "2023-12-06 14:26:15,619 : INFO : EPOCH 8: training on 99524 raw words (60342 effective words) took 0.2s, 247473 effective words/s\n",
      "2023-12-06 14:26:15,866 : INFO : EPOCH 9: training on 99524 raw words (60290 effective words) took 0.2s, 247741 effective words/s\n",
      "2023-12-06 14:26:15,867 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604043 effective words) took 2.5s, 241808 effective words/s', 'datetime': '2023-12-06T14:26:15.867111', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:26:15,868 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:26:15.868111', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 15%|        | 75/486 [12:37<51:57,  7.58s/it]2023-12-06 14:26:18,589 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:26:18,589 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:26:18,608 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:26:18,609 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:26:18,615 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:26:18.615732', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:26:18,616 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:26:18.616732', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:26:18,620 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:26:18,621 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:26:18,621 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:26:18.621734', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:26:18,628 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:26:18,629 : INFO : resetting layer weights\n",
      "2023-12-06 14:26:18,630 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:26:18.630824', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:26:18,874 : INFO : EPOCH 0: training on 99524 raw words (60405 effective words) took 0.2s, 252853 effective words/s\n",
      "2023-12-06 14:26:19,103 : INFO : EPOCH 1: training on 99524 raw words (60298 effective words) took 0.2s, 269092 effective words/s\n",
      "2023-12-06 14:26:19,331 : INFO : EPOCH 2: training on 99524 raw words (60485 effective words) took 0.2s, 270086 effective words/s\n",
      "2023-12-06 14:26:19,563 : INFO : EPOCH 3: training on 99524 raw words (60414 effective words) took 0.2s, 265350 effective words/s\n",
      "2023-12-06 14:26:19,792 : INFO : EPOCH 4: training on 99524 raw words (60409 effective words) took 0.2s, 268832 effective words/s\n",
      "2023-12-06 14:26:20,017 : INFO : EPOCH 5: training on 99524 raw words (60369 effective words) took 0.2s, 273754 effective words/s\n",
      "2023-12-06 14:26:20,245 : INFO : EPOCH 6: training on 99524 raw words (60347 effective words) took 0.2s, 269636 effective words/s\n",
      "2023-12-06 14:26:20,476 : INFO : EPOCH 7: training on 99524 raw words (60485 effective words) took 0.2s, 266077 effective words/s\n",
      "2023-12-06 14:26:20,706 : INFO : EPOCH 8: training on 99524 raw words (60432 effective words) took 0.2s, 268656 effective words/s\n",
      "2023-12-06 14:26:20,935 : INFO : EPOCH 9: training on 99524 raw words (60457 effective words) took 0.2s, 268848 effective words/s\n",
      "2023-12-06 14:26:21,162 : INFO : EPOCH 10: training on 99524 raw words (60367 effective words) took 0.2s, 270584 effective words/s\n",
      "2023-12-06 14:26:21,396 : INFO : EPOCH 11: training on 99524 raw words (60415 effective words) took 0.2s, 262561 effective words/s\n",
      "2023-12-06 14:26:21,628 : INFO : EPOCH 12: training on 99524 raw words (60439 effective words) took 0.2s, 266157 effective words/s\n",
      "2023-12-06 14:26:21,856 : INFO : EPOCH 13: training on 99524 raw words (60404 effective words) took 0.2s, 270456 effective words/s\n",
      "2023-12-06 14:26:22,083 : INFO : EPOCH 14: training on 99524 raw words (60521 effective words) took 0.2s, 270810 effective words/s\n",
      "2023-12-06 14:26:22,319 : INFO : EPOCH 15: training on 99524 raw words (60589 effective words) took 0.2s, 262363 effective words/s\n",
      "2023-12-06 14:26:22,549 : INFO : EPOCH 16: training on 99524 raw words (60411 effective words) took 0.2s, 266717 effective words/s\n",
      "2023-12-06 14:26:22,775 : INFO : EPOCH 17: training on 99524 raw words (60370 effective words) took 0.2s, 273705 effective words/s\n",
      "2023-12-06 14:26:23,001 : INFO : EPOCH 18: training on 99524 raw words (60389 effective words) took 0.2s, 271128 effective words/s\n",
      "2023-12-06 14:26:23,235 : INFO : EPOCH 19: training on 99524 raw words (60442 effective words) took 0.2s, 263879 effective words/s\n",
      "2023-12-06 14:26:23,461 : INFO : EPOCH 20: training on 99524 raw words (60208 effective words) took 0.2s, 270200 effective words/s\n",
      "2023-12-06 14:26:23,688 : INFO : EPOCH 21: training on 99524 raw words (60419 effective words) took 0.2s, 272406 effective words/s\n",
      "2023-12-06 14:26:23,918 : INFO : EPOCH 22: training on 99524 raw words (60166 effective words) took 0.2s, 266208 effective words/s\n",
      "2023-12-06 14:26:24,152 : INFO : EPOCH 23: training on 99524 raw words (60472 effective words) took 0.2s, 262437 effective words/s\n",
      "2023-12-06 14:26:24,381 : INFO : EPOCH 24: training on 99524 raw words (60241 effective words) took 0.2s, 268738 effective words/s\n",
      "2023-12-06 14:26:24,608 : INFO : EPOCH 25: training on 99524 raw words (60327 effective words) took 0.2s, 270775 effective words/s\n",
      "2023-12-06 14:26:24,839 : INFO : EPOCH 26: training on 99524 raw words (60323 effective words) took 0.2s, 266102 effective words/s\n",
      "2023-12-06 14:26:25,073 : INFO : EPOCH 27: training on 99524 raw words (60356 effective words) took 0.2s, 262548 effective words/s\n",
      "2023-12-06 14:26:25,299 : INFO : EPOCH 28: training on 99524 raw words (60230 effective words) took 0.2s, 272654 effective words/s\n",
      "2023-12-06 14:26:25,529 : INFO : EPOCH 29: training on 99524 raw words (60401 effective words) took 0.2s, 267463 effective words/s\n",
      "2023-12-06 14:26:25,530 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811591 effective words) took 6.9s, 262608 effective words/s', 'datetime': '2023-12-06T14:26:25.530087', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:26:25,530 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:26:25.530087', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 16%|        | 76/486 [12:47<57:13,  8.37s/it]2023-12-06 14:26:28,801 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:26:28,802 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:26:28,822 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:26:28,823 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:26:28,829 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:26:28.829337', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:26:28,829 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:26:28.829337', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:26:28,834 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:26:28,834 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:26:28,835 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:26:28.835226', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:26:28,846 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:26:28,846 : INFO : resetting layer weights\n",
      "2023-12-06 14:26:28,848 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:26:28.848320', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:26:29,099 : INFO : EPOCH 0: training on 99524 raw words (60629 effective words) took 0.2s, 244496 effective words/s\n",
      "2023-12-06 14:26:29,343 : INFO : EPOCH 1: training on 99524 raw words (60538 effective words) took 0.2s, 253937 effective words/s\n",
      "2023-12-06 14:26:29,585 : INFO : EPOCH 2: training on 99524 raw words (60332 effective words) took 0.2s, 253726 effective words/s\n",
      "2023-12-06 14:26:29,828 : INFO : EPOCH 3: training on 99524 raw words (60265 effective words) took 0.2s, 252065 effective words/s\n",
      "2023-12-06 14:26:30,078 : INFO : EPOCH 4: training on 99524 raw words (60418 effective words) took 0.2s, 246181 effective words/s\n",
      "2023-12-06 14:26:30,334 : INFO : EPOCH 5: training on 99524 raw words (60271 effective words) took 0.3s, 240225 effective words/s\n",
      "2023-12-06 14:26:30,578 : INFO : EPOCH 6: training on 99524 raw words (60500 effective words) took 0.2s, 252365 effective words/s\n",
      "2023-12-06 14:26:30,818 : INFO : EPOCH 7: training on 99524 raw words (60307 effective words) took 0.2s, 254718 effective words/s\n",
      "2023-12-06 14:26:31,066 : INFO : EPOCH 8: training on 99524 raw words (60344 effective words) took 0.2s, 248713 effective words/s\n",
      "2023-12-06 14:26:31,311 : INFO : EPOCH 9: training on 99524 raw words (60339 effective words) took 0.2s, 250456 effective words/s\n",
      "2023-12-06 14:26:31,554 : INFO : EPOCH 10: training on 99524 raw words (60272 effective words) took 0.2s, 252141 effective words/s\n",
      "2023-12-06 14:26:31,795 : INFO : EPOCH 11: training on 99524 raw words (60530 effective words) took 0.2s, 256379 effective words/s\n",
      "2023-12-06 14:26:32,044 : INFO : EPOCH 12: training on 99524 raw words (60330 effective words) took 0.2s, 247145 effective words/s\n",
      "2023-12-06 14:26:32,282 : INFO : EPOCH 13: training on 99524 raw words (60257 effective words) took 0.2s, 256145 effective words/s\n",
      "2023-12-06 14:26:32,525 : INFO : EPOCH 14: training on 99524 raw words (60390 effective words) took 0.2s, 253621 effective words/s\n",
      "2023-12-06 14:26:32,776 : INFO : EPOCH 15: training on 99524 raw words (60465 effective words) took 0.2s, 246113 effective words/s\n",
      "2023-12-06 14:26:33,025 : INFO : EPOCH 16: training on 99524 raw words (60335 effective words) took 0.2s, 246835 effective words/s\n",
      "2023-12-06 14:26:33,267 : INFO : EPOCH 17: training on 99524 raw words (60151 effective words) took 0.2s, 253309 effective words/s\n",
      "2023-12-06 14:26:33,511 : INFO : EPOCH 18: training on 99524 raw words (60388 effective words) took 0.2s, 251991 effective words/s\n",
      "2023-12-06 14:26:33,755 : INFO : EPOCH 19: training on 99524 raw words (60644 effective words) took 0.2s, 252383 effective words/s\n",
      "2023-12-06 14:26:34,000 : INFO : EPOCH 20: training on 99524 raw words (60366 effective words) took 0.2s, 250583 effective words/s\n",
      "2023-12-06 14:26:34,242 : INFO : EPOCH 21: training on 99524 raw words (60355 effective words) took 0.2s, 254737 effective words/s\n",
      "2023-12-06 14:26:34,482 : INFO : EPOCH 22: training on 99524 raw words (60472 effective words) took 0.2s, 257132 effective words/s\n",
      "2023-12-06 14:26:34,723 : INFO : EPOCH 23: training on 99524 raw words (60287 effective words) took 0.2s, 255079 effective words/s\n",
      "2023-12-06 14:26:34,975 : INFO : EPOCH 24: training on 99524 raw words (60347 effective words) took 0.2s, 242605 effective words/s\n",
      "2023-12-06 14:26:35,217 : INFO : EPOCH 25: training on 99524 raw words (60451 effective words) took 0.2s, 253846 effective words/s\n",
      "2023-12-06 14:26:35,462 : INFO : EPOCH 26: training on 99524 raw words (60203 effective words) took 0.2s, 249796 effective words/s\n",
      "2023-12-06 14:26:35,705 : INFO : EPOCH 27: training on 99524 raw words (60389 effective words) took 0.2s, 253043 effective words/s\n",
      "2023-12-06 14:26:35,951 : INFO : EPOCH 28: training on 99524 raw words (60385 effective words) took 0.2s, 251215 effective words/s\n",
      "2023-12-06 14:26:36,197 : INFO : EPOCH 29: training on 99524 raw words (60326 effective words) took 0.2s, 248394 effective words/s\n",
      "2023-12-06 14:26:36,198 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811286 effective words) took 7.4s, 246419 effective words/s', 'datetime': '2023-12-06T14:26:36.198447', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:26:36,199 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:26:36.199447', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 16%|        | 77/486 [12:58<1:01:52,  9.08s/it]2023-12-06 14:26:39,521 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:26:39,521 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:26:39,541 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:26:39,542 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:26:39,548 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:26:39.548161', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:26:39,549 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:26:39.549167', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:26:39,554 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:26:39,555 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:26:39,555 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:26:39.555826', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:26:39,562 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:26:39,563 : INFO : resetting layer weights\n",
      "2023-12-06 14:26:39,565 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:26:39.565790', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:26:39,825 : INFO : EPOCH 0: training on 99524 raw words (60407 effective words) took 0.3s, 238010 effective words/s\n",
      "2023-12-06 14:26:40,071 : INFO : EPOCH 1: training on 99524 raw words (60336 effective words) took 0.2s, 248779 effective words/s\n",
      "2023-12-06 14:26:40,318 : INFO : EPOCH 2: training on 99524 raw words (60508 effective words) took 0.2s, 250327 effective words/s\n",
      "2023-12-06 14:26:40,568 : INFO : EPOCH 3: training on 99524 raw words (60357 effective words) took 0.2s, 246123 effective words/s\n",
      "2023-12-06 14:26:40,816 : INFO : EPOCH 4: training on 99524 raw words (60317 effective words) took 0.2s, 247383 effective words/s\n",
      "2023-12-06 14:26:41,063 : INFO : EPOCH 5: training on 99524 raw words (60436 effective words) took 0.2s, 249402 effective words/s\n",
      "2023-12-06 14:26:41,308 : INFO : EPOCH 6: training on 99524 raw words (60442 effective words) took 0.2s, 251864 effective words/s\n",
      "2023-12-06 14:26:41,555 : INFO : EPOCH 7: training on 99524 raw words (60464 effective words) took 0.2s, 248866 effective words/s\n",
      "2023-12-06 14:26:41,800 : INFO : EPOCH 8: training on 99524 raw words (60371 effective words) took 0.2s, 251065 effective words/s\n",
      "2023-12-06 14:26:42,048 : INFO : EPOCH 9: training on 99524 raw words (60442 effective words) took 0.2s, 248776 effective words/s\n",
      "2023-12-06 14:26:42,293 : INFO : EPOCH 10: training on 99524 raw words (60355 effective words) took 0.2s, 250274 effective words/s\n",
      "2023-12-06 14:26:42,545 : INFO : EPOCH 11: training on 99524 raw words (60302 effective words) took 0.2s, 243375 effective words/s\n",
      "2023-12-06 14:26:42,795 : INFO : EPOCH 12: training on 99524 raw words (60400 effective words) took 0.2s, 246049 effective words/s\n",
      "2023-12-06 14:26:43,042 : INFO : EPOCH 13: training on 99524 raw words (60397 effective words) took 0.2s, 249679 effective words/s\n",
      "2023-12-06 14:26:43,290 : INFO : EPOCH 14: training on 99524 raw words (60455 effective words) took 0.2s, 248719 effective words/s\n",
      "2023-12-06 14:26:43,538 : INFO : EPOCH 15: training on 99524 raw words (60398 effective words) took 0.2s, 247866 effective words/s\n",
      "2023-12-06 14:26:43,786 : INFO : EPOCH 16: training on 99524 raw words (60369 effective words) took 0.2s, 247709 effective words/s\n",
      "2023-12-06 14:26:44,034 : INFO : EPOCH 17: training on 99524 raw words (60383 effective words) took 0.2s, 248135 effective words/s\n",
      "2023-12-06 14:26:44,284 : INFO : EPOCH 18: training on 99524 raw words (60298 effective words) took 0.2s, 244658 effective words/s\n",
      "2023-12-06 14:26:44,533 : INFO : EPOCH 19: training on 99524 raw words (60487 effective words) took 0.2s, 247357 effective words/s\n",
      "2023-12-06 14:26:44,783 : INFO : EPOCH 20: training on 99524 raw words (60432 effective words) took 0.2s, 246606 effective words/s\n",
      "2023-12-06 14:26:45,032 : INFO : EPOCH 21: training on 99524 raw words (60411 effective words) took 0.2s, 246586 effective words/s\n",
      "2023-12-06 14:26:45,278 : INFO : EPOCH 22: training on 99524 raw words (60489 effective words) took 0.2s, 251169 effective words/s\n",
      "2023-12-06 14:26:45,529 : INFO : EPOCH 23: training on 99524 raw words (60391 effective words) took 0.2s, 243924 effective words/s\n",
      "2023-12-06 14:26:45,778 : INFO : EPOCH 24: training on 99524 raw words (60447 effective words) took 0.2s, 247158 effective words/s\n",
      "2023-12-06 14:26:46,025 : INFO : EPOCH 25: training on 99524 raw words (60465 effective words) took 0.2s, 249578 effective words/s\n",
      "2023-12-06 14:26:46,274 : INFO : EPOCH 26: training on 99524 raw words (60555 effective words) took 0.2s, 248376 effective words/s\n",
      "2023-12-06 14:26:46,523 : INFO : EPOCH 27: training on 99524 raw words (60512 effective words) took 0.2s, 246763 effective words/s\n",
      "2023-12-06 14:26:46,773 : INFO : EPOCH 28: training on 99524 raw words (60450 effective words) took 0.2s, 246412 effective words/s\n",
      "2023-12-06 14:26:47,020 : INFO : EPOCH 29: training on 99524 raw words (60465 effective words) took 0.2s, 249518 effective words/s\n",
      "2023-12-06 14:26:47,021 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812541 effective words) took 7.5s, 243142 effective words/s', 'datetime': '2023-12-06T14:26:47.021999', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:26:47,023 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:26:47.021999', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 16%|        | 78/486 [13:09<1:05:39,  9.66s/it]2023-12-06 14:26:50,524 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:26:50,525 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:26:50,544 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:26:50,545 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:26:50,550 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:26:50.550946', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:26:50,551 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:26:50.551946', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:26:50,555 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:26:50,556 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:26:50,556 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:26:50.556946', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:26:50,563 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:26:50,564 : INFO : resetting layer weights\n",
      "2023-12-06 14:26:50,567 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:26:50.567259', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:26:50,808 : INFO : EPOCH 0: training on 99524 raw words (60492 effective words) took 0.2s, 255089 effective words/s\n",
      "2023-12-06 14:26:51,034 : INFO : EPOCH 1: training on 99524 raw words (60333 effective words) took 0.2s, 270758 effective words/s\n",
      "2023-12-06 14:26:51,260 : INFO : EPOCH 2: training on 99524 raw words (60465 effective words) took 0.2s, 273240 effective words/s\n",
      "2023-12-06 14:26:51,494 : INFO : EPOCH 3: training on 99524 raw words (60149 effective words) took 0.2s, 262138 effective words/s\n",
      "2023-12-06 14:26:51,723 : INFO : EPOCH 4: training on 99524 raw words (60321 effective words) took 0.2s, 267585 effective words/s\n",
      "2023-12-06 14:26:51,952 : INFO : EPOCH 5: training on 99524 raw words (60308 effective words) took 0.2s, 268823 effective words/s\n",
      "2023-12-06 14:26:52,180 : INFO : EPOCH 6: training on 99524 raw words (60315 effective words) took 0.2s, 270565 effective words/s\n",
      "2023-12-06 14:26:52,418 : INFO : EPOCH 7: training on 99524 raw words (60238 effective words) took 0.2s, 256045 effective words/s\n",
      "2023-12-06 14:26:52,650 : INFO : EPOCH 8: training on 99524 raw words (60423 effective words) took 0.2s, 265789 effective words/s\n",
      "2023-12-06 14:26:52,876 : INFO : EPOCH 9: training on 99524 raw words (60331 effective words) took 0.2s, 272436 effective words/s\n",
      "2023-12-06 14:26:53,102 : INFO : EPOCH 10: training on 99524 raw words (60277 effective words) took 0.2s, 271918 effective words/s\n",
      "2023-12-06 14:26:53,337 : INFO : EPOCH 11: training on 99524 raw words (60334 effective words) took 0.2s, 262194 effective words/s\n",
      "2023-12-06 14:26:53,568 : INFO : EPOCH 12: training on 99524 raw words (60255 effective words) took 0.2s, 266085 effective words/s\n",
      "2023-12-06 14:26:53,794 : INFO : EPOCH 13: training on 99524 raw words (60349 effective words) took 0.2s, 271341 effective words/s\n",
      "2023-12-06 14:26:54,028 : INFO : EPOCH 14: training on 99524 raw words (60469 effective words) took 0.2s, 263045 effective words/s\n",
      "2023-12-06 14:26:54,260 : INFO : EPOCH 15: training on 99524 raw words (60217 effective words) took 0.2s, 264977 effective words/s\n",
      "2023-12-06 14:26:54,486 : INFO : EPOCH 16: training on 99524 raw words (60428 effective words) took 0.2s, 273525 effective words/s\n",
      "2023-12-06 14:26:54,714 : INFO : EPOCH 17: training on 99524 raw words (60481 effective words) took 0.2s, 269776 effective words/s\n",
      "2023-12-06 14:26:54,947 : INFO : EPOCH 18: training on 99524 raw words (60308 effective words) took 0.2s, 264042 effective words/s\n",
      "2023-12-06 14:26:55,178 : INFO : EPOCH 19: training on 99524 raw words (60640 effective words) took 0.2s, 268252 effective words/s\n",
      "2023-12-06 14:26:55,402 : INFO : EPOCH 20: training on 99524 raw words (60267 effective words) took 0.2s, 272898 effective words/s\n",
      "2023-12-06 14:26:55,627 : INFO : EPOCH 21: training on 99524 raw words (60438 effective words) took 0.2s, 274902 effective words/s\n",
      "2023-12-06 14:26:55,859 : INFO : EPOCH 22: training on 99524 raw words (60364 effective words) took 0.2s, 265232 effective words/s\n",
      "2023-12-06 14:26:56,093 : INFO : EPOCH 23: training on 99524 raw words (60321 effective words) took 0.2s, 262887 effective words/s\n",
      "2023-12-06 14:26:56,320 : INFO : EPOCH 24: training on 99524 raw words (60414 effective words) took 0.2s, 270713 effective words/s\n",
      "2023-12-06 14:26:56,547 : INFO : EPOCH 25: training on 99524 raw words (60583 effective words) took 0.2s, 272730 effective words/s\n",
      "2023-12-06 14:26:56,780 : INFO : EPOCH 26: training on 99524 raw words (60473 effective words) took 0.2s, 263805 effective words/s\n",
      "2023-12-06 14:26:57,011 : INFO : EPOCH 27: training on 99524 raw words (60428 effective words) took 0.2s, 267762 effective words/s\n",
      "2023-12-06 14:26:57,236 : INFO : EPOCH 28: training on 99524 raw words (60340 effective words) took 0.2s, 272613 effective words/s\n",
      "2023-12-06 14:26:57,464 : INFO : EPOCH 29: training on 99524 raw words (60285 effective words) took 0.2s, 270278 effective words/s\n",
      "2023-12-06 14:26:57,699 : INFO : EPOCH 30: training on 99524 raw words (60464 effective words) took 0.2s, 262804 effective words/s\n",
      "2023-12-06 14:26:57,926 : INFO : EPOCH 31: training on 99524 raw words (60449 effective words) took 0.2s, 270343 effective words/s\n",
      "2023-12-06 14:26:58,156 : INFO : EPOCH 32: training on 99524 raw words (60288 effective words) took 0.2s, 267871 effective words/s\n",
      "2023-12-06 14:26:58,384 : INFO : EPOCH 33: training on 99524 raw words (60472 effective words) took 0.2s, 269141 effective words/s\n",
      "2023-12-06 14:26:58,635 : INFO : EPOCH 34: training on 99524 raw words (60255 effective words) took 0.2s, 245487 effective words/s\n",
      "2023-12-06 14:26:58,867 : INFO : EPOCH 35: training on 99524 raw words (60509 effective words) took 0.2s, 264631 effective words/s\n",
      "2023-12-06 14:26:59,094 : INFO : EPOCH 36: training on 99524 raw words (60397 effective words) took 0.2s, 272178 effective words/s\n",
      "2023-12-06 14:26:59,328 : INFO : EPOCH 37: training on 99524 raw words (60288 effective words) took 0.2s, 262136 effective words/s\n",
      "2023-12-06 14:26:59,556 : INFO : EPOCH 38: training on 99524 raw words (60256 effective words) took 0.2s, 269324 effective words/s\n",
      "2023-12-06 14:26:59,783 : INFO : EPOCH 39: training on 99524 raw words (60488 effective words) took 0.2s, 271233 effective words/s\n",
      "2023-12-06 14:27:00,018 : INFO : EPOCH 40: training on 99524 raw words (60432 effective words) took 0.2s, 261313 effective words/s\n",
      "2023-12-06 14:27:00,259 : INFO : EPOCH 41: training on 99524 raw words (60448 effective words) took 0.2s, 256626 effective words/s\n",
      "2023-12-06 14:27:00,489 : INFO : EPOCH 42: training on 99524 raw words (60402 effective words) took 0.2s, 267925 effective words/s\n",
      "2023-12-06 14:27:00,717 : INFO : EPOCH 43: training on 99524 raw words (60418 effective words) took 0.2s, 270656 effective words/s\n",
      "2023-12-06 14:27:00,952 : INFO : EPOCH 44: training on 99524 raw words (60353 effective words) took 0.2s, 261721 effective words/s\n",
      "2023-12-06 14:27:01,187 : INFO : EPOCH 45: training on 99524 raw words (60383 effective words) took 0.2s, 262310 effective words/s\n",
      "2023-12-06 14:27:01,421 : INFO : EPOCH 46: training on 99524 raw words (60440 effective words) took 0.2s, 263465 effective words/s\n",
      "2023-12-06 14:27:01,652 : INFO : EPOCH 47: training on 99524 raw words (60340 effective words) took 0.2s, 266026 effective words/s\n",
      "2023-12-06 14:27:01,880 : INFO : EPOCH 48: training on 99524 raw words (60264 effective words) took 0.2s, 270928 effective words/s\n",
      "2023-12-06 14:27:02,113 : INFO : EPOCH 49: training on 99524 raw words (60357 effective words) took 0.2s, 263404 effective words/s\n",
      "2023-12-06 14:27:02,113 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3018749 effective words) took 11.5s, 261435 effective words/s', 'datetime': '2023-12-06T14:27:02.113753', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:27:02,114 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n5,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:27:02.114753', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 16%|        | 79/486 [13:24<1:16:50, 11.33s/it]2023-12-06 14:27:05,752 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:27:05,752 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:27:05,773 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:27:05,774 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:27:05,779 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:27:05.779503', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:27:05,779 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:27:05.779503', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:27:05,784 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:27:05,785 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:27:05,785 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:27:05.785503', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:27:05,792 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:27:05,792 : INFO : resetting layer weights\n",
      "2023-12-06 14:27:05,794 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:27:05.794884', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:27:06,057 : INFO : EPOCH 0: training on 99524 raw words (60414 effective words) took 0.3s, 233957 effective words/s\n",
      "2023-12-06 14:27:06,300 : INFO : EPOCH 1: training on 99524 raw words (60338 effective words) took 0.2s, 252118 effective words/s\n",
      "2023-12-06 14:27:06,540 : INFO : EPOCH 2: training on 99524 raw words (60395 effective words) took 0.2s, 256725 effective words/s\n",
      "2023-12-06 14:27:06,787 : INFO : EPOCH 3: training on 99524 raw words (60386 effective words) took 0.2s, 248743 effective words/s\n",
      "2023-12-06 14:27:07,032 : INFO : EPOCH 4: training on 99524 raw words (60360 effective words) took 0.2s, 250930 effective words/s\n",
      "2023-12-06 14:27:07,273 : INFO : EPOCH 5: training on 99524 raw words (60512 effective words) took 0.2s, 255208 effective words/s\n",
      "2023-12-06 14:27:07,516 : INFO : EPOCH 6: training on 99524 raw words (60460 effective words) took 0.2s, 254278 effective words/s\n",
      "2023-12-06 14:27:07,765 : INFO : EPOCH 7: training on 99524 raw words (60390 effective words) took 0.2s, 246543 effective words/s\n",
      "2023-12-06 14:27:08,008 : INFO : EPOCH 8: training on 99524 raw words (60488 effective words) took 0.2s, 254914 effective words/s\n",
      "2023-12-06 14:27:08,249 : INFO : EPOCH 9: training on 99524 raw words (60166 effective words) took 0.2s, 253275 effective words/s\n",
      "2023-12-06 14:27:08,493 : INFO : EPOCH 10: training on 99524 raw words (60225 effective words) took 0.2s, 250743 effective words/s\n",
      "2023-12-06 14:27:08,740 : INFO : EPOCH 11: training on 99524 raw words (60511 effective words) took 0.2s, 250299 effective words/s\n",
      "2023-12-06 14:27:08,979 : INFO : EPOCH 12: training on 99524 raw words (60433 effective words) took 0.2s, 257298 effective words/s\n",
      "2023-12-06 14:27:09,227 : INFO : EPOCH 13: training on 99524 raw words (60558 effective words) took 0.2s, 249667 effective words/s\n",
      "2023-12-06 14:27:09,468 : INFO : EPOCH 14: training on 99524 raw words (60409 effective words) took 0.2s, 255040 effective words/s\n",
      "2023-12-06 14:27:09,710 : INFO : EPOCH 15: training on 99524 raw words (60520 effective words) took 0.2s, 253851 effective words/s\n",
      "2023-12-06 14:27:09,957 : INFO : EPOCH 16: training on 99524 raw words (60303 effective words) took 0.2s, 249425 effective words/s\n",
      "2023-12-06 14:27:10,202 : INFO : EPOCH 17: training on 99524 raw words (60332 effective words) took 0.2s, 250240 effective words/s\n",
      "2023-12-06 14:27:10,445 : INFO : EPOCH 18: training on 99524 raw words (60258 effective words) took 0.2s, 253044 effective words/s\n",
      "2023-12-06 14:27:10,686 : INFO : EPOCH 19: training on 99524 raw words (60375 effective words) took 0.2s, 254873 effective words/s\n",
      "2023-12-06 14:27:10,928 : INFO : EPOCH 20: training on 99524 raw words (60410 effective words) took 0.2s, 253997 effective words/s\n",
      "2023-12-06 14:27:11,171 : INFO : EPOCH 21: training on 99524 raw words (60408 effective words) took 0.2s, 253256 effective words/s\n",
      "2023-12-06 14:27:11,412 : INFO : EPOCH 22: training on 99524 raw words (60303 effective words) took 0.2s, 254773 effective words/s\n",
      "2023-12-06 14:27:11,652 : INFO : EPOCH 23: training on 99524 raw words (60359 effective words) took 0.2s, 257243 effective words/s\n",
      "2023-12-06 14:27:11,900 : INFO : EPOCH 24: training on 99524 raw words (60370 effective words) took 0.2s, 247405 effective words/s\n",
      "2023-12-06 14:27:12,147 : INFO : EPOCH 25: training on 99524 raw words (60293 effective words) took 0.2s, 249507 effective words/s\n",
      "2023-12-06 14:27:12,388 : INFO : EPOCH 26: training on 99524 raw words (60489 effective words) took 0.2s, 255044 effective words/s\n",
      "2023-12-06 14:27:12,628 : INFO : EPOCH 27: training on 99524 raw words (60525 effective words) took 0.2s, 256720 effective words/s\n",
      "2023-12-06 14:27:12,882 : INFO : EPOCH 28: training on 99524 raw words (60377 effective words) took 0.2s, 241750 effective words/s\n",
      "2023-12-06 14:27:13,151 : INFO : EPOCH 29: training on 99524 raw words (60337 effective words) took 0.3s, 230013 effective words/s\n",
      "2023-12-06 14:27:13,404 : INFO : EPOCH 30: training on 99524 raw words (60365 effective words) took 0.2s, 243294 effective words/s\n",
      "2023-12-06 14:27:13,647 : INFO : EPOCH 31: training on 99524 raw words (60402 effective words) took 0.2s, 252905 effective words/s\n",
      "2023-12-06 14:27:13,886 : INFO : EPOCH 32: training on 99524 raw words (60228 effective words) took 0.2s, 257567 effective words/s\n",
      "2023-12-06 14:27:14,128 : INFO : EPOCH 33: training on 99524 raw words (60459 effective words) took 0.2s, 254069 effective words/s\n",
      "2023-12-06 14:27:14,375 : INFO : EPOCH 34: training on 99524 raw words (60357 effective words) took 0.2s, 248396 effective words/s\n",
      "2023-12-06 14:27:14,613 : INFO : EPOCH 35: training on 99524 raw words (60417 effective words) took 0.2s, 259442 effective words/s\n",
      "2023-12-06 14:27:14,889 : INFO : EPOCH 36: training on 99524 raw words (60369 effective words) took 0.3s, 222181 effective words/s\n",
      "2023-12-06 14:27:15,133 : INFO : EPOCH 37: training on 99524 raw words (60425 effective words) took 0.2s, 252797 effective words/s\n",
      "2023-12-06 14:27:15,372 : INFO : EPOCH 38: training on 99524 raw words (60208 effective words) took 0.2s, 255491 effective words/s\n",
      "2023-12-06 14:27:15,615 : INFO : EPOCH 39: training on 99524 raw words (60350 effective words) took 0.2s, 253929 effective words/s\n",
      "2023-12-06 14:27:15,859 : INFO : EPOCH 40: training on 99524 raw words (60506 effective words) took 0.2s, 253098 effective words/s\n",
      "2023-12-06 14:27:16,098 : INFO : EPOCH 41: training on 99524 raw words (60580 effective words) took 0.2s, 257487 effective words/s\n",
      "2023-12-06 14:27:16,352 : INFO : EPOCH 42: training on 99524 raw words (60456 effective words) took 0.2s, 242613 effective words/s\n",
      "2023-12-06 14:27:16,598 : INFO : EPOCH 43: training on 99524 raw words (60224 effective words) took 0.2s, 248884 effective words/s\n",
      "2023-12-06 14:27:16,845 : INFO : EPOCH 44: training on 99524 raw words (60455 effective words) took 0.2s, 250386 effective words/s\n",
      "2023-12-06 14:27:17,088 : INFO : EPOCH 45: training on 99524 raw words (60466 effective words) took 0.2s, 253241 effective words/s\n",
      "2023-12-06 14:27:17,326 : INFO : EPOCH 46: training on 99524 raw words (60513 effective words) took 0.2s, 258831 effective words/s\n",
      "2023-12-06 14:27:17,572 : INFO : EPOCH 47: training on 99524 raw words (60433 effective words) took 0.2s, 249939 effective words/s\n",
      "2023-12-06 14:27:17,816 : INFO : EPOCH 48: training on 99524 raw words (60384 effective words) took 0.2s, 252508 effective words/s\n",
      "2023-12-06 14:27:18,055 : INFO : EPOCH 49: training on 99524 raw words (60495 effective words) took 0.2s, 257883 effective words/s\n",
      "2023-12-06 14:27:18,056 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3019796 effective words) took 12.3s, 246300 effective words/s', 'datetime': '2023-12-06T14:27:18.056356', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:27:18,056 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n10,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:27:18.056356', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 16%|        | 80/486 [13:40<1:26:45, 12.82s/it]2023-12-06 14:27:22,057 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:27:22,057 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:27:22,077 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:27:22,078 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:27:22,083 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:27:22.083094', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:27:22,084 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:27:22.084098', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:27:22,088 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:27:22,089 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:27:22,089 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:27:22.089098', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:27:22,099 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:27:22,101 : INFO : resetting layer weights\n",
      "2023-12-06 14:27:22,102 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:27:22.102246', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:27:22,356 : INFO : EPOCH 0: training on 99524 raw words (60306 effective words) took 0.3s, 241058 effective words/s\n",
      "2023-12-06 14:27:22,606 : INFO : EPOCH 1: training on 99524 raw words (60441 effective words) took 0.2s, 245866 effective words/s\n",
      "2023-12-06 14:27:22,853 : INFO : EPOCH 2: training on 99524 raw words (60466 effective words) took 0.2s, 248477 effective words/s\n",
      "2023-12-06 14:27:23,103 : INFO : EPOCH 3: training on 99524 raw words (60323 effective words) took 0.2s, 245782 effective words/s\n",
      "2023-12-06 14:27:23,354 : INFO : EPOCH 4: training on 99524 raw words (60295 effective words) took 0.2s, 244802 effective words/s\n",
      "2023-12-06 14:27:23,602 : INFO : EPOCH 5: training on 99524 raw words (60343 effective words) took 0.2s, 248443 effective words/s\n",
      "2023-12-06 14:27:23,847 : INFO : EPOCH 6: training on 99524 raw words (60463 effective words) took 0.2s, 251271 effective words/s\n",
      "2023-12-06 14:27:24,102 : INFO : EPOCH 7: training on 99524 raw words (60284 effective words) took 0.2s, 241201 effective words/s\n",
      "2023-12-06 14:27:24,350 : INFO : EPOCH 8: training on 99524 raw words (60430 effective words) took 0.2s, 248118 effective words/s\n",
      "2023-12-06 14:27:24,597 : INFO : EPOCH 9: training on 99524 raw words (60156 effective words) took 0.2s, 247839 effective words/s\n",
      "2023-12-06 14:27:24,849 : INFO : EPOCH 10: training on 99524 raw words (60545 effective words) took 0.2s, 244196 effective words/s\n",
      "2023-12-06 14:27:25,096 : INFO : EPOCH 11: training on 99524 raw words (60361 effective words) took 0.2s, 248736 effective words/s\n",
      "2023-12-06 14:27:25,342 : INFO : EPOCH 12: training on 99524 raw words (60385 effective words) took 0.2s, 249996 effective words/s\n",
      "2023-12-06 14:27:25,593 : INFO : EPOCH 13: training on 99524 raw words (60413 effective words) took 0.2s, 244426 effective words/s\n",
      "2023-12-06 14:27:25,842 : INFO : EPOCH 14: training on 99524 raw words (60404 effective words) took 0.2s, 247794 effective words/s\n",
      "2023-12-06 14:27:26,088 : INFO : EPOCH 15: training on 99524 raw words (60546 effective words) took 0.2s, 251209 effective words/s\n",
      "2023-12-06 14:27:26,333 : INFO : EPOCH 16: training on 99524 raw words (60265 effective words) took 0.2s, 250062 effective words/s\n",
      "2023-12-06 14:27:26,586 : INFO : EPOCH 17: training on 99524 raw words (60355 effective words) took 0.2s, 243378 effective words/s\n",
      "2023-12-06 14:27:26,830 : INFO : EPOCH 18: training on 99524 raw words (60146 effective words) took 0.2s, 250576 effective words/s\n",
      "2023-12-06 14:27:27,076 : INFO : EPOCH 19: training on 99524 raw words (60304 effective words) took 0.2s, 250472 effective words/s\n",
      "2023-12-06 14:27:27,323 : INFO : EPOCH 20: training on 99524 raw words (60526 effective words) took 0.2s, 249321 effective words/s\n",
      "2023-12-06 14:27:27,571 : INFO : EPOCH 21: training on 99524 raw words (60538 effective words) took 0.2s, 249524 effective words/s\n",
      "2023-12-06 14:27:27,818 : INFO : EPOCH 22: training on 99524 raw words (60594 effective words) took 0.2s, 249383 effective words/s\n",
      "2023-12-06 14:27:28,066 : INFO : EPOCH 23: training on 99524 raw words (60404 effective words) took 0.2s, 248595 effective words/s\n",
      "2023-12-06 14:27:28,308 : INFO : EPOCH 24: training on 99524 raw words (60434 effective words) took 0.2s, 252910 effective words/s\n",
      "2023-12-06 14:27:28,562 : INFO : EPOCH 25: training on 99524 raw words (60384 effective words) took 0.2s, 243561 effective words/s\n",
      "2023-12-06 14:27:28,810 : INFO : EPOCH 26: training on 99524 raw words (60380 effective words) took 0.2s, 247710 effective words/s\n",
      "2023-12-06 14:27:29,055 : INFO : EPOCH 27: training on 99524 raw words (60569 effective words) took 0.2s, 251354 effective words/s\n",
      "2023-12-06 14:27:29,301 : INFO : EPOCH 28: training on 99524 raw words (60176 effective words) took 0.2s, 249255 effective words/s\n",
      "2023-12-06 14:27:29,551 : INFO : EPOCH 29: training on 99524 raw words (60391 effective words) took 0.2s, 246587 effective words/s\n",
      "2023-12-06 14:27:29,797 : INFO : EPOCH 30: training on 99524 raw words (60392 effective words) took 0.2s, 250182 effective words/s\n",
      "2023-12-06 14:27:30,043 : INFO : EPOCH 31: training on 99524 raw words (60361 effective words) took 0.2s, 249362 effective words/s\n",
      "2023-12-06 14:27:30,291 : INFO : EPOCH 32: training on 99524 raw words (60289 effective words) took 0.2s, 248381 effective words/s\n",
      "2023-12-06 14:27:30,540 : INFO : EPOCH 33: training on 99524 raw words (60472 effective words) took 0.2s, 247162 effective words/s\n",
      "2023-12-06 14:27:30,786 : INFO : EPOCH 34: training on 99524 raw words (60270 effective words) took 0.2s, 248914 effective words/s\n",
      "2023-12-06 14:27:31,033 : INFO : EPOCH 35: training on 99524 raw words (60397 effective words) took 0.2s, 248509 effective words/s\n",
      "2023-12-06 14:27:31,287 : INFO : EPOCH 36: training on 99524 raw words (60352 effective words) took 0.2s, 242756 effective words/s\n",
      "2023-12-06 14:27:31,534 : INFO : EPOCH 37: training on 99524 raw words (60323 effective words) took 0.2s, 248357 effective words/s\n",
      "2023-12-06 14:27:31,781 : INFO : EPOCH 38: training on 99524 raw words (60552 effective words) took 0.2s, 249088 effective words/s\n",
      "2023-12-06 14:27:32,030 : INFO : EPOCH 39: training on 99524 raw words (60167 effective words) took 0.2s, 245671 effective words/s\n",
      "2023-12-06 14:27:32,292 : INFO : EPOCH 40: training on 99524 raw words (60445 effective words) took 0.3s, 236287 effective words/s\n",
      "2023-12-06 14:27:32,541 : INFO : EPOCH 41: training on 99524 raw words (60470 effective words) took 0.2s, 245872 effective words/s\n",
      "2023-12-06 14:27:32,788 : INFO : EPOCH 42: training on 99524 raw words (60453 effective words) took 0.2s, 249552 effective words/s\n",
      "2023-12-06 14:27:33,036 : INFO : EPOCH 43: training on 99524 raw words (60300 effective words) took 0.2s, 248012 effective words/s\n",
      "2023-12-06 14:27:33,287 : INFO : EPOCH 44: training on 99524 raw words (60362 effective words) took 0.2s, 244716 effective words/s\n",
      "2023-12-06 14:27:33,534 : INFO : EPOCH 45: training on 99524 raw words (60281 effective words) took 0.2s, 249114 effective words/s\n",
      "2023-12-06 14:27:33,792 : INFO : EPOCH 46: training on 99524 raw words (60303 effective words) took 0.3s, 237867 effective words/s\n",
      "2023-12-06 14:27:33,986 : INFO : EPOCH 47: training on 99524 raw words (60411 effective words) took 0.2s, 318126 effective words/s\n",
      "2023-12-06 14:27:34,183 : INFO : EPOCH 48: training on 99524 raw words (60217 effective words) took 0.2s, 312151 effective words/s\n",
      "2023-12-06 14:27:34,397 : INFO : EPOCH 49: training on 99524 raw words (60385 effective words) took 0.2s, 287730 effective words/s\n",
      "2023-12-06 14:27:34,398 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3018829 effective words) took 12.3s, 245518 effective words/s', 'datetime': '2023-12-06T14:27:34.398561', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:27:34,398 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d50,n15,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:27:34.398561', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 17%|        | 81/486 [13:57<1:33:55, 13.91s/it]2023-12-06 14:27:38,522 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:27:38,522 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:27:38,542 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:27:38,543 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:27:38,550 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:27:38.550781', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:27:38,551 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:27:38.551782', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:27:38,558 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:27:38,558 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:27:38,559 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:27:38.559783', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:27:38,572 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:27:38,573 : INFO : resetting layer weights\n",
      "2023-12-06 14:27:38,576 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:27:38.576164', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:27:38,738 : INFO : EPOCH 0: training on 99524 raw words (65423 effective words) took 0.2s, 417317 effective words/s\n",
      "2023-12-06 14:27:38,882 : INFO : EPOCH 1: training on 99524 raw words (65554 effective words) took 0.1s, 467945 effective words/s\n",
      "2023-12-06 14:27:39,026 : INFO : EPOCH 2: training on 99524 raw words (65611 effective words) took 0.1s, 469700 effective words/s\n",
      "2023-12-06 14:27:39,177 : INFO : EPOCH 3: training on 99524 raw words (65446 effective words) took 0.1s, 446378 effective words/s\n",
      "2023-12-06 14:27:39,320 : INFO : EPOCH 4: training on 99524 raw words (65532 effective words) took 0.1s, 475559 effective words/s\n",
      "2023-12-06 14:27:39,462 : INFO : EPOCH 5: training on 99524 raw words (65541 effective words) took 0.1s, 476429 effective words/s\n",
      "2023-12-06 14:27:39,613 : INFO : EPOCH 6: training on 99524 raw words (65655 effective words) took 0.1s, 449152 effective words/s\n",
      "2023-12-06 14:27:39,756 : INFO : EPOCH 7: training on 99524 raw words (65577 effective words) took 0.1s, 468813 effective words/s\n",
      "2023-12-06 14:27:39,899 : INFO : EPOCH 8: training on 99524 raw words (65583 effective words) took 0.1s, 474434 effective words/s\n",
      "2023-12-06 14:27:40,046 : INFO : EPOCH 9: training on 99524 raw words (65650 effective words) took 0.1s, 460614 effective words/s\n",
      "2023-12-06 14:27:40,047 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655572 effective words) took 1.5s, 445733 effective words/s', 'datetime': '2023-12-06T14:27:40.047699', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:27:40,048 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:27:40.048202', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 17%|        | 82/486 [14:01<1:13:48, 10.96s/it]2023-12-06 14:27:42,591 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:27:42,591 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:27:42,612 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:27:42,613 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:27:42,620 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:27:42.620139', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:27:42,620 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:27:42.620139', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:27:42,630 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:27:42,631 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:27:42,631 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:27:42.631165', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:27:42,646 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:27:42,646 : INFO : resetting layer weights\n",
      "2023-12-06 14:27:42,648 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:27:42.648183', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:27:42,799 : INFO : EPOCH 0: training on 99524 raw words (65427 effective words) took 0.1s, 444652 effective words/s\n",
      "2023-12-06 14:27:42,943 : INFO : EPOCH 1: training on 99524 raw words (65607 effective words) took 0.1s, 470147 effective words/s\n",
      "2023-12-06 14:27:43,085 : INFO : EPOCH 2: training on 99524 raw words (65642 effective words) took 0.1s, 478876 effective words/s\n",
      "2023-12-06 14:27:43,234 : INFO : EPOCH 3: training on 99524 raw words (65547 effective words) took 0.1s, 453462 effective words/s\n",
      "2023-12-06 14:27:43,376 : INFO : EPOCH 4: training on 99524 raw words (65334 effective words) took 0.1s, 471775 effective words/s\n",
      "2023-12-06 14:27:43,519 : INFO : EPOCH 5: training on 99524 raw words (65444 effective words) took 0.1s, 475068 effective words/s\n",
      "2023-12-06 14:27:43,668 : INFO : EPOCH 6: training on 99524 raw words (65461 effective words) took 0.1s, 450711 effective words/s\n",
      "2023-12-06 14:27:43,814 : INFO : EPOCH 7: training on 99524 raw words (65550 effective words) took 0.1s, 462514 effective words/s\n",
      "2023-12-06 14:27:43,956 : INFO : EPOCH 8: training on 99524 raw words (65516 effective words) took 0.1s, 476856 effective words/s\n",
      "2023-12-06 14:27:44,112 : INFO : EPOCH 9: training on 99524 raw words (65408 effective words) took 0.2s, 433539 effective words/s\n",
      "2023-12-06 14:27:44,113 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (654936 effective words) took 1.5s, 447380 effective words/s', 'datetime': '2023-12-06T14:27:44.113534', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:27:44,114 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:27:44.114535', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 17%|        | 83/486 [14:05<59:46,  8.90s/it]  2023-12-06 14:27:46,680 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:27:46,680 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:27:46,704 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:27:46,704 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:27:46,711 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:27:46.711534', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:27:46,711 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:27:46.711534', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:27:46,722 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:27:46,723 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:27:46,724 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:27:46.724534', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:27:46,745 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:27:46,746 : INFO : resetting layer weights\n",
      "2023-12-06 14:27:46,748 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:27:46.748174', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:27:46,909 : INFO : EPOCH 0: training on 99524 raw words (65614 effective words) took 0.2s, 422646 effective words/s\n",
      "2023-12-06 14:27:47,050 : INFO : EPOCH 1: training on 99524 raw words (65732 effective words) took 0.1s, 481234 effective words/s\n",
      "2023-12-06 14:27:47,191 : INFO : EPOCH 2: training on 99524 raw words (65655 effective words) took 0.1s, 480265 effective words/s\n",
      "2023-12-06 14:27:47,337 : INFO : EPOCH 3: training on 99524 raw words (65364 effective words) took 0.1s, 459823 effective words/s\n",
      "2023-12-06 14:27:47,480 : INFO : EPOCH 4: training on 99524 raw words (65490 effective words) took 0.1s, 477599 effective words/s\n",
      "2023-12-06 14:27:47,620 : INFO : EPOCH 5: training on 99524 raw words (65364 effective words) took 0.1s, 479852 effective words/s\n",
      "2023-12-06 14:27:47,767 : INFO : EPOCH 6: training on 99524 raw words (65466 effective words) took 0.1s, 460576 effective words/s\n",
      "2023-12-06 14:27:47,909 : INFO : EPOCH 7: training on 99524 raw words (65465 effective words) took 0.1s, 474763 effective words/s\n",
      "2023-12-06 14:27:48,050 : INFO : EPOCH 8: training on 99524 raw words (65367 effective words) took 0.1s, 478504 effective words/s\n",
      "2023-12-06 14:27:48,197 : INFO : EPOCH 9: training on 99524 raw words (65602 effective words) took 0.1s, 459182 effective words/s\n",
      "2023-12-06 14:27:48,197 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655119 effective words) took 1.4s, 452209 effective words/s', 'datetime': '2023-12-06T14:27:48.197854', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:27:48,198 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:27:48.198854', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 17%|        | 84/486 [14:09<50:04,  7.47s/it]2023-12-06 14:27:50,830 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:27:50,831 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:27:50,850 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:27:50,851 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:27:50,859 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:27:50.859452', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:27:50,860 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:27:50.860451', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:27:50,866 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:27:50,868 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:27:50,868 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:27:50.868651', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:27:50,883 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:27:50,885 : INFO : resetting layer weights\n",
      "2023-12-06 14:27:50,886 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:27:50.886046', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:27:51,038 : INFO : EPOCH 0: training on 99524 raw words (65477 effective words) took 0.1s, 443924 effective words/s\n",
      "2023-12-06 14:27:51,182 : INFO : EPOCH 1: training on 99524 raw words (65565 effective words) took 0.1s, 471730 effective words/s\n",
      "2023-12-06 14:27:51,332 : INFO : EPOCH 2: training on 99524 raw words (65542 effective words) took 0.1s, 445526 effective words/s\n",
      "2023-12-06 14:27:51,480 : INFO : EPOCH 3: training on 99524 raw words (65501 effective words) took 0.1s, 459019 effective words/s\n",
      "2023-12-06 14:27:51,622 : INFO : EPOCH 4: training on 99524 raw words (65481 effective words) took 0.1s, 472076 effective words/s\n",
      "2023-12-06 14:27:51,764 : INFO : EPOCH 5: training on 99524 raw words (65373 effective words) took 0.1s, 478019 effective words/s\n",
      "2023-12-06 14:27:51,918 : INFO : EPOCH 6: training on 99524 raw words (65565 effective words) took 0.2s, 436712 effective words/s\n",
      "2023-12-06 14:27:52,064 : INFO : EPOCH 7: training on 99524 raw words (65519 effective words) took 0.1s, 465207 effective words/s\n",
      "2023-12-06 14:27:52,205 : INFO : EPOCH 8: training on 99524 raw words (65601 effective words) took 0.1s, 478173 effective words/s\n",
      "2023-12-06 14:27:52,353 : INFO : EPOCH 9: training on 99524 raw words (65545 effective words) took 0.1s, 459541 effective words/s\n",
      "2023-12-06 14:27:52,495 : INFO : EPOCH 10: training on 99524 raw words (65446 effective words) took 0.1s, 472221 effective words/s\n",
      "2023-12-06 14:27:52,636 : INFO : EPOCH 11: training on 99524 raw words (65529 effective words) took 0.1s, 481129 effective words/s\n",
      "2023-12-06 14:27:52,781 : INFO : EPOCH 12: training on 99524 raw words (65533 effective words) took 0.1s, 468008 effective words/s\n",
      "2023-12-06 14:27:52,928 : INFO : EPOCH 13: training on 99524 raw words (65549 effective words) took 0.1s, 456630 effective words/s\n",
      "2023-12-06 14:27:53,073 : INFO : EPOCH 14: training on 99524 raw words (65455 effective words) took 0.1s, 471137 effective words/s\n",
      "2023-12-06 14:27:53,217 : INFO : EPOCH 15: training on 99524 raw words (65452 effective words) took 0.1s, 463569 effective words/s\n",
      "2023-12-06 14:27:53,367 : INFO : EPOCH 16: training on 99524 raw words (65414 effective words) took 0.1s, 452161 effective words/s\n",
      "2023-12-06 14:27:53,512 : INFO : EPOCH 17: training on 99524 raw words (65572 effective words) took 0.1s, 466161 effective words/s\n",
      "2023-12-06 14:27:53,656 : INFO : EPOCH 18: training on 99524 raw words (65512 effective words) took 0.1s, 466206 effective words/s\n",
      "2023-12-06 14:27:53,804 : INFO : EPOCH 19: training on 99524 raw words (65558 effective words) took 0.1s, 456565 effective words/s\n",
      "2023-12-06 14:27:53,948 : INFO : EPOCH 20: training on 99524 raw words (65681 effective words) took 0.1s, 471567 effective words/s\n",
      "2023-12-06 14:27:54,089 : INFO : EPOCH 21: training on 99524 raw words (65579 effective words) took 0.1s, 478474 effective words/s\n",
      "2023-12-06 14:27:54,239 : INFO : EPOCH 22: training on 99524 raw words (65638 effective words) took 0.1s, 453617 effective words/s\n",
      "2023-12-06 14:27:54,386 : INFO : EPOCH 23: training on 99524 raw words (65561 effective words) took 0.1s, 456149 effective words/s\n",
      "2023-12-06 14:27:54,529 : INFO : EPOCH 24: training on 99524 raw words (65515 effective words) took 0.1s, 475625 effective words/s\n",
      "2023-12-06 14:27:54,669 : INFO : EPOCH 25: training on 99524 raw words (65482 effective words) took 0.1s, 481377 effective words/s\n",
      "2023-12-06 14:27:54,810 : INFO : EPOCH 26: training on 99524 raw words (65621 effective words) took 0.1s, 484952 effective words/s\n",
      "2023-12-06 14:27:54,957 : INFO : EPOCH 27: training on 99524 raw words (65660 effective words) took 0.1s, 457721 effective words/s\n",
      "2023-12-06 14:27:55,099 : INFO : EPOCH 28: training on 99524 raw words (65406 effective words) took 0.1s, 475639 effective words/s\n",
      "2023-12-06 14:27:55,242 : INFO : EPOCH 29: training on 99524 raw words (65653 effective words) took 0.1s, 477070 effective words/s\n",
      "2023-12-06 14:27:55,243 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965985 effective words) took 4.4s, 451282 effective words/s', 'datetime': '2023-12-06T14:27:55.243287', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:27:55,244 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:27:55.244291', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 17%|        | 85/486 [14:16<49:22,  7.39s/it]2023-12-06 14:27:58,011 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:27:58,012 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:27:58,032 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:27:58,033 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:27:58,038 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:27:58.038325', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:27:58,039 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:27:58.039325', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:27:58,046 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:27:58,046 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:27:58,047 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:27:58.047326', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:27:58,062 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:27:58,062 : INFO : resetting layer weights\n",
      "2023-12-06 14:27:58,065 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:27:58.065838', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:27:58,223 : INFO : EPOCH 0: training on 99524 raw words (65532 effective words) took 0.2s, 425961 effective words/s\n",
      "2023-12-06 14:27:58,366 : INFO : EPOCH 1: training on 99524 raw words (65494 effective words) took 0.1s, 468666 effective words/s\n",
      "2023-12-06 14:27:58,517 : INFO : EPOCH 2: training on 99524 raw words (65508 effective words) took 0.1s, 450417 effective words/s\n",
      "2023-12-06 14:27:58,663 : INFO : EPOCH 3: training on 99524 raw words (65637 effective words) took 0.1s, 466152 effective words/s\n",
      "2023-12-06 14:27:58,806 : INFO : EPOCH 4: training on 99524 raw words (65635 effective words) took 0.1s, 473170 effective words/s\n",
      "2023-12-06 14:27:58,952 : INFO : EPOCH 5: training on 99524 raw words (65391 effective words) took 0.1s, 459018 effective words/s\n",
      "2023-12-06 14:27:59,093 : INFO : EPOCH 6: training on 99524 raw words (65484 effective words) took 0.1s, 478235 effective words/s\n",
      "2023-12-06 14:27:59,240 : INFO : EPOCH 7: training on 99524 raw words (65452 effective words) took 0.1s, 461110 effective words/s\n",
      "2023-12-06 14:27:59,390 : INFO : EPOCH 8: training on 99524 raw words (65631 effective words) took 0.1s, 450628 effective words/s\n",
      "2023-12-06 14:27:59,532 : INFO : EPOCH 9: training on 99524 raw words (65482 effective words) took 0.1s, 475407 effective words/s\n",
      "2023-12-06 14:27:59,676 : INFO : EPOCH 10: training on 99524 raw words (65337 effective words) took 0.1s, 471156 effective words/s\n",
      "2023-12-06 14:27:59,819 : INFO : EPOCH 11: training on 99524 raw words (65661 effective words) took 0.1s, 477038 effective words/s\n",
      "2023-12-06 14:27:59,965 : INFO : EPOCH 12: training on 99524 raw words (65490 effective words) took 0.1s, 462419 effective words/s\n",
      "2023-12-06 14:28:00,108 : INFO : EPOCH 13: training on 99524 raw words (65547 effective words) took 0.1s, 469566 effective words/s\n",
      "2023-12-06 14:28:00,251 : INFO : EPOCH 14: training on 99524 raw words (65611 effective words) took 0.1s, 476314 effective words/s\n",
      "2023-12-06 14:28:00,398 : INFO : EPOCH 15: training on 99524 raw words (65616 effective words) took 0.1s, 458462 effective words/s\n",
      "2023-12-06 14:28:00,541 : INFO : EPOCH 16: training on 99524 raw words (65545 effective words) took 0.1s, 473551 effective words/s\n",
      "2023-12-06 14:28:00,684 : INFO : EPOCH 17: training on 99524 raw words (65391 effective words) took 0.1s, 474236 effective words/s\n",
      "2023-12-06 14:28:00,833 : INFO : EPOCH 18: training on 99524 raw words (65594 effective words) took 0.1s, 450523 effective words/s\n",
      "2023-12-06 14:28:00,975 : INFO : EPOCH 19: training on 99524 raw words (65724 effective words) took 0.1s, 475634 effective words/s\n",
      "2023-12-06 14:28:01,127 : INFO : EPOCH 20: training on 99524 raw words (65527 effective words) took 0.1s, 445812 effective words/s\n",
      "2023-12-06 14:28:01,275 : INFO : EPOCH 21: training on 99524 raw words (65470 effective words) took 0.1s, 455533 effective words/s\n",
      "2023-12-06 14:28:01,417 : INFO : EPOCH 22: training on 99524 raw words (65687 effective words) took 0.1s, 477176 effective words/s\n",
      "2023-12-06 14:28:01,559 : INFO : EPOCH 23: training on 99524 raw words (65714 effective words) took 0.1s, 476502 effective words/s\n",
      "2023-12-06 14:28:01,702 : INFO : EPOCH 24: training on 99524 raw words (65492 effective words) took 0.1s, 473929 effective words/s\n",
      "2023-12-06 14:28:01,848 : INFO : EPOCH 25: training on 99524 raw words (65533 effective words) took 0.1s, 460438 effective words/s\n",
      "2023-12-06 14:28:01,991 : INFO : EPOCH 26: training on 99524 raw words (65699 effective words) took 0.1s, 477229 effective words/s\n",
      "2023-12-06 14:28:02,134 : INFO : EPOCH 27: training on 99524 raw words (65720 effective words) took 0.1s, 474207 effective words/s\n",
      "2023-12-06 14:28:02,281 : INFO : EPOCH 28: training on 99524 raw words (65592 effective words) took 0.1s, 459302 effective words/s\n",
      "2023-12-06 14:28:02,425 : INFO : EPOCH 29: training on 99524 raw words (65471 effective words) took 0.1s, 468156 effective words/s\n",
      "2023-12-06 14:28:02,426 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1966667 effective words) took 4.4s, 451069 effective words/s', 'datetime': '2023-12-06T14:28:02.426508', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:28:02,426 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:28:02.426508', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 18%|        | 86/486 [14:23<49:08,  7.37s/it]2023-12-06 14:28:05,348 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:28:05,349 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:28:05,371 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:28:05,372 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:28:05,377 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:28:05.377030', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:28:05,378 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:28:05.378260', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:28:05,387 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:28:05,388 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:28:05,388 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:28:05.388769', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:28:05,404 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:28:05,405 : INFO : resetting layer weights\n",
      "2023-12-06 14:28:05,406 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:28:05.406478', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:28:05,563 : INFO : EPOCH 0: training on 99524 raw words (65408 effective words) took 0.2s, 428698 effective words/s\n",
      "2023-12-06 14:28:05,703 : INFO : EPOCH 1: training on 99524 raw words (65483 effective words) took 0.1s, 481619 effective words/s\n",
      "2023-12-06 14:28:05,844 : INFO : EPOCH 2: training on 99524 raw words (65612 effective words) took 0.1s, 484510 effective words/s\n",
      "2023-12-06 14:28:05,989 : INFO : EPOCH 3: training on 99524 raw words (65329 effective words) took 0.1s, 461851 effective words/s\n",
      "2023-12-06 14:28:06,128 : INFO : EPOCH 4: training on 99524 raw words (65547 effective words) took 0.1s, 485639 effective words/s\n",
      "2023-12-06 14:28:06,274 : INFO : EPOCH 5: training on 99524 raw words (65531 effective words) took 0.1s, 466457 effective words/s\n",
      "2023-12-06 14:28:06,420 : INFO : EPOCH 6: training on 99524 raw words (65497 effective words) took 0.1s, 464029 effective words/s\n",
      "2023-12-06 14:28:06,560 : INFO : EPOCH 7: training on 99524 raw words (65538 effective words) took 0.1s, 486743 effective words/s\n",
      "2023-12-06 14:28:06,700 : INFO : EPOCH 8: training on 99524 raw words (65600 effective words) took 0.1s, 481030 effective words/s\n",
      "2023-12-06 14:28:06,839 : INFO : EPOCH 9: training on 99524 raw words (65482 effective words) took 0.1s, 485370 effective words/s\n",
      "2023-12-06 14:28:06,984 : INFO : EPOCH 10: training on 99524 raw words (65480 effective words) took 0.1s, 469125 effective words/s\n",
      "2023-12-06 14:28:07,124 : INFO : EPOCH 11: training on 99524 raw words (65492 effective words) took 0.1s, 482652 effective words/s\n",
      "2023-12-06 14:28:07,264 : INFO : EPOCH 12: training on 99524 raw words (65447 effective words) took 0.1s, 477946 effective words/s\n",
      "2023-12-06 14:28:07,410 : INFO : EPOCH 13: training on 99524 raw words (65270 effective words) took 0.1s, 462279 effective words/s\n",
      "2023-12-06 14:28:07,550 : INFO : EPOCH 14: training on 99524 raw words (65615 effective words) took 0.1s, 482866 effective words/s\n",
      "2023-12-06 14:28:07,691 : INFO : EPOCH 15: training on 99524 raw words (65560 effective words) took 0.1s, 481700 effective words/s\n",
      "2023-12-06 14:28:07,837 : INFO : EPOCH 16: training on 99524 raw words (65431 effective words) took 0.1s, 462558 effective words/s\n",
      "2023-12-06 14:28:07,978 : INFO : EPOCH 17: training on 99524 raw words (65377 effective words) took 0.1s, 475873 effective words/s\n",
      "2023-12-06 14:28:08,119 : INFO : EPOCH 18: training on 99524 raw words (65447 effective words) took 0.1s, 483139 effective words/s\n",
      "2023-12-06 14:28:08,262 : INFO : EPOCH 19: training on 99524 raw words (65588 effective words) took 0.1s, 469817 effective words/s\n",
      "2023-12-06 14:28:08,402 : INFO : EPOCH 20: training on 99524 raw words (65475 effective words) took 0.1s, 483309 effective words/s\n",
      "2023-12-06 14:28:08,543 : INFO : EPOCH 21: training on 99524 raw words (65503 effective words) took 0.1s, 480170 effective words/s\n",
      "2023-12-06 14:28:08,690 : INFO : EPOCH 22: training on 99524 raw words (65622 effective words) took 0.1s, 462271 effective words/s\n",
      "2023-12-06 14:28:08,830 : INFO : EPOCH 23: training on 99524 raw words (65473 effective words) took 0.1s, 481549 effective words/s\n",
      "2023-12-06 14:28:08,971 : INFO : EPOCH 24: training on 99524 raw words (65761 effective words) took 0.1s, 482868 effective words/s\n",
      "2023-12-06 14:28:09,110 : INFO : EPOCH 25: training on 99524 raw words (65499 effective words) took 0.1s, 484900 effective words/s\n",
      "2023-12-06 14:28:09,257 : INFO : EPOCH 26: training on 99524 raw words (65709 effective words) took 0.1s, 463009 effective words/s\n",
      "2023-12-06 14:28:09,396 : INFO : EPOCH 27: training on 99524 raw words (65531 effective words) took 0.1s, 484872 effective words/s\n",
      "2023-12-06 14:28:09,535 : INFO : EPOCH 28: training on 99524 raw words (65528 effective words) took 0.1s, 486147 effective words/s\n",
      "2023-12-06 14:28:09,682 : INFO : EPOCH 29: training on 99524 raw words (65490 effective words) took 0.1s, 461593 effective words/s\n",
      "2023-12-06 14:28:09,683 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965325 effective words) took 4.3s, 459670 effective words/s', 'datetime': '2023-12-06T14:28:09.683365', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:28:09,683 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:28:09.683365', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 18%|        | 87/486 [14:31<49:12,  7.40s/it]2023-12-06 14:28:12,812 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:28:12,812 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:28:12,833 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:28:12,834 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:28:12,842 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:28:12.842296', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:28:12,842 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:28:12.842296', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:28:12,851 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:28:12,852 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:28:12,852 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:28:12.852894', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:28:12,868 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:28:12,869 : INFO : resetting layer weights\n",
      "2023-12-06 14:28:12,872 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:28:12.872222', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:28:13,023 : INFO : EPOCH 0: training on 99524 raw words (65551 effective words) took 0.1s, 441812 effective words/s\n",
      "2023-12-06 14:28:13,165 : INFO : EPOCH 1: training on 99524 raw words (65641 effective words) took 0.1s, 476270 effective words/s\n",
      "2023-12-06 14:28:13,307 : INFO : EPOCH 2: training on 99524 raw words (65742 effective words) took 0.1s, 477382 effective words/s\n",
      "2023-12-06 14:28:13,453 : INFO : EPOCH 3: training on 99524 raw words (65393 effective words) took 0.1s, 461066 effective words/s\n",
      "2023-12-06 14:28:13,596 : INFO : EPOCH 4: training on 99524 raw words (65610 effective words) took 0.1s, 476917 effective words/s\n",
      "2023-12-06 14:28:13,736 : INFO : EPOCH 5: training on 99524 raw words (65514 effective words) took 0.1s, 480769 effective words/s\n",
      "2023-12-06 14:28:13,884 : INFO : EPOCH 6: training on 99524 raw words (65478 effective words) took 0.1s, 455178 effective words/s\n",
      "2023-12-06 14:28:14,024 : INFO : EPOCH 7: training on 99524 raw words (65468 effective words) took 0.1s, 483815 effective words/s\n",
      "2023-12-06 14:28:14,166 : INFO : EPOCH 8: training on 99524 raw words (65353 effective words) took 0.1s, 475125 effective words/s\n",
      "2023-12-06 14:28:14,312 : INFO : EPOCH 9: training on 99524 raw words (65582 effective words) took 0.1s, 462405 effective words/s\n",
      "2023-12-06 14:28:14,463 : INFO : EPOCH 10: training on 99524 raw words (65419 effective words) took 0.1s, 447060 effective words/s\n",
      "2023-12-06 14:28:14,607 : INFO : EPOCH 11: training on 99524 raw words (65522 effective words) took 0.1s, 470518 effective words/s\n",
      "2023-12-06 14:28:14,752 : INFO : EPOCH 12: training on 99524 raw words (65595 effective words) took 0.1s, 464254 effective words/s\n",
      "2023-12-06 14:28:14,895 : INFO : EPOCH 13: training on 99524 raw words (65607 effective words) took 0.1s, 474522 effective words/s\n",
      "2023-12-06 14:28:15,041 : INFO : EPOCH 14: training on 99524 raw words (65630 effective words) took 0.1s, 459991 effective words/s\n",
      "2023-12-06 14:28:15,186 : INFO : EPOCH 15: training on 99524 raw words (65701 effective words) took 0.1s, 469841 effective words/s\n",
      "2023-12-06 14:28:15,335 : INFO : EPOCH 16: training on 99524 raw words (65545 effective words) took 0.1s, 454935 effective words/s\n",
      "2023-12-06 14:28:15,479 : INFO : EPOCH 17: training on 99524 raw words (65563 effective words) took 0.1s, 465911 effective words/s\n",
      "2023-12-06 14:28:15,622 : INFO : EPOCH 18: training on 99524 raw words (65578 effective words) took 0.1s, 475480 effective words/s\n",
      "2023-12-06 14:28:15,769 : INFO : EPOCH 19: training on 99524 raw words (65669 effective words) took 0.1s, 460991 effective words/s\n",
      "2023-12-06 14:28:15,910 : INFO : EPOCH 20: training on 99524 raw words (65597 effective words) took 0.1s, 478200 effective words/s\n",
      "2023-12-06 14:28:16,052 : INFO : EPOCH 21: training on 99524 raw words (65706 effective words) took 0.1s, 477563 effective words/s\n",
      "2023-12-06 14:28:16,203 : INFO : EPOCH 22: training on 99524 raw words (65603 effective words) took 0.1s, 446884 effective words/s\n",
      "2023-12-06 14:28:16,348 : INFO : EPOCH 23: training on 99524 raw words (65609 effective words) took 0.1s, 468015 effective words/s\n",
      "2023-12-06 14:28:16,488 : INFO : EPOCH 24: training on 99524 raw words (65526 effective words) took 0.1s, 479322 effective words/s\n",
      "2023-12-06 14:28:16,635 : INFO : EPOCH 25: training on 99524 raw words (65257 effective words) took 0.1s, 457440 effective words/s\n",
      "2023-12-06 14:28:16,776 : INFO : EPOCH 26: training on 99524 raw words (65643 effective words) took 0.1s, 481336 effective words/s\n",
      "2023-12-06 14:28:16,918 : INFO : EPOCH 27: training on 99524 raw words (65562 effective words) took 0.1s, 476614 effective words/s\n",
      "2023-12-06 14:28:17,060 : INFO : EPOCH 28: training on 99524 raw words (65631 effective words) took 0.1s, 477394 effective words/s\n",
      "2023-12-06 14:28:17,210 : INFO : EPOCH 29: training on 99524 raw words (65550 effective words) took 0.1s, 451573 effective words/s\n",
      "2023-12-06 14:28:17,352 : INFO : EPOCH 30: training on 99524 raw words (65507 effective words) took 0.1s, 477979 effective words/s\n",
      "2023-12-06 14:28:17,493 : INFO : EPOCH 31: training on 99524 raw words (65404 effective words) took 0.1s, 475036 effective words/s\n",
      "2023-12-06 14:28:17,643 : INFO : EPOCH 32: training on 99524 raw words (65622 effective words) took 0.1s, 452895 effective words/s\n",
      "2023-12-06 14:28:17,787 : INFO : EPOCH 33: training on 99524 raw words (65713 effective words) took 0.1s, 470871 effective words/s\n",
      "2023-12-06 14:28:17,930 : INFO : EPOCH 34: training on 99524 raw words (65584 effective words) took 0.1s, 473255 effective words/s\n",
      "2023-12-06 14:28:18,080 : INFO : EPOCH 35: training on 99524 raw words (65678 effective words) took 0.1s, 450632 effective words/s\n",
      "2023-12-06 14:28:18,222 : INFO : EPOCH 36: training on 99524 raw words (65492 effective words) took 0.1s, 475911 effective words/s\n",
      "2023-12-06 14:28:18,365 : INFO : EPOCH 37: training on 99524 raw words (65342 effective words) took 0.1s, 471719 effective words/s\n",
      "2023-12-06 14:28:18,507 : INFO : EPOCH 38: training on 99524 raw words (65492 effective words) took 0.1s, 475236 effective words/s\n",
      "2023-12-06 14:28:18,653 : INFO : EPOCH 39: training on 99524 raw words (65513 effective words) took 0.1s, 459347 effective words/s\n",
      "2023-12-06 14:28:18,800 : INFO : EPOCH 40: training on 99524 raw words (65610 effective words) took 0.1s, 461510 effective words/s\n",
      "2023-12-06 14:28:18,951 : INFO : EPOCH 41: training on 99524 raw words (65639 effective words) took 0.1s, 447269 effective words/s\n",
      "2023-12-06 14:28:19,095 : INFO : EPOCH 42: training on 99524 raw words (65571 effective words) took 0.1s, 469403 effective words/s\n",
      "2023-12-06 14:28:19,244 : INFO : EPOCH 43: training on 99524 raw words (65571 effective words) took 0.1s, 455457 effective words/s\n",
      "2023-12-06 14:28:19,386 : INFO : EPOCH 44: training on 99524 raw words (65533 effective words) took 0.1s, 474963 effective words/s\n",
      "2023-12-06 14:28:19,529 : INFO : EPOCH 45: training on 99524 raw words (65463 effective words) took 0.1s, 474100 effective words/s\n",
      "2023-12-06 14:28:19,676 : INFO : EPOCH 46: training on 99524 raw words (65591 effective words) took 0.1s, 460161 effective words/s\n",
      "2023-12-06 14:28:19,823 : INFO : EPOCH 47: training on 99524 raw words (65624 effective words) took 0.1s, 465987 effective words/s\n",
      "2023-12-06 14:28:19,966 : INFO : EPOCH 48: training on 99524 raw words (65510 effective words) took 0.1s, 471774 effective words/s\n",
      "2023-12-06 14:28:20,116 : INFO : EPOCH 49: training on 99524 raw words (65666 effective words) took 0.1s, 452752 effective words/s\n",
      "2023-12-06 14:28:20,117 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3277970 effective words) took 7.2s, 452492 effective words/s', 'datetime': '2023-12-06T14:28:20.117059', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:28:20,117 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:28:20.117059', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 18%|        | 88/486 [14:41<55:00,  8.29s/it]2023-12-06 14:28:23,190 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:28:23,191 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:28:23,211 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:28:23,212 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:28:23,218 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:28:23.218746', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:28:23,219 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:28:23.219746', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:28:23,229 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:28:23,230 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:28:23,230 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:28:23.230603', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:28:23,241 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:28:23,242 : INFO : resetting layer weights\n",
      "2023-12-06 14:28:23,244 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:28:23.243176', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:28:23,408 : INFO : EPOCH 0: training on 99524 raw words (65355 effective words) took 0.2s, 408397 effective words/s\n",
      "2023-12-06 14:28:23,550 : INFO : EPOCH 1: training on 99524 raw words (65692 effective words) took 0.1s, 475904 effective words/s\n",
      "2023-12-06 14:28:23,691 : INFO : EPOCH 2: training on 99524 raw words (65641 effective words) took 0.1s, 476787 effective words/s\n",
      "2023-12-06 14:28:23,839 : INFO : EPOCH 3: training on 99524 raw words (65342 effective words) took 0.1s, 455820 effective words/s\n",
      "2023-12-06 14:28:23,982 : INFO : EPOCH 4: training on 99524 raw words (65612 effective words) took 0.1s, 476008 effective words/s\n",
      "2023-12-06 14:28:24,124 : INFO : EPOCH 5: training on 99524 raw words (65384 effective words) took 0.1s, 470568 effective words/s\n",
      "2023-12-06 14:28:24,268 : INFO : EPOCH 6: training on 99524 raw words (65517 effective words) took 0.1s, 472062 effective words/s\n",
      "2023-12-06 14:28:24,416 : INFO : EPOCH 7: training on 99524 raw words (65507 effective words) took 0.1s, 456400 effective words/s\n",
      "2023-12-06 14:28:24,558 : INFO : EPOCH 8: training on 99524 raw words (65478 effective words) took 0.1s, 477122 effective words/s\n",
      "2023-12-06 14:28:24,700 : INFO : EPOCH 9: training on 99524 raw words (65554 effective words) took 0.1s, 474022 effective words/s\n",
      "2023-12-06 14:28:24,849 : INFO : EPOCH 10: training on 99524 raw words (65582 effective words) took 0.1s, 454374 effective words/s\n",
      "2023-12-06 14:28:24,990 : INFO : EPOCH 11: training on 99524 raw words (65521 effective words) took 0.1s, 476043 effective words/s\n",
      "2023-12-06 14:28:25,142 : INFO : EPOCH 12: training on 99524 raw words (65570 effective words) took 0.1s, 446863 effective words/s\n",
      "2023-12-06 14:28:25,292 : INFO : EPOCH 13: training on 99524 raw words (65554 effective words) took 0.1s, 451134 effective words/s\n",
      "2023-12-06 14:28:25,436 : INFO : EPOCH 14: training on 99524 raw words (65518 effective words) took 0.1s, 471009 effective words/s\n",
      "2023-12-06 14:28:25,578 : INFO : EPOCH 15: training on 99524 raw words (65697 effective words) took 0.1s, 473831 effective words/s\n",
      "2023-12-06 14:28:25,729 : INFO : EPOCH 16: training on 99524 raw words (65422 effective words) took 0.1s, 448693 effective words/s\n",
      "2023-12-06 14:28:25,881 : INFO : EPOCH 17: training on 99524 raw words (65473 effective words) took 0.1s, 443143 effective words/s\n",
      "2023-12-06 14:28:26,025 : INFO : EPOCH 18: training on 99524 raw words (65426 effective words) took 0.1s, 471015 effective words/s\n",
      "2023-12-06 14:28:26,173 : INFO : EPOCH 19: training on 99524 raw words (65615 effective words) took 0.1s, 455341 effective words/s\n",
      "2023-12-06 14:28:26,316 : INFO : EPOCH 20: training on 99524 raw words (65554 effective words) took 0.1s, 472554 effective words/s\n",
      "2023-12-06 14:28:26,460 : INFO : EPOCH 21: training on 99524 raw words (65626 effective words) took 0.1s, 471879 effective words/s\n",
      "2023-12-06 14:28:26,603 : INFO : EPOCH 22: training on 99524 raw words (65511 effective words) took 0.1s, 472721 effective words/s\n",
      "2023-12-06 14:28:26,752 : INFO : EPOCH 23: training on 99524 raw words (65478 effective words) took 0.1s, 452408 effective words/s\n",
      "2023-12-06 14:28:26,895 : INFO : EPOCH 24: training on 99524 raw words (65489 effective words) took 0.1s, 470976 effective words/s\n",
      "2023-12-06 14:28:27,039 : INFO : EPOCH 25: training on 99524 raw words (65455 effective words) took 0.1s, 472201 effective words/s\n",
      "2023-12-06 14:28:27,187 : INFO : EPOCH 26: training on 99524 raw words (65653 effective words) took 0.1s, 454765 effective words/s\n",
      "2023-12-06 14:28:27,330 : INFO : EPOCH 27: training on 99524 raw words (65626 effective words) took 0.1s, 472827 effective words/s\n",
      "2023-12-06 14:28:27,477 : INFO : EPOCH 28: training on 99524 raw words (65656 effective words) took 0.1s, 458001 effective words/s\n",
      "2023-12-06 14:28:27,621 : INFO : EPOCH 29: training on 99524 raw words (65652 effective words) took 0.1s, 471265 effective words/s\n",
      "2023-12-06 14:28:27,773 : INFO : EPOCH 30: training on 99524 raw words (65518 effective words) took 0.1s, 446748 effective words/s\n",
      "2023-12-06 14:28:27,915 : INFO : EPOCH 31: training on 99524 raw words (65488 effective words) took 0.1s, 474943 effective words/s\n",
      "2023-12-06 14:28:28,058 : INFO : EPOCH 32: training on 99524 raw words (65534 effective words) took 0.1s, 472235 effective words/s\n",
      "2023-12-06 14:28:28,206 : INFO : EPOCH 33: training on 99524 raw words (65720 effective words) took 0.1s, 456287 effective words/s\n",
      "2023-12-06 14:28:28,351 : INFO : EPOCH 34: training on 99524 raw words (65445 effective words) took 0.1s, 469706 effective words/s\n",
      "2023-12-06 14:28:28,503 : INFO : EPOCH 35: training on 99524 raw words (65660 effective words) took 0.1s, 442964 effective words/s\n",
      "2023-12-06 14:28:28,652 : INFO : EPOCH 36: training on 99524 raw words (65433 effective words) took 0.1s, 453666 effective words/s\n",
      "2023-12-06 14:28:28,797 : INFO : EPOCH 37: training on 99524 raw words (65545 effective words) took 0.1s, 467602 effective words/s\n",
      "2023-12-06 14:28:28,938 : INFO : EPOCH 38: training on 99524 raw words (65504 effective words) took 0.1s, 477606 effective words/s\n",
      "2023-12-06 14:28:29,089 : INFO : EPOCH 39: training on 99524 raw words (65522 effective words) took 0.1s, 448386 effective words/s\n",
      "2023-12-06 14:28:29,232 : INFO : EPOCH 40: training on 99524 raw words (65534 effective words) took 0.1s, 471993 effective words/s\n",
      "2023-12-06 14:28:29,375 : INFO : EPOCH 41: training on 99524 raw words (65670 effective words) took 0.1s, 472859 effective words/s\n",
      "2023-12-06 14:28:29,517 : INFO : EPOCH 42: training on 99524 raw words (65605 effective words) took 0.1s, 475824 effective words/s\n",
      "2023-12-06 14:28:29,667 : INFO : EPOCH 43: training on 99524 raw words (65669 effective words) took 0.1s, 450960 effective words/s\n",
      "2023-12-06 14:28:29,811 : INFO : EPOCH 44: training on 99524 raw words (65499 effective words) took 0.1s, 471037 effective words/s\n",
      "2023-12-06 14:28:29,954 : INFO : EPOCH 45: training on 99524 raw words (65531 effective words) took 0.1s, 473101 effective words/s\n",
      "2023-12-06 14:28:30,104 : INFO : EPOCH 46: training on 99524 raw words (65437 effective words) took 0.1s, 449601 effective words/s\n",
      "2023-12-06 14:28:30,247 : INFO : EPOCH 47: training on 99524 raw words (65471 effective words) took 0.1s, 472380 effective words/s\n",
      "2023-12-06 14:28:30,390 : INFO : EPOCH 48: training on 99524 raw words (65498 effective words) took 0.1s, 471664 effective words/s\n",
      "2023-12-06 14:28:30,532 : INFO : EPOCH 49: training on 99524 raw words (65598 effective words) took 0.1s, 475209 effective words/s\n",
      "2023-12-06 14:28:30,533 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3277041 effective words) took 7.3s, 449563 effective words/s', 'datetime': '2023-12-06T14:28:30.533994', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:28:30,533 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:28:30.533994', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 18%|        | 89/486 [14:52<59:43,  9.03s/it]2023-12-06 14:28:33,929 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:28:33,929 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:28:33,951 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:28:33,952 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:28:33,959 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:28:33.959612', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:28:33,960 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:28:33.960612', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:28:33,967 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:28:33,968 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:28:33,968 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:28:33.968120', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:28:33,985 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:28:33,985 : INFO : resetting layer weights\n",
      "2023-12-06 14:28:33,987 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:28:33.987528', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:28:34,137 : INFO : EPOCH 0: training on 99524 raw words (65505 effective words) took 0.1s, 447347 effective words/s\n",
      "2023-12-06 14:28:34,278 : INFO : EPOCH 1: training on 99524 raw words (65569 effective words) took 0.1s, 480507 effective words/s\n",
      "2023-12-06 14:28:34,418 : INFO : EPOCH 2: training on 99524 raw words (65543 effective words) took 0.1s, 482954 effective words/s\n",
      "2023-12-06 14:28:34,563 : INFO : EPOCH 3: training on 99524 raw words (65599 effective words) took 0.1s, 468948 effective words/s\n",
      "2023-12-06 14:28:34,708 : INFO : EPOCH 4: training on 99524 raw words (65498 effective words) took 0.1s, 464969 effective words/s\n",
      "2023-12-06 14:28:34,849 : INFO : EPOCH 5: training on 99524 raw words (65551 effective words) took 0.1s, 481405 effective words/s\n",
      "2023-12-06 14:28:35,002 : INFO : EPOCH 6: training on 99524 raw words (65467 effective words) took 0.1s, 440170 effective words/s\n",
      "2023-12-06 14:28:35,143 : INFO : EPOCH 7: training on 99524 raw words (65741 effective words) took 0.1s, 483889 effective words/s\n",
      "2023-12-06 14:28:35,282 : INFO : EPOCH 8: training on 99524 raw words (65610 effective words) took 0.1s, 485297 effective words/s\n",
      "2023-12-06 14:28:35,429 : INFO : EPOCH 9: training on 99524 raw words (65591 effective words) took 0.1s, 461040 effective words/s\n",
      "2023-12-06 14:28:35,568 : INFO : EPOCH 10: training on 99524 raw words (65373 effective words) took 0.1s, 485433 effective words/s\n",
      "2023-12-06 14:28:35,710 : INFO : EPOCH 11: training on 99524 raw words (65533 effective words) took 0.1s, 476385 effective words/s\n",
      "2023-12-06 14:28:35,851 : INFO : EPOCH 12: training on 99524 raw words (65528 effective words) took 0.1s, 481273 effective words/s\n",
      "2023-12-06 14:28:35,996 : INFO : EPOCH 13: training on 99524 raw words (65409 effective words) took 0.1s, 462041 effective words/s\n",
      "2023-12-06 14:28:36,136 : INFO : EPOCH 14: training on 99524 raw words (65607 effective words) took 0.1s, 488381 effective words/s\n",
      "2023-12-06 14:28:36,275 : INFO : EPOCH 15: training on 99524 raw words (65527 effective words) took 0.1s, 483188 effective words/s\n",
      "2023-12-06 14:28:36,422 : INFO : EPOCH 16: training on 99524 raw words (65352 effective words) took 0.1s, 459584 effective words/s\n",
      "2023-12-06 14:28:36,564 : INFO : EPOCH 17: training on 99524 raw words (65416 effective words) took 0.1s, 477256 effective words/s\n",
      "2023-12-06 14:28:36,704 : INFO : EPOCH 18: training on 99524 raw words (65511 effective words) took 0.1s, 482509 effective words/s\n",
      "2023-12-06 14:28:36,852 : INFO : EPOCH 19: training on 99524 raw words (65653 effective words) took 0.1s, 458317 effective words/s\n",
      "2023-12-06 14:28:36,993 : INFO : EPOCH 20: training on 99524 raw words (65446 effective words) took 0.1s, 476989 effective words/s\n",
      "2023-12-06 14:28:37,134 : INFO : EPOCH 21: training on 99524 raw words (65514 effective words) took 0.1s, 483004 effective words/s\n",
      "2023-12-06 14:28:37,279 : INFO : EPOCH 22: training on 99524 raw words (65501 effective words) took 0.1s, 464401 effective words/s\n",
      "2023-12-06 14:28:37,421 : INFO : EPOCH 23: training on 99524 raw words (65671 effective words) took 0.1s, 477178 effective words/s\n",
      "2023-12-06 14:28:37,562 : INFO : EPOCH 24: training on 99524 raw words (65709 effective words) took 0.1s, 484587 effective words/s\n",
      "2023-12-06 14:28:37,713 : INFO : EPOCH 25: training on 99524 raw words (65560 effective words) took 0.1s, 448591 effective words/s\n",
      "2023-12-06 14:28:37,859 : INFO : EPOCH 26: training on 99524 raw words (65516 effective words) took 0.1s, 461962 effective words/s\n",
      "2023-12-06 14:28:37,997 : INFO : EPOCH 27: training on 99524 raw words (65650 effective words) took 0.1s, 489361 effective words/s\n",
      "2023-12-06 14:28:38,138 : INFO : EPOCH 28: training on 99524 raw words (65575 effective words) took 0.1s, 482032 effective words/s\n",
      "2023-12-06 14:28:38,285 : INFO : EPOCH 29: training on 99524 raw words (65745 effective words) took 0.1s, 458714 effective words/s\n",
      "2023-12-06 14:28:38,426 : INFO : EPOCH 30: training on 99524 raw words (65599 effective words) took 0.1s, 484494 effective words/s\n",
      "2023-12-06 14:28:38,571 : INFO : EPOCH 31: training on 99524 raw words (65327 effective words) took 0.1s, 460948 effective words/s\n",
      "2023-12-06 14:28:38,719 : INFO : EPOCH 32: training on 99524 raw words (65592 effective words) took 0.1s, 457623 effective words/s\n",
      "2023-12-06 14:28:38,859 : INFO : EPOCH 33: training on 99524 raw words (65628 effective words) took 0.1s, 485865 effective words/s\n",
      "2023-12-06 14:28:39,001 : INFO : EPOCH 34: training on 99524 raw words (65391 effective words) took 0.1s, 474319 effective words/s\n",
      "2023-12-06 14:28:39,147 : INFO : EPOCH 35: training on 99524 raw words (65537 effective words) took 0.1s, 467175 effective words/s\n",
      "2023-12-06 14:28:39,288 : INFO : EPOCH 36: training on 99524 raw words (65340 effective words) took 0.1s, 480392 effective words/s\n",
      "2023-12-06 14:28:39,428 : INFO : EPOCH 37: training on 99524 raw words (65402 effective words) took 0.1s, 481152 effective words/s\n",
      "2023-12-06 14:28:39,568 : INFO : EPOCH 38: training on 99524 raw words (65344 effective words) took 0.1s, 482239 effective words/s\n",
      "2023-12-06 14:28:39,714 : INFO : EPOCH 39: training on 99524 raw words (65383 effective words) took 0.1s, 463086 effective words/s\n",
      "2023-12-06 14:28:39,854 : INFO : EPOCH 40: training on 99524 raw words (65454 effective words) took 0.1s, 480801 effective words/s\n",
      "2023-12-06 14:28:39,995 : INFO : EPOCH 41: training on 99524 raw words (65523 effective words) took 0.1s, 479911 effective words/s\n",
      "2023-12-06 14:28:40,140 : INFO : EPOCH 42: training on 99524 raw words (65565 effective words) took 0.1s, 466789 effective words/s\n",
      "2023-12-06 14:28:40,295 : INFO : EPOCH 43: training on 99524 raw words (65447 effective words) took 0.2s, 435454 effective words/s\n",
      "2023-12-06 14:28:40,437 : INFO : EPOCH 44: training on 99524 raw words (65571 effective words) took 0.1s, 480478 effective words/s\n",
      "2023-12-06 14:28:40,584 : INFO : EPOCH 45: training on 99524 raw words (65454 effective words) took 0.1s, 457333 effective words/s\n",
      "2023-12-06 14:28:40,727 : INFO : EPOCH 46: training on 99524 raw words (65571 effective words) took 0.1s, 474352 effective words/s\n",
      "2023-12-06 14:28:40,868 : INFO : EPOCH 47: training on 99524 raw words (65369 effective words) took 0.1s, 477996 effective words/s\n",
      "2023-12-06 14:28:41,013 : INFO : EPOCH 48: training on 99524 raw words (65688 effective words) took 0.1s, 466158 effective words/s\n",
      "2023-12-06 14:28:41,155 : INFO : EPOCH 49: training on 99524 raw words (65656 effective words) took 0.1s, 480901 effective words/s\n",
      "2023-12-06 14:28:41,156 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276311 effective words) took 7.2s, 457073 effective words/s', 'datetime': '2023-12-06T14:28:41.156327', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:28:41,156 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:28:41.156327', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 19%|        | 90/486 [15:03<1:03:30,  9.62s/it]2023-12-06 14:28:44,942 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:28:44,942 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:28:44,963 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:28:44,964 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:28:44,970 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:28:44.970874', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:28:44,971 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:28:44.971874', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:28:44,976 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:28:44,977 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:28:44,978 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:28:44.978679', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:28:44,986 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:28:44,986 : INFO : resetting layer weights\n",
      "2023-12-06 14:28:44,988 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:28:44.988746', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:28:45,151 : INFO : EPOCH 0: training on 99524 raw words (62725 effective words) took 0.2s, 396066 effective words/s\n",
      "2023-12-06 14:28:45,296 : INFO : EPOCH 1: training on 99524 raw words (62730 effective words) took 0.1s, 446326 effective words/s\n",
      "2023-12-06 14:28:45,460 : INFO : EPOCH 2: training on 99524 raw words (62767 effective words) took 0.2s, 395504 effective words/s\n",
      "2023-12-06 14:28:45,616 : INFO : EPOCH 3: training on 99524 raw words (62606 effective words) took 0.2s, 413379 effective words/s\n",
      "2023-12-06 14:28:45,767 : INFO : EPOCH 4: training on 99524 raw words (62688 effective words) took 0.1s, 428133 effective words/s\n",
      "2023-12-06 14:28:45,917 : INFO : EPOCH 5: training on 99524 raw words (62745 effective words) took 0.1s, 433435 effective words/s\n",
      "2023-12-06 14:28:46,069 : INFO : EPOCH 6: training on 99524 raw words (62796 effective words) took 0.1s, 423095 effective words/s\n",
      "2023-12-06 14:28:46,220 : INFO : EPOCH 7: training on 99524 raw words (62710 effective words) took 0.1s, 430189 effective words/s\n",
      "2023-12-06 14:28:46,377 : INFO : EPOCH 8: training on 99524 raw words (62671 effective words) took 0.2s, 410438 effective words/s\n",
      "2023-12-06 14:28:46,541 : INFO : EPOCH 9: training on 99524 raw words (62831 effective words) took 0.2s, 392486 effective words/s\n",
      "2023-12-06 14:28:46,543 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627269 effective words) took 1.6s, 403586 effective words/s', 'datetime': '2023-12-06T14:28:46.543784', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:28:46,544 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:28:46.544784', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 19%|        | 91/486 [15:08<53:07,  8.07s/it]  2023-12-06 14:28:49,393 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:28:49,394 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:28:49,418 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:28:49,419 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:28:49,424 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:28:49.424258', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:28:49,425 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:28:49.424258', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:28:49,430 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:28:49,431 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:28:49,431 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:28:49.431729', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:28:49,440 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:28:49,441 : INFO : resetting layer weights\n",
      "2023-12-06 14:28:49,442 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:28:49.442879', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:28:49,624 : INFO : EPOCH 0: training on 99524 raw words (62708 effective words) took 0.2s, 356759 effective words/s\n",
      "2023-12-06 14:28:49,774 : INFO : EPOCH 1: training on 99524 raw words (62718 effective words) took 0.1s, 432250 effective words/s\n",
      "2023-12-06 14:28:49,923 : INFO : EPOCH 2: training on 99524 raw words (62719 effective words) took 0.1s, 432008 effective words/s\n",
      "2023-12-06 14:28:50,082 : INFO : EPOCH 3: training on 99524 raw words (62729 effective words) took 0.2s, 405414 effective words/s\n",
      "2023-12-06 14:28:50,231 : INFO : EPOCH 4: training on 99524 raw words (62639 effective words) took 0.1s, 433932 effective words/s\n",
      "2023-12-06 14:28:50,377 : INFO : EPOCH 5: training on 99524 raw words (62595 effective words) took 0.1s, 442929 effective words/s\n",
      "2023-12-06 14:28:50,511 : INFO : EPOCH 6: training on 99524 raw words (62836 effective words) took 0.1s, 485259 effective words/s\n",
      "2023-12-06 14:28:50,636 : INFO : EPOCH 7: training on 99524 raw words (62668 effective words) took 0.1s, 516478 effective words/s\n",
      "2023-12-06 14:28:50,766 : INFO : EPOCH 8: training on 99524 raw words (62611 effective words) took 0.1s, 498998 effective words/s\n",
      "2023-12-06 14:28:50,899 : INFO : EPOCH 9: training on 99524 raw words (62900 effective words) took 0.1s, 489129 effective words/s\n",
      "2023-12-06 14:28:50,900 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627123 effective words) took 1.5s, 430598 effective words/s', 'datetime': '2023-12-06T14:28:50.900486', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:28:50,900 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:28:50.900486', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 19%|        | 92/486 [15:12<45:20,  6.90s/it]2023-12-06 14:28:53,574 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:28:53,575 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:28:53,595 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:28:53,596 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:28:53,600 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:28:53.600724', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:28:53,601 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:28:53.601733', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:28:53,607 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:28:53,607 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:28:53,608 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:28:53.608363', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:28:53,616 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:28:53,617 : INFO : resetting layer weights\n",
      "2023-12-06 14:28:53,619 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:28:53.619786', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:28:53,759 : INFO : EPOCH 0: training on 99524 raw words (62573 effective words) took 0.1s, 461244 effective words/s\n",
      "2023-12-06 14:28:53,883 : INFO : EPOCH 1: training on 99524 raw words (62891 effective words) took 0.1s, 527310 effective words/s\n",
      "2023-12-06 14:28:54,006 : INFO : EPOCH 2: training on 99524 raw words (62711 effective words) took 0.1s, 526636 effective words/s\n",
      "2023-12-06 14:28:54,155 : INFO : EPOCH 3: training on 99524 raw words (62538 effective words) took 0.1s, 432757 effective words/s\n",
      "2023-12-06 14:28:54,291 : INFO : EPOCH 4: training on 99524 raw words (62721 effective words) took 0.1s, 475291 effective words/s\n",
      "2023-12-06 14:28:54,420 : INFO : EPOCH 5: training on 99524 raw words (62675 effective words) took 0.1s, 503745 effective words/s\n",
      "2023-12-06 14:28:54,557 : INFO : EPOCH 6: training on 99524 raw words (62792 effective words) took 0.1s, 473995 effective words/s\n",
      "2023-12-06 14:28:54,681 : INFO : EPOCH 7: training on 99524 raw words (62661 effective words) took 0.1s, 524226 effective words/s\n",
      "2023-12-06 14:28:54,806 : INFO : EPOCH 8: training on 99524 raw words (62767 effective words) took 0.1s, 524871 effective words/s\n",
      "2023-12-06 14:28:54,938 : INFO : EPOCH 9: training on 99524 raw words (62507 effective words) took 0.1s, 487982 effective words/s\n",
      "2023-12-06 14:28:54,939 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (626836 effective words) took 1.3s, 475244 effective words/s', 'datetime': '2023-12-06T14:28:54.939099', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:28:54,940 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:28:54.940098', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 19%|        | 93/486 [15:16<39:36,  6.05s/it]2023-12-06 14:28:57,621 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:28:57,621 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:28:57,642 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:28:57,643 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:28:57,647 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:28:57.647691', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:28:57,648 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:28:57.648700', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:28:57,653 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:28:57,654 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:28:57,654 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:28:57.654696', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:28:57,663 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:28:57,664 : INFO : resetting layer weights\n",
      "2023-12-06 14:28:57,666 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:28:57.666345', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:28:57,800 : INFO : EPOCH 0: training on 99524 raw words (62724 effective words) took 0.1s, 482277 effective words/s\n",
      "2023-12-06 14:28:57,923 : INFO : EPOCH 1: training on 99524 raw words (62772 effective words) took 0.1s, 527543 effective words/s\n",
      "2023-12-06 14:28:58,051 : INFO : EPOCH 2: training on 99524 raw words (62767 effective words) took 0.1s, 510965 effective words/s\n",
      "2023-12-06 14:28:58,193 : INFO : EPOCH 3: training on 99524 raw words (62705 effective words) took 0.1s, 458095 effective words/s\n",
      "2023-12-06 14:28:58,316 : INFO : EPOCH 4: training on 99524 raw words (62656 effective words) took 0.1s, 528211 effective words/s\n",
      "2023-12-06 14:28:58,437 : INFO : EPOCH 5: training on 99524 raw words (62666 effective words) took 0.1s, 530897 effective words/s\n",
      "2023-12-06 14:28:58,577 : INFO : EPOCH 6: training on 99524 raw words (62592 effective words) took 0.1s, 463765 effective words/s\n",
      "2023-12-06 14:28:58,701 : INFO : EPOCH 7: training on 99524 raw words (62777 effective words) took 0.1s, 521675 effective words/s\n",
      "2023-12-06 14:28:58,825 : INFO : EPOCH 8: training on 99524 raw words (62624 effective words) took 0.1s, 526031 effective words/s\n",
      "2023-12-06 14:28:58,957 : INFO : EPOCH 9: training on 99524 raw words (62789 effective words) took 0.1s, 491892 effective words/s\n",
      "2023-12-06 14:28:59,080 : INFO : EPOCH 10: training on 99524 raw words (62658 effective words) took 0.1s, 530785 effective words/s\n",
      "2023-12-06 14:28:59,203 : INFO : EPOCH 11: training on 99524 raw words (62822 effective words) took 0.1s, 524198 effective words/s\n",
      "2023-12-06 14:28:59,326 : INFO : EPOCH 12: training on 99524 raw words (62767 effective words) took 0.1s, 534757 effective words/s\n",
      "2023-12-06 14:28:59,458 : INFO : EPOCH 13: training on 99524 raw words (62737 effective words) took 0.1s, 487294 effective words/s\n",
      "2023-12-06 14:28:59,581 : INFO : EPOCH 14: training on 99524 raw words (62873 effective words) took 0.1s, 528676 effective words/s\n",
      "2023-12-06 14:28:59,704 : INFO : EPOCH 15: training on 99524 raw words (62757 effective words) took 0.1s, 531470 effective words/s\n",
      "2023-12-06 14:28:59,827 : INFO : EPOCH 16: training on 99524 raw words (62744 effective words) took 0.1s, 524582 effective words/s\n",
      "2023-12-06 14:28:59,982 : INFO : EPOCH 17: training on 99524 raw words (62551 effective words) took 0.2s, 414861 effective words/s\n",
      "2023-12-06 14:29:00,108 : INFO : EPOCH 18: training on 99524 raw words (62664 effective words) took 0.1s, 517827 effective words/s\n",
      "2023-12-06 14:29:00,232 : INFO : EPOCH 19: training on 99524 raw words (62765 effective words) took 0.1s, 525778 effective words/s\n",
      "2023-12-06 14:29:00,354 : INFO : EPOCH 20: training on 99524 raw words (62751 effective words) took 0.1s, 533013 effective words/s\n",
      "2023-12-06 14:29:00,485 : INFO : EPOCH 21: training on 99524 raw words (62891 effective words) took 0.1s, 495735 effective words/s\n",
      "2023-12-06 14:29:00,608 : INFO : EPOCH 22: training on 99524 raw words (62702 effective words) took 0.1s, 528055 effective words/s\n",
      "2023-12-06 14:29:00,732 : INFO : EPOCH 23: training on 99524 raw words (62846 effective words) took 0.1s, 526037 effective words/s\n",
      "2023-12-06 14:29:00,863 : INFO : EPOCH 24: training on 99524 raw words (62723 effective words) took 0.1s, 496693 effective words/s\n",
      "2023-12-06 14:29:00,986 : INFO : EPOCH 25: training on 99524 raw words (62652 effective words) took 0.1s, 527570 effective words/s\n",
      "2023-12-06 14:29:01,107 : INFO : EPOCH 26: training on 99524 raw words (62917 effective words) took 0.1s, 533920 effective words/s\n",
      "2023-12-06 14:29:01,237 : INFO : EPOCH 27: training on 99524 raw words (62824 effective words) took 0.1s, 502534 effective words/s\n",
      "2023-12-06 14:29:01,359 : INFO : EPOCH 28: training on 99524 raw words (62781 effective words) took 0.1s, 529465 effective words/s\n",
      "2023-12-06 14:29:01,482 : INFO : EPOCH 29: training on 99524 raw words (62767 effective words) took 0.1s, 528267 effective words/s\n",
      "2023-12-06 14:29:01,483 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1882264 effective words) took 3.8s, 493063 effective words/s', 'datetime': '2023-12-06T14:29:01.483877', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:29:01,484 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:29:01.484879', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 19%|        | 94/486 [15:23<40:57,  6.27s/it]2023-12-06 14:29:04,746 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:29:04,747 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:29:04,767 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:29:04,768 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:29:04,774 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:29:04.774713', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:29:04,774 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:29:04.774713', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:29:04,780 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:29:04,781 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:29:04,782 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:29:04.782267', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:29:04,789 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:29:04,790 : INFO : resetting layer weights\n",
      "2023-12-06 14:29:04,792 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:29:04.792730', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:29:04,934 : INFO : EPOCH 0: training on 99524 raw words (62731 effective words) took 0.1s, 459118 effective words/s\n",
      "2023-12-06 14:29:05,070 : INFO : EPOCH 1: training on 99524 raw words (62796 effective words) took 0.1s, 474656 effective words/s\n",
      "2023-12-06 14:29:05,219 : INFO : EPOCH 2: training on 99524 raw words (62721 effective words) took 0.1s, 435252 effective words/s\n",
      "2023-12-06 14:29:05,358 : INFO : EPOCH 3: training on 99524 raw words (62652 effective words) took 0.1s, 470426 effective words/s\n",
      "2023-12-06 14:29:05,483 : INFO : EPOCH 4: training on 99524 raw words (62637 effective words) took 0.1s, 520691 effective words/s\n",
      "2023-12-06 14:29:05,607 : INFO : EPOCH 5: training on 99524 raw words (62630 effective words) took 0.1s, 527040 effective words/s\n",
      "2023-12-06 14:29:05,734 : INFO : EPOCH 6: training on 99524 raw words (62865 effective words) took 0.1s, 508225 effective words/s\n",
      "2023-12-06 14:29:05,858 : INFO : EPOCH 7: training on 99524 raw words (62811 effective words) took 0.1s, 522575 effective words/s\n",
      "2023-12-06 14:29:05,980 : INFO : EPOCH 8: training on 99524 raw words (62656 effective words) took 0.1s, 534788 effective words/s\n",
      "2023-12-06 14:29:06,108 : INFO : EPOCH 9: training on 99524 raw words (62764 effective words) took 0.1s, 507465 effective words/s\n",
      "2023-12-06 14:29:06,230 : INFO : EPOCH 10: training on 99524 raw words (62748 effective words) took 0.1s, 532468 effective words/s\n",
      "2023-12-06 14:29:06,351 : INFO : EPOCH 11: training on 99524 raw words (62714 effective words) took 0.1s, 533246 effective words/s\n",
      "2023-12-06 14:29:06,480 : INFO : EPOCH 12: training on 99524 raw words (62782 effective words) took 0.1s, 502371 effective words/s\n",
      "2023-12-06 14:29:06,601 : INFO : EPOCH 13: training on 99524 raw words (62718 effective words) took 0.1s, 537518 effective words/s\n",
      "2023-12-06 14:29:06,724 : INFO : EPOCH 14: training on 99524 raw words (62830 effective words) took 0.1s, 528716 effective words/s\n",
      "2023-12-06 14:29:06,859 : INFO : EPOCH 15: training on 99524 raw words (62719 effective words) took 0.1s, 482829 effective words/s\n",
      "2023-12-06 14:29:06,982 : INFO : EPOCH 16: training on 99524 raw words (62653 effective words) took 0.1s, 531254 effective words/s\n",
      "2023-12-06 14:29:07,103 : INFO : EPOCH 17: training on 99524 raw words (62665 effective words) took 0.1s, 533072 effective words/s\n",
      "2023-12-06 14:29:07,233 : INFO : EPOCH 18: training on 99524 raw words (62731 effective words) took 0.1s, 502544 effective words/s\n",
      "2023-12-06 14:29:07,353 : INFO : EPOCH 19: training on 99524 raw words (62757 effective words) took 0.1s, 538117 effective words/s\n",
      "2023-12-06 14:29:07,473 : INFO : EPOCH 20: training on 99524 raw words (62644 effective words) took 0.1s, 533578 effective words/s\n",
      "2023-12-06 14:29:07,595 : INFO : EPOCH 21: training on 99524 raw words (62766 effective words) took 0.1s, 539835 effective words/s\n",
      "2023-12-06 14:29:07,724 : INFO : EPOCH 22: training on 99524 raw words (62766 effective words) took 0.1s, 502563 effective words/s\n",
      "2023-12-06 14:29:07,845 : INFO : EPOCH 23: training on 99524 raw words (62764 effective words) took 0.1s, 535601 effective words/s\n",
      "2023-12-06 14:29:07,969 : INFO : EPOCH 24: training on 99524 raw words (62808 effective words) took 0.1s, 523546 effective words/s\n",
      "2023-12-06 14:29:08,096 : INFO : EPOCH 25: training on 99524 raw words (62657 effective words) took 0.1s, 511543 effective words/s\n",
      "2023-12-06 14:29:08,218 : INFO : EPOCH 26: training on 99524 raw words (62711 effective words) took 0.1s, 532613 effective words/s\n",
      "2023-12-06 14:29:08,337 : INFO : EPOCH 27: training on 99524 raw words (62899 effective words) took 0.1s, 544470 effective words/s\n",
      "2023-12-06 14:29:08,465 : INFO : EPOCH 28: training on 99524 raw words (62767 effective words) took 0.1s, 505176 effective words/s\n",
      "2023-12-06 14:29:08,587 : INFO : EPOCH 29: training on 99524 raw words (62818 effective words) took 0.1s, 537250 effective words/s\n",
      "2023-12-06 14:29:08,587 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1882180 effective words) took 3.8s, 496083 effective words/s', 'datetime': '2023-12-06T14:29:08.587055', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:29:08,588 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:29:08.588443', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 20%|        | 95/486 [15:30<42:32,  6.53s/it]2023-12-06 14:29:11,537 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:29:11,537 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:29:11,557 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:29:11,558 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:29:11,562 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:29:11.562369', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:29:11,563 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:29:11.563369', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:29:11,568 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:29:11,569 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:29:11,569 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:29:11.569375', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:29:11,577 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:29:11,578 : INFO : resetting layer weights\n",
      "2023-12-06 14:29:11,580 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:29:11.579369', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:29:11,735 : INFO : EPOCH 0: training on 99524 raw words (62692 effective words) took 0.2s, 413353 effective words/s\n",
      "2023-12-06 14:29:11,852 : INFO : EPOCH 1: training on 99524 raw words (62813 effective words) took 0.1s, 554111 effective words/s\n",
      "2023-12-06 14:29:11,972 : INFO : EPOCH 2: training on 99524 raw words (62782 effective words) took 0.1s, 542761 effective words/s\n",
      "2023-12-06 14:29:12,099 : INFO : EPOCH 3: training on 99524 raw words (62600 effective words) took 0.1s, 510079 effective words/s\n",
      "2023-12-06 14:29:12,218 : INFO : EPOCH 4: training on 99524 raw words (62711 effective words) took 0.1s, 547112 effective words/s\n",
      "2023-12-06 14:29:12,335 : INFO : EPOCH 5: training on 99524 raw words (62664 effective words) took 0.1s, 548248 effective words/s\n",
      "2023-12-06 14:29:12,461 : INFO : EPOCH 6: training on 99524 raw words (62752 effective words) took 0.1s, 515569 effective words/s\n",
      "2023-12-06 14:29:12,581 : INFO : EPOCH 7: training on 99524 raw words (62666 effective words) took 0.1s, 546761 effective words/s\n",
      "2023-12-06 14:29:12,699 : INFO : EPOCH 8: training on 99524 raw words (62689 effective words) took 0.1s, 543180 effective words/s\n",
      "2023-12-06 14:29:12,825 : INFO : EPOCH 9: training on 99524 raw words (62866 effective words) took 0.1s, 516889 effective words/s\n",
      "2023-12-06 14:29:12,943 : INFO : EPOCH 10: training on 99524 raw words (62621 effective words) took 0.1s, 548297 effective words/s\n",
      "2023-12-06 14:29:13,063 : INFO : EPOCH 11: training on 99524 raw words (62728 effective words) took 0.1s, 541299 effective words/s\n",
      "2023-12-06 14:29:13,189 : INFO : EPOCH 12: training on 99524 raw words (62721 effective words) took 0.1s, 514152 effective words/s\n",
      "2023-12-06 14:29:13,307 : INFO : EPOCH 13: training on 99524 raw words (62709 effective words) took 0.1s, 547666 effective words/s\n",
      "2023-12-06 14:29:13,426 : INFO : EPOCH 14: training on 99524 raw words (62785 effective words) took 0.1s, 548482 effective words/s\n",
      "2023-12-06 14:29:13,553 : INFO : EPOCH 15: training on 99524 raw words (62581 effective words) took 0.1s, 509997 effective words/s\n",
      "2023-12-06 14:29:13,672 : INFO : EPOCH 16: training on 99524 raw words (62890 effective words) took 0.1s, 549213 effective words/s\n",
      "2023-12-06 14:29:13,807 : INFO : EPOCH 17: training on 99524 raw words (62580 effective words) took 0.1s, 478910 effective words/s\n",
      "2023-12-06 14:29:13,933 : INFO : EPOCH 18: training on 99524 raw words (62660 effective words) took 0.1s, 512208 effective words/s\n",
      "2023-12-06 14:29:14,052 : INFO : EPOCH 19: training on 99524 raw words (62782 effective words) took 0.1s, 543064 effective words/s\n",
      "2023-12-06 14:29:14,171 : INFO : EPOCH 20: training on 99524 raw words (62822 effective words) took 0.1s, 548732 effective words/s\n",
      "2023-12-06 14:29:14,289 : INFO : EPOCH 21: training on 99524 raw words (62679 effective words) took 0.1s, 553256 effective words/s\n",
      "2023-12-06 14:29:14,426 : INFO : EPOCH 22: training on 99524 raw words (62830 effective words) took 0.1s, 471657 effective words/s\n",
      "2023-12-06 14:29:14,567 : INFO : EPOCH 23: training on 99524 raw words (62665 effective words) took 0.1s, 460041 effective words/s\n",
      "2023-12-06 14:29:14,714 : INFO : EPOCH 24: training on 99524 raw words (62954 effective words) took 0.1s, 441352 effective words/s\n",
      "2023-12-06 14:29:14,860 : INFO : EPOCH 25: training on 99524 raw words (62757 effective words) took 0.1s, 442580 effective words/s\n",
      "2023-12-06 14:29:14,999 : INFO : EPOCH 26: training on 99524 raw words (62830 effective words) took 0.1s, 464453 effective words/s\n",
      "2023-12-06 14:29:15,142 : INFO : EPOCH 27: training on 99524 raw words (62815 effective words) took 0.1s, 455999 effective words/s\n",
      "2023-12-06 14:29:15,282 : INFO : EPOCH 28: training on 99524 raw words (62743 effective words) took 0.1s, 463354 effective words/s\n",
      "2023-12-06 14:29:15,428 : INFO : EPOCH 29: training on 99524 raw words (62704 effective words) took 0.1s, 443162 effective words/s\n",
      "2023-12-06 14:29:15,429 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1882091 effective words) took 3.8s, 489001 effective words/s', 'datetime': '2023-12-06T14:29:15.429124', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:29:15,430 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:29:15.430124', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 20%|        | 96/486 [15:37<43:22,  6.67s/it]2023-12-06 14:29:18,553 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:29:18,553 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:29:18,573 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:29:18,573 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:29:18,578 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:29:18.578300', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:29:18,578 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:29:18.578300', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:29:18,584 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:29:18,585 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:29:18,585 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:29:18.585056', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:29:18,594 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:29:18,595 : INFO : resetting layer weights\n",
      "2023-12-06 14:29:18,597 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:29:18.597237', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:29:18,746 : INFO : EPOCH 0: training on 99524 raw words (62765 effective words) took 0.1s, 434942 effective words/s\n",
      "2023-12-06 14:29:18,888 : INFO : EPOCH 1: training on 99524 raw words (62742 effective words) took 0.1s, 454569 effective words/s\n",
      "2023-12-06 14:29:19,029 : INFO : EPOCH 2: training on 99524 raw words (62795 effective words) took 0.1s, 461901 effective words/s\n",
      "2023-12-06 14:29:19,174 : INFO : EPOCH 3: training on 99524 raw words (62609 effective words) took 0.1s, 441228 effective words/s\n",
      "2023-12-06 14:29:19,315 : INFO : EPOCH 4: training on 99524 raw words (62777 effective words) took 0.1s, 459609 effective words/s\n",
      "2023-12-06 14:29:19,457 : INFO : EPOCH 5: training on 99524 raw words (62705 effective words) took 0.1s, 457359 effective words/s\n",
      "2023-12-06 14:29:19,603 : INFO : EPOCH 6: training on 99524 raw words (62673 effective words) took 0.1s, 440966 effective words/s\n",
      "2023-12-06 14:29:19,750 : INFO : EPOCH 7: training on 99524 raw words (62782 effective words) took 0.1s, 440460 effective words/s\n",
      "2023-12-06 14:29:19,896 : INFO : EPOCH 8: training on 99524 raw words (62722 effective words) took 0.1s, 442826 effective words/s\n",
      "2023-12-06 14:29:20,043 : INFO : EPOCH 9: training on 99524 raw words (62828 effective words) took 0.1s, 439417 effective words/s\n",
      "2023-12-06 14:29:20,183 : INFO : EPOCH 10: training on 99524 raw words (62647 effective words) took 0.1s, 462823 effective words/s\n",
      "2023-12-06 14:29:20,325 : INFO : EPOCH 11: training on 99524 raw words (62825 effective words) took 0.1s, 460022 effective words/s\n",
      "2023-12-06 14:29:20,462 : INFO : EPOCH 12: training on 99524 raw words (62740 effective words) took 0.1s, 467556 effective words/s\n",
      "2023-12-06 14:29:20,610 : INFO : EPOCH 13: training on 99524 raw words (62548 effective words) took 0.1s, 441334 effective words/s\n",
      "2023-12-06 14:29:20,750 : INFO : EPOCH 14: training on 99524 raw words (62847 effective words) took 0.1s, 459889 effective words/s\n",
      "2023-12-06 14:29:20,890 : INFO : EPOCH 15: training on 99524 raw words (62834 effective words) took 0.1s, 463296 effective words/s\n",
      "2023-12-06 14:29:21,034 : INFO : EPOCH 16: training on 99524 raw words (62795 effective words) took 0.1s, 449525 effective words/s\n",
      "2023-12-06 14:29:21,175 : INFO : EPOCH 17: training on 99524 raw words (62767 effective words) took 0.1s, 463997 effective words/s\n",
      "2023-12-06 14:29:21,313 : INFO : EPOCH 18: training on 99524 raw words (62621 effective words) took 0.1s, 463898 effective words/s\n",
      "2023-12-06 14:29:21,463 : INFO : EPOCH 19: training on 99524 raw words (62744 effective words) took 0.1s, 432142 effective words/s\n",
      "2023-12-06 14:29:21,607 : INFO : EPOCH 20: training on 99524 raw words (62697 effective words) took 0.1s, 450264 effective words/s\n",
      "2023-12-06 14:29:21,746 : INFO : EPOCH 21: training on 99524 raw words (62661 effective words) took 0.1s, 464171 effective words/s\n",
      "2023-12-06 14:29:21,889 : INFO : EPOCH 22: training on 99524 raw words (62838 effective words) took 0.1s, 451753 effective words/s\n",
      "2023-12-06 14:29:22,032 : INFO : EPOCH 23: training on 99524 raw words (62759 effective words) took 0.1s, 456548 effective words/s\n",
      "2023-12-06 14:29:22,181 : INFO : EPOCH 24: training on 99524 raw words (62807 effective words) took 0.1s, 437945 effective words/s\n",
      "2023-12-06 14:29:22,323 : INFO : EPOCH 25: training on 99524 raw words (62584 effective words) took 0.1s, 451285 effective words/s\n",
      "2023-12-06 14:29:22,469 : INFO : EPOCH 26: training on 99524 raw words (62764 effective words) took 0.1s, 448569 effective words/s\n",
      "2023-12-06 14:29:22,607 : INFO : EPOCH 27: training on 99524 raw words (62942 effective words) took 0.1s, 468930 effective words/s\n",
      "2023-12-06 14:29:22,747 : INFO : EPOCH 28: training on 99524 raw words (62759 effective words) took 0.1s, 466420 effective words/s\n",
      "2023-12-06 14:29:22,893 : INFO : EPOCH 29: training on 99524 raw words (62815 effective words) took 0.1s, 441710 effective words/s\n",
      "2023-12-06 14:29:23,033 : INFO : EPOCH 30: training on 99524 raw words (62695 effective words) took 0.1s, 460318 effective words/s\n",
      "2023-12-06 14:29:23,174 : INFO : EPOCH 31: training on 99524 raw words (62698 effective words) took 0.1s, 460552 effective words/s\n",
      "2023-12-06 14:29:23,322 : INFO : EPOCH 32: training on 99524 raw words (62900 effective words) took 0.1s, 437468 effective words/s\n",
      "2023-12-06 14:29:23,461 : INFO : EPOCH 33: training on 99524 raw words (62814 effective words) took 0.1s, 466221 effective words/s\n",
      "2023-12-06 14:29:23,601 : INFO : EPOCH 34: training on 99524 raw words (62950 effective words) took 0.1s, 463175 effective words/s\n",
      "2023-12-06 14:29:23,746 : INFO : EPOCH 35: training on 99524 raw words (62787 effective words) took 0.1s, 449254 effective words/s\n",
      "2023-12-06 14:29:23,889 : INFO : EPOCH 36: training on 99524 raw words (62676 effective words) took 0.1s, 454656 effective words/s\n",
      "2023-12-06 14:29:24,029 : INFO : EPOCH 37: training on 99524 raw words (62622 effective words) took 0.1s, 462273 effective words/s\n",
      "2023-12-06 14:29:24,169 : INFO : EPOCH 38: training on 99524 raw words (62690 effective words) took 0.1s, 459605 effective words/s\n",
      "2023-12-06 14:29:24,317 : INFO : EPOCH 39: training on 99524 raw words (62803 effective words) took 0.1s, 436292 effective words/s\n",
      "2023-12-06 14:29:24,458 : INFO : EPOCH 40: training on 99524 raw words (62728 effective words) took 0.1s, 462253 effective words/s\n",
      "2023-12-06 14:29:24,601 : INFO : EPOCH 41: training on 99524 raw words (62735 effective words) took 0.1s, 453727 effective words/s\n",
      "2023-12-06 14:29:24,746 : INFO : EPOCH 42: training on 99524 raw words (62754 effective words) took 0.1s, 440943 effective words/s\n",
      "2023-12-06 14:29:24,894 : INFO : EPOCH 43: training on 99524 raw words (62712 effective words) took 0.1s, 439481 effective words/s\n",
      "2023-12-06 14:29:25,034 : INFO : EPOCH 44: training on 99524 raw words (62799 effective words) took 0.1s, 462787 effective words/s\n",
      "2023-12-06 14:29:25,174 : INFO : EPOCH 45: training on 99524 raw words (62652 effective words) took 0.1s, 463580 effective words/s\n",
      "2023-12-06 14:29:25,318 : INFO : EPOCH 46: training on 99524 raw words (62621 effective words) took 0.1s, 444588 effective words/s\n",
      "2023-12-06 14:29:25,470 : INFO : EPOCH 47: training on 99524 raw words (62658 effective words) took 0.1s, 428720 effective words/s\n",
      "2023-12-06 14:29:25,611 : INFO : EPOCH 48: training on 99524 raw words (62814 effective words) took 0.1s, 456537 effective words/s\n",
      "2023-12-06 14:29:25,758 : INFO : EPOCH 49: training on 99524 raw words (62699 effective words) took 0.1s, 440493 effective words/s\n",
      "2023-12-06 14:29:25,759 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3137199 effective words) took 7.2s, 438054 effective words/s', 'datetime': '2023-12-06T14:29:25.759758', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:29:25,759 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:29:25.759758', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 20%|        | 97/486 [15:47<50:19,  7.76s/it]2023-12-06 14:29:28,854 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:29:28,854 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:29:28,873 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:29:28,874 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:29:28,881 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:29:28.881510', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:29:28,882 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:29:28.882013', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:29:28,887 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:29:28,887 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:29:28,888 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:29:28.888208', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:29:28,896 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:29:28,896 : INFO : resetting layer weights\n",
      "2023-12-06 14:29:28,899 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:29:28.899032', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:29:29,058 : INFO : EPOCH 0: training on 99524 raw words (62726 effective words) took 0.2s, 400292 effective words/s\n",
      "2023-12-06 14:29:29,201 : INFO : EPOCH 1: training on 99524 raw words (62877 effective words) took 0.1s, 456833 effective words/s\n",
      "2023-12-06 14:29:29,341 : INFO : EPOCH 2: training on 99524 raw words (62645 effective words) took 0.1s, 459565 effective words/s\n",
      "2023-12-06 14:29:29,488 : INFO : EPOCH 3: training on 99524 raw words (62571 effective words) took 0.1s, 438104 effective words/s\n",
      "2023-12-06 14:29:29,631 : INFO : EPOCH 4: training on 99524 raw words (62733 effective words) took 0.1s, 453013 effective words/s\n",
      "2023-12-06 14:29:29,770 : INFO : EPOCH 5: training on 99524 raw words (62664 effective words) took 0.1s, 465376 effective words/s\n",
      "2023-12-06 14:29:29,917 : INFO : EPOCH 6: training on 99524 raw words (62687 effective words) took 0.1s, 438795 effective words/s\n",
      "2023-12-06 14:29:30,060 : INFO : EPOCH 7: training on 99524 raw words (62801 effective words) took 0.1s, 449737 effective words/s\n",
      "2023-12-06 14:29:30,202 : INFO : EPOCH 8: training on 99524 raw words (62814 effective words) took 0.1s, 460048 effective words/s\n",
      "2023-12-06 14:29:30,350 : INFO : EPOCH 9: training on 99524 raw words (62753 effective words) took 0.1s, 439006 effective words/s\n",
      "2023-12-06 14:29:30,491 : INFO : EPOCH 10: training on 99524 raw words (62714 effective words) took 0.1s, 456924 effective words/s\n",
      "2023-12-06 14:29:30,632 : INFO : EPOCH 11: training on 99524 raw words (62573 effective words) took 0.1s, 459766 effective words/s\n",
      "2023-12-06 14:29:30,784 : INFO : EPOCH 12: training on 99524 raw words (62663 effective words) took 0.1s, 423117 effective words/s\n",
      "2023-12-06 14:29:30,925 : INFO : EPOCH 13: training on 99524 raw words (62817 effective words) took 0.1s, 457165 effective words/s\n",
      "2023-12-06 14:29:31,065 : INFO : EPOCH 14: training on 99524 raw words (62855 effective words) took 0.1s, 464187 effective words/s\n",
      "2023-12-06 14:29:31,214 : INFO : EPOCH 15: training on 99524 raw words (62644 effective words) took 0.1s, 434609 effective words/s\n",
      "2023-12-06 14:29:31,355 : INFO : EPOCH 16: training on 99524 raw words (62720 effective words) took 0.1s, 457516 effective words/s\n",
      "2023-12-06 14:29:31,495 : INFO : EPOCH 17: training on 99524 raw words (62661 effective words) took 0.1s, 461208 effective words/s\n",
      "2023-12-06 14:29:31,651 : INFO : EPOCH 18: training on 99524 raw words (62646 effective words) took 0.2s, 412690 effective words/s\n",
      "2023-12-06 14:29:31,794 : INFO : EPOCH 19: training on 99524 raw words (62718 effective words) took 0.1s, 454976 effective words/s\n",
      "2023-12-06 14:29:31,936 : INFO : EPOCH 20: training on 99524 raw words (62646 effective words) took 0.1s, 455318 effective words/s\n",
      "2023-12-06 14:29:32,083 : INFO : EPOCH 21: training on 99524 raw words (62944 effective words) took 0.1s, 437640 effective words/s\n",
      "2023-12-06 14:29:32,226 : INFO : EPOCH 22: training on 99524 raw words (62779 effective words) took 0.1s, 455010 effective words/s\n",
      "2023-12-06 14:29:32,368 : INFO : EPOCH 23: training on 99524 raw words (62755 effective words) took 0.1s, 459032 effective words/s\n",
      "2023-12-06 14:29:32,515 : INFO : EPOCH 24: training on 99524 raw words (62720 effective words) took 0.1s, 437675 effective words/s\n",
      "2023-12-06 14:29:32,656 : INFO : EPOCH 25: training on 99524 raw words (62789 effective words) took 0.1s, 456067 effective words/s\n",
      "2023-12-06 14:29:32,808 : INFO : EPOCH 26: training on 99524 raw words (62770 effective words) took 0.1s, 429707 effective words/s\n",
      "2023-12-06 14:29:32,956 : INFO : EPOCH 27: training on 99524 raw words (63042 effective words) took 0.1s, 438651 effective words/s\n",
      "2023-12-06 14:29:33,097 : INFO : EPOCH 28: training on 99524 raw words (62701 effective words) took 0.1s, 456572 effective words/s\n",
      "2023-12-06 14:29:33,241 : INFO : EPOCH 29: training on 99524 raw words (62699 effective words) took 0.1s, 450994 effective words/s\n",
      "2023-12-06 14:29:33,384 : INFO : EPOCH 30: training on 99524 raw words (62770 effective words) took 0.1s, 450631 effective words/s\n",
      "2023-12-06 14:29:33,530 : INFO : EPOCH 31: training on 99524 raw words (62758 effective words) took 0.1s, 441611 effective words/s\n",
      "2023-12-06 14:29:33,673 : INFO : EPOCH 32: training on 99524 raw words (62825 effective words) took 0.1s, 454906 effective words/s\n",
      "2023-12-06 14:29:33,816 : INFO : EPOCH 33: training on 99524 raw words (62680 effective words) took 0.1s, 451882 effective words/s\n",
      "2023-12-06 14:29:33,964 : INFO : EPOCH 34: training on 99524 raw words (62794 effective words) took 0.1s, 438167 effective words/s\n",
      "2023-12-06 14:29:34,104 : INFO : EPOCH 35: training on 99524 raw words (62787 effective words) took 0.1s, 460584 effective words/s\n",
      "2023-12-06 14:29:34,245 : INFO : EPOCH 36: training on 99524 raw words (62596 effective words) took 0.1s, 459707 effective words/s\n",
      "2023-12-06 14:29:34,396 : INFO : EPOCH 37: training on 99524 raw words (62529 effective words) took 0.1s, 427492 effective words/s\n",
      "2023-12-06 14:29:34,546 : INFO : EPOCH 38: training on 99524 raw words (62609 effective words) took 0.1s, 431948 effective words/s\n",
      "2023-12-06 14:29:34,687 : INFO : EPOCH 39: training on 99524 raw words (62648 effective words) took 0.1s, 459152 effective words/s\n",
      "2023-12-06 14:29:34,834 : INFO : EPOCH 40: training on 99524 raw words (62711 effective words) took 0.1s, 438384 effective words/s\n",
      "2023-12-06 14:29:34,973 : INFO : EPOCH 41: training on 99524 raw words (62740 effective words) took 0.1s, 463139 effective words/s\n",
      "2023-12-06 14:29:35,116 : INFO : EPOCH 42: training on 99524 raw words (62644 effective words) took 0.1s, 451244 effective words/s\n",
      "2023-12-06 14:29:35,266 : INFO : EPOCH 43: training on 99524 raw words (62707 effective words) took 0.1s, 433117 effective words/s\n",
      "2023-12-06 14:29:35,408 : INFO : EPOCH 44: training on 99524 raw words (62584 effective words) took 0.1s, 452072 effective words/s\n",
      "2023-12-06 14:29:35,551 : INFO : EPOCH 45: training on 99524 raw words (62790 effective words) took 0.1s, 456505 effective words/s\n",
      "2023-12-06 14:29:35,699 : INFO : EPOCH 46: training on 99524 raw words (62569 effective words) took 0.1s, 431979 effective words/s\n",
      "2023-12-06 14:29:35,840 : INFO : EPOCH 47: training on 99524 raw words (62575 effective words) took 0.1s, 460301 effective words/s\n",
      "2023-12-06 14:29:35,981 : INFO : EPOCH 48: training on 99524 raw words (62802 effective words) took 0.1s, 460095 effective words/s\n",
      "2023-12-06 14:29:36,127 : INFO : EPOCH 49: training on 99524 raw words (62778 effective words) took 0.1s, 442171 effective words/s\n",
      "2023-12-06 14:29:36,128 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136023 effective words) took 7.2s, 433812 effective words/s', 'datetime': '2023-12-06T14:29:36.128218', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:29:36,129 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:29:36.129218', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 20%|        | 98/486 [15:58<55:42,  8.62s/it]2023-12-06 14:29:39,461 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:29:39,462 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:29:39,480 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:29:39,481 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:29:39,488 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:29:39.488567', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:29:39,489 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:29:39.489567', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:29:39,494 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:29:39,495 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:29:39,495 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:29:39.495567', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:29:39,503 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:29:39,503 : INFO : resetting layer weights\n",
      "2023-12-06 14:29:39,505 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:29:39.505668', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:29:39,655 : INFO : EPOCH 0: training on 99524 raw words (62694 effective words) took 0.1s, 429343 effective words/s\n",
      "2023-12-06 14:29:39,795 : INFO : EPOCH 1: training on 99524 raw words (62782 effective words) took 0.1s, 465262 effective words/s\n",
      "2023-12-06 14:29:39,935 : INFO : EPOCH 2: training on 99524 raw words (62661 effective words) took 0.1s, 462206 effective words/s\n",
      "2023-12-06 14:29:40,078 : INFO : EPOCH 3: training on 99524 raw words (62679 effective words) took 0.1s, 451888 effective words/s\n",
      "2023-12-06 14:29:40,219 : INFO : EPOCH 4: training on 99524 raw words (62544 effective words) took 0.1s, 458315 effective words/s\n",
      "2023-12-06 14:29:40,359 : INFO : EPOCH 5: training on 99524 raw words (62716 effective words) took 0.1s, 462817 effective words/s\n",
      "2023-12-06 14:29:40,501 : INFO : EPOCH 6: training on 99524 raw words (62759 effective words) took 0.1s, 457462 effective words/s\n",
      "2023-12-06 14:29:40,654 : INFO : EPOCH 7: training on 99524 raw words (62759 effective words) took 0.1s, 419952 effective words/s\n",
      "2023-12-06 14:29:40,794 : INFO : EPOCH 8: training on 99524 raw words (62845 effective words) took 0.1s, 462715 effective words/s\n",
      "2023-12-06 14:29:40,932 : INFO : EPOCH 9: training on 99524 raw words (62671 effective words) took 0.1s, 467306 effective words/s\n",
      "2023-12-06 14:29:41,078 : INFO : EPOCH 10: training on 99524 raw words (62627 effective words) took 0.1s, 444357 effective words/s\n",
      "2023-12-06 14:29:41,220 : INFO : EPOCH 11: training on 99524 raw words (62821 effective words) took 0.1s, 453493 effective words/s\n",
      "2023-12-06 14:29:41,361 : INFO : EPOCH 12: training on 99524 raw words (62784 effective words) took 0.1s, 463232 effective words/s\n",
      "2023-12-06 14:29:41,507 : INFO : EPOCH 13: training on 99524 raw words (62598 effective words) took 0.1s, 441532 effective words/s\n",
      "2023-12-06 14:29:41,646 : INFO : EPOCH 14: training on 99524 raw words (62722 effective words) took 0.1s, 463435 effective words/s\n",
      "2023-12-06 14:29:41,785 : INFO : EPOCH 15: training on 99524 raw words (62777 effective words) took 0.1s, 466594 effective words/s\n",
      "2023-12-06 14:29:41,930 : INFO : EPOCH 16: training on 99524 raw words (62879 effective words) took 0.1s, 449136 effective words/s\n",
      "2023-12-06 14:29:42,070 : INFO : EPOCH 17: training on 99524 raw words (62667 effective words) took 0.1s, 460065 effective words/s\n",
      "2023-12-06 14:29:42,210 : INFO : EPOCH 18: training on 99524 raw words (62790 effective words) took 0.1s, 466031 effective words/s\n",
      "2023-12-06 14:29:42,356 : INFO : EPOCH 19: training on 99524 raw words (62680 effective words) took 0.1s, 442731 effective words/s\n",
      "2023-12-06 14:29:42,494 : INFO : EPOCH 20: training on 99524 raw words (62846 effective words) took 0.1s, 465608 effective words/s\n",
      "2023-12-06 14:29:42,634 : INFO : EPOCH 21: training on 99524 raw words (62745 effective words) took 0.1s, 464406 effective words/s\n",
      "2023-12-06 14:29:42,775 : INFO : EPOCH 22: training on 99524 raw words (62968 effective words) took 0.1s, 461295 effective words/s\n",
      "2023-12-06 14:29:42,919 : INFO : EPOCH 23: training on 99524 raw words (62861 effective words) took 0.1s, 453942 effective words/s\n",
      "2023-12-06 14:29:43,067 : INFO : EPOCH 24: training on 99524 raw words (62731 effective words) took 0.1s, 436242 effective words/s\n",
      "2023-12-06 14:29:43,207 : INFO : EPOCH 25: training on 99524 raw words (62776 effective words) took 0.1s, 459844 effective words/s\n",
      "2023-12-06 14:29:43,353 : INFO : EPOCH 26: training on 99524 raw words (62792 effective words) took 0.1s, 444769 effective words/s\n",
      "2023-12-06 14:29:43,494 : INFO : EPOCH 27: training on 99524 raw words (62842 effective words) took 0.1s, 463347 effective words/s\n",
      "2023-12-06 14:29:43,633 : INFO : EPOCH 28: training on 99524 raw words (62788 effective words) took 0.1s, 464864 effective words/s\n",
      "2023-12-06 14:29:43,779 : INFO : EPOCH 29: training on 99524 raw words (62625 effective words) took 0.1s, 442743 effective words/s\n",
      "2023-12-06 14:29:43,917 : INFO : EPOCH 30: training on 99524 raw words (62606 effective words) took 0.1s, 468548 effective words/s\n",
      "2023-12-06 14:29:44,055 : INFO : EPOCH 31: training on 99524 raw words (62644 effective words) took 0.1s, 467621 effective words/s\n",
      "2023-12-06 14:29:44,201 : INFO : EPOCH 32: training on 99524 raw words (62723 effective words) took 0.1s, 441769 effective words/s\n",
      "2023-12-06 14:29:44,341 : INFO : EPOCH 33: training on 99524 raw words (62895 effective words) took 0.1s, 465073 effective words/s\n",
      "2023-12-06 14:29:44,482 : INFO : EPOCH 34: training on 99524 raw words (62782 effective words) took 0.1s, 461704 effective words/s\n",
      "2023-12-06 14:29:44,626 : INFO : EPOCH 35: training on 99524 raw words (62856 effective words) took 0.1s, 447778 effective words/s\n",
      "2023-12-06 14:29:44,771 : INFO : EPOCH 36: training on 99524 raw words (62658 effective words) took 0.1s, 447018 effective words/s\n",
      "2023-12-06 14:29:44,911 : INFO : EPOCH 37: training on 99524 raw words (62533 effective words) took 0.1s, 464319 effective words/s\n",
      "2023-12-06 14:29:45,056 : INFO : EPOCH 38: training on 99524 raw words (62497 effective words) took 0.1s, 443807 effective words/s\n",
      "2023-12-06 14:29:45,195 : INFO : EPOCH 39: training on 99524 raw words (62668 effective words) took 0.1s, 467000 effective words/s\n",
      "2023-12-06 14:29:45,345 : INFO : EPOCH 40: training on 99524 raw words (62687 effective words) took 0.1s, 430671 effective words/s\n",
      "2023-12-06 14:29:45,491 : INFO : EPOCH 41: training on 99524 raw words (62822 effective words) took 0.1s, 442279 effective words/s\n",
      "2023-12-06 14:29:45,630 : INFO : EPOCH 42: training on 99524 raw words (62713 effective words) took 0.1s, 467828 effective words/s\n",
      "2023-12-06 14:29:45,770 : INFO : EPOCH 43: training on 99524 raw words (62765 effective words) took 0.1s, 459734 effective words/s\n",
      "2023-12-06 14:29:45,917 : INFO : EPOCH 44: training on 99524 raw words (62674 effective words) took 0.1s, 443429 effective words/s\n",
      "2023-12-06 14:29:46,056 : INFO : EPOCH 45: training on 99524 raw words (62602 effective words) took 0.1s, 466163 effective words/s\n",
      "2023-12-06 14:29:46,203 : INFO : EPOCH 46: training on 99524 raw words (62670 effective words) took 0.1s, 439338 effective words/s\n",
      "2023-12-06 14:29:46,343 : INFO : EPOCH 47: training on 99524 raw words (62635 effective words) took 0.1s, 461403 effective words/s\n",
      "2023-12-06 14:29:46,482 : INFO : EPOCH 48: training on 99524 raw words (62723 effective words) took 0.1s, 465815 effective words/s\n",
      "2023-12-06 14:29:46,627 : INFO : EPOCH 49: training on 99524 raw words (62610 effective words) took 0.1s, 446045 effective words/s\n",
      "2023-12-06 14:29:46,628 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136192 effective words) took 7.1s, 440382 effective words/s', 'datetime': '2023-12-06T14:29:46.628559', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:29:46,628 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:29:46.628559', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 20%|        | 99/486 [16:08<59:47,  9.27s/it]2023-12-06 14:29:50,263 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:29:50,264 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:29:50,283 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:29:50,283 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:29:50,289 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:29:50.289945', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:29:50,289 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:29:50.289945', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:29:50,294 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:29:50,295 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:29:50,295 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:29:50.295480', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:29:50,302 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:29:50,303 : INFO : resetting layer weights\n",
      "2023-12-06 14:29:50,305 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:29:50.305784', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:29:50,461 : INFO : EPOCH 0: training on 99524 raw words (60366 effective words) took 0.2s, 400139 effective words/s\n",
      "2023-12-06 14:29:50,604 : INFO : EPOCH 1: training on 99524 raw words (60391 effective words) took 0.1s, 435307 effective words/s\n",
      "2023-12-06 14:29:50,745 : INFO : EPOCH 2: training on 99524 raw words (60378 effective words) took 0.1s, 442112 effective words/s\n",
      "2023-12-06 14:29:50,892 : INFO : EPOCH 3: training on 99524 raw words (60321 effective words) took 0.1s, 423023 effective words/s\n",
      "2023-12-06 14:29:51,032 : INFO : EPOCH 4: training on 99524 raw words (60424 effective words) took 0.1s, 446248 effective words/s\n",
      "2023-12-06 14:29:51,178 : INFO : EPOCH 5: training on 99524 raw words (60292 effective words) took 0.1s, 425543 effective words/s\n",
      "2023-12-06 14:29:51,326 : INFO : EPOCH 6: training on 99524 raw words (60340 effective words) took 0.1s, 421764 effective words/s\n",
      "2023-12-06 14:29:51,466 : INFO : EPOCH 7: training on 99524 raw words (60428 effective words) took 0.1s, 443977 effective words/s\n",
      "2023-12-06 14:29:51,609 : INFO : EPOCH 8: training on 99524 raw words (60402 effective words) took 0.1s, 436910 effective words/s\n",
      "2023-12-06 14:29:51,754 : INFO : EPOCH 9: training on 99524 raw words (60254 effective words) took 0.1s, 424298 effective words/s\n",
      "2023-12-06 14:29:51,755 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603596 effective words) took 1.4s, 416305 effective words/s', 'datetime': '2023-12-06T14:29:51.755812', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:29:51,756 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:29:51.756812', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 21%|        | 100/486 [16:12<49:30,  7.69s/it]2023-12-06 14:29:54,278 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:29:54,278 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:29:54,298 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:29:54,299 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:29:54,303 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:29:54.303674', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:29:54,303 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:29:54.303674', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:29:54,309 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:29:54,310 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:29:54,311 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:29:54.311391', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:29:54,320 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:29:54,321 : INFO : resetting layer weights\n",
      "2023-12-06 14:29:54,323 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:29:54.323396', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:29:54,482 : INFO : EPOCH 0: training on 99524 raw words (60367 effective words) took 0.2s, 393118 effective words/s\n",
      "2023-12-06 14:29:54,625 : INFO : EPOCH 1: training on 99524 raw words (60454 effective words) took 0.1s, 435843 effective words/s\n",
      "2023-12-06 14:29:54,765 : INFO : EPOCH 2: training on 99524 raw words (60522 effective words) took 0.1s, 440438 effective words/s\n",
      "2023-12-06 14:29:54,914 : INFO : EPOCH 3: training on 99524 raw words (60232 effective words) took 0.1s, 419937 effective words/s\n",
      "2023-12-06 14:29:55,057 : INFO : EPOCH 4: training on 99524 raw words (60534 effective words) took 0.1s, 436915 effective words/s\n",
      "2023-12-06 14:29:55,198 : INFO : EPOCH 5: training on 99524 raw words (60430 effective words) took 0.1s, 439480 effective words/s\n",
      "2023-12-06 14:29:55,339 : INFO : EPOCH 6: training on 99524 raw words (60326 effective words) took 0.1s, 445090 effective words/s\n",
      "2023-12-06 14:29:55,491 : INFO : EPOCH 7: training on 99524 raw words (60497 effective words) took 0.1s, 407733 effective words/s\n",
      "2023-12-06 14:29:55,634 : INFO : EPOCH 8: training on 99524 raw words (60405 effective words) took 0.1s, 436251 effective words/s\n",
      "2023-12-06 14:29:55,775 : INFO : EPOCH 9: training on 99524 raw words (60308 effective words) took 0.1s, 443237 effective words/s\n",
      "2023-12-06 14:29:55,776 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604075 effective words) took 1.5s, 416141 effective words/s', 'datetime': '2023-12-06T14:29:55.776566', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:29:55,776 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:29:55.776566', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 21%|        | 101/486 [16:16<42:23,  6.61s/it]2023-12-06 14:29:58,343 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:29:58,343 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:29:58,367 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:29:58,368 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:29:58,372 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:29:58.371938', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:29:58,372 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:29:58.372938', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:29:58,376 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:29:58,377 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:29:58,377 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:29:58.377949', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:29:58,385 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:29:58,385 : INFO : resetting layer weights\n",
      "2023-12-06 14:29:58,388 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:29:58.388252', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:29:58,544 : INFO : EPOCH 0: training on 99524 raw words (60337 effective words) took 0.2s, 393420 effective words/s\n",
      "2023-12-06 14:29:58,690 : INFO : EPOCH 1: training on 99524 raw words (60443 effective words) took 0.1s, 428487 effective words/s\n",
      "2023-12-06 14:29:58,828 : INFO : EPOCH 2: training on 99524 raw words (60424 effective words) took 0.1s, 451945 effective words/s\n",
      "2023-12-06 14:29:58,973 : INFO : EPOCH 3: training on 99524 raw words (60121 effective words) took 0.1s, 426487 effective words/s\n",
      "2023-12-06 14:29:59,114 : INFO : EPOCH 4: training on 99524 raw words (60416 effective words) took 0.1s, 445216 effective words/s\n",
      "2023-12-06 14:29:59,253 : INFO : EPOCH 5: training on 99524 raw words (60355 effective words) took 0.1s, 446288 effective words/s\n",
      "2023-12-06 14:29:59,398 : INFO : EPOCH 6: training on 99524 raw words (60313 effective words) took 0.1s, 430600 effective words/s\n",
      "2023-12-06 14:29:59,537 : INFO : EPOCH 7: training on 99524 raw words (60297 effective words) took 0.1s, 446322 effective words/s\n",
      "2023-12-06 14:29:59,675 : INFO : EPOCH 8: training on 99524 raw words (60368 effective words) took 0.1s, 451433 effective words/s\n",
      "2023-12-06 14:29:59,822 : INFO : EPOCH 9: training on 99524 raw words (60346 effective words) took 0.1s, 428288 effective words/s\n",
      "2023-12-06 14:29:59,823 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603420 effective words) took 1.4s, 420441 effective words/s', 'datetime': '2023-12-06T14:29:59.823749', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:29:59,824 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:29:59.824749', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 21%|        | 102/486 [16:21<37:27,  5.85s/it]2023-12-06 14:30:02,441 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:30:02,441 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:30:02,461 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:30:02,462 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:30:02,467 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:30:02.467284', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:30:02,468 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:30:02.468284', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:30:02,474 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:30:02,475 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:30:02,475 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:30:02.475284', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:30:02,483 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:30:02,484 : INFO : resetting layer weights\n",
      "2023-12-06 14:30:02,485 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:30:02.485008', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:30:02,634 : INFO : EPOCH 0: training on 99524 raw words (60364 effective words) took 0.1s, 413316 effective words/s\n",
      "2023-12-06 14:30:02,786 : INFO : EPOCH 1: training on 99524 raw words (60356 effective words) took 0.1s, 411483 effective words/s\n",
      "2023-12-06 14:30:02,928 : INFO : EPOCH 2: training on 99524 raw words (60338 effective words) took 0.1s, 438244 effective words/s\n",
      "2023-12-06 14:30:03,074 : INFO : EPOCH 3: training on 99524 raw words (60194 effective words) took 0.1s, 425098 effective words/s\n",
      "2023-12-06 14:30:03,218 : INFO : EPOCH 4: training on 99524 raw words (60368 effective words) took 0.1s, 435296 effective words/s\n",
      "2023-12-06 14:30:03,357 : INFO : EPOCH 5: training on 99524 raw words (60356 effective words) took 0.1s, 445205 effective words/s\n",
      "2023-12-06 14:30:03,503 : INFO : EPOCH 6: training on 99524 raw words (60382 effective words) took 0.1s, 426423 effective words/s\n",
      "2023-12-06 14:30:03,645 : INFO : EPOCH 7: training on 99524 raw words (60421 effective words) took 0.1s, 437332 effective words/s\n",
      "2023-12-06 14:30:03,786 : INFO : EPOCH 8: training on 99524 raw words (60563 effective words) took 0.1s, 443464 effective words/s\n",
      "2023-12-06 14:30:03,931 : INFO : EPOCH 9: training on 99524 raw words (60329 effective words) took 0.1s, 427682 effective words/s\n",
      "2023-12-06 14:30:04,071 : INFO : EPOCH 10: training on 99524 raw words (60461 effective words) took 0.1s, 446354 effective words/s\n",
      "2023-12-06 14:30:04,218 : INFO : EPOCH 11: training on 99524 raw words (60481 effective words) took 0.1s, 426593 effective words/s\n",
      "2023-12-06 14:30:04,359 : INFO : EPOCH 12: training on 99524 raw words (60433 effective words) took 0.1s, 442566 effective words/s\n",
      "2023-12-06 14:30:04,505 : INFO : EPOCH 13: training on 99524 raw words (60493 effective words) took 0.1s, 425115 effective words/s\n",
      "2023-12-06 14:30:04,645 : INFO : EPOCH 14: training on 99524 raw words (60403 effective words) took 0.1s, 445111 effective words/s\n",
      "2023-12-06 14:30:04,792 : INFO : EPOCH 15: training on 99524 raw words (60360 effective words) took 0.1s, 424943 effective words/s\n",
      "2023-12-06 14:30:04,939 : INFO : EPOCH 16: training on 99524 raw words (60545 effective words) took 0.1s, 422686 effective words/s\n",
      "2023-12-06 14:30:05,080 : INFO : EPOCH 17: training on 99524 raw words (60433 effective words) took 0.1s, 441962 effective words/s\n",
      "2023-12-06 14:30:05,230 : INFO : EPOCH 18: training on 99524 raw words (60147 effective words) took 0.1s, 413974 effective words/s\n",
      "2023-12-06 14:30:05,374 : INFO : EPOCH 19: training on 99524 raw words (60480 effective words) took 0.1s, 432933 effective words/s\n",
      "2023-12-06 14:30:05,513 : INFO : EPOCH 20: training on 99524 raw words (60459 effective words) took 0.1s, 450581 effective words/s\n",
      "2023-12-06 14:30:05,655 : INFO : EPOCH 21: training on 99524 raw words (60426 effective words) took 0.1s, 437322 effective words/s\n",
      "2023-12-06 14:30:05,796 : INFO : EPOCH 22: training on 99524 raw words (60389 effective words) took 0.1s, 442628 effective words/s\n",
      "2023-12-06 14:30:05,942 : INFO : EPOCH 23: training on 99524 raw words (60444 effective words) took 0.1s, 427329 effective words/s\n",
      "2023-12-06 14:30:06,089 : INFO : EPOCH 24: training on 99524 raw words (60463 effective words) took 0.1s, 424297 effective words/s\n",
      "2023-12-06 14:30:06,230 : INFO : EPOCH 25: training on 99524 raw words (60269 effective words) took 0.1s, 440526 effective words/s\n",
      "2023-12-06 14:30:06,376 : INFO : EPOCH 26: training on 99524 raw words (60534 effective words) took 0.1s, 426761 effective words/s\n",
      "2023-12-06 14:30:06,517 : INFO : EPOCH 27: training on 99524 raw words (60576 effective words) took 0.1s, 446384 effective words/s\n",
      "2023-12-06 14:30:06,656 : INFO : EPOCH 28: training on 99524 raw words (60459 effective words) took 0.1s, 448544 effective words/s\n",
      "2023-12-06 14:30:06,801 : INFO : EPOCH 29: training on 99524 raw words (60516 effective words) took 0.1s, 430163 effective words/s\n",
      "2023-12-06 14:30:06,801 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812442 effective words) took 4.3s, 419867 effective words/s', 'datetime': '2023-12-06T14:30:06.801762', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:30:06,802 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:30:06.802767', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 21%|        | 103/486 [16:28<39:48,  6.24s/it]2023-12-06 14:30:09,570 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:30:09,570 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:30:09,590 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:30:09,592 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:30:09,597 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:30:09.597394', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:30:09,597 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:30:09.597898', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:30:09,604 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:30:09,604 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:30:09,604 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:30:09.604757', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:30:09,612 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:30:09,612 : INFO : resetting layer weights\n",
      "2023-12-06 14:30:09,614 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:30:09.614223', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:30:09,763 : INFO : EPOCH 0: training on 99524 raw words (60369 effective words) took 0.1s, 416968 effective words/s\n",
      "2023-12-06 14:30:09,914 : INFO : EPOCH 1: training on 99524 raw words (60487 effective words) took 0.1s, 412470 effective words/s\n",
      "2023-12-06 14:30:10,056 : INFO : EPOCH 2: training on 99524 raw words (60460 effective words) took 0.1s, 438644 effective words/s\n",
      "2023-12-06 14:30:10,206 : INFO : EPOCH 3: training on 99524 raw words (60213 effective words) took 0.1s, 413913 effective words/s\n",
      "2023-12-06 14:30:10,348 : INFO : EPOCH 4: training on 99524 raw words (60223 effective words) took 0.1s, 435195 effective words/s\n",
      "2023-12-06 14:30:10,491 : INFO : EPOCH 5: training on 99524 raw words (60440 effective words) took 0.1s, 438812 effective words/s\n",
      "2023-12-06 14:30:10,638 : INFO : EPOCH 6: training on 99524 raw words (60362 effective words) took 0.1s, 422190 effective words/s\n",
      "2023-12-06 14:30:10,780 : INFO : EPOCH 7: training on 99524 raw words (60575 effective words) took 0.1s, 442585 effective words/s\n",
      "2023-12-06 14:30:10,921 : INFO : EPOCH 8: training on 99524 raw words (60589 effective words) took 0.1s, 441723 effective words/s\n",
      "2023-12-06 14:30:11,066 : INFO : EPOCH 9: training on 99524 raw words (60324 effective words) took 0.1s, 426651 effective words/s\n",
      "2023-12-06 14:30:11,208 : INFO : EPOCH 10: training on 99524 raw words (60377 effective words) took 0.1s, 439037 effective words/s\n",
      "2023-12-06 14:30:11,350 : INFO : EPOCH 11: training on 99524 raw words (60541 effective words) took 0.1s, 440835 effective words/s\n",
      "2023-12-06 14:30:11,499 : INFO : EPOCH 12: training on 99524 raw words (60530 effective words) took 0.1s, 417727 effective words/s\n",
      "2023-12-06 14:30:11,648 : INFO : EPOCH 13: training on 99524 raw words (60457 effective words) took 0.1s, 423680 effective words/s\n",
      "2023-12-06 14:30:11,791 : INFO : EPOCH 14: training on 99524 raw words (60470 effective words) took 0.1s, 434251 effective words/s\n",
      "2023-12-06 14:30:11,939 : INFO : EPOCH 15: training on 99524 raw words (60337 effective words) took 0.1s, 420305 effective words/s\n",
      "2023-12-06 14:30:12,082 : INFO : EPOCH 16: training on 99524 raw words (60428 effective words) took 0.1s, 436217 effective words/s\n",
      "2023-12-06 14:30:12,223 : INFO : EPOCH 17: training on 99524 raw words (60410 effective words) took 0.1s, 442992 effective words/s\n",
      "2023-12-06 14:30:12,375 : INFO : EPOCH 18: training on 99524 raw words (60205 effective words) took 0.1s, 407030 effective words/s\n",
      "2023-12-06 14:30:12,517 : INFO : EPOCH 19: training on 99524 raw words (60503 effective words) took 0.1s, 441638 effective words/s\n",
      "2023-12-06 14:30:12,663 : INFO : EPOCH 20: training on 99524 raw words (60358 effective words) took 0.1s, 425291 effective words/s\n",
      "2023-12-06 14:30:12,813 : INFO : EPOCH 21: training on 99524 raw words (60436 effective words) took 0.1s, 415165 effective words/s\n",
      "2023-12-06 14:30:12,956 : INFO : EPOCH 22: training on 99524 raw words (60587 effective words) took 0.1s, 437434 effective words/s\n",
      "2023-12-06 14:30:13,104 : INFO : EPOCH 23: training on 99524 raw words (60492 effective words) took 0.1s, 420251 effective words/s\n",
      "2023-12-06 14:30:13,247 : INFO : EPOCH 24: training on 99524 raw words (60301 effective words) took 0.1s, 438569 effective words/s\n",
      "2023-12-06 14:30:13,388 : INFO : EPOCH 25: training on 99524 raw words (60329 effective words) took 0.1s, 440653 effective words/s\n",
      "2023-12-06 14:30:13,536 : INFO : EPOCH 26: training on 99524 raw words (60487 effective words) took 0.1s, 421188 effective words/s\n",
      "2023-12-06 14:30:13,678 : INFO : EPOCH 27: training on 99524 raw words (60467 effective words) took 0.1s, 438883 effective words/s\n",
      "2023-12-06 14:30:13,818 : INFO : EPOCH 28: training on 99524 raw words (60388 effective words) took 0.1s, 443445 effective words/s\n",
      "2023-12-06 14:30:13,967 : INFO : EPOCH 29: training on 99524 raw words (60343 effective words) took 0.1s, 417791 effective words/s\n",
      "2023-12-06 14:30:13,968 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812488 effective words) took 4.4s, 416318 effective words/s', 'datetime': '2023-12-06T14:30:13.968652', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:30:13,969 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:30:13.969653', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 21%|       | 104/486 [16:35<41:49,  6.57s/it]2023-12-06 14:30:16,919 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:30:16,919 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:30:16,940 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:30:16,941 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:30:16,947 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:30:16.947152', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:30:16,947 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:30:16.947152', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:30:16,951 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:30:16,952 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:30:16,952 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:30:16.952660', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:30:16,962 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:30:16,963 : INFO : resetting layer weights\n",
      "2023-12-06 14:30:16,964 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:30:16.964172', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:30:17,120 : INFO : EPOCH 0: training on 99524 raw words (60348 effective words) took 0.2s, 397776 effective words/s\n",
      "2023-12-06 14:30:17,259 : INFO : EPOCH 1: training on 99524 raw words (60397 effective words) took 0.1s, 444685 effective words/s\n",
      "2023-12-06 14:30:17,406 : INFO : EPOCH 2: training on 99524 raw words (60428 effective words) took 0.1s, 426521 effective words/s\n",
      "2023-12-06 14:30:17,550 : INFO : EPOCH 3: training on 99524 raw words (60284 effective words) took 0.1s, 432464 effective words/s\n",
      "2023-12-06 14:30:17,691 : INFO : EPOCH 4: training on 99524 raw words (60403 effective words) took 0.1s, 443999 effective words/s\n",
      "2023-12-06 14:30:17,831 : INFO : EPOCH 5: training on 99524 raw words (60426 effective words) took 0.1s, 445021 effective words/s\n",
      "2023-12-06 14:30:17,977 : INFO : EPOCH 6: training on 99524 raw words (60258 effective words) took 0.1s, 425263 effective words/s\n",
      "2023-12-06 14:30:18,116 : INFO : EPOCH 7: training on 99524 raw words (60479 effective words) took 0.1s, 449304 effective words/s\n",
      "2023-12-06 14:30:18,258 : INFO : EPOCH 8: training on 99524 raw words (60374 effective words) took 0.1s, 440117 effective words/s\n",
      "2023-12-06 14:30:18,403 : INFO : EPOCH 9: training on 99524 raw words (60495 effective words) took 0.1s, 430017 effective words/s\n",
      "2023-12-06 14:30:18,543 : INFO : EPOCH 10: training on 99524 raw words (60356 effective words) took 0.1s, 445094 effective words/s\n",
      "2023-12-06 14:30:18,683 : INFO : EPOCH 11: training on 99524 raw words (60401 effective words) took 0.1s, 445172 effective words/s\n",
      "2023-12-06 14:30:18,829 : INFO : EPOCH 12: training on 99524 raw words (60317 effective words) took 0.1s, 427363 effective words/s\n",
      "2023-12-06 14:30:18,968 : INFO : EPOCH 13: training on 99524 raw words (60378 effective words) took 0.1s, 447358 effective words/s\n",
      "2023-12-06 14:30:19,107 : INFO : EPOCH 14: training on 99524 raw words (60462 effective words) took 0.1s, 445701 effective words/s\n",
      "2023-12-06 14:30:19,253 : INFO : EPOCH 15: training on 99524 raw words (60488 effective words) took 0.1s, 428114 effective words/s\n",
      "2023-12-06 14:30:19,394 : INFO : EPOCH 16: training on 99524 raw words (60434 effective words) took 0.1s, 443200 effective words/s\n",
      "2023-12-06 14:30:19,535 : INFO : EPOCH 17: training on 99524 raw words (60257 effective words) took 0.1s, 441261 effective words/s\n",
      "2023-12-06 14:30:19,681 : INFO : EPOCH 18: training on 99524 raw words (60333 effective words) took 0.1s, 425355 effective words/s\n",
      "2023-12-06 14:30:19,820 : INFO : EPOCH 19: training on 99524 raw words (60459 effective words) took 0.1s, 447803 effective words/s\n",
      "2023-12-06 14:30:19,972 : INFO : EPOCH 20: training on 99524 raw words (60319 effective words) took 0.1s, 412260 effective words/s\n",
      "2023-12-06 14:30:20,117 : INFO : EPOCH 21: training on 99524 raw words (60486 effective words) took 0.1s, 428251 effective words/s\n",
      "2023-12-06 14:30:20,259 : INFO : EPOCH 22: training on 99524 raw words (60551 effective words) took 0.1s, 439553 effective words/s\n",
      "2023-12-06 14:30:20,406 : INFO : EPOCH 23: training on 99524 raw words (60324 effective words) took 0.1s, 423289 effective words/s\n",
      "2023-12-06 14:30:20,547 : INFO : EPOCH 24: training on 99524 raw words (60405 effective words) took 0.1s, 446095 effective words/s\n",
      "2023-12-06 14:30:20,687 : INFO : EPOCH 25: training on 99524 raw words (60383 effective words) took 0.1s, 441995 effective words/s\n",
      "2023-12-06 14:30:20,842 : INFO : EPOCH 26: training on 99524 raw words (60432 effective words) took 0.1s, 407487 effective words/s\n",
      "2023-12-06 14:30:20,981 : INFO : EPOCH 27: training on 99524 raw words (60534 effective words) took 0.1s, 448309 effective words/s\n",
      "2023-12-06 14:30:21,120 : INFO : EPOCH 28: training on 99524 raw words (60446 effective words) took 0.1s, 448413 effective words/s\n",
      "2023-12-06 14:30:21,266 : INFO : EPOCH 29: training on 99524 raw words (60496 effective words) took 0.1s, 428882 effective words/s\n",
      "2023-12-06 14:30:21,267 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812153 effective words) took 4.3s, 421266 effective words/s', 'datetime': '2023-12-06T14:30:21.267317', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:30:21,267 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:30:21.267317', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 22%|       | 105/486 [16:42<43:22,  6.83s/it]2023-12-06 14:30:24,359 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:30:24,360 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:30:24,380 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:30:24,381 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:30:24,385 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:30:24.385311', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:30:24,386 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:30:24.386317', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:30:24,390 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:30:24,391 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:30:24,391 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:30:24.391652', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:30:24,398 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:30:24,399 : INFO : resetting layer weights\n",
      "2023-12-06 14:30:24,401 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:30:24.401253', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:30:24,554 : INFO : EPOCH 0: training on 99524 raw words (60399 effective words) took 0.1s, 403582 effective words/s\n",
      "2023-12-06 14:30:24,694 : INFO : EPOCH 1: training on 99524 raw words (60510 effective words) took 0.1s, 445037 effective words/s\n",
      "2023-12-06 14:30:24,841 : INFO : EPOCH 2: training on 99524 raw words (60399 effective words) took 0.1s, 423609 effective words/s\n",
      "2023-12-06 14:30:24,993 : INFO : EPOCH 3: training on 99524 raw words (60233 effective words) took 0.1s, 410026 effective words/s\n",
      "2023-12-06 14:30:25,136 : INFO : EPOCH 4: training on 99524 raw words (60370 effective words) took 0.1s, 434731 effective words/s\n",
      "2023-12-06 14:30:25,279 : INFO : EPOCH 5: training on 99524 raw words (60454 effective words) took 0.1s, 440344 effective words/s\n",
      "2023-12-06 14:30:25,426 : INFO : EPOCH 6: training on 99524 raw words (60381 effective words) took 0.1s, 422692 effective words/s\n",
      "2023-12-06 14:30:25,567 : INFO : EPOCH 7: training on 99524 raw words (60424 effective words) took 0.1s, 441457 effective words/s\n",
      "2023-12-06 14:30:25,710 : INFO : EPOCH 8: training on 99524 raw words (60563 effective words) took 0.1s, 437633 effective words/s\n",
      "2023-12-06 14:30:25,859 : INFO : EPOCH 9: training on 99524 raw words (60445 effective words) took 0.1s, 418442 effective words/s\n",
      "2023-12-06 14:30:26,002 : INFO : EPOCH 10: training on 99524 raw words (60329 effective words) took 0.1s, 437986 effective words/s\n",
      "2023-12-06 14:30:26,143 : INFO : EPOCH 11: training on 99524 raw words (60527 effective words) took 0.1s, 442990 effective words/s\n",
      "2023-12-06 14:30:26,292 : INFO : EPOCH 12: training on 99524 raw words (60313 effective words) took 0.1s, 419883 effective words/s\n",
      "2023-12-06 14:30:26,433 : INFO : EPOCH 13: training on 99524 raw words (60326 effective words) took 0.1s, 439602 effective words/s\n",
      "2023-12-06 14:30:26,579 : INFO : EPOCH 14: training on 99524 raw words (60354 effective words) took 0.1s, 424422 effective words/s\n",
      "2023-12-06 14:30:26,720 : INFO : EPOCH 15: training on 99524 raw words (60267 effective words) took 0.1s, 442726 effective words/s\n",
      "2023-12-06 14:30:26,862 : INFO : EPOCH 16: training on 99524 raw words (60337 effective words) took 0.1s, 439960 effective words/s\n",
      "2023-12-06 14:30:27,016 : INFO : EPOCH 17: training on 99524 raw words (60329 effective words) took 0.1s, 402678 effective words/s\n",
      "2023-12-06 14:30:27,158 : INFO : EPOCH 18: training on 99524 raw words (60375 effective words) took 0.1s, 438627 effective words/s\n",
      "2023-12-06 14:30:27,301 : INFO : EPOCH 19: training on 99524 raw words (60398 effective words) took 0.1s, 437356 effective words/s\n",
      "2023-12-06 14:30:27,447 : INFO : EPOCH 20: training on 99524 raw words (60416 effective words) took 0.1s, 427110 effective words/s\n",
      "2023-12-06 14:30:27,586 : INFO : EPOCH 21: training on 99524 raw words (60398 effective words) took 0.1s, 445116 effective words/s\n",
      "2023-12-06 14:30:27,727 : INFO : EPOCH 22: training on 99524 raw words (60492 effective words) took 0.1s, 445095 effective words/s\n",
      "2023-12-06 14:30:27,874 : INFO : EPOCH 23: training on 99524 raw words (60315 effective words) took 0.1s, 427186 effective words/s\n",
      "2023-12-06 14:30:28,014 : INFO : EPOCH 24: training on 99524 raw words (60612 effective words) took 0.1s, 443586 effective words/s\n",
      "2023-12-06 14:30:28,160 : INFO : EPOCH 25: training on 99524 raw words (60310 effective words) took 0.1s, 425375 effective words/s\n",
      "2023-12-06 14:30:28,304 : INFO : EPOCH 26: training on 99524 raw words (60509 effective words) took 0.1s, 435574 effective words/s\n",
      "2023-12-06 14:30:28,445 : INFO : EPOCH 27: training on 99524 raw words (60622 effective words) took 0.1s, 442755 effective words/s\n",
      "2023-12-06 14:30:28,593 : INFO : EPOCH 28: training on 99524 raw words (60416 effective words) took 0.1s, 419594 effective words/s\n",
      "2023-12-06 14:30:28,735 : INFO : EPOCH 29: training on 99524 raw words (60372 effective words) took 0.1s, 439951 effective words/s\n",
      "2023-12-06 14:30:28,874 : INFO : EPOCH 30: training on 99524 raw words (60454 effective words) took 0.1s, 445899 effective words/s\n",
      "2023-12-06 14:30:29,018 : INFO : EPOCH 31: training on 99524 raw words (60474 effective words) took 0.1s, 434455 effective words/s\n",
      "2023-12-06 14:30:29,158 : INFO : EPOCH 32: training on 99524 raw words (60538 effective words) took 0.1s, 442727 effective words/s\n",
      "2023-12-06 14:30:29,310 : INFO : EPOCH 33: training on 99524 raw words (60386 effective words) took 0.1s, 410672 effective words/s\n",
      "2023-12-06 14:30:29,451 : INFO : EPOCH 34: training on 99524 raw words (60491 effective words) took 0.1s, 442456 effective words/s\n",
      "2023-12-06 14:30:29,591 : INFO : EPOCH 35: training on 99524 raw words (60541 effective words) took 0.1s, 448209 effective words/s\n",
      "2023-12-06 14:30:29,736 : INFO : EPOCH 36: training on 99524 raw words (60243 effective words) took 0.1s, 425482 effective words/s\n",
      "2023-12-06 14:30:29,885 : INFO : EPOCH 37: training on 99524 raw words (60300 effective words) took 0.1s, 415534 effective words/s\n",
      "2023-12-06 14:30:30,028 : INFO : EPOCH 38: training on 99524 raw words (60313 effective words) took 0.1s, 437260 effective words/s\n",
      "2023-12-06 14:30:30,177 : INFO : EPOCH 39: training on 99524 raw words (60370 effective words) took 0.1s, 417325 effective words/s\n",
      "2023-12-06 14:30:30,317 : INFO : EPOCH 40: training on 99524 raw words (60315 effective words) took 0.1s, 445053 effective words/s\n",
      "2023-12-06 14:30:30,456 : INFO : EPOCH 41: training on 99524 raw words (60592 effective words) took 0.1s, 445957 effective words/s\n",
      "2023-12-06 14:30:30,604 : INFO : EPOCH 42: training on 99524 raw words (60338 effective words) took 0.1s, 423061 effective words/s\n",
      "2023-12-06 14:30:30,745 : INFO : EPOCH 43: training on 99524 raw words (60382 effective words) took 0.1s, 441640 effective words/s\n",
      "2023-12-06 14:30:30,885 : INFO : EPOCH 44: training on 99524 raw words (60419 effective words) took 0.1s, 446000 effective words/s\n",
      "2023-12-06 14:30:31,032 : INFO : EPOCH 45: training on 99524 raw words (60490 effective words) took 0.1s, 424727 effective words/s\n",
      "2023-12-06 14:30:31,172 : INFO : EPOCH 46: training on 99524 raw words (60392 effective words) took 0.1s, 442617 effective words/s\n",
      "2023-12-06 14:30:31,311 : INFO : EPOCH 47: training on 99524 raw words (60442 effective words) took 0.1s, 448122 effective words/s\n",
      "2023-12-06 14:30:31,459 : INFO : EPOCH 48: training on 99524 raw words (60523 effective words) took 0.1s, 422170 effective words/s\n",
      "2023-12-06 14:30:31,600 : INFO : EPOCH 49: training on 99524 raw words (60306 effective words) took 0.1s, 441177 effective words/s\n",
      "2023-12-06 14:30:31,601 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3020504 effective words) took 7.2s, 419495 effective words/s', 'datetime': '2023-12-06T14:30:31.601606', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:30:31,602 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:30:31.602606', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 22%|       | 106/486 [16:53<49:55,  7.88s/it]2023-12-06 14:30:34,692 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:30:34,693 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:30:34,718 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:30:34,718 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:30:34,722 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:30:34.722584', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:30:34,722 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:30:34.722584', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:30:34,727 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:30:34,727 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:30:34,728 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:30:34.728593', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:30:34,735 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:30:34,736 : INFO : resetting layer weights\n",
      "2023-12-06 14:30:34,737 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:30:34.737007', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:30:34,899 : INFO : EPOCH 0: training on 99524 raw words (60223 effective words) took 0.2s, 381532 effective words/s\n",
      "2023-12-06 14:30:35,042 : INFO : EPOCH 1: training on 99524 raw words (60377 effective words) took 0.1s, 437140 effective words/s\n",
      "2023-12-06 14:30:35,183 : INFO : EPOCH 2: training on 99524 raw words (60554 effective words) took 0.1s, 443578 effective words/s\n",
      "2023-12-06 14:30:35,328 : INFO : EPOCH 3: training on 99524 raw words (60319 effective words) took 0.1s, 426537 effective words/s\n",
      "2023-12-06 14:30:35,470 : INFO : EPOCH 4: training on 99524 raw words (60331 effective words) took 0.1s, 438689 effective words/s\n",
      "2023-12-06 14:30:35,612 : INFO : EPOCH 5: training on 99524 raw words (60446 effective words) took 0.1s, 440588 effective words/s\n",
      "2023-12-06 14:30:35,760 : INFO : EPOCH 6: training on 99524 raw words (60310 effective words) took 0.1s, 420035 effective words/s\n",
      "2023-12-06 14:30:35,901 : INFO : EPOCH 7: training on 99524 raw words (60526 effective words) took 0.1s, 440721 effective words/s\n",
      "2023-12-06 14:30:36,040 : INFO : EPOCH 8: training on 99524 raw words (60407 effective words) took 0.1s, 448954 effective words/s\n",
      "2023-12-06 14:30:36,187 : INFO : EPOCH 9: training on 99524 raw words (60305 effective words) took 0.1s, 420975 effective words/s\n",
      "2023-12-06 14:30:36,328 : INFO : EPOCH 10: training on 99524 raw words (60193 effective words) took 0.1s, 440389 effective words/s\n",
      "2023-12-06 14:30:36,470 : INFO : EPOCH 11: training on 99524 raw words (60449 effective words) took 0.1s, 440050 effective words/s\n",
      "2023-12-06 14:30:36,619 : INFO : EPOCH 12: training on 99524 raw words (60458 effective words) took 0.1s, 422172 effective words/s\n",
      "2023-12-06 14:30:36,761 : INFO : EPOCH 13: training on 99524 raw words (60393 effective words) took 0.1s, 438266 effective words/s\n",
      "2023-12-06 14:30:36,901 : INFO : EPOCH 14: training on 99524 raw words (60374 effective words) took 0.1s, 442293 effective words/s\n",
      "2023-12-06 14:30:37,050 : INFO : EPOCH 15: training on 99524 raw words (60348 effective words) took 0.1s, 420596 effective words/s\n",
      "2023-12-06 14:30:37,192 : INFO : EPOCH 16: training on 99524 raw words (60302 effective words) took 0.1s, 434402 effective words/s\n",
      "2023-12-06 14:30:37,331 : INFO : EPOCH 17: training on 99524 raw words (60194 effective words) took 0.1s, 448084 effective words/s\n",
      "2023-12-06 14:30:37,478 : INFO : EPOCH 18: training on 99524 raw words (60224 effective words) took 0.1s, 423985 effective words/s\n",
      "2023-12-06 14:30:37,624 : INFO : EPOCH 19: training on 99524 raw words (60500 effective words) took 0.1s, 425993 effective words/s\n",
      "2023-12-06 14:30:37,773 : INFO : EPOCH 20: training on 99524 raw words (60446 effective words) took 0.1s, 417061 effective words/s\n",
      "2023-12-06 14:30:37,920 : INFO : EPOCH 21: training on 99524 raw words (60380 effective words) took 0.1s, 422954 effective words/s\n",
      "2023-12-06 14:30:38,062 : INFO : EPOCH 22: training on 99524 raw words (60476 effective words) took 0.1s, 441237 effective words/s\n",
      "2023-12-06 14:30:38,203 : INFO : EPOCH 23: training on 99524 raw words (60481 effective words) took 0.1s, 442881 effective words/s\n",
      "2023-12-06 14:30:38,353 : INFO : EPOCH 24: training on 99524 raw words (60264 effective words) took 0.1s, 415504 effective words/s\n",
      "2023-12-06 14:30:38,495 : INFO : EPOCH 25: training on 99524 raw words (60260 effective words) took 0.1s, 437198 effective words/s\n",
      "2023-12-06 14:30:38,634 : INFO : EPOCH 26: training on 99524 raw words (60477 effective words) took 0.1s, 446618 effective words/s\n",
      "2023-12-06 14:30:38,784 : INFO : EPOCH 27: training on 99524 raw words (60374 effective words) took 0.1s, 414960 effective words/s\n",
      "2023-12-06 14:30:38,927 : INFO : EPOCH 28: training on 99524 raw words (60350 effective words) took 0.1s, 435056 effective words/s\n",
      "2023-12-06 14:30:39,068 : INFO : EPOCH 29: training on 99524 raw words (60480 effective words) took 0.1s, 443967 effective words/s\n",
      "2023-12-06 14:30:39,216 : INFO : EPOCH 30: training on 99524 raw words (60342 effective words) took 0.1s, 420336 effective words/s\n",
      "2023-12-06 14:30:39,357 : INFO : EPOCH 31: training on 99524 raw words (60446 effective words) took 0.1s, 441621 effective words/s\n",
      "2023-12-06 14:30:39,498 : INFO : EPOCH 32: training on 99524 raw words (60542 effective words) took 0.1s, 442776 effective words/s\n",
      "2023-12-06 14:30:39,645 : INFO : EPOCH 33: training on 99524 raw words (60600 effective words) took 0.1s, 424296 effective words/s\n",
      "2023-12-06 14:30:39,789 : INFO : EPOCH 34: training on 99524 raw words (60520 effective words) took 0.1s, 436761 effective words/s\n",
      "2023-12-06 14:30:39,929 : INFO : EPOCH 35: training on 99524 raw words (60743 effective words) took 0.1s, 445845 effective words/s\n",
      "2023-12-06 14:30:40,077 : INFO : EPOCH 36: training on 99524 raw words (60445 effective words) took 0.1s, 420668 effective words/s\n",
      "2023-12-06 14:30:40,225 : INFO : EPOCH 37: training on 99524 raw words (60338 effective words) took 0.1s, 424098 effective words/s\n",
      "2023-12-06 14:30:40,365 : INFO : EPOCH 38: training on 99524 raw words (60374 effective words) took 0.1s, 445970 effective words/s\n",
      "2023-12-06 14:30:40,513 : INFO : EPOCH 39: training on 99524 raw words (60332 effective words) took 0.1s, 419681 effective words/s\n",
      "2023-12-06 14:30:40,662 : INFO : EPOCH 40: training on 99524 raw words (60413 effective words) took 0.1s, 416106 effective words/s\n",
      "2023-12-06 14:30:40,804 : INFO : EPOCH 41: training on 99524 raw words (60470 effective words) took 0.1s, 439526 effective words/s\n",
      "2023-12-06 14:30:40,951 : INFO : EPOCH 42: training on 99524 raw words (60324 effective words) took 0.1s, 422737 effective words/s\n",
      "2023-12-06 14:30:41,094 : INFO : EPOCH 43: training on 99524 raw words (60472 effective words) took 0.1s, 437667 effective words/s\n",
      "2023-12-06 14:30:41,244 : INFO : EPOCH 44: training on 99524 raw words (60261 effective words) took 0.1s, 413834 effective words/s\n",
      "2023-12-06 14:30:41,386 : INFO : EPOCH 45: training on 99524 raw words (60289 effective words) took 0.1s, 436560 effective words/s\n",
      "2023-12-06 14:30:41,526 : INFO : EPOCH 46: training on 99524 raw words (60387 effective words) took 0.1s, 446083 effective words/s\n",
      "2023-12-06 14:30:41,672 : INFO : EPOCH 47: training on 99524 raw words (60223 effective words) took 0.1s, 424122 effective words/s\n",
      "2023-12-06 14:30:41,813 : INFO : EPOCH 48: training on 99524 raw words (60365 effective words) took 0.1s, 442327 effective words/s\n",
      "2023-12-06 14:30:41,955 : INFO : EPOCH 49: training on 99524 raw words (60405 effective words) took 0.1s, 437546 effective words/s\n",
      "2023-12-06 14:30:41,956 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3019512 effective words) took 7.2s, 418301 effective words/s', 'datetime': '2023-12-06T14:30:41.956921', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:30:41,957 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:30:41.957920', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 22%|       | 107/486 [17:03<54:55,  8.69s/it]2023-12-06 14:30:45,283 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:30:45,283 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:30:45,304 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:30:45,305 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:30:45,308 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:30:45.308675', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:30:45,309 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:30:45.309675', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:30:45,315 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:30:45,315 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:30:45,316 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:30:45.316676', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:30:45,323 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:30:45,324 : INFO : resetting layer weights\n",
      "2023-12-06 14:30:45,325 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:30:45.325184', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:30:45,483 : INFO : EPOCH 0: training on 99524 raw words (60369 effective words) took 0.2s, 392097 effective words/s\n",
      "2023-12-06 14:30:45,629 : INFO : EPOCH 1: training on 99524 raw words (60314 effective words) took 0.1s, 426407 effective words/s\n",
      "2023-12-06 14:30:45,769 : INFO : EPOCH 2: training on 99524 raw words (60620 effective words) took 0.1s, 446402 effective words/s\n",
      "2023-12-06 14:30:45,916 : INFO : EPOCH 3: training on 99524 raw words (60277 effective words) took 0.1s, 422923 effective words/s\n",
      "2023-12-06 14:30:46,057 : INFO : EPOCH 4: training on 99524 raw words (60456 effective words) took 0.1s, 441973 effective words/s\n",
      "2023-12-06 14:30:46,198 : INFO : EPOCH 5: training on 99524 raw words (60449 effective words) took 0.1s, 440269 effective words/s\n",
      "2023-12-06 14:30:46,338 : INFO : EPOCH 6: training on 99524 raw words (60275 effective words) took 0.1s, 447243 effective words/s\n",
      "2023-12-06 14:30:46,483 : INFO : EPOCH 7: training on 99524 raw words (60589 effective words) took 0.1s, 431823 effective words/s\n",
      "2023-12-06 14:30:46,623 : INFO : EPOCH 8: training on 99524 raw words (60310 effective words) took 0.1s, 444395 effective words/s\n",
      "2023-12-06 14:30:46,762 : INFO : EPOCH 9: training on 99524 raw words (60455 effective words) took 0.1s, 446107 effective words/s\n",
      "2023-12-06 14:30:46,909 : INFO : EPOCH 10: training on 99524 raw words (60378 effective words) took 0.1s, 426791 effective words/s\n",
      "2023-12-06 14:30:47,049 : INFO : EPOCH 11: training on 99524 raw words (60311 effective words) took 0.1s, 443894 effective words/s\n",
      "2023-12-06 14:30:47,189 : INFO : EPOCH 12: training on 99524 raw words (60497 effective words) took 0.1s, 446008 effective words/s\n",
      "2023-12-06 14:30:47,334 : INFO : EPOCH 13: training on 99524 raw words (60483 effective words) took 0.1s, 431656 effective words/s\n",
      "2023-12-06 14:30:47,474 : INFO : EPOCH 14: training on 99524 raw words (60402 effective words) took 0.1s, 444565 effective words/s\n",
      "2023-12-06 14:30:47,613 : INFO : EPOCH 15: training on 99524 raw words (60375 effective words) took 0.1s, 448522 effective words/s\n",
      "2023-12-06 14:30:47,759 : INFO : EPOCH 16: training on 99524 raw words (60494 effective words) took 0.1s, 425713 effective words/s\n",
      "2023-12-06 14:30:47,901 : INFO : EPOCH 17: training on 99524 raw words (60353 effective words) took 0.1s, 439644 effective words/s\n",
      "2023-12-06 14:30:48,040 : INFO : EPOCH 18: training on 99524 raw words (60270 effective words) took 0.1s, 448385 effective words/s\n",
      "2023-12-06 14:30:48,218 : INFO : EPOCH 19: training on 99524 raw words (60448 effective words) took 0.2s, 346460 effective words/s\n",
      "2023-12-06 14:30:48,371 : INFO : EPOCH 20: training on 99524 raw words (60350 effective words) took 0.1s, 409967 effective words/s\n",
      "2023-12-06 14:30:48,512 : INFO : EPOCH 21: training on 99524 raw words (60511 effective words) took 0.1s, 443441 effective words/s\n",
      "2023-12-06 14:30:48,659 : INFO : EPOCH 22: training on 99524 raw words (60485 effective words) took 0.1s, 428605 effective words/s\n",
      "2023-12-06 14:30:48,804 : INFO : EPOCH 23: training on 99524 raw words (60438 effective words) took 0.1s, 427668 effective words/s\n",
      "2023-12-06 14:30:48,949 : INFO : EPOCH 24: training on 99524 raw words (60348 effective words) took 0.1s, 430710 effective words/s\n",
      "2023-12-06 14:30:49,096 : INFO : EPOCH 25: training on 99524 raw words (60316 effective words) took 0.1s, 420882 effective words/s\n",
      "2023-12-06 14:30:49,237 : INFO : EPOCH 26: training on 99524 raw words (60542 effective words) took 0.1s, 443529 effective words/s\n",
      "2023-12-06 14:30:49,379 : INFO : EPOCH 27: training on 99524 raw words (60602 effective words) took 0.1s, 444591 effective words/s\n",
      "2023-12-06 14:30:49,528 : INFO : EPOCH 28: training on 99524 raw words (60463 effective words) took 0.1s, 417077 effective words/s\n",
      "2023-12-06 14:30:49,669 : INFO : EPOCH 29: training on 99524 raw words (60392 effective words) took 0.1s, 442964 effective words/s\n",
      "2023-12-06 14:30:49,817 : INFO : EPOCH 30: training on 99524 raw words (60335 effective words) took 0.1s, 421167 effective words/s\n",
      "2023-12-06 14:30:49,959 : INFO : EPOCH 31: training on 99524 raw words (60365 effective words) took 0.1s, 439426 effective words/s\n",
      "2023-12-06 14:30:50,099 : INFO : EPOCH 32: training on 99524 raw words (60571 effective words) took 0.1s, 445024 effective words/s\n",
      "2023-12-06 14:30:50,244 : INFO : EPOCH 33: training on 99524 raw words (60471 effective words) took 0.1s, 429327 effective words/s\n",
      "2023-12-06 14:30:50,385 : INFO : EPOCH 34: training on 99524 raw words (60432 effective words) took 0.1s, 443307 effective words/s\n",
      "2023-12-06 14:30:50,525 : INFO : EPOCH 35: training on 99524 raw words (60579 effective words) took 0.1s, 445992 effective words/s\n",
      "2023-12-06 14:30:50,670 : INFO : EPOCH 36: training on 99524 raw words (60375 effective words) took 0.1s, 429945 effective words/s\n",
      "2023-12-06 14:30:50,810 : INFO : EPOCH 37: training on 99524 raw words (60348 effective words) took 0.1s, 445290 effective words/s\n",
      "2023-12-06 14:30:50,963 : INFO : EPOCH 38: training on 99524 raw words (60209 effective words) took 0.1s, 405841 effective words/s\n",
      "2023-12-06 14:30:51,102 : INFO : EPOCH 39: training on 99524 raw words (60448 effective words) took 0.1s, 446325 effective words/s\n",
      "2023-12-06 14:30:51,245 : INFO : EPOCH 40: training on 99524 raw words (60372 effective words) took 0.1s, 435728 effective words/s\n",
      "2023-12-06 14:30:51,393 : INFO : EPOCH 41: training on 99524 raw words (60584 effective words) took 0.1s, 425808 effective words/s\n",
      "2023-12-06 14:30:51,533 : INFO : EPOCH 42: training on 99524 raw words (60455 effective words) took 0.1s, 441889 effective words/s\n",
      "2023-12-06 14:30:51,674 : INFO : EPOCH 43: training on 99524 raw words (60511 effective words) took 0.1s, 443344 effective words/s\n",
      "2023-12-06 14:30:51,819 : INFO : EPOCH 44: training on 99524 raw words (60338 effective words) took 0.1s, 435035 effective words/s\n",
      "2023-12-06 14:30:51,958 : INFO : EPOCH 45: training on 99524 raw words (60414 effective words) took 0.1s, 445554 effective words/s\n",
      "2023-12-06 14:30:52,106 : INFO : EPOCH 46: training on 99524 raw words (60379 effective words) took 0.1s, 422697 effective words/s\n",
      "2023-12-06 14:30:52,248 : INFO : EPOCH 47: training on 99524 raw words (60256 effective words) took 0.1s, 437896 effective words/s\n",
      "2023-12-06 14:30:52,387 : INFO : EPOCH 48: training on 99524 raw words (60337 effective words) took 0.1s, 446867 effective words/s\n",
      "2023-12-06 14:30:52,533 : INFO : EPOCH 49: training on 99524 raw words (60341 effective words) took 0.1s, 424973 effective words/s\n",
      "2023-12-06 14:30:52,534 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3020692 effective words) took 7.2s, 419039 effective words/s', 'datetime': '2023-12-06T14:30:52.534453', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:30:52,535 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:30:52.535453', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 22%|       | 108/486 [17:14<58:55,  9.35s/it]2023-12-06 14:30:56,170 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:30:56,170 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:30:56,190 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:30:56,190 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:30:56,195 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:30:56.195900', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:30:56,196 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:30:56.196900', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:30:56,205 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:30:56,207 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:30:56,207 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:30:56.207900', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:30:56,217 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:30:56,218 : INFO : resetting layer weights\n",
      "2023-12-06 14:30:56,220 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:30:56.220693', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:30:56,379 : INFO : EPOCH 0: training on 99524 raw words (65427 effective words) took 0.2s, 422430 effective words/s\n",
      "2023-12-06 14:30:56,524 : INFO : EPOCH 1: training on 99524 raw words (65711 effective words) took 0.1s, 467674 effective words/s\n",
      "2023-12-06 14:30:56,672 : INFO : EPOCH 2: training on 99524 raw words (65548 effective words) took 0.1s, 457586 effective words/s\n",
      "2023-12-06 14:30:56,823 : INFO : EPOCH 3: training on 99524 raw words (65498 effective words) took 0.1s, 451428 effective words/s\n",
      "2023-12-06 14:30:56,964 : INFO : EPOCH 4: training on 99524 raw words (65420 effective words) took 0.1s, 475563 effective words/s\n",
      "2023-12-06 14:30:57,105 : INFO : EPOCH 5: training on 99524 raw words (65451 effective words) took 0.1s, 480772 effective words/s\n",
      "2023-12-06 14:30:57,251 : INFO : EPOCH 6: training on 99524 raw words (65540 effective words) took 0.1s, 464352 effective words/s\n",
      "2023-12-06 14:30:57,400 : INFO : EPOCH 7: training on 99524 raw words (65539 effective words) took 0.1s, 453483 effective words/s\n",
      "2023-12-06 14:30:57,542 : INFO : EPOCH 8: training on 99524 raw words (65515 effective words) took 0.1s, 471200 effective words/s\n",
      "2023-12-06 14:30:57,686 : INFO : EPOCH 9: training on 99524 raw words (65450 effective words) took 0.1s, 470219 effective words/s\n",
      "2023-12-06 14:30:57,687 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655099 effective words) took 1.5s, 446684 effective words/s', 'datetime': '2023-12-06T14:30:57.687771', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:30:57,688 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:30:57.688771', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 22%|       | 109/486 [17:18<48:53,  7.78s/it]2023-12-06 14:31:00,284 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:31:00,284 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:31:00,304 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:31:00,305 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:31:00,313 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:31:00.313959', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:31:00,313 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:31:00.313959', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:31:00,323 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:31:00,325 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:31:00,325 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:31:00.325960', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:31:00,341 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:31:00,342 : INFO : resetting layer weights\n",
      "2023-12-06 14:31:00,344 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:31:00.344967', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:31:00,496 : INFO : EPOCH 0: training on 99524 raw words (65514 effective words) took 0.1s, 443434 effective words/s\n",
      "2023-12-06 14:31:00,648 : INFO : EPOCH 1: training on 99524 raw words (65707 effective words) took 0.1s, 447128 effective words/s\n",
      "2023-12-06 14:31:00,792 : INFO : EPOCH 2: training on 99524 raw words (65568 effective words) took 0.1s, 469297 effective words/s\n",
      "2023-12-06 14:31:00,944 : INFO : EPOCH 3: training on 99524 raw words (65530 effective words) took 0.1s, 443304 effective words/s\n",
      "2023-12-06 14:31:01,089 : INFO : EPOCH 4: training on 99524 raw words (65577 effective words) took 0.1s, 467357 effective words/s\n",
      "2023-12-06 14:31:01,232 : INFO : EPOCH 5: training on 99524 raw words (65462 effective words) took 0.1s, 471012 effective words/s\n",
      "2023-12-06 14:31:01,380 : INFO : EPOCH 6: training on 99524 raw words (65560 effective words) took 0.1s, 459598 effective words/s\n",
      "2023-12-06 14:31:01,523 : INFO : EPOCH 7: training on 99524 raw words (65576 effective words) took 0.1s, 472215 effective words/s\n",
      "2023-12-06 14:31:01,667 : INFO : EPOCH 8: training on 99524 raw words (65518 effective words) took 0.1s, 468272 effective words/s\n",
      "2023-12-06 14:31:01,815 : INFO : EPOCH 9: training on 99524 raw words (65490 effective words) took 0.1s, 455356 effective words/s\n",
      "2023-12-06 14:31:01,816 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655502 effective words) took 1.5s, 445663 effective words/s', 'datetime': '2023-12-06T14:31:01.816589', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:31:01,816 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:31:01.816589', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 23%|       | 110/486 [17:23<41:51,  6.68s/it]2023-12-06 14:31:04,396 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:31:04,397 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:31:04,417 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:31:04,418 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:31:04,426 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:31:04.426599', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:31:04,427 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:31:04.427600', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:31:04,434 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:31:04,434 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:31:04,434 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:31:04.434598', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:31:04,445 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:31:04,446 : INFO : resetting layer weights\n",
      "2023-12-06 14:31:04,448 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:31:04.448599', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:31:04,607 : INFO : EPOCH 0: training on 99524 raw words (65579 effective words) took 0.2s, 423112 effective words/s\n",
      "2023-12-06 14:31:04,749 : INFO : EPOCH 1: training on 99524 raw words (65655 effective words) took 0.1s, 478167 effective words/s\n",
      "2023-12-06 14:31:04,889 : INFO : EPOCH 2: training on 99524 raw words (65604 effective words) took 0.1s, 484836 effective words/s\n",
      "2023-12-06 14:31:05,036 : INFO : EPOCH 3: training on 99524 raw words (65557 effective words) took 0.1s, 459882 effective words/s\n",
      "2023-12-06 14:31:05,175 : INFO : EPOCH 4: training on 99524 raw words (65606 effective words) took 0.1s, 486347 effective words/s\n",
      "2023-12-06 14:31:05,316 : INFO : EPOCH 5: training on 99524 raw words (65447 effective words) took 0.1s, 480490 effective words/s\n",
      "2023-12-06 14:31:05,458 : INFO : EPOCH 6: training on 99524 raw words (65521 effective words) took 0.1s, 474751 effective words/s\n",
      "2023-12-06 14:31:05,607 : INFO : EPOCH 7: training on 99524 raw words (65637 effective words) took 0.1s, 453435 effective words/s\n",
      "2023-12-06 14:31:05,750 : INFO : EPOCH 8: training on 99524 raw words (65668 effective words) took 0.1s, 474295 effective words/s\n",
      "2023-12-06 14:31:05,891 : INFO : EPOCH 9: training on 99524 raw words (65535 effective words) took 0.1s, 483018 effective words/s\n",
      "2023-12-06 14:31:05,892 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655809 effective words) took 1.4s, 454514 effective words/s', 'datetime': '2023-12-06T14:31:05.892400', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:31:05,893 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:31:05.893400', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 23%|       | 111/486 [17:27<36:57,  5.91s/it]2023-12-06 14:31:08,520 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:31:08,520 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:31:08,540 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:31:08,541 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:31:08,548 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:31:08.548046', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:31:08,549 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:31:08.549046', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:31:08,555 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:31:08,556 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:31:08,556 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:31:08.556860', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:31:08,572 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:31:08,573 : INFO : resetting layer weights\n",
      "2023-12-06 14:31:08,575 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:31:08.575388', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:31:08,732 : INFO : EPOCH 0: training on 99524 raw words (65465 effective words) took 0.2s, 426016 effective words/s\n",
      "2023-12-06 14:31:08,874 : INFO : EPOCH 1: training on 99524 raw words (65556 effective words) took 0.1s, 475043 effective words/s\n",
      "2023-12-06 14:31:09,017 : INFO : EPOCH 2: training on 99524 raw words (65633 effective words) took 0.1s, 475531 effective words/s\n",
      "2023-12-06 14:31:09,165 : INFO : EPOCH 3: training on 99524 raw words (65425 effective words) took 0.1s, 453351 effective words/s\n",
      "2023-12-06 14:31:09,307 : INFO : EPOCH 4: training on 99524 raw words (65442 effective words) took 0.1s, 476270 effective words/s\n",
      "2023-12-06 14:31:09,449 : INFO : EPOCH 5: training on 99524 raw words (65458 effective words) took 0.1s, 475934 effective words/s\n",
      "2023-12-06 14:31:09,595 : INFO : EPOCH 6: training on 99524 raw words (65678 effective words) took 0.1s, 462488 effective words/s\n",
      "2023-12-06 14:31:09,742 : INFO : EPOCH 7: training on 99524 raw words (65583 effective words) took 0.1s, 460775 effective words/s\n",
      "2023-12-06 14:31:09,885 : INFO : EPOCH 8: training on 99524 raw words (65435 effective words) took 0.1s, 473559 effective words/s\n",
      "2023-12-06 14:31:10,026 : INFO : EPOCH 9: training on 99524 raw words (65465 effective words) took 0.1s, 477587 effective words/s\n",
      "2023-12-06 14:31:10,172 : INFO : EPOCH 10: training on 99524 raw words (65480 effective words) took 0.1s, 464812 effective words/s\n",
      "2023-12-06 14:31:10,314 : INFO : EPOCH 11: training on 99524 raw words (65583 effective words) took 0.1s, 475696 effective words/s\n",
      "2023-12-06 14:31:10,465 : INFO : EPOCH 12: training on 99524 raw words (65558 effective words) took 0.1s, 449103 effective words/s\n",
      "2023-12-06 14:31:10,608 : INFO : EPOCH 13: training on 99524 raw words (65626 effective words) took 0.1s, 473328 effective words/s\n",
      "2023-12-06 14:31:10,751 : INFO : EPOCH 14: training on 99524 raw words (65689 effective words) took 0.1s, 474924 effective words/s\n",
      "2023-12-06 14:31:10,898 : INFO : EPOCH 15: training on 99524 raw words (65532 effective words) took 0.1s, 457194 effective words/s\n",
      "2023-12-06 14:31:11,042 : INFO : EPOCH 16: training on 99524 raw words (65591 effective words) took 0.1s, 472976 effective words/s\n",
      "2023-12-06 14:31:11,198 : INFO : EPOCH 17: training on 99524 raw words (65570 effective words) took 0.2s, 431790 effective words/s\n",
      "2023-12-06 14:31:11,341 : INFO : EPOCH 18: training on 99524 raw words (65305 effective words) took 0.1s, 471874 effective words/s\n",
      "2023-12-06 14:31:11,482 : INFO : EPOCH 19: training on 99524 raw words (65648 effective words) took 0.1s, 477360 effective words/s\n",
      "2023-12-06 14:31:11,631 : INFO : EPOCH 20: training on 99524 raw words (65497 effective words) took 0.1s, 455865 effective words/s\n",
      "2023-12-06 14:31:11,773 : INFO : EPOCH 21: training on 99524 raw words (65577 effective words) took 0.1s, 475439 effective words/s\n",
      "2023-12-06 14:31:11,912 : INFO : EPOCH 22: training on 99524 raw words (65532 effective words) took 0.1s, 486783 effective words/s\n",
      "2023-12-06 14:31:12,061 : INFO : EPOCH 23: training on 99524 raw words (65626 effective words) took 0.1s, 456696 effective words/s\n",
      "2023-12-06 14:31:12,202 : INFO : EPOCH 24: training on 99524 raw words (65560 effective words) took 0.1s, 477282 effective words/s\n",
      "2023-12-06 14:31:12,345 : INFO : EPOCH 25: training on 99524 raw words (65461 effective words) took 0.1s, 472250 effective words/s\n",
      "2023-12-06 14:31:12,487 : INFO : EPOCH 26: training on 99524 raw words (65676 effective words) took 0.1s, 477922 effective words/s\n",
      "2023-12-06 14:31:12,635 : INFO : EPOCH 27: training on 99524 raw words (65673 effective words) took 0.1s, 457251 effective words/s\n",
      "2023-12-06 14:31:12,776 : INFO : EPOCH 28: training on 99524 raw words (65641 effective words) took 0.1s, 481063 effective words/s\n",
      "2023-12-06 14:31:12,926 : INFO : EPOCH 29: training on 99524 raw words (65508 effective words) took 0.1s, 452990 effective words/s\n",
      "2023-12-06 14:31:12,927 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1966473 effective words) took 4.4s, 451944 effective words/s', 'datetime': '2023-12-06T14:31:12.927065', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:31:12,927 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:31:12.927065', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 23%|       | 112/486 [17:34<39:18,  6.31s/it]2023-12-06 14:31:15,739 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:31:15,740 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:31:15,760 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:31:15,761 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:31:15,766 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:31:15.766284', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:31:15,766 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:31:15.766284', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:31:15,773 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:31:15,773 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:31:15,774 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:31:15.774974', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:31:15,785 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:31:15,785 : INFO : resetting layer weights\n",
      "2023-12-06 14:31:15,787 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:31:15.787799', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:31:15,948 : INFO : EPOCH 0: training on 99524 raw words (65573 effective words) took 0.2s, 421590 effective words/s\n",
      "2023-12-06 14:31:16,091 : INFO : EPOCH 1: training on 99524 raw words (65556 effective words) took 0.1s, 473217 effective words/s\n",
      "2023-12-06 14:31:16,234 : INFO : EPOCH 2: training on 99524 raw words (65449 effective words) took 0.1s, 468952 effective words/s\n",
      "2023-12-06 14:31:16,384 : INFO : EPOCH 3: training on 99524 raw words (65559 effective words) took 0.1s, 450157 effective words/s\n",
      "2023-12-06 14:31:16,528 : INFO : EPOCH 4: training on 99524 raw words (65571 effective words) took 0.1s, 472321 effective words/s\n",
      "2023-12-06 14:31:16,672 : INFO : EPOCH 5: training on 99524 raw words (65407 effective words) took 0.1s, 472350 effective words/s\n",
      "2023-12-06 14:31:16,820 : INFO : EPOCH 6: training on 99524 raw words (65286 effective words) took 0.1s, 454659 effective words/s\n",
      "2023-12-06 14:31:16,968 : INFO : EPOCH 7: training on 99524 raw words (65525 effective words) took 0.1s, 458239 effective words/s\n",
      "2023-12-06 14:31:17,110 : INFO : EPOCH 8: training on 99524 raw words (65719 effective words) took 0.1s, 474622 effective words/s\n",
      "2023-12-06 14:31:17,259 : INFO : EPOCH 9: training on 99524 raw words (65554 effective words) took 0.1s, 455305 effective words/s\n",
      "2023-12-06 14:31:17,402 : INFO : EPOCH 10: training on 99524 raw words (65397 effective words) took 0.1s, 472138 effective words/s\n",
      "2023-12-06 14:31:17,544 : INFO : EPOCH 11: training on 99524 raw words (65597 effective words) took 0.1s, 477423 effective words/s\n",
      "2023-12-06 14:31:17,693 : INFO : EPOCH 12: training on 99524 raw words (65434 effective words) took 0.1s, 454424 effective words/s\n",
      "2023-12-06 14:31:17,835 : INFO : EPOCH 13: training on 99524 raw words (65495 effective words) took 0.1s, 473475 effective words/s\n",
      "2023-12-06 14:31:17,979 : INFO : EPOCH 14: training on 99524 raw words (65632 effective words) took 0.1s, 471103 effective words/s\n",
      "2023-12-06 14:31:18,136 : INFO : EPOCH 15: training on 99524 raw words (65606 effective words) took 0.2s, 433458 effective words/s\n",
      "2023-12-06 14:31:18,278 : INFO : EPOCH 16: training on 99524 raw words (65582 effective words) took 0.1s, 474349 effective words/s\n",
      "2023-12-06 14:31:18,427 : INFO : EPOCH 17: training on 99524 raw words (65554 effective words) took 0.1s, 454728 effective words/s\n",
      "2023-12-06 14:31:18,572 : INFO : EPOCH 18: training on 99524 raw words (65594 effective words) took 0.1s, 465036 effective words/s\n",
      "2023-12-06 14:31:18,714 : INFO : EPOCH 19: training on 99524 raw words (65678 effective words) took 0.1s, 477961 effective words/s\n",
      "2023-12-06 14:31:18,864 : INFO : EPOCH 20: training on 99524 raw words (65393 effective words) took 0.1s, 450332 effective words/s\n",
      "2023-12-06 14:31:19,007 : INFO : EPOCH 21: training on 99524 raw words (65415 effective words) took 0.1s, 470116 effective words/s\n",
      "2023-12-06 14:31:19,148 : INFO : EPOCH 22: training on 99524 raw words (65548 effective words) took 0.1s, 479695 effective words/s\n",
      "2023-12-06 14:31:19,298 : INFO : EPOCH 23: training on 99524 raw words (65570 effective words) took 0.1s, 450734 effective words/s\n",
      "2023-12-06 14:31:19,441 : INFO : EPOCH 24: training on 99524 raw words (65566 effective words) took 0.1s, 471894 effective words/s\n",
      "2023-12-06 14:31:19,582 : INFO : EPOCH 25: training on 99524 raw words (65436 effective words) took 0.1s, 478217 effective words/s\n",
      "2023-12-06 14:31:19,734 : INFO : EPOCH 26: training on 99524 raw words (65792 effective words) took 0.1s, 452458 effective words/s\n",
      "2023-12-06 14:31:19,877 : INFO : EPOCH 27: training on 99524 raw words (65676 effective words) took 0.1s, 473670 effective words/s\n",
      "2023-12-06 14:31:20,026 : INFO : EPOCH 28: training on 99524 raw words (65582 effective words) took 0.1s, 452546 effective words/s\n",
      "2023-12-06 14:31:20,173 : INFO : EPOCH 29: training on 99524 raw words (65686 effective words) took 0.1s, 459849 effective words/s\n",
      "2023-12-06 14:31:20,174 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1966432 effective words) took 4.4s, 448320 effective words/s', 'datetime': '2023-12-06T14:31:20.174419', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:31:20,175 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:31:20.175423', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 23%|       | 113/486 [17:41<41:11,  6.63s/it]2023-12-06 14:31:23,112 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:31:23,113 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:31:23,132 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:31:23,133 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:31:23,140 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:31:23.140858', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:31:23,141 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:31:23.141858', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:31:23,151 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:31:23,152 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:31:23,152 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:31:23.152825', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:31:23,163 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:31:23,163 : INFO : resetting layer weights\n",
      "2023-12-06 14:31:23,165 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:31:23.165824', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:31:23,325 : INFO : EPOCH 0: training on 99524 raw words (65593 effective words) took 0.2s, 420904 effective words/s\n",
      "2023-12-06 14:31:23,465 : INFO : EPOCH 1: training on 99524 raw words (65583 effective words) took 0.1s, 483164 effective words/s\n",
      "2023-12-06 14:31:23,612 : INFO : EPOCH 2: training on 99524 raw words (65649 effective words) took 0.1s, 461521 effective words/s\n",
      "2023-12-06 14:31:23,753 : INFO : EPOCH 3: training on 99524 raw words (65574 effective words) took 0.1s, 480522 effective words/s\n",
      "2023-12-06 14:31:23,893 : INFO : EPOCH 4: training on 99524 raw words (65466 effective words) took 0.1s, 484466 effective words/s\n",
      "2023-12-06 14:31:24,038 : INFO : EPOCH 5: training on 99524 raw words (65518 effective words) took 0.1s, 462349 effective words/s\n",
      "2023-12-06 14:31:24,178 : INFO : EPOCH 6: training on 99524 raw words (65455 effective words) took 0.1s, 482895 effective words/s\n",
      "2023-12-06 14:31:24,323 : INFO : EPOCH 7: training on 99524 raw words (65640 effective words) took 0.1s, 466290 effective words/s\n",
      "2023-12-06 14:31:24,470 : INFO : EPOCH 8: training on 99524 raw words (65547 effective words) took 0.1s, 463183 effective words/s\n",
      "2023-12-06 14:31:24,612 : INFO : EPOCH 9: training on 99524 raw words (65441 effective words) took 0.1s, 478208 effective words/s\n",
      "2023-12-06 14:31:24,752 : INFO : EPOCH 10: training on 99524 raw words (65556 effective words) took 0.1s, 479254 effective words/s\n",
      "2023-12-06 14:31:24,900 : INFO : EPOCH 11: training on 99524 raw words (65578 effective words) took 0.1s, 460093 effective words/s\n",
      "2023-12-06 14:31:25,040 : INFO : EPOCH 12: training on 99524 raw words (65483 effective words) took 0.1s, 483318 effective words/s\n",
      "2023-12-06 14:31:25,180 : INFO : EPOCH 13: training on 99524 raw words (65470 effective words) took 0.1s, 483916 effective words/s\n",
      "2023-12-06 14:31:25,326 : INFO : EPOCH 14: training on 99524 raw words (65417 effective words) took 0.1s, 464610 effective words/s\n",
      "2023-12-06 14:31:25,466 : INFO : EPOCH 15: training on 99524 raw words (65558 effective words) took 0.1s, 479150 effective words/s\n",
      "2023-12-06 14:31:25,607 : INFO : EPOCH 16: training on 99524 raw words (65492 effective words) took 0.1s, 482826 effective words/s\n",
      "2023-12-06 14:31:25,765 : INFO : EPOCH 17: training on 99524 raw words (65436 effective words) took 0.2s, 424610 effective words/s\n",
      "2023-12-06 14:31:25,908 : INFO : EPOCH 18: training on 99524 raw words (65485 effective words) took 0.1s, 473163 effective words/s\n",
      "2023-12-06 14:31:26,048 : INFO : EPOCH 19: training on 99524 raw words (65462 effective words) took 0.1s, 484524 effective words/s\n",
      "2023-12-06 14:31:26,192 : INFO : EPOCH 20: training on 99524 raw words (65570 effective words) took 0.1s, 468830 effective words/s\n",
      "2023-12-06 14:31:26,333 : INFO : EPOCH 21: training on 99524 raw words (65528 effective words) took 0.1s, 480259 effective words/s\n",
      "2023-12-06 14:31:26,493 : INFO : EPOCH 22: training on 99524 raw words (65503 effective words) took 0.2s, 418508 effective words/s\n",
      "2023-12-06 14:31:26,645 : INFO : EPOCH 23: training on 99524 raw words (65520 effective words) took 0.1s, 451376 effective words/s\n",
      "2023-12-06 14:31:26,789 : INFO : EPOCH 24: training on 99524 raw words (65580 effective words) took 0.1s, 472104 effective words/s\n",
      "2023-12-06 14:31:26,936 : INFO : EPOCH 25: training on 99524 raw words (65470 effective words) took 0.1s, 456475 effective words/s\n",
      "2023-12-06 14:31:27,077 : INFO : EPOCH 26: training on 99524 raw words (65633 effective words) took 0.1s, 483131 effective words/s\n",
      "2023-12-06 14:31:27,217 : INFO : EPOCH 27: training on 99524 raw words (65698 effective words) took 0.1s, 484084 effective words/s\n",
      "2023-12-06 14:31:27,362 : INFO : EPOCH 28: training on 99524 raw words (65492 effective words) took 0.1s, 465292 effective words/s\n",
      "2023-12-06 14:31:27,508 : INFO : EPOCH 29: training on 99524 raw words (65599 effective words) took 0.1s, 465364 effective words/s\n",
      "2023-12-06 14:31:27,509 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965996 effective words) took 4.3s, 452666 effective words/s', 'datetime': '2023-12-06T14:31:27.509252', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:31:27,509 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:31:27.509252', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 23%|       | 114/486 [17:49<42:43,  6.89s/it]2023-12-06 14:31:30,627 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:31:30,628 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:31:30,649 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:31:30,650 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:31:30,655 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:31:30.655073', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:31:30,656 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:31:30.656075', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:31:30,662 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:31:30,663 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:31:30,663 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:31:30.663057', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:31:30,673 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:31:30,674 : INFO : resetting layer weights\n",
      "2023-12-06 14:31:30,676 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:31:30.676467', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:31:30,834 : INFO : EPOCH 0: training on 99524 raw words (65532 effective words) took 0.2s, 425938 effective words/s\n",
      "2023-12-06 14:31:30,977 : INFO : EPOCH 1: training on 99524 raw words (65425 effective words) took 0.1s, 471456 effective words/s\n",
      "2023-12-06 14:31:31,121 : INFO : EPOCH 2: training on 99524 raw words (65634 effective words) took 0.1s, 472647 effective words/s\n",
      "2023-12-06 14:31:31,268 : INFO : EPOCH 3: training on 99524 raw words (65440 effective words) took 0.1s, 457075 effective words/s\n",
      "2023-12-06 14:31:31,411 : INFO : EPOCH 4: training on 99524 raw words (65434 effective words) took 0.1s, 472357 effective words/s\n",
      "2023-12-06 14:31:31,553 : INFO : EPOCH 5: training on 99524 raw words (65547 effective words) took 0.1s, 479164 effective words/s\n",
      "2023-12-06 14:31:31,701 : INFO : EPOCH 6: training on 99524 raw words (65478 effective words) took 0.1s, 455218 effective words/s\n",
      "2023-12-06 14:31:31,846 : INFO : EPOCH 7: training on 99524 raw words (65495 effective words) took 0.1s, 462437 effective words/s\n",
      "2023-12-06 14:31:31,989 : INFO : EPOCH 8: training on 99524 raw words (65606 effective words) took 0.1s, 476782 effective words/s\n",
      "2023-12-06 14:31:32,136 : INFO : EPOCH 9: training on 99524 raw words (65450 effective words) took 0.1s, 457824 effective words/s\n",
      "2023-12-06 14:31:32,279 : INFO : EPOCH 10: training on 99524 raw words (65468 effective words) took 0.1s, 471095 effective words/s\n",
      "2023-12-06 14:31:32,419 : INFO : EPOCH 11: training on 99524 raw words (65550 effective words) took 0.1s, 479712 effective words/s\n",
      "2023-12-06 14:31:32,568 : INFO : EPOCH 12: training on 99524 raw words (65595 effective words) took 0.1s, 456331 effective words/s\n",
      "2023-12-06 14:31:32,719 : INFO : EPOCH 13: training on 99524 raw words (65517 effective words) took 0.1s, 447233 effective words/s\n",
      "2023-12-06 14:31:32,870 : INFO : EPOCH 14: training on 99524 raw words (65584 effective words) took 0.1s, 449188 effective words/s\n",
      "2023-12-06 14:31:33,020 : INFO : EPOCH 15: training on 99524 raw words (65668 effective words) took 0.1s, 455485 effective words/s\n",
      "2023-12-06 14:31:33,160 : INFO : EPOCH 16: training on 99524 raw words (65526 effective words) took 0.1s, 481665 effective words/s\n",
      "2023-12-06 14:31:33,308 : INFO : EPOCH 17: training on 99524 raw words (65437 effective words) took 0.1s, 454420 effective words/s\n",
      "2023-12-06 14:31:33,452 : INFO : EPOCH 18: training on 99524 raw words (65451 effective words) took 0.1s, 469436 effective words/s\n",
      "2023-12-06 14:31:33,602 : INFO : EPOCH 19: training on 99524 raw words (65624 effective words) took 0.1s, 452361 effective words/s\n",
      "2023-12-06 14:31:33,755 : INFO : EPOCH 20: training on 99524 raw words (65539 effective words) took 0.1s, 440808 effective words/s\n",
      "2023-12-06 14:31:33,897 : INFO : EPOCH 21: training on 99524 raw words (65546 effective words) took 0.1s, 475619 effective words/s\n",
      "2023-12-06 14:31:34,046 : INFO : EPOCH 22: training on 99524 raw words (65482 effective words) took 0.1s, 455226 effective words/s\n",
      "2023-12-06 14:31:34,192 : INFO : EPOCH 23: training on 99524 raw words (65660 effective words) took 0.1s, 460025 effective words/s\n",
      "2023-12-06 14:31:34,339 : INFO : EPOCH 24: training on 99524 raw words (65725 effective words) took 0.1s, 459710 effective words/s\n",
      "2023-12-06 14:31:34,484 : INFO : EPOCH 25: training on 99524 raw words (65477 effective words) took 0.1s, 467676 effective words/s\n",
      "2023-12-06 14:31:34,627 : INFO : EPOCH 26: training on 99524 raw words (65606 effective words) took 0.1s, 473212 effective words/s\n",
      "2023-12-06 14:31:34,776 : INFO : EPOCH 27: training on 99524 raw words (65514 effective words) took 0.1s, 453906 effective words/s\n",
      "2023-12-06 14:31:34,917 : INFO : EPOCH 28: training on 99524 raw words (65523 effective words) took 0.1s, 479463 effective words/s\n",
      "2023-12-06 14:31:35,060 : INFO : EPOCH 29: training on 99524 raw words (65639 effective words) took 0.1s, 475534 effective words/s\n",
      "2023-12-06 14:31:35,208 : INFO : EPOCH 30: training on 99524 raw words (65386 effective words) took 0.1s, 454071 effective words/s\n",
      "2023-12-06 14:31:35,352 : INFO : EPOCH 31: training on 99524 raw words (65687 effective words) took 0.1s, 468702 effective words/s\n",
      "2023-12-06 14:31:35,495 : INFO : EPOCH 32: training on 99524 raw words (65545 effective words) took 0.1s, 472882 effective words/s\n",
      "2023-12-06 14:31:35,641 : INFO : EPOCH 33: training on 99524 raw words (65681 effective words) took 0.1s, 463448 effective words/s\n",
      "2023-12-06 14:31:35,782 : INFO : EPOCH 34: training on 99524 raw words (65612 effective words) took 0.1s, 480320 effective words/s\n",
      "2023-12-06 14:31:35,922 : INFO : EPOCH 35: training on 99524 raw words (65756 effective words) took 0.1s, 482675 effective words/s\n",
      "2023-12-06 14:31:36,070 : INFO : EPOCH 36: training on 99524 raw words (65305 effective words) took 0.1s, 456262 effective words/s\n",
      "2023-12-06 14:31:36,211 : INFO : EPOCH 37: training on 99524 raw words (65467 effective words) took 0.1s, 481155 effective words/s\n",
      "2023-12-06 14:31:36,353 : INFO : EPOCH 38: training on 99524 raw words (65449 effective words) took 0.1s, 474209 effective words/s\n",
      "2023-12-06 14:31:36,501 : INFO : EPOCH 39: training on 99524 raw words (65394 effective words) took 0.1s, 456517 effective words/s\n",
      "2023-12-06 14:31:36,652 : INFO : EPOCH 40: training on 99524 raw words (65412 effective words) took 0.1s, 444608 effective words/s\n",
      "2023-12-06 14:31:36,797 : INFO : EPOCH 41: training on 99524 raw words (65589 effective words) took 0.1s, 468276 effective words/s\n",
      "2023-12-06 14:31:36,945 : INFO : EPOCH 42: training on 99524 raw words (65589 effective words) took 0.1s, 455816 effective words/s\n",
      "2023-12-06 14:31:37,092 : INFO : EPOCH 43: training on 99524 raw words (65618 effective words) took 0.1s, 460996 effective words/s\n",
      "2023-12-06 14:31:37,236 : INFO : EPOCH 44: training on 99524 raw words (65589 effective words) took 0.1s, 470350 effective words/s\n",
      "2023-12-06 14:31:37,384 : INFO : EPOCH 45: training on 99524 raw words (65515 effective words) took 0.1s, 453415 effective words/s\n",
      "2023-12-06 14:31:37,528 : INFO : EPOCH 46: training on 99524 raw words (65400 effective words) took 0.1s, 471117 effective words/s\n",
      "2023-12-06 14:31:37,669 : INFO : EPOCH 47: training on 99524 raw words (65472 effective words) took 0.1s, 479598 effective words/s\n",
      "2023-12-06 14:31:37,816 : INFO : EPOCH 48: training on 99524 raw words (65555 effective words) took 0.1s, 457378 effective words/s\n",
      "2023-12-06 14:31:37,960 : INFO : EPOCH 49: training on 99524 raw words (65513 effective words) took 0.1s, 474738 effective words/s\n",
      "2023-12-06 14:31:37,961 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276706 effective words) took 7.3s, 449796 effective words/s', 'datetime': '2023-12-06T14:31:37.961610', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:31:37,961 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:31:37.961610', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 24%|       | 115/486 [17:59<49:11,  7.96s/it]2023-12-06 14:31:41,069 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:31:41,070 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:31:41,101 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:31:41,102 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:31:41,109 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:31:41.109916', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:31:41,110 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:31:41.110916', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:31:41,118 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:31:41,119 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:31:41,119 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:31:41.119020', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:31:41,135 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:31:41,136 : INFO : resetting layer weights\n",
      "2023-12-06 14:31:41,137 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:31:41.137946', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:31:41,298 : INFO : EPOCH 0: training on 99524 raw words (65556 effective words) took 0.2s, 417590 effective words/s\n",
      "2023-12-06 14:31:41,442 : INFO : EPOCH 1: training on 99524 raw words (65540 effective words) took 0.1s, 467989 effective words/s\n",
      "2023-12-06 14:31:41,585 : INFO : EPOCH 2: training on 99524 raw words (65694 effective words) took 0.1s, 477446 effective words/s\n",
      "2023-12-06 14:31:41,736 : INFO : EPOCH 3: training on 99524 raw words (65439 effective words) took 0.1s, 446065 effective words/s\n",
      "2023-12-06 14:31:41,878 : INFO : EPOCH 4: training on 99524 raw words (65641 effective words) took 0.1s, 475134 effective words/s\n",
      "2023-12-06 14:31:42,026 : INFO : EPOCH 5: training on 99524 raw words (65406 effective words) took 0.1s, 455784 effective words/s\n",
      "2023-12-06 14:31:42,169 : INFO : EPOCH 6: training on 99524 raw words (65545 effective words) took 0.1s, 474446 effective words/s\n",
      "2023-12-06 14:31:42,310 : INFO : EPOCH 7: training on 99524 raw words (65520 effective words) took 0.1s, 475619 effective words/s\n",
      "2023-12-06 14:31:42,462 : INFO : EPOCH 8: training on 99524 raw words (65464 effective words) took 0.1s, 445045 effective words/s\n",
      "2023-12-06 14:31:42,605 : INFO : EPOCH 9: training on 99524 raw words (65421 effective words) took 0.1s, 469922 effective words/s\n",
      "2023-12-06 14:31:42,748 : INFO : EPOCH 10: training on 99524 raw words (65534 effective words) took 0.1s, 474707 effective words/s\n",
      "2023-12-06 14:31:42,895 : INFO : EPOCH 11: training on 99524 raw words (65577 effective words) took 0.1s, 459736 effective words/s\n",
      "2023-12-06 14:31:43,040 : INFO : EPOCH 12: training on 99524 raw words (65494 effective words) took 0.1s, 464989 effective words/s\n",
      "2023-12-06 14:31:43,182 : INFO : EPOCH 13: training on 99524 raw words (65540 effective words) took 0.1s, 477964 effective words/s\n",
      "2023-12-06 14:31:43,331 : INFO : EPOCH 14: training on 99524 raw words (65454 effective words) took 0.1s, 452131 effective words/s\n",
      "2023-12-06 14:31:43,476 : INFO : EPOCH 15: training on 99524 raw words (65547 effective words) took 0.1s, 470463 effective words/s\n",
      "2023-12-06 14:31:43,618 : INFO : EPOCH 16: training on 99524 raw words (65537 effective words) took 0.1s, 474540 effective words/s\n",
      "2023-12-06 14:31:43,773 : INFO : EPOCH 17: training on 99524 raw words (65386 effective words) took 0.2s, 433696 effective words/s\n",
      "2023-12-06 14:31:43,917 : INFO : EPOCH 18: training on 99524 raw words (65398 effective words) took 0.1s, 467849 effective words/s\n",
      "2023-12-06 14:31:44,059 : INFO : EPOCH 19: training on 99524 raw words (65647 effective words) took 0.1s, 476914 effective words/s\n",
      "2023-12-06 14:31:44,208 : INFO : EPOCH 20: training on 99524 raw words (65610 effective words) took 0.1s, 454286 effective words/s\n",
      "2023-12-06 14:31:44,353 : INFO : EPOCH 21: training on 99524 raw words (65528 effective words) took 0.1s, 468064 effective words/s\n",
      "2023-12-06 14:31:44,495 : INFO : EPOCH 22: training on 99524 raw words (65693 effective words) took 0.1s, 475792 effective words/s\n",
      "2023-12-06 14:31:44,644 : INFO : EPOCH 23: training on 99524 raw words (65573 effective words) took 0.1s, 453826 effective words/s\n",
      "2023-12-06 14:31:44,788 : INFO : EPOCH 24: training on 99524 raw words (65601 effective words) took 0.1s, 467282 effective words/s\n",
      "2023-12-06 14:31:44,931 : INFO : EPOCH 25: training on 99524 raw words (65376 effective words) took 0.1s, 473045 effective words/s\n",
      "2023-12-06 14:31:45,085 : INFO : EPOCH 26: training on 99524 raw words (65684 effective words) took 0.1s, 439505 effective words/s\n",
      "2023-12-06 14:31:45,228 : INFO : EPOCH 27: training on 99524 raw words (65650 effective words) took 0.1s, 473264 effective words/s\n",
      "2023-12-06 14:31:45,373 : INFO : EPOCH 28: training on 99524 raw words (65518 effective words) took 0.1s, 467493 effective words/s\n",
      "2023-12-06 14:31:45,525 : INFO : EPOCH 29: training on 99524 raw words (65684 effective words) took 0.1s, 448666 effective words/s\n",
      "2023-12-06 14:31:45,667 : INFO : EPOCH 30: training on 99524 raw words (65614 effective words) took 0.1s, 475619 effective words/s\n",
      "2023-12-06 14:31:45,809 : INFO : EPOCH 31: training on 99524 raw words (65398 effective words) took 0.1s, 474794 effective words/s\n",
      "2023-12-06 14:31:45,964 : INFO : EPOCH 32: training on 99524 raw words (65659 effective words) took 0.2s, 437149 effective words/s\n",
      "2023-12-06 14:31:46,109 : INFO : EPOCH 33: training on 99524 raw words (65641 effective words) took 0.1s, 465659 effective words/s\n",
      "2023-12-06 14:31:46,251 : INFO : EPOCH 34: training on 99524 raw words (65585 effective words) took 0.1s, 473512 effective words/s\n",
      "2023-12-06 14:31:46,401 : INFO : EPOCH 35: training on 99524 raw words (65531 effective words) took 0.1s, 453057 effective words/s\n",
      "2023-12-06 14:31:46,546 : INFO : EPOCH 36: training on 99524 raw words (65542 effective words) took 0.1s, 465710 effective words/s\n",
      "2023-12-06 14:31:46,689 : INFO : EPOCH 37: training on 99524 raw words (65446 effective words) took 0.1s, 472738 effective words/s\n",
      "2023-12-06 14:31:46,840 : INFO : EPOCH 38: training on 99524 raw words (65529 effective words) took 0.1s, 448616 effective words/s\n",
      "2023-12-06 14:31:46,983 : INFO : EPOCH 39: training on 99524 raw words (65461 effective words) took 0.1s, 471959 effective words/s\n",
      "2023-12-06 14:31:47,124 : INFO : EPOCH 40: training on 99524 raw words (65449 effective words) took 0.1s, 476767 effective words/s\n",
      "2023-12-06 14:31:47,271 : INFO : EPOCH 41: training on 99524 raw words (65698 effective words) took 0.1s, 461428 effective words/s\n",
      "2023-12-06 14:31:47,415 : INFO : EPOCH 42: training on 99524 raw words (65700 effective words) took 0.1s, 469788 effective words/s\n",
      "2023-12-06 14:31:47,556 : INFO : EPOCH 43: training on 99524 raw words (65573 effective words) took 0.1s, 478469 effective words/s\n",
      "2023-12-06 14:31:47,704 : INFO : EPOCH 44: training on 99524 raw words (65487 effective words) took 0.1s, 455183 effective words/s\n",
      "2023-12-06 14:31:47,849 : INFO : EPOCH 45: training on 99524 raw words (65443 effective words) took 0.1s, 466284 effective words/s\n",
      "2023-12-06 14:31:47,991 : INFO : EPOCH 46: training on 99524 raw words (65502 effective words) took 0.1s, 474352 effective words/s\n",
      "2023-12-06 14:31:48,143 : INFO : EPOCH 47: training on 99524 raw words (65531 effective words) took 0.1s, 446311 effective words/s\n",
      "2023-12-06 14:31:48,288 : INFO : EPOCH 48: training on 99524 raw words (65527 effective words) took 0.1s, 467382 effective words/s\n",
      "2023-12-06 14:31:48,432 : INFO : EPOCH 49: training on 99524 raw words (65595 effective words) took 0.1s, 467943 effective words/s\n",
      "2023-12-06 14:31:48,433 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3277168 effective words) took 7.3s, 449192 effective words/s', 'datetime': '2023-12-06T14:31:48.433764', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:31:48,433 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:31:48.433764', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 24%|       | 116/486 [18:10<54:16,  8.80s/it]2023-12-06 14:31:51,835 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:31:51,835 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:31:51,855 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:31:51,856 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:31:51,863 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:31:51.863273', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:31:51,864 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:31:51.864276', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:31:51,871 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:31:51,871 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:31:51,872 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:31:51.872501', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:31:51,882 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:31:51,883 : INFO : resetting layer weights\n",
      "2023-12-06 14:31:51,885 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:31:51.885571', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:31:52,048 : INFO : EPOCH 0: training on 99524 raw words (65608 effective words) took 0.2s, 410903 effective words/s\n",
      "2023-12-06 14:31:52,189 : INFO : EPOCH 1: training on 99524 raw words (65705 effective words) took 0.1s, 480537 effective words/s\n",
      "2023-12-06 14:31:52,331 : INFO : EPOCH 2: training on 99524 raw words (65740 effective words) took 0.1s, 479860 effective words/s\n",
      "2023-12-06 14:31:52,476 : INFO : EPOCH 3: training on 99524 raw words (65542 effective words) took 0.1s, 465889 effective words/s\n",
      "2023-12-06 14:31:52,616 : INFO : EPOCH 4: training on 99524 raw words (65473 effective words) took 0.1s, 484352 effective words/s\n",
      "2023-12-06 14:31:52,756 : INFO : EPOCH 5: training on 99524 raw words (65468 effective words) took 0.1s, 480050 effective words/s\n",
      "2023-12-06 14:31:52,901 : INFO : EPOCH 6: training on 99524 raw words (65417 effective words) took 0.1s, 465668 effective words/s\n",
      "2023-12-06 14:31:53,043 : INFO : EPOCH 7: training on 99524 raw words (65532 effective words) took 0.1s, 477823 effective words/s\n",
      "2023-12-06 14:31:53,183 : INFO : EPOCH 8: training on 99524 raw words (65588 effective words) took 0.1s, 482485 effective words/s\n",
      "2023-12-06 14:31:53,330 : INFO : EPOCH 9: training on 99524 raw words (65494 effective words) took 0.1s, 459001 effective words/s\n",
      "2023-12-06 14:31:53,472 : INFO : EPOCH 10: training on 99524 raw words (65412 effective words) took 0.1s, 475216 effective words/s\n",
      "2023-12-06 14:31:53,613 : INFO : EPOCH 11: training on 99524 raw words (65572 effective words) took 0.1s, 482062 effective words/s\n",
      "2023-12-06 14:31:53,760 : INFO : EPOCH 12: training on 99524 raw words (65497 effective words) took 0.1s, 460293 effective words/s\n",
      "2023-12-06 14:31:53,900 : INFO : EPOCH 13: training on 99524 raw words (65606 effective words) took 0.1s, 483921 effective words/s\n",
      "2023-12-06 14:31:54,040 : INFO : EPOCH 14: training on 99524 raw words (65577 effective words) took 0.1s, 481795 effective words/s\n",
      "2023-12-06 14:31:54,186 : INFO : EPOCH 15: training on 99524 raw words (65533 effective words) took 0.1s, 465656 effective words/s\n",
      "2023-12-06 14:31:54,339 : INFO : EPOCH 16: training on 99524 raw words (65543 effective words) took 0.1s, 443413 effective words/s\n",
      "2023-12-06 14:31:54,479 : INFO : EPOCH 17: training on 99524 raw words (65450 effective words) took 0.1s, 483338 effective words/s\n",
      "2023-12-06 14:31:54,623 : INFO : EPOCH 18: training on 99524 raw words (65291 effective words) took 0.1s, 466740 effective words/s\n",
      "2023-12-06 14:31:54,764 : INFO : EPOCH 19: training on 99524 raw words (65604 effective words) took 0.1s, 478154 effective words/s\n",
      "2023-12-06 14:31:54,904 : INFO : EPOCH 20: training on 99524 raw words (65457 effective words) took 0.1s, 482347 effective words/s\n",
      "2023-12-06 14:31:55,050 : INFO : EPOCH 21: training on 99524 raw words (65508 effective words) took 0.1s, 465512 effective words/s\n",
      "2023-12-06 14:31:55,190 : INFO : EPOCH 22: training on 99524 raw words (65504 effective words) took 0.1s, 483526 effective words/s\n",
      "2023-12-06 14:31:55,332 : INFO : EPOCH 23: training on 99524 raw words (65489 effective words) took 0.1s, 475851 effective words/s\n",
      "2023-12-06 14:31:55,477 : INFO : EPOCH 24: training on 99524 raw words (65446 effective words) took 0.1s, 463581 effective words/s\n",
      "2023-12-06 14:31:55,619 : INFO : EPOCH 25: training on 99524 raw words (65538 effective words) took 0.1s, 477640 effective words/s\n",
      "2023-12-06 14:31:55,760 : INFO : EPOCH 26: training on 99524 raw words (65548 effective words) took 0.1s, 479816 effective words/s\n",
      "2023-12-06 14:31:55,910 : INFO : EPOCH 27: training on 99524 raw words (65663 effective words) took 0.1s, 450442 effective words/s\n",
      "2023-12-06 14:31:56,050 : INFO : EPOCH 28: training on 99524 raw words (65530 effective words) took 0.1s, 481677 effective words/s\n",
      "2023-12-06 14:31:56,191 : INFO : EPOCH 29: training on 99524 raw words (65567 effective words) took 0.1s, 479874 effective words/s\n",
      "2023-12-06 14:31:56,338 : INFO : EPOCH 30: training on 99524 raw words (65534 effective words) took 0.1s, 462235 effective words/s\n",
      "2023-12-06 14:31:56,478 : INFO : EPOCH 31: training on 99524 raw words (65522 effective words) took 0.1s, 481073 effective words/s\n",
      "2023-12-06 14:31:56,617 : INFO : EPOCH 32: training on 99524 raw words (65543 effective words) took 0.1s, 485768 effective words/s\n",
      "2023-12-06 14:31:56,763 : INFO : EPOCH 33: training on 99524 raw words (65813 effective words) took 0.1s, 464877 effective words/s\n",
      "2023-12-06 14:31:56,903 : INFO : EPOCH 34: training on 99524 raw words (65590 effective words) took 0.1s, 483561 effective words/s\n",
      "2023-12-06 14:31:57,044 : INFO : EPOCH 35: training on 99524 raw words (65695 effective words) took 0.1s, 484521 effective words/s\n",
      "2023-12-06 14:31:57,197 : INFO : EPOCH 36: training on 99524 raw words (65494 effective words) took 0.1s, 441745 effective words/s\n",
      "2023-12-06 14:31:57,340 : INFO : EPOCH 37: training on 99524 raw words (65397 effective words) took 0.1s, 474163 effective words/s\n",
      "2023-12-06 14:31:57,480 : INFO : EPOCH 38: training on 99524 raw words (65431 effective words) took 0.1s, 479032 effective words/s\n",
      "2023-12-06 14:31:57,627 : INFO : EPOCH 39: training on 99524 raw words (65620 effective words) took 0.1s, 460848 effective words/s\n",
      "2023-12-06 14:31:57,769 : INFO : EPOCH 40: training on 99524 raw words (65571 effective words) took 0.1s, 475588 effective words/s\n",
      "2023-12-06 14:31:57,910 : INFO : EPOCH 41: training on 99524 raw words (65784 effective words) took 0.1s, 481702 effective words/s\n",
      "2023-12-06 14:31:58,057 : INFO : EPOCH 42: training on 99524 raw words (65562 effective words) took 0.1s, 459660 effective words/s\n",
      "2023-12-06 14:31:58,199 : INFO : EPOCH 43: training on 99524 raw words (65492 effective words) took 0.1s, 476174 effective words/s\n",
      "2023-12-06 14:31:58,340 : INFO : EPOCH 44: training on 99524 raw words (65600 effective words) took 0.1s, 481283 effective words/s\n",
      "2023-12-06 14:31:58,484 : INFO : EPOCH 45: training on 99524 raw words (65441 effective words) took 0.1s, 464776 effective words/s\n",
      "2023-12-06 14:31:58,628 : INFO : EPOCH 46: training on 99524 raw words (65514 effective words) took 0.1s, 474375 effective words/s\n",
      "2023-12-06 14:31:58,767 : INFO : EPOCH 47: training on 99524 raw words (65411 effective words) took 0.1s, 482665 effective words/s\n",
      "2023-12-06 14:31:58,915 : INFO : EPOCH 48: training on 99524 raw words (65595 effective words) took 0.1s, 460988 effective words/s\n",
      "2023-12-06 14:31:59,057 : INFO : EPOCH 49: training on 99524 raw words (65742 effective words) took 0.1s, 476910 effective words/s\n",
      "2023-12-06 14:31:59,058 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3277253 effective words) took 7.2s, 456936 effective words/s', 'datetime': '2023-12-06T14:31:59.058399', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:31:59,058 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:31:59.058399', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 24%|       | 117/486 [18:21<57:52,  9.41s/it]2023-12-06 14:32:02,668 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:32:02,669 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:32:02,691 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:32:02,692 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:32:02,697 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:32:02.697489', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:02,698 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:32:02.698497', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:02,703 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:32:02,704 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:32:02,705 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:32:02.705489', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:02,716 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:32:02,716 : INFO : resetting layer weights\n",
      "2023-12-06 14:32:02,718 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:32:02.718000', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:32:02,873 : INFO : EPOCH 0: training on 99524 raw words (62653 effective words) took 0.2s, 414393 effective words/s\n",
      "2023-12-06 14:32:03,024 : INFO : EPOCH 1: training on 99524 raw words (62858 effective words) took 0.1s, 432742 effective words/s\n",
      "2023-12-06 14:32:03,167 : INFO : EPOCH 2: training on 99524 raw words (62715 effective words) took 0.1s, 454750 effective words/s\n",
      "2023-12-06 14:32:03,312 : INFO : EPOCH 3: training on 99524 raw words (62730 effective words) took 0.1s, 442938 effective words/s\n",
      "2023-12-06 14:32:03,453 : INFO : EPOCH 4: training on 99524 raw words (62706 effective words) took 0.1s, 460818 effective words/s\n",
      "2023-12-06 14:32:03,593 : INFO : EPOCH 5: training on 99524 raw words (62621 effective words) took 0.1s, 463126 effective words/s\n",
      "2023-12-06 14:32:03,739 : INFO : EPOCH 6: training on 99524 raw words (62615 effective words) took 0.1s, 440755 effective words/s\n",
      "2023-12-06 14:32:03,880 : INFO : EPOCH 7: training on 99524 raw words (62820 effective words) took 0.1s, 459400 effective words/s\n",
      "2023-12-06 14:32:04,020 : INFO : EPOCH 8: training on 99524 raw words (62785 effective words) took 0.1s, 462329 effective words/s\n",
      "2023-12-06 14:32:04,166 : INFO : EPOCH 9: training on 99524 raw words (62724 effective words) took 0.1s, 441845 effective words/s\n",
      "2023-12-06 14:32:04,167 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627227 effective words) took 1.4s, 432911 effective words/s', 'datetime': '2023-12-06T14:32:04.167618', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:32:04,168 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:32:04.168619', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 24%|       | 118/486 [18:25<47:52,  7.81s/it]2023-12-06 14:32:06,731 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:32:06,731 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:32:06,750 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:32:06,751 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:32:06,757 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:32:06.757423', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:06,758 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:32:06.758423', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:06,763 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:32:06,764 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:32:06,764 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:32:06.764317', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:06,772 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:32:06,772 : INFO : resetting layer weights\n",
      "2023-12-06 14:32:06,774 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:32:06.774308', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:32:06,923 : INFO : EPOCH 0: training on 99524 raw words (62684 effective words) took 0.1s, 433532 effective words/s\n",
      "2023-12-06 14:32:07,077 : INFO : EPOCH 1: training on 99524 raw words (62941 effective words) took 0.1s, 422378 effective words/s\n",
      "2023-12-06 14:32:07,219 : INFO : EPOCH 2: training on 99524 raw words (62890 effective words) took 0.1s, 457605 effective words/s\n",
      "2023-12-06 14:32:07,368 : INFO : EPOCH 3: training on 99524 raw words (62616 effective words) took 0.1s, 431606 effective words/s\n",
      "2023-12-06 14:32:07,510 : INFO : EPOCH 4: training on 99524 raw words (62685 effective words) took 0.1s, 457697 effective words/s\n",
      "2023-12-06 14:32:07,652 : INFO : EPOCH 5: training on 99524 raw words (62583 effective words) took 0.1s, 455360 effective words/s\n",
      "2023-12-06 14:32:07,800 : INFO : EPOCH 6: training on 99524 raw words (62787 effective words) took 0.1s, 437682 effective words/s\n",
      "2023-12-06 14:32:07,943 : INFO : EPOCH 7: training on 99524 raw words (62652 effective words) took 0.1s, 452473 effective words/s\n",
      "2023-12-06 14:32:08,083 : INFO : EPOCH 8: training on 99524 raw words (62663 effective words) took 0.1s, 462259 effective words/s\n",
      "2023-12-06 14:32:08,229 : INFO : EPOCH 9: training on 99524 raw words (62745 effective words) took 0.1s, 441396 effective words/s\n",
      "2023-12-06 14:32:08,230 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627246 effective words) took 1.5s, 431064 effective words/s', 'datetime': '2023-12-06T14:32:08.230305', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:32:08,231 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:32:08.231305', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 24%|       | 119/486 [18:29<40:53,  6.69s/it]2023-12-06 14:32:10,803 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:32:10,803 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:32:10,824 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:32:10,825 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:32:10,831 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:32:10.831867', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:10,832 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:32:10.832868', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:10,838 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:32:10,838 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:32:10,839 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:32:10.839875', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:10,852 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:32:10,853 : INFO : resetting layer weights\n",
      "2023-12-06 14:32:10,855 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:32:10.855385', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:32:11,012 : INFO : EPOCH 0: training on 99524 raw words (62737 effective words) took 0.2s, 408662 effective words/s\n",
      "2023-12-06 14:32:11,156 : INFO : EPOCH 1: training on 99524 raw words (62670 effective words) took 0.1s, 453370 effective words/s\n",
      "2023-12-06 14:32:11,302 : INFO : EPOCH 2: training on 99524 raw words (62846 effective words) took 0.1s, 441603 effective words/s\n",
      "2023-12-06 14:32:11,448 : INFO : EPOCH 3: training on 99524 raw words (62630 effective words) took 0.1s, 442701 effective words/s\n",
      "2023-12-06 14:32:11,589 : INFO : EPOCH 4: training on 99524 raw words (62766 effective words) took 0.1s, 460526 effective words/s\n",
      "2023-12-06 14:32:11,736 : INFO : EPOCH 5: training on 99524 raw words (62648 effective words) took 0.1s, 441599 effective words/s\n",
      "2023-12-06 14:32:11,879 : INFO : EPOCH 6: training on 99524 raw words (62699 effective words) took 0.1s, 450791 effective words/s\n",
      "2023-12-06 14:32:12,019 : INFO : EPOCH 7: training on 99524 raw words (62590 effective words) took 0.1s, 461549 effective words/s\n",
      "2023-12-06 14:32:12,164 : INFO : EPOCH 8: training on 99524 raw words (62760 effective words) took 0.1s, 446752 effective words/s\n",
      "2023-12-06 14:32:12,304 : INFO : EPOCH 9: training on 99524 raw words (62689 effective words) took 0.1s, 463203 effective words/s\n",
      "2023-12-06 14:32:12,305 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627035 effective words) took 1.4s, 432577 effective words/s', 'datetime': '2023-12-06T14:32:12.304607', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:32:12,305 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:32:12.305607', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 25%|       | 120/486 [18:33<36:07,  5.92s/it]2023-12-06 14:32:14,942 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:32:14,943 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:32:14,963 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:32:14,963 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:32:14,970 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:32:14.970393', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:14,970 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:32:14.970393', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:14,978 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:32:14,978 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:32:14,979 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:32:14.979394', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:14,991 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:32:14,992 : INFO : resetting layer weights\n",
      "2023-12-06 14:32:14,993 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:32:14.993703', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:32:15,151 : INFO : EPOCH 0: training on 99524 raw words (62715 effective words) took 0.2s, 410376 effective words/s\n",
      "2023-12-06 14:32:15,293 : INFO : EPOCH 1: training on 99524 raw words (62810 effective words) took 0.1s, 457302 effective words/s\n",
      "2023-12-06 14:32:15,438 : INFO : EPOCH 2: training on 99524 raw words (62639 effective words) took 0.1s, 447778 effective words/s\n",
      "2023-12-06 14:32:15,585 : INFO : EPOCH 3: training on 99524 raw words (62567 effective words) took 0.1s, 438622 effective words/s\n",
      "2023-12-06 14:32:15,725 : INFO : EPOCH 4: training on 99524 raw words (62773 effective words) took 0.1s, 460617 effective words/s\n",
      "2023-12-06 14:32:15,865 : INFO : EPOCH 5: training on 99524 raw words (62612 effective words) took 0.1s, 461717 effective words/s\n",
      "2023-12-06 14:32:16,013 : INFO : EPOCH 6: training on 99524 raw words (62736 effective words) took 0.1s, 438930 effective words/s\n",
      "2023-12-06 14:32:16,158 : INFO : EPOCH 7: training on 99524 raw words (62770 effective words) took 0.1s, 448246 effective words/s\n",
      "2023-12-06 14:32:16,308 : INFO : EPOCH 8: training on 99524 raw words (62723 effective words) took 0.1s, 429984 effective words/s\n",
      "2023-12-06 14:32:16,449 : INFO : EPOCH 9: training on 99524 raw words (62755 effective words) took 0.1s, 456919 effective words/s\n",
      "2023-12-06 14:32:16,589 : INFO : EPOCH 10: training on 99524 raw words (62614 effective words) took 0.1s, 463567 effective words/s\n",
      "2023-12-06 14:32:16,736 : INFO : EPOCH 11: training on 99524 raw words (62718 effective words) took 0.1s, 443040 effective words/s\n",
      "2023-12-06 14:32:16,877 : INFO : EPOCH 12: training on 99524 raw words (62724 effective words) took 0.1s, 455628 effective words/s\n",
      "2023-12-06 14:32:17,018 : INFO : EPOCH 13: training on 99524 raw words (62742 effective words) took 0.1s, 461386 effective words/s\n",
      "2023-12-06 14:32:17,165 : INFO : EPOCH 14: training on 99524 raw words (62742 effective words) took 0.1s, 437675 effective words/s\n",
      "2023-12-06 14:32:17,306 : INFO : EPOCH 15: training on 99524 raw words (62734 effective words) took 0.1s, 458013 effective words/s\n",
      "2023-12-06 14:32:17,446 : INFO : EPOCH 16: training on 99524 raw words (62723 effective words) took 0.1s, 463886 effective words/s\n",
      "2023-12-06 14:32:17,593 : INFO : EPOCH 17: training on 99524 raw words (62596 effective words) took 0.1s, 437935 effective words/s\n",
      "2023-12-06 14:32:17,742 : INFO : EPOCH 18: training on 99524 raw words (62698 effective words) took 0.1s, 436600 effective words/s\n",
      "2023-12-06 14:32:17,893 : INFO : EPOCH 19: training on 99524 raw words (62736 effective words) took 0.1s, 430230 effective words/s\n",
      "2023-12-06 14:32:18,040 : INFO : EPOCH 20: training on 99524 raw words (62700 effective words) took 0.1s, 439175 effective words/s\n",
      "2023-12-06 14:32:18,181 : INFO : EPOCH 21: training on 99524 raw words (62678 effective words) took 0.1s, 458527 effective words/s\n",
      "2023-12-06 14:32:18,319 : INFO : EPOCH 22: training on 99524 raw words (62843 effective words) took 0.1s, 467148 effective words/s\n",
      "2023-12-06 14:32:18,466 : INFO : EPOCH 23: training on 99524 raw words (62779 effective words) took 0.1s, 441134 effective words/s\n",
      "2023-12-06 14:32:18,608 : INFO : EPOCH 24: training on 99524 raw words (62834 effective words) took 0.1s, 458094 effective words/s\n",
      "2023-12-06 14:32:18,749 : INFO : EPOCH 25: training on 99524 raw words (62725 effective words) took 0.1s, 459699 effective words/s\n",
      "2023-12-06 14:32:18,895 : INFO : EPOCH 26: training on 99524 raw words (62722 effective words) took 0.1s, 442179 effective words/s\n",
      "2023-12-06 14:32:19,035 : INFO : EPOCH 27: training on 99524 raw words (62903 effective words) took 0.1s, 462222 effective words/s\n",
      "2023-12-06 14:32:19,175 : INFO : EPOCH 28: training on 99524 raw words (62699 effective words) took 0.1s, 461678 effective words/s\n",
      "2023-12-06 14:32:19,322 : INFO : EPOCH 29: training on 99524 raw words (62810 effective words) took 0.1s, 441866 effective words/s\n",
      "2023-12-06 14:32:19,323 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881820 effective words) took 4.3s, 434760 effective words/s', 'datetime': '2023-12-06T14:32:19.323196', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:32:19,324 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:32:19.324211', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 25%|       | 121/486 [18:40<38:20,  6.30s/it]2023-12-06 14:32:22,132 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:32:22,133 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:32:22,153 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:32:22,154 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:32:22,161 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:32:22.161866', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:22,162 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:32:22.162866', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:22,168 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:32:22,169 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:32:22,169 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:32:22.169874', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:22,177 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:32:22,178 : INFO : resetting layer weights\n",
      "2023-12-06 14:32:22,180 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:32:22.180882', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:32:22,343 : INFO : EPOCH 0: training on 99524 raw words (62719 effective words) took 0.2s, 394405 effective words/s\n",
      "2023-12-06 14:32:22,488 : INFO : EPOCH 1: training on 99524 raw words (62850 effective words) took 0.1s, 454834 effective words/s\n",
      "2023-12-06 14:32:22,630 : INFO : EPOCH 2: training on 99524 raw words (62731 effective words) took 0.1s, 455160 effective words/s\n",
      "2023-12-06 14:32:22,778 : INFO : EPOCH 3: training on 99524 raw words (62653 effective words) took 0.1s, 435667 effective words/s\n",
      "2023-12-06 14:32:22,921 : INFO : EPOCH 4: training on 99524 raw words (62890 effective words) took 0.1s, 455132 effective words/s\n",
      "2023-12-06 14:32:23,063 : INFO : EPOCH 5: training on 99524 raw words (62874 effective words) took 0.1s, 454877 effective words/s\n",
      "2023-12-06 14:32:23,211 : INFO : EPOCH 6: training on 99524 raw words (62821 effective words) took 0.1s, 437150 effective words/s\n",
      "2023-12-06 14:32:23,357 : INFO : EPOCH 7: training on 99524 raw words (62652 effective words) took 0.1s, 440971 effective words/s\n",
      "2023-12-06 14:32:23,502 : INFO : EPOCH 8: training on 99524 raw words (62741 effective words) took 0.1s, 447652 effective words/s\n",
      "2023-12-06 14:32:23,651 : INFO : EPOCH 9: training on 99524 raw words (62711 effective words) took 0.1s, 437219 effective words/s\n",
      "2023-12-06 14:32:23,796 : INFO : EPOCH 10: training on 99524 raw words (62697 effective words) took 0.1s, 448011 effective words/s\n",
      "2023-12-06 14:32:23,943 : INFO : EPOCH 11: training on 99524 raw words (62748 effective words) took 0.1s, 440040 effective words/s\n",
      "2023-12-06 14:32:24,086 : INFO : EPOCH 12: training on 99524 raw words (62775 effective words) took 0.1s, 451351 effective words/s\n",
      "2023-12-06 14:32:24,227 : INFO : EPOCH 13: training on 99524 raw words (62782 effective words) took 0.1s, 459242 effective words/s\n",
      "2023-12-06 14:32:24,376 : INFO : EPOCH 14: training on 99524 raw words (62786 effective words) took 0.1s, 435415 effective words/s\n",
      "2023-12-06 14:32:24,518 : INFO : EPOCH 15: training on 99524 raw words (62722 effective words) took 0.1s, 456559 effective words/s\n",
      "2023-12-06 14:32:24,668 : INFO : EPOCH 16: training on 99524 raw words (62674 effective words) took 0.1s, 428089 effective words/s\n",
      "2023-12-06 14:32:24,819 : INFO : EPOCH 17: training on 99524 raw words (62629 effective words) took 0.1s, 430624 effective words/s\n",
      "2023-12-06 14:32:24,962 : INFO : EPOCH 18: training on 99524 raw words (62595 effective words) took 0.1s, 452510 effective words/s\n",
      "2023-12-06 14:32:25,102 : INFO : EPOCH 19: training on 99524 raw words (62695 effective words) took 0.1s, 461229 effective words/s\n",
      "2023-12-06 14:32:25,250 : INFO : EPOCH 20: training on 99524 raw words (62763 effective words) took 0.1s, 434327 effective words/s\n",
      "2023-12-06 14:32:25,394 : INFO : EPOCH 21: training on 99524 raw words (62821 effective words) took 0.1s, 450572 effective words/s\n",
      "2023-12-06 14:32:25,538 : INFO : EPOCH 22: training on 99524 raw words (62925 effective words) took 0.1s, 451585 effective words/s\n",
      "2023-12-06 14:32:25,688 : INFO : EPOCH 23: training on 99524 raw words (62786 effective words) took 0.1s, 433051 effective words/s\n",
      "2023-12-06 14:32:25,831 : INFO : EPOCH 24: training on 99524 raw words (62750 effective words) took 0.1s, 451994 effective words/s\n",
      "2023-12-06 14:32:25,973 : INFO : EPOCH 25: training on 99524 raw words (62647 effective words) took 0.1s, 457538 effective words/s\n",
      "2023-12-06 14:32:26,119 : INFO : EPOCH 26: training on 99524 raw words (62915 effective words) took 0.1s, 441627 effective words/s\n",
      "2023-12-06 14:32:26,267 : INFO : EPOCH 27: training on 99524 raw words (62980 effective words) took 0.1s, 439637 effective words/s\n",
      "2023-12-06 14:32:26,410 : INFO : EPOCH 28: training on 99524 raw words (62784 effective words) took 0.1s, 455971 effective words/s\n",
      "2023-12-06 14:32:26,558 : INFO : EPOCH 29: training on 99524 raw words (62754 effective words) took 0.1s, 436782 effective words/s\n",
      "2023-12-06 14:32:26,559 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1882870 effective words) took 4.4s, 430064 effective words/s', 'datetime': '2023-12-06T14:32:26.559523', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:32:26,560 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:32:26.560522', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 25%|       | 122/486 [18:48<40:15,  6.64s/it]2023-12-06 14:32:29,551 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:32:29,552 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:32:29,575 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:32:29,576 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:32:29,581 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:32:29.581206', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:29,581 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:32:29.581206', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:29,589 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:32:29,590 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:32:29,590 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:32:29.590206', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:29,598 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:32:29,599 : INFO : resetting layer weights\n",
      "2023-12-06 14:32:29,601 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:32:29.601300', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:32:29,758 : INFO : EPOCH 0: training on 99524 raw words (62636 effective words) took 0.2s, 406924 effective words/s\n",
      "2023-12-06 14:32:29,896 : INFO : EPOCH 1: training on 99524 raw words (62874 effective words) took 0.1s, 469710 effective words/s\n",
      "2023-12-06 14:32:30,036 : INFO : EPOCH 2: training on 99524 raw words (62817 effective words) took 0.1s, 466814 effective words/s\n",
      "2023-12-06 14:32:30,179 : INFO : EPOCH 3: training on 99524 raw words (62620 effective words) took 0.1s, 449624 effective words/s\n",
      "2023-12-06 14:32:30,317 : INFO : EPOCH 4: training on 99524 raw words (62659 effective words) took 0.1s, 468820 effective words/s\n",
      "2023-12-06 14:32:30,462 : INFO : EPOCH 5: training on 99524 raw words (62798 effective words) took 0.1s, 445431 effective words/s\n",
      "2023-12-06 14:32:30,610 : INFO : EPOCH 6: training on 99524 raw words (62678 effective words) took 0.1s, 440749 effective words/s\n",
      "2023-12-06 14:32:30,749 : INFO : EPOCH 7: training on 99524 raw words (62716 effective words) took 0.1s, 464247 effective words/s\n",
      "2023-12-06 14:32:30,889 : INFO : EPOCH 8: training on 99524 raw words (62781 effective words) took 0.1s, 463320 effective words/s\n",
      "2023-12-06 14:32:31,035 : INFO : EPOCH 9: training on 99524 raw words (62727 effective words) took 0.1s, 442413 effective words/s\n",
      "2023-12-06 14:32:31,174 : INFO : EPOCH 10: training on 99524 raw words (62787 effective words) took 0.1s, 465914 effective words/s\n",
      "2023-12-06 14:32:31,313 : INFO : EPOCH 11: training on 99524 raw words (62852 effective words) took 0.1s, 465904 effective words/s\n",
      "2023-12-06 14:32:31,459 : INFO : EPOCH 12: training on 99524 raw words (62804 effective words) took 0.1s, 445513 effective words/s\n",
      "2023-12-06 14:32:31,598 : INFO : EPOCH 13: training on 99524 raw words (62764 effective words) took 0.1s, 463707 effective words/s\n",
      "2023-12-06 14:32:31,744 : INFO : EPOCH 14: training on 99524 raw words (62743 effective words) took 0.1s, 444250 effective words/s\n",
      "2023-12-06 14:32:31,883 : INFO : EPOCH 15: training on 99524 raw words (62676 effective words) took 0.1s, 468065 effective words/s\n",
      "2023-12-06 14:32:32,023 : INFO : EPOCH 16: training on 99524 raw words (62980 effective words) took 0.1s, 466102 effective words/s\n",
      "2023-12-06 14:32:32,167 : INFO : EPOCH 17: training on 99524 raw words (62601 effective words) took 0.1s, 445329 effective words/s\n",
      "2023-12-06 14:32:32,306 : INFO : EPOCH 18: training on 99524 raw words (62712 effective words) took 0.1s, 465606 effective words/s\n",
      "2023-12-06 14:32:32,455 : INFO : EPOCH 19: training on 99524 raw words (62920 effective words) took 0.1s, 435868 effective words/s\n",
      "2023-12-06 14:32:32,600 : INFO : EPOCH 20: training on 99524 raw words (62722 effective words) took 0.1s, 448387 effective words/s\n",
      "2023-12-06 14:32:32,740 : INFO : EPOCH 21: training on 99524 raw words (62812 effective words) took 0.1s, 461598 effective words/s\n",
      "2023-12-06 14:32:32,879 : INFO : EPOCH 22: training on 99524 raw words (62846 effective words) took 0.1s, 468004 effective words/s\n",
      "2023-12-06 14:32:33,027 : INFO : EPOCH 23: training on 99524 raw words (62831 effective words) took 0.1s, 441652 effective words/s\n",
      "2023-12-06 14:32:33,165 : INFO : EPOCH 24: training on 99524 raw words (62692 effective words) took 0.1s, 465442 effective words/s\n",
      "2023-12-06 14:32:33,309 : INFO : EPOCH 25: training on 99524 raw words (62760 effective words) took 0.1s, 450036 effective words/s\n",
      "2023-12-06 14:32:33,464 : INFO : EPOCH 26: training on 99524 raw words (62887 effective words) took 0.2s, 416436 effective words/s\n",
      "2023-12-06 14:32:33,606 : INFO : EPOCH 27: training on 99524 raw words (62920 effective words) took 0.1s, 457679 effective words/s\n",
      "2023-12-06 14:32:33,751 : INFO : EPOCH 28: training on 99524 raw words (62601 effective words) took 0.1s, 444648 effective words/s\n",
      "2023-12-06 14:32:33,891 : INFO : EPOCH 29: training on 99524 raw words (62512 effective words) took 0.1s, 463469 effective words/s\n",
      "2023-12-06 14:32:33,892 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1882728 effective words) took 4.3s, 438833 effective words/s', 'datetime': '2023-12-06T14:32:33.892082', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:32:33,892 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:32:33.892082', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 25%|       | 123/486 [18:55<41:38,  6.88s/it]2023-12-06 14:32:37,004 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:32:37,004 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:32:37,024 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:32:37,025 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:32:37,032 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:32:37.032676', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:37,033 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:32:37.033180', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:37,038 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:32:37,039 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:32:37,039 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:32:37.039693', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:37,051 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:32:37,052 : INFO : resetting layer weights\n",
      "2023-12-06 14:32:37,054 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:32:37.054874', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:32:37,210 : INFO : EPOCH 0: training on 99524 raw words (62609 effective words) took 0.2s, 412605 effective words/s\n",
      "2023-12-06 14:32:37,352 : INFO : EPOCH 1: training on 99524 raw words (62750 effective words) took 0.1s, 458800 effective words/s\n",
      "2023-12-06 14:32:37,501 : INFO : EPOCH 2: training on 99524 raw words (62805 effective words) took 0.1s, 432843 effective words/s\n",
      "2023-12-06 14:32:37,642 : INFO : EPOCH 3: training on 99524 raw words (62686 effective words) took 0.1s, 458682 effective words/s\n",
      "2023-12-06 14:32:37,783 : INFO : EPOCH 4: training on 99524 raw words (62680 effective words) took 0.1s, 458333 effective words/s\n",
      "2023-12-06 14:32:37,934 : INFO : EPOCH 5: training on 99524 raw words (62601 effective words) took 0.1s, 427495 effective words/s\n",
      "2023-12-06 14:32:38,078 : INFO : EPOCH 6: training on 99524 raw words (62651 effective words) took 0.1s, 449302 effective words/s\n",
      "2023-12-06 14:32:38,220 : INFO : EPOCH 7: training on 99524 raw words (62772 effective words) took 0.1s, 456535 effective words/s\n",
      "2023-12-06 14:32:38,367 : INFO : EPOCH 8: training on 99524 raw words (62810 effective words) took 0.1s, 440266 effective words/s\n",
      "2023-12-06 14:32:38,508 : INFO : EPOCH 9: training on 99524 raw words (62861 effective words) took 0.1s, 459416 effective words/s\n",
      "2023-12-06 14:32:38,656 : INFO : EPOCH 10: training on 99524 raw words (62613 effective words) took 0.1s, 436404 effective words/s\n",
      "2023-12-06 14:32:38,797 : INFO : EPOCH 11: training on 99524 raw words (62975 effective words) took 0.1s, 464206 effective words/s\n",
      "2023-12-06 14:32:38,935 : INFO : EPOCH 12: training on 99524 raw words (62878 effective words) took 0.1s, 469906 effective words/s\n",
      "2023-12-06 14:32:39,082 : INFO : EPOCH 13: training on 99524 raw words (62658 effective words) took 0.1s, 441325 effective words/s\n",
      "2023-12-06 14:32:39,222 : INFO : EPOCH 14: training on 99524 raw words (62823 effective words) took 0.1s, 462577 effective words/s\n",
      "2023-12-06 14:32:39,364 : INFO : EPOCH 15: training on 99524 raw words (62768 effective words) took 0.1s, 456761 effective words/s\n",
      "2023-12-06 14:32:39,511 : INFO : EPOCH 16: training on 99524 raw words (62803 effective words) took 0.1s, 440142 effective words/s\n",
      "2023-12-06 14:32:39,653 : INFO : EPOCH 17: training on 99524 raw words (62812 effective words) took 0.1s, 456667 effective words/s\n",
      "2023-12-06 14:32:39,794 : INFO : EPOCH 18: training on 99524 raw words (62682 effective words) took 0.1s, 458061 effective words/s\n",
      "2023-12-06 14:32:39,946 : INFO : EPOCH 19: training on 99524 raw words (62719 effective words) took 0.1s, 425514 effective words/s\n",
      "2023-12-06 14:32:40,093 : INFO : EPOCH 20: training on 99524 raw words (62739 effective words) took 0.1s, 441771 effective words/s\n",
      "2023-12-06 14:32:40,240 : INFO : EPOCH 21: training on 99524 raw words (62809 effective words) took 0.1s, 440604 effective words/s\n",
      "2023-12-06 14:32:40,381 : INFO : EPOCH 22: training on 99524 raw words (62855 effective words) took 0.1s, 459109 effective words/s\n",
      "2023-12-06 14:32:40,522 : INFO : EPOCH 23: training on 99524 raw words (62772 effective words) took 0.1s, 457674 effective words/s\n",
      "2023-12-06 14:32:40,671 : INFO : EPOCH 24: training on 99524 raw words (62699 effective words) took 0.1s, 435618 effective words/s\n",
      "2023-12-06 14:32:40,813 : INFO : EPOCH 25: training on 99524 raw words (62785 effective words) took 0.1s, 455636 effective words/s\n",
      "2023-12-06 14:32:40,955 : INFO : EPOCH 26: training on 99524 raw words (62824 effective words) took 0.1s, 456324 effective words/s\n",
      "2023-12-06 14:32:41,104 : INFO : EPOCH 27: training on 99524 raw words (62790 effective words) took 0.1s, 435904 effective words/s\n",
      "2023-12-06 14:32:41,247 : INFO : EPOCH 28: training on 99524 raw words (62752 effective words) took 0.1s, 453255 effective words/s\n",
      "2023-12-06 14:32:41,387 : INFO : EPOCH 29: training on 99524 raw words (62759 effective words) took 0.1s, 460317 effective words/s\n",
      "2023-12-06 14:32:41,535 : INFO : EPOCH 30: training on 99524 raw words (62647 effective words) took 0.1s, 439403 effective words/s\n",
      "2023-12-06 14:32:41,677 : INFO : EPOCH 31: training on 99524 raw words (62630 effective words) took 0.1s, 456326 effective words/s\n",
      "2023-12-06 14:32:41,818 : INFO : EPOCH 32: training on 99524 raw words (62793 effective words) took 0.1s, 457937 effective words/s\n",
      "2023-12-06 14:32:41,964 : INFO : EPOCH 33: training on 99524 raw words (62810 effective words) took 0.1s, 441867 effective words/s\n",
      "2023-12-06 14:32:42,105 : INFO : EPOCH 34: training on 99524 raw words (62829 effective words) took 0.1s, 460878 effective words/s\n",
      "2023-12-06 14:32:42,248 : INFO : EPOCH 35: training on 99524 raw words (62706 effective words) took 0.1s, 455174 effective words/s\n",
      "2023-12-06 14:32:42,400 : INFO : EPOCH 36: training on 99524 raw words (62692 effective words) took 0.1s, 423869 effective words/s\n",
      "2023-12-06 14:32:42,542 : INFO : EPOCH 37: training on 99524 raw words (62725 effective words) took 0.1s, 454139 effective words/s\n",
      "2023-12-06 14:32:42,685 : INFO : EPOCH 38: training on 99524 raw words (62613 effective words) took 0.1s, 453982 effective words/s\n",
      "2023-12-06 14:32:42,833 : INFO : EPOCH 39: training on 99524 raw words (62750 effective words) took 0.1s, 437358 effective words/s\n",
      "2023-12-06 14:32:42,973 : INFO : EPOCH 40: training on 99524 raw words (62648 effective words) took 0.1s, 458735 effective words/s\n",
      "2023-12-06 14:32:43,116 : INFO : EPOCH 41: training on 99524 raw words (62933 effective words) took 0.1s, 458619 effective words/s\n",
      "2023-12-06 14:32:43,263 : INFO : EPOCH 42: training on 99524 raw words (62764 effective words) took 0.1s, 438712 effective words/s\n",
      "2023-12-06 14:32:43,405 : INFO : EPOCH 43: training on 99524 raw words (62803 effective words) took 0.1s, 459583 effective words/s\n",
      "2023-12-06 14:32:43,545 : INFO : EPOCH 44: training on 99524 raw words (62789 effective words) took 0.1s, 461801 effective words/s\n",
      "2023-12-06 14:32:43,694 : INFO : EPOCH 45: training on 99524 raw words (62762 effective words) took 0.1s, 432058 effective words/s\n",
      "2023-12-06 14:32:43,836 : INFO : EPOCH 46: training on 99524 raw words (62772 effective words) took 0.1s, 457219 effective words/s\n",
      "2023-12-06 14:32:43,976 : INFO : EPOCH 47: training on 99524 raw words (62730 effective words) took 0.1s, 459543 effective words/s\n",
      "2023-12-06 14:32:44,123 : INFO : EPOCH 48: training on 99524 raw words (62733 effective words) took 0.1s, 442439 effective words/s\n",
      "2023-12-06 14:32:44,266 : INFO : EPOCH 49: training on 99524 raw words (62868 effective words) took 0.1s, 453139 effective words/s\n",
      "2023-12-06 14:32:44,267 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3137737 effective words) took 7.2s, 435053 effective words/s', 'datetime': '2023-12-06T14:32:44.267556', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:32:44,268 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:32:44.268864', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 26%|       | 124/486 [19:06<47:57,  7.95s/it]2023-12-06 14:32:47,448 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:32:47,448 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:32:47,467 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:32:47,467 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:32:47,472 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:32:47.472257', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:47,472 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:32:47.472257', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:47,479 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:32:47,480 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:32:47,481 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:32:47.481982', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:47,489 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:32:47,490 : INFO : resetting layer weights\n",
      "2023-12-06 14:32:47,491 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:32:47.491548', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:32:47,647 : INFO : EPOCH 0: training on 99524 raw words (62659 effective words) took 0.2s, 414505 effective words/s\n",
      "2023-12-06 14:32:47,800 : INFO : EPOCH 1: training on 99524 raw words (62739 effective words) took 0.1s, 420538 effective words/s\n",
      "2023-12-06 14:32:47,942 : INFO : EPOCH 2: training on 99524 raw words (62694 effective words) took 0.1s, 457900 effective words/s\n",
      "2023-12-06 14:32:48,091 : INFO : EPOCH 3: training on 99524 raw words (62576 effective words) took 0.1s, 434267 effective words/s\n",
      "2023-12-06 14:32:48,233 : INFO : EPOCH 4: training on 99524 raw words (62696 effective words) took 0.1s, 453385 effective words/s\n",
      "2023-12-06 14:32:48,373 : INFO : EPOCH 5: training on 99524 raw words (62628 effective words) took 0.1s, 461818 effective words/s\n",
      "2023-12-06 14:32:48,520 : INFO : EPOCH 6: training on 99524 raw words (62679 effective words) took 0.1s, 438542 effective words/s\n",
      "2023-12-06 14:32:48,662 : INFO : EPOCH 7: training on 99524 raw words (62798 effective words) took 0.1s, 456566 effective words/s\n",
      "2023-12-06 14:32:48,803 : INFO : EPOCH 8: training on 99524 raw words (62695 effective words) took 0.1s, 458098 effective words/s\n",
      "2023-12-06 14:32:48,951 : INFO : EPOCH 9: training on 99524 raw words (62781 effective words) took 0.1s, 442903 effective words/s\n",
      "2023-12-06 14:32:49,093 : INFO : EPOCH 10: training on 99524 raw words (62534 effective words) took 0.1s, 452876 effective words/s\n",
      "2023-12-06 14:32:49,233 : INFO : EPOCH 11: training on 99524 raw words (62798 effective words) took 0.1s, 459356 effective words/s\n",
      "2023-12-06 14:32:49,381 : INFO : EPOCH 12: training on 99524 raw words (62841 effective words) took 0.1s, 439189 effective words/s\n",
      "2023-12-06 14:32:49,524 : INFO : EPOCH 13: training on 99524 raw words (62694 effective words) took 0.1s, 455054 effective words/s\n",
      "2023-12-06 14:32:49,663 : INFO : EPOCH 14: training on 99524 raw words (62776 effective words) took 0.1s, 464187 effective words/s\n",
      "2023-12-06 14:32:49,809 : INFO : EPOCH 15: training on 99524 raw words (62789 effective words) took 0.1s, 441556 effective words/s\n",
      "2023-12-06 14:32:49,951 : INFO : EPOCH 16: training on 99524 raw words (62781 effective words) took 0.1s, 457716 effective words/s\n",
      "2023-12-06 14:32:50,097 : INFO : EPOCH 17: training on 99524 raw words (62655 effective words) took 0.1s, 440718 effective words/s\n",
      "2023-12-06 14:32:50,248 : INFO : EPOCH 18: training on 99524 raw words (62610 effective words) took 0.1s, 430168 effective words/s\n",
      "2023-12-06 14:32:50,390 : INFO : EPOCH 19: training on 99524 raw words (62819 effective words) took 0.1s, 455686 effective words/s\n",
      "2023-12-06 14:32:50,537 : INFO : EPOCH 20: training on 99524 raw words (62738 effective words) took 0.1s, 438841 effective words/s\n",
      "2023-12-06 14:32:50,684 : INFO : EPOCH 21: training on 99524 raw words (62772 effective words) took 0.1s, 439210 effective words/s\n",
      "2023-12-06 14:32:50,827 : INFO : EPOCH 22: training on 99524 raw words (62785 effective words) took 0.1s, 452245 effective words/s\n",
      "2023-12-06 14:32:50,975 : INFO : EPOCH 23: training on 99524 raw words (62672 effective words) took 0.1s, 438215 effective words/s\n",
      "2023-12-06 14:32:51,118 : INFO : EPOCH 24: training on 99524 raw words (62779 effective words) took 0.1s, 452517 effective words/s\n",
      "2023-12-06 14:32:51,261 : INFO : EPOCH 25: training on 99524 raw words (62566 effective words) took 0.1s, 450933 effective words/s\n",
      "2023-12-06 14:32:51,408 : INFO : EPOCH 26: training on 99524 raw words (62873 effective words) took 0.1s, 444449 effective words/s\n",
      "2023-12-06 14:32:51,551 : INFO : EPOCH 27: training on 99524 raw words (62877 effective words) took 0.1s, 451734 effective words/s\n",
      "2023-12-06 14:32:51,693 : INFO : EPOCH 28: training on 99524 raw words (62803 effective words) took 0.1s, 456181 effective words/s\n",
      "2023-12-06 14:32:51,840 : INFO : EPOCH 29: training on 99524 raw words (62763 effective words) took 0.1s, 438556 effective words/s\n",
      "2023-12-06 14:32:51,982 : INFO : EPOCH 30: training on 99524 raw words (62738 effective words) took 0.1s, 457233 effective words/s\n",
      "2023-12-06 14:32:52,131 : INFO : EPOCH 31: training on 99524 raw words (62705 effective words) took 0.1s, 431760 effective words/s\n",
      "2023-12-06 14:32:52,278 : INFO : EPOCH 32: training on 99524 raw words (62719 effective words) took 0.1s, 441343 effective words/s\n",
      "2023-12-06 14:32:52,420 : INFO : EPOCH 33: training on 99524 raw words (62863 effective words) took 0.1s, 454722 effective words/s\n",
      "2023-12-06 14:32:52,563 : INFO : EPOCH 34: training on 99524 raw words (62573 effective words) took 0.1s, 453010 effective words/s\n",
      "2023-12-06 14:32:52,716 : INFO : EPOCH 35: training on 99524 raw words (62897 effective words) took 0.1s, 423358 effective words/s\n",
      "2023-12-06 14:32:52,873 : INFO : EPOCH 36: training on 99524 raw words (62754 effective words) took 0.2s, 414017 effective words/s\n",
      "2023-12-06 14:32:53,015 : INFO : EPOCH 37: training on 99524 raw words (62753 effective words) took 0.1s, 453739 effective words/s\n",
      "2023-12-06 14:32:53,162 : INFO : EPOCH 38: training on 99524 raw words (62753 effective words) took 0.1s, 441725 effective words/s\n",
      "2023-12-06 14:32:53,304 : INFO : EPOCH 39: training on 99524 raw words (62673 effective words) took 0.1s, 454126 effective words/s\n",
      "2023-12-06 14:32:53,444 : INFO : EPOCH 40: training on 99524 raw words (62787 effective words) took 0.1s, 460482 effective words/s\n",
      "2023-12-06 14:32:53,592 : INFO : EPOCH 41: training on 99524 raw words (62872 effective words) took 0.1s, 440871 effective words/s\n",
      "2023-12-06 14:32:53,735 : INFO : EPOCH 42: training on 99524 raw words (62711 effective words) took 0.1s, 449867 effective words/s\n",
      "2023-12-06 14:32:53,876 : INFO : EPOCH 43: training on 99524 raw words (62666 effective words) took 0.1s, 456939 effective words/s\n",
      "2023-12-06 14:32:54,024 : INFO : EPOCH 44: training on 99524 raw words (62614 effective words) took 0.1s, 440577 effective words/s\n",
      "2023-12-06 14:32:54,167 : INFO : EPOCH 45: training on 99524 raw words (62705 effective words) took 0.1s, 450086 effective words/s\n",
      "2023-12-06 14:32:54,308 : INFO : EPOCH 46: training on 99524 raw words (62764 effective words) took 0.1s, 458203 effective words/s\n",
      "2023-12-06 14:32:54,453 : INFO : EPOCH 47: training on 99524 raw words (62728 effective words) took 0.1s, 444702 effective words/s\n",
      "2023-12-06 14:32:54,605 : INFO : EPOCH 48: training on 99524 raw words (62894 effective words) took 0.1s, 428177 effective words/s\n",
      "2023-12-06 14:32:54,747 : INFO : EPOCH 49: training on 99524 raw words (62725 effective words) took 0.1s, 453407 effective words/s\n",
      "2023-12-06 14:32:54,748 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136764 effective words) took 7.3s, 432310 effective words/s', 'datetime': '2023-12-06T14:32:54.748426', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:32:54,749 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:32:54.749425', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 26%|       | 125/486 [19:16<52:48,  8.78s/it]2023-12-06 14:32:58,156 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:32:58,156 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:32:58,177 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:32:58,178 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:32:58,184 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:32:58.184967', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:58,184 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:32:58.184967', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:58,190 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:32:58,190 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:32:58,191 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:32:58.191972', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:32:58,200 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:32:58,200 : INFO : resetting layer weights\n",
      "2023-12-06 14:32:58,202 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:32:58.202516', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:32:58,363 : INFO : EPOCH 0: training on 99524 raw words (62825 effective words) took 0.2s, 403572 effective words/s\n",
      "2023-12-06 14:32:58,512 : INFO : EPOCH 1: training on 99524 raw words (62723 effective words) took 0.1s, 437593 effective words/s\n",
      "2023-12-06 14:32:58,660 : INFO : EPOCH 2: training on 99524 raw words (62777 effective words) took 0.1s, 440510 effective words/s\n",
      "2023-12-06 14:32:58,805 : INFO : EPOCH 3: training on 99524 raw words (62611 effective words) took 0.1s, 443718 effective words/s\n",
      "2023-12-06 14:32:58,947 : INFO : EPOCH 4: training on 99524 raw words (62744 effective words) took 0.1s, 457286 effective words/s\n",
      "2023-12-06 14:32:59,086 : INFO : EPOCH 5: training on 99524 raw words (62794 effective words) took 0.1s, 463151 effective words/s\n",
      "2023-12-06 14:32:59,236 : INFO : EPOCH 6: training on 99524 raw words (62726 effective words) took 0.1s, 432935 effective words/s\n",
      "2023-12-06 14:32:59,377 : INFO : EPOCH 7: training on 99524 raw words (62735 effective words) took 0.1s, 459902 effective words/s\n",
      "2023-12-06 14:32:59,516 : INFO : EPOCH 8: training on 99524 raw words (62716 effective words) took 0.1s, 464566 effective words/s\n",
      "2023-12-06 14:32:59,662 : INFO : EPOCH 9: training on 99524 raw words (62696 effective words) took 0.1s, 446078 effective words/s\n",
      "2023-12-06 14:32:59,802 : INFO : EPOCH 10: training on 99524 raw words (62722 effective words) took 0.1s, 459979 effective words/s\n",
      "2023-12-06 14:32:59,941 : INFO : EPOCH 11: training on 99524 raw words (62998 effective words) took 0.1s, 468562 effective words/s\n",
      "2023-12-06 14:33:00,087 : INFO : EPOCH 12: training on 99524 raw words (62818 effective words) took 0.1s, 444803 effective words/s\n",
      "2023-12-06 14:33:00,228 : INFO : EPOCH 13: training on 99524 raw words (62650 effective words) took 0.1s, 458473 effective words/s\n",
      "2023-12-06 14:33:00,368 : INFO : EPOCH 14: training on 99524 raw words (62849 effective words) took 0.1s, 463609 effective words/s\n",
      "2023-12-06 14:33:00,513 : INFO : EPOCH 15: training on 99524 raw words (62737 effective words) took 0.1s, 445453 effective words/s\n",
      "2023-12-06 14:33:00,654 : INFO : EPOCH 16: training on 99524 raw words (62747 effective words) took 0.1s, 460031 effective words/s\n",
      "2023-12-06 14:33:00,793 : INFO : EPOCH 17: training on 99524 raw words (62536 effective words) took 0.1s, 463324 effective words/s\n",
      "2023-12-06 14:33:00,946 : INFO : EPOCH 18: training on 99524 raw words (62789 effective words) took 0.1s, 422767 effective words/s\n",
      "2023-12-06 14:33:01,086 : INFO : EPOCH 19: training on 99524 raw words (62799 effective words) took 0.1s, 465563 effective words/s\n",
      "2023-12-06 14:33:01,227 : INFO : EPOCH 20: training on 99524 raw words (62757 effective words) took 0.1s, 460772 effective words/s\n",
      "2023-12-06 14:33:01,374 : INFO : EPOCH 21: training on 99524 raw words (62756 effective words) took 0.1s, 442192 effective words/s\n",
      "2023-12-06 14:33:01,512 : INFO : EPOCH 22: training on 99524 raw words (62813 effective words) took 0.1s, 466346 effective words/s\n",
      "2023-12-06 14:33:01,652 : INFO : EPOCH 23: training on 99524 raw words (62752 effective words) took 0.1s, 462708 effective words/s\n",
      "2023-12-06 14:33:01,798 : INFO : EPOCH 24: training on 99524 raw words (62862 effective words) took 0.1s, 444661 effective words/s\n",
      "2023-12-06 14:33:01,938 : INFO : EPOCH 25: training on 99524 raw words (62771 effective words) took 0.1s, 460438 effective words/s\n",
      "2023-12-06 14:33:02,079 : INFO : EPOCH 26: training on 99524 raw words (62724 effective words) took 0.1s, 463590 effective words/s\n",
      "2023-12-06 14:33:02,223 : INFO : EPOCH 27: training on 99524 raw words (62816 effective words) took 0.1s, 447765 effective words/s\n",
      "2023-12-06 14:33:02,364 : INFO : EPOCH 28: training on 99524 raw words (62698 effective words) took 0.1s, 461552 effective words/s\n",
      "2023-12-06 14:33:02,508 : INFO : EPOCH 29: training on 99524 raw words (62786 effective words) took 0.1s, 447007 effective words/s\n",
      "2023-12-06 14:33:02,648 : INFO : EPOCH 30: training on 99524 raw words (62680 effective words) took 0.1s, 465350 effective words/s\n",
      "2023-12-06 14:33:02,788 : INFO : EPOCH 31: training on 99524 raw words (62685 effective words) took 0.1s, 461482 effective words/s\n",
      "2023-12-06 14:33:02,933 : INFO : EPOCH 32: training on 99524 raw words (62711 effective words) took 0.1s, 447447 effective words/s\n",
      "2023-12-06 14:33:03,071 : INFO : EPOCH 33: training on 99524 raw words (62727 effective words) took 0.1s, 465314 effective words/s\n",
      "2023-12-06 14:33:03,213 : INFO : EPOCH 34: training on 99524 raw words (62767 effective words) took 0.1s, 459257 effective words/s\n",
      "2023-12-06 14:33:03,358 : INFO : EPOCH 35: training on 99524 raw words (62756 effective words) took 0.1s, 448315 effective words/s\n",
      "2023-12-06 14:33:03,507 : INFO : EPOCH 36: training on 99524 raw words (62772 effective words) took 0.1s, 435229 effective words/s\n",
      "2023-12-06 14:33:03,646 : INFO : EPOCH 37: training on 99524 raw words (62692 effective words) took 0.1s, 462835 effective words/s\n",
      "2023-12-06 14:33:03,793 : INFO : EPOCH 38: training on 99524 raw words (62620 effective words) took 0.1s, 444422 effective words/s\n",
      "2023-12-06 14:33:03,933 : INFO : EPOCH 39: training on 99524 raw words (62742 effective words) took 0.1s, 463472 effective words/s\n",
      "2023-12-06 14:33:04,079 : INFO : EPOCH 40: training on 99524 raw words (62675 effective words) took 0.1s, 442713 effective words/s\n",
      "2023-12-06 14:33:04,219 : INFO : EPOCH 41: training on 99524 raw words (62756 effective words) took 0.1s, 464094 effective words/s\n",
      "2023-12-06 14:33:04,357 : INFO : EPOCH 42: training on 99524 raw words (62681 effective words) took 0.1s, 467751 effective words/s\n",
      "2023-12-06 14:33:04,504 : INFO : EPOCH 43: training on 99524 raw words (62585 effective words) took 0.1s, 441807 effective words/s\n",
      "2023-12-06 14:33:04,643 : INFO : EPOCH 44: training on 99524 raw words (62817 effective words) took 0.1s, 465008 effective words/s\n",
      "2023-12-06 14:33:04,789 : INFO : EPOCH 45: training on 99524 raw words (62754 effective words) took 0.1s, 442068 effective words/s\n",
      "2023-12-06 14:33:04,936 : INFO : EPOCH 46: training on 99524 raw words (62737 effective words) took 0.1s, 440144 effective words/s\n",
      "2023-12-06 14:33:05,075 : INFO : EPOCH 47: training on 99524 raw words (62648 effective words) took 0.1s, 465186 effective words/s\n",
      "2023-12-06 14:33:05,214 : INFO : EPOCH 48: training on 99524 raw words (62767 effective words) took 0.1s, 465620 effective words/s\n",
      "2023-12-06 14:33:05,360 : INFO : EPOCH 49: training on 99524 raw words (62804 effective words) took 0.1s, 444479 effective words/s\n",
      "2023-12-06 14:33:05,361 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3137103 effective words) took 7.2s, 438246 effective words/s', 'datetime': '2023-12-06T14:33:05.361308', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:33:05,362 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:33:05.362325', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 26%|       | 126/486 [19:28<58:05,  9.68s/it]2023-12-06 14:33:09,947 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:33:09,948 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:33:09,971 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:33:09,972 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:33:09,976 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:33:09.976804', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:33:09,976 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:33:09.976804', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:33:09,983 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:33:09,984 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:33:09,985 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:33:09.985804', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:33:09,995 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:33:09,997 : INFO : resetting layer weights\n",
      "2023-12-06 14:33:09,998 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:33:09.998440', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:33:10,159 : INFO : EPOCH 0: training on 99524 raw words (60278 effective words) took 0.2s, 381771 effective words/s\n",
      "2023-12-06 14:33:10,297 : INFO : EPOCH 1: training on 99524 raw words (60352 effective words) took 0.1s, 458258 effective words/s\n",
      "2023-12-06 14:33:10,447 : INFO : EPOCH 2: training on 99524 raw words (60382 effective words) took 0.1s, 416732 effective words/s\n",
      "2023-12-06 14:33:10,584 : INFO : EPOCH 3: training on 99524 raw words (60371 effective words) took 0.1s, 454467 effective words/s\n",
      "2023-12-06 14:33:10,718 : INFO : EPOCH 4: training on 99524 raw words (60490 effective words) took 0.1s, 468101 effective words/s\n",
      "2023-12-06 14:33:10,866 : INFO : EPOCH 5: training on 99524 raw words (60424 effective words) took 0.1s, 419726 effective words/s\n",
      "2023-12-06 14:33:11,010 : INFO : EPOCH 6: training on 99524 raw words (60391 effective words) took 0.1s, 436988 effective words/s\n",
      "2023-12-06 14:33:11,147 : INFO : EPOCH 7: training on 99524 raw words (60459 effective words) took 0.1s, 452901 effective words/s\n",
      "2023-12-06 14:33:11,300 : INFO : EPOCH 8: training on 99524 raw words (60339 effective words) took 0.1s, 407773 effective words/s\n",
      "2023-12-06 14:33:11,439 : INFO : EPOCH 9: training on 99524 raw words (60306 effective words) took 0.1s, 453250 effective words/s\n",
      "2023-12-06 14:33:11,440 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603792 effective words) took 1.4s, 418871 effective words/s', 'datetime': '2023-12-06T14:33:11.440562', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:33:11,440 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:33:11.440562', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 26%|       | 127/486 [19:32<47:58,  8.02s/it]2023-12-06 14:33:14,084 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:33:14,084 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:33:14,105 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:33:14,106 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:33:14,112 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:33:14.112061', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:33:14,113 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:33:14.113061', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:33:14,117 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:33:14,117 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:33:14,118 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:33:14.118568', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:33:14,128 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:33:14,129 : INFO : resetting layer weights\n",
      "2023-12-06 14:33:14,130 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:33:14.130247', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:33:14,289 : INFO : EPOCH 0: training on 99524 raw words (60449 effective words) took 0.2s, 389588 effective words/s\n",
      "2023-12-06 14:33:14,432 : INFO : EPOCH 1: training on 99524 raw words (60520 effective words) took 0.1s, 437570 effective words/s\n",
      "2023-12-06 14:33:14,573 : INFO : EPOCH 2: training on 99524 raw words (60369 effective words) took 0.1s, 443689 effective words/s\n",
      "2023-12-06 14:33:14,719 : INFO : EPOCH 3: training on 99524 raw words (60367 effective words) took 0.1s, 424865 effective words/s\n",
      "2023-12-06 14:33:14,865 : INFO : EPOCH 4: training on 99524 raw words (60382 effective words) took 0.1s, 431474 effective words/s\n",
      "2023-12-06 14:33:15,012 : INFO : EPOCH 5: training on 99524 raw words (60473 effective words) took 0.1s, 424392 effective words/s\n",
      "2023-12-06 14:33:15,161 : INFO : EPOCH 6: training on 99524 raw words (60367 effective words) took 0.1s, 417749 effective words/s\n",
      "2023-12-06 14:33:15,303 : INFO : EPOCH 7: training on 99524 raw words (60465 effective words) took 0.1s, 438356 effective words/s\n",
      "2023-12-06 14:33:15,447 : INFO : EPOCH 8: training on 99524 raw words (60428 effective words) took 0.1s, 435619 effective words/s\n",
      "2023-12-06 14:33:15,593 : INFO : EPOCH 9: training on 99524 raw words (60304 effective words) took 0.1s, 422390 effective words/s\n",
      "2023-12-06 14:33:15,594 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604124 effective words) took 1.5s, 412636 effective words/s', 'datetime': '2023-12-06T14:33:15.594986', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:33:15,595 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:33:15.595985', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 26%|       | 128/486 [19:36<40:45,  6.83s/it]2023-12-06 14:33:18,140 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:33:18,141 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:33:18,161 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:33:18,162 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:33:18,167 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:33:18.167611', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:33:18,168 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:33:18.168611', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:33:18,174 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:33:18,175 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:33:18,175 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:33:18.175226', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:33:18,186 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:33:18,187 : INFO : resetting layer weights\n",
      "2023-12-06 14:33:18,188 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:33:18.188906', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:33:18,348 : INFO : EPOCH 0: training on 99524 raw words (60240 effective words) took 0.2s, 388626 effective words/s\n",
      "2023-12-06 14:33:18,496 : INFO : EPOCH 1: training on 99524 raw words (60296 effective words) took 0.1s, 426125 effective words/s\n",
      "2023-12-06 14:33:18,637 : INFO : EPOCH 2: training on 99524 raw words (60452 effective words) took 0.1s, 444658 effective words/s\n",
      "2023-12-06 14:33:18,785 : INFO : EPOCH 3: training on 99524 raw words (60319 effective words) took 0.1s, 419826 effective words/s\n",
      "2023-12-06 14:33:18,925 : INFO : EPOCH 4: training on 99524 raw words (60316 effective words) took 0.1s, 443671 effective words/s\n",
      "2023-12-06 14:33:19,066 : INFO : EPOCH 5: training on 99524 raw words (60292 effective words) took 0.1s, 441933 effective words/s\n",
      "2023-12-06 14:33:19,212 : INFO : EPOCH 6: training on 99524 raw words (60421 effective words) took 0.1s, 428404 effective words/s\n",
      "2023-12-06 14:33:19,352 : INFO : EPOCH 7: training on 99524 raw words (60592 effective words) took 0.1s, 444430 effective words/s\n",
      "2023-12-06 14:33:19,492 : INFO : EPOCH 8: training on 99524 raw words (60458 effective words) took 0.1s, 446592 effective words/s\n",
      "2023-12-06 14:33:19,639 : INFO : EPOCH 9: training on 99524 raw words (60397 effective words) took 0.1s, 424793 effective words/s\n",
      "2023-12-06 14:33:19,639 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603783 effective words) took 1.5s, 416355 effective words/s', 'datetime': '2023-12-06T14:33:19.639353', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:33:19,640 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:33:19.640353', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 27%|       | 129/486 [19:40<35:45,  6.01s/it]2023-12-06 14:33:22,233 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:33:22,234 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:33:22,255 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:33:22,255 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:33:22,260 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:33:22.260883', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:33:22,260 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:33:22.260883', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:33:22,265 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:33:22,266 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:33:22,266 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:33:22.266401', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:33:22,276 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:33:22,277 : INFO : resetting layer weights\n",
      "2023-12-06 14:33:22,279 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:33:22.279262', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:33:22,431 : INFO : EPOCH 0: training on 99524 raw words (60264 effective words) took 0.1s, 403476 effective words/s\n",
      "2023-12-06 14:33:22,573 : INFO : EPOCH 1: training on 99524 raw words (60459 effective words) took 0.1s, 443707 effective words/s\n",
      "2023-12-06 14:33:22,719 : INFO : EPOCH 2: training on 99524 raw words (60490 effective words) took 0.1s, 431140 effective words/s\n",
      "2023-12-06 14:33:22,865 : INFO : EPOCH 3: training on 99524 raw words (60160 effective words) took 0.1s, 423317 effective words/s\n",
      "2023-12-06 14:33:23,004 : INFO : EPOCH 4: training on 99524 raw words (60284 effective words) took 0.1s, 447209 effective words/s\n",
      "2023-12-06 14:33:23,144 : INFO : EPOCH 5: training on 99524 raw words (60326 effective words) took 0.1s, 445267 effective words/s\n",
      "2023-12-06 14:33:23,289 : INFO : EPOCH 6: training on 99524 raw words (60549 effective words) took 0.1s, 429579 effective words/s\n",
      "2023-12-06 14:33:23,430 : INFO : EPOCH 7: training on 99524 raw words (60469 effective words) took 0.1s, 442764 effective words/s\n",
      "2023-12-06 14:33:23,569 : INFO : EPOCH 8: training on 99524 raw words (60445 effective words) took 0.1s, 448602 effective words/s\n",
      "2023-12-06 14:33:23,714 : INFO : EPOCH 9: training on 99524 raw words (60345 effective words) took 0.1s, 428633 effective words/s\n",
      "2023-12-06 14:33:23,854 : INFO : EPOCH 10: training on 99524 raw words (60330 effective words) took 0.1s, 443312 effective words/s\n",
      "2023-12-06 14:33:23,996 : INFO : EPOCH 11: training on 99524 raw words (60469 effective words) took 0.1s, 442523 effective words/s\n",
      "2023-12-06 14:33:24,142 : INFO : EPOCH 12: training on 99524 raw words (60451 effective words) took 0.1s, 423569 effective words/s\n",
      "2023-12-06 14:33:24,282 : INFO : EPOCH 13: training on 99524 raw words (60365 effective words) took 0.1s, 446414 effective words/s\n",
      "2023-12-06 14:33:24,420 : INFO : EPOCH 14: training on 99524 raw words (60472 effective words) took 0.1s, 452433 effective words/s\n",
      "2023-12-06 14:33:24,565 : INFO : EPOCH 15: training on 99524 raw words (60392 effective words) took 0.1s, 429465 effective words/s\n",
      "2023-12-06 14:33:24,704 : INFO : EPOCH 16: training on 99524 raw words (60302 effective words) took 0.1s, 449642 effective words/s\n",
      "2023-12-06 14:33:24,847 : INFO : EPOCH 17: training on 99524 raw words (60275 effective words) took 0.1s, 433760 effective words/s\n",
      "2023-12-06 14:33:24,999 : INFO : EPOCH 18: training on 99524 raw words (60381 effective words) took 0.1s, 407602 effective words/s\n",
      "2023-12-06 14:33:25,140 : INFO : EPOCH 19: training on 99524 raw words (60357 effective words) took 0.1s, 444143 effective words/s\n",
      "2023-12-06 14:33:25,281 : INFO : EPOCH 20: training on 99524 raw words (60288 effective words) took 0.1s, 443102 effective words/s\n",
      "2023-12-06 14:33:25,429 : INFO : EPOCH 21: training on 99524 raw words (60405 effective words) took 0.1s, 417912 effective words/s\n",
      "2023-12-06 14:33:25,569 : INFO : EPOCH 22: training on 99524 raw words (60551 effective words) took 0.1s, 447937 effective words/s\n",
      "2023-12-06 14:33:25,707 : INFO : EPOCH 23: training on 99524 raw words (60481 effective words) took 0.1s, 448406 effective words/s\n",
      "2023-12-06 14:33:25,856 : INFO : EPOCH 24: training on 99524 raw words (60492 effective words) took 0.1s, 421933 effective words/s\n",
      "2023-12-06 14:33:25,997 : INFO : EPOCH 25: training on 99524 raw words (60209 effective words) took 0.1s, 437672 effective words/s\n",
      "2023-12-06 14:33:26,139 : INFO : EPOCH 26: training on 99524 raw words (60541 effective words) took 0.1s, 442909 effective words/s\n",
      "2023-12-06 14:33:26,286 : INFO : EPOCH 27: training on 99524 raw words (60598 effective words) took 0.1s, 421698 effective words/s\n",
      "2023-12-06 14:33:26,427 : INFO : EPOCH 28: training on 99524 raw words (60413 effective words) took 0.1s, 446038 effective words/s\n",
      "2023-12-06 14:33:26,565 : INFO : EPOCH 29: training on 99524 raw words (60516 effective words) took 0.1s, 449791 effective words/s\n",
      "2023-12-06 14:33:26,566 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812079 effective words) took 4.3s, 422671 effective words/s', 'datetime': '2023-12-06T14:33:26.566847', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:33:26,567 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:33:26.567847', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 27%|       | 130/486 [19:48<37:39,  6.35s/it]2023-12-06 14:33:29,368 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:33:29,368 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:33:29,388 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:33:29,389 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:33:29,395 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:33:29.394648', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:33:29,395 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:33:29.395648', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:33:29,400 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:33:29,401 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:33:29,401 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:33:29.401660', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:33:29,407 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:33:29,408 : INFO : resetting layer weights\n",
      "2023-12-06 14:33:29,410 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:33:29.410665', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:33:29,556 : INFO : EPOCH 0: training on 99524 raw words (60421 effective words) took 0.1s, 424871 effective words/s\n",
      "2023-12-06 14:33:29,699 : INFO : EPOCH 1: training on 99524 raw words (60581 effective words) took 0.1s, 438135 effective words/s\n",
      "2023-12-06 14:33:29,851 : INFO : EPOCH 2: training on 99524 raw words (60334 effective words) took 0.1s, 410411 effective words/s\n",
      "2023-12-06 14:33:29,998 : INFO : EPOCH 3: training on 99524 raw words (60262 effective words) took 0.1s, 421634 effective words/s\n",
      "2023-12-06 14:33:30,144 : INFO : EPOCH 4: training on 99524 raw words (60435 effective words) took 0.1s, 429306 effective words/s\n",
      "2023-12-06 14:33:30,288 : INFO : EPOCH 5: training on 99524 raw words (60398 effective words) took 0.1s, 431485 effective words/s\n",
      "2023-12-06 14:33:30,435 : INFO : EPOCH 6: training on 99524 raw words (60355 effective words) took 0.1s, 423379 effective words/s\n",
      "2023-12-06 14:33:30,577 : INFO : EPOCH 7: training on 99524 raw words (60432 effective words) took 0.1s, 440527 effective words/s\n",
      "2023-12-06 14:33:30,720 : INFO : EPOCH 8: training on 99524 raw words (60393 effective words) took 0.1s, 437693 effective words/s\n",
      "2023-12-06 14:33:30,869 : INFO : EPOCH 9: training on 99524 raw words (60361 effective words) took 0.1s, 417917 effective words/s\n",
      "2023-12-06 14:33:31,011 : INFO : EPOCH 10: training on 99524 raw words (60419 effective words) took 0.1s, 441616 effective words/s\n",
      "2023-12-06 14:33:31,152 : INFO : EPOCH 11: training on 99524 raw words (60568 effective words) took 0.1s, 438737 effective words/s\n",
      "2023-12-06 14:33:31,300 : INFO : EPOCH 12: training on 99524 raw words (60434 effective words) took 0.1s, 419258 effective words/s\n",
      "2023-12-06 14:33:31,441 : INFO : EPOCH 13: training on 99524 raw words (60543 effective words) took 0.1s, 444442 effective words/s\n",
      "2023-12-06 14:33:31,588 : INFO : EPOCH 14: training on 99524 raw words (60302 effective words) took 0.1s, 423185 effective words/s\n",
      "2023-12-06 14:33:31,731 : INFO : EPOCH 15: training on 99524 raw words (60409 effective words) took 0.1s, 436974 effective words/s\n",
      "2023-12-06 14:33:31,874 : INFO : EPOCH 16: training on 99524 raw words (60410 effective words) took 0.1s, 439139 effective words/s\n",
      "2023-12-06 14:33:32,020 : INFO : EPOCH 17: training on 99524 raw words (60308 effective words) took 0.1s, 424446 effective words/s\n",
      "2023-12-06 14:33:32,162 : INFO : EPOCH 18: training on 99524 raw words (60349 effective words) took 0.1s, 438723 effective words/s\n",
      "2023-12-06 14:33:32,304 : INFO : EPOCH 19: training on 99524 raw words (60375 effective words) took 0.1s, 437848 effective words/s\n",
      "2023-12-06 14:33:32,458 : INFO : EPOCH 20: training on 99524 raw words (60352 effective words) took 0.2s, 401730 effective words/s\n",
      "2023-12-06 14:33:32,602 : INFO : EPOCH 21: training on 99524 raw words (60604 effective words) took 0.1s, 435464 effective words/s\n",
      "2023-12-06 14:33:32,745 : INFO : EPOCH 22: training on 99524 raw words (60489 effective words) took 0.1s, 439191 effective words/s\n",
      "2023-12-06 14:33:32,896 : INFO : EPOCH 23: training on 99524 raw words (60446 effective words) took 0.1s, 412416 effective words/s\n",
      "2023-12-06 14:33:33,040 : INFO : EPOCH 24: training on 99524 raw words (60605 effective words) took 0.1s, 431664 effective words/s\n",
      "2023-12-06 14:33:33,183 : INFO : EPOCH 25: training on 99524 raw words (60336 effective words) took 0.1s, 437714 effective words/s\n",
      "2023-12-06 14:33:33,329 : INFO : EPOCH 26: training on 99524 raw words (60583 effective words) took 0.1s, 427073 effective words/s\n",
      "2023-12-06 14:33:33,473 : INFO : EPOCH 27: training on 99524 raw words (60488 effective words) took 0.1s, 432052 effective words/s\n",
      "2023-12-06 14:33:33,617 : INFO : EPOCH 28: training on 99524 raw words (60327 effective words) took 0.1s, 435231 effective words/s\n",
      "2023-12-06 14:33:33,766 : INFO : EPOCH 29: training on 99524 raw words (60402 effective words) took 0.1s, 416574 effective words/s\n",
      "2023-12-06 14:33:33,767 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812721 effective words) took 4.4s, 416168 effective words/s', 'datetime': '2023-12-06T14:33:33.767290', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:33:33,767 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:33:33.767290', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 27%|       | 131/486 [19:55<39:19,  6.65s/it]2023-12-06 14:33:36,714 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:33:36,715 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:33:36,735 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:33:36,735 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:33:36,740 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:33:36.740858', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:33:36,741 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:33:36.741858', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:33:36,747 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:33:36,747 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:33:36,748 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:33:36.748374', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:33:36,755 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:33:36,756 : INFO : resetting layer weights\n",
      "2023-12-06 14:33:36,758 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:33:36.758125', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:33:36,914 : INFO : EPOCH 0: training on 99524 raw words (60363 effective words) took 0.2s, 395347 effective words/s\n",
      "2023-12-06 14:33:37,055 : INFO : EPOCH 1: training on 99524 raw words (60497 effective words) took 0.1s, 449663 effective words/s\n",
      "2023-12-06 14:33:37,204 : INFO : EPOCH 2: training on 99524 raw words (60449 effective words) took 0.1s, 419342 effective words/s\n",
      "2023-12-06 14:33:37,344 : INFO : EPOCH 3: training on 99524 raw words (60177 effective words) took 0.1s, 443234 effective words/s\n",
      "2023-12-06 14:33:37,484 : INFO : EPOCH 4: training on 99524 raw words (60374 effective words) took 0.1s, 445730 effective words/s\n",
      "2023-12-06 14:33:37,633 : INFO : EPOCH 5: training on 99524 raw words (60287 effective words) took 0.1s, 416673 effective words/s\n",
      "2023-12-06 14:33:37,773 : INFO : EPOCH 6: training on 99524 raw words (60387 effective words) took 0.1s, 443118 effective words/s\n",
      "2023-12-06 14:33:37,913 : INFO : EPOCH 7: training on 99524 raw words (60459 effective words) took 0.1s, 446440 effective words/s\n",
      "2023-12-06 14:33:38,060 : INFO : EPOCH 8: training on 99524 raw words (60386 effective words) took 0.1s, 422214 effective words/s\n",
      "2023-12-06 14:33:38,201 : INFO : EPOCH 9: training on 99524 raw words (60282 effective words) took 0.1s, 444198 effective words/s\n",
      "2023-12-06 14:33:38,341 : INFO : EPOCH 10: training on 99524 raw words (60405 effective words) took 0.1s, 448042 effective words/s\n",
      "2023-12-06 14:33:38,486 : INFO : EPOCH 11: training on 99524 raw words (60464 effective words) took 0.1s, 426470 effective words/s\n",
      "2023-12-06 14:33:38,627 : INFO : EPOCH 12: training on 99524 raw words (60376 effective words) took 0.1s, 444334 effective words/s\n",
      "2023-12-06 14:33:38,768 : INFO : EPOCH 13: training on 99524 raw words (60380 effective words) took 0.1s, 440769 effective words/s\n",
      "2023-12-06 14:33:38,915 : INFO : EPOCH 14: training on 99524 raw words (60404 effective words) took 0.1s, 426877 effective words/s\n",
      "2023-12-06 14:33:39,056 : INFO : EPOCH 15: training on 99524 raw words (60429 effective words) took 0.1s, 441103 effective words/s\n",
      "2023-12-06 14:33:39,195 : INFO : EPOCH 16: training on 99524 raw words (60419 effective words) took 0.1s, 448521 effective words/s\n",
      "2023-12-06 14:33:39,339 : INFO : EPOCH 17: training on 99524 raw words (60219 effective words) took 0.1s, 429603 effective words/s\n",
      "2023-12-06 14:33:39,490 : INFO : EPOCH 18: training on 99524 raw words (60492 effective words) took 0.1s, 415303 effective words/s\n",
      "2023-12-06 14:33:39,628 : INFO : EPOCH 19: training on 99524 raw words (60476 effective words) took 0.1s, 452664 effective words/s\n",
      "2023-12-06 14:33:39,773 : INFO : EPOCH 20: training on 99524 raw words (60428 effective words) took 0.1s, 431381 effective words/s\n",
      "2023-12-06 14:33:39,914 : INFO : EPOCH 21: training on 99524 raw words (60489 effective words) took 0.1s, 442035 effective words/s\n",
      "2023-12-06 14:33:40,053 : INFO : EPOCH 22: training on 99524 raw words (60477 effective words) took 0.1s, 449758 effective words/s\n",
      "2023-12-06 14:33:40,199 : INFO : EPOCH 23: training on 99524 raw words (60465 effective words) took 0.1s, 430208 effective words/s\n",
      "2023-12-06 14:33:40,338 : INFO : EPOCH 24: training on 99524 raw words (60442 effective words) took 0.1s, 445692 effective words/s\n",
      "2023-12-06 14:33:40,479 : INFO : EPOCH 25: training on 99524 raw words (60215 effective words) took 0.1s, 443848 effective words/s\n",
      "2023-12-06 14:33:40,624 : INFO : EPOCH 26: training on 99524 raw words (60668 effective words) took 0.1s, 427521 effective words/s\n",
      "2023-12-06 14:33:40,767 : INFO : EPOCH 27: training on 99524 raw words (60474 effective words) took 0.1s, 439372 effective words/s\n",
      "2023-12-06 14:33:40,906 : INFO : EPOCH 28: training on 99524 raw words (60418 effective words) took 0.1s, 449757 effective words/s\n",
      "2023-12-06 14:33:41,052 : INFO : EPOCH 29: training on 99524 raw words (60344 effective words) took 0.1s, 425466 effective words/s\n",
      "2023-12-06 14:33:41,053 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812145 effective words) took 4.3s, 421939 effective words/s', 'datetime': '2023-12-06T14:33:41.053490', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:33:41,054 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:33:41.054489', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 27%|       | 132/486 [20:02<40:36,  6.88s/it]2023-12-06 14:33:44,144 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:33:44,145 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:33:44,165 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:33:44,165 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:33:44,169 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:33:44.169993', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:33:44,169 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:33:44.169993', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:33:44,174 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:33:44,175 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:33:44,175 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:33:44.175875', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:33:44,185 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:33:44,186 : INFO : resetting layer weights\n",
      "2023-12-06 14:33:44,187 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:33:44.187876', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:33:44,335 : INFO : EPOCH 0: training on 99524 raw words (60408 effective words) took 0.1s, 419993 effective words/s\n",
      "2023-12-06 14:33:44,487 : INFO : EPOCH 1: training on 99524 raw words (60522 effective words) took 0.1s, 415471 effective words/s\n",
      "2023-12-06 14:33:44,626 : INFO : EPOCH 2: training on 99524 raw words (60351 effective words) took 0.1s, 447897 effective words/s\n",
      "2023-12-06 14:33:44,772 : INFO : EPOCH 3: training on 99524 raw words (60218 effective words) took 0.1s, 424222 effective words/s\n",
      "2023-12-06 14:33:44,913 : INFO : EPOCH 4: training on 99524 raw words (60385 effective words) took 0.1s, 442841 effective words/s\n",
      "2023-12-06 14:33:45,057 : INFO : EPOCH 5: training on 99524 raw words (60377 effective words) took 0.1s, 433584 effective words/s\n",
      "2023-12-06 14:33:45,203 : INFO : EPOCH 6: training on 99524 raw words (60397 effective words) took 0.1s, 426203 effective words/s\n",
      "2023-12-06 14:33:45,345 : INFO : EPOCH 7: training on 99524 raw words (60446 effective words) took 0.1s, 440480 effective words/s\n",
      "2023-12-06 14:33:45,484 : INFO : EPOCH 8: training on 99524 raw words (60367 effective words) took 0.1s, 444238 effective words/s\n",
      "2023-12-06 14:33:45,631 : INFO : EPOCH 9: training on 99524 raw words (60350 effective words) took 0.1s, 425017 effective words/s\n",
      "2023-12-06 14:33:45,771 : INFO : EPOCH 10: training on 99524 raw words (60359 effective words) took 0.1s, 442881 effective words/s\n",
      "2023-12-06 14:33:45,913 : INFO : EPOCH 11: training on 99524 raw words (60388 effective words) took 0.1s, 443347 effective words/s\n",
      "2023-12-06 14:33:46,055 : INFO : EPOCH 12: training on 99524 raw words (60393 effective words) took 0.1s, 435045 effective words/s\n",
      "2023-12-06 14:33:46,196 : INFO : EPOCH 13: training on 99524 raw words (60439 effective words) took 0.1s, 443781 effective words/s\n",
      "2023-12-06 14:33:46,335 : INFO : EPOCH 14: training on 99524 raw words (60390 effective words) took 0.1s, 450361 effective words/s\n",
      "2023-12-06 14:33:46,479 : INFO : EPOCH 15: training on 99524 raw words (60343 effective words) took 0.1s, 428621 effective words/s\n",
      "2023-12-06 14:33:46,619 : INFO : EPOCH 16: training on 99524 raw words (60253 effective words) took 0.1s, 444138 effective words/s\n",
      "2023-12-06 14:33:46,757 : INFO : EPOCH 17: training on 99524 raw words (60317 effective words) took 0.1s, 447411 effective words/s\n",
      "2023-12-06 14:33:46,910 : INFO : EPOCH 18: training on 99524 raw words (60361 effective words) took 0.1s, 409572 effective words/s\n",
      "2023-12-06 14:33:47,049 : INFO : EPOCH 19: training on 99524 raw words (60336 effective words) took 0.1s, 449886 effective words/s\n",
      "2023-12-06 14:33:47,188 : INFO : EPOCH 20: training on 99524 raw words (60365 effective words) took 0.1s, 448352 effective words/s\n",
      "2023-12-06 14:33:47,333 : INFO : EPOCH 21: training on 99524 raw words (60327 effective words) took 0.1s, 426413 effective words/s\n",
      "2023-12-06 14:33:47,473 : INFO : EPOCH 22: training on 99524 raw words (60416 effective words) took 0.1s, 447352 effective words/s\n",
      "2023-12-06 14:33:47,613 : INFO : EPOCH 23: training on 99524 raw words (60428 effective words) took 0.1s, 443695 effective words/s\n",
      "2023-12-06 14:33:47,759 : INFO : EPOCH 24: training on 99524 raw words (60484 effective words) took 0.1s, 427542 effective words/s\n",
      "2023-12-06 14:33:47,901 : INFO : EPOCH 25: training on 99524 raw words (60287 effective words) took 0.1s, 437520 effective words/s\n",
      "2023-12-06 14:33:48,041 : INFO : EPOCH 26: training on 99524 raw words (60423 effective words) took 0.1s, 447091 effective words/s\n",
      "2023-12-06 14:33:48,187 : INFO : EPOCH 27: training on 99524 raw words (60367 effective words) took 0.1s, 426522 effective words/s\n",
      "2023-12-06 14:33:48,331 : INFO : EPOCH 28: training on 99524 raw words (60374 effective words) took 0.1s, 433401 effective words/s\n",
      "2023-12-06 14:33:48,470 : INFO : EPOCH 29: training on 99524 raw words (60501 effective words) took 0.1s, 447717 effective words/s\n",
      "2023-12-06 14:33:48,615 : INFO : EPOCH 30: training on 99524 raw words (60245 effective words) took 0.1s, 425683 effective words/s\n",
      "2023-12-06 14:33:48,756 : INFO : EPOCH 31: training on 99524 raw words (60350 effective words) took 0.1s, 444722 effective words/s\n",
      "2023-12-06 14:33:48,893 : INFO : EPOCH 32: training on 99524 raw words (60403 effective words) took 0.1s, 451795 effective words/s\n",
      "2023-12-06 14:33:49,040 : INFO : EPOCH 33: training on 99524 raw words (60428 effective words) took 0.1s, 427618 effective words/s\n",
      "2023-12-06 14:33:49,180 : INFO : EPOCH 34: training on 99524 raw words (60447 effective words) took 0.1s, 446879 effective words/s\n",
      "2023-12-06 14:33:49,319 : INFO : EPOCH 35: training on 99524 raw words (60362 effective words) took 0.1s, 447820 effective words/s\n",
      "2023-12-06 14:33:49,471 : INFO : EPOCH 36: training on 99524 raw words (60333 effective words) took 0.1s, 405499 effective words/s\n",
      "2023-12-06 14:33:49,615 : INFO : EPOCH 37: training on 99524 raw words (60398 effective words) took 0.1s, 436706 effective words/s\n",
      "2023-12-06 14:33:49,754 : INFO : EPOCH 38: training on 99524 raw words (60395 effective words) took 0.1s, 445514 effective words/s\n",
      "2023-12-06 14:33:49,905 : INFO : EPOCH 39: training on 99524 raw words (60351 effective words) took 0.1s, 414490 effective words/s\n",
      "2023-12-06 14:33:50,045 : INFO : EPOCH 40: training on 99524 raw words (60376 effective words) took 0.1s, 445674 effective words/s\n",
      "2023-12-06 14:33:50,188 : INFO : EPOCH 41: training on 99524 raw words (60556 effective words) took 0.1s, 436255 effective words/s\n",
      "2023-12-06 14:33:50,333 : INFO : EPOCH 42: training on 99524 raw words (60367 effective words) took 0.1s, 429070 effective words/s\n",
      "2023-12-06 14:33:50,472 : INFO : EPOCH 43: training on 99524 raw words (60330 effective words) took 0.1s, 447786 effective words/s\n",
      "2023-12-06 14:33:50,612 : INFO : EPOCH 44: training on 99524 raw words (60332 effective words) took 0.1s, 441249 effective words/s\n",
      "2023-12-06 14:33:50,758 : INFO : EPOCH 45: training on 99524 raw words (60450 effective words) took 0.1s, 430469 effective words/s\n",
      "2023-12-06 14:33:50,898 : INFO : EPOCH 46: training on 99524 raw words (60261 effective words) took 0.1s, 444532 effective words/s\n",
      "2023-12-06 14:33:51,038 : INFO : EPOCH 47: training on 99524 raw words (60268 effective words) took 0.1s, 441832 effective words/s\n",
      "2023-12-06 14:33:51,184 : INFO : EPOCH 48: training on 99524 raw words (60368 effective words) took 0.1s, 426686 effective words/s\n",
      "2023-12-06 14:33:51,326 : INFO : EPOCH 49: training on 99524 raw words (60361 effective words) took 0.1s, 440032 effective words/s\n",
      "2023-12-06 14:33:51,327 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3018753 effective words) took 7.1s, 422904 effective words/s', 'datetime': '2023-12-06T14:33:51.327686', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:33:51,327 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:33:51.327686', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 27%|       | 133/486 [20:13<46:28,  7.90s/it]2023-12-06 14:33:54,423 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:33:54,423 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:33:54,443 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:33:54,444 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:33:54,448 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:33:54.448492', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:33:54,448 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:33:54.448492', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:33:54,454 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:33:54,455 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:33:54,455 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:33:54.455696', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:33:54,463 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:33:54,463 : INFO : resetting layer weights\n",
      "2023-12-06 14:33:54,465 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:33:54.465406', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:33:54,619 : INFO : EPOCH 0: training on 99524 raw words (60288 effective words) took 0.1s, 402387 effective words/s\n",
      "2023-12-06 14:33:54,765 : INFO : EPOCH 1: training on 99524 raw words (60483 effective words) took 0.1s, 427905 effective words/s\n",
      "2023-12-06 14:33:54,909 : INFO : EPOCH 2: training on 99524 raw words (60362 effective words) took 0.1s, 431927 effective words/s\n",
      "2023-12-06 14:33:55,056 : INFO : EPOCH 3: training on 99524 raw words (60255 effective words) took 0.1s, 421143 effective words/s\n",
      "2023-12-06 14:33:55,199 : INFO : EPOCH 4: training on 99524 raw words (60468 effective words) took 0.1s, 439049 effective words/s\n",
      "2023-12-06 14:33:55,342 : INFO : EPOCH 5: training on 99524 raw words (60319 effective words) took 0.1s, 436628 effective words/s\n",
      "2023-12-06 14:33:55,488 : INFO : EPOCH 6: training on 99524 raw words (60450 effective words) took 0.1s, 427006 effective words/s\n",
      "2023-12-06 14:33:55,631 : INFO : EPOCH 7: training on 99524 raw words (60342 effective words) took 0.1s, 436601 effective words/s\n",
      "2023-12-06 14:33:55,772 : INFO : EPOCH 8: training on 99524 raw words (60423 effective words) took 0.1s, 440663 effective words/s\n",
      "2023-12-06 14:33:55,919 : INFO : EPOCH 9: training on 99524 raw words (60467 effective words) took 0.1s, 423271 effective words/s\n",
      "2023-12-06 14:33:56,061 : INFO : EPOCH 10: training on 99524 raw words (60476 effective words) took 0.1s, 440974 effective words/s\n",
      "2023-12-06 14:33:56,201 : INFO : EPOCH 11: training on 99524 raw words (60605 effective words) took 0.1s, 446521 effective words/s\n",
      "2023-12-06 14:33:56,352 : INFO : EPOCH 12: training on 99524 raw words (60421 effective words) took 0.1s, 412186 effective words/s\n",
      "2023-12-06 14:33:56,497 : INFO : EPOCH 13: training on 99524 raw words (60324 effective words) took 0.1s, 431352 effective words/s\n",
      "2023-12-06 14:33:56,637 : INFO : EPOCH 14: training on 99524 raw words (60358 effective words) took 0.1s, 444606 effective words/s\n",
      "2023-12-06 14:33:56,785 : INFO : EPOCH 15: training on 99524 raw words (60271 effective words) took 0.1s, 420957 effective words/s\n",
      "2023-12-06 14:33:56,927 : INFO : EPOCH 16: training on 99524 raw words (60490 effective words) took 0.1s, 440400 effective words/s\n",
      "2023-12-06 14:33:57,076 : INFO : EPOCH 17: training on 99524 raw words (60305 effective words) took 0.1s, 414475 effective words/s\n",
      "2023-12-06 14:33:57,224 : INFO : EPOCH 18: training on 99524 raw words (60333 effective words) took 0.1s, 421708 effective words/s\n",
      "2023-12-06 14:33:57,367 : INFO : EPOCH 19: training on 99524 raw words (60487 effective words) took 0.1s, 436101 effective words/s\n",
      "2023-12-06 14:33:57,509 : INFO : EPOCH 20: training on 99524 raw words (60474 effective words) took 0.1s, 440716 effective words/s\n",
      "2023-12-06 14:33:57,661 : INFO : EPOCH 21: training on 99524 raw words (60378 effective words) took 0.1s, 408390 effective words/s\n",
      "2023-12-06 14:33:57,802 : INFO : EPOCH 22: training on 99524 raw words (60458 effective words) took 0.1s, 438870 effective words/s\n",
      "2023-12-06 14:33:57,943 : INFO : EPOCH 23: training on 99524 raw words (60518 effective words) took 0.1s, 444491 effective words/s\n",
      "2023-12-06 14:33:58,089 : INFO : EPOCH 24: training on 99524 raw words (60447 effective words) took 0.1s, 424805 effective words/s\n",
      "2023-12-06 14:33:58,231 : INFO : EPOCH 25: training on 99524 raw words (60345 effective words) took 0.1s, 439712 effective words/s\n",
      "2023-12-06 14:33:58,371 : INFO : EPOCH 26: training on 99524 raw words (60366 effective words) took 0.1s, 445898 effective words/s\n",
      "2023-12-06 14:33:58,518 : INFO : EPOCH 27: training on 99524 raw words (60611 effective words) took 0.1s, 422719 effective words/s\n",
      "2023-12-06 14:33:58,663 : INFO : EPOCH 28: training on 99524 raw words (60486 effective words) took 0.1s, 433701 effective words/s\n",
      "2023-12-06 14:33:58,806 : INFO : EPOCH 29: training on 99524 raw words (60445 effective words) took 0.1s, 438647 effective words/s\n",
      "2023-12-06 14:33:58,953 : INFO : EPOCH 30: training on 99524 raw words (60302 effective words) took 0.1s, 421433 effective words/s\n",
      "2023-12-06 14:33:59,095 : INFO : EPOCH 31: training on 99524 raw words (60323 effective words) took 0.1s, 437194 effective words/s\n",
      "2023-12-06 14:33:59,238 : INFO : EPOCH 32: training on 99524 raw words (60538 effective words) took 0.1s, 441582 effective words/s\n",
      "2023-12-06 14:33:59,385 : INFO : EPOCH 33: training on 99524 raw words (60550 effective words) took 0.1s, 422364 effective words/s\n",
      "2023-12-06 14:33:59,535 : INFO : EPOCH 34: training on 99524 raw words (60452 effective words) took 0.1s, 417008 effective words/s\n",
      "2023-12-06 14:33:59,676 : INFO : EPOCH 35: training on 99524 raw words (60579 effective words) took 0.1s, 441032 effective words/s\n",
      "2023-12-06 14:33:59,826 : INFO : EPOCH 36: training on 99524 raw words (60289 effective words) took 0.1s, 412914 effective words/s\n",
      "2023-12-06 14:33:59,986 : INFO : EPOCH 37: training on 99524 raw words (60242 effective words) took 0.2s, 389542 effective words/s\n",
      "2023-12-06 14:34:00,140 : INFO : EPOCH 38: training on 99524 raw words (60253 effective words) took 0.1s, 404258 effective words/s\n",
      "2023-12-06 14:34:00,289 : INFO : EPOCH 39: training on 99524 raw words (60369 effective words) took 0.1s, 418644 effective words/s\n",
      "2023-12-06 14:34:00,436 : INFO : EPOCH 40: training on 99524 raw words (60331 effective words) took 0.1s, 421010 effective words/s\n",
      "2023-12-06 14:34:00,579 : INFO : EPOCH 41: training on 99524 raw words (60637 effective words) took 0.1s, 436509 effective words/s\n",
      "2023-12-06 14:34:00,729 : INFO : EPOCH 42: training on 99524 raw words (60553 effective words) took 0.1s, 419860 effective words/s\n",
      "2023-12-06 14:34:00,871 : INFO : EPOCH 43: training on 99524 raw words (60402 effective words) took 0.1s, 438318 effective words/s\n",
      "2023-12-06 14:34:01,013 : INFO : EPOCH 44: training on 99524 raw words (60328 effective words) took 0.1s, 439011 effective words/s\n",
      "2023-12-06 14:34:01,161 : INFO : EPOCH 45: training on 99524 raw words (60304 effective words) took 0.1s, 417595 effective words/s\n",
      "2023-12-06 14:34:01,305 : INFO : EPOCH 46: training on 99524 raw words (60387 effective words) took 0.1s, 435996 effective words/s\n",
      "2023-12-06 14:34:01,446 : INFO : EPOCH 47: training on 99524 raw words (60360 effective words) took 0.1s, 440195 effective words/s\n",
      "2023-12-06 14:34:01,595 : INFO : EPOCH 48: training on 99524 raw words (60347 effective words) took 0.1s, 420325 effective words/s\n",
      "2023-12-06 14:34:01,739 : INFO : EPOCH 49: training on 99524 raw words (60313 effective words) took 0.1s, 430026 effective words/s\n",
      "2023-12-06 14:34:01,739 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3020314 effective words) took 7.3s, 415215 effective words/s', 'datetime': '2023-12-06T14:34:01.739877', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:34:01,740 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:34:01.740877', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 28%|       | 134/486 [20:23<51:11,  8.73s/it]2023-12-06 14:34:05,078 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:34:05,079 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:34:05,109 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:34:05,109 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:34:05,115 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:34:05.115915', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:34:05,115 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:34:05.115915', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:34:05,123 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:34:05,125 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:34:05,125 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:34:05.125025', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:34:05,135 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:34:05,136 : INFO : resetting layer weights\n",
      "2023-12-06 14:34:05,138 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:34:05.138618', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:34:05,289 : INFO : EPOCH 0: training on 99524 raw words (60413 effective words) took 0.1s, 408796 effective words/s\n",
      "2023-12-06 14:34:05,434 : INFO : EPOCH 1: training on 99524 raw words (60455 effective words) took 0.1s, 431741 effective words/s\n",
      "2023-12-06 14:34:05,581 : INFO : EPOCH 2: training on 99524 raw words (60588 effective words) took 0.1s, 424540 effective words/s\n",
      "2023-12-06 14:34:05,726 : INFO : EPOCH 3: training on 99524 raw words (60460 effective words) took 0.1s, 428493 effective words/s\n",
      "2023-12-06 14:34:05,874 : INFO : EPOCH 4: training on 99524 raw words (60316 effective words) took 0.1s, 424708 effective words/s\n",
      "2023-12-06 14:34:06,020 : INFO : EPOCH 5: training on 99524 raw words (60329 effective words) took 0.1s, 427174 effective words/s\n",
      "2023-12-06 14:34:06,163 : INFO : EPOCH 6: training on 99524 raw words (60479 effective words) took 0.1s, 435011 effective words/s\n",
      "2023-12-06 14:34:06,309 : INFO : EPOCH 7: training on 99524 raw words (60494 effective words) took 0.1s, 429620 effective words/s\n",
      "2023-12-06 14:34:06,455 : INFO : EPOCH 8: training on 99524 raw words (60426 effective words) took 0.1s, 426766 effective words/s\n",
      "2023-12-06 14:34:06,596 : INFO : EPOCH 9: training on 99524 raw words (60371 effective words) took 0.1s, 444013 effective words/s\n",
      "2023-12-06 14:34:06,735 : INFO : EPOCH 10: training on 99524 raw words (60230 effective words) took 0.1s, 444685 effective words/s\n",
      "2023-12-06 14:34:06,884 : INFO : EPOCH 11: training on 99524 raw words (60467 effective words) took 0.1s, 423208 effective words/s\n",
      "2023-12-06 14:34:07,025 : INFO : EPOCH 12: training on 99524 raw words (60320 effective words) took 0.1s, 443131 effective words/s\n",
      "2023-12-06 14:34:07,166 : INFO : EPOCH 13: training on 99524 raw words (60364 effective words) took 0.1s, 439478 effective words/s\n",
      "2023-12-06 14:34:07,313 : INFO : EPOCH 14: training on 99524 raw words (60311 effective words) took 0.1s, 424574 effective words/s\n",
      "2023-12-06 14:34:07,453 : INFO : EPOCH 15: training on 99524 raw words (60400 effective words) took 0.1s, 444926 effective words/s\n",
      "2023-12-06 14:34:07,602 : INFO : EPOCH 16: training on 99524 raw words (60416 effective words) took 0.1s, 416388 effective words/s\n",
      "2023-12-06 14:34:07,756 : INFO : EPOCH 17: training on 99524 raw words (60281 effective words) took 0.2s, 401414 effective words/s\n",
      "2023-12-06 14:34:07,915 : INFO : EPOCH 18: training on 99524 raw words (60390 effective words) took 0.2s, 393484 effective words/s\n",
      "2023-12-06 14:34:08,077 : INFO : EPOCH 19: training on 99524 raw words (60393 effective words) took 0.2s, 382726 effective words/s\n",
      "2023-12-06 14:34:08,228 : INFO : EPOCH 20: training on 99524 raw words (60348 effective words) took 0.1s, 415958 effective words/s\n",
      "2023-12-06 14:34:08,370 : INFO : EPOCH 21: training on 99524 raw words (60477 effective words) took 0.1s, 441033 effective words/s\n",
      "2023-12-06 14:34:08,512 : INFO : EPOCH 22: training on 99524 raw words (60516 effective words) took 0.1s, 439374 effective words/s\n",
      "2023-12-06 14:34:08,657 : INFO : EPOCH 23: training on 99524 raw words (60456 effective words) took 0.1s, 427753 effective words/s\n",
      "2023-12-06 14:34:08,800 : INFO : EPOCH 24: training on 99524 raw words (60531 effective words) took 0.1s, 441155 effective words/s\n",
      "2023-12-06 14:34:08,941 : INFO : EPOCH 25: training on 99524 raw words (60192 effective words) took 0.1s, 437865 effective words/s\n",
      "2023-12-06 14:34:09,087 : INFO : EPOCH 26: training on 99524 raw words (60564 effective words) took 0.1s, 430644 effective words/s\n",
      "2023-12-06 14:34:09,227 : INFO : EPOCH 27: training on 99524 raw words (60576 effective words) took 0.1s, 444766 effective words/s\n",
      "2023-12-06 14:34:09,370 : INFO : EPOCH 28: training on 99524 raw words (60381 effective words) took 0.1s, 433955 effective words/s\n",
      "2023-12-06 14:34:09,517 : INFO : EPOCH 29: training on 99524 raw words (60405 effective words) took 0.1s, 425716 effective words/s\n",
      "2023-12-06 14:34:09,657 : INFO : EPOCH 30: training on 99524 raw words (60458 effective words) took 0.1s, 445887 effective words/s\n",
      "2023-12-06 14:34:09,801 : INFO : EPOCH 31: training on 99524 raw words (60296 effective words) took 0.1s, 434544 effective words/s\n",
      "2023-12-06 14:34:09,949 : INFO : EPOCH 32: training on 99524 raw words (60249 effective words) took 0.1s, 419840 effective words/s\n",
      "2023-12-06 14:34:10,098 : INFO : EPOCH 33: training on 99524 raw words (60402 effective words) took 0.1s, 417920 effective words/s\n",
      "2023-12-06 14:34:10,241 : INFO : EPOCH 34: training on 99524 raw words (60481 effective words) took 0.1s, 436606 effective words/s\n",
      "2023-12-06 14:34:10,387 : INFO : EPOCH 35: training on 99524 raw words (60453 effective words) took 0.1s, 427746 effective words/s\n",
      "2023-12-06 14:34:10,527 : INFO : EPOCH 36: training on 99524 raw words (60343 effective words) took 0.1s, 442009 effective words/s\n",
      "2023-12-06 14:34:10,669 : INFO : EPOCH 37: training on 99524 raw words (60240 effective words) took 0.1s, 441024 effective words/s\n",
      "2023-12-06 14:34:10,818 : INFO : EPOCH 38: training on 99524 raw words (60407 effective words) took 0.1s, 414253 effective words/s\n",
      "2023-12-06 14:34:10,960 : INFO : EPOCH 39: training on 99524 raw words (60338 effective words) took 0.1s, 440479 effective words/s\n",
      "2023-12-06 14:34:11,102 : INFO : EPOCH 40: training on 99524 raw words (60293 effective words) took 0.1s, 438862 effective words/s\n",
      "2023-12-06 14:34:11,248 : INFO : EPOCH 41: training on 99524 raw words (60442 effective words) took 0.1s, 427362 effective words/s\n",
      "2023-12-06 14:34:11,388 : INFO : EPOCH 42: training on 99524 raw words (60563 effective words) took 0.1s, 446513 effective words/s\n",
      "2023-12-06 14:34:11,530 : INFO : EPOCH 43: training on 99524 raw words (60632 effective words) took 0.1s, 439467 effective words/s\n",
      "2023-12-06 14:34:11,677 : INFO : EPOCH 44: training on 99524 raw words (60365 effective words) took 0.1s, 424690 effective words/s\n",
      "2023-12-06 14:34:11,818 : INFO : EPOCH 45: training on 99524 raw words (60351 effective words) took 0.1s, 438192 effective words/s\n",
      "2023-12-06 14:34:11,965 : INFO : EPOCH 46: training on 99524 raw words (60429 effective words) took 0.1s, 427604 effective words/s\n",
      "2023-12-06 14:34:12,112 : INFO : EPOCH 47: training on 99524 raw words (60374 effective words) took 0.1s, 422304 effective words/s\n",
      "2023-12-06 14:34:12,252 : INFO : EPOCH 48: training on 99524 raw words (60497 effective words) took 0.1s, 445906 effective words/s\n",
      "2023-12-06 14:34:12,395 : INFO : EPOCH 49: training on 99524 raw words (60599 effective words) took 0.1s, 440131 effective words/s\n",
      "2023-12-06 14:34:12,396 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3020561 effective words) took 7.3s, 416198 effective words/s', 'datetime': '2023-12-06T14:34:12.396615', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:34:12,397 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:34:12.397902', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 28%|       | 135/486 [20:34<55:14,  9.44s/it]2023-12-06 14:34:16,193 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:34:16,194 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:34:16,225 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:34:16,225 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:34:16,233 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:34:16.233465', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:34:16,233 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:34:16.233465', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:34:16,242 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:34:16,244 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:34:16,245 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:34:16.245522', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:34:16,262 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:34:16,263 : INFO : resetting layer weights\n",
      "2023-12-06 14:34:16,265 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:34:16.265064', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:34:16,469 : INFO : EPOCH 0: training on 99524 raw words (65398 effective words) took 0.2s, 329359 effective words/s\n",
      "2023-12-06 14:34:16,623 : INFO : EPOCH 1: training on 99524 raw words (65689 effective words) took 0.1s, 449991 effective words/s\n",
      "2023-12-06 14:34:16,775 : INFO : EPOCH 2: training on 99524 raw words (65565 effective words) took 0.1s, 444911 effective words/s\n",
      "2023-12-06 14:34:16,918 : INFO : EPOCH 3: training on 99524 raw words (65360 effective words) took 0.1s, 474318 effective words/s\n",
      "2023-12-06 14:34:17,064 : INFO : EPOCH 4: training on 99524 raw words (65512 effective words) took 0.1s, 462195 effective words/s\n",
      "2023-12-06 14:34:17,208 : INFO : EPOCH 5: training on 99524 raw words (65400 effective words) took 0.1s, 470070 effective words/s\n",
      "2023-12-06 14:34:17,348 : INFO : EPOCH 6: training on 99524 raw words (65506 effective words) took 0.1s, 481073 effective words/s\n",
      "2023-12-06 14:34:17,497 : INFO : EPOCH 7: training on 99524 raw words (65662 effective words) took 0.1s, 453267 effective words/s\n",
      "2023-12-06 14:34:17,638 : INFO : EPOCH 8: training on 99524 raw words (65488 effective words) took 0.1s, 478084 effective words/s\n",
      "2023-12-06 14:34:17,780 : INFO : EPOCH 9: training on 99524 raw words (65609 effective words) took 0.1s, 476791 effective words/s\n",
      "2023-12-06 14:34:17,781 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655189 effective words) took 1.5s, 432327 effective words/s', 'datetime': '2023-12-06T14:34:17.781625', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:34:17,782 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:34:17.782624', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 28%|       | 136/486 [20:38<45:47,  7.85s/it]2023-12-06 14:34:20,326 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:34:20,326 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:34:20,346 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:34:20,346 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:34:20,353 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:34:20.353562', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:34:20,354 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:34:20.354567', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:34:20,363 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:34:20,364 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:34:20,365 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:34:20.365366', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:34:20,375 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:34:20,376 : INFO : resetting layer weights\n",
      "2023-12-06 14:34:20,377 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:34:20.377396', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:34:20,536 : INFO : EPOCH 0: training on 99524 raw words (65376 effective words) took 0.2s, 422124 effective words/s\n",
      "2023-12-06 14:34:20,683 : INFO : EPOCH 1: training on 99524 raw words (65627 effective words) took 0.1s, 461894 effective words/s\n",
      "2023-12-06 14:34:20,828 : INFO : EPOCH 2: training on 99524 raw words (65594 effective words) took 0.1s, 465367 effective words/s\n",
      "2023-12-06 14:34:20,986 : INFO : EPOCH 3: training on 99524 raw words (65513 effective words) took 0.2s, 427779 effective words/s\n",
      "2023-12-06 14:34:21,131 : INFO : EPOCH 4: training on 99524 raw words (65580 effective words) took 0.1s, 468195 effective words/s\n",
      "2023-12-06 14:34:21,278 : INFO : EPOCH 5: training on 99524 raw words (65478 effective words) took 0.1s, 458075 effective words/s\n",
      "2023-12-06 14:34:21,420 : INFO : EPOCH 6: training on 99524 raw words (65516 effective words) took 0.1s, 476886 effective words/s\n",
      "2023-12-06 14:34:21,563 : INFO : EPOCH 7: training on 99524 raw words (65582 effective words) took 0.1s, 470221 effective words/s\n",
      "2023-12-06 14:34:21,712 : INFO : EPOCH 8: training on 99524 raw words (65483 effective words) took 0.1s, 453637 effective words/s\n",
      "2023-12-06 14:34:21,855 : INFO : EPOCH 9: training on 99524 raw words (65450 effective words) took 0.1s, 472942 effective words/s\n",
      "2023-12-06 14:34:21,856 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655199 effective words) took 1.5s, 443318 effective words/s', 'datetime': '2023-12-06T14:34:21.856475', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:34:21,856 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:34:21.856475', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 28%|       | 137/486 [20:43<39:10,  6.74s/it]2023-12-06 14:34:24,459 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:34:24,460 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:34:24,482 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:34:24,483 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:34:24,490 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:34:24.490976', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:34:24,491 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:34:24.491978', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:34:24,502 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:34:24,502 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:34:24,503 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:34:24.503487', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:34:24,513 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:34:24,513 : INFO : resetting layer weights\n",
      "2023-12-06 14:34:24,515 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:34:24.515995', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:34:24,682 : INFO : EPOCH 0: training on 99524 raw words (65364 effective words) took 0.2s, 402811 effective words/s\n",
      "2023-12-06 14:34:24,826 : INFO : EPOCH 1: training on 99524 raw words (65597 effective words) took 0.1s, 477867 effective words/s\n",
      "2023-12-06 14:34:24,971 : INFO : EPOCH 2: training on 99524 raw words (65500 effective words) took 0.1s, 466147 effective words/s\n",
      "2023-12-06 14:34:25,118 : INFO : EPOCH 3: training on 99524 raw words (65516 effective words) took 0.1s, 459758 effective words/s\n",
      "2023-12-06 14:34:25,259 : INFO : EPOCH 4: training on 99524 raw words (65503 effective words) took 0.1s, 478650 effective words/s\n",
      "2023-12-06 14:34:25,399 : INFO : EPOCH 5: training on 99524 raw words (65672 effective words) took 0.1s, 481689 effective words/s\n",
      "2023-12-06 14:34:25,548 : INFO : EPOCH 6: training on 99524 raw words (65504 effective words) took 0.1s, 454349 effective words/s\n",
      "2023-12-06 14:34:25,689 : INFO : EPOCH 7: training on 99524 raw words (65417 effective words) took 0.1s, 479181 effective words/s\n",
      "2023-12-06 14:34:25,829 : INFO : EPOCH 8: training on 99524 raw words (65630 effective words) took 0.1s, 481691 effective words/s\n",
      "2023-12-06 14:34:25,977 : INFO : EPOCH 9: training on 99524 raw words (65462 effective words) took 0.1s, 460464 effective words/s\n",
      "2023-12-06 14:34:25,978 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655165 effective words) took 1.5s, 448435 effective words/s', 'datetime': '2023-12-06T14:34:25.978091', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:34:25,978 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:34:25.978091', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 28%|       | 138/486 [20:47<34:51,  6.01s/it]2023-12-06 14:34:28,773 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:34:28,773 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:34:28,798 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:34:28,800 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:34:28,808 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:34:28.808299', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:34:28,810 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:34:28.810300', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:34:28,819 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:34:28,821 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:34:28,822 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:34:28.822083', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:34:28,832 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:34:28,833 : INFO : resetting layer weights\n",
      "2023-12-06 14:34:28,835 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:34:28.835613', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:34:29,025 : INFO : EPOCH 0: training on 99524 raw words (65639 effective words) took 0.2s, 354050 effective words/s\n",
      "2023-12-06 14:34:29,175 : INFO : EPOCH 1: training on 99524 raw words (65663 effective words) took 0.1s, 452562 effective words/s\n",
      "2023-12-06 14:34:29,320 : INFO : EPOCH 2: training on 99524 raw words (65743 effective words) took 0.1s, 472005 effective words/s\n",
      "2023-12-06 14:34:29,487 : INFO : EPOCH 3: training on 99524 raw words (65406 effective words) took 0.2s, 401548 effective words/s\n",
      "2023-12-06 14:34:29,632 : INFO : EPOCH 4: training on 99524 raw words (65544 effective words) took 0.1s, 466959 effective words/s\n",
      "2023-12-06 14:34:29,777 : INFO : EPOCH 5: training on 99524 raw words (65375 effective words) took 0.1s, 466099 effective words/s\n",
      "2023-12-06 14:34:29,924 : INFO : EPOCH 6: training on 99524 raw words (65772 effective words) took 0.1s, 457019 effective words/s\n",
      "2023-12-06 14:34:30,076 : INFO : EPOCH 7: training on 99524 raw words (65501 effective words) took 0.1s, 446252 effective words/s\n",
      "2023-12-06 14:34:30,223 : INFO : EPOCH 8: training on 99524 raw words (65494 effective words) took 0.1s, 457214 effective words/s\n",
      "2023-12-06 14:34:30,376 : INFO : EPOCH 9: training on 99524 raw words (65569 effective words) took 0.1s, 443017 effective words/s\n",
      "2023-12-06 14:34:30,520 : INFO : EPOCH 10: training on 99524 raw words (65509 effective words) took 0.1s, 470845 effective words/s\n",
      "2023-12-06 14:34:30,663 : INFO : EPOCH 11: training on 99524 raw words (65500 effective words) took 0.1s, 472507 effective words/s\n",
      "2023-12-06 14:34:30,812 : INFO : EPOCH 12: training on 99524 raw words (65558 effective words) took 0.1s, 452396 effective words/s\n",
      "2023-12-06 14:34:30,955 : INFO : EPOCH 13: training on 99524 raw words (65654 effective words) took 0.1s, 470823 effective words/s\n",
      "2023-12-06 14:34:31,102 : INFO : EPOCH 14: training on 99524 raw words (65715 effective words) took 0.1s, 463616 effective words/s\n",
      "2023-12-06 14:34:31,254 : INFO : EPOCH 15: training on 99524 raw words (65457 effective words) took 0.1s, 442537 effective words/s\n",
      "2023-12-06 14:34:31,398 : INFO : EPOCH 16: training on 99524 raw words (65395 effective words) took 0.1s, 469842 effective words/s\n",
      "2023-12-06 14:34:31,542 : INFO : EPOCH 17: training on 99524 raw words (65393 effective words) took 0.1s, 466723 effective words/s\n",
      "2023-12-06 14:34:31,693 : INFO : EPOCH 18: training on 99524 raw words (65484 effective words) took 0.1s, 447944 effective words/s\n",
      "2023-12-06 14:34:31,843 : INFO : EPOCH 19: training on 99524 raw words (65532 effective words) took 0.1s, 452050 effective words/s\n",
      "2023-12-06 14:34:31,996 : INFO : EPOCH 20: training on 99524 raw words (65515 effective words) took 0.1s, 438344 effective words/s\n",
      "2023-12-06 14:34:32,144 : INFO : EPOCH 21: training on 99524 raw words (65468 effective words) took 0.1s, 457198 effective words/s\n",
      "2023-12-06 14:34:32,286 : INFO : EPOCH 22: training on 99524 raw words (65540 effective words) took 0.1s, 475642 effective words/s\n",
      "2023-12-06 14:34:32,427 : INFO : EPOCH 23: training on 99524 raw words (65403 effective words) took 0.1s, 479915 effective words/s\n",
      "2023-12-06 14:34:32,574 : INFO : EPOCH 24: training on 99524 raw words (65640 effective words) took 0.1s, 459627 effective words/s\n",
      "2023-12-06 14:34:32,717 : INFO : EPOCH 25: training on 99524 raw words (65553 effective words) took 0.1s, 475861 effective words/s\n",
      "2023-12-06 14:34:32,859 : INFO : EPOCH 26: training on 99524 raw words (65762 effective words) took 0.1s, 478651 effective words/s\n",
      "2023-12-06 14:34:33,008 : INFO : EPOCH 27: training on 99524 raw words (65647 effective words) took 0.1s, 453463 effective words/s\n",
      "2023-12-06 14:34:33,151 : INFO : EPOCH 28: training on 99524 raw words (65557 effective words) took 0.1s, 472778 effective words/s\n",
      "2023-12-06 14:34:33,292 : INFO : EPOCH 29: training on 99524 raw words (65607 effective words) took 0.1s, 482522 effective words/s\n",
      "2023-12-06 14:34:33,293 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1966595 effective words) took 4.5s, 441314 effective words/s', 'datetime': '2023-12-06T14:34:33.293278', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:34:33,294 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:34:33.293278', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 29%|       | 139/486 [20:54<37:08,  6.42s/it]2023-12-06 14:34:36,164 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:34:36,165 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:34:36,186 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:34:36,186 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:34:36,191 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:34:36.191869', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:34:36,192 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:34:36.192871', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:34:36,198 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:34:36,199 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:34:36,200 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:34:36.199875', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:34:36,210 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:34:36,212 : INFO : resetting layer weights\n",
      "2023-12-06 14:34:36,213 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:34:36.213387', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:34:36,356 : INFO : EPOCH 0: training on 99524 raw words (65597 effective words) took 0.1s, 469803 effective words/s\n",
      "2023-12-06 14:34:36,486 : INFO : EPOCH 1: training on 99524 raw words (65687 effective words) took 0.1s, 526766 effective words/s\n",
      "2023-12-06 14:34:36,616 : INFO : EPOCH 2: training on 99524 raw words (65606 effective words) took 0.1s, 518890 effective words/s\n",
      "2023-12-06 14:34:36,773 : INFO : EPOCH 3: training on 99524 raw words (65467 effective words) took 0.2s, 432027 effective words/s\n",
      "2023-12-06 14:34:36,917 : INFO : EPOCH 4: training on 99524 raw words (65618 effective words) took 0.1s, 468339 effective words/s\n",
      "2023-12-06 14:34:37,062 : INFO : EPOCH 5: training on 99524 raw words (65509 effective words) took 0.1s, 466490 effective words/s\n",
      "2023-12-06 14:34:37,210 : INFO : EPOCH 6: training on 99524 raw words (65456 effective words) took 0.1s, 454028 effective words/s\n",
      "2023-12-06 14:34:37,354 : INFO : EPOCH 7: training on 99524 raw words (65439 effective words) took 0.1s, 472557 effective words/s\n",
      "2023-12-06 14:34:37,498 : INFO : EPOCH 8: training on 99524 raw words (65550 effective words) took 0.1s, 469985 effective words/s\n",
      "2023-12-06 14:34:37,647 : INFO : EPOCH 9: training on 99524 raw words (65611 effective words) took 0.1s, 452537 effective words/s\n",
      "2023-12-06 14:34:37,791 : INFO : EPOCH 10: training on 99524 raw words (65540 effective words) took 0.1s, 469899 effective words/s\n",
      "2023-12-06 14:34:37,935 : INFO : EPOCH 11: training on 99524 raw words (65636 effective words) took 0.1s, 470321 effective words/s\n",
      "2023-12-06 14:34:38,084 : INFO : EPOCH 12: training on 99524 raw words (65601 effective words) took 0.1s, 455656 effective words/s\n",
      "2023-12-06 14:34:38,225 : INFO : EPOCH 13: training on 99524 raw words (65399 effective words) took 0.1s, 475393 effective words/s\n",
      "2023-12-06 14:34:38,370 : INFO : EPOCH 14: training on 99524 raw words (65595 effective words) took 0.1s, 467910 effective words/s\n",
      "2023-12-06 14:34:38,519 : INFO : EPOCH 15: training on 99524 raw words (65543 effective words) took 0.1s, 454556 effective words/s\n",
      "2023-12-06 14:34:38,662 : INFO : EPOCH 16: training on 99524 raw words (65503 effective words) took 0.1s, 472224 effective words/s\n",
      "2023-12-06 14:34:38,806 : INFO : EPOCH 17: training on 99524 raw words (65498 effective words) took 0.1s, 469464 effective words/s\n",
      "2023-12-06 14:34:38,952 : INFO : EPOCH 18: training on 99524 raw words (65501 effective words) took 0.1s, 462066 effective words/s\n",
      "2023-12-06 14:34:39,100 : INFO : EPOCH 19: training on 99524 raw words (65572 effective words) took 0.1s, 460005 effective words/s\n",
      "2023-12-06 14:34:39,251 : INFO : EPOCH 20: training on 99524 raw words (65604 effective words) took 0.1s, 445662 effective words/s\n",
      "2023-12-06 14:34:39,399 : INFO : EPOCH 21: training on 99524 raw words (65597 effective words) took 0.1s, 456501 effective words/s\n",
      "2023-12-06 14:34:39,544 : INFO : EPOCH 22: training on 99524 raw words (65588 effective words) took 0.1s, 465911 effective words/s\n",
      "2023-12-06 14:34:39,688 : INFO : EPOCH 23: training on 99524 raw words (65579 effective words) took 0.1s, 470517 effective words/s\n",
      "2023-12-06 14:34:39,837 : INFO : EPOCH 24: training on 99524 raw words (65504 effective words) took 0.1s, 454214 effective words/s\n",
      "2023-12-06 14:34:39,980 : INFO : EPOCH 25: training on 99524 raw words (65519 effective words) took 0.1s, 472420 effective words/s\n",
      "2023-12-06 14:34:40,125 : INFO : EPOCH 26: training on 99524 raw words (65779 effective words) took 0.1s, 466269 effective words/s\n",
      "2023-12-06 14:34:40,276 : INFO : EPOCH 27: training on 99524 raw words (65904 effective words) took 0.1s, 452211 effective words/s\n",
      "2023-12-06 14:34:40,418 : INFO : EPOCH 28: training on 99524 raw words (65562 effective words) took 0.1s, 475158 effective words/s\n",
      "2023-12-06 14:34:40,561 : INFO : EPOCH 29: training on 99524 raw words (65594 effective words) took 0.1s, 471150 effective words/s\n",
      "2023-12-06 14:34:40,562 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1967158 effective words) took 4.3s, 452381 effective words/s', 'datetime': '2023-12-06T14:34:40.562564', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:34:40,563 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:34:40.563564', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 29%|       | 140/486 [21:02<38:55,  6.75s/it]2023-12-06 14:34:43,677 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:34:43,678 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:34:43,703 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:34:43,704 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:34:43,711 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:34:43.711955', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:34:43,712 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:34:43.712955', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:34:43,723 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:34:43,723 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:34:43,725 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:34:43.725089', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:34:43,740 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:34:43,741 : INFO : resetting layer weights\n",
      "2023-12-06 14:34:43,744 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:34:43.744720', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:34:43,908 : INFO : EPOCH 0: training on 99524 raw words (65507 effective words) took 0.2s, 410593 effective words/s\n",
      "2023-12-06 14:34:44,055 : INFO : EPOCH 1: training on 99524 raw words (65454 effective words) took 0.1s, 469119 effective words/s\n",
      "2023-12-06 14:34:44,206 : INFO : EPOCH 2: training on 99524 raw words (65572 effective words) took 0.1s, 449056 effective words/s\n",
      "2023-12-06 14:34:44,359 : INFO : EPOCH 3: training on 99524 raw words (65387 effective words) took 0.1s, 441000 effective words/s\n",
      "2023-12-06 14:34:44,504 : INFO : EPOCH 4: training on 99524 raw words (65488 effective words) took 0.1s, 468760 effective words/s\n",
      "2023-12-06 14:34:44,648 : INFO : EPOCH 5: training on 99524 raw words (65308 effective words) took 0.1s, 464546 effective words/s\n",
      "2023-12-06 14:34:44,798 : INFO : EPOCH 6: training on 99524 raw words (65484 effective words) took 0.1s, 453039 effective words/s\n",
      "2023-12-06 14:34:44,939 : INFO : EPOCH 7: training on 99524 raw words (65513 effective words) took 0.1s, 480606 effective words/s\n",
      "2023-12-06 14:34:45,085 : INFO : EPOCH 8: training on 99524 raw words (65650 effective words) took 0.1s, 461536 effective words/s\n",
      "2023-12-06 14:34:45,234 : INFO : EPOCH 9: training on 99524 raw words (65364 effective words) took 0.1s, 454165 effective words/s\n",
      "2023-12-06 14:34:45,375 : INFO : EPOCH 10: training on 99524 raw words (65473 effective words) took 0.1s, 479509 effective words/s\n",
      "2023-12-06 14:34:45,523 : INFO : EPOCH 11: training on 99524 raw words (65681 effective words) took 0.1s, 458119 effective words/s\n",
      "2023-12-06 14:34:45,672 : INFO : EPOCH 12: training on 99524 raw words (65549 effective words) took 0.1s, 451540 effective words/s\n",
      "2023-12-06 14:34:45,816 : INFO : EPOCH 13: training on 99524 raw words (65550 effective words) took 0.1s, 472116 effective words/s\n",
      "2023-12-06 14:34:45,956 : INFO : EPOCH 14: training on 99524 raw words (65536 effective words) took 0.1s, 481282 effective words/s\n",
      "2023-12-06 14:34:46,114 : INFO : EPOCH 15: training on 99524 raw words (65582 effective words) took 0.2s, 427394 effective words/s\n",
      "2023-12-06 14:34:46,273 : INFO : EPOCH 16: training on 99524 raw words (65394 effective words) took 0.2s, 425077 effective words/s\n",
      "2023-12-06 14:34:46,459 : INFO : EPOCH 17: training on 99524 raw words (65505 effective words) took 0.2s, 363950 effective words/s\n",
      "2023-12-06 14:34:46,620 : INFO : EPOCH 18: training on 99524 raw words (65430 effective words) took 0.2s, 422612 effective words/s\n",
      "2023-12-06 14:34:46,764 : INFO : EPOCH 19: training on 99524 raw words (65604 effective words) took 0.1s, 465392 effective words/s\n",
      "2023-12-06 14:34:46,905 : INFO : EPOCH 20: training on 99524 raw words (65378 effective words) took 0.1s, 479327 effective words/s\n",
      "2023-12-06 14:34:47,051 : INFO : EPOCH 21: training on 99524 raw words (65555 effective words) took 0.1s, 466072 effective words/s\n",
      "2023-12-06 14:34:47,191 : INFO : EPOCH 22: training on 99524 raw words (65602 effective words) took 0.1s, 484058 effective words/s\n",
      "2023-12-06 14:34:47,333 : INFO : EPOCH 23: training on 99524 raw words (65677 effective words) took 0.1s, 481938 effective words/s\n",
      "2023-12-06 14:34:47,482 : INFO : EPOCH 24: training on 99524 raw words (65542 effective words) took 0.1s, 455241 effective words/s\n",
      "2023-12-06 14:34:47,622 : INFO : EPOCH 25: training on 99524 raw words (65386 effective words) took 0.1s, 476514 effective words/s\n",
      "2023-12-06 14:34:47,767 : INFO : EPOCH 26: training on 99524 raw words (65557 effective words) took 0.1s, 470596 effective words/s\n",
      "2023-12-06 14:34:47,914 : INFO : EPOCH 27: training on 99524 raw words (65714 effective words) took 0.1s, 460554 effective words/s\n",
      "2023-12-06 14:34:48,053 : INFO : EPOCH 28: training on 99524 raw words (65595 effective words) took 0.1s, 486541 effective words/s\n",
      "2023-12-06 14:34:48,200 : INFO : EPOCH 29: training on 99524 raw words (65652 effective words) took 0.1s, 462889 effective words/s\n",
      "2023-12-06 14:34:48,200 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965689 effective words) took 4.5s, 441174 effective words/s', 'datetime': '2023-12-06T14:34:48.200403', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:34:48,201 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:34:48.201403', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 29%|       | 141/486 [21:10<40:26,  7.03s/it]2023-12-06 14:34:51,676 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:34:51,677 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:34:51,700 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:34:51,701 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:34:51,707 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:34:51.707547', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:34:51,708 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:34:51.708549', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:34:51,714 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:34:51,715 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:34:51,715 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:34:51.715720', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:34:51,732 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:34:51,733 : INFO : resetting layer weights\n",
      "2023-12-06 14:34:51,735 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:34:51.735939', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:34:51,929 : INFO : EPOCH 0: training on 99524 raw words (65392 effective words) took 0.2s, 347479 effective words/s\n",
      "2023-12-06 14:34:52,089 : INFO : EPOCH 1: training on 99524 raw words (65587 effective words) took 0.2s, 428980 effective words/s\n",
      "2023-12-06 14:34:52,234 : INFO : EPOCH 2: training on 99524 raw words (65581 effective words) took 0.1s, 467986 effective words/s\n",
      "2023-12-06 14:34:52,382 : INFO : EPOCH 3: training on 99524 raw words (65454 effective words) took 0.1s, 455016 effective words/s\n",
      "2023-12-06 14:34:52,525 : INFO : EPOCH 4: training on 99524 raw words (65701 effective words) took 0.1s, 476836 effective words/s\n",
      "2023-12-06 14:34:52,669 : INFO : EPOCH 5: training on 99524 raw words (65467 effective words) took 0.1s, 470373 effective words/s\n",
      "2023-12-06 14:34:52,818 : INFO : EPOCH 6: training on 99524 raw words (65509 effective words) took 0.1s, 454051 effective words/s\n",
      "2023-12-06 14:34:52,960 : INFO : EPOCH 7: training on 99524 raw words (65523 effective words) took 0.1s, 474660 effective words/s\n",
      "2023-12-06 14:34:53,109 : INFO : EPOCH 8: training on 99524 raw words (65636 effective words) took 0.1s, 454360 effective words/s\n",
      "2023-12-06 14:34:53,261 : INFO : EPOCH 9: training on 99524 raw words (65623 effective words) took 0.1s, 444737 effective words/s\n",
      "2023-12-06 14:34:53,404 : INFO : EPOCH 10: training on 99524 raw words (65361 effective words) took 0.1s, 471631 effective words/s\n",
      "2023-12-06 14:34:53,547 : INFO : EPOCH 11: training on 99524 raw words (65686 effective words) took 0.1s, 477275 effective words/s\n",
      "2023-12-06 14:34:53,694 : INFO : EPOCH 12: training on 99524 raw words (65546 effective words) took 0.1s, 457272 effective words/s\n",
      "2023-12-06 14:34:53,840 : INFO : EPOCH 13: training on 99524 raw words (65694 effective words) took 0.1s, 466333 effective words/s\n",
      "2023-12-06 14:34:53,983 : INFO : EPOCH 14: training on 99524 raw words (65642 effective words) took 0.1s, 474142 effective words/s\n",
      "2023-12-06 14:34:54,132 : INFO : EPOCH 15: training on 99524 raw words (65535 effective words) took 0.1s, 454461 effective words/s\n",
      "2023-12-06 14:34:54,272 : INFO : EPOCH 16: training on 99524 raw words (65453 effective words) took 0.1s, 479479 effective words/s\n",
      "2023-12-06 14:34:54,426 : INFO : EPOCH 17: training on 99524 raw words (65426 effective words) took 0.1s, 436757 effective words/s\n",
      "2023-12-06 14:34:54,589 : INFO : EPOCH 18: training on 99524 raw words (65503 effective words) took 0.2s, 411251 effective words/s\n",
      "2023-12-06 14:34:54,746 : INFO : EPOCH 19: training on 99524 raw words (65719 effective words) took 0.2s, 434691 effective words/s\n",
      "2023-12-06 14:34:54,897 : INFO : EPOCH 20: training on 99524 raw words (65662 effective words) took 0.1s, 453265 effective words/s\n",
      "2023-12-06 14:34:55,045 : INFO : EPOCH 21: training on 99524 raw words (65550 effective words) took 0.1s, 457754 effective words/s\n",
      "2023-12-06 14:34:55,192 : INFO : EPOCH 22: training on 99524 raw words (65524 effective words) took 0.1s, 458228 effective words/s\n",
      "2023-12-06 14:34:55,352 : INFO : EPOCH 23: training on 99524 raw words (65583 effective words) took 0.2s, 424430 effective words/s\n",
      "2023-12-06 14:34:55,504 : INFO : EPOCH 24: training on 99524 raw words (65444 effective words) took 0.1s, 445690 effective words/s\n",
      "2023-12-06 14:34:55,649 : INFO : EPOCH 25: training on 99524 raw words (65495 effective words) took 0.1s, 467112 effective words/s\n",
      "2023-12-06 14:34:55,792 : INFO : EPOCH 26: training on 99524 raw words (65684 effective words) took 0.1s, 472154 effective words/s\n",
      "2023-12-06 14:34:55,942 : INFO : EPOCH 27: training on 99524 raw words (65707 effective words) took 0.1s, 455247 effective words/s\n",
      "2023-12-06 14:34:56,085 : INFO : EPOCH 28: training on 99524 raw words (65361 effective words) took 0.1s, 470883 effective words/s\n",
      "2023-12-06 14:34:56,227 : INFO : EPOCH 29: training on 99524 raw words (65554 effective words) took 0.1s, 473750 effective words/s\n",
      "2023-12-06 14:34:56,374 : INFO : EPOCH 30: training on 99524 raw words (65438 effective words) took 0.1s, 458296 effective words/s\n",
      "2023-12-06 14:34:56,525 : INFO : EPOCH 31: training on 99524 raw words (65514 effective words) took 0.1s, 448089 effective words/s\n",
      "2023-12-06 14:34:56,680 : INFO : EPOCH 32: training on 99524 raw words (65516 effective words) took 0.2s, 433706 effective words/s\n",
      "2023-12-06 14:34:56,842 : INFO : EPOCH 33: training on 99524 raw words (65612 effective words) took 0.2s, 422410 effective words/s\n",
      "2023-12-06 14:34:56,994 : INFO : EPOCH 34: training on 99524 raw words (65669 effective words) took 0.1s, 441832 effective words/s\n",
      "2023-12-06 14:34:57,139 : INFO : EPOCH 35: training on 99524 raw words (65578 effective words) took 0.1s, 465566 effective words/s\n",
      "2023-12-06 14:34:57,296 : INFO : EPOCH 36: training on 99524 raw words (65534 effective words) took 0.2s, 432971 effective words/s\n",
      "2023-12-06 14:34:57,459 : INFO : EPOCH 37: training on 99524 raw words (65456 effective words) took 0.2s, 417133 effective words/s\n",
      "2023-12-06 14:34:57,605 : INFO : EPOCH 38: training on 99524 raw words (65383 effective words) took 0.1s, 462424 effective words/s\n",
      "2023-12-06 14:34:57,752 : INFO : EPOCH 39: training on 99524 raw words (65526 effective words) took 0.1s, 457370 effective words/s\n",
      "2023-12-06 14:34:57,899 : INFO : EPOCH 40: training on 99524 raw words (65502 effective words) took 0.1s, 462047 effective words/s\n",
      "2023-12-06 14:34:58,055 : INFO : EPOCH 41: training on 99524 raw words (65626 effective words) took 0.1s, 438156 effective words/s\n",
      "2023-12-06 14:34:58,202 : INFO : EPOCH 42: training on 99524 raw words (65648 effective words) took 0.1s, 461693 effective words/s\n",
      "2023-12-06 14:34:58,345 : INFO : EPOCH 43: training on 99524 raw words (65529 effective words) took 0.1s, 471024 effective words/s\n",
      "2023-12-06 14:34:58,498 : INFO : EPOCH 44: training on 99524 raw words (65562 effective words) took 0.1s, 442208 effective words/s\n",
      "2023-12-06 14:34:58,644 : INFO : EPOCH 45: training on 99524 raw words (65557 effective words) took 0.1s, 465839 effective words/s\n",
      "2023-12-06 14:34:58,788 : INFO : EPOCH 46: training on 99524 raw words (65647 effective words) took 0.1s, 471179 effective words/s\n",
      "2023-12-06 14:34:58,938 : INFO : EPOCH 47: training on 99524 raw words (65387 effective words) took 0.1s, 448267 effective words/s\n",
      "2023-12-06 14:34:59,093 : INFO : EPOCH 48: training on 99524 raw words (65762 effective words) took 0.2s, 437955 effective words/s\n",
      "2023-12-06 14:34:59,250 : INFO : EPOCH 49: training on 99524 raw words (65672 effective words) took 0.2s, 432206 effective words/s\n",
      "2023-12-06 14:34:59,251 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3277720 effective words) took 7.5s, 436163 effective words/s', 'datetime': '2023-12-06T14:34:59.251349', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:34:59,252 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:34:59.252346', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 29%|       | 142/486 [21:21<47:17,  8.25s/it]2023-12-06 14:35:02,453 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:35:02,454 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:35:02,472 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:35:02,474 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:35:02,480 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:35:02.479217', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:02,481 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:35:02.481217', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:02,488 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:35:02,488 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:35:02,489 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:35:02.489217', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:02,498 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:35:02,499 : INFO : resetting layer weights\n",
      "2023-12-06 14:35:02,501 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:35:02.501745', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:35:02,665 : INFO : EPOCH 0: training on 99524 raw words (65475 effective words) took 0.2s, 408944 effective words/s\n",
      "2023-12-06 14:35:02,815 : INFO : EPOCH 1: training on 99524 raw words (65643 effective words) took 0.1s, 454014 effective words/s\n",
      "2023-12-06 14:35:02,963 : INFO : EPOCH 2: training on 99524 raw words (65647 effective words) took 0.1s, 458012 effective words/s\n",
      "2023-12-06 14:35:03,105 : INFO : EPOCH 3: training on 99524 raw words (65440 effective words) took 0.1s, 473760 effective words/s\n",
      "2023-12-06 14:35:03,248 : INFO : EPOCH 4: training on 99524 raw words (65534 effective words) took 0.1s, 472064 effective words/s\n",
      "2023-12-06 14:35:03,398 : INFO : EPOCH 5: training on 99524 raw words (65425 effective words) took 0.1s, 449868 effective words/s\n",
      "2023-12-06 14:35:03,543 : INFO : EPOCH 6: training on 99524 raw words (65568 effective words) took 0.1s, 469279 effective words/s\n",
      "2023-12-06 14:35:03,686 : INFO : EPOCH 7: training on 99524 raw words (65601 effective words) took 0.1s, 473376 effective words/s\n",
      "2023-12-06 14:35:03,834 : INFO : EPOCH 8: training on 99524 raw words (65476 effective words) took 0.1s, 453513 effective words/s\n",
      "2023-12-06 14:35:03,978 : INFO : EPOCH 9: training on 99524 raw words (65447 effective words) took 0.1s, 469491 effective words/s\n",
      "2023-12-06 14:35:04,119 : INFO : EPOCH 10: training on 99524 raw words (65368 effective words) took 0.1s, 475711 effective words/s\n",
      "2023-12-06 14:35:04,269 : INFO : EPOCH 11: training on 99524 raw words (65580 effective words) took 0.1s, 454945 effective words/s\n",
      "2023-12-06 14:35:04,412 : INFO : EPOCH 12: training on 99524 raw words (65590 effective words) took 0.1s, 471152 effective words/s\n",
      "2023-12-06 14:35:04,556 : INFO : EPOCH 13: training on 99524 raw words (65382 effective words) took 0.1s, 471394 effective words/s\n",
      "2023-12-06 14:35:04,705 : INFO : EPOCH 14: training on 99524 raw words (65637 effective words) took 0.1s, 454407 effective words/s\n",
      "2023-12-06 14:35:04,849 : INFO : EPOCH 15: training on 99524 raw words (65550 effective words) took 0.1s, 469262 effective words/s\n",
      "2023-12-06 14:35:04,992 : INFO : EPOCH 16: training on 99524 raw words (65592 effective words) took 0.1s, 472503 effective words/s\n",
      "2023-12-06 14:35:05,149 : INFO : EPOCH 17: training on 99524 raw words (65393 effective words) took 0.2s, 429671 effective words/s\n",
      "2023-12-06 14:35:05,294 : INFO : EPOCH 18: training on 99524 raw words (65470 effective words) took 0.1s, 465365 effective words/s\n",
      "2023-12-06 14:35:05,448 : INFO : EPOCH 19: training on 99524 raw words (65632 effective words) took 0.1s, 440612 effective words/s\n",
      "2023-12-06 14:35:05,591 : INFO : EPOCH 20: training on 99524 raw words (65434 effective words) took 0.1s, 472271 effective words/s\n",
      "2023-12-06 14:35:05,733 : INFO : EPOCH 21: training on 99524 raw words (65587 effective words) took 0.1s, 473372 effective words/s\n",
      "2023-12-06 14:35:05,882 : INFO : EPOCH 22: training on 99524 raw words (65583 effective words) took 0.1s, 455303 effective words/s\n",
      "2023-12-06 14:35:06,025 : INFO : EPOCH 23: training on 99524 raw words (65546 effective words) took 0.1s, 474205 effective words/s\n",
      "2023-12-06 14:35:06,168 : INFO : EPOCH 24: training on 99524 raw words (65451 effective words) took 0.1s, 471770 effective words/s\n",
      "2023-12-06 14:35:06,316 : INFO : EPOCH 25: training on 99524 raw words (65453 effective words) took 0.1s, 455686 effective words/s\n",
      "2023-12-06 14:35:06,459 : INFO : EPOCH 26: training on 99524 raw words (65616 effective words) took 0.1s, 472370 effective words/s\n",
      "2023-12-06 14:35:06,605 : INFO : EPOCH 27: training on 99524 raw words (65547 effective words) took 0.1s, 465913 effective words/s\n",
      "2023-12-06 14:35:06,757 : INFO : EPOCH 28: training on 99524 raw words (65628 effective words) took 0.1s, 443849 effective words/s\n",
      "2023-12-06 14:35:06,900 : INFO : EPOCH 29: training on 99524 raw words (65777 effective words) took 0.1s, 475712 effective words/s\n",
      "2023-12-06 14:35:07,043 : INFO : EPOCH 30: training on 99524 raw words (65480 effective words) took 0.1s, 472142 effective words/s\n",
      "2023-12-06 14:35:07,191 : INFO : EPOCH 31: training on 99524 raw words (65578 effective words) took 0.1s, 454774 effective words/s\n",
      "2023-12-06 14:35:07,335 : INFO : EPOCH 32: training on 99524 raw words (65564 effective words) took 0.1s, 471638 effective words/s\n",
      "2023-12-06 14:35:07,487 : INFO : EPOCH 33: training on 99524 raw words (65678 effective words) took 0.1s, 443096 effective words/s\n",
      "2023-12-06 14:35:07,636 : INFO : EPOCH 34: training on 99524 raw words (65614 effective words) took 0.1s, 453095 effective words/s\n",
      "2023-12-06 14:35:07,779 : INFO : EPOCH 35: training on 99524 raw words (65583 effective words) took 0.1s, 473478 effective words/s\n",
      "2023-12-06 14:35:07,924 : INFO : EPOCH 36: training on 99524 raw words (65641 effective words) took 0.1s, 468121 effective words/s\n",
      "2023-12-06 14:35:08,074 : INFO : EPOCH 37: training on 99524 raw words (65365 effective words) took 0.1s, 448597 effective words/s\n",
      "2023-12-06 14:35:08,216 : INFO : EPOCH 38: training on 99524 raw words (65393 effective words) took 0.1s, 473814 effective words/s\n",
      "2023-12-06 14:35:08,358 : INFO : EPOCH 39: training on 99524 raw words (65426 effective words) took 0.1s, 470870 effective words/s\n",
      "2023-12-06 14:35:08,518 : INFO : EPOCH 40: training on 99524 raw words (65502 effective words) took 0.2s, 424975 effective words/s\n",
      "2023-12-06 14:35:08,675 : INFO : EPOCH 41: training on 99524 raw words (65769 effective words) took 0.2s, 430804 effective words/s\n",
      "2023-12-06 14:35:08,826 : INFO : EPOCH 42: training on 99524 raw words (65727 effective words) took 0.1s, 451821 effective words/s\n",
      "2023-12-06 14:35:08,982 : INFO : EPOCH 43: training on 99524 raw words (65675 effective words) took 0.2s, 434617 effective words/s\n",
      "2023-12-06 14:35:09,136 : INFO : EPOCH 44: training on 99524 raw words (65547 effective words) took 0.1s, 438546 effective words/s\n",
      "2023-12-06 14:35:09,281 : INFO : EPOCH 45: training on 99524 raw words (65455 effective words) took 0.1s, 464822 effective words/s\n",
      "2023-12-06 14:35:09,430 : INFO : EPOCH 46: training on 99524 raw words (65626 effective words) took 0.1s, 454678 effective words/s\n",
      "2023-12-06 14:35:09,572 : INFO : EPOCH 47: training on 99524 raw words (65464 effective words) took 0.1s, 474277 effective words/s\n",
      "2023-12-06 14:35:09,727 : INFO : EPOCH 48: training on 99524 raw words (65526 effective words) took 0.1s, 438461 effective words/s\n",
      "2023-12-06 14:35:09,891 : INFO : EPOCH 49: training on 99524 raw words (65524 effective words) took 0.2s, 413345 effective words/s\n",
      "2023-12-06 14:35:09,893 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3277209 effective words) took 7.4s, 443393 effective words/s', 'datetime': '2023-12-06T14:35:09.893262', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:35:09,893 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:35:09.893262', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 29%|       | 143/486 [21:31<51:41,  9.04s/it]2023-12-06 14:35:13,349 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:35:13,349 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:35:13,369 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:35:13,370 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:35:13,375 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:35:13.375696', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:13,376 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:35:13.376696', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:13,387 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:35:13,387 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:35:13,388 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:35:13.388280', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:13,398 : INFO : estimated required memory for 1966 words and 50 dimensions: 3494600 bytes\n",
      "2023-12-06 14:35:13,399 : INFO : resetting layer weights\n",
      "2023-12-06 14:35:13,400 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:35:13.400658', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:35:13,559 : INFO : EPOCH 0: training on 99524 raw words (65363 effective words) took 0.2s, 421763 effective words/s\n",
      "2023-12-06 14:35:13,704 : INFO : EPOCH 1: training on 99524 raw words (65565 effective words) took 0.1s, 465674 effective words/s\n",
      "2023-12-06 14:35:13,857 : INFO : EPOCH 2: training on 99524 raw words (65673 effective words) took 0.1s, 444930 effective words/s\n",
      "2023-12-06 14:35:13,999 : INFO : EPOCH 3: training on 99524 raw words (65400 effective words) took 0.1s, 479254 effective words/s\n",
      "2023-12-06 14:35:14,142 : INFO : EPOCH 4: training on 99524 raw words (65378 effective words) took 0.1s, 470709 effective words/s\n",
      "2023-12-06 14:35:14,288 : INFO : EPOCH 5: training on 99524 raw words (65476 effective words) took 0.1s, 461951 effective words/s\n",
      "2023-12-06 14:35:14,430 : INFO : EPOCH 6: training on 99524 raw words (65561 effective words) took 0.1s, 475596 effective words/s\n",
      "2023-12-06 14:35:14,573 : INFO : EPOCH 7: training on 99524 raw words (65459 effective words) took 0.1s, 473839 effective words/s\n",
      "2023-12-06 14:35:14,722 : INFO : EPOCH 8: training on 99524 raw words (65384 effective words) took 0.1s, 452310 effective words/s\n",
      "2023-12-06 14:35:14,864 : INFO : EPOCH 9: training on 99524 raw words (65575 effective words) took 0.1s, 476930 effective words/s\n",
      "2023-12-06 14:35:15,005 : INFO : EPOCH 10: training on 99524 raw words (65500 effective words) took 0.1s, 478185 effective words/s\n",
      "2023-12-06 14:35:15,152 : INFO : EPOCH 11: training on 99524 raw words (65600 effective words) took 0.1s, 461545 effective words/s\n",
      "2023-12-06 14:35:15,293 : INFO : EPOCH 12: training on 99524 raw words (65565 effective words) took 0.1s, 482134 effective words/s\n",
      "2023-12-06 14:35:15,443 : INFO : EPOCH 13: training on 99524 raw words (65528 effective words) took 0.1s, 451613 effective words/s\n",
      "2023-12-06 14:35:15,592 : INFO : EPOCH 14: training on 99524 raw words (65649 effective words) took 0.1s, 455670 effective words/s\n",
      "2023-12-06 14:35:15,733 : INFO : EPOCH 15: training on 99524 raw words (65476 effective words) took 0.1s, 481308 effective words/s\n",
      "2023-12-06 14:35:15,880 : INFO : EPOCH 16: training on 99524 raw words (65480 effective words) took 0.1s, 455487 effective words/s\n",
      "2023-12-06 14:35:16,022 : INFO : EPOCH 17: training on 99524 raw words (65364 effective words) took 0.1s, 477939 effective words/s\n",
      "2023-12-06 14:35:16,164 : INFO : EPOCH 18: training on 99524 raw words (65480 effective words) took 0.1s, 474587 effective words/s\n",
      "2023-12-06 14:35:16,315 : INFO : EPOCH 19: training on 99524 raw words (65691 effective words) took 0.1s, 449573 effective words/s\n",
      "2023-12-06 14:35:16,458 : INFO : EPOCH 20: training on 99524 raw words (65596 effective words) took 0.1s, 475588 effective words/s\n",
      "2023-12-06 14:35:16,597 : INFO : EPOCH 21: training on 99524 raw words (65509 effective words) took 0.1s, 482199 effective words/s\n",
      "2023-12-06 14:35:16,745 : INFO : EPOCH 22: training on 99524 raw words (65505 effective words) took 0.1s, 458635 effective words/s\n",
      "2023-12-06 14:35:16,887 : INFO : EPOCH 23: training on 99524 raw words (65622 effective words) took 0.1s, 477052 effective words/s\n",
      "2023-12-06 14:35:17,034 : INFO : EPOCH 24: training on 99524 raw words (65484 effective words) took 0.1s, 461674 effective words/s\n",
      "2023-12-06 14:35:17,175 : INFO : EPOCH 25: training on 99524 raw words (65455 effective words) took 0.1s, 477687 effective words/s\n",
      "2023-12-06 14:35:17,315 : INFO : EPOCH 26: training on 99524 raw words (65528 effective words) took 0.1s, 480409 effective words/s\n",
      "2023-12-06 14:35:17,463 : INFO : EPOCH 27: training on 99524 raw words (65712 effective words) took 0.1s, 461055 effective words/s\n",
      "2023-12-06 14:35:17,603 : INFO : EPOCH 28: training on 99524 raw words (65513 effective words) took 0.1s, 478847 effective words/s\n",
      "2023-12-06 14:35:17,753 : INFO : EPOCH 29: training on 99524 raw words (65469 effective words) took 0.1s, 451011 effective words/s\n",
      "2023-12-06 14:35:17,899 : INFO : EPOCH 30: training on 99524 raw words (65396 effective words) took 0.1s, 460491 effective words/s\n",
      "2023-12-06 14:35:18,047 : INFO : EPOCH 31: training on 99524 raw words (65558 effective words) took 0.1s, 459316 effective words/s\n",
      "2023-12-06 14:35:18,189 : INFO : EPOCH 32: training on 99524 raw words (65525 effective words) took 0.1s, 480447 effective words/s\n",
      "2023-12-06 14:35:18,335 : INFO : EPOCH 33: training on 99524 raw words (65636 effective words) took 0.1s, 461692 effective words/s\n",
      "2023-12-06 14:35:18,476 : INFO : EPOCH 34: training on 99524 raw words (65432 effective words) took 0.1s, 476337 effective words/s\n",
      "2023-12-06 14:35:18,617 : INFO : EPOCH 35: training on 99524 raw words (65630 effective words) took 0.1s, 481624 effective words/s\n",
      "2023-12-06 14:35:18,765 : INFO : EPOCH 36: training on 99524 raw words (65544 effective words) took 0.1s, 455762 effective words/s\n",
      "2023-12-06 14:35:18,910 : INFO : EPOCH 37: training on 99524 raw words (65390 effective words) took 0.1s, 470075 effective words/s\n",
      "2023-12-06 14:35:19,054 : INFO : EPOCH 38: training on 99524 raw words (65343 effective words) took 0.1s, 468159 effective words/s\n",
      "2023-12-06 14:35:19,201 : INFO : EPOCH 39: training on 99524 raw words (65455 effective words) took 0.1s, 457560 effective words/s\n",
      "2023-12-06 14:35:19,353 : INFO : EPOCH 40: training on 99524 raw words (65525 effective words) took 0.1s, 445669 effective words/s\n",
      "2023-12-06 14:35:19,494 : INFO : EPOCH 41: training on 99524 raw words (65727 effective words) took 0.1s, 480664 effective words/s\n",
      "2023-12-06 14:35:19,642 : INFO : EPOCH 42: training on 99524 raw words (65605 effective words) took 0.1s, 459192 effective words/s\n",
      "2023-12-06 14:35:19,788 : INFO : EPOCH 43: training on 99524 raw words (65676 effective words) took 0.1s, 461183 effective words/s\n",
      "2023-12-06 14:35:19,929 : INFO : EPOCH 44: training on 99524 raw words (65571 effective words) took 0.1s, 479502 effective words/s\n",
      "2023-12-06 14:35:20,074 : INFO : EPOCH 45: training on 99524 raw words (65446 effective words) took 0.1s, 465633 effective words/s\n",
      "2023-12-06 14:35:20,217 : INFO : EPOCH 46: training on 99524 raw words (65600 effective words) took 0.1s, 473811 effective words/s\n",
      "2023-12-06 14:35:20,360 : INFO : EPOCH 47: training on 99524 raw words (65544 effective words) took 0.1s, 473947 effective words/s\n",
      "2023-12-06 14:35:20,511 : INFO : EPOCH 48: training on 99524 raw words (65561 effective words) took 0.1s, 445923 effective words/s\n",
      "2023-12-06 14:35:20,653 : INFO : EPOCH 49: training on 99524 raw words (65505 effective words) took 0.1s, 476356 effective words/s\n",
      "2023-12-06 14:35:20,654 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276229 effective words) took 7.3s, 451698 effective words/s', 'datetime': '2023-12-06T14:35:20.654641', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:35:20,654 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:35:20.654641', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 30%|       | 144/486 [21:42<54:45,  9.61s/it]2023-12-06 14:35:24,276 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:35:24,277 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:35:24,296 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:35:24,297 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:35:24,303 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:35:24.303879', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:24,304 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:35:24.304879', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:24,311 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:35:24,312 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:35:24,312 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:35:24.312882', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:24,325 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:35:24,326 : INFO : resetting layer weights\n",
      "2023-12-06 14:35:24,327 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:35:24.327879', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:35:24,481 : INFO : EPOCH 0: training on 99524 raw words (62828 effective words) took 0.1s, 419047 effective words/s\n",
      "2023-12-06 14:35:24,631 : INFO : EPOCH 1: training on 99524 raw words (62748 effective words) took 0.1s, 436012 effective words/s\n",
      "2023-12-06 14:35:24,778 : INFO : EPOCH 2: training on 99524 raw words (62932 effective words) took 0.1s, 443738 effective words/s\n",
      "2023-12-06 14:35:24,922 : INFO : EPOCH 3: training on 99524 raw words (62628 effective words) took 0.1s, 452398 effective words/s\n",
      "2023-12-06 14:35:25,065 : INFO : EPOCH 4: training on 99524 raw words (62750 effective words) took 0.1s, 451627 effective words/s\n",
      "2023-12-06 14:35:25,214 : INFO : EPOCH 5: training on 99524 raw words (62647 effective words) took 0.1s, 433265 effective words/s\n",
      "2023-12-06 14:35:25,356 : INFO : EPOCH 6: training on 99524 raw words (62671 effective words) took 0.1s, 453791 effective words/s\n",
      "2023-12-06 14:35:25,506 : INFO : EPOCH 7: training on 99524 raw words (62743 effective words) took 0.1s, 432489 effective words/s\n",
      "2023-12-06 14:35:25,648 : INFO : EPOCH 8: training on 99524 raw words (62619 effective words) took 0.1s, 456812 effective words/s\n",
      "2023-12-06 14:35:25,789 : INFO : EPOCH 9: training on 99524 raw words (62687 effective words) took 0.1s, 457768 effective words/s\n",
      "2023-12-06 14:35:25,790 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627253 effective words) took 1.5s, 429245 effective words/s', 'datetime': '2023-12-06T14:35:25.790206', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:35:25,791 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:35:25.791206', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 30%|       | 145/486 [21:46<45:04,  7.93s/it]2023-12-06 14:35:28,300 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:35:28,300 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:35:28,324 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:35:28,324 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:35:28,329 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:35:28.329149', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:28,330 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:35:28.330149', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:28,337 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:35:28,338 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:35:28,338 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:35:28.338324', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:28,348 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:35:28,348 : INFO : resetting layer weights\n",
      "2023-12-06 14:35:28,350 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:35:28.350632', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:35:28,503 : INFO : EPOCH 0: training on 99524 raw words (62631 effective words) took 0.1s, 419094 effective words/s\n",
      "2023-12-06 14:35:28,654 : INFO : EPOCH 1: training on 99524 raw words (62829 effective words) took 0.1s, 437447 effective words/s\n",
      "2023-12-06 14:35:28,798 : INFO : EPOCH 2: training on 99524 raw words (62743 effective words) took 0.1s, 450854 effective words/s\n",
      "2023-12-06 14:35:28,949 : INFO : EPOCH 3: training on 99524 raw words (62686 effective words) took 0.1s, 427881 effective words/s\n",
      "2023-12-06 14:35:29,092 : INFO : EPOCH 4: training on 99524 raw words (62859 effective words) took 0.1s, 452215 effective words/s\n",
      "2023-12-06 14:35:29,237 : INFO : EPOCH 5: training on 99524 raw words (62662 effective words) took 0.1s, 449869 effective words/s\n",
      "2023-12-06 14:35:29,384 : INFO : EPOCH 6: training on 99524 raw words (62593 effective words) took 0.1s, 434890 effective words/s\n",
      "2023-12-06 14:35:29,527 : INFO : EPOCH 7: training on 99524 raw words (62687 effective words) took 0.1s, 452139 effective words/s\n",
      "2023-12-06 14:35:29,669 : INFO : EPOCH 8: training on 99524 raw words (62857 effective words) took 0.1s, 457833 effective words/s\n",
      "2023-12-06 14:35:29,817 : INFO : EPOCH 9: training on 99524 raw words (62713 effective words) took 0.1s, 434790 effective words/s\n",
      "2023-12-06 14:35:29,818 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627260 effective words) took 1.5s, 427295 effective words/s', 'datetime': '2023-12-06T14:35:29.818922', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:35:29,818 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:35:29.818922', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 30%|       | 146/486 [21:51<38:23,  6.77s/it]2023-12-06 14:35:32,373 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:35:32,373 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:35:32,395 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:35:32,397 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:35:32,401 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:35:32.401795', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:32,402 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:35:32.402795', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:32,407 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:35:32,409 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:35:32,409 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:35:32.409540', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:32,417 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:35:32,418 : INFO : resetting layer weights\n",
      "2023-12-06 14:35:32,420 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:35:32.420550', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:35:32,572 : INFO : EPOCH 0: training on 99524 raw words (62827 effective words) took 0.1s, 423315 effective words/s\n",
      "2023-12-06 14:35:32,723 : INFO : EPOCH 1: training on 99524 raw words (62689 effective words) took 0.1s, 428628 effective words/s\n",
      "2023-12-06 14:35:32,864 : INFO : EPOCH 2: training on 99524 raw words (62971 effective words) took 0.1s, 458219 effective words/s\n",
      "2023-12-06 14:35:33,017 : INFO : EPOCH 3: training on 99524 raw words (62660 effective words) took 0.1s, 421458 effective words/s\n",
      "2023-12-06 14:35:33,158 : INFO : EPOCH 4: training on 99524 raw words (62646 effective words) took 0.1s, 463657 effective words/s\n",
      "2023-12-06 14:35:33,297 : INFO : EPOCH 5: training on 99524 raw words (62783 effective words) took 0.1s, 464724 effective words/s\n",
      "2023-12-06 14:35:33,443 : INFO : EPOCH 6: training on 99524 raw words (62699 effective words) took 0.1s, 443395 effective words/s\n",
      "2023-12-06 14:35:33,584 : INFO : EPOCH 7: training on 99524 raw words (62692 effective words) took 0.1s, 458824 effective words/s\n",
      "2023-12-06 14:35:33,723 : INFO : EPOCH 8: training on 99524 raw words (62742 effective words) took 0.1s, 463021 effective words/s\n",
      "2023-12-06 14:35:33,868 : INFO : EPOCH 9: training on 99524 raw words (62592 effective words) took 0.1s, 447555 effective words/s\n",
      "2023-12-06 14:35:33,869 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627301 effective words) took 1.4s, 433142 effective words/s', 'datetime': '2023-12-06T14:35:33.869406', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:35:33,869 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:35:33.869406', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 30%|       | 147/486 [21:55<33:49,  5.99s/it]2023-12-06 14:35:36,521 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:35:36,521 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:35:36,544 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:35:36,545 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:35:36,551 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:35:36.551772', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:36,551 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:35:36.551772', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:36,558 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:35:36,559 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:35:36,560 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:35:36.560277', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:36,571 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:35:36,572 : INFO : resetting layer weights\n",
      "2023-12-06 14:35:36,575 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:35:36.575189', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:35:36,730 : INFO : EPOCH 0: training on 99524 raw words (62686 effective words) took 0.2s, 416080 effective words/s\n",
      "2023-12-06 14:35:36,881 : INFO : EPOCH 1: training on 99524 raw words (62692 effective words) took 0.1s, 433964 effective words/s\n",
      "2023-12-06 14:35:37,025 : INFO : EPOCH 2: training on 99524 raw words (62830 effective words) took 0.1s, 451453 effective words/s\n",
      "2023-12-06 14:35:37,170 : INFO : EPOCH 3: training on 99524 raw words (62570 effective words) took 0.1s, 441601 effective words/s\n",
      "2023-12-06 14:35:37,311 : INFO : EPOCH 4: training on 99524 raw words (62712 effective words) took 0.1s, 460470 effective words/s\n",
      "2023-12-06 14:35:37,451 : INFO : EPOCH 5: training on 99524 raw words (62705 effective words) took 0.1s, 460920 effective words/s\n",
      "2023-12-06 14:35:37,599 : INFO : EPOCH 6: training on 99524 raw words (62740 effective words) took 0.1s, 440778 effective words/s\n",
      "2023-12-06 14:35:37,740 : INFO : EPOCH 7: training on 99524 raw words (62710 effective words) took 0.1s, 457895 effective words/s\n",
      "2023-12-06 14:35:37,882 : INFO : EPOCH 8: training on 99524 raw words (62665 effective words) took 0.1s, 455972 effective words/s\n",
      "2023-12-06 14:35:38,025 : INFO : EPOCH 9: training on 99524 raw words (62577 effective words) took 0.1s, 447585 effective words/s\n",
      "2023-12-06 14:35:38,170 : INFO : EPOCH 10: training on 99524 raw words (62693 effective words) took 0.1s, 447292 effective words/s\n",
      "2023-12-06 14:35:38,313 : INFO : EPOCH 11: training on 99524 raw words (62822 effective words) took 0.1s, 452580 effective words/s\n",
      "2023-12-06 14:35:38,462 : INFO : EPOCH 12: training on 99524 raw words (62680 effective words) took 0.1s, 435811 effective words/s\n",
      "2023-12-06 14:35:38,603 : INFO : EPOCH 13: training on 99524 raw words (62579 effective words) took 0.1s, 456415 effective words/s\n",
      "2023-12-06 14:35:38,745 : INFO : EPOCH 14: training on 99524 raw words (62783 effective words) took 0.1s, 458082 effective words/s\n",
      "2023-12-06 14:35:38,899 : INFO : EPOCH 15: training on 99524 raw words (62749 effective words) took 0.1s, 418884 effective words/s\n",
      "2023-12-06 14:35:39,039 : INFO : EPOCH 16: training on 99524 raw words (62662 effective words) took 0.1s, 458820 effective words/s\n",
      "2023-12-06 14:35:39,193 : INFO : EPOCH 17: training on 99524 raw words (62705 effective words) took 0.1s, 420913 effective words/s\n",
      "2023-12-06 14:35:39,334 : INFO : EPOCH 18: training on 99524 raw words (62766 effective words) took 0.1s, 457980 effective words/s\n",
      "2023-12-06 14:35:39,474 : INFO : EPOCH 19: training on 99524 raw words (62740 effective words) took 0.1s, 465082 effective words/s\n",
      "2023-12-06 14:35:39,622 : INFO : EPOCH 20: training on 99524 raw words (62572 effective words) took 0.1s, 436490 effective words/s\n",
      "2023-12-06 14:35:39,762 : INFO : EPOCH 21: training on 99524 raw words (62717 effective words) took 0.1s, 459988 effective words/s\n",
      "2023-12-06 14:35:39,904 : INFO : EPOCH 22: training on 99524 raw words (62757 effective words) took 0.1s, 454898 effective words/s\n",
      "2023-12-06 14:35:40,049 : INFO : EPOCH 23: training on 99524 raw words (62762 effective words) took 0.1s, 445551 effective words/s\n",
      "2023-12-06 14:35:40,191 : INFO : EPOCH 24: training on 99524 raw words (62795 effective words) took 0.1s, 459581 effective words/s\n",
      "2023-12-06 14:35:40,330 : INFO : EPOCH 25: training on 99524 raw words (62770 effective words) took 0.1s, 465316 effective words/s\n",
      "2023-12-06 14:35:40,477 : INFO : EPOCH 26: training on 99524 raw words (62807 effective words) took 0.1s, 441208 effective words/s\n",
      "2023-12-06 14:35:40,616 : INFO : EPOCH 27: training on 99524 raw words (62722 effective words) took 0.1s, 463823 effective words/s\n",
      "2023-12-06 14:35:40,756 : INFO : EPOCH 28: training on 99524 raw words (62601 effective words) took 0.1s, 461652 effective words/s\n",
      "2023-12-06 14:35:40,905 : INFO : EPOCH 29: training on 99524 raw words (62780 effective words) took 0.1s, 432775 effective words/s\n",
      "2023-12-06 14:35:40,906 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881349 effective words) took 4.3s, 434394 effective words/s', 'datetime': '2023-12-06T14:35:40.906912', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:35:40,906 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:35:40.906912', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 30%|       | 148/486 [22:02<35:50,  6.36s/it]2023-12-06 14:35:43,764 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:35:43,765 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:35:43,786 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:35:43,787 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:35:43,794 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:35:43.794604', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:43,794 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:35:43.794604', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:43,803 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:35:43,804 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:35:43,804 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:35:43.804603', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:43,817 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:35:43,817 : INFO : resetting layer weights\n",
      "2023-12-06 14:35:43,819 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:35:43.819603', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:35:43,997 : INFO : EPOCH 0: training on 99524 raw words (62744 effective words) took 0.2s, 359849 effective words/s\n",
      "2023-12-06 14:35:44,161 : INFO : EPOCH 1: training on 99524 raw words (62762 effective words) took 0.2s, 405442 effective words/s\n",
      "2023-12-06 14:35:44,308 : INFO : EPOCH 2: training on 99524 raw words (62736 effective words) took 0.1s, 442305 effective words/s\n",
      "2023-12-06 14:35:44,457 : INFO : EPOCH 3: training on 99524 raw words (62727 effective words) took 0.1s, 433474 effective words/s\n",
      "2023-12-06 14:35:44,610 : INFO : EPOCH 4: training on 99524 raw words (62652 effective words) took 0.1s, 421919 effective words/s\n",
      "2023-12-06 14:35:44,763 : INFO : EPOCH 5: training on 99524 raw words (62641 effective words) took 0.1s, 423455 effective words/s\n",
      "2023-12-06 14:35:44,913 : INFO : EPOCH 6: training on 99524 raw words (62645 effective words) took 0.1s, 431075 effective words/s\n",
      "2023-12-06 14:35:45,055 : INFO : EPOCH 7: training on 99524 raw words (62862 effective words) took 0.1s, 456800 effective words/s\n",
      "2023-12-06 14:35:45,227 : INFO : EPOCH 8: training on 99524 raw words (62624 effective words) took 0.2s, 373863 effective words/s\n",
      "2023-12-06 14:35:45,406 : INFO : EPOCH 9: training on 99524 raw words (62727 effective words) took 0.2s, 363078 effective words/s\n",
      "2023-12-06 14:35:45,553 : INFO : EPOCH 10: training on 99524 raw words (62639 effective words) took 0.1s, 436217 effective words/s\n",
      "2023-12-06 14:35:45,703 : INFO : EPOCH 11: training on 99524 raw words (62713 effective words) took 0.1s, 432119 effective words/s\n",
      "2023-12-06 14:35:45,874 : INFO : EPOCH 12: training on 99524 raw words (62691 effective words) took 0.2s, 382191 effective words/s\n",
      "2023-12-06 14:35:46,021 : INFO : EPOCH 13: training on 99524 raw words (62773 effective words) took 0.1s, 441208 effective words/s\n",
      "2023-12-06 14:35:46,166 : INFO : EPOCH 14: training on 99524 raw words (62762 effective words) took 0.1s, 445905 effective words/s\n",
      "2023-12-06 14:35:46,318 : INFO : EPOCH 15: training on 99524 raw words (62702 effective words) took 0.1s, 426274 effective words/s\n",
      "2023-12-06 14:35:46,460 : INFO : EPOCH 16: training on 99524 raw words (62754 effective words) took 0.1s, 455665 effective words/s\n",
      "2023-12-06 14:35:46,605 : INFO : EPOCH 17: training on 99524 raw words (62654 effective words) took 0.1s, 447990 effective words/s\n",
      "2023-12-06 14:35:46,756 : INFO : EPOCH 18: training on 99524 raw words (62522 effective words) took 0.1s, 424525 effective words/s\n",
      "2023-12-06 14:35:46,899 : INFO : EPOCH 19: training on 99524 raw words (62777 effective words) took 0.1s, 450832 effective words/s\n",
      "2023-12-06 14:35:47,048 : INFO : EPOCH 20: training on 99524 raw words (62729 effective words) took 0.1s, 435338 effective words/s\n",
      "2023-12-06 14:35:47,194 : INFO : EPOCH 21: training on 99524 raw words (62787 effective words) took 0.1s, 443334 effective words/s\n",
      "2023-12-06 14:35:47,336 : INFO : EPOCH 22: training on 99524 raw words (62924 effective words) took 0.1s, 456786 effective words/s\n",
      "2023-12-06 14:35:47,483 : INFO : EPOCH 23: training on 99524 raw words (62858 effective words) took 0.1s, 440828 effective words/s\n",
      "2023-12-06 14:35:47,626 : INFO : EPOCH 24: training on 99524 raw words (62809 effective words) took 0.1s, 451882 effective words/s\n",
      "2023-12-06 14:35:47,771 : INFO : EPOCH 25: training on 99524 raw words (62545 effective words) took 0.1s, 445531 effective words/s\n",
      "2023-12-06 14:35:47,921 : INFO : EPOCH 26: training on 99524 raw words (62682 effective words) took 0.1s, 429253 effective words/s\n",
      "2023-12-06 14:35:48,067 : INFO : EPOCH 27: training on 99524 raw words (62873 effective words) took 0.1s, 446403 effective words/s\n",
      "2023-12-06 14:35:48,227 : INFO : EPOCH 28: training on 99524 raw words (62780 effective words) took 0.2s, 400744 effective words/s\n",
      "2023-12-06 14:35:48,392 : INFO : EPOCH 29: training on 99524 raw words (62626 effective words) took 0.2s, 392751 effective words/s\n",
      "2023-12-06 14:35:48,393 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881720 effective words) took 4.6s, 411411 effective words/s', 'datetime': '2023-12-06T14:35:48.393610', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:35:48,394 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:35:48.394611', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 31%|       | 149/486 [22:10<38:02,  6.77s/it]2023-12-06 14:35:51,493 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:35:51,494 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:35:51,514 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:35:51,515 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:35:51,520 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:35:51.520118', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:51,520 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:35:51.520118', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:51,527 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:35:51,528 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:35:51,528 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:35:51.528789', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:51,537 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:35:51,537 : INFO : resetting layer weights\n",
      "2023-12-06 14:35:51,539 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:35:51.539784', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:35:51,717 : INFO : EPOCH 0: training on 99524 raw words (62819 effective words) took 0.2s, 361949 effective words/s\n",
      "2023-12-06 14:35:51,875 : INFO : EPOCH 1: training on 99524 raw words (62635 effective words) took 0.2s, 406082 effective words/s\n",
      "2023-12-06 14:35:52,038 : INFO : EPOCH 2: training on 99524 raw words (62773 effective words) took 0.2s, 395891 effective words/s\n",
      "2023-12-06 14:35:52,193 : INFO : EPOCH 3: training on 99524 raw words (62602 effective words) took 0.1s, 419534 effective words/s\n",
      "2023-12-06 14:35:52,332 : INFO : EPOCH 4: training on 99524 raw words (62671 effective words) took 0.1s, 463635 effective words/s\n",
      "2023-12-06 14:35:52,472 : INFO : EPOCH 5: training on 99524 raw words (62666 effective words) took 0.1s, 464540 effective words/s\n",
      "2023-12-06 14:35:52,619 : INFO : EPOCH 6: training on 99524 raw words (62842 effective words) took 0.1s, 440896 effective words/s\n",
      "2023-12-06 14:35:52,769 : INFO : EPOCH 7: training on 99524 raw words (62672 effective words) took 0.1s, 428018 effective words/s\n",
      "2023-12-06 14:35:52,915 : INFO : EPOCH 8: training on 99524 raw words (62750 effective words) took 0.1s, 446061 effective words/s\n",
      "2023-12-06 14:35:53,064 : INFO : EPOCH 9: training on 99524 raw words (62744 effective words) took 0.1s, 431772 effective words/s\n",
      "2023-12-06 14:35:53,204 : INFO : EPOCH 10: training on 99524 raw words (62695 effective words) took 0.1s, 462216 effective words/s\n",
      "2023-12-06 14:35:53,344 : INFO : EPOCH 11: training on 99524 raw words (62736 effective words) took 0.1s, 461050 effective words/s\n",
      "2023-12-06 14:35:53,493 : INFO : EPOCH 12: training on 99524 raw words (62729 effective words) took 0.1s, 436336 effective words/s\n",
      "2023-12-06 14:35:53,635 : INFO : EPOCH 13: training on 99524 raw words (62581 effective words) took 0.1s, 454519 effective words/s\n",
      "2023-12-06 14:35:53,776 : INFO : EPOCH 14: training on 99524 raw words (62806 effective words) took 0.1s, 461032 effective words/s\n",
      "2023-12-06 14:35:53,922 : INFO : EPOCH 15: training on 99524 raw words (62655 effective words) took 0.1s, 441281 effective words/s\n",
      "2023-12-06 14:35:54,061 : INFO : EPOCH 16: training on 99524 raw words (62662 effective words) took 0.1s, 465793 effective words/s\n",
      "2023-12-06 14:35:54,215 : INFO : EPOCH 17: training on 99524 raw words (62608 effective words) took 0.1s, 420129 effective words/s\n",
      "2023-12-06 14:35:54,361 : INFO : EPOCH 18: training on 99524 raw words (62717 effective words) took 0.1s, 442478 effective words/s\n",
      "2023-12-06 14:35:54,503 : INFO : EPOCH 19: training on 99524 raw words (62822 effective words) took 0.1s, 457295 effective words/s\n",
      "2023-12-06 14:35:54,643 : INFO : EPOCH 20: training on 99524 raw words (62722 effective words) took 0.1s, 459483 effective words/s\n",
      "2023-12-06 14:35:54,791 : INFO : EPOCH 21: training on 99524 raw words (62767 effective words) took 0.1s, 438949 effective words/s\n",
      "2023-12-06 14:35:54,931 : INFO : EPOCH 22: training on 99524 raw words (62922 effective words) took 0.1s, 464758 effective words/s\n",
      "2023-12-06 14:35:55,072 : INFO : EPOCH 23: training on 99524 raw words (62688 effective words) took 0.1s, 461761 effective words/s\n",
      "2023-12-06 14:35:55,219 : INFO : EPOCH 24: training on 99524 raw words (62748 effective words) took 0.1s, 435009 effective words/s\n",
      "2023-12-06 14:35:55,361 : INFO : EPOCH 25: training on 99524 raw words (62723 effective words) took 0.1s, 457728 effective words/s\n",
      "2023-12-06 14:35:55,503 : INFO : EPOCH 26: training on 99524 raw words (62727 effective words) took 0.1s, 458167 effective words/s\n",
      "2023-12-06 14:35:55,648 : INFO : EPOCH 27: training on 99524 raw words (62809 effective words) took 0.1s, 442027 effective words/s\n",
      "2023-12-06 14:35:55,788 : INFO : EPOCH 28: training on 99524 raw words (62687 effective words) took 0.1s, 467235 effective words/s\n",
      "2023-12-06 14:35:55,929 : INFO : EPOCH 29: training on 99524 raw words (62771 effective words) took 0.1s, 462297 effective words/s\n",
      "2023-12-06 14:35:55,930 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881749 effective words) took 4.4s, 428638 effective words/s', 'datetime': '2023-12-06T14:35:55.930014', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:35:55,931 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:35:55.931021', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 31%|       | 150/486 [22:17<39:19,  7.02s/it]2023-12-06 14:35:59,100 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:35:59,101 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:35:59,122 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:35:59,123 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:35:59,130 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:35:59.130741', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:59,130 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:35:59.130741', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:59,136 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:35:59,137 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:35:59,137 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:35:59.137760', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:35:59,149 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:35:59,150 : INFO : resetting layer weights\n",
      "2023-12-06 14:35:59,152 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:35:59.152912', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:35:59,320 : INFO : EPOCH 0: training on 99524 raw words (62646 effective words) took 0.2s, 381779 effective words/s\n",
      "2023-12-06 14:35:59,465 : INFO : EPOCH 1: training on 99524 raw words (62787 effective words) took 0.1s, 453626 effective words/s\n",
      "2023-12-06 14:35:59,607 : INFO : EPOCH 2: training on 99524 raw words (62700 effective words) took 0.1s, 455616 effective words/s\n",
      "2023-12-06 14:35:59,759 : INFO : EPOCH 3: training on 99524 raw words (62743 effective words) took 0.1s, 429357 effective words/s\n",
      "2023-12-06 14:35:59,901 : INFO : EPOCH 4: training on 99524 raw words (62806 effective words) took 0.1s, 453000 effective words/s\n",
      "2023-12-06 14:36:00,051 : INFO : EPOCH 5: training on 99524 raw words (62558 effective words) took 0.1s, 431369 effective words/s\n",
      "2023-12-06 14:36:00,192 : INFO : EPOCH 6: training on 99524 raw words (62624 effective words) took 0.1s, 458918 effective words/s\n",
      "2023-12-06 14:36:00,335 : INFO : EPOCH 7: training on 99524 raw words (62770 effective words) took 0.1s, 452241 effective words/s\n",
      "2023-12-06 14:36:00,481 : INFO : EPOCH 8: training on 99524 raw words (62601 effective words) took 0.1s, 440692 effective words/s\n",
      "2023-12-06 14:36:00,626 : INFO : EPOCH 9: training on 99524 raw words (62667 effective words) took 0.1s, 451260 effective words/s\n",
      "2023-12-06 14:36:00,771 : INFO : EPOCH 10: training on 99524 raw words (62633 effective words) took 0.1s, 443126 effective words/s\n",
      "2023-12-06 14:36:00,927 : INFO : EPOCH 11: training on 99524 raw words (62847 effective words) took 0.2s, 417505 effective words/s\n",
      "2023-12-06 14:36:01,072 : INFO : EPOCH 12: training on 99524 raw words (62823 effective words) took 0.1s, 446907 effective words/s\n",
      "2023-12-06 14:36:01,214 : INFO : EPOCH 13: training on 99524 raw words (62604 effective words) took 0.1s, 454549 effective words/s\n",
      "2023-12-06 14:36:01,362 : INFO : EPOCH 14: training on 99524 raw words (62777 effective words) took 0.1s, 434151 effective words/s\n",
      "2023-12-06 14:36:01,505 : INFO : EPOCH 15: training on 99524 raw words (62611 effective words) took 0.1s, 452222 effective words/s\n",
      "2023-12-06 14:36:01,646 : INFO : EPOCH 16: training on 99524 raw words (62671 effective words) took 0.1s, 458713 effective words/s\n",
      "2023-12-06 14:36:01,794 : INFO : EPOCH 17: training on 99524 raw words (62685 effective words) took 0.1s, 437263 effective words/s\n",
      "2023-12-06 14:36:01,935 : INFO : EPOCH 18: training on 99524 raw words (62717 effective words) took 0.1s, 459074 effective words/s\n",
      "2023-12-06 14:36:02,075 : INFO : EPOCH 19: training on 99524 raw words (62661 effective words) took 0.1s, 465298 effective words/s\n",
      "2023-12-06 14:36:02,227 : INFO : EPOCH 20: training on 99524 raw words (62641 effective words) took 0.1s, 421157 effective words/s\n",
      "2023-12-06 14:36:02,370 : INFO : EPOCH 21: training on 99524 raw words (62762 effective words) took 0.1s, 453182 effective words/s\n",
      "2023-12-06 14:36:02,515 : INFO : EPOCH 22: training on 99524 raw words (62906 effective words) took 0.1s, 446944 effective words/s\n",
      "2023-12-06 14:36:02,657 : INFO : EPOCH 23: training on 99524 raw words (62720 effective words) took 0.1s, 460437 effective words/s\n",
      "2023-12-06 14:36:02,797 : INFO : EPOCH 24: training on 99524 raw words (62894 effective words) took 0.1s, 462524 effective words/s\n",
      "2023-12-06 14:36:02,946 : INFO : EPOCH 25: training on 99524 raw words (62638 effective words) took 0.1s, 434342 effective words/s\n",
      "2023-12-06 14:36:03,087 : INFO : EPOCH 26: training on 99524 raw words (62848 effective words) took 0.1s, 458538 effective words/s\n",
      "2023-12-06 14:36:03,237 : INFO : EPOCH 27: training on 99524 raw words (63053 effective words) took 0.1s, 432340 effective words/s\n",
      "2023-12-06 14:36:03,388 : INFO : EPOCH 28: training on 99524 raw words (62770 effective words) took 0.1s, 432989 effective words/s\n",
      "2023-12-06 14:36:03,531 : INFO : EPOCH 29: training on 99524 raw words (62621 effective words) took 0.1s, 451511 effective words/s\n",
      "2023-12-06 14:36:03,672 : INFO : EPOCH 30: training on 99524 raw words (62647 effective words) took 0.1s, 458332 effective words/s\n",
      "2023-12-06 14:36:03,819 : INFO : EPOCH 31: training on 99524 raw words (62778 effective words) took 0.1s, 442572 effective words/s\n",
      "2023-12-06 14:36:03,963 : INFO : EPOCH 32: training on 99524 raw words (62772 effective words) took 0.1s, 451003 effective words/s\n",
      "2023-12-06 14:36:04,117 : INFO : EPOCH 33: training on 99524 raw words (62766 effective words) took 0.2s, 417900 effective words/s\n",
      "2023-12-06 14:36:04,265 : INFO : EPOCH 34: training on 99524 raw words (62812 effective words) took 0.1s, 441586 effective words/s\n",
      "2023-12-06 14:36:04,408 : INFO : EPOCH 35: training on 99524 raw words (62777 effective words) took 0.1s, 450371 effective words/s\n",
      "2023-12-06 14:36:04,556 : INFO : EPOCH 36: training on 99524 raw words (62812 effective words) took 0.1s, 439405 effective words/s\n",
      "2023-12-06 14:36:04,701 : INFO : EPOCH 37: training on 99524 raw words (62571 effective words) took 0.1s, 444808 effective words/s\n",
      "2023-12-06 14:36:04,844 : INFO : EPOCH 38: training on 99524 raw words (62645 effective words) took 0.1s, 452223 effective words/s\n",
      "2023-12-06 14:36:04,991 : INFO : EPOCH 39: training on 99524 raw words (62748 effective words) took 0.1s, 437943 effective words/s\n",
      "2023-12-06 14:36:05,133 : INFO : EPOCH 40: training on 99524 raw words (62702 effective words) took 0.1s, 456689 effective words/s\n",
      "2023-12-06 14:36:05,276 : INFO : EPOCH 41: training on 99524 raw words (62903 effective words) took 0.1s, 455356 effective words/s\n",
      "2023-12-06 14:36:05,424 : INFO : EPOCH 42: training on 99524 raw words (62795 effective words) took 0.1s, 435591 effective words/s\n",
      "2023-12-06 14:36:05,575 : INFO : EPOCH 43: training on 99524 raw words (62838 effective words) took 0.1s, 427152 effective words/s\n",
      "2023-12-06 14:36:05,719 : INFO : EPOCH 44: training on 99524 raw words (62663 effective words) took 0.1s, 451492 effective words/s\n",
      "2023-12-06 14:36:05,869 : INFO : EPOCH 45: training on 99524 raw words (62686 effective words) took 0.1s, 427638 effective words/s\n",
      "2023-12-06 14:36:06,012 : INFO : EPOCH 46: training on 99524 raw words (62778 effective words) took 0.1s, 455079 effective words/s\n",
      "2023-12-06 14:36:06,160 : INFO : EPOCH 47: training on 99524 raw words (62695 effective words) took 0.1s, 438158 effective words/s\n",
      "2023-12-06 14:36:06,303 : INFO : EPOCH 48: training on 99524 raw words (62861 effective words) took 0.1s, 451692 effective words/s\n",
      "2023-12-06 14:36:06,445 : INFO : EPOCH 49: training on 99524 raw words (62803 effective words) took 0.1s, 458471 effective words/s\n",
      "2023-12-06 14:36:06,446 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136836 effective words) took 7.3s, 430137 effective words/s', 'datetime': '2023-12-06T14:36:06.446149', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:36:06,446 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:36:06.446149', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 31%|       | 151/486 [22:28<44:59,  8.06s/it]2023-12-06 14:36:09,569 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:36:09,569 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:36:09,590 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:36:09,591 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:36:09,597 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:36:09.597521', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:36:09,598 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:36:09.598521', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:36:09,604 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:36:09,606 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:36:09,606 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:36:09.606522', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:36:09,618 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:36:09,619 : INFO : resetting layer weights\n",
      "2023-12-06 14:36:09,620 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:36:09.620030', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:36:09,782 : INFO : EPOCH 0: training on 99524 raw words (62779 effective words) took 0.2s, 395570 effective words/s\n",
      "2023-12-06 14:36:09,935 : INFO : EPOCH 1: training on 99524 raw words (62815 effective words) took 0.1s, 429088 effective words/s\n",
      "2023-12-06 14:36:10,076 : INFO : EPOCH 2: training on 99524 raw words (62645 effective words) took 0.1s, 457983 effective words/s\n",
      "2023-12-06 14:36:10,224 : INFO : EPOCH 3: training on 99524 raw words (62738 effective words) took 0.1s, 438365 effective words/s\n",
      "2023-12-06 14:36:10,366 : INFO : EPOCH 4: training on 99524 raw words (62740 effective words) took 0.1s, 453852 effective words/s\n",
      "2023-12-06 14:36:10,509 : INFO : EPOCH 5: training on 99524 raw words (62702 effective words) took 0.1s, 451285 effective words/s\n",
      "2023-12-06 14:36:10,657 : INFO : EPOCH 6: training on 99524 raw words (62749 effective words) took 0.1s, 439466 effective words/s\n",
      "2023-12-06 14:36:10,797 : INFO : EPOCH 7: training on 99524 raw words (62753 effective words) took 0.1s, 458497 effective words/s\n",
      "2023-12-06 14:36:10,937 : INFO : EPOCH 8: training on 99524 raw words (62823 effective words) took 0.1s, 464283 effective words/s\n",
      "2023-12-06 14:36:11,083 : INFO : EPOCH 9: training on 99524 raw words (62789 effective words) took 0.1s, 444316 effective words/s\n",
      "2023-12-06 14:36:11,227 : INFO : EPOCH 10: training on 99524 raw words (62681 effective words) took 0.1s, 451590 effective words/s\n",
      "2023-12-06 14:36:11,367 : INFO : EPOCH 11: training on 99524 raw words (62767 effective words) took 0.1s, 461145 effective words/s\n",
      "2023-12-06 14:36:11,514 : INFO : EPOCH 12: training on 99524 raw words (62852 effective words) took 0.1s, 439485 effective words/s\n",
      "2023-12-06 14:36:11,656 : INFO : EPOCH 13: training on 99524 raw words (62732 effective words) took 0.1s, 453928 effective words/s\n",
      "2023-12-06 14:36:11,796 : INFO : EPOCH 14: training on 99524 raw words (62899 effective words) took 0.1s, 463647 effective words/s\n",
      "2023-12-06 14:36:11,946 : INFO : EPOCH 15: training on 99524 raw words (62553 effective words) took 0.1s, 430099 effective words/s\n",
      "2023-12-06 14:36:12,089 : INFO : EPOCH 16: training on 99524 raw words (62828 effective words) took 0.1s, 455516 effective words/s\n",
      "2023-12-06 14:36:12,241 : INFO : EPOCH 17: training on 99524 raw words (62682 effective words) took 0.1s, 424119 effective words/s\n",
      "2023-12-06 14:36:12,390 : INFO : EPOCH 18: training on 99524 raw words (62590 effective words) took 0.1s, 433893 effective words/s\n",
      "2023-12-06 14:36:12,532 : INFO : EPOCH 19: training on 99524 raw words (62641 effective words) took 0.1s, 455402 effective words/s\n",
      "2023-12-06 14:36:12,671 : INFO : EPOCH 20: training on 99524 raw words (62773 effective words) took 0.1s, 464509 effective words/s\n",
      "2023-12-06 14:36:12,818 : INFO : EPOCH 21: training on 99524 raw words (62701 effective words) took 0.1s, 439857 effective words/s\n",
      "2023-12-06 14:36:12,958 : INFO : EPOCH 22: training on 99524 raw words (62908 effective words) took 0.1s, 464022 effective words/s\n",
      "2023-12-06 14:36:13,100 : INFO : EPOCH 23: training on 99524 raw words (62757 effective words) took 0.1s, 456756 effective words/s\n",
      "2023-12-06 14:36:13,246 : INFO : EPOCH 24: training on 99524 raw words (62853 effective words) took 0.1s, 442845 effective words/s\n",
      "2023-12-06 14:36:13,387 : INFO : EPOCH 25: training on 99524 raw words (62611 effective words) took 0.1s, 455967 effective words/s\n",
      "2023-12-06 14:36:13,531 : INFO : EPOCH 26: training on 99524 raw words (62730 effective words) took 0.1s, 451765 effective words/s\n",
      "2023-12-06 14:36:13,682 : INFO : EPOCH 27: training on 99524 raw words (62815 effective words) took 0.1s, 426467 effective words/s\n",
      "2023-12-06 14:36:13,835 : INFO : EPOCH 28: training on 99524 raw words (62788 effective words) took 0.1s, 424663 effective words/s\n",
      "2023-12-06 14:36:13,977 : INFO : EPOCH 29: training on 99524 raw words (62684 effective words) took 0.1s, 458298 effective words/s\n",
      "2023-12-06 14:36:14,125 : INFO : EPOCH 30: training on 99524 raw words (62726 effective words) took 0.1s, 434557 effective words/s\n",
      "2023-12-06 14:36:14,273 : INFO : EPOCH 31: training on 99524 raw words (62585 effective words) took 0.1s, 437997 effective words/s\n",
      "2023-12-06 14:36:14,414 : INFO : EPOCH 32: training on 99524 raw words (62720 effective words) took 0.1s, 459142 effective words/s\n",
      "2023-12-06 14:36:14,561 : INFO : EPOCH 33: training on 99524 raw words (62831 effective words) took 0.1s, 441821 effective words/s\n",
      "2023-12-06 14:36:14,703 : INFO : EPOCH 34: training on 99524 raw words (62964 effective words) took 0.1s, 456745 effective words/s\n",
      "2023-12-06 14:36:14,846 : INFO : EPOCH 35: training on 99524 raw words (62749 effective words) took 0.1s, 452420 effective words/s\n",
      "2023-12-06 14:36:14,992 : INFO : EPOCH 36: training on 99524 raw words (62612 effective words) took 0.1s, 440391 effective words/s\n",
      "2023-12-06 14:36:15,135 : INFO : EPOCH 37: training on 99524 raw words (62750 effective words) took 0.1s, 455912 effective words/s\n",
      "2023-12-06 14:36:15,276 : INFO : EPOCH 38: training on 99524 raw words (62547 effective words) took 0.1s, 456934 effective words/s\n",
      "2023-12-06 14:36:15,423 : INFO : EPOCH 39: training on 99524 raw words (62680 effective words) took 0.1s, 441179 effective words/s\n",
      "2023-12-06 14:36:15,565 : INFO : EPOCH 40: training on 99524 raw words (62682 effective words) took 0.1s, 457611 effective words/s\n",
      "2023-12-06 14:36:15,712 : INFO : EPOCH 41: training on 99524 raw words (62827 effective words) took 0.1s, 439632 effective words/s\n",
      "2023-12-06 14:36:15,856 : INFO : EPOCH 42: training on 99524 raw words (62730 effective words) took 0.1s, 450550 effective words/s\n",
      "2023-12-06 14:36:15,996 : INFO : EPOCH 43: training on 99524 raw words (62723 effective words) took 0.1s, 461469 effective words/s\n",
      "2023-12-06 14:36:16,152 : INFO : EPOCH 44: training on 99524 raw words (62684 effective words) took 0.2s, 413877 effective words/s\n",
      "2023-12-06 14:36:16,302 : INFO : EPOCH 45: training on 99524 raw words (62483 effective words) took 0.1s, 430365 effective words/s\n",
      "2023-12-06 14:36:16,446 : INFO : EPOCH 46: training on 99524 raw words (62748 effective words) took 0.1s, 449338 effective words/s\n",
      "2023-12-06 14:36:16,587 : INFO : EPOCH 47: training on 99524 raw words (62659 effective words) took 0.1s, 456390 effective words/s\n",
      "2023-12-06 14:36:16,736 : INFO : EPOCH 48: training on 99524 raw words (62661 effective words) took 0.1s, 437170 effective words/s\n",
      "2023-12-06 14:36:16,881 : INFO : EPOCH 49: training on 99524 raw words (62766 effective words) took 0.1s, 446062 effective words/s\n",
      "2023-12-06 14:36:16,881 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136505 effective words) took 7.3s, 431979 effective words/s', 'datetime': '2023-12-06T14:36:16.881462', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:36:16,882 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:36:16.882461', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 31%|      | 152/486 [22:38<49:18,  8.86s/it]2023-12-06 14:36:20,301 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:36:20,301 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:36:20,322 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:36:20,323 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:36:20,328 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:36:20.328468', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:36:20,328 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:36:20.328468', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:36:20,337 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:36:20,337 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:36:20,338 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:36:20.338254', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:36:20,346 : INFO : estimated required memory for 1509 words and 50 dimensions: 3083300 bytes\n",
      "2023-12-06 14:36:20,346 : INFO : resetting layer weights\n",
      "2023-12-06 14:36:20,348 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:36:20.348486', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:36:20,498 : INFO : EPOCH 0: training on 99524 raw words (62719 effective words) took 0.1s, 428285 effective words/s\n",
      "2023-12-06 14:36:20,653 : INFO : EPOCH 1: training on 99524 raw words (62794 effective words) took 0.1s, 420285 effective words/s\n",
      "2023-12-06 14:36:20,801 : INFO : EPOCH 2: training on 99524 raw words (62846 effective words) took 0.1s, 440185 effective words/s\n",
      "2023-12-06 14:36:20,940 : INFO : EPOCH 3: training on 99524 raw words (62621 effective words) took 0.1s, 465081 effective words/s\n",
      "2023-12-06 14:36:21,080 : INFO : EPOCH 4: training on 99524 raw words (62701 effective words) took 0.1s, 460006 effective words/s\n",
      "2023-12-06 14:36:21,225 : INFO : EPOCH 5: training on 99524 raw words (62718 effective words) took 0.1s, 448981 effective words/s\n",
      "2023-12-06 14:36:21,363 : INFO : EPOCH 6: training on 99524 raw words (62595 effective words) took 0.1s, 468144 effective words/s\n",
      "2023-12-06 14:36:21,513 : INFO : EPOCH 7: training on 99524 raw words (62835 effective words) took 0.1s, 432286 effective words/s\n",
      "2023-12-06 14:36:21,654 : INFO : EPOCH 8: training on 99524 raw words (62831 effective words) took 0.1s, 457364 effective words/s\n",
      "2023-12-06 14:36:21,795 : INFO : EPOCH 9: training on 99524 raw words (62823 effective words) took 0.1s, 462063 effective words/s\n",
      "2023-12-06 14:36:21,943 : INFO : EPOCH 10: training on 99524 raw words (62638 effective words) took 0.1s, 437188 effective words/s\n",
      "2023-12-06 14:36:22,086 : INFO : EPOCH 11: training on 99524 raw words (62777 effective words) took 0.1s, 454791 effective words/s\n",
      "2023-12-06 14:36:22,226 : INFO : EPOCH 12: training on 99524 raw words (62700 effective words) took 0.1s, 461025 effective words/s\n",
      "2023-12-06 14:36:22,373 : INFO : EPOCH 13: training on 99524 raw words (62691 effective words) took 0.1s, 442254 effective words/s\n",
      "2023-12-06 14:36:22,515 : INFO : EPOCH 14: training on 99524 raw words (62674 effective words) took 0.1s, 453762 effective words/s\n",
      "2023-12-06 14:36:22,670 : INFO : EPOCH 15: training on 99524 raw words (62674 effective words) took 0.2s, 417228 effective words/s\n",
      "2023-12-06 14:36:22,812 : INFO : EPOCH 16: training on 99524 raw words (62809 effective words) took 0.1s, 457099 effective words/s\n",
      "2023-12-06 14:36:22,957 : INFO : EPOCH 17: training on 99524 raw words (62633 effective words) took 0.1s, 446535 effective words/s\n",
      "2023-12-06 14:36:23,102 : INFO : EPOCH 18: training on 99524 raw words (62632 effective words) took 0.1s, 447416 effective words/s\n",
      "2023-12-06 14:36:23,243 : INFO : EPOCH 19: training on 99524 raw words (62983 effective words) took 0.1s, 460544 effective words/s\n",
      "2023-12-06 14:36:23,391 : INFO : EPOCH 20: training on 99524 raw words (62773 effective words) took 0.1s, 439919 effective words/s\n",
      "2023-12-06 14:36:23,530 : INFO : EPOCH 21: training on 99524 raw words (62616 effective words) took 0.1s, 461975 effective words/s\n",
      "2023-12-06 14:36:23,672 : INFO : EPOCH 22: training on 99524 raw words (62826 effective words) took 0.1s, 457300 effective words/s\n",
      "2023-12-06 14:36:23,819 : INFO : EPOCH 23: training on 99524 raw words (62773 effective words) took 0.1s, 441935 effective words/s\n",
      "2023-12-06 14:36:23,958 : INFO : EPOCH 24: training on 99524 raw words (62673 effective words) took 0.1s, 464062 effective words/s\n",
      "2023-12-06 14:36:24,100 : INFO : EPOCH 25: training on 99524 raw words (62486 effective words) took 0.1s, 453374 effective words/s\n",
      "2023-12-06 14:36:24,247 : INFO : EPOCH 26: training on 99524 raw words (62833 effective words) took 0.1s, 443336 effective words/s\n",
      "2023-12-06 14:36:24,386 : INFO : EPOCH 27: training on 99524 raw words (62798 effective words) took 0.1s, 467322 effective words/s\n",
      "2023-12-06 14:36:24,532 : INFO : EPOCH 28: training on 99524 raw words (62780 effective words) took 0.1s, 440912 effective words/s\n",
      "2023-12-06 14:36:24,682 : INFO : EPOCH 29: training on 99524 raw words (62761 effective words) took 0.1s, 431778 effective words/s\n",
      "2023-12-06 14:36:24,822 : INFO : EPOCH 30: training on 99524 raw words (62607 effective words) took 0.1s, 462226 effective words/s\n",
      "2023-12-06 14:36:24,969 : INFO : EPOCH 31: training on 99524 raw words (62614 effective words) took 0.1s, 443843 effective words/s\n",
      "2023-12-06 14:36:25,108 : INFO : EPOCH 32: training on 99524 raw words (62484 effective words) took 0.1s, 462242 effective words/s\n",
      "2023-12-06 14:36:25,255 : INFO : EPOCH 33: training on 99524 raw words (62787 effective words) took 0.1s, 441511 effective words/s\n",
      "2023-12-06 14:36:25,396 : INFO : EPOCH 34: training on 99524 raw words (62732 effective words) took 0.1s, 459859 effective words/s\n",
      "2023-12-06 14:36:25,536 : INFO : EPOCH 35: training on 99524 raw words (62797 effective words) took 0.1s, 461613 effective words/s\n",
      "2023-12-06 14:36:25,681 : INFO : EPOCH 36: training on 99524 raw words (62541 effective words) took 0.1s, 448771 effective words/s\n",
      "2023-12-06 14:36:25,823 : INFO : EPOCH 37: training on 99524 raw words (62695 effective words) took 0.1s, 456682 effective words/s\n",
      "2023-12-06 14:36:25,967 : INFO : EPOCH 38: training on 99524 raw words (62636 effective words) took 0.1s, 447554 effective words/s\n",
      "2023-12-06 14:36:26,107 : INFO : EPOCH 39: training on 99524 raw words (62767 effective words) took 0.1s, 463800 effective words/s\n",
      "2023-12-06 14:36:26,247 : INFO : EPOCH 40: training on 99524 raw words (62558 effective words) took 0.1s, 460251 effective words/s\n",
      "2023-12-06 14:36:26,395 : INFO : EPOCH 41: training on 99524 raw words (62917 effective words) took 0.1s, 441566 effective words/s\n",
      "2023-12-06 14:36:26,534 : INFO : EPOCH 42: training on 99524 raw words (62807 effective words) took 0.1s, 463343 effective words/s\n",
      "2023-12-06 14:36:26,676 : INFO : EPOCH 43: training on 99524 raw words (62789 effective words) took 0.1s, 457998 effective words/s\n",
      "2023-12-06 14:36:26,831 : INFO : EPOCH 44: training on 99524 raw words (62610 effective words) took 0.2s, 414176 effective words/s\n",
      "2023-12-06 14:36:26,974 : INFO : EPOCH 45: training on 99524 raw words (62725 effective words) took 0.1s, 454004 effective words/s\n",
      "2023-12-06 14:36:27,113 : INFO : EPOCH 46: training on 99524 raw words (62631 effective words) took 0.1s, 464128 effective words/s\n",
      "2023-12-06 14:36:27,260 : INFO : EPOCH 47: training on 99524 raw words (62605 effective words) took 0.1s, 442820 effective words/s\n",
      "2023-12-06 14:36:27,404 : INFO : EPOCH 48: training on 99524 raw words (62853 effective words) took 0.1s, 450990 effective words/s\n",
      "2023-12-06 14:36:27,549 : INFO : EPOCH 49: training on 99524 raw words (62944 effective words) took 0.1s, 445719 effective words/s\n",
      "2023-12-06 14:36:27,550 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136112 effective words) took 7.2s, 435484 effective words/s', 'datetime': '2023-12-06T14:36:27.550766', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:36:27,550 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:36:27.550766', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 31%|      | 153/486 [22:49<52:36,  9.48s/it]2023-12-06 14:36:31,227 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:36:31,227 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:36:31,249 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:36:31,251 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:36:31,256 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:36:31.256746', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:36:31,256 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:36:31.256746', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:36:31,262 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:36:31,262 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:36:31,263 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:36:31.263550', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:36:31,273 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:36:31,273 : INFO : resetting layer weights\n",
      "2023-12-06 14:36:31,275 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:36:31.275983', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:36:31,425 : INFO : EPOCH 0: training on 99524 raw words (60335 effective words) took 0.1s, 413054 effective words/s\n",
      "2023-12-06 14:36:31,581 : INFO : EPOCH 1: training on 99524 raw words (60463 effective words) took 0.1s, 405279 effective words/s\n",
      "2023-12-06 14:36:31,722 : INFO : EPOCH 2: training on 99524 raw words (60430 effective words) took 0.1s, 439993 effective words/s\n",
      "2023-12-06 14:36:31,868 : INFO : EPOCH 3: training on 99524 raw words (60180 effective words) took 0.1s, 424328 effective words/s\n",
      "2023-12-06 14:36:32,011 : INFO : EPOCH 4: training on 99524 raw words (60419 effective words) took 0.1s, 439099 effective words/s\n",
      "2023-12-06 14:36:32,150 : INFO : EPOCH 5: training on 99524 raw words (60395 effective words) took 0.1s, 447190 effective words/s\n",
      "2023-12-06 14:36:32,296 : INFO : EPOCH 6: training on 99524 raw words (60407 effective words) took 0.1s, 427343 effective words/s\n",
      "2023-12-06 14:36:32,437 : INFO : EPOCH 7: training on 99524 raw words (60374 effective words) took 0.1s, 443082 effective words/s\n",
      "2023-12-06 14:36:32,576 : INFO : EPOCH 8: training on 99524 raw words (60394 effective words) took 0.1s, 445749 effective words/s\n",
      "2023-12-06 14:36:32,724 : INFO : EPOCH 9: training on 99524 raw words (60287 effective words) took 0.1s, 424725 effective words/s\n",
      "2023-12-06 14:36:32,725 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603684 effective words) took 1.4s, 416770 effective words/s', 'datetime': '2023-12-06T14:36:32.725018', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:36:32,726 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:36:32.726018', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 32%|      | 154/486 [22:53<43:22,  7.84s/it]2023-12-06 14:36:35,234 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:36:35,234 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:36:35,255 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:36:35,256 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:36:35,261 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:36:35.261144', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:36:35,261 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:36:35.261144', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:36:35,266 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:36:35,267 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:36:35,267 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:36:35.267293', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:36:35,274 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:36:35,274 : INFO : resetting layer weights\n",
      "2023-12-06 14:36:35,276 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:36:35.276975', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:36:35,433 : INFO : EPOCH 0: training on 99524 raw words (60449 effective words) took 0.2s, 397035 effective words/s\n",
      "2023-12-06 14:36:35,591 : INFO : EPOCH 1: training on 99524 raw words (60392 effective words) took 0.2s, 398062 effective words/s\n",
      "2023-12-06 14:36:35,739 : INFO : EPOCH 2: training on 99524 raw words (60522 effective words) took 0.1s, 422268 effective words/s\n",
      "2023-12-06 14:36:35,888 : INFO : EPOCH 3: training on 99524 raw words (60404 effective words) took 0.1s, 417614 effective words/s\n",
      "2023-12-06 14:36:36,033 : INFO : EPOCH 4: training on 99524 raw words (60371 effective words) took 0.1s, 431889 effective words/s\n",
      "2023-12-06 14:36:36,180 : INFO : EPOCH 5: training on 99524 raw words (60444 effective words) took 0.1s, 421251 effective words/s\n",
      "2023-12-06 14:36:36,324 : INFO : EPOCH 6: training on 99524 raw words (60338 effective words) took 0.1s, 433219 effective words/s\n",
      "2023-12-06 14:36:36,475 : INFO : EPOCH 7: training on 99524 raw words (60438 effective words) took 0.1s, 411605 effective words/s\n",
      "2023-12-06 14:36:36,618 : INFO : EPOCH 8: training on 99524 raw words (60411 effective words) took 0.1s, 434644 effective words/s\n",
      "2023-12-06 14:36:36,766 : INFO : EPOCH 9: training on 99524 raw words (60340 effective words) took 0.1s, 421751 effective words/s\n",
      "2023-12-06 14:36:36,768 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604109 effective words) took 1.5s, 405358 effective words/s', 'datetime': '2023-12-06T14:36:36.768181', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:36:36,768 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:36:36.768181', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 32%|      | 155/486 [22:57<37:01,  6.71s/it]2023-12-06 14:36:39,317 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:36:39,319 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:36:39,340 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:36:39,341 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:36:39,345 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:36:39.345171', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:36:39,346 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:36:39.346171', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:36:39,351 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:36:39,351 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:36:39,352 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:36:39.352560', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:36:39,359 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:36:39,360 : INFO : resetting layer weights\n",
      "2023-12-06 14:36:39,362 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:36:39.362002', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:36:39,514 : INFO : EPOCH 0: training on 99524 raw words (60377 effective words) took 0.1s, 406933 effective words/s\n",
      "2023-12-06 14:36:39,668 : INFO : EPOCH 1: training on 99524 raw words (60298 effective words) took 0.1s, 405210 effective words/s\n",
      "2023-12-06 14:36:39,813 : INFO : EPOCH 2: training on 99524 raw words (60349 effective words) took 0.1s, 430606 effective words/s\n",
      "2023-12-06 14:36:39,959 : INFO : EPOCH 3: training on 99524 raw words (60312 effective words) took 0.1s, 425352 effective words/s\n",
      "2023-12-06 14:36:40,099 : INFO : EPOCH 4: training on 99524 raw words (60463 effective words) took 0.1s, 446149 effective words/s\n",
      "2023-12-06 14:36:40,238 : INFO : EPOCH 5: training on 99524 raw words (60252 effective words) took 0.1s, 446666 effective words/s\n",
      "2023-12-06 14:36:40,385 : INFO : EPOCH 6: training on 99524 raw words (60454 effective words) took 0.1s, 425467 effective words/s\n",
      "2023-12-06 14:36:40,527 : INFO : EPOCH 7: training on 99524 raw words (60443 effective words) took 0.1s, 442906 effective words/s\n",
      "2023-12-06 14:36:40,672 : INFO : EPOCH 8: training on 99524 raw words (60178 effective words) took 0.1s, 428131 effective words/s\n",
      "2023-12-06 14:36:40,825 : INFO : EPOCH 9: training on 99524 raw words (60304 effective words) took 0.1s, 405001 effective words/s\n",
      "2023-12-06 14:36:40,826 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603430 effective words) took 1.5s, 412288 effective words/s', 'datetime': '2023-12-06T14:36:40.826425', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:36:40,826 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:36:40.826425', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 32%|      | 156/486 [23:02<32:44,  5.95s/it]2023-12-06 14:36:43,501 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:36:43,502 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:36:43,521 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:36:43,522 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:36:43,528 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:36:43.528090', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:36:43,529 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:36:43.529090', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:36:43,534 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:36:43,535 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:36:43,536 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:36:43.536097', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:36:43,545 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:36:43,546 : INFO : resetting layer weights\n",
      "2023-12-06 14:36:43,547 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:36:43.547600', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:36:43,709 : INFO : EPOCH 0: training on 99524 raw words (60386 effective words) took 0.2s, 381946 effective words/s\n",
      "2023-12-06 14:36:43,860 : INFO : EPOCH 1: training on 99524 raw words (60288 effective words) took 0.1s, 413284 effective words/s\n",
      "2023-12-06 14:36:44,006 : INFO : EPOCH 2: training on 99524 raw words (60363 effective words) took 0.1s, 426957 effective words/s\n",
      "2023-12-06 14:36:44,154 : INFO : EPOCH 3: training on 99524 raw words (60206 effective words) took 0.1s, 419783 effective words/s\n",
      "2023-12-06 14:36:44,296 : INFO : EPOCH 4: training on 99524 raw words (60363 effective words) took 0.1s, 440227 effective words/s\n",
      "2023-12-06 14:36:44,443 : INFO : EPOCH 5: training on 99524 raw words (60446 effective words) took 0.1s, 420378 effective words/s\n",
      "2023-12-06 14:36:44,585 : INFO : EPOCH 6: training on 99524 raw words (60390 effective words) took 0.1s, 442362 effective words/s\n",
      "2023-12-06 14:36:44,732 : INFO : EPOCH 7: training on 99524 raw words (60397 effective words) took 0.1s, 420302 effective words/s\n",
      "2023-12-06 14:36:44,876 : INFO : EPOCH 8: training on 99524 raw words (60335 effective words) took 0.1s, 433846 effective words/s\n",
      "2023-12-06 14:36:45,022 : INFO : EPOCH 9: training on 99524 raw words (60307 effective words) took 0.1s, 424808 effective words/s\n",
      "2023-12-06 14:36:45,164 : INFO : EPOCH 10: training on 99524 raw words (60287 effective words) took 0.1s, 437124 effective words/s\n",
      "2023-12-06 14:36:45,315 : INFO : EPOCH 11: training on 99524 raw words (60364 effective words) took 0.1s, 413353 effective words/s\n",
      "2023-12-06 14:36:45,458 : INFO : EPOCH 12: training on 99524 raw words (60402 effective words) took 0.1s, 436645 effective words/s\n",
      "2023-12-06 14:36:45,606 : INFO : EPOCH 13: training on 99524 raw words (60245 effective words) took 0.1s, 417640 effective words/s\n",
      "2023-12-06 14:36:45,749 : INFO : EPOCH 14: training on 99524 raw words (60430 effective words) took 0.1s, 435136 effective words/s\n",
      "2023-12-06 14:36:45,894 : INFO : EPOCH 15: training on 99524 raw words (60173 effective words) took 0.1s, 429377 effective words/s\n",
      "2023-12-06 14:36:46,043 : INFO : EPOCH 16: training on 99524 raw words (60513 effective words) took 0.1s, 417404 effective words/s\n",
      "2023-12-06 14:36:46,191 : INFO : EPOCH 17: training on 99524 raw words (60489 effective words) took 0.1s, 424460 effective words/s\n",
      "2023-12-06 14:36:46,332 : INFO : EPOCH 18: training on 99524 raw words (60412 effective words) took 0.1s, 438512 effective words/s\n",
      "2023-12-06 14:36:46,476 : INFO : EPOCH 19: training on 99524 raw words (60429 effective words) took 0.1s, 435434 effective words/s\n",
      "2023-12-06 14:36:46,627 : INFO : EPOCH 20: training on 99524 raw words (60425 effective words) took 0.1s, 412980 effective words/s\n",
      "2023-12-06 14:36:46,769 : INFO : EPOCH 21: training on 99524 raw words (60545 effective words) took 0.1s, 439212 effective words/s\n",
      "2023-12-06 14:36:46,914 : INFO : EPOCH 22: training on 99524 raw words (60468 effective words) took 0.1s, 428962 effective words/s\n",
      "2023-12-06 14:36:47,056 : INFO : EPOCH 23: training on 99524 raw words (60390 effective words) took 0.1s, 438444 effective words/s\n",
      "2023-12-06 14:36:47,208 : INFO : EPOCH 24: training on 99524 raw words (60433 effective words) took 0.1s, 413769 effective words/s\n",
      "2023-12-06 14:36:47,350 : INFO : EPOCH 25: training on 99524 raw words (60238 effective words) took 0.1s, 437110 effective words/s\n",
      "2023-12-06 14:36:47,497 : INFO : EPOCH 26: training on 99524 raw words (60525 effective words) took 0.1s, 425309 effective words/s\n",
      "2023-12-06 14:36:47,640 : INFO : EPOCH 27: training on 99524 raw words (60639 effective words) took 0.1s, 438909 effective words/s\n",
      "2023-12-06 14:36:47,790 : INFO : EPOCH 28: training on 99524 raw words (60210 effective words) took 0.1s, 412418 effective words/s\n",
      "2023-12-06 14:36:47,951 : INFO : EPOCH 29: training on 99524 raw words (60354 effective words) took 0.2s, 386443 effective words/s\n",
      "2023-12-06 14:36:47,952 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811452 effective words) took 4.4s, 411269 effective words/s', 'datetime': '2023-12-06T14:36:47.952404', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:36:47,953 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:36:47.953403', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 32%|      | 157/486 [23:09<34:54,  6.37s/it]2023-12-06 14:36:50,830 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:36:50,830 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:36:50,852 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:36:50,853 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:36:50,859 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:36:50.859915', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:36:50,860 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:36:50.860914', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:36:50,867 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:36:50,868 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:36:50,869 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:36:50.869914', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:36:50,880 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:36:50,881 : INFO : resetting layer weights\n",
      "2023-12-06 14:36:50,883 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:36:50.883022', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:36:51,062 : INFO : EPOCH 0: training on 99524 raw words (60225 effective words) took 0.2s, 343862 effective words/s\n",
      "2023-12-06 14:36:51,207 : INFO : EPOCH 1: training on 99524 raw words (60448 effective words) took 0.1s, 431384 effective words/s\n",
      "2023-12-06 14:36:51,358 : INFO : EPOCH 2: training on 99524 raw words (60479 effective words) took 0.1s, 415049 effective words/s\n",
      "2023-12-06 14:36:51,501 : INFO : EPOCH 3: training on 99524 raw words (60262 effective words) took 0.1s, 434656 effective words/s\n",
      "2023-12-06 14:36:51,648 : INFO : EPOCH 4: training on 99524 raw words (60444 effective words) took 0.1s, 420745 effective words/s\n",
      "2023-12-06 14:36:51,792 : INFO : EPOCH 5: training on 99524 raw words (60313 effective words) took 0.1s, 434294 effective words/s\n",
      "2023-12-06 14:36:51,934 : INFO : EPOCH 6: training on 99524 raw words (60326 effective words) took 0.1s, 436164 effective words/s\n",
      "2023-12-06 14:36:52,084 : INFO : EPOCH 7: training on 99524 raw words (60490 effective words) took 0.1s, 417211 effective words/s\n",
      "2023-12-06 14:36:52,228 : INFO : EPOCH 8: training on 99524 raw words (60428 effective words) took 0.1s, 431306 effective words/s\n",
      "2023-12-06 14:36:52,378 : INFO : EPOCH 9: training on 99524 raw words (60286 effective words) took 0.1s, 415761 effective words/s\n",
      "2023-12-06 14:36:52,521 : INFO : EPOCH 10: training on 99524 raw words (60428 effective words) took 0.1s, 434982 effective words/s\n",
      "2023-12-06 14:36:52,664 : INFO : EPOCH 11: training on 99524 raw words (60511 effective words) took 0.1s, 437565 effective words/s\n",
      "2023-12-06 14:36:52,813 : INFO : EPOCH 12: training on 99524 raw words (60413 effective words) took 0.1s, 417098 effective words/s\n",
      "2023-12-06 14:36:52,956 : INFO : EPOCH 13: training on 99524 raw words (60433 effective words) took 0.1s, 434073 effective words/s\n",
      "2023-12-06 14:36:53,109 : INFO : EPOCH 14: training on 99524 raw words (60509 effective words) took 0.1s, 409361 effective words/s\n",
      "2023-12-06 14:36:53,264 : INFO : EPOCH 15: training on 99524 raw words (60298 effective words) took 0.2s, 401406 effective words/s\n",
      "2023-12-06 14:36:53,416 : INFO : EPOCH 16: training on 99524 raw words (60586 effective words) took 0.1s, 409454 effective words/s\n",
      "2023-12-06 14:36:53,561 : INFO : EPOCH 17: training on 99524 raw words (60284 effective words) took 0.1s, 427409 effective words/s\n",
      "2023-12-06 14:36:53,713 : INFO : EPOCH 18: training on 99524 raw words (60365 effective words) took 0.1s, 407538 effective words/s\n",
      "2023-12-06 14:36:53,859 : INFO : EPOCH 19: training on 99524 raw words (60358 effective words) took 0.1s, 428505 effective words/s\n",
      "2023-12-06 14:36:54,012 : INFO : EPOCH 20: training on 99524 raw words (60446 effective words) took 0.1s, 407563 effective words/s\n",
      "2023-12-06 14:36:54,157 : INFO : EPOCH 21: training on 99524 raw words (60520 effective words) took 0.1s, 430181 effective words/s\n",
      "2023-12-06 14:36:54,316 : INFO : EPOCH 22: training on 99524 raw words (60446 effective words) took 0.2s, 393005 effective words/s\n",
      "2023-12-06 14:36:54,472 : INFO : EPOCH 23: training on 99524 raw words (60459 effective words) took 0.2s, 401586 effective words/s\n",
      "2023-12-06 14:36:54,648 : INFO : EPOCH 24: training on 99524 raw words (60391 effective words) took 0.2s, 353909 effective words/s\n",
      "2023-12-06 14:36:54,791 : INFO : EPOCH 25: training on 99524 raw words (60345 effective words) took 0.1s, 434196 effective words/s\n",
      "2023-12-06 14:36:54,935 : INFO : EPOCH 26: training on 99524 raw words (60464 effective words) took 0.1s, 433418 effective words/s\n",
      "2023-12-06 14:36:55,085 : INFO : EPOCH 27: training on 99524 raw words (60453 effective words) took 0.1s, 413193 effective words/s\n",
      "2023-12-06 14:36:55,230 : INFO : EPOCH 28: training on 99524 raw words (60376 effective words) took 0.1s, 432773 effective words/s\n",
      "2023-12-06 14:36:55,381 : INFO : EPOCH 29: training on 99524 raw words (60549 effective words) took 0.1s, 414892 effective words/s\n",
      "2023-12-06 14:36:55,382 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812335 effective words) took 4.5s, 402958 effective words/s', 'datetime': '2023-12-06T14:36:55.382118', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:36:55,383 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:36:55.383118', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 33%|      | 158/486 [23:17<36:54,  6.75s/it]2023-12-06 14:36:58,485 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:36:58,486 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:36:58,506 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:36:58,507 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:36:58,512 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:36:58.512877', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:36:58,512 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:36:58.512877', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:36:58,517 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:36:58,518 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:36:58,519 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:36:58.519440', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:36:58,525 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:36:58,526 : INFO : resetting layer weights\n",
      "2023-12-06 14:36:58,527 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:36:58.527953', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:36:58,695 : INFO : EPOCH 0: training on 99524 raw words (60196 effective words) took 0.2s, 371394 effective words/s\n",
      "2023-12-06 14:36:58,855 : INFO : EPOCH 1: training on 99524 raw words (60454 effective words) took 0.2s, 394937 effective words/s\n",
      "2023-12-06 14:36:58,996 : INFO : EPOCH 2: training on 99524 raw words (60318 effective words) took 0.1s, 443673 effective words/s\n",
      "2023-12-06 14:36:59,141 : INFO : EPOCH 3: training on 99524 raw words (60296 effective words) took 0.1s, 427434 effective words/s\n",
      "2023-12-06 14:36:59,281 : INFO : EPOCH 4: training on 99524 raw words (60414 effective words) took 0.1s, 449174 effective words/s\n",
      "2023-12-06 14:36:59,426 : INFO : EPOCH 5: training on 99524 raw words (60428 effective words) took 0.1s, 427789 effective words/s\n",
      "2023-12-06 14:36:59,568 : INFO : EPOCH 6: training on 99524 raw words (60272 effective words) took 0.1s, 440204 effective words/s\n",
      "2023-12-06 14:36:59,714 : INFO : EPOCH 7: training on 99524 raw words (60379 effective words) took 0.1s, 428372 effective words/s\n",
      "2023-12-06 14:36:59,854 : INFO : EPOCH 8: training on 99524 raw words (60448 effective words) took 0.1s, 444233 effective words/s\n",
      "2023-12-06 14:37:00,000 : INFO : EPOCH 9: training on 99524 raw words (60244 effective words) took 0.1s, 423201 effective words/s\n",
      "2023-12-06 14:37:00,141 : INFO : EPOCH 10: training on 99524 raw words (60390 effective words) took 0.1s, 443446 effective words/s\n",
      "2023-12-06 14:37:00,282 : INFO : EPOCH 11: training on 99524 raw words (60421 effective words) took 0.1s, 442934 effective words/s\n",
      "2023-12-06 14:37:00,429 : INFO : EPOCH 12: training on 99524 raw words (60327 effective words) took 0.1s, 424527 effective words/s\n",
      "2023-12-06 14:37:00,574 : INFO : EPOCH 13: training on 99524 raw words (60434 effective words) took 0.1s, 427336 effective words/s\n",
      "2023-12-06 14:37:00,715 : INFO : EPOCH 14: training on 99524 raw words (60368 effective words) took 0.1s, 440624 effective words/s\n",
      "2023-12-06 14:37:00,869 : INFO : EPOCH 15: training on 99524 raw words (60284 effective words) took 0.1s, 406779 effective words/s\n",
      "2023-12-06 14:37:01,011 : INFO : EPOCH 16: training on 99524 raw words (60383 effective words) took 0.1s, 437395 effective words/s\n",
      "2023-12-06 14:37:01,160 : INFO : EPOCH 17: training on 99524 raw words (60302 effective words) took 0.1s, 414627 effective words/s\n",
      "2023-12-06 14:37:01,301 : INFO : EPOCH 18: training on 99524 raw words (60394 effective words) took 0.1s, 445546 effective words/s\n",
      "2023-12-06 14:37:01,447 : INFO : EPOCH 19: training on 99524 raw words (60493 effective words) took 0.1s, 428470 effective words/s\n",
      "2023-12-06 14:37:01,586 : INFO : EPOCH 20: training on 99524 raw words (60439 effective words) took 0.1s, 449913 effective words/s\n",
      "2023-12-06 14:37:01,731 : INFO : EPOCH 21: training on 99524 raw words (60449 effective words) took 0.1s, 428128 effective words/s\n",
      "2023-12-06 14:37:01,872 : INFO : EPOCH 22: training on 99524 raw words (60573 effective words) took 0.1s, 445365 effective words/s\n",
      "2023-12-06 14:37:02,019 : INFO : EPOCH 23: training on 99524 raw words (60400 effective words) took 0.1s, 422341 effective words/s\n",
      "2023-12-06 14:37:02,159 : INFO : EPOCH 24: training on 99524 raw words (60284 effective words) took 0.1s, 445604 effective words/s\n",
      "2023-12-06 14:37:02,304 : INFO : EPOCH 25: training on 99524 raw words (60409 effective words) took 0.1s, 428364 effective words/s\n",
      "2023-12-06 14:37:02,444 : INFO : EPOCH 26: training on 99524 raw words (60644 effective words) took 0.1s, 445579 effective words/s\n",
      "2023-12-06 14:37:02,590 : INFO : EPOCH 27: training on 99524 raw words (60494 effective words) took 0.1s, 430303 effective words/s\n",
      "2023-12-06 14:37:02,730 : INFO : EPOCH 28: training on 99524 raw words (60408 effective words) took 0.1s, 445426 effective words/s\n",
      "2023-12-06 14:37:02,878 : INFO : EPOCH 29: training on 99524 raw words (60368 effective words) took 0.1s, 420331 effective words/s\n",
      "2023-12-06 14:37:02,878 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811713 effective words) took 4.4s, 416455 effective words/s', 'datetime': '2023-12-06T14:37:02.878780', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:37:02,879 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:37:02.879780', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 33%|      | 159/486 [23:24<38:08,  7.00s/it]2023-12-06 14:37:06,057 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:37:06,057 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:37:06,077 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:37:06,077 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:37:06,083 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:37:06.083943', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:37:06,084 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:37:06.084448', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:37:06,089 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:37:06,090 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:37:06,091 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:37:06.091170', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:37:06,101 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:37:06,101 : INFO : resetting layer weights\n",
      "2023-12-06 14:37:06,102 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:37:06.102605', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:37:06,255 : INFO : EPOCH 0: training on 99524 raw words (60327 effective words) took 0.1s, 405345 effective words/s\n",
      "2023-12-06 14:37:06,401 : INFO : EPOCH 1: training on 99524 raw words (60569 effective words) took 0.1s, 432255 effective words/s\n",
      "2023-12-06 14:37:06,553 : INFO : EPOCH 2: training on 99524 raw words (60368 effective words) took 0.1s, 408754 effective words/s\n",
      "2023-12-06 14:37:06,696 : INFO : EPOCH 3: training on 99524 raw words (60360 effective words) took 0.1s, 435241 effective words/s\n",
      "2023-12-06 14:37:06,843 : INFO : EPOCH 4: training on 99524 raw words (60293 effective words) took 0.1s, 424509 effective words/s\n",
      "2023-12-06 14:37:06,985 : INFO : EPOCH 5: training on 99524 raw words (60390 effective words) took 0.1s, 438060 effective words/s\n",
      "2023-12-06 14:37:07,131 : INFO : EPOCH 6: training on 99524 raw words (60342 effective words) took 0.1s, 427059 effective words/s\n",
      "2023-12-06 14:37:07,271 : INFO : EPOCH 7: training on 99524 raw words (60368 effective words) took 0.1s, 443477 effective words/s\n",
      "2023-12-06 14:37:07,419 : INFO : EPOCH 8: training on 99524 raw words (60387 effective words) took 0.1s, 418967 effective words/s\n",
      "2023-12-06 14:37:07,561 : INFO : EPOCH 9: training on 99524 raw words (60386 effective words) took 0.1s, 443279 effective words/s\n",
      "2023-12-06 14:37:07,702 : INFO : EPOCH 10: training on 99524 raw words (60356 effective words) took 0.1s, 438605 effective words/s\n",
      "2023-12-06 14:37:07,850 : INFO : EPOCH 11: training on 99524 raw words (60407 effective words) took 0.1s, 423194 effective words/s\n",
      "2023-12-06 14:37:07,994 : INFO : EPOCH 12: training on 99524 raw words (60417 effective words) took 0.1s, 435016 effective words/s\n",
      "2023-12-06 14:37:08,140 : INFO : EPOCH 13: training on 99524 raw words (60373 effective words) took 0.1s, 424999 effective words/s\n",
      "2023-12-06 14:37:08,281 : INFO : EPOCH 14: training on 99524 raw words (60381 effective words) took 0.1s, 443160 effective words/s\n",
      "2023-12-06 14:37:08,435 : INFO : EPOCH 15: training on 99524 raw words (60320 effective words) took 0.1s, 403638 effective words/s\n",
      "2023-12-06 14:37:08,579 : INFO : EPOCH 16: training on 99524 raw words (60316 effective words) took 0.1s, 431985 effective words/s\n",
      "2023-12-06 14:37:08,726 : INFO : EPOCH 17: training on 99524 raw words (60400 effective words) took 0.1s, 423370 effective words/s\n",
      "2023-12-06 14:37:08,869 : INFO : EPOCH 18: training on 99524 raw words (60459 effective words) took 0.1s, 436756 effective words/s\n",
      "2023-12-06 14:37:09,014 : INFO : EPOCH 19: training on 99524 raw words (60381 effective words) took 0.1s, 428184 effective words/s\n",
      "2023-12-06 14:37:09,156 : INFO : EPOCH 20: training on 99524 raw words (60402 effective words) took 0.1s, 439122 effective words/s\n",
      "2023-12-06 14:37:09,301 : INFO : EPOCH 21: training on 99524 raw words (60568 effective words) took 0.1s, 431448 effective words/s\n",
      "2023-12-06 14:37:09,442 : INFO : EPOCH 22: training on 99524 raw words (60427 effective words) took 0.1s, 441514 effective words/s\n",
      "2023-12-06 14:37:09,589 : INFO : EPOCH 23: training on 99524 raw words (60549 effective words) took 0.1s, 424672 effective words/s\n",
      "2023-12-06 14:37:09,731 : INFO : EPOCH 24: training on 99524 raw words (60437 effective words) took 0.1s, 440785 effective words/s\n",
      "2023-12-06 14:37:09,878 : INFO : EPOCH 25: training on 99524 raw words (60217 effective words) took 0.1s, 422364 effective words/s\n",
      "2023-12-06 14:37:10,019 : INFO : EPOCH 26: training on 99524 raw words (60410 effective words) took 0.1s, 441533 effective words/s\n",
      "2023-12-06 14:37:10,166 : INFO : EPOCH 27: training on 99524 raw words (60629 effective words) took 0.1s, 425023 effective words/s\n",
      "2023-12-06 14:37:10,305 : INFO : EPOCH 28: training on 99524 raw words (60330 effective words) took 0.1s, 446244 effective words/s\n",
      "2023-12-06 14:37:10,458 : INFO : EPOCH 29: training on 99524 raw words (60368 effective words) took 0.1s, 406413 effective words/s\n",
      "2023-12-06 14:37:10,599 : INFO : EPOCH 30: training on 99524 raw words (60352 effective words) took 0.1s, 440525 effective words/s\n",
      "2023-12-06 14:37:10,746 : INFO : EPOCH 31: training on 99524 raw words (60285 effective words) took 0.1s, 425319 effective words/s\n",
      "2023-12-06 14:37:10,895 : INFO : EPOCH 32: training on 99524 raw words (60394 effective words) took 0.1s, 422195 effective words/s\n",
      "2023-12-06 14:37:11,036 : INFO : EPOCH 33: training on 99524 raw words (60326 effective words) took 0.1s, 441071 effective words/s\n",
      "2023-12-06 14:37:11,183 : INFO : EPOCH 34: training on 99524 raw words (60576 effective words) took 0.1s, 423313 effective words/s\n",
      "2023-12-06 14:37:11,325 : INFO : EPOCH 35: training on 99524 raw words (60485 effective words) took 0.1s, 437577 effective words/s\n",
      "2023-12-06 14:37:11,474 : INFO : EPOCH 36: training on 99524 raw words (60385 effective words) took 0.1s, 420958 effective words/s\n",
      "2023-12-06 14:37:11,612 : INFO : EPOCH 37: training on 99524 raw words (60279 effective words) took 0.1s, 447308 effective words/s\n",
      "2023-12-06 14:37:11,757 : INFO : EPOCH 38: training on 99524 raw words (60382 effective words) took 0.1s, 431576 effective words/s\n",
      "2023-12-06 14:37:11,900 : INFO : EPOCH 39: training on 99524 raw words (60341 effective words) took 0.1s, 434199 effective words/s\n",
      "2023-12-06 14:37:12,046 : INFO : EPOCH 40: training on 99524 raw words (60330 effective words) took 0.1s, 425848 effective words/s\n",
      "2023-12-06 14:37:12,190 : INFO : EPOCH 41: training on 99524 raw words (60466 effective words) took 0.1s, 435720 effective words/s\n",
      "2023-12-06 14:37:12,334 : INFO : EPOCH 42: training on 99524 raw words (60376 effective words) took 0.1s, 433126 effective words/s\n",
      "2023-12-06 14:37:12,485 : INFO : EPOCH 43: training on 99524 raw words (60442 effective words) took 0.1s, 412336 effective words/s\n",
      "2023-12-06 14:37:12,634 : INFO : EPOCH 44: training on 99524 raw words (60331 effective words) took 0.1s, 415541 effective words/s\n",
      "2023-12-06 14:37:12,781 : INFO : EPOCH 45: training on 99524 raw words (60318 effective words) took 0.1s, 421295 effective words/s\n",
      "2023-12-06 14:37:12,923 : INFO : EPOCH 46: training on 99524 raw words (60481 effective words) took 0.1s, 442003 effective words/s\n",
      "2023-12-06 14:37:13,068 : INFO : EPOCH 47: training on 99524 raw words (60295 effective words) took 0.1s, 427877 effective words/s\n",
      "2023-12-06 14:37:13,214 : INFO : EPOCH 48: training on 99524 raw words (60362 effective words) took 0.1s, 425872 effective words/s\n",
      "2023-12-06 14:37:13,357 : INFO : EPOCH 49: training on 99524 raw words (60362 effective words) took 0.1s, 439717 effective words/s\n",
      "2023-12-06 14:37:13,358 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3019505 effective words) took 7.3s, 416185 effective words/s', 'datetime': '2023-12-06T14:37:13.358686', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:37:13,358 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:37:13.358686', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 33%|      | 160/486 [23:35<43:34,  8.02s/it]2023-12-06 14:37:16,459 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:37:16,460 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:37:16,480 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:37:16,480 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:37:16,486 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:37:16.486284', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:37:16,487 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:37:16.487284', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:37:16,493 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:37:16,495 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:37:16,495 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:37:16.495289', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:37:16,502 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:37:16,503 : INFO : resetting layer weights\n",
      "2023-12-06 14:37:16,504 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:37:16.504284', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:37:16,681 : INFO : EPOCH 0: training on 99524 raw words (60238 effective words) took 0.2s, 347994 effective words/s\n",
      "2023-12-06 14:37:16,829 : INFO : EPOCH 1: training on 99524 raw words (60537 effective words) took 0.1s, 425001 effective words/s\n",
      "2023-12-06 14:37:16,977 : INFO : EPOCH 2: training on 99524 raw words (60392 effective words) took 0.1s, 416936 effective words/s\n",
      "2023-12-06 14:37:17,124 : INFO : EPOCH 3: training on 99524 raw words (60362 effective words) took 0.1s, 425906 effective words/s\n",
      "2023-12-06 14:37:17,274 : INFO : EPOCH 4: training on 99524 raw words (60335 effective words) took 0.1s, 415581 effective words/s\n",
      "2023-12-06 14:37:17,416 : INFO : EPOCH 5: training on 99524 raw words (60431 effective words) took 0.1s, 440048 effective words/s\n",
      "2023-12-06 14:37:17,565 : INFO : EPOCH 6: training on 99524 raw words (60299 effective words) took 0.1s, 416188 effective words/s\n",
      "2023-12-06 14:37:17,709 : INFO : EPOCH 7: training on 99524 raw words (60506 effective words) took 0.1s, 433064 effective words/s\n",
      "2023-12-06 14:37:17,857 : INFO : EPOCH 8: training on 99524 raw words (60421 effective words) took 0.1s, 421461 effective words/s\n",
      "2023-12-06 14:37:18,001 : INFO : EPOCH 9: training on 99524 raw words (60363 effective words) took 0.1s, 431661 effective words/s\n",
      "2023-12-06 14:37:18,145 : INFO : EPOCH 10: training on 99524 raw words (60219 effective words) took 0.1s, 431067 effective words/s\n",
      "2023-12-06 14:37:18,294 : INFO : EPOCH 11: training on 99524 raw words (60459 effective words) took 0.1s, 420282 effective words/s\n",
      "2023-12-06 14:37:18,439 : INFO : EPOCH 12: training on 99524 raw words (60275 effective words) took 0.1s, 431553 effective words/s\n",
      "2023-12-06 14:37:18,587 : INFO : EPOCH 13: training on 99524 raw words (60249 effective words) took 0.1s, 417987 effective words/s\n",
      "2023-12-06 14:37:18,730 : INFO : EPOCH 14: training on 99524 raw words (60482 effective words) took 0.1s, 437480 effective words/s\n",
      "2023-12-06 14:37:18,880 : INFO : EPOCH 15: training on 99524 raw words (60406 effective words) took 0.1s, 412123 effective words/s\n",
      "2023-12-06 14:37:19,031 : INFO : EPOCH 16: training on 99524 raw words (60394 effective words) took 0.1s, 416066 effective words/s\n",
      "2023-12-06 14:37:19,174 : INFO : EPOCH 17: training on 99524 raw words (60283 effective words) took 0.1s, 433601 effective words/s\n",
      "2023-12-06 14:37:19,322 : INFO : EPOCH 18: training on 99524 raw words (60425 effective words) took 0.1s, 421429 effective words/s\n",
      "2023-12-06 14:37:19,469 : INFO : EPOCH 19: training on 99524 raw words (60413 effective words) took 0.1s, 422053 effective words/s\n",
      "2023-12-06 14:37:19,618 : INFO : EPOCH 20: training on 99524 raw words (60558 effective words) took 0.1s, 420938 effective words/s\n",
      "2023-12-06 14:37:19,762 : INFO : EPOCH 21: training on 99524 raw words (60435 effective words) took 0.1s, 431672 effective words/s\n",
      "2023-12-06 14:37:19,914 : INFO : EPOCH 22: training on 99524 raw words (60479 effective words) took 0.1s, 412478 effective words/s\n",
      "2023-12-06 14:37:20,069 : INFO : EPOCH 23: training on 99524 raw words (60456 effective words) took 0.2s, 399768 effective words/s\n",
      "2023-12-06 14:37:20,213 : INFO : EPOCH 24: training on 99524 raw words (60444 effective words) took 0.1s, 432626 effective words/s\n",
      "2023-12-06 14:37:20,372 : INFO : EPOCH 25: training on 99524 raw words (60300 effective words) took 0.2s, 390168 effective words/s\n",
      "2023-12-06 14:37:20,515 : INFO : EPOCH 26: training on 99524 raw words (60517 effective words) took 0.1s, 435413 effective words/s\n",
      "2023-12-06 14:37:20,665 : INFO : EPOCH 27: training on 99524 raw words (60585 effective words) took 0.1s, 416015 effective words/s\n",
      "2023-12-06 14:37:20,810 : INFO : EPOCH 28: training on 99524 raw words (60430 effective words) took 0.1s, 429707 effective words/s\n",
      "2023-12-06 14:37:20,961 : INFO : EPOCH 29: training on 99524 raw words (60490 effective words) took 0.1s, 415235 effective words/s\n",
      "2023-12-06 14:37:21,107 : INFO : EPOCH 30: training on 99524 raw words (60374 effective words) took 0.1s, 426301 effective words/s\n",
      "2023-12-06 14:37:21,251 : INFO : EPOCH 31: training on 99524 raw words (60271 effective words) took 0.1s, 430575 effective words/s\n",
      "2023-12-06 14:37:21,404 : INFO : EPOCH 32: training on 99524 raw words (60314 effective words) took 0.1s, 405865 effective words/s\n",
      "2023-12-06 14:37:21,549 : INFO : EPOCH 33: training on 99524 raw words (60530 effective words) took 0.1s, 434080 effective words/s\n",
      "2023-12-06 14:37:21,694 : INFO : EPOCH 34: training on 99524 raw words (60374 effective words) took 0.1s, 432366 effective words/s\n",
      "2023-12-06 14:37:21,856 : INFO : EPOCH 35: training on 99524 raw words (60589 effective words) took 0.2s, 382284 effective words/s\n",
      "2023-12-06 14:37:22,004 : INFO : EPOCH 36: training on 99524 raw words (60369 effective words) took 0.1s, 423398 effective words/s\n",
      "2023-12-06 14:37:22,153 : INFO : EPOCH 37: training on 99524 raw words (60447 effective words) took 0.1s, 415929 effective words/s\n",
      "2023-12-06 14:37:22,298 : INFO : EPOCH 38: training on 99524 raw words (60325 effective words) took 0.1s, 430849 effective words/s\n",
      "2023-12-06 14:37:22,451 : INFO : EPOCH 39: training on 99524 raw words (60433 effective words) took 0.1s, 405704 effective words/s\n",
      "2023-12-06 14:37:22,611 : INFO : EPOCH 40: training on 99524 raw words (60357 effective words) took 0.2s, 390647 effective words/s\n",
      "2023-12-06 14:37:22,760 : INFO : EPOCH 41: training on 99524 raw words (60498 effective words) took 0.1s, 416711 effective words/s\n",
      "2023-12-06 14:37:22,906 : INFO : EPOCH 42: training on 99524 raw words (60369 effective words) took 0.1s, 427302 effective words/s\n",
      "2023-12-06 14:37:23,054 : INFO : EPOCH 43: training on 99524 raw words (60425 effective words) took 0.1s, 418543 effective words/s\n",
      "2023-12-06 14:37:23,199 : INFO : EPOCH 44: training on 99524 raw words (60293 effective words) took 0.1s, 433611 effective words/s\n",
      "2023-12-06 14:37:23,351 : INFO : EPOCH 45: training on 99524 raw words (60364 effective words) took 0.1s, 407201 effective words/s\n",
      "2023-12-06 14:37:23,502 : INFO : EPOCH 46: training on 99524 raw words (60316 effective words) took 0.1s, 415608 effective words/s\n",
      "2023-12-06 14:37:23,651 : INFO : EPOCH 47: training on 99524 raw words (60332 effective words) took 0.1s, 417103 effective words/s\n",
      "2023-12-06 14:37:23,794 : INFO : EPOCH 48: training on 99524 raw words (60462 effective words) took 0.1s, 432666 effective words/s\n",
      "2023-12-06 14:37:23,942 : INFO : EPOCH 49: training on 99524 raw words (60450 effective words) took 0.1s, 422180 effective words/s\n",
      "2023-12-06 14:37:23,943 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3020075 effective words) took 7.4s, 406015 effective words/s', 'datetime': '2023-12-06T14:37:23.943689', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:37:23,943 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:37:23.943689', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 33%|      | 161/486 [23:45<48:05,  8.88s/it]2023-12-06 14:37:27,342 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:37:27,342 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:37:27,362 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:37:27,362 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:37:27,369 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:37:27.369786', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:37:27,370 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:37:27.370786', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:37:27,377 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:37:27,378 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:37:27,378 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:37:27.378001', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:37:27,385 : INFO : estimated required memory for 1231 words and 50 dimensions: 2833100 bytes\n",
      "2023-12-06 14:37:27,385 : INFO : resetting layer weights\n",
      "2023-12-06 14:37:27,387 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 50 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:37:27.387203', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:37:27,567 : INFO : EPOCH 0: training on 99524 raw words (60453 effective words) took 0.2s, 340862 effective words/s\n",
      "2023-12-06 14:37:27,722 : INFO : EPOCH 1: training on 99524 raw words (60339 effective words) took 0.1s, 405590 effective words/s\n",
      "2023-12-06 14:37:27,877 : INFO : EPOCH 2: training on 99524 raw words (60430 effective words) took 0.2s, 401526 effective words/s\n",
      "2023-12-06 14:37:28,023 : INFO : EPOCH 3: training on 99524 raw words (60402 effective words) took 0.1s, 426633 effective words/s\n",
      "2023-12-06 14:37:28,172 : INFO : EPOCH 4: training on 99524 raw words (60242 effective words) took 0.1s, 415009 effective words/s\n",
      "2023-12-06 14:37:28,313 : INFO : EPOCH 5: training on 99524 raw words (60530 effective words) took 0.1s, 444925 effective words/s\n",
      "2023-12-06 14:37:28,454 : INFO : EPOCH 6: training on 99524 raw words (60535 effective words) took 0.1s, 446175 effective words/s\n",
      "2023-12-06 14:37:28,601 : INFO : EPOCH 7: training on 99524 raw words (60472 effective words) took 0.1s, 422736 effective words/s\n",
      "2023-12-06 14:37:28,742 : INFO : EPOCH 8: training on 99524 raw words (60698 effective words) took 0.1s, 446035 effective words/s\n",
      "2023-12-06 14:37:28,887 : INFO : EPOCH 9: training on 99524 raw words (60440 effective words) took 0.1s, 425417 effective words/s\n",
      "2023-12-06 14:37:29,028 : INFO : EPOCH 10: training on 99524 raw words (60426 effective words) took 0.1s, 443159 effective words/s\n",
      "2023-12-06 14:37:29,177 : INFO : EPOCH 11: training on 99524 raw words (60460 effective words) took 0.1s, 420165 effective words/s\n",
      "2023-12-06 14:37:29,323 : INFO : EPOCH 12: training on 99524 raw words (60573 effective words) took 0.1s, 427436 effective words/s\n",
      "2023-12-06 14:37:29,465 : INFO : EPOCH 13: training on 99524 raw words (60518 effective words) took 0.1s, 439499 effective words/s\n",
      "2023-12-06 14:37:29,609 : INFO : EPOCH 14: training on 99524 raw words (60478 effective words) took 0.1s, 433331 effective words/s\n",
      "2023-12-06 14:37:29,748 : INFO : EPOCH 15: training on 99524 raw words (60340 effective words) took 0.1s, 448941 effective words/s\n",
      "2023-12-06 14:37:29,894 : INFO : EPOCH 16: training on 99524 raw words (60362 effective words) took 0.1s, 426159 effective words/s\n",
      "2023-12-06 14:37:30,034 : INFO : EPOCH 17: training on 99524 raw words (60308 effective words) took 0.1s, 446708 effective words/s\n",
      "2023-12-06 14:37:30,181 : INFO : EPOCH 18: training on 99524 raw words (60300 effective words) took 0.1s, 422418 effective words/s\n",
      "2023-12-06 14:37:30,324 : INFO : EPOCH 19: training on 99524 raw words (60520 effective words) took 0.1s, 437727 effective words/s\n",
      "2023-12-06 14:37:30,470 : INFO : EPOCH 20: training on 99524 raw words (60364 effective words) took 0.1s, 425454 effective words/s\n",
      "2023-12-06 14:37:30,610 : INFO : EPOCH 21: training on 99524 raw words (60517 effective words) took 0.1s, 445684 effective words/s\n",
      "2023-12-06 14:37:30,752 : INFO : EPOCH 22: training on 99524 raw words (60495 effective words) took 0.1s, 442336 effective words/s\n",
      "2023-12-06 14:37:30,896 : INFO : EPOCH 23: training on 99524 raw words (60632 effective words) took 0.1s, 433271 effective words/s\n",
      "2023-12-06 14:37:31,037 : INFO : EPOCH 24: training on 99524 raw words (60382 effective words) took 0.1s, 444858 effective words/s\n",
      "2023-12-06 14:37:31,179 : INFO : EPOCH 25: training on 99524 raw words (60251 effective words) took 0.1s, 437886 effective words/s\n",
      "2023-12-06 14:37:31,331 : INFO : EPOCH 26: training on 99524 raw words (60457 effective words) took 0.1s, 409263 effective words/s\n",
      "2023-12-06 14:37:31,471 : INFO : EPOCH 27: training on 99524 raw words (60532 effective words) took 0.1s, 445525 effective words/s\n",
      "2023-12-06 14:37:31,619 : INFO : EPOCH 28: training on 99524 raw words (60415 effective words) took 0.1s, 423186 effective words/s\n",
      "2023-12-06 14:37:31,760 : INFO : EPOCH 29: training on 99524 raw words (60583 effective words) took 0.1s, 441385 effective words/s\n",
      "2023-12-06 14:37:31,907 : INFO : EPOCH 30: training on 99524 raw words (60373 effective words) took 0.1s, 425454 effective words/s\n",
      "2023-12-06 14:37:32,047 : INFO : EPOCH 31: training on 99524 raw words (60356 effective words) took 0.1s, 442749 effective words/s\n",
      "2023-12-06 14:37:32,193 : INFO : EPOCH 32: training on 99524 raw words (60432 effective words) took 0.1s, 425514 effective words/s\n",
      "2023-12-06 14:37:32,337 : INFO : EPOCH 33: training on 99524 raw words (60366 effective words) took 0.1s, 435603 effective words/s\n",
      "2023-12-06 14:37:32,483 : INFO : EPOCH 34: training on 99524 raw words (60502 effective words) took 0.1s, 428055 effective words/s\n",
      "2023-12-06 14:37:32,633 : INFO : EPOCH 35: training on 99524 raw words (60513 effective words) took 0.1s, 417899 effective words/s\n",
      "2023-12-06 14:37:32,774 : INFO : EPOCH 36: training on 99524 raw words (60413 effective words) took 0.1s, 442716 effective words/s\n",
      "2023-12-06 14:37:32,924 : INFO : EPOCH 37: training on 99524 raw words (60267 effective words) took 0.1s, 412833 effective words/s\n",
      "2023-12-06 14:37:33,073 : INFO : EPOCH 38: training on 99524 raw words (60371 effective words) took 0.1s, 417940 effective words/s\n",
      "2023-12-06 14:37:33,215 : INFO : EPOCH 39: training on 99524 raw words (60403 effective words) took 0.1s, 441924 effective words/s\n",
      "2023-12-06 14:37:33,356 : INFO : EPOCH 40: training on 99524 raw words (60396 effective words) took 0.1s, 443642 effective words/s\n",
      "2023-12-06 14:37:33,503 : INFO : EPOCH 41: training on 99524 raw words (60537 effective words) took 0.1s, 424942 effective words/s\n",
      "2023-12-06 14:37:33,642 : INFO : EPOCH 42: training on 99524 raw words (60404 effective words) took 0.1s, 444998 effective words/s\n",
      "2023-12-06 14:37:33,788 : INFO : EPOCH 43: training on 99524 raw words (60408 effective words) took 0.1s, 426763 effective words/s\n",
      "2023-12-06 14:37:33,929 : INFO : EPOCH 44: training on 99524 raw words (60272 effective words) took 0.1s, 442108 effective words/s\n",
      "2023-12-06 14:37:34,075 : INFO : EPOCH 45: training on 99524 raw words (60404 effective words) took 0.1s, 427003 effective words/s\n",
      "2023-12-06 14:37:34,216 : INFO : EPOCH 46: training on 99524 raw words (60421 effective words) took 0.1s, 441832 effective words/s\n",
      "2023-12-06 14:37:34,356 : INFO : EPOCH 47: training on 99524 raw words (60286 effective words) took 0.1s, 443228 effective words/s\n",
      "2023-12-06 14:37:34,507 : INFO : EPOCH 48: training on 99524 raw words (60475 effective words) took 0.1s, 417120 effective words/s\n",
      "2023-12-06 14:37:34,647 : INFO : EPOCH 49: training on 99524 raw words (60406 effective words) took 0.1s, 442602 effective words/s\n",
      "2023-12-06 14:37:34,648 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3021459 effective words) took 7.3s, 416091 effective words/s', 'datetime': '2023-12-06T14:37:34.648534', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:37:34,650 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d50,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:37:34.650108', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 33%|      | 162/486 [23:56<51:09,  9.47s/it]2023-12-06 14:37:38,204 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:37:38,205 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:37:38,226 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:37:38,226 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:37:38,234 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:37:38.234159', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:37:38,235 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:37:38.235159', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:37:38,244 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:37:38,245 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:37:38,245 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:37:38.245674', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:37:38,261 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:37:38,262 : INFO : resetting layer weights\n",
      "2023-12-06 14:37:38,267 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:37:38.267562', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:37:38,520 : INFO : EPOCH 0: training on 99524 raw words (65463 effective words) took 0.2s, 263561 effective words/s\n",
      "2023-12-06 14:37:38,751 : INFO : EPOCH 1: training on 99524 raw words (65592 effective words) took 0.2s, 289461 effective words/s\n",
      "2023-12-06 14:37:38,990 : INFO : EPOCH 2: training on 99524 raw words (65529 effective words) took 0.2s, 280122 effective words/s\n",
      "2023-12-06 14:37:39,229 : INFO : EPOCH 3: training on 99524 raw words (65564 effective words) took 0.2s, 278840 effective words/s\n",
      "2023-12-06 14:37:39,466 : INFO : EPOCH 4: training on 99524 raw words (65518 effective words) took 0.2s, 282143 effective words/s\n",
      "2023-12-06 14:37:39,697 : INFO : EPOCH 5: training on 99524 raw words (65516 effective words) took 0.2s, 288407 effective words/s\n",
      "2023-12-06 14:37:39,935 : INFO : EPOCH 6: training on 99524 raw words (65510 effective words) took 0.2s, 280322 effective words/s\n",
      "2023-12-06 14:37:40,169 : INFO : EPOCH 7: training on 99524 raw words (65601 effective words) took 0.2s, 286161 effective words/s\n",
      "2023-12-06 14:37:40,406 : INFO : EPOCH 8: training on 99524 raw words (65462 effective words) took 0.2s, 280648 effective words/s\n",
      "2023-12-06 14:37:40,637 : INFO : EPOCH 9: training on 99524 raw words (65469 effective words) took 0.2s, 289453 effective words/s\n",
      "2023-12-06 14:37:40,638 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655224 effective words) took 2.4s, 276446 effective words/s', 'datetime': '2023-12-06T14:37:40.638219', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:37:40,639 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:37:40.639218', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 34%|      | 163/486 [24:01<44:00,  8.18s/it]2023-12-06 14:37:43,354 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:37:43,354 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:37:43,374 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:37:43,375 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:37:43,382 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:37:43.382633', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:37:43,383 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:37:43.383634', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:37:43,393 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:37:43,394 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:37:43,394 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:37:43.394202', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:37:43,405 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:37:43,406 : INFO : resetting layer weights\n",
      "2023-12-06 14:37:43,410 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:37:43.410290', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:37:43,689 : INFO : EPOCH 0: training on 99524 raw words (65554 effective words) took 0.3s, 238280 effective words/s\n",
      "2023-12-06 14:37:43,938 : INFO : EPOCH 1: training on 99524 raw words (65428 effective words) took 0.2s, 266702 effective words/s\n",
      "2023-12-06 14:37:44,183 : INFO : EPOCH 2: training on 99524 raw words (65492 effective words) took 0.2s, 272042 effective words/s\n",
      "2023-12-06 14:37:44,435 : INFO : EPOCH 3: training on 99524 raw words (65543 effective words) took 0.2s, 266020 effective words/s\n",
      "2023-12-06 14:37:44,681 : INFO : EPOCH 4: training on 99524 raw words (65600 effective words) took 0.2s, 272530 effective words/s\n",
      "2023-12-06 14:37:44,928 : INFO : EPOCH 5: training on 99524 raw words (65522 effective words) took 0.2s, 269413 effective words/s\n",
      "2023-12-06 14:37:45,169 : INFO : EPOCH 6: training on 99524 raw words (65539 effective words) took 0.2s, 276663 effective words/s\n",
      "2023-12-06 14:37:45,415 : INFO : EPOCH 7: training on 99524 raw words (65556 effective words) took 0.2s, 271330 effective words/s\n",
      "2023-12-06 14:37:45,660 : INFO : EPOCH 8: training on 99524 raw words (65304 effective words) took 0.2s, 271324 effective words/s\n",
      "2023-12-06 14:37:45,904 : INFO : EPOCH 9: training on 99524 raw words (65356 effective words) took 0.2s, 271712 effective words/s\n",
      "2023-12-06 14:37:45,905 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (654894 effective words) took 2.5s, 262538 effective words/s', 'datetime': '2023-12-06T14:37:45.905798', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:37:45,905 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:37:45.905798', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 34%|      | 164/486 [24:07<39:19,  7.33s/it]2023-12-06 14:37:48,697 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:37:48,698 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:37:48,719 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:37:48,719 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:37:48,725 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:37:48.725727', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:37:48,726 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:37:48.726231', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:37:48,734 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:37:48,734 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:37:48,735 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:37:48.735240', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:37:48,750 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:37:48,751 : INFO : resetting layer weights\n",
      "2023-12-06 14:37:48,753 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:37:48.753961', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:37:49,022 : INFO : EPOCH 0: training on 99524 raw words (65438 effective words) took 0.3s, 248078 effective words/s\n",
      "2023-12-06 14:37:49,284 : INFO : EPOCH 1: training on 99524 raw words (65514 effective words) took 0.3s, 254848 effective words/s\n",
      "2023-12-06 14:37:49,544 : INFO : EPOCH 2: training on 99524 raw words (65472 effective words) took 0.3s, 256495 effective words/s\n",
      "2023-12-06 14:37:49,806 : INFO : EPOCH 3: training on 99524 raw words (65649 effective words) took 0.3s, 253992 effective words/s\n",
      "2023-12-06 14:37:50,070 : INFO : EPOCH 4: training on 99524 raw words (65648 effective words) took 0.3s, 253787 effective words/s\n",
      "2023-12-06 14:37:50,328 : INFO : EPOCH 5: training on 99524 raw words (65781 effective words) took 0.3s, 259942 effective words/s\n",
      "2023-12-06 14:37:50,591 : INFO : EPOCH 6: training on 99524 raw words (65623 effective words) took 0.3s, 253607 effective words/s\n",
      "2023-12-06 14:37:50,850 : INFO : EPOCH 7: training on 99524 raw words (65612 effective words) took 0.3s, 257201 effective words/s\n",
      "2023-12-06 14:37:51,109 : INFO : EPOCH 8: training on 99524 raw words (65555 effective words) took 0.3s, 257215 effective words/s\n",
      "2023-12-06 14:37:51,368 : INFO : EPOCH 9: training on 99524 raw words (65492 effective words) took 0.3s, 257606 effective words/s\n",
      "2023-12-06 14:37:51,369 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655784 effective words) took 2.6s, 250810 effective words/s', 'datetime': '2023-12-06T14:37:51.369456', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:37:51,369 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:37:51.369456', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 34%|      | 165/486 [24:12<36:28,  6.82s/it]2023-12-06 14:37:54,331 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:37:54,332 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:37:54,352 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:37:54,353 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:37:54,358 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:37:54.358943', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:37:54,359 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:37:54.359944', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:37:54,366 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:37:54,366 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:37:54,366 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:37:54.366978', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:37:54,377 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:37:54,379 : INFO : resetting layer weights\n",
      "2023-12-06 14:37:54,381 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:37:54.381933', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:37:54,668 : INFO : EPOCH 0: training on 99524 raw words (65372 effective words) took 0.3s, 232655 effective words/s\n",
      "2023-12-06 14:37:54,907 : INFO : EPOCH 1: training on 99524 raw words (65423 effective words) took 0.2s, 279028 effective words/s\n",
      "2023-12-06 14:37:55,152 : INFO : EPOCH 2: training on 99524 raw words (65696 effective words) took 0.2s, 272814 effective words/s\n",
      "2023-12-06 14:37:55,387 : INFO : EPOCH 3: training on 99524 raw words (65534 effective words) took 0.2s, 283280 effective words/s\n",
      "2023-12-06 14:37:55,629 : INFO : EPOCH 4: training on 99524 raw words (65523 effective words) took 0.2s, 275832 effective words/s\n",
      "2023-12-06 14:37:55,870 : INFO : EPOCH 5: training on 99524 raw words (65352 effective words) took 0.2s, 275586 effective words/s\n",
      "2023-12-06 14:37:56,105 : INFO : EPOCH 6: training on 99524 raw words (65530 effective words) took 0.2s, 285238 effective words/s\n",
      "2023-12-06 14:37:56,344 : INFO : EPOCH 7: training on 99524 raw words (65443 effective words) took 0.2s, 278809 effective words/s\n",
      "2023-12-06 14:37:56,586 : INFO : EPOCH 8: training on 99524 raw words (65491 effective words) took 0.2s, 275620 effective words/s\n",
      "2023-12-06 14:37:56,824 : INFO : EPOCH 9: training on 99524 raw words (65564 effective words) took 0.2s, 280061 effective words/s\n",
      "2023-12-06 14:37:57,063 : INFO : EPOCH 10: training on 99524 raw words (65698 effective words) took 0.2s, 279986 effective words/s\n",
      "2023-12-06 14:37:57,303 : INFO : EPOCH 11: training on 99524 raw words (65540 effective words) took 0.2s, 278158 effective words/s\n",
      "2023-12-06 14:37:57,541 : INFO : EPOCH 12: training on 99524 raw words (65410 effective words) took 0.2s, 280422 effective words/s\n",
      "2023-12-06 14:37:57,777 : INFO : EPOCH 13: training on 99524 raw words (65472 effective words) took 0.2s, 282828 effective words/s\n",
      "2023-12-06 14:37:58,030 : INFO : EPOCH 14: training on 99524 raw words (65455 effective words) took 0.2s, 264262 effective words/s\n",
      "2023-12-06 14:37:58,277 : INFO : EPOCH 15: training on 99524 raw words (65447 effective words) took 0.2s, 269632 effective words/s\n",
      "2023-12-06 14:37:58,516 : INFO : EPOCH 16: training on 99524 raw words (65602 effective words) took 0.2s, 279072 effective words/s\n",
      "2023-12-06 14:37:58,755 : INFO : EPOCH 17: training on 99524 raw words (65482 effective words) took 0.2s, 280981 effective words/s\n",
      "2023-12-06 14:37:58,990 : INFO : EPOCH 18: training on 99524 raw words (65496 effective words) took 0.2s, 284003 effective words/s\n",
      "2023-12-06 14:37:59,226 : INFO : EPOCH 19: training on 99524 raw words (65466 effective words) took 0.2s, 283429 effective words/s\n",
      "2023-12-06 14:37:59,460 : INFO : EPOCH 20: training on 99524 raw words (65413 effective words) took 0.2s, 283429 effective words/s\n",
      "2023-12-06 14:37:59,702 : INFO : EPOCH 21: training on 99524 raw words (65429 effective words) took 0.2s, 277030 effective words/s\n",
      "2023-12-06 14:37:59,941 : INFO : EPOCH 22: training on 99524 raw words (65589 effective words) took 0.2s, 279964 effective words/s\n",
      "2023-12-06 14:38:00,185 : INFO : EPOCH 23: training on 99524 raw words (65540 effective words) took 0.2s, 273377 effective words/s\n",
      "2023-12-06 14:38:00,453 : INFO : EPOCH 24: training on 99524 raw words (65668 effective words) took 0.3s, 249024 effective words/s\n",
      "2023-12-06 14:38:00,696 : INFO : EPOCH 25: training on 99524 raw words (65534 effective words) took 0.2s, 275400 effective words/s\n",
      "2023-12-06 14:38:00,961 : INFO : EPOCH 26: training on 99524 raw words (65498 effective words) took 0.3s, 251194 effective words/s\n",
      "2023-12-06 14:38:01,208 : INFO : EPOCH 27: training on 99524 raw words (65660 effective words) took 0.2s, 273919 effective words/s\n",
      "2023-12-06 14:38:01,464 : INFO : EPOCH 28: training on 99524 raw words (65511 effective words) took 0.3s, 259460 effective words/s\n",
      "2023-12-06 14:38:01,704 : INFO : EPOCH 29: training on 99524 raw words (65567 effective words) took 0.2s, 278041 effective words/s\n",
      "2023-12-06 14:38:01,705 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965405 effective words) took 7.3s, 268385 effective words/s', 'datetime': '2023-12-06T14:38:01.705914', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:38:01,706 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:38:01.706920', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 34%|      | 166/486 [24:23<42:36,  7.99s/it]2023-12-06 14:38:05,046 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:38:05,047 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:38:05,069 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:38:05,070 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:38:05,078 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:38:05.078003', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:38:05,079 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:38:05.079008', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:38:05,086 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:38:05,087 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:38:05,087 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:38:05.087299', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:38:05,097 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:38:05,098 : INFO : resetting layer weights\n",
      "2023-12-06 14:38:05,102 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:38:05.102340', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:38:05,409 : INFO : EPOCH 0: training on 99524 raw words (65551 effective words) took 0.3s, 216436 effective words/s\n",
      "2023-12-06 14:38:05,667 : INFO : EPOCH 1: training on 99524 raw words (65478 effective words) took 0.3s, 258891 effective words/s\n",
      "2023-12-06 14:38:05,916 : INFO : EPOCH 2: training on 99524 raw words (65410 effective words) took 0.2s, 267423 effective words/s\n",
      "2023-12-06 14:38:06,163 : INFO : EPOCH 3: training on 99524 raw words (65605 effective words) took 0.2s, 270708 effective words/s\n",
      "2023-12-06 14:38:06,414 : INFO : EPOCH 4: training on 99524 raw words (65463 effective words) took 0.2s, 265375 effective words/s\n",
      "2023-12-06 14:38:06,660 : INFO : EPOCH 5: training on 99524 raw words (65542 effective words) took 0.2s, 271507 effective words/s\n",
      "2023-12-06 14:38:06,911 : INFO : EPOCH 6: training on 99524 raw words (65523 effective words) took 0.2s, 265894 effective words/s\n",
      "2023-12-06 14:38:07,155 : INFO : EPOCH 7: training on 99524 raw words (65311 effective words) took 0.2s, 272029 effective words/s\n",
      "2023-12-06 14:38:07,407 : INFO : EPOCH 8: training on 99524 raw words (65584 effective words) took 0.2s, 265087 effective words/s\n",
      "2023-12-06 14:38:07,650 : INFO : EPOCH 9: training on 99524 raw words (65566 effective words) took 0.2s, 275045 effective words/s\n",
      "2023-12-06 14:38:07,898 : INFO : EPOCH 10: training on 99524 raw words (65454 effective words) took 0.2s, 268171 effective words/s\n",
      "2023-12-06 14:38:08,140 : INFO : EPOCH 11: training on 99524 raw words (65410 effective words) took 0.2s, 276004 effective words/s\n",
      "2023-12-06 14:38:08,385 : INFO : EPOCH 12: training on 99524 raw words (65522 effective words) took 0.2s, 271285 effective words/s\n",
      "2023-12-06 14:38:08,622 : INFO : EPOCH 13: training on 99524 raw words (65394 effective words) took 0.2s, 281024 effective words/s\n",
      "2023-12-06 14:38:08,876 : INFO : EPOCH 14: training on 99524 raw words (65341 effective words) took 0.2s, 261811 effective words/s\n",
      "2023-12-06 14:38:09,119 : INFO : EPOCH 15: training on 99524 raw words (65433 effective words) took 0.2s, 275675 effective words/s\n",
      "2023-12-06 14:38:09,369 : INFO : EPOCH 16: training on 99524 raw words (65560 effective words) took 0.2s, 266202 effective words/s\n",
      "2023-12-06 14:38:09,614 : INFO : EPOCH 17: training on 99524 raw words (65515 effective words) took 0.2s, 272437 effective words/s\n",
      "2023-12-06 14:38:09,864 : INFO : EPOCH 18: training on 99524 raw words (65610 effective words) took 0.2s, 266671 effective words/s\n",
      "2023-12-06 14:38:10,107 : INFO : EPOCH 19: training on 99524 raw words (65498 effective words) took 0.2s, 274985 effective words/s\n",
      "2023-12-06 14:38:10,356 : INFO : EPOCH 20: training on 99524 raw words (65546 effective words) took 0.2s, 267266 effective words/s\n",
      "2023-12-06 14:38:10,600 : INFO : EPOCH 21: training on 99524 raw words (65385 effective words) took 0.2s, 272882 effective words/s\n",
      "2023-12-06 14:38:10,848 : INFO : EPOCH 22: training on 99524 raw words (65595 effective words) took 0.2s, 268410 effective words/s\n",
      "2023-12-06 14:38:11,096 : INFO : EPOCH 23: training on 99524 raw words (65641 effective words) took 0.2s, 270173 effective words/s\n",
      "2023-12-06 14:38:11,347 : INFO : EPOCH 24: training on 99524 raw words (65654 effective words) took 0.2s, 265838 effective words/s\n",
      "2023-12-06 14:38:11,592 : INFO : EPOCH 25: training on 99524 raw words (65418 effective words) took 0.2s, 272460 effective words/s\n",
      "2023-12-06 14:38:11,841 : INFO : EPOCH 26: training on 99524 raw words (65519 effective words) took 0.2s, 267522 effective words/s\n",
      "2023-12-06 14:38:12,088 : INFO : EPOCH 27: training on 99524 raw words (65449 effective words) took 0.2s, 270859 effective words/s\n",
      "2023-12-06 14:38:12,349 : INFO : EPOCH 28: training on 99524 raw words (65715 effective words) took 0.3s, 256220 effective words/s\n",
      "2023-12-06 14:38:12,601 : INFO : EPOCH 29: training on 99524 raw words (65468 effective words) took 0.2s, 264398 effective words/s\n",
      "2023-12-06 14:38:12,603 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965160 effective words) took 7.5s, 262026 effective words/s', 'datetime': '2023-12-06T14:38:12.603501', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:38:12,603 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:38:12.603501', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 34%|      | 167/486 [24:34<47:12,  8.88s/it]2023-12-06 14:38:16,009 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:38:16,011 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:38:16,035 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:38:16,036 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:38:16,042 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:38:16.042268', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:38:16,042 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:38:16.042771', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:38:16,053 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:38:16,054 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:38:16,054 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:38:16.054058', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:38:16,065 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:38:16,065 : INFO : resetting layer weights\n",
      "2023-12-06 14:38:16,068 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:38:16.068399', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:38:16,334 : INFO : EPOCH 0: training on 99524 raw words (65349 effective words) took 0.3s, 249123 effective words/s\n",
      "2023-12-06 14:38:16,600 : INFO : EPOCH 1: training on 99524 raw words (65523 effective words) took 0.3s, 251069 effective words/s\n",
      "2023-12-06 14:38:16,860 : INFO : EPOCH 2: training on 99524 raw words (65576 effective words) took 0.3s, 255811 effective words/s\n",
      "2023-12-06 14:38:17,117 : INFO : EPOCH 3: training on 99524 raw words (65395 effective words) took 0.3s, 259375 effective words/s\n",
      "2023-12-06 14:38:17,380 : INFO : EPOCH 4: training on 99524 raw words (65473 effective words) took 0.3s, 253083 effective words/s\n",
      "2023-12-06 14:38:17,637 : INFO : EPOCH 5: training on 99524 raw words (65646 effective words) took 0.3s, 259381 effective words/s\n",
      "2023-12-06 14:38:17,897 : INFO : EPOCH 6: training on 99524 raw words (65424 effective words) took 0.3s, 255963 effective words/s\n",
      "2023-12-06 14:38:18,157 : INFO : EPOCH 7: training on 99524 raw words (65429 effective words) took 0.3s, 256217 effective words/s\n",
      "2023-12-06 14:38:18,423 : INFO : EPOCH 8: training on 99524 raw words (65619 effective words) took 0.3s, 250804 effective words/s\n",
      "2023-12-06 14:38:18,683 : INFO : EPOCH 9: training on 99524 raw words (65446 effective words) took 0.3s, 255909 effective words/s\n",
      "2023-12-06 14:38:18,942 : INFO : EPOCH 10: training on 99524 raw words (65550 effective words) took 0.3s, 257129 effective words/s\n",
      "2023-12-06 14:38:19,207 : INFO : EPOCH 11: training on 99524 raw words (65579 effective words) took 0.3s, 253357 effective words/s\n",
      "2023-12-06 14:38:19,462 : INFO : EPOCH 12: training on 99524 raw words (65716 effective words) took 0.3s, 262128 effective words/s\n",
      "2023-12-06 14:38:19,719 : INFO : EPOCH 13: training on 99524 raw words (65497 effective words) took 0.3s, 258039 effective words/s\n",
      "2023-12-06 14:38:19,983 : INFO : EPOCH 14: training on 99524 raw words (65631 effective words) took 0.3s, 253548 effective words/s\n",
      "2023-12-06 14:38:20,240 : INFO : EPOCH 15: training on 99524 raw words (65361 effective words) took 0.3s, 258590 effective words/s\n",
      "2023-12-06 14:38:20,501 : INFO : EPOCH 16: training on 99524 raw words (65552 effective words) took 0.3s, 255467 effective words/s\n",
      "2023-12-06 14:38:20,762 : INFO : EPOCH 17: training on 99524 raw words (65602 effective words) took 0.3s, 256782 effective words/s\n",
      "2023-12-06 14:38:21,022 : INFO : EPOCH 18: training on 99524 raw words (65564 effective words) took 0.3s, 256699 effective words/s\n",
      "2023-12-06 14:38:21,276 : INFO : EPOCH 19: training on 99524 raw words (65384 effective words) took 0.3s, 261289 effective words/s\n",
      "2023-12-06 14:38:21,533 : INFO : EPOCH 20: training on 99524 raw words (65477 effective words) took 0.3s, 259868 effective words/s\n",
      "2023-12-06 14:38:21,795 : INFO : EPOCH 21: training on 99524 raw words (65418 effective words) took 0.3s, 254360 effective words/s\n",
      "2023-12-06 14:38:22,051 : INFO : EPOCH 22: training on 99524 raw words (65470 effective words) took 0.3s, 259527 effective words/s\n",
      "2023-12-06 14:38:22,312 : INFO : EPOCH 23: training on 99524 raw words (65506 effective words) took 0.3s, 255891 effective words/s\n",
      "2023-12-06 14:38:22,570 : INFO : EPOCH 24: training on 99524 raw words (65690 effective words) took 0.3s, 258812 effective words/s\n",
      "2023-12-06 14:38:22,830 : INFO : EPOCH 25: training on 99524 raw words (65310 effective words) took 0.3s, 255312 effective words/s\n",
      "2023-12-06 14:38:23,087 : INFO : EPOCH 26: training on 99524 raw words (65503 effective words) took 0.3s, 260076 effective words/s\n",
      "2023-12-06 14:38:23,351 : INFO : EPOCH 27: training on 99524 raw words (65435 effective words) took 0.3s, 251972 effective words/s\n",
      "2023-12-06 14:38:23,612 : INFO : EPOCH 28: training on 99524 raw words (65451 effective words) took 0.3s, 255061 effective words/s\n",
      "2023-12-06 14:38:23,881 : INFO : EPOCH 29: training on 99524 raw words (65549 effective words) took 0.3s, 249004 effective words/s\n",
      "2023-12-06 14:38:23,882 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965125 effective words) took 7.8s, 251508 effective words/s', 'datetime': '2023-12-06T14:38:23.882267', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:38:23,883 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:38:23.883266', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 35%|      | 168/486 [24:46<51:07,  9.65s/it]2023-12-06 14:38:27,441 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:38:27,442 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:38:27,464 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:38:27,465 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:38:27,472 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:38:27.472793', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:38:27,473 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:38:27.473792', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:38:27,481 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:38:27,482 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:38:27,482 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:38:27.482644', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:38:27,498 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:38:27,498 : INFO : resetting layer weights\n",
      "2023-12-06 14:38:27,502 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:38:27.502131', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:38:27,749 : INFO : EPOCH 0: training on 99524 raw words (65570 effective words) took 0.2s, 270769 effective words/s\n",
      "2023-12-06 14:38:27,981 : INFO : EPOCH 1: training on 99524 raw words (65490 effective words) took 0.2s, 286734 effective words/s\n",
      "2023-12-06 14:38:28,229 : INFO : EPOCH 2: training on 99524 raw words (65560 effective words) took 0.2s, 269027 effective words/s\n",
      "2023-12-06 14:38:28,463 : INFO : EPOCH 3: training on 99524 raw words (65489 effective words) took 0.2s, 285725 effective words/s\n",
      "2023-12-06 14:38:28,705 : INFO : EPOCH 4: training on 99524 raw words (65545 effective words) took 0.2s, 275968 effective words/s\n",
      "2023-12-06 14:38:28,940 : INFO : EPOCH 5: training on 99524 raw words (65541 effective words) took 0.2s, 283614 effective words/s\n",
      "2023-12-06 14:38:29,182 : INFO : EPOCH 6: training on 99524 raw words (65529 effective words) took 0.2s, 276670 effective words/s\n",
      "2023-12-06 14:38:29,410 : INFO : EPOCH 7: training on 99524 raw words (65452 effective words) took 0.2s, 291737 effective words/s\n",
      "2023-12-06 14:38:29,650 : INFO : EPOCH 8: training on 99524 raw words (65426 effective words) took 0.2s, 278644 effective words/s\n",
      "2023-12-06 14:38:29,882 : INFO : EPOCH 9: training on 99524 raw words (65427 effective words) took 0.2s, 286571 effective words/s\n",
      "2023-12-06 14:38:30,124 : INFO : EPOCH 10: training on 99524 raw words (65590 effective words) took 0.2s, 275804 effective words/s\n",
      "2023-12-06 14:38:30,358 : INFO : EPOCH 11: training on 99524 raw words (65798 effective words) took 0.2s, 286728 effective words/s\n",
      "2023-12-06 14:38:30,598 : INFO : EPOCH 12: training on 99524 raw words (65504 effective words) took 0.2s, 278769 effective words/s\n",
      "2023-12-06 14:38:30,832 : INFO : EPOCH 13: training on 99524 raw words (65530 effective words) took 0.2s, 285421 effective words/s\n",
      "2023-12-06 14:38:31,088 : INFO : EPOCH 14: training on 99524 raw words (65322 effective words) took 0.3s, 259085 effective words/s\n",
      "2023-12-06 14:38:31,327 : INFO : EPOCH 15: training on 99524 raw words (65446 effective words) took 0.2s, 279207 effective words/s\n",
      "2023-12-06 14:38:31,567 : INFO : EPOCH 16: training on 99524 raw words (65522 effective words) took 0.2s, 278768 effective words/s\n",
      "2023-12-06 14:38:31,801 : INFO : EPOCH 17: training on 99524 raw words (65526 effective words) took 0.2s, 285442 effective words/s\n",
      "2023-12-06 14:38:32,042 : INFO : EPOCH 18: training on 99524 raw words (65668 effective words) took 0.2s, 278986 effective words/s\n",
      "2023-12-06 14:38:32,285 : INFO : EPOCH 19: training on 99524 raw words (65405 effective words) took 0.2s, 273718 effective words/s\n",
      "2023-12-06 14:38:32,529 : INFO : EPOCH 20: training on 99524 raw words (65485 effective words) took 0.2s, 273962 effective words/s\n",
      "2023-12-06 14:38:32,765 : INFO : EPOCH 21: training on 99524 raw words (65522 effective words) took 0.2s, 281953 effective words/s\n",
      "2023-12-06 14:38:33,008 : INFO : EPOCH 22: training on 99524 raw words (65546 effective words) took 0.2s, 275704 effective words/s\n",
      "2023-12-06 14:38:33,241 : INFO : EPOCH 23: training on 99524 raw words (65598 effective words) took 0.2s, 287427 effective words/s\n",
      "2023-12-06 14:38:33,478 : INFO : EPOCH 24: training on 99524 raw words (65557 effective words) took 0.2s, 281584 effective words/s\n",
      "2023-12-06 14:38:33,719 : INFO : EPOCH 25: training on 99524 raw words (65696 effective words) took 0.2s, 277015 effective words/s\n",
      "2023-12-06 14:38:33,964 : INFO : EPOCH 26: training on 99524 raw words (65546 effective words) took 0.2s, 273532 effective words/s\n",
      "2023-12-06 14:38:34,197 : INFO : EPOCH 27: training on 99524 raw words (65558 effective words) took 0.2s, 286121 effective words/s\n",
      "2023-12-06 14:38:34,441 : INFO : EPOCH 28: training on 99524 raw words (65620 effective words) took 0.2s, 273547 effective words/s\n",
      "2023-12-06 14:38:34,673 : INFO : EPOCH 29: training on 99524 raw words (65783 effective words) took 0.2s, 289443 effective words/s\n",
      "2023-12-06 14:38:34,909 : INFO : EPOCH 30: training on 99524 raw words (65539 effective words) took 0.2s, 282837 effective words/s\n",
      "2023-12-06 14:38:35,152 : INFO : EPOCH 31: training on 99524 raw words (65556 effective words) took 0.2s, 277399 effective words/s\n",
      "2023-12-06 14:38:35,381 : INFO : EPOCH 32: training on 99524 raw words (65596 effective words) took 0.2s, 291089 effective words/s\n",
      "2023-12-06 14:38:35,618 : INFO : EPOCH 33: training on 99524 raw words (65424 effective words) took 0.2s, 281462 effective words/s\n",
      "2023-12-06 14:38:35,851 : INFO : EPOCH 34: training on 99524 raw words (65500 effective words) took 0.2s, 286072 effective words/s\n",
      "2023-12-06 14:38:36,089 : INFO : EPOCH 35: training on 99524 raw words (65477 effective words) took 0.2s, 280705 effective words/s\n",
      "2023-12-06 14:38:36,323 : INFO : EPOCH 36: training on 99524 raw words (65522 effective words) took 0.2s, 285659 effective words/s\n",
      "2023-12-06 14:38:36,562 : INFO : EPOCH 37: training on 99524 raw words (65458 effective words) took 0.2s, 277785 effective words/s\n",
      "2023-12-06 14:38:36,797 : INFO : EPOCH 38: training on 99524 raw words (65449 effective words) took 0.2s, 285435 effective words/s\n",
      "2023-12-06 14:38:37,038 : INFO : EPOCH 39: training on 99524 raw words (65459 effective words) took 0.2s, 276566 effective words/s\n",
      "2023-12-06 14:38:37,268 : INFO : EPOCH 40: training on 99524 raw words (65588 effective words) took 0.2s, 290704 effective words/s\n",
      "2023-12-06 14:38:37,510 : INFO : EPOCH 41: training on 99524 raw words (65407 effective words) took 0.2s, 276044 effective words/s\n",
      "2023-12-06 14:38:37,749 : INFO : EPOCH 42: training on 99524 raw words (65485 effective words) took 0.2s, 279029 effective words/s\n",
      "2023-12-06 14:38:37,991 : INFO : EPOCH 43: training on 99524 raw words (65689 effective words) took 0.2s, 277037 effective words/s\n",
      "2023-12-06 14:38:38,229 : INFO : EPOCH 44: training on 99524 raw words (65418 effective words) took 0.2s, 279871 effective words/s\n",
      "2023-12-06 14:38:38,479 : INFO : EPOCH 45: training on 99524 raw words (65495 effective words) took 0.2s, 266595 effective words/s\n",
      "2023-12-06 14:38:38,721 : INFO : EPOCH 46: training on 99524 raw words (65439 effective words) took 0.2s, 277154 effective words/s\n",
      "2023-12-06 14:38:38,963 : INFO : EPOCH 47: training on 99524 raw words (65480 effective words) took 0.2s, 275269 effective words/s\n",
      "2023-12-06 14:38:39,201 : INFO : EPOCH 48: training on 99524 raw words (65640 effective words) took 0.2s, 280392 effective words/s\n",
      "2023-12-06 14:38:39,446 : INFO : EPOCH 49: training on 99524 raw words (65410 effective words) took 0.2s, 272488 effective words/s\n",
      "2023-12-06 14:38:39,448 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276282 effective words) took 11.9s, 274282 effective words/s', 'datetime': '2023-12-06T14:38:39.447074', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:38:39,448 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:38:39.448073', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 35%|      | 169/486 [25:01<1:00:34, 11.47s/it]2023-12-06 14:38:43,156 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:38:43,156 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:38:43,176 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:38:43,177 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:38:43,185 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:38:43.185629', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:38:43,185 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:38:43.185629', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:38:43,192 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:38:43,193 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:38:43,193 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:38:43.193635', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:38:43,204 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:38:43,205 : INFO : resetting layer weights\n",
      "2023-12-06 14:38:43,208 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:38:43.208731', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:38:43,466 : INFO : EPOCH 0: training on 99524 raw words (65545 effective words) took 0.3s, 259159 effective words/s\n",
      "2023-12-06 14:38:43,711 : INFO : EPOCH 1: training on 99524 raw words (65489 effective words) took 0.2s, 271196 effective words/s\n",
      "2023-12-06 14:38:43,964 : INFO : EPOCH 2: training on 99524 raw words (65435 effective words) took 0.2s, 263712 effective words/s\n",
      "2023-12-06 14:38:44,211 : INFO : EPOCH 3: training on 99524 raw words (65632 effective words) took 0.2s, 271195 effective words/s\n",
      "2023-12-06 14:38:44,457 : INFO : EPOCH 4: training on 99524 raw words (65580 effective words) took 0.2s, 270928 effective words/s\n",
      "2023-12-06 14:38:44,698 : INFO : EPOCH 5: training on 99524 raw words (65490 effective words) took 0.2s, 277238 effective words/s\n",
      "2023-12-06 14:38:44,945 : INFO : EPOCH 6: training on 99524 raw words (65456 effective words) took 0.2s, 269558 effective words/s\n",
      "2023-12-06 14:38:45,190 : INFO : EPOCH 7: training on 99524 raw words (65596 effective words) took 0.2s, 271539 effective words/s\n",
      "2023-12-06 14:38:45,440 : INFO : EPOCH 8: training on 99524 raw words (65670 effective words) took 0.2s, 267675 effective words/s\n",
      "2023-12-06 14:38:45,686 : INFO : EPOCH 9: training on 99524 raw words (65521 effective words) took 0.2s, 270657 effective words/s\n",
      "2023-12-06 14:38:45,946 : INFO : EPOCH 10: training on 99524 raw words (65566 effective words) took 0.3s, 256545 effective words/s\n",
      "2023-12-06 14:38:46,194 : INFO : EPOCH 11: training on 99524 raw words (65534 effective words) took 0.2s, 269378 effective words/s\n",
      "2023-12-06 14:38:46,445 : INFO : EPOCH 12: training on 99524 raw words (65675 effective words) took 0.2s, 265993 effective words/s\n",
      "2023-12-06 14:38:46,693 : INFO : EPOCH 13: training on 99524 raw words (65492 effective words) took 0.2s, 269178 effective words/s\n",
      "2023-12-06 14:38:46,947 : INFO : EPOCH 14: training on 99524 raw words (65554 effective words) took 0.2s, 262301 effective words/s\n",
      "2023-12-06 14:38:47,193 : INFO : EPOCH 15: training on 99524 raw words (65465 effective words) took 0.2s, 270612 effective words/s\n",
      "2023-12-06 14:38:47,443 : INFO : EPOCH 16: training on 99524 raw words (65645 effective words) took 0.2s, 267350 effective words/s\n",
      "2023-12-06 14:38:47,694 : INFO : EPOCH 17: training on 99524 raw words (65454 effective words) took 0.2s, 266028 effective words/s\n",
      "2023-12-06 14:38:47,951 : INFO : EPOCH 18: training on 99524 raw words (65462 effective words) took 0.3s, 258962 effective words/s\n",
      "2023-12-06 14:38:48,200 : INFO : EPOCH 19: training on 99524 raw words (65666 effective words) took 0.2s, 268957 effective words/s\n",
      "2023-12-06 14:38:48,447 : INFO : EPOCH 20: training on 99524 raw words (65307 effective words) took 0.2s, 269203 effective words/s\n",
      "2023-12-06 14:38:48,692 : INFO : EPOCH 21: training on 99524 raw words (65441 effective words) took 0.2s, 271451 effective words/s\n",
      "2023-12-06 14:38:48,939 : INFO : EPOCH 22: training on 99524 raw words (65536 effective words) took 0.2s, 270312 effective words/s\n",
      "2023-12-06 14:38:49,179 : INFO : EPOCH 23: training on 99524 raw words (65504 effective words) took 0.2s, 277807 effective words/s\n",
      "2023-12-06 14:38:49,437 : INFO : EPOCH 24: training on 99524 raw words (65395 effective words) took 0.3s, 257349 effective words/s\n",
      "2023-12-06 14:38:49,688 : INFO : EPOCH 25: training on 99524 raw words (65527 effective words) took 0.2s, 266402 effective words/s\n",
      "2023-12-06 14:38:49,940 : INFO : EPOCH 26: training on 99524 raw words (65459 effective words) took 0.2s, 265168 effective words/s\n",
      "2023-12-06 14:38:50,185 : INFO : EPOCH 27: training on 99524 raw words (65483 effective words) took 0.2s, 271506 effective words/s\n",
      "2023-12-06 14:38:50,437 : INFO : EPOCH 28: training on 99524 raw words (65534 effective words) took 0.2s, 265286 effective words/s\n",
      "2023-12-06 14:38:50,684 : INFO : EPOCH 29: training on 99524 raw words (65415 effective words) took 0.2s, 269945 effective words/s\n",
      "2023-12-06 14:38:50,930 : INFO : EPOCH 30: training on 99524 raw words (65557 effective words) took 0.2s, 270509 effective words/s\n",
      "2023-12-06 14:38:51,176 : INFO : EPOCH 31: training on 99524 raw words (65367 effective words) took 0.2s, 270492 effective words/s\n",
      "2023-12-06 14:38:51,424 : INFO : EPOCH 32: training on 99524 raw words (65419 effective words) took 0.2s, 268313 effective words/s\n",
      "2023-12-06 14:38:51,676 : INFO : EPOCH 33: training on 99524 raw words (65404 effective words) took 0.2s, 266194 effective words/s\n",
      "2023-12-06 14:38:51,922 : INFO : EPOCH 34: training on 99524 raw words (65578 effective words) took 0.2s, 271027 effective words/s\n",
      "2023-12-06 14:38:52,162 : INFO : EPOCH 35: training on 99524 raw words (65510 effective words) took 0.2s, 276958 effective words/s\n",
      "2023-12-06 14:38:52,409 : INFO : EPOCH 36: training on 99524 raw words (65512 effective words) took 0.2s, 270185 effective words/s\n",
      "2023-12-06 14:38:52,651 : INFO : EPOCH 37: training on 99524 raw words (65674 effective words) took 0.2s, 276801 effective words/s\n",
      "2023-12-06 14:38:52,903 : INFO : EPOCH 38: training on 99524 raw words (65495 effective words) took 0.2s, 264213 effective words/s\n",
      "2023-12-06 14:38:53,144 : INFO : EPOCH 39: training on 99524 raw words (65435 effective words) took 0.2s, 276406 effective words/s\n",
      "2023-12-06 14:38:53,390 : INFO : EPOCH 40: training on 99524 raw words (65502 effective words) took 0.2s, 271009 effective words/s\n",
      "2023-12-06 14:38:53,638 : INFO : EPOCH 41: training on 99524 raw words (65647 effective words) took 0.2s, 269448 effective words/s\n",
      "2023-12-06 14:38:53,884 : INFO : EPOCH 42: training on 99524 raw words (65574 effective words) took 0.2s, 273146 effective words/s\n",
      "2023-12-06 14:38:54,133 : INFO : EPOCH 43: training on 99524 raw words (65476 effective words) took 0.2s, 266849 effective words/s\n",
      "2023-12-06 14:38:54,376 : INFO : EPOCH 44: training on 99524 raw words (65537 effective words) took 0.2s, 274519 effective words/s\n",
      "2023-12-06 14:38:54,624 : INFO : EPOCH 45: training on 99524 raw words (65530 effective words) took 0.2s, 269207 effective words/s\n",
      "2023-12-06 14:38:54,875 : INFO : EPOCH 46: training on 99524 raw words (65497 effective words) took 0.2s, 266935 effective words/s\n",
      "2023-12-06 14:38:55,122 : INFO : EPOCH 47: training on 99524 raw words (65556 effective words) took 0.2s, 269519 effective words/s\n",
      "2023-12-06 14:38:55,366 : INFO : EPOCH 48: training on 99524 raw words (65605 effective words) took 0.2s, 273823 effective words/s\n",
      "2023-12-06 14:38:55,612 : INFO : EPOCH 49: training on 99524 raw words (65622 effective words) took 0.2s, 271416 effective words/s\n",
      "2023-12-06 14:38:55,613 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276025 effective words) took 12.4s, 264110 effective words/s', 'datetime': '2023-12-06T14:38:55.613811', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:38:55,614 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:38:55.614855', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 35%|      | 170/486 [25:18<1:08:25, 12.99s/it]2023-12-06 14:38:59,705 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:38:59,706 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:38:59,727 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:38:59,728 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:38:59,737 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:38:59.737959', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:38:59,738 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:38:59.738966', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:38:59,746 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:38:59,747 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:38:59,748 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:38:59.748834', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:38:59,766 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:38:59,767 : INFO : resetting layer weights\n",
      "2023-12-06 14:38:59,771 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:38:59.771068', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:39:00,060 : INFO : EPOCH 0: training on 99524 raw words (65477 effective words) took 0.3s, 230843 effective words/s\n",
      "2023-12-06 14:39:00,321 : INFO : EPOCH 1: training on 99524 raw words (65516 effective words) took 0.3s, 254976 effective words/s\n",
      "2023-12-06 14:39:00,582 : INFO : EPOCH 2: training on 99524 raw words (65440 effective words) took 0.3s, 254781 effective words/s\n",
      "2023-12-06 14:39:00,842 : INFO : EPOCH 3: training on 99524 raw words (65679 effective words) took 0.3s, 257563 effective words/s\n",
      "2023-12-06 14:39:01,105 : INFO : EPOCH 4: training on 99524 raw words (65547 effective words) took 0.3s, 253583 effective words/s\n",
      "2023-12-06 14:39:01,365 : INFO : EPOCH 5: training on 99524 raw words (65569 effective words) took 0.3s, 256572 effective words/s\n",
      "2023-12-06 14:39:01,626 : INFO : EPOCH 6: training on 99524 raw words (65409 effective words) took 0.3s, 254153 effective words/s\n",
      "2023-12-06 14:39:01,892 : INFO : EPOCH 7: training on 99524 raw words (65463 effective words) took 0.3s, 250841 effective words/s\n",
      "2023-12-06 14:39:02,153 : INFO : EPOCH 8: training on 99524 raw words (65482 effective words) took 0.3s, 256601 effective words/s\n",
      "2023-12-06 14:39:02,410 : INFO : EPOCH 9: training on 99524 raw words (65597 effective words) took 0.3s, 259908 effective words/s\n",
      "2023-12-06 14:39:02,669 : INFO : EPOCH 10: training on 99524 raw words (65673 effective words) took 0.3s, 257824 effective words/s\n",
      "2023-12-06 14:39:02,936 : INFO : EPOCH 11: training on 99524 raw words (65580 effective words) took 0.3s, 248869 effective words/s\n",
      "2023-12-06 14:39:03,197 : INFO : EPOCH 12: training on 99524 raw words (65520 effective words) took 0.3s, 256406 effective words/s\n",
      "2023-12-06 14:39:03,458 : INFO : EPOCH 13: training on 99524 raw words (65638 effective words) took 0.3s, 255499 effective words/s\n",
      "2023-12-06 14:39:03,718 : INFO : EPOCH 14: training on 99524 raw words (65326 effective words) took 0.3s, 255443 effective words/s\n",
      "2023-12-06 14:39:03,978 : INFO : EPOCH 15: training on 99524 raw words (65564 effective words) took 0.3s, 256248 effective words/s\n",
      "2023-12-06 14:39:04,242 : INFO : EPOCH 16: training on 99524 raw words (65630 effective words) took 0.3s, 252676 effective words/s\n",
      "2023-12-06 14:39:04,504 : INFO : EPOCH 17: training on 99524 raw words (65473 effective words) took 0.3s, 255150 effective words/s\n",
      "2023-12-06 14:39:04,760 : INFO : EPOCH 18: training on 99524 raw words (65543 effective words) took 0.3s, 260153 effective words/s\n",
      "2023-12-06 14:39:05,024 : INFO : EPOCH 19: training on 99524 raw words (65676 effective words) took 0.3s, 253742 effective words/s\n",
      "2023-12-06 14:39:05,293 : INFO : EPOCH 20: training on 99524 raw words (65563 effective words) took 0.3s, 248103 effective words/s\n",
      "2023-12-06 14:39:05,555 : INFO : EPOCH 21: training on 99524 raw words (65439 effective words) took 0.3s, 254310 effective words/s\n",
      "2023-12-06 14:39:05,815 : INFO : EPOCH 22: training on 99524 raw words (65447 effective words) took 0.3s, 255649 effective words/s\n",
      "2023-12-06 14:39:06,075 : INFO : EPOCH 23: training on 99524 raw words (65522 effective words) took 0.3s, 256969 effective words/s\n",
      "2023-12-06 14:39:06,334 : INFO : EPOCH 24: training on 99524 raw words (65469 effective words) took 0.3s, 257576 effective words/s\n",
      "2023-12-06 14:39:06,597 : INFO : EPOCH 25: training on 99524 raw words (65497 effective words) took 0.3s, 253841 effective words/s\n",
      "2023-12-06 14:39:06,858 : INFO : EPOCH 26: training on 99524 raw words (65440 effective words) took 0.3s, 254605 effective words/s\n",
      "2023-12-06 14:39:07,119 : INFO : EPOCH 27: training on 99524 raw words (65557 effective words) took 0.3s, 255903 effective words/s\n",
      "2023-12-06 14:39:07,375 : INFO : EPOCH 28: training on 99524 raw words (65569 effective words) took 0.3s, 261132 effective words/s\n",
      "2023-12-06 14:39:07,638 : INFO : EPOCH 29: training on 99524 raw words (65565 effective words) took 0.3s, 253142 effective words/s\n",
      "2023-12-06 14:39:07,895 : INFO : EPOCH 30: training on 99524 raw words (65441 effective words) took 0.3s, 259510 effective words/s\n",
      "2023-12-06 14:39:08,162 : INFO : EPOCH 31: training on 99524 raw words (65475 effective words) took 0.3s, 248575 effective words/s\n",
      "2023-12-06 14:39:08,425 : INFO : EPOCH 32: training on 99524 raw words (65537 effective words) took 0.3s, 253782 effective words/s\n",
      "2023-12-06 14:39:08,690 : INFO : EPOCH 33: training on 99524 raw words (65544 effective words) took 0.3s, 251821 effective words/s\n",
      "2023-12-06 14:39:08,949 : INFO : EPOCH 34: training on 99524 raw words (65552 effective words) took 0.3s, 257281 effective words/s\n",
      "2023-12-06 14:39:09,210 : INFO : EPOCH 35: training on 99524 raw words (65682 effective words) took 0.3s, 255813 effective words/s\n",
      "2023-12-06 14:39:09,469 : INFO : EPOCH 36: training on 99524 raw words (65336 effective words) took 0.3s, 256778 effective words/s\n",
      "2023-12-06 14:39:09,726 : INFO : EPOCH 37: training on 99524 raw words (65583 effective words) took 0.3s, 258830 effective words/s\n",
      "2023-12-06 14:39:09,985 : INFO : EPOCH 38: training on 99524 raw words (65573 effective words) took 0.3s, 258902 effective words/s\n",
      "2023-12-06 14:39:10,241 : INFO : EPOCH 39: training on 99524 raw words (65571 effective words) took 0.3s, 259855 effective words/s\n",
      "2023-12-06 14:39:10,504 : INFO : EPOCH 40: training on 99524 raw words (65689 effective words) took 0.3s, 254618 effective words/s\n",
      "2023-12-06 14:39:10,767 : INFO : EPOCH 41: training on 99524 raw words (65577 effective words) took 0.3s, 253860 effective words/s\n",
      "2023-12-06 14:39:11,026 : INFO : EPOCH 42: training on 99524 raw words (65458 effective words) took 0.3s, 256355 effective words/s\n",
      "2023-12-06 14:39:11,287 : INFO : EPOCH 43: training on 99524 raw words (65610 effective words) took 0.3s, 255367 effective words/s\n",
      "2023-12-06 14:39:11,546 : INFO : EPOCH 44: training on 99524 raw words (65578 effective words) took 0.3s, 257895 effective words/s\n",
      "2023-12-06 14:39:11,805 : INFO : EPOCH 45: training on 99524 raw words (65573 effective words) took 0.3s, 258011 effective words/s\n",
      "2023-12-06 14:39:12,065 : INFO : EPOCH 46: training on 99524 raw words (65658 effective words) took 0.3s, 257002 effective words/s\n",
      "2023-12-06 14:39:12,320 : INFO : EPOCH 47: training on 99524 raw words (65455 effective words) took 0.3s, 259843 effective words/s\n",
      "2023-12-06 14:39:12,577 : INFO : EPOCH 48: training on 99524 raw words (65540 effective words) took 0.3s, 260198 effective words/s\n",
      "2023-12-06 14:39:12,834 : INFO : EPOCH 49: training on 99524 raw words (65490 effective words) took 0.3s, 258968 effective words/s\n",
      "2023-12-06 14:39:12,836 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276792 effective words) took 13.1s, 250823 effective words/s', 'datetime': '2023-12-06T14:39:12.836532', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:39:12,836 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:39:12.836532', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 35%|      | 171/486 [25:35<1:15:30, 14.38s/it]2023-12-06 14:39:17,331 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:39:17,332 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:39:17,355 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:39:17,356 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:39:17,362 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:39:17.362788', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:39:17,362 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:39:17.362788', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:39:17,368 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:39:17,369 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:39:17,370 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:39:17.370790', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:39:17,379 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:39:17,379 : INFO : resetting layer weights\n",
      "2023-12-06 14:39:17,382 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:39:17.382391', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:39:17,629 : INFO : EPOCH 0: training on 99524 raw words (62599 effective words) took 0.2s, 258463 effective words/s\n",
      "2023-12-06 14:39:17,859 : INFO : EPOCH 1: training on 99524 raw words (62831 effective words) took 0.2s, 278110 effective words/s\n",
      "2023-12-06 14:39:18,101 : INFO : EPOCH 2: training on 99524 raw words (62806 effective words) took 0.2s, 264070 effective words/s\n",
      "2023-12-06 14:39:18,336 : INFO : EPOCH 3: training on 99524 raw words (62769 effective words) took 0.2s, 272847 effective words/s\n",
      "2023-12-06 14:39:18,573 : INFO : EPOCH 4: training on 99524 raw words (62633 effective words) took 0.2s, 268610 effective words/s\n",
      "2023-12-06 14:39:18,803 : INFO : EPOCH 5: training on 99524 raw words (62728 effective words) took 0.2s, 277819 effective words/s\n",
      "2023-12-06 14:39:19,038 : INFO : EPOCH 6: training on 99524 raw words (62752 effective words) took 0.2s, 272775 effective words/s\n",
      "2023-12-06 14:39:19,265 : INFO : EPOCH 7: training on 99524 raw words (62841 effective words) took 0.2s, 280765 effective words/s\n",
      "2023-12-06 14:39:19,506 : INFO : EPOCH 8: training on 99524 raw words (62684 effective words) took 0.2s, 265009 effective words/s\n",
      "2023-12-06 14:39:19,735 : INFO : EPOCH 9: training on 99524 raw words (62606 effective words) took 0.2s, 279017 effective words/s\n",
      "2023-12-06 14:39:19,736 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627249 effective words) took 2.4s, 266554 effective words/s', 'datetime': '2023-12-06T14:39:19.736648', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:39:19,736 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:39:19.736648', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 35%|      | 172/486 [25:41<1:00:42, 11.60s/it]2023-12-06 14:39:22,442 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:39:22,442 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:39:22,465 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:39:22,466 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:39:22,471 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:39:22.471117', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:39:22,472 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:39:22.472122', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:39:22,477 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:39:22,478 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:39:22,478 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:39:22.478121', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:39:22,486 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:39:22,488 : INFO : resetting layer weights\n",
      "2023-12-06 14:39:22,490 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:39:22.490610', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:39:22,747 : INFO : EPOCH 0: training on 99524 raw words (62576 effective words) took 0.3s, 247542 effective words/s\n",
      "2023-12-06 14:39:22,998 : INFO : EPOCH 1: training on 99524 raw words (62563 effective words) took 0.2s, 253277 effective words/s\n",
      "2023-12-06 14:39:23,246 : INFO : EPOCH 2: training on 99524 raw words (62794 effective words) took 0.2s, 258605 effective words/s\n",
      "2023-12-06 14:39:23,487 : INFO : EPOCH 3: training on 99524 raw words (62767 effective words) took 0.2s, 265058 effective words/s\n",
      "2023-12-06 14:39:23,728 : INFO : EPOCH 4: training on 99524 raw words (62702 effective words) took 0.2s, 266284 effective words/s\n",
      "2023-12-06 14:39:23,972 : INFO : EPOCH 5: training on 99524 raw words (62856 effective words) took 0.2s, 260661 effective words/s\n",
      "2023-12-06 14:39:24,213 : INFO : EPOCH 6: training on 99524 raw words (62718 effective words) took 0.2s, 265579 effective words/s\n",
      "2023-12-06 14:39:24,460 : INFO : EPOCH 7: training on 99524 raw words (62717 effective words) took 0.2s, 258948 effective words/s\n",
      "2023-12-06 14:39:24,707 : INFO : EPOCH 8: training on 99524 raw words (62696 effective words) took 0.2s, 258195 effective words/s\n",
      "2023-12-06 14:39:24,953 : INFO : EPOCH 9: training on 99524 raw words (62790 effective words) took 0.2s, 260071 effective words/s\n",
      "2023-12-06 14:39:24,954 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627179 effective words) took 2.5s, 254689 effective words/s', 'datetime': '2023-12-06T14:39:24.954382', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:39:24,954 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:39:24.954382', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 36%|      | 173/486 [25:46<50:37,  9.70s/it]  2023-12-06 14:39:27,722 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:39:27,722 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:39:27,744 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:39:27,745 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:39:27,750 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:39:27.750050', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:39:27,751 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:39:27.751050', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:39:27,759 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:39:27,760 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:39:27,760 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:39:27.760564', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:39:27,773 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:39:27,773 : INFO : resetting layer weights\n",
      "2023-12-06 14:39:27,776 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:39:27.776215', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:39:28,037 : INFO : EPOCH 0: training on 99524 raw words (62654 effective words) took 0.3s, 243878 effective words/s\n",
      "2023-12-06 14:39:28,297 : INFO : EPOCH 1: training on 99524 raw words (62846 effective words) took 0.3s, 245205 effective words/s\n",
      "2023-12-06 14:39:28,556 : INFO : EPOCH 2: training on 99524 raw words (62895 effective words) took 0.3s, 246928 effective words/s\n",
      "2023-12-06 14:39:28,812 : INFO : EPOCH 3: training on 99524 raw words (62873 effective words) took 0.3s, 249855 effective words/s\n",
      "2023-12-06 14:39:29,071 : INFO : EPOCH 4: training on 99524 raw words (62832 effective words) took 0.3s, 248292 effective words/s\n",
      "2023-12-06 14:39:29,333 : INFO : EPOCH 5: training on 99524 raw words (62729 effective words) took 0.3s, 244257 effective words/s\n",
      "2023-12-06 14:39:29,595 : INFO : EPOCH 6: training on 99524 raw words (62621 effective words) took 0.3s, 243061 effective words/s\n",
      "2023-12-06 14:39:29,857 : INFO : EPOCH 7: training on 99524 raw words (62914 effective words) took 0.3s, 245216 effective words/s\n",
      "2023-12-06 14:39:30,112 : INFO : EPOCH 8: training on 99524 raw words (62796 effective words) took 0.3s, 249536 effective words/s\n",
      "2023-12-06 14:39:30,373 : INFO : EPOCH 9: training on 99524 raw words (62691 effective words) took 0.3s, 245003 effective words/s\n",
      "2023-12-06 14:39:30,374 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627851 effective words) took 2.6s, 241715 effective words/s', 'datetime': '2023-12-06T14:39:30.374368', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:39:30,375 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:39:30.375365', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 36%|      | 174/486 [25:51<43:51,  8.44s/it]2023-12-06 14:39:33,196 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:39:33,196 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:39:33,217 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:39:33,218 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:39:33,222 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:39:33.222949', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:39:33,223 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:39:33.223949', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:39:33,228 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:39:33,229 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:39:33,229 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:39:33.229949', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:39:33,241 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:39:33,243 : INFO : resetting layer weights\n",
      "2023-12-06 14:39:33,246 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:39:33.246869', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:39:33,497 : INFO : EPOCH 0: training on 99524 raw words (62829 effective words) took 0.2s, 253992 effective words/s\n",
      "2023-12-06 14:39:33,728 : INFO : EPOCH 1: training on 99524 raw words (62677 effective words) took 0.2s, 276588 effective words/s\n",
      "2023-12-06 14:39:33,966 : INFO : EPOCH 2: training on 99524 raw words (62581 effective words) took 0.2s, 268084 effective words/s\n",
      "2023-12-06 14:39:34,203 : INFO : EPOCH 3: training on 99524 raw words (62700 effective words) took 0.2s, 271441 effective words/s\n",
      "2023-12-06 14:39:34,431 : INFO : EPOCH 4: training on 99524 raw words (62769 effective words) took 0.2s, 281128 effective words/s\n",
      "2023-12-06 14:39:34,670 : INFO : EPOCH 5: training on 99524 raw words (62611 effective words) took 0.2s, 266317 effective words/s\n",
      "2023-12-06 14:39:34,903 : INFO : EPOCH 6: training on 99524 raw words (62798 effective words) took 0.2s, 274189 effective words/s\n",
      "2023-12-06 14:39:35,144 : INFO : EPOCH 7: training on 99524 raw words (62547 effective words) took 0.2s, 264122 effective words/s\n",
      "2023-12-06 14:39:35,378 : INFO : EPOCH 8: training on 99524 raw words (62746 effective words) took 0.2s, 272540 effective words/s\n",
      "2023-12-06 14:39:35,616 : INFO : EPOCH 9: training on 99524 raw words (62582 effective words) took 0.2s, 268512 effective words/s\n",
      "2023-12-06 14:39:35,855 : INFO : EPOCH 10: training on 99524 raw words (62758 effective words) took 0.2s, 267110 effective words/s\n",
      "2023-12-06 14:39:36,088 : INFO : EPOCH 11: training on 99524 raw words (62741 effective words) took 0.2s, 273961 effective words/s\n",
      "2023-12-06 14:39:36,328 : INFO : EPOCH 12: training on 99524 raw words (62659 effective words) took 0.2s, 265765 effective words/s\n",
      "2023-12-06 14:39:36,563 : INFO : EPOCH 13: training on 99524 raw words (62809 effective words) took 0.2s, 272838 effective words/s\n",
      "2023-12-06 14:39:36,818 : INFO : EPOCH 14: training on 99524 raw words (62699 effective words) took 0.3s, 250429 effective words/s\n",
      "2023-12-06 14:39:37,054 : INFO : EPOCH 15: training on 99524 raw words (62617 effective words) took 0.2s, 271274 effective words/s\n",
      "2023-12-06 14:39:37,294 : INFO : EPOCH 16: training on 99524 raw words (62713 effective words) took 0.2s, 265198 effective words/s\n",
      "2023-12-06 14:39:37,529 : INFO : EPOCH 17: training on 99524 raw words (62650 effective words) took 0.2s, 272415 effective words/s\n",
      "2023-12-06 14:39:37,768 : INFO : EPOCH 18: training on 99524 raw words (62537 effective words) took 0.2s, 266952 effective words/s\n",
      "2023-12-06 14:39:37,999 : INFO : EPOCH 19: training on 99524 raw words (62843 effective words) took 0.2s, 277530 effective words/s\n",
      "2023-12-06 14:39:38,233 : INFO : EPOCH 20: training on 99524 raw words (62779 effective words) took 0.2s, 272894 effective words/s\n",
      "2023-12-06 14:39:38,471 : INFO : EPOCH 21: training on 99524 raw words (62768 effective words) took 0.2s, 268558 effective words/s\n",
      "2023-12-06 14:39:38,709 : INFO : EPOCH 22: training on 99524 raw words (62835 effective words) took 0.2s, 269416 effective words/s\n",
      "2023-12-06 14:39:38,944 : INFO : EPOCH 23: training on 99524 raw words (62659 effective words) took 0.2s, 272925 effective words/s\n",
      "2023-12-06 14:39:39,188 : INFO : EPOCH 24: training on 99524 raw words (62660 effective words) took 0.2s, 262530 effective words/s\n",
      "2023-12-06 14:39:39,419 : INFO : EPOCH 25: training on 99524 raw words (62602 effective words) took 0.2s, 276282 effective words/s\n",
      "2023-12-06 14:39:39,654 : INFO : EPOCH 26: training on 99524 raw words (62679 effective words) took 0.2s, 272398 effective words/s\n",
      "2023-12-06 14:39:39,885 : INFO : EPOCH 27: training on 99524 raw words (62605 effective words) took 0.2s, 276181 effective words/s\n",
      "2023-12-06 14:39:40,126 : INFO : EPOCH 28: training on 99524 raw words (62819 effective words) took 0.2s, 265367 effective words/s\n",
      "2023-12-06 14:39:40,361 : INFO : EPOCH 29: training on 99524 raw words (62704 effective words) took 0.2s, 271927 effective words/s\n",
      "2023-12-06 14:39:40,361 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1880976 effective words) took 7.1s, 264369 effective words/s', 'datetime': '2023-12-06T14:39:40.361840', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:39:40,363 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:39:40.363063', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 36%|      | 175/486 [26:02<47:00,  9.07s/it]2023-12-06 14:39:43,744 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:39:43,745 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:39:43,766 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:39:43,766 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:39:43,773 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:39:43.773340', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:39:43,774 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:39:43.774341', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:39:43,781 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:39:43,782 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:39:43,782 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:39:43.782998', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:39:43,791 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:39:43,792 : INFO : resetting layer weights\n",
      "2023-12-06 14:39:43,795 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:39:43.795649', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:39:44,051 : INFO : EPOCH 0: training on 99524 raw words (62753 effective words) took 0.3s, 249392 effective words/s\n",
      "2023-12-06 14:39:44,297 : INFO : EPOCH 1: training on 99524 raw words (62610 effective words) took 0.2s, 259753 effective words/s\n",
      "2023-12-06 14:39:44,542 : INFO : EPOCH 2: training on 99524 raw words (62476 effective words) took 0.2s, 258665 effective words/s\n",
      "2023-12-06 14:39:44,780 : INFO : EPOCH 3: training on 99524 raw words (62697 effective words) took 0.2s, 267462 effective words/s\n",
      "2023-12-06 14:39:45,024 : INFO : EPOCH 4: training on 99524 raw words (62920 effective words) took 0.2s, 263091 effective words/s\n",
      "2023-12-06 14:39:45,271 : INFO : EPOCH 5: training on 99524 raw words (62689 effective words) took 0.2s, 258386 effective words/s\n",
      "2023-12-06 14:39:45,516 : INFO : EPOCH 6: training on 99524 raw words (62676 effective words) took 0.2s, 260096 effective words/s\n",
      "2023-12-06 14:39:45,759 : INFO : EPOCH 7: training on 99524 raw words (62745 effective words) took 0.2s, 263453 effective words/s\n",
      "2023-12-06 14:39:46,006 : INFO : EPOCH 8: training on 99524 raw words (62715 effective words) took 0.2s, 257897 effective words/s\n",
      "2023-12-06 14:39:46,246 : INFO : EPOCH 9: training on 99524 raw words (62676 effective words) took 0.2s, 265740 effective words/s\n",
      "2023-12-06 14:39:46,489 : INFO : EPOCH 10: training on 99524 raw words (62782 effective words) took 0.2s, 262879 effective words/s\n",
      "2023-12-06 14:39:46,729 : INFO : EPOCH 11: training on 99524 raw words (62629 effective words) took 0.2s, 265059 effective words/s\n",
      "2023-12-06 14:39:46,974 : INFO : EPOCH 12: training on 99524 raw words (62627 effective words) took 0.2s, 261356 effective words/s\n",
      "2023-12-06 14:39:47,215 : INFO : EPOCH 13: training on 99524 raw words (62797 effective words) took 0.2s, 264316 effective words/s\n",
      "2023-12-06 14:39:47,475 : INFO : EPOCH 14: training on 99524 raw words (62787 effective words) took 0.3s, 245868 effective words/s\n",
      "2023-12-06 14:39:47,732 : INFO : EPOCH 15: training on 99524 raw words (62598 effective words) took 0.3s, 247732 effective words/s\n",
      "2023-12-06 14:39:47,991 : INFO : EPOCH 16: training on 99524 raw words (62867 effective words) took 0.3s, 248552 effective words/s\n",
      "2023-12-06 14:39:48,238 : INFO : EPOCH 17: training on 99524 raw words (62778 effective words) took 0.2s, 258550 effective words/s\n",
      "2023-12-06 14:39:48,484 : INFO : EPOCH 18: training on 99524 raw words (62790 effective words) took 0.2s, 259004 effective words/s\n",
      "2023-12-06 14:39:48,729 : INFO : EPOCH 19: training on 99524 raw words (62719 effective words) took 0.2s, 260746 effective words/s\n",
      "2023-12-06 14:39:48,976 : INFO : EPOCH 20: training on 99524 raw words (62622 effective words) took 0.2s, 258501 effective words/s\n",
      "2023-12-06 14:39:49,216 : INFO : EPOCH 21: training on 99524 raw words (62702 effective words) took 0.2s, 265868 effective words/s\n",
      "2023-12-06 14:39:49,464 : INFO : EPOCH 22: training on 99524 raw words (62885 effective words) took 0.2s, 258182 effective words/s\n",
      "2023-12-06 14:39:49,708 : INFO : EPOCH 23: training on 99524 raw words (62606 effective words) took 0.2s, 260794 effective words/s\n",
      "2023-12-06 14:39:49,955 : INFO : EPOCH 24: training on 99524 raw words (62652 effective words) took 0.2s, 257730 effective words/s\n",
      "2023-12-06 14:39:50,191 : INFO : EPOCH 25: training on 99524 raw words (62725 effective words) took 0.2s, 270731 effective words/s\n",
      "2023-12-06 14:39:50,439 : INFO : EPOCH 26: training on 99524 raw words (62927 effective words) took 0.2s, 258597 effective words/s\n",
      "2023-12-06 14:39:50,692 : INFO : EPOCH 27: training on 99524 raw words (62563 effective words) took 0.2s, 251588 effective words/s\n",
      "2023-12-06 14:39:50,975 : INFO : EPOCH 28: training on 99524 raw words (62734 effective words) took 0.3s, 225185 effective words/s\n",
      "2023-12-06 14:39:51,229 : INFO : EPOCH 29: training on 99524 raw words (62691 effective words) took 0.2s, 250955 effective words/s\n",
      "2023-12-06 14:39:51,230 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881438 effective words) took 7.4s, 253088 effective words/s', 'datetime': '2023-12-06T14:39:51.230562', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:39:51,230 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:39:51.230562', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 36%|      | 176/486 [26:13<49:38,  9.61s/it]2023-12-06 14:39:54,608 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:39:54,609 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:39:54,629 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:39:54,630 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:39:54,635 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:39:54.635337', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:39:54,635 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:39:54.635337', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:39:54,643 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:39:54,643 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:39:54,643 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:39:54.643947', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:39:54,652 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:39:54,653 : INFO : resetting layer weights\n",
      "2023-12-06 14:39:54,657 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:39:54.657226', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:39:54,926 : INFO : EPOCH 0: training on 99524 raw words (62708 effective words) took 0.3s, 236211 effective words/s\n",
      "2023-12-06 14:39:55,186 : INFO : EPOCH 1: training on 99524 raw words (62760 effective words) took 0.3s, 245235 effective words/s\n",
      "2023-12-06 14:39:55,451 : INFO : EPOCH 2: training on 99524 raw words (62807 effective words) took 0.3s, 241655 effective words/s\n",
      "2023-12-06 14:39:55,718 : INFO : EPOCH 3: training on 99524 raw words (62530 effective words) took 0.3s, 239943 effective words/s\n",
      "2023-12-06 14:39:55,975 : INFO : EPOCH 4: training on 99524 raw words (62779 effective words) took 0.3s, 248561 effective words/s\n",
      "2023-12-06 14:39:56,229 : INFO : EPOCH 5: training on 99524 raw words (62612 effective words) took 0.2s, 250707 effective words/s\n",
      "2023-12-06 14:39:56,481 : INFO : EPOCH 6: training on 99524 raw words (62838 effective words) took 0.2s, 253714 effective words/s\n",
      "2023-12-06 14:39:56,752 : INFO : EPOCH 7: training on 99524 raw words (62622 effective words) took 0.3s, 235235 effective words/s\n",
      "2023-12-06 14:39:57,018 : INFO : EPOCH 8: training on 99524 raw words (62687 effective words) took 0.3s, 241083 effective words/s\n",
      "2023-12-06 14:39:57,279 : INFO : EPOCH 9: training on 99524 raw words (62739 effective words) took 0.3s, 245306 effective words/s\n",
      "2023-12-06 14:39:57,536 : INFO : EPOCH 10: training on 99524 raw words (62822 effective words) took 0.3s, 248321 effective words/s\n",
      "2023-12-06 14:39:57,797 : INFO : EPOCH 11: training on 99524 raw words (62662 effective words) took 0.3s, 244011 effective words/s\n",
      "2023-12-06 14:39:58,064 : INFO : EPOCH 12: training on 99524 raw words (62759 effective words) took 0.3s, 239851 effective words/s\n",
      "2023-12-06 14:39:58,324 : INFO : EPOCH 13: training on 99524 raw words (62670 effective words) took 0.3s, 244953 effective words/s\n",
      "2023-12-06 14:39:58,595 : INFO : EPOCH 14: training on 99524 raw words (62879 effective words) took 0.3s, 235628 effective words/s\n",
      "2023-12-06 14:39:58,854 : INFO : EPOCH 15: training on 99524 raw words (62634 effective words) took 0.3s, 247541 effective words/s\n",
      "2023-12-06 14:39:59,110 : INFO : EPOCH 16: training on 99524 raw words (62785 effective words) took 0.3s, 250289 effective words/s\n",
      "2023-12-06 14:39:59,380 : INFO : EPOCH 17: training on 99524 raw words (62856 effective words) took 0.3s, 236776 effective words/s\n",
      "2023-12-06 14:39:59,641 : INFO : EPOCH 18: training on 99524 raw words (62716 effective words) took 0.3s, 245226 effective words/s\n",
      "2023-12-06 14:39:59,896 : INFO : EPOCH 19: training on 99524 raw words (62763 effective words) took 0.3s, 250403 effective words/s\n",
      "2023-12-06 14:40:00,171 : INFO : EPOCH 20: training on 99524 raw words (62759 effective words) took 0.3s, 231258 effective words/s\n",
      "2023-12-06 14:40:00,432 : INFO : EPOCH 21: training on 99524 raw words (62752 effective words) took 0.3s, 245160 effective words/s\n",
      "2023-12-06 14:40:00,686 : INFO : EPOCH 22: training on 99524 raw words (62724 effective words) took 0.3s, 250814 effective words/s\n",
      "2023-12-06 14:40:00,960 : INFO : EPOCH 23: training on 99524 raw words (62873 effective words) took 0.3s, 233870 effective words/s\n",
      "2023-12-06 14:40:01,216 : INFO : EPOCH 24: training on 99524 raw words (62750 effective words) took 0.3s, 250071 effective words/s\n",
      "2023-12-06 14:40:01,470 : INFO : EPOCH 25: training on 99524 raw words (62720 effective words) took 0.2s, 251055 effective words/s\n",
      "2023-12-06 14:40:01,726 : INFO : EPOCH 26: training on 99524 raw words (62934 effective words) took 0.3s, 249767 effective words/s\n",
      "2023-12-06 14:40:01,985 : INFO : EPOCH 27: training on 99524 raw words (62701 effective words) took 0.3s, 246624 effective words/s\n",
      "2023-12-06 14:40:02,254 : INFO : EPOCH 28: training on 99524 raw words (62716 effective words) took 0.3s, 237644 effective words/s\n",
      "2023-12-06 14:40:02,510 : INFO : EPOCH 29: training on 99524 raw words (62780 effective words) took 0.3s, 248409 effective words/s\n",
      "2023-12-06 14:40:02,511 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1882337 effective words) took 7.9s, 239669 effective words/s', 'datetime': '2023-12-06T14:40:02.511697', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:40:02,511 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:40:02.511697', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 36%|      | 177/486 [26:24<52:26, 10.18s/it]2023-12-06 14:40:06,136 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:40:06,137 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:40:06,157 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:40:06,157 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:40:06,164 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:40:06.164199', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:40:06,165 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:40:06.165199', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:40:06,173 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:40:06,173 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:40:06,174 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:40:06.174338', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:40:06,185 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:40:06,185 : INFO : resetting layer weights\n",
      "2023-12-06 14:40:06,189 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:40:06.189028', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:40:06,449 : INFO : EPOCH 0: training on 99524 raw words (62750 effective words) took 0.3s, 245322 effective words/s\n",
      "2023-12-06 14:40:06,694 : INFO : EPOCH 1: training on 99524 raw words (62772 effective words) took 0.2s, 262782 effective words/s\n",
      "2023-12-06 14:40:06,929 : INFO : EPOCH 2: training on 99524 raw words (62758 effective words) took 0.2s, 273231 effective words/s\n",
      "2023-12-06 14:40:07,166 : INFO : EPOCH 3: training on 99524 raw words (62650 effective words) took 0.2s, 268052 effective words/s\n",
      "2023-12-06 14:40:07,401 : INFO : EPOCH 4: training on 99524 raw words (62618 effective words) took 0.2s, 272790 effective words/s\n",
      "2023-12-06 14:40:07,639 : INFO : EPOCH 5: training on 99524 raw words (62798 effective words) took 0.2s, 269283 effective words/s\n",
      "2023-12-06 14:40:07,868 : INFO : EPOCH 6: training on 99524 raw words (62629 effective words) took 0.2s, 279011 effective words/s\n",
      "2023-12-06 14:40:08,104 : INFO : EPOCH 7: training on 99524 raw words (62693 effective words) took 0.2s, 269003 effective words/s\n",
      "2023-12-06 14:40:08,337 : INFO : EPOCH 8: training on 99524 raw words (62694 effective words) took 0.2s, 276188 effective words/s\n",
      "2023-12-06 14:40:08,570 : INFO : EPOCH 9: training on 99524 raw words (62748 effective words) took 0.2s, 274496 effective words/s\n",
      "2023-12-06 14:40:08,801 : INFO : EPOCH 10: training on 99524 raw words (62675 effective words) took 0.2s, 276829 effective words/s\n",
      "2023-12-06 14:40:09,035 : INFO : EPOCH 11: training on 99524 raw words (62742 effective words) took 0.2s, 272145 effective words/s\n",
      "2023-12-06 14:40:09,275 : INFO : EPOCH 12: training on 99524 raw words (62776 effective words) took 0.2s, 266900 effective words/s\n",
      "2023-12-06 14:40:09,511 : INFO : EPOCH 13: training on 99524 raw words (62766 effective words) took 0.2s, 272003 effective words/s\n",
      "2023-12-06 14:40:09,749 : INFO : EPOCH 14: training on 99524 raw words (62712 effective words) took 0.2s, 268955 effective words/s\n",
      "2023-12-06 14:40:09,990 : INFO : EPOCH 15: training on 99524 raw words (62640 effective words) took 0.2s, 263643 effective words/s\n",
      "2023-12-06 14:40:10,220 : INFO : EPOCH 16: training on 99524 raw words (62734 effective words) took 0.2s, 277416 effective words/s\n",
      "2023-12-06 14:40:10,460 : INFO : EPOCH 17: training on 99524 raw words (62585 effective words) took 0.2s, 265823 effective words/s\n",
      "2023-12-06 14:40:10,692 : INFO : EPOCH 18: training on 99524 raw words (62688 effective words) took 0.2s, 275369 effective words/s\n",
      "2023-12-06 14:40:10,931 : INFO : EPOCH 19: training on 99524 raw words (62740 effective words) took 0.2s, 267489 effective words/s\n",
      "2023-12-06 14:40:11,166 : INFO : EPOCH 20: training on 99524 raw words (62564 effective words) took 0.2s, 271904 effective words/s\n",
      "2023-12-06 14:40:11,405 : INFO : EPOCH 21: training on 99524 raw words (62489 effective words) took 0.2s, 266703 effective words/s\n",
      "2023-12-06 14:40:11,636 : INFO : EPOCH 22: training on 99524 raw words (62644 effective words) took 0.2s, 275842 effective words/s\n",
      "2023-12-06 14:40:11,873 : INFO : EPOCH 23: training on 99524 raw words (62662 effective words) took 0.2s, 268982 effective words/s\n",
      "2023-12-06 14:40:12,106 : INFO : EPOCH 24: training on 99524 raw words (62737 effective words) took 0.2s, 274914 effective words/s\n",
      "2023-12-06 14:40:12,350 : INFO : EPOCH 25: training on 99524 raw words (62805 effective words) took 0.2s, 262422 effective words/s\n",
      "2023-12-06 14:40:12,588 : INFO : EPOCH 26: training on 99524 raw words (62596 effective words) took 0.2s, 267775 effective words/s\n",
      "2023-12-06 14:40:12,829 : INFO : EPOCH 27: training on 99524 raw words (62573 effective words) took 0.2s, 264599 effective words/s\n",
      "2023-12-06 14:40:13,075 : INFO : EPOCH 28: training on 99524 raw words (62577 effective words) took 0.2s, 259207 effective words/s\n",
      "2023-12-06 14:40:13,314 : INFO : EPOCH 29: training on 99524 raw words (62668 effective words) took 0.2s, 267470 effective words/s\n",
      "2023-12-06 14:40:13,548 : INFO : EPOCH 30: training on 99524 raw words (62506 effective words) took 0.2s, 272467 effective words/s\n",
      "2023-12-06 14:40:13,787 : INFO : EPOCH 31: training on 99524 raw words (62639 effective words) took 0.2s, 266787 effective words/s\n",
      "2023-12-06 14:40:14,018 : INFO : EPOCH 32: training on 99524 raw words (62819 effective words) took 0.2s, 276772 effective words/s\n",
      "2023-12-06 14:40:14,257 : INFO : EPOCH 33: training on 99524 raw words (62741 effective words) took 0.2s, 268787 effective words/s\n",
      "2023-12-06 14:40:14,500 : INFO : EPOCH 34: training on 99524 raw words (62847 effective words) took 0.2s, 262000 effective words/s\n",
      "2023-12-06 14:40:14,748 : INFO : EPOCH 35: training on 99524 raw words (62548 effective words) took 0.2s, 258549 effective words/s\n",
      "2023-12-06 14:40:14,984 : INFO : EPOCH 36: training on 99524 raw words (62728 effective words) took 0.2s, 270864 effective words/s\n",
      "2023-12-06 14:40:15,225 : INFO : EPOCH 37: training on 99524 raw words (62672 effective words) took 0.2s, 265756 effective words/s\n",
      "2023-12-06 14:40:15,466 : INFO : EPOCH 38: training on 99524 raw words (62724 effective words) took 0.2s, 264783 effective words/s\n",
      "2023-12-06 14:40:15,700 : INFO : EPOCH 39: training on 99524 raw words (62673 effective words) took 0.2s, 273999 effective words/s\n",
      "2023-12-06 14:40:15,945 : INFO : EPOCH 40: training on 99524 raw words (62699 effective words) took 0.2s, 260682 effective words/s\n",
      "2023-12-06 14:40:16,185 : INFO : EPOCH 41: training on 99524 raw words (62749 effective words) took 0.2s, 267278 effective words/s\n",
      "2023-12-06 14:40:16,419 : INFO : EPOCH 42: training on 99524 raw words (62719 effective words) took 0.2s, 272327 effective words/s\n",
      "2023-12-06 14:40:16,648 : INFO : EPOCH 43: training on 99524 raw words (62824 effective words) took 0.2s, 280247 effective words/s\n",
      "2023-12-06 14:40:16,884 : INFO : EPOCH 44: training on 99524 raw words (62810 effective words) took 0.2s, 271685 effective words/s\n",
      "2023-12-06 14:40:17,112 : INFO : EPOCH 45: training on 99524 raw words (62686 effective words) took 0.2s, 279571 effective words/s\n",
      "2023-12-06 14:40:17,355 : INFO : EPOCH 46: training on 99524 raw words (62933 effective words) took 0.2s, 263860 effective words/s\n",
      "2023-12-06 14:40:17,598 : INFO : EPOCH 47: training on 99524 raw words (62797 effective words) took 0.2s, 264701 effective words/s\n",
      "2023-12-06 14:40:17,837 : INFO : EPOCH 48: training on 99524 raw words (62828 effective words) took 0.2s, 269120 effective words/s\n",
      "2023-12-06 14:40:18,070 : INFO : EPOCH 49: training on 99524 raw words (62704 effective words) took 0.2s, 275053 effective words/s\n",
      "2023-12-06 14:40:18,071 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3135129 effective words) took 11.9s, 263872 effective words/s', 'datetime': '2023-12-06T14:40:18.071153', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:40:18,071 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:40:18.071153', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 37%|      | 178/486 [26:40<1:00:49, 11.85s/it]2023-12-06 14:40:21,876 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:40:21,877 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:40:21,908 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:40:21,909 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:40:21,914 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:40:21.914294', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:40:21,914 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:40:21.914294', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:40:21,921 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:40:21,922 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:40:21,923 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:40:21.923870', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:40:21,932 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:40:21,933 : INFO : resetting layer weights\n",
      "2023-12-06 14:40:21,936 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:40:21.936424', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:40:22,208 : INFO : EPOCH 0: training on 99524 raw words (62804 effective words) took 0.3s, 236065 effective words/s\n",
      "2023-12-06 14:40:22,452 : INFO : EPOCH 1: training on 99524 raw words (62712 effective words) took 0.2s, 261962 effective words/s\n",
      "2023-12-06 14:40:22,699 : INFO : EPOCH 2: training on 99524 raw words (62735 effective words) took 0.2s, 258220 effective words/s\n",
      "2023-12-06 14:40:22,953 : INFO : EPOCH 3: training on 99524 raw words (62732 effective words) took 0.2s, 251139 effective words/s\n",
      "2023-12-06 14:40:23,203 : INFO : EPOCH 4: training on 99524 raw words (62818 effective words) took 0.2s, 257539 effective words/s\n",
      "2023-12-06 14:40:23,441 : INFO : EPOCH 5: training on 99524 raw words (62777 effective words) took 0.2s, 268255 effective words/s\n",
      "2023-12-06 14:40:23,688 : INFO : EPOCH 6: training on 99524 raw words (62564 effective words) took 0.2s, 258334 effective words/s\n",
      "2023-12-06 14:40:23,930 : INFO : EPOCH 7: training on 99524 raw words (62652 effective words) took 0.2s, 262764 effective words/s\n",
      "2023-12-06 14:40:24,169 : INFO : EPOCH 8: training on 99524 raw words (62775 effective words) took 0.2s, 268292 effective words/s\n",
      "2023-12-06 14:40:24,425 : INFO : EPOCH 9: training on 99524 raw words (62563 effective words) took 0.3s, 248140 effective words/s\n",
      "2023-12-06 14:40:24,685 : INFO : EPOCH 10: training on 99524 raw words (62518 effective words) took 0.3s, 245027 effective words/s\n",
      "2023-12-06 14:40:24,929 : INFO : EPOCH 11: training on 99524 raw words (62906 effective words) took 0.2s, 262775 effective words/s\n",
      "2023-12-06 14:40:25,178 : INFO : EPOCH 12: training on 99524 raw words (62690 effective words) took 0.2s, 256449 effective words/s\n",
      "2023-12-06 14:40:25,459 : INFO : EPOCH 13: training on 99524 raw words (62697 effective words) took 0.3s, 227800 effective words/s\n",
      "2023-12-06 14:40:25,710 : INFO : EPOCH 14: training on 99524 raw words (62816 effective words) took 0.2s, 255651 effective words/s\n",
      "2023-12-06 14:40:25,975 : INFO : EPOCH 15: training on 99524 raw words (62794 effective words) took 0.3s, 240980 effective words/s\n",
      "2023-12-06 14:40:26,236 : INFO : EPOCH 16: training on 99524 raw words (62537 effective words) took 0.3s, 243434 effective words/s\n",
      "2023-12-06 14:40:26,486 : INFO : EPOCH 17: training on 99524 raw words (62713 effective words) took 0.2s, 255663 effective words/s\n",
      "2023-12-06 14:40:26,734 : INFO : EPOCH 18: training on 99524 raw words (62693 effective words) took 0.2s, 258118 effective words/s\n",
      "2023-12-06 14:40:26,980 : INFO : EPOCH 19: training on 99524 raw words (62735 effective words) took 0.2s, 259001 effective words/s\n",
      "2023-12-06 14:40:27,219 : INFO : EPOCH 20: training on 99524 raw words (62731 effective words) took 0.2s, 266946 effective words/s\n",
      "2023-12-06 14:40:27,466 : INFO : EPOCH 21: training on 99524 raw words (62729 effective words) took 0.2s, 258409 effective words/s\n",
      "2023-12-06 14:40:27,720 : INFO : EPOCH 22: training on 99524 raw words (62741 effective words) took 0.2s, 251870 effective words/s\n",
      "2023-12-06 14:40:27,993 : INFO : EPOCH 23: training on 99524 raw words (62714 effective words) took 0.3s, 233283 effective words/s\n",
      "2023-12-06 14:40:28,254 : INFO : EPOCH 24: training on 99524 raw words (62815 effective words) took 0.3s, 247056 effective words/s\n",
      "2023-12-06 14:40:28,510 : INFO : EPOCH 25: training on 99524 raw words (62794 effective words) took 0.3s, 250334 effective words/s\n",
      "2023-12-06 14:40:28,757 : INFO : EPOCH 26: training on 99524 raw words (62919 effective words) took 0.2s, 260481 effective words/s\n",
      "2023-12-06 14:40:29,035 : INFO : EPOCH 27: training on 99524 raw words (62729 effective words) took 0.3s, 228459 effective words/s\n",
      "2023-12-06 14:40:29,276 : INFO : EPOCH 28: training on 99524 raw words (62809 effective words) took 0.2s, 266420 effective words/s\n",
      "2023-12-06 14:40:29,517 : INFO : EPOCH 29: training on 99524 raw words (62715 effective words) took 0.2s, 264360 effective words/s\n",
      "2023-12-06 14:40:29,773 : INFO : EPOCH 30: training on 99524 raw words (62764 effective words) took 0.3s, 250616 effective words/s\n",
      "2023-12-06 14:40:30,027 : INFO : EPOCH 31: training on 99524 raw words (62714 effective words) took 0.2s, 251180 effective words/s\n",
      "2023-12-06 14:40:30,272 : INFO : EPOCH 32: training on 99524 raw words (63070 effective words) took 0.2s, 261228 effective words/s\n",
      "2023-12-06 14:40:30,520 : INFO : EPOCH 33: training on 99524 raw words (62714 effective words) took 0.2s, 258084 effective words/s\n",
      "2023-12-06 14:40:30,764 : INFO : EPOCH 34: training on 99524 raw words (62709 effective words) took 0.2s, 262435 effective words/s\n",
      "2023-12-06 14:40:31,030 : INFO : EPOCH 35: training on 99524 raw words (62832 effective words) took 0.3s, 239327 effective words/s\n",
      "2023-12-06 14:40:31,282 : INFO : EPOCH 36: training on 99524 raw words (62736 effective words) took 0.2s, 254704 effective words/s\n",
      "2023-12-06 14:40:31,541 : INFO : EPOCH 37: training on 99524 raw words (62785 effective words) took 0.3s, 247077 effective words/s\n",
      "2023-12-06 14:40:31,782 : INFO : EPOCH 38: training on 99524 raw words (62682 effective words) took 0.2s, 264210 effective words/s\n",
      "2023-12-06 14:40:32,037 : INFO : EPOCH 39: training on 99524 raw words (62801 effective words) took 0.3s, 250575 effective words/s\n",
      "2023-12-06 14:40:32,289 : INFO : EPOCH 40: training on 99524 raw words (62720 effective words) took 0.2s, 253591 effective words/s\n",
      "2023-12-06 14:40:32,533 : INFO : EPOCH 41: training on 99524 raw words (62692 effective words) took 0.2s, 262479 effective words/s\n",
      "2023-12-06 14:40:32,787 : INFO : EPOCH 42: training on 99524 raw words (62765 effective words) took 0.2s, 251886 effective words/s\n",
      "2023-12-06 14:40:33,046 : INFO : EPOCH 43: training on 99524 raw words (62796 effective words) took 0.3s, 247115 effective words/s\n",
      "2023-12-06 14:40:33,299 : INFO : EPOCH 44: training on 99524 raw words (62722 effective words) took 0.2s, 253690 effective words/s\n",
      "2023-12-06 14:40:33,543 : INFO : EPOCH 45: training on 99524 raw words (62834 effective words) took 0.2s, 262657 effective words/s\n",
      "2023-12-06 14:40:33,806 : INFO : EPOCH 46: training on 99524 raw words (62497 effective words) took 0.3s, 242673 effective words/s\n",
      "2023-12-06 14:40:34,062 : INFO : EPOCH 47: training on 99524 raw words (62797 effective words) took 0.3s, 251076 effective words/s\n",
      "2023-12-06 14:40:34,316 : INFO : EPOCH 48: training on 99524 raw words (62871 effective words) took 0.2s, 252796 effective words/s\n",
      "2023-12-06 14:40:34,568 : INFO : EPOCH 49: training on 99524 raw words (62645 effective words) took 0.2s, 252885 effective words/s\n",
      "2023-12-06 14:40:34,569 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3137073 effective words) took 12.6s, 248346 effective words/s', 'datetime': '2023-12-06T14:40:34.569430', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:40:34,570 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:40:34.570429', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 37%|      | 179/486 [26:57<1:08:05, 13.31s/it]2023-12-06 14:40:38,582 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:40:38,582 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:40:38,602 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:40:38,603 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:40:38,608 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:40:38.608588', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:40:38,609 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:40:38.609588', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:40:38,617 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:40:38,617 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:40:38,618 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:40:38.618568', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:40:38,630 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:40:38,631 : INFO : resetting layer weights\n",
      "2023-12-06 14:40:38,634 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:40:38.634586', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:40:38,896 : INFO : EPOCH 0: training on 99524 raw words (62715 effective words) took 0.3s, 242442 effective words/s\n",
      "2023-12-06 14:40:39,152 : INFO : EPOCH 1: training on 99524 raw words (62799 effective words) took 0.3s, 250438 effective words/s\n",
      "2023-12-06 14:40:39,407 : INFO : EPOCH 2: training on 99524 raw words (62724 effective words) took 0.3s, 249813 effective words/s\n",
      "2023-12-06 14:40:39,659 : INFO : EPOCH 3: training on 99524 raw words (62732 effective words) took 0.2s, 253546 effective words/s\n",
      "2023-12-06 14:40:39,917 : INFO : EPOCH 4: training on 99524 raw words (62865 effective words) took 0.3s, 247272 effective words/s\n",
      "2023-12-06 14:40:40,173 : INFO : EPOCH 5: training on 99524 raw words (62883 effective words) took 0.3s, 250434 effective words/s\n",
      "2023-12-06 14:40:40,427 : INFO : EPOCH 6: training on 99524 raw words (62772 effective words) took 0.2s, 251503 effective words/s\n",
      "2023-12-06 14:40:40,682 : INFO : EPOCH 7: training on 99524 raw words (62822 effective words) took 0.3s, 250660 effective words/s\n",
      "2023-12-06 14:40:40,941 : INFO : EPOCH 8: training on 99524 raw words (62642 effective words) took 0.3s, 245604 effective words/s\n",
      "2023-12-06 14:40:41,198 : INFO : EPOCH 9: training on 99524 raw words (62724 effective words) took 0.3s, 248388 effective words/s\n",
      "2023-12-06 14:40:41,457 : INFO : EPOCH 10: training on 99524 raw words (62697 effective words) took 0.3s, 247133 effective words/s\n",
      "2023-12-06 14:40:41,714 : INFO : EPOCH 11: training on 99524 raw words (62700 effective words) took 0.3s, 247396 effective words/s\n",
      "2023-12-06 14:40:41,967 : INFO : EPOCH 12: training on 99524 raw words (62903 effective words) took 0.2s, 252901 effective words/s\n",
      "2023-12-06 14:40:42,247 : INFO : EPOCH 13: training on 99524 raw words (62705 effective words) took 0.3s, 227980 effective words/s\n",
      "2023-12-06 14:40:42,509 : INFO : EPOCH 14: training on 99524 raw words (62734 effective words) took 0.3s, 243802 effective words/s\n",
      "2023-12-06 14:40:42,765 : INFO : EPOCH 15: training on 99524 raw words (62793 effective words) took 0.3s, 248637 effective words/s\n",
      "2023-12-06 14:40:43,027 : INFO : EPOCH 16: training on 99524 raw words (62738 effective words) took 0.3s, 244296 effective words/s\n",
      "2023-12-06 14:40:43,284 : INFO : EPOCH 17: training on 99524 raw words (62748 effective words) took 0.3s, 247598 effective words/s\n",
      "2023-12-06 14:40:43,543 : INFO : EPOCH 18: training on 99524 raw words (62703 effective words) took 0.3s, 246546 effective words/s\n",
      "2023-12-06 14:40:43,800 : INFO : EPOCH 19: training on 99524 raw words (62744 effective words) took 0.3s, 248804 effective words/s\n",
      "2023-12-06 14:40:44,056 : INFO : EPOCH 20: training on 99524 raw words (62623 effective words) took 0.3s, 249028 effective words/s\n",
      "2023-12-06 14:40:44,312 : INFO : EPOCH 21: training on 99524 raw words (62675 effective words) took 0.3s, 249585 effective words/s\n",
      "2023-12-06 14:40:44,568 : INFO : EPOCH 22: training on 99524 raw words (62677 effective words) took 0.3s, 248261 effective words/s\n",
      "2023-12-06 14:40:44,827 : INFO : EPOCH 23: training on 99524 raw words (62725 effective words) took 0.3s, 246181 effective words/s\n",
      "2023-12-06 14:40:45,096 : INFO : EPOCH 24: training on 99524 raw words (62698 effective words) took 0.3s, 237620 effective words/s\n",
      "2023-12-06 14:40:45,352 : INFO : EPOCH 25: training on 99524 raw words (62855 effective words) took 0.3s, 250775 effective words/s\n",
      "2023-12-06 14:40:45,615 : INFO : EPOCH 26: training on 99524 raw words (62573 effective words) took 0.3s, 242164 effective words/s\n",
      "2023-12-06 14:40:45,868 : INFO : EPOCH 27: training on 99524 raw words (62632 effective words) took 0.2s, 252000 effective words/s\n",
      "2023-12-06 14:40:46,126 : INFO : EPOCH 28: training on 99524 raw words (62789 effective words) took 0.3s, 248527 effective words/s\n",
      "2023-12-06 14:40:46,380 : INFO : EPOCH 29: training on 99524 raw words (62719 effective words) took 0.3s, 250584 effective words/s\n",
      "2023-12-06 14:40:46,637 : INFO : EPOCH 30: training on 99524 raw words (62744 effective words) took 0.3s, 248527 effective words/s\n",
      "2023-12-06 14:40:46,894 : INFO : EPOCH 31: training on 99524 raw words (62680 effective words) took 0.3s, 247849 effective words/s\n",
      "2023-12-06 14:40:47,149 : INFO : EPOCH 32: training on 99524 raw words (62649 effective words) took 0.3s, 249284 effective words/s\n",
      "2023-12-06 14:40:47,399 : INFO : EPOCH 33: training on 99524 raw words (62604 effective words) took 0.2s, 254745 effective words/s\n",
      "2023-12-06 14:40:47,657 : INFO : EPOCH 34: training on 99524 raw words (62687 effective words) took 0.3s, 247952 effective words/s\n",
      "2023-12-06 14:40:47,913 : INFO : EPOCH 35: training on 99524 raw words (62816 effective words) took 0.3s, 250157 effective words/s\n",
      "2023-12-06 14:40:48,196 : INFO : EPOCH 36: training on 99524 raw words (62756 effective words) took 0.3s, 225069 effective words/s\n",
      "2023-12-06 14:40:48,524 : INFO : EPOCH 37: training on 99524 raw words (62676 effective words) took 0.3s, 193366 effective words/s\n",
      "2023-12-06 14:40:48,808 : INFO : EPOCH 38: training on 99524 raw words (62672 effective words) took 0.3s, 226442 effective words/s\n",
      "2023-12-06 14:40:49,083 : INFO : EPOCH 39: training on 99524 raw words (62746 effective words) took 0.3s, 231952 effective words/s\n",
      "2023-12-06 14:40:49,356 : INFO : EPOCH 40: training on 99524 raw words (62685 effective words) took 0.3s, 233354 effective words/s\n",
      "2023-12-06 14:40:49,623 : INFO : EPOCH 41: training on 99524 raw words (62863 effective words) took 0.3s, 238442 effective words/s\n",
      "2023-12-06 14:40:49,888 : INFO : EPOCH 42: training on 99524 raw words (62787 effective words) took 0.3s, 240749 effective words/s\n",
      "2023-12-06 14:40:50,152 : INFO : EPOCH 43: training on 99524 raw words (62915 effective words) took 0.3s, 242310 effective words/s\n",
      "2023-12-06 14:40:50,420 : INFO : EPOCH 44: training on 99524 raw words (62665 effective words) took 0.3s, 237453 effective words/s\n",
      "2023-12-06 14:40:50,685 : INFO : EPOCH 45: training on 99524 raw words (62708 effective words) took 0.3s, 241017 effective words/s\n",
      "2023-12-06 14:40:50,951 : INFO : EPOCH 46: training on 99524 raw words (62750 effective words) took 0.3s, 241251 effective words/s\n",
      "2023-12-06 14:40:51,209 : INFO : EPOCH 47: training on 99524 raw words (63005 effective words) took 0.3s, 247395 effective words/s\n",
      "2023-12-06 14:40:51,465 : INFO : EPOCH 48: training on 99524 raw words (62711 effective words) took 0.3s, 249653 effective words/s\n",
      "2023-12-06 14:40:51,721 : INFO : EPOCH 49: training on 99524 raw words (62803 effective words) took 0.3s, 249526 effective words/s\n",
      "2023-12-06 14:40:51,722 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3137031 effective words) took 13.1s, 239692 effective words/s', 'datetime': '2023-12-06T14:40:51.722301', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:40:51,722 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:40:51.722301', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 37%|      | 180/486 [27:15<1:14:46, 14.66s/it]2023-12-06 14:40:56,405 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:40:56,405 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:40:56,425 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:40:56,426 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:40:56,432 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:40:56.432512', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:40:56,432 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:40:56.432512', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:40:56,439 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:40:56,439 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:40:56,440 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:40:56.440514', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:40:56,447 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:40:56,447 : INFO : resetting layer weights\n",
      "2023-12-06 14:40:56,450 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:40:56.450540', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:40:56,698 : INFO : EPOCH 0: training on 99524 raw words (60540 effective words) took 0.2s, 247547 effective words/s\n",
      "2023-12-06 14:40:56,937 : INFO : EPOCH 1: training on 99524 raw words (60526 effective words) took 0.2s, 257902 effective words/s\n",
      "2023-12-06 14:40:57,173 : INFO : EPOCH 2: training on 99524 raw words (60436 effective words) took 0.2s, 261726 effective words/s\n",
      "2023-12-06 14:40:57,409 : INFO : EPOCH 3: training on 99524 raw words (60434 effective words) took 0.2s, 261811 effective words/s\n",
      "2023-12-06 14:40:57,635 : INFO : EPOCH 4: training on 99524 raw words (60427 effective words) took 0.2s, 271756 effective words/s\n",
      "2023-12-06 14:40:57,869 : INFO : EPOCH 5: training on 99524 raw words (60320 effective words) took 0.2s, 263038 effective words/s\n",
      "2023-12-06 14:40:58,121 : INFO : EPOCH 6: training on 99524 raw words (60258 effective words) took 0.2s, 244313 effective words/s\n",
      "2023-12-06 14:40:58,358 : INFO : EPOCH 7: training on 99524 raw words (60405 effective words) took 0.2s, 259894 effective words/s\n",
      "2023-12-06 14:40:58,605 : INFO : EPOCH 8: training on 99524 raw words (60278 effective words) took 0.2s, 248649 effective words/s\n",
      "2023-12-06 14:40:58,840 : INFO : EPOCH 9: training on 99524 raw words (60257 effective words) took 0.2s, 260890 effective words/s\n",
      "2023-12-06 14:40:58,841 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603881 effective words) took 2.4s, 252578 effective words/s', 'datetime': '2023-12-06T14:40:58.841898', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:40:58,841 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:40:58.841898', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 37%|      | 181/486 [27:20<59:58, 11.80s/it]  2023-12-06 14:41:01,520 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:41:01,520 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:41:01,539 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:41:01,540 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:41:01,544 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:41:01.544762', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:41:01,545 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:41:01.545763', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:41:01,551 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:41:01,552 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:41:01,553 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:41:01.553766', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:41:01,564 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:41:01,564 : INFO : resetting layer weights\n",
      "2023-12-06 14:41:01,567 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:41:01.567390', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:41:01,821 : INFO : EPOCH 0: training on 99524 raw words (60460 effective words) took 0.3s, 241663 effective words/s\n",
      "2023-12-06 14:41:02,062 : INFO : EPOCH 1: training on 99524 raw words (60175 effective words) took 0.2s, 255119 effective words/s\n",
      "2023-12-06 14:41:02,302 : INFO : EPOCH 2: training on 99524 raw words (60482 effective words) took 0.2s, 257348 effective words/s\n",
      "2023-12-06 14:41:02,541 : INFO : EPOCH 3: training on 99524 raw words (60402 effective words) took 0.2s, 257374 effective words/s\n",
      "2023-12-06 14:41:02,794 : INFO : EPOCH 4: training on 99524 raw words (60327 effective words) took 0.2s, 242933 effective words/s\n",
      "2023-12-06 14:41:03,038 : INFO : EPOCH 5: training on 99524 raw words (60447 effective words) took 0.2s, 253009 effective words/s\n",
      "2023-12-06 14:41:03,280 : INFO : EPOCH 6: training on 99524 raw words (60364 effective words) took 0.2s, 254272 effective words/s\n",
      "2023-12-06 14:41:03,527 : INFO : EPOCH 7: training on 99524 raw words (60360 effective words) took 0.2s, 248214 effective words/s\n",
      "2023-12-06 14:41:03,767 : INFO : EPOCH 8: training on 99524 raw words (60201 effective words) took 0.2s, 255076 effective words/s\n",
      "2023-12-06 14:41:04,003 : INFO : EPOCH 9: training on 99524 raw words (60459 effective words) took 0.2s, 261854 effective words/s\n",
      "2023-12-06 14:41:04,004 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603677 effective words) took 2.4s, 247721 effective words/s', 'datetime': '2023-12-06T14:41:04.004592', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:41:04,005 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:41:04.005622', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 37%|      | 182/486 [27:25<49:47,  9.83s/it]2023-12-06 14:41:07,136 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:41:07,138 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:41:07,159 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:41:07,160 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:41:07,164 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:41:07.164733', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:41:07,165 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:41:07.165726', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:41:07,171 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:41:07,172 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:41:07,172 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:41:07.172628', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:41:07,180 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:41:07,181 : INFO : resetting layer weights\n",
      "2023-12-06 14:41:07,184 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:41:07.184713', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:41:07,460 : INFO : EPOCH 0: training on 99524 raw words (60334 effective words) took 0.3s, 224540 effective words/s\n",
      "2023-12-06 14:41:07,719 : INFO : EPOCH 1: training on 99524 raw words (60351 effective words) took 0.3s, 238386 effective words/s\n",
      "2023-12-06 14:41:07,970 : INFO : EPOCH 2: training on 99524 raw words (60714 effective words) took 0.2s, 245677 effective words/s\n",
      "2023-12-06 14:41:08,241 : INFO : EPOCH 3: training on 99524 raw words (60350 effective words) took 0.3s, 227099 effective words/s\n",
      "2023-12-06 14:41:08,499 : INFO : EPOCH 4: training on 99524 raw words (60425 effective words) took 0.3s, 238919 effective words/s\n",
      "2023-12-06 14:41:08,789 : INFO : EPOCH 5: training on 99524 raw words (60589 effective words) took 0.3s, 212136 effective words/s\n",
      "2023-12-06 14:41:09,041 : INFO : EPOCH 6: training on 99524 raw words (60314 effective words) took 0.2s, 243806 effective words/s\n",
      "2023-12-06 14:41:09,306 : INFO : EPOCH 7: training on 99524 raw words (60316 effective words) took 0.3s, 230638 effective words/s\n",
      "2023-12-06 14:41:09,561 : INFO : EPOCH 8: training on 99524 raw words (60358 effective words) took 0.2s, 242235 effective words/s\n",
      "2023-12-06 14:41:09,822 : INFO : EPOCH 9: training on 99524 raw words (60502 effective words) took 0.3s, 235029 effective words/s\n",
      "2023-12-06 14:41:09,823 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604253 effective words) took 2.6s, 229119 effective words/s', 'datetime': '2023-12-06T14:41:09.823804', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:41:09,824 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:41:09.824804', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 38%|      | 183/486 [27:31<43:36,  8.64s/it]2023-12-06 14:41:12,607 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:41:12,607 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:41:12,627 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:41:12,628 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:41:12,635 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:41:12.635119', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:41:12,635 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:41:12.635119', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:41:12,642 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:41:12,643 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:41:12,643 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:41:12.643124', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:41:12,653 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:41:12,653 : INFO : resetting layer weights\n",
      "2023-12-06 14:41:12,656 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:41:12.656632', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:41:12,902 : INFO : EPOCH 0: training on 99524 raw words (60416 effective words) took 0.2s, 248736 effective words/s\n",
      "2023-12-06 14:41:13,137 : INFO : EPOCH 1: training on 99524 raw words (60206 effective words) took 0.2s, 263360 effective words/s\n",
      "2023-12-06 14:41:13,374 : INFO : EPOCH 2: training on 99524 raw words (60411 effective words) took 0.2s, 258243 effective words/s\n",
      "2023-12-06 14:41:13,607 : INFO : EPOCH 3: training on 99524 raw words (60393 effective words) took 0.2s, 264899 effective words/s\n",
      "2023-12-06 14:41:13,840 : INFO : EPOCH 4: training on 99524 raw words (60328 effective words) took 0.2s, 263745 effective words/s\n",
      "2023-12-06 14:41:14,073 : INFO : EPOCH 5: training on 99524 raw words (60514 effective words) took 0.2s, 263941 effective words/s\n",
      "2023-12-06 14:41:14,313 : INFO : EPOCH 6: training on 99524 raw words (60445 effective words) took 0.2s, 257066 effective words/s\n",
      "2023-12-06 14:41:14,504 : INFO : EPOCH 7: training on 99524 raw words (60421 effective words) took 0.2s, 322509 effective words/s\n",
      "2023-12-06 14:41:14,711 : INFO : EPOCH 8: training on 99524 raw words (60328 effective words) took 0.2s, 298434 effective words/s\n",
      "2023-12-06 14:41:14,924 : INFO : EPOCH 9: training on 99524 raw words (60497 effective words) took 0.2s, 289698 effective words/s\n",
      "2023-12-06 14:41:15,159 : INFO : EPOCH 10: training on 99524 raw words (60694 effective words) took 0.2s, 262473 effective words/s\n",
      "2023-12-06 14:41:15,390 : INFO : EPOCH 11: training on 99524 raw words (60533 effective words) took 0.2s, 267424 effective words/s\n",
      "2023-12-06 14:41:15,629 : INFO : EPOCH 12: training on 99524 raw words (60387 effective words) took 0.2s, 257987 effective words/s\n",
      "2023-12-06 14:41:15,870 : INFO : EPOCH 13: training on 99524 raw words (60428 effective words) took 0.2s, 255409 effective words/s\n",
      "2023-12-06 14:41:16,112 : INFO : EPOCH 14: training on 99524 raw words (60323 effective words) took 0.2s, 254138 effective words/s\n",
      "2023-12-06 14:41:16,343 : INFO : EPOCH 15: training on 99524 raw words (60476 effective words) took 0.2s, 266507 effective words/s\n",
      "2023-12-06 14:41:16,581 : INFO : EPOCH 16: training on 99524 raw words (60551 effective words) took 0.2s, 259941 effective words/s\n",
      "2023-12-06 14:41:16,810 : INFO : EPOCH 17: training on 99524 raw words (60370 effective words) took 0.2s, 268509 effective words/s\n",
      "2023-12-06 14:41:17,046 : INFO : EPOCH 18: training on 99524 raw words (60448 effective words) took 0.2s, 261202 effective words/s\n",
      "2023-12-06 14:41:17,278 : INFO : EPOCH 19: training on 99524 raw words (60626 effective words) took 0.2s, 267231 effective words/s\n",
      "2023-12-06 14:41:17,513 : INFO : EPOCH 20: training on 99524 raw words (60324 effective words) took 0.2s, 261760 effective words/s\n",
      "2023-12-06 14:41:17,741 : INFO : EPOCH 21: training on 99524 raw words (60498 effective words) took 0.2s, 268817 effective words/s\n",
      "2023-12-06 14:41:17,973 : INFO : EPOCH 22: training on 99524 raw words (60537 effective words) took 0.2s, 267248 effective words/s\n",
      "2023-12-06 14:41:18,207 : INFO : EPOCH 23: training on 99524 raw words (60299 effective words) took 0.2s, 261468 effective words/s\n",
      "2023-12-06 14:41:18,442 : INFO : EPOCH 24: training on 99524 raw words (60376 effective words) took 0.2s, 262086 effective words/s\n",
      "2023-12-06 14:41:18,669 : INFO : EPOCH 25: training on 99524 raw words (60427 effective words) took 0.2s, 272237 effective words/s\n",
      "2023-12-06 14:41:18,922 : INFO : EPOCH 26: training on 99524 raw words (60527 effective words) took 0.3s, 241946 effective words/s\n",
      "2023-12-06 14:41:19,164 : INFO : EPOCH 27: training on 99524 raw words (60426 effective words) took 0.2s, 255244 effective words/s\n",
      "2023-12-06 14:41:19,398 : INFO : EPOCH 28: training on 99524 raw words (60389 effective words) took 0.2s, 263203 effective words/s\n",
      "2023-12-06 14:41:19,636 : INFO : EPOCH 29: training on 99524 raw words (60350 effective words) took 0.2s, 259043 effective words/s\n",
      "2023-12-06 14:41:19,636 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812948 effective words) took 7.0s, 259731 effective words/s', 'datetime': '2023-12-06T14:41:19.636673', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:41:19,638 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:41:19.638116', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 38%|      | 184/486 [27:41<45:53,  9.12s/it]2023-12-06 14:41:22,848 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:41:22,849 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:41:22,869 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:41:22,870 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:41:22,874 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:41:22.874718', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:41:22,874 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:41:22.874718', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:41:22,879 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:41:22,880 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:41:22,881 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:41:22.881839', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:41:22,890 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:41:22,891 : INFO : resetting layer weights\n",
      "2023-12-06 14:41:22,894 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:41:22.894122', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:41:23,141 : INFO : EPOCH 0: training on 99524 raw words (60490 effective words) took 0.2s, 249073 effective words/s\n",
      "2023-12-06 14:41:23,383 : INFO : EPOCH 1: training on 99524 raw words (60465 effective words) took 0.2s, 255233 effective words/s\n",
      "2023-12-06 14:41:23,624 : INFO : EPOCH 2: training on 99524 raw words (60395 effective words) took 0.2s, 256330 effective words/s\n",
      "2023-12-06 14:41:23,864 : INFO : EPOCH 3: training on 99524 raw words (60438 effective words) took 0.2s, 254734 effective words/s\n",
      "2023-12-06 14:41:24,104 : INFO : EPOCH 4: training on 99524 raw words (60349 effective words) took 0.2s, 256635 effective words/s\n",
      "2023-12-06 14:41:24,345 : INFO : EPOCH 5: training on 99524 raw words (60519 effective words) took 0.2s, 255908 effective words/s\n",
      "2023-12-06 14:41:24,584 : INFO : EPOCH 6: training on 99524 raw words (60308 effective words) took 0.2s, 257242 effective words/s\n",
      "2023-12-06 14:41:24,822 : INFO : EPOCH 7: training on 99524 raw words (60397 effective words) took 0.2s, 257109 effective words/s\n",
      "2023-12-06 14:41:25,065 : INFO : EPOCH 8: training on 99524 raw words (60366 effective words) took 0.2s, 254101 effective words/s\n",
      "2023-12-06 14:41:25,299 : INFO : EPOCH 9: training on 99524 raw words (60336 effective words) took 0.2s, 262829 effective words/s\n",
      "2023-12-06 14:41:25,539 : INFO : EPOCH 10: training on 99524 raw words (60385 effective words) took 0.2s, 255427 effective words/s\n",
      "2023-12-06 14:41:25,776 : INFO : EPOCH 11: training on 99524 raw words (60386 effective words) took 0.2s, 260243 effective words/s\n",
      "2023-12-06 14:41:26,023 : INFO : EPOCH 12: training on 99524 raw words (60269 effective words) took 0.2s, 248687 effective words/s\n",
      "2023-12-06 14:41:26,269 : INFO : EPOCH 13: training on 99524 raw words (60391 effective words) took 0.2s, 249053 effective words/s\n",
      "2023-12-06 14:41:26,518 : INFO : EPOCH 14: training on 99524 raw words (60345 effective words) took 0.2s, 248361 effective words/s\n",
      "2023-12-06 14:41:26,757 : INFO : EPOCH 15: training on 99524 raw words (60261 effective words) took 0.2s, 255342 effective words/s\n",
      "2023-12-06 14:41:27,019 : INFO : EPOCH 16: training on 99524 raw words (60383 effective words) took 0.3s, 234869 effective words/s\n",
      "2023-12-06 14:41:27,259 : INFO : EPOCH 17: training on 99524 raw words (60635 effective words) took 0.2s, 257615 effective words/s\n",
      "2023-12-06 14:41:27,502 : INFO : EPOCH 18: training on 99524 raw words (60297 effective words) took 0.2s, 251520 effective words/s\n",
      "2023-12-06 14:41:27,743 : INFO : EPOCH 19: training on 99524 raw words (60210 effective words) took 0.2s, 255205 effective words/s\n",
      "2023-12-06 14:41:27,980 : INFO : EPOCH 20: training on 99524 raw words (60327 effective words) took 0.2s, 260531 effective words/s\n",
      "2023-12-06 14:41:28,226 : INFO : EPOCH 21: training on 99524 raw words (60451 effective words) took 0.2s, 249491 effective words/s\n",
      "2023-12-06 14:41:28,462 : INFO : EPOCH 22: training on 99524 raw words (60471 effective words) took 0.2s, 261630 effective words/s\n",
      "2023-12-06 14:41:28,705 : INFO : EPOCH 23: training on 99524 raw words (60468 effective words) took 0.2s, 252244 effective words/s\n",
      "2023-12-06 14:41:28,947 : INFO : EPOCH 24: training on 99524 raw words (60429 effective words) took 0.2s, 254476 effective words/s\n",
      "2023-12-06 14:41:29,193 : INFO : EPOCH 25: training on 99524 raw words (60328 effective words) took 0.2s, 250403 effective words/s\n",
      "2023-12-06 14:41:29,438 : INFO : EPOCH 26: training on 99524 raw words (60403 effective words) took 0.2s, 249734 effective words/s\n",
      "2023-12-06 14:41:29,678 : INFO : EPOCH 27: training on 99524 raw words (60299 effective words) took 0.2s, 255765 effective words/s\n",
      "2023-12-06 14:41:29,916 : INFO : EPOCH 28: training on 99524 raw words (60425 effective words) took 0.2s, 259720 effective words/s\n",
      "2023-12-06 14:41:30,156 : INFO : EPOCH 29: training on 99524 raw words (60434 effective words) took 0.2s, 255758 effective words/s\n",
      "2023-12-06 14:41:30,157 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811660 effective words) took 7.3s, 249433 effective words/s', 'datetime': '2023-12-06T14:41:30.157593', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:41:30,158 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:41:30.158598', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 38%|      | 185/486 [27:52<48:01,  9.57s/it]2023-12-06 14:41:33,486 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:41:33,486 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:41:33,507 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:41:33,507 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:41:33,513 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:41:33.513650', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:41:33,514 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:41:33.514650', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:41:33,520 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:41:33,520 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:41:33,521 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:41:33.521809', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:41:33,529 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:41:33,530 : INFO : resetting layer weights\n",
      "2023-12-06 14:41:33,532 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:41:33.532319', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:41:33,802 : INFO : EPOCH 0: training on 99524 raw words (60322 effective words) took 0.3s, 226703 effective words/s\n",
      "2023-12-06 14:41:34,068 : INFO : EPOCH 1: training on 99524 raw words (60402 effective words) took 0.3s, 230350 effective words/s\n",
      "2023-12-06 14:41:34,323 : INFO : EPOCH 2: training on 99524 raw words (60320 effective words) took 0.2s, 241395 effective words/s\n",
      "2023-12-06 14:41:34,577 : INFO : EPOCH 3: training on 99524 raw words (60593 effective words) took 0.3s, 242334 effective words/s\n",
      "2023-12-06 14:41:34,852 : INFO : EPOCH 4: training on 99524 raw words (60324 effective words) took 0.3s, 223635 effective words/s\n",
      "2023-12-06 14:41:35,122 : INFO : EPOCH 5: training on 99524 raw words (60281 effective words) took 0.3s, 227850 effective words/s\n",
      "2023-12-06 14:41:35,382 : INFO : EPOCH 6: training on 99524 raw words (60435 effective words) took 0.3s, 236946 effective words/s\n",
      "2023-12-06 14:41:35,636 : INFO : EPOCH 7: training on 99524 raw words (60336 effective words) took 0.2s, 242458 effective words/s\n",
      "2023-12-06 14:41:35,913 : INFO : EPOCH 8: training on 99524 raw words (60413 effective words) took 0.3s, 223568 effective words/s\n",
      "2023-12-06 14:41:36,170 : INFO : EPOCH 9: training on 99524 raw words (60413 effective words) took 0.3s, 238667 effective words/s\n",
      "2023-12-06 14:41:36,434 : INFO : EPOCH 10: training on 99524 raw words (60334 effective words) took 0.3s, 232978 effective words/s\n",
      "2023-12-06 14:41:36,701 : INFO : EPOCH 11: training on 99524 raw words (60432 effective words) took 0.3s, 230745 effective words/s\n",
      "2023-12-06 14:41:36,984 : INFO : EPOCH 12: training on 99524 raw words (60413 effective words) took 0.3s, 217718 effective words/s\n",
      "2023-12-06 14:41:37,245 : INFO : EPOCH 13: training on 99524 raw words (60399 effective words) took 0.3s, 236221 effective words/s\n",
      "2023-12-06 14:41:37,506 : INFO : EPOCH 14: training on 99524 raw words (60430 effective words) took 0.3s, 234910 effective words/s\n",
      "2023-12-06 14:41:37,770 : INFO : EPOCH 15: training on 99524 raw words (60295 effective words) took 0.3s, 232342 effective words/s\n",
      "2023-12-06 14:41:38,028 : INFO : EPOCH 16: training on 99524 raw words (60132 effective words) took 0.3s, 238607 effective words/s\n",
      "2023-12-06 14:41:38,288 : INFO : EPOCH 17: training on 99524 raw words (60380 effective words) took 0.3s, 236096 effective words/s\n",
      "2023-12-06 14:41:38,544 : INFO : EPOCH 18: training on 99524 raw words (60460 effective words) took 0.3s, 239983 effective words/s\n",
      "2023-12-06 14:41:38,800 : INFO : EPOCH 19: training on 99524 raw words (60240 effective words) took 0.3s, 239812 effective words/s\n",
      "2023-12-06 14:41:39,062 : INFO : EPOCH 20: training on 99524 raw words (60409 effective words) took 0.3s, 234565 effective words/s\n",
      "2023-12-06 14:41:39,326 : INFO : EPOCH 21: training on 99524 raw words (60491 effective words) took 0.3s, 233210 effective words/s\n",
      "2023-12-06 14:41:39,616 : INFO : EPOCH 22: training on 99524 raw words (60455 effective words) took 0.3s, 212659 effective words/s\n",
      "2023-12-06 14:41:39,889 : INFO : EPOCH 23: training on 99524 raw words (60227 effective words) took 0.3s, 224761 effective words/s\n",
      "2023-12-06 14:41:40,161 : INFO : EPOCH 24: training on 99524 raw words (60256 effective words) took 0.3s, 226006 effective words/s\n",
      "2023-12-06 14:41:40,429 : INFO : EPOCH 25: training on 99524 raw words (60263 effective words) took 0.3s, 229241 effective words/s\n",
      "2023-12-06 14:41:40,697 : INFO : EPOCH 26: training on 99524 raw words (60321 effective words) took 0.3s, 228142 effective words/s\n",
      "2023-12-06 14:41:40,960 : INFO : EPOCH 27: training on 99524 raw words (60360 effective words) took 0.3s, 233558 effective words/s\n",
      "2023-12-06 14:41:41,231 : INFO : EPOCH 28: training on 99524 raw words (60199 effective words) took 0.3s, 226404 effective words/s\n",
      "2023-12-06 14:41:41,507 : INFO : EPOCH 29: training on 99524 raw words (60230 effective words) took 0.3s, 222420 effective words/s\n",
      "2023-12-06 14:41:41,508 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1810565 effective words) took 8.0s, 227020 effective words/s', 'datetime': '2023-12-06T14:41:41.508128', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:41:41,509 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:41:41.509128', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 38%|      | 186/486 [28:03<50:56, 10.19s/it]2023-12-06 14:41:45,103 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:41:45,104 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:41:45,124 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:41:45,124 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:41:45,129 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:41:45.129290', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:41:45,129 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:41:45.129290', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:41:45,134 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:41:45,135 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:41:45,135 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:41:45.135797', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:41:45,142 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:41:45,143 : INFO : resetting layer weights\n",
      "2023-12-06 14:41:45,146 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:41:45.145557', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:41:45,405 : INFO : EPOCH 0: training on 99524 raw words (60312 effective words) took 0.3s, 235372 effective words/s\n",
      "2023-12-06 14:41:45,635 : INFO : EPOCH 1: training on 99524 raw words (60342 effective words) took 0.2s, 268157 effective words/s\n",
      "2023-12-06 14:41:45,872 : INFO : EPOCH 2: training on 99524 raw words (60540 effective words) took 0.2s, 260569 effective words/s\n",
      "2023-12-06 14:41:46,101 : INFO : EPOCH 3: training on 99524 raw words (60422 effective words) took 0.2s, 268940 effective words/s\n",
      "2023-12-06 14:41:46,338 : INFO : EPOCH 4: training on 99524 raw words (60649 effective words) took 0.2s, 261223 effective words/s\n",
      "2023-12-06 14:41:46,575 : INFO : EPOCH 5: training on 99524 raw words (60429 effective words) took 0.2s, 258828 effective words/s\n",
      "2023-12-06 14:41:46,814 : INFO : EPOCH 6: training on 99524 raw words (60334 effective words) took 0.2s, 257553 effective words/s\n",
      "2023-12-06 14:41:47,068 : INFO : EPOCH 7: training on 99524 raw words (60173 effective words) took 0.2s, 242542 effective words/s\n",
      "2023-12-06 14:41:47,308 : INFO : EPOCH 8: training on 99524 raw words (60387 effective words) took 0.2s, 256614 effective words/s\n",
      "2023-12-06 14:41:47,542 : INFO : EPOCH 9: training on 99524 raw words (60483 effective words) took 0.2s, 263698 effective words/s\n",
      "2023-12-06 14:41:47,797 : INFO : EPOCH 10: training on 99524 raw words (60427 effective words) took 0.2s, 242286 effective words/s\n",
      "2023-12-06 14:41:48,031 : INFO : EPOCH 11: training on 99524 raw words (60458 effective words) took 0.2s, 263071 effective words/s\n",
      "2023-12-06 14:41:48,285 : INFO : EPOCH 12: training on 99524 raw words (60381 effective words) took 0.2s, 242604 effective words/s\n",
      "2023-12-06 14:41:48,551 : INFO : EPOCH 13: training on 99524 raw words (60450 effective words) took 0.3s, 231206 effective words/s\n",
      "2023-12-06 14:41:48,807 : INFO : EPOCH 14: training on 99524 raw words (60610 effective words) took 0.3s, 241466 effective words/s\n",
      "2023-12-06 14:41:49,048 : INFO : EPOCH 15: training on 99524 raw words (60402 effective words) took 0.2s, 255239 effective words/s\n",
      "2023-12-06 14:41:49,286 : INFO : EPOCH 16: training on 99524 raw words (60355 effective words) took 0.2s, 259029 effective words/s\n",
      "2023-12-06 14:41:49,514 : INFO : EPOCH 17: training on 99524 raw words (60443 effective words) took 0.2s, 269477 effective words/s\n",
      "2023-12-06 14:41:49,767 : INFO : EPOCH 18: training on 99524 raw words (60398 effective words) took 0.2s, 243322 effective words/s\n",
      "2023-12-06 14:41:49,999 : INFO : EPOCH 19: training on 99524 raw words (60549 effective words) took 0.2s, 266641 effective words/s\n",
      "2023-12-06 14:41:50,253 : INFO : EPOCH 20: training on 99524 raw words (60338 effective words) took 0.2s, 241533 effective words/s\n",
      "2023-12-06 14:41:50,495 : INFO : EPOCH 21: training on 99524 raw words (60426 effective words) took 0.2s, 254613 effective words/s\n",
      "2023-12-06 14:41:50,747 : INFO : EPOCH 22: training on 99524 raw words (60295 effective words) took 0.2s, 242493 effective words/s\n",
      "2023-12-06 14:41:51,031 : INFO : EPOCH 23: training on 99524 raw words (60329 effective words) took 0.3s, 218204 effective words/s\n",
      "2023-12-06 14:41:51,277 : INFO : EPOCH 24: training on 99524 raw words (60145 effective words) took 0.2s, 248638 effective words/s\n",
      "2023-12-06 14:41:51,508 : INFO : EPOCH 25: training on 99524 raw words (60371 effective words) took 0.2s, 267752 effective words/s\n",
      "2023-12-06 14:41:51,765 : INFO : EPOCH 26: training on 99524 raw words (60527 effective words) took 0.3s, 240216 effective words/s\n",
      "2023-12-06 14:41:52,015 : INFO : EPOCH 27: training on 99524 raw words (60485 effective words) took 0.2s, 245300 effective words/s\n",
      "2023-12-06 14:41:52,267 : INFO : EPOCH 28: training on 99524 raw words (60579 effective words) took 0.2s, 245575 effective words/s\n",
      "2023-12-06 14:41:52,512 : INFO : EPOCH 29: training on 99524 raw words (60338 effective words) took 0.2s, 252270 effective words/s\n",
      "2023-12-06 14:41:52,749 : INFO : EPOCH 30: training on 99524 raw words (60320 effective words) took 0.2s, 257894 effective words/s\n",
      "2023-12-06 14:41:52,988 : INFO : EPOCH 31: training on 99524 raw words (60357 effective words) took 0.2s, 256895 effective words/s\n",
      "2023-12-06 14:41:53,231 : INFO : EPOCH 32: training on 99524 raw words (60490 effective words) took 0.2s, 255126 effective words/s\n",
      "2023-12-06 14:41:53,474 : INFO : EPOCH 33: training on 99524 raw words (60458 effective words) took 0.2s, 252792 effective words/s\n",
      "2023-12-06 14:41:53,727 : INFO : EPOCH 34: training on 99524 raw words (60403 effective words) took 0.2s, 244370 effective words/s\n",
      "2023-12-06 14:41:53,970 : INFO : EPOCH 35: training on 99524 raw words (60438 effective words) took 0.2s, 254203 effective words/s\n",
      "2023-12-06 14:41:54,235 : INFO : EPOCH 36: training on 99524 raw words (60323 effective words) took 0.3s, 231650 effective words/s\n",
      "2023-12-06 14:41:54,465 : INFO : EPOCH 37: training on 99524 raw words (60375 effective words) took 0.2s, 267814 effective words/s\n",
      "2023-12-06 14:41:54,703 : INFO : EPOCH 38: training on 99524 raw words (60274 effective words) took 0.2s, 257695 effective words/s\n",
      "2023-12-06 14:41:54,954 : INFO : EPOCH 39: training on 99524 raw words (60263 effective words) took 0.2s, 246189 effective words/s\n",
      "2023-12-06 14:41:55,187 : INFO : EPOCH 40: training on 99524 raw words (60399 effective words) took 0.2s, 263426 effective words/s\n",
      "2023-12-06 14:41:55,436 : INFO : EPOCH 41: training on 99524 raw words (60478 effective words) took 0.2s, 248306 effective words/s\n",
      "2023-12-06 14:41:55,673 : INFO : EPOCH 42: training on 99524 raw words (60311 effective words) took 0.2s, 259182 effective words/s\n",
      "2023-12-06 14:41:55,910 : INFO : EPOCH 43: training on 99524 raw words (60426 effective words) took 0.2s, 259480 effective words/s\n",
      "2023-12-06 14:41:56,143 : INFO : EPOCH 44: training on 99524 raw words (60400 effective words) took 0.2s, 264169 effective words/s\n",
      "2023-12-06 14:41:56,375 : INFO : EPOCH 45: training on 99524 raw words (60256 effective words) took 0.2s, 264544 effective words/s\n",
      "2023-12-06 14:41:56,626 : INFO : EPOCH 46: training on 99524 raw words (60418 effective words) took 0.2s, 245409 effective words/s\n",
      "2023-12-06 14:41:56,885 : INFO : EPOCH 47: training on 99524 raw words (60213 effective words) took 0.3s, 237740 effective words/s\n",
      "2023-12-06 14:41:57,136 : INFO : EPOCH 48: training on 99524 raw words (60333 effective words) took 0.2s, 246303 effective words/s\n",
      "2023-12-06 14:41:57,407 : INFO : EPOCH 49: training on 99524 raw words (60356 effective words) took 0.3s, 226469 effective words/s\n",
      "2023-12-06 14:41:57,408 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3019668 effective words) took 12.3s, 246261 effective words/s', 'datetime': '2023-12-06T14:41:57.408477', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:41:57,409 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:41:57.409475', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 38%|      | 187/486 [28:20<59:55, 12.02s/it]2023-12-06 14:42:01,414 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:42:01,414 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:42:01,446 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:42:01,447 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:42:01,451 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:42:01.451222', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:42:01,452 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:42:01.452221', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:42:01,456 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:42:01,457 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:42:01,457 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:42:01.457685', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:42:01,468 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:42:01,469 : INFO : resetting layer weights\n",
      "2023-12-06 14:42:01,474 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:42:01.474211', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:42:01,780 : INFO : EPOCH 0: training on 99524 raw words (60468 effective words) took 0.3s, 201158 effective words/s\n",
      "2023-12-06 14:42:02,042 : INFO : EPOCH 1: training on 99524 raw words (60320 effective words) took 0.3s, 235222 effective words/s\n",
      "2023-12-06 14:42:02,308 : INFO : EPOCH 2: training on 99524 raw words (60407 effective words) took 0.3s, 232039 effective words/s\n",
      "2023-12-06 14:42:02,549 : INFO : EPOCH 3: training on 99524 raw words (60440 effective words) took 0.2s, 255813 effective words/s\n",
      "2023-12-06 14:42:02,811 : INFO : EPOCH 4: training on 99524 raw words (60392 effective words) took 0.3s, 234288 effective words/s\n",
      "2023-12-06 14:42:03,072 : INFO : EPOCH 5: training on 99524 raw words (60308 effective words) took 0.3s, 234931 effective words/s\n",
      "2023-12-06 14:42:03,340 : INFO : EPOCH 6: training on 99524 raw words (60280 effective words) took 0.3s, 229731 effective words/s\n",
      "2023-12-06 14:42:03,592 : INFO : EPOCH 7: training on 99524 raw words (60297 effective words) took 0.2s, 244051 effective words/s\n",
      "2023-12-06 14:42:03,838 : INFO : EPOCH 8: training on 99524 raw words (60326 effective words) took 0.2s, 248684 effective words/s\n",
      "2023-12-06 14:42:04,093 : INFO : EPOCH 9: training on 99524 raw words (60395 effective words) took 0.3s, 240942 effective words/s\n",
      "2023-12-06 14:42:04,357 : INFO : EPOCH 10: training on 99524 raw words (60420 effective words) took 0.3s, 233489 effective words/s\n",
      "2023-12-06 14:42:04,610 : INFO : EPOCH 11: training on 99524 raw words (60311 effective words) took 0.2s, 244323 effective words/s\n",
      "2023-12-06 14:42:04,855 : INFO : EPOCH 12: training on 99524 raw words (60277 effective words) took 0.2s, 249475 effective words/s\n",
      "2023-12-06 14:42:05,108 : INFO : EPOCH 13: training on 99524 raw words (60316 effective words) took 0.2s, 243051 effective words/s\n",
      "2023-12-06 14:42:05,347 : INFO : EPOCH 14: training on 99524 raw words (60429 effective words) took 0.2s, 257496 effective words/s\n",
      "2023-12-06 14:42:05,590 : INFO : EPOCH 15: training on 99524 raw words (60529 effective words) took 0.2s, 253898 effective words/s\n",
      "2023-12-06 14:42:05,833 : INFO : EPOCH 16: training on 99524 raw words (60427 effective words) took 0.2s, 252269 effective words/s\n",
      "2023-12-06 14:42:06,095 : INFO : EPOCH 17: training on 99524 raw words (60494 effective words) took 0.3s, 236308 effective words/s\n",
      "2023-12-06 14:42:06,336 : INFO : EPOCH 18: training on 99524 raw words (60453 effective words) took 0.2s, 254697 effective words/s\n",
      "2023-12-06 14:42:06,601 : INFO : EPOCH 19: training on 99524 raw words (60374 effective words) took 0.3s, 231752 effective words/s\n",
      "2023-12-06 14:42:06,851 : INFO : EPOCH 20: training on 99524 raw words (60495 effective words) took 0.2s, 246200 effective words/s\n",
      "2023-12-06 14:42:07,123 : INFO : EPOCH 21: training on 99524 raw words (60361 effective words) took 0.3s, 227585 effective words/s\n",
      "2023-12-06 14:42:07,367 : INFO : EPOCH 22: training on 99524 raw words (60445 effective words) took 0.2s, 253102 effective words/s\n",
      "2023-12-06 14:42:07,608 : INFO : EPOCH 23: training on 99524 raw words (60379 effective words) took 0.2s, 255893 effective words/s\n",
      "2023-12-06 14:42:07,852 : INFO : EPOCH 24: training on 99524 raw words (60278 effective words) took 0.2s, 250413 effective words/s\n",
      "2023-12-06 14:42:08,095 : INFO : EPOCH 25: training on 99524 raw words (60378 effective words) took 0.2s, 253190 effective words/s\n",
      "2023-12-06 14:42:08,342 : INFO : EPOCH 26: training on 99524 raw words (60474 effective words) took 0.2s, 249750 effective words/s\n",
      "2023-12-06 14:42:08,580 : INFO : EPOCH 27: training on 99524 raw words (60188 effective words) took 0.2s, 257315 effective words/s\n",
      "2023-12-06 14:42:08,823 : INFO : EPOCH 28: training on 99524 raw words (60411 effective words) took 0.2s, 253036 effective words/s\n",
      "2023-12-06 14:42:09,062 : INFO : EPOCH 29: training on 99524 raw words (60588 effective words) took 0.2s, 259114 effective words/s\n",
      "2023-12-06 14:42:09,309 : INFO : EPOCH 30: training on 99524 raw words (60511 effective words) took 0.2s, 250036 effective words/s\n",
      "2023-12-06 14:42:09,548 : INFO : EPOCH 31: training on 99524 raw words (60374 effective words) took 0.2s, 256301 effective words/s\n",
      "2023-12-06 14:42:09,790 : INFO : EPOCH 32: training on 99524 raw words (60446 effective words) took 0.2s, 253915 effective words/s\n",
      "2023-12-06 14:42:10,031 : INFO : EPOCH 33: training on 99524 raw words (60462 effective words) took 0.2s, 255086 effective words/s\n",
      "2023-12-06 14:42:10,280 : INFO : EPOCH 34: training on 99524 raw words (60342 effective words) took 0.2s, 248028 effective words/s\n",
      "2023-12-06 14:42:10,515 : INFO : EPOCH 35: training on 99524 raw words (60332 effective words) took 0.2s, 261125 effective words/s\n",
      "2023-12-06 14:42:10,763 : INFO : EPOCH 36: training on 99524 raw words (60322 effective words) took 0.2s, 247363 effective words/s\n",
      "2023-12-06 14:42:11,008 : INFO : EPOCH 37: training on 99524 raw words (60392 effective words) took 0.2s, 251082 effective words/s\n",
      "2023-12-06 14:42:11,247 : INFO : EPOCH 38: training on 99524 raw words (60435 effective words) took 0.2s, 256482 effective words/s\n",
      "2023-12-06 14:42:11,494 : INFO : EPOCH 39: training on 99524 raw words (60314 effective words) took 0.2s, 248724 effective words/s\n",
      "2023-12-06 14:42:11,741 : INFO : EPOCH 40: training on 99524 raw words (60402 effective words) took 0.2s, 250164 effective words/s\n",
      "2023-12-06 14:42:11,978 : INFO : EPOCH 41: training on 99524 raw words (60364 effective words) took 0.2s, 259168 effective words/s\n",
      "2023-12-06 14:42:12,215 : INFO : EPOCH 42: training on 99524 raw words (60636 effective words) took 0.2s, 259605 effective words/s\n",
      "2023-12-06 14:42:12,461 : INFO : EPOCH 43: training on 99524 raw words (60407 effective words) took 0.2s, 249886 effective words/s\n",
      "2023-12-06 14:42:12,698 : INFO : EPOCH 44: training on 99524 raw words (60127 effective words) took 0.2s, 258868 effective words/s\n",
      "2023-12-06 14:42:12,941 : INFO : EPOCH 45: training on 99524 raw words (60308 effective words) took 0.2s, 252848 effective words/s\n",
      "2023-12-06 14:42:13,190 : INFO : EPOCH 46: training on 99524 raw words (60514 effective words) took 0.2s, 247202 effective words/s\n",
      "2023-12-06 14:42:13,458 : INFO : EPOCH 47: training on 99524 raw words (60389 effective words) took 0.3s, 229973 effective words/s\n",
      "2023-12-06 14:42:13,712 : INFO : EPOCH 48: training on 99524 raw words (60350 effective words) took 0.2s, 242016 effective words/s\n",
      "2023-12-06 14:42:13,985 : INFO : EPOCH 49: training on 99524 raw words (60267 effective words) took 0.3s, 225752 effective words/s\n",
      "2023-12-06 14:42:13,987 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3019354 effective words) took 12.5s, 241331 effective words/s', 'datetime': '2023-12-06T14:42:13.987124', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:42:13,988 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:42:13.988130', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 39%|      | 188/486 [28:36<1:06:43, 13.44s/it]2023-12-06 14:42:18,144 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:42:18,145 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:42:18,165 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:42:18,166 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:42:18,172 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:42:18.172265', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:42:18,173 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:42:18.173265', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:42:18,178 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:42:18,178 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:42:18,178 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:42:18.178265', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:42:18,185 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:42:18,186 : INFO : resetting layer weights\n",
      "2023-12-06 14:42:18,189 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:42:18.189306', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:42:18,448 : INFO : EPOCH 0: training on 99524 raw words (60274 effective words) took 0.3s, 235667 effective words/s\n",
      "2023-12-06 14:42:18,705 : INFO : EPOCH 1: training on 99524 raw words (60303 effective words) took 0.3s, 239458 effective words/s\n",
      "2023-12-06 14:42:18,961 : INFO : EPOCH 2: training on 99524 raw words (60257 effective words) took 0.3s, 239075 effective words/s\n",
      "2023-12-06 14:42:19,211 : INFO : EPOCH 3: training on 99524 raw words (60440 effective words) took 0.2s, 246726 effective words/s\n",
      "2023-12-06 14:42:19,466 : INFO : EPOCH 4: training on 99524 raw words (60339 effective words) took 0.3s, 239968 effective words/s\n",
      "2023-12-06 14:42:19,721 : INFO : EPOCH 5: training on 99524 raw words (60445 effective words) took 0.3s, 241658 effective words/s\n",
      "2023-12-06 14:42:19,974 : INFO : EPOCH 6: training on 99524 raw words (60422 effective words) took 0.2s, 243171 effective words/s\n",
      "2023-12-06 14:42:20,230 : INFO : EPOCH 7: training on 99524 raw words (60436 effective words) took 0.3s, 240399 effective words/s\n",
      "2023-12-06 14:42:20,483 : INFO : EPOCH 8: training on 99524 raw words (60445 effective words) took 0.2s, 242806 effective words/s\n",
      "2023-12-06 14:42:20,732 : INFO : EPOCH 9: training on 99524 raw words (60436 effective words) took 0.2s, 247147 effective words/s\n",
      "2023-12-06 14:42:20,982 : INFO : EPOCH 10: training on 99524 raw words (60380 effective words) took 0.2s, 245737 effective words/s\n",
      "2023-12-06 14:42:21,236 : INFO : EPOCH 11: training on 99524 raw words (60495 effective words) took 0.2s, 241987 effective words/s\n",
      "2023-12-06 14:42:21,485 : INFO : EPOCH 12: training on 99524 raw words (60418 effective words) took 0.2s, 247059 effective words/s\n",
      "2023-12-06 14:42:21,742 : INFO : EPOCH 13: training on 99524 raw words (60222 effective words) took 0.3s, 237804 effective words/s\n",
      "2023-12-06 14:42:21,999 : INFO : EPOCH 14: training on 99524 raw words (60345 effective words) took 0.3s, 240440 effective words/s\n",
      "2023-12-06 14:42:22,252 : INFO : EPOCH 15: training on 99524 raw words (60360 effective words) took 0.2s, 242332 effective words/s\n",
      "2023-12-06 14:42:22,507 : INFO : EPOCH 16: training on 99524 raw words (60383 effective words) took 0.3s, 240984 effective words/s\n",
      "2023-12-06 14:42:22,764 : INFO : EPOCH 17: training on 99524 raw words (60379 effective words) took 0.3s, 239579 effective words/s\n",
      "2023-12-06 14:42:23,036 : INFO : EPOCH 18: training on 99524 raw words (60436 effective words) took 0.3s, 225470 effective words/s\n",
      "2023-12-06 14:42:23,291 : INFO : EPOCH 19: training on 99524 raw words (60410 effective words) took 0.3s, 241007 effective words/s\n",
      "2023-12-06 14:42:23,549 : INFO : EPOCH 20: training on 99524 raw words (60411 effective words) took 0.3s, 237465 effective words/s\n",
      "2023-12-06 14:42:23,809 : INFO : EPOCH 21: training on 99524 raw words (60449 effective words) took 0.3s, 237616 effective words/s\n",
      "2023-12-06 14:42:24,062 : INFO : EPOCH 22: training on 99524 raw words (60312 effective words) took 0.2s, 242311 effective words/s\n",
      "2023-12-06 14:42:24,315 : INFO : EPOCH 23: training on 99524 raw words (60473 effective words) took 0.2s, 243046 effective words/s\n",
      "2023-12-06 14:42:24,570 : INFO : EPOCH 24: training on 99524 raw words (60366 effective words) took 0.3s, 241250 effective words/s\n",
      "2023-12-06 14:42:24,827 : INFO : EPOCH 25: training on 99524 raw words (60459 effective words) took 0.3s, 239397 effective words/s\n",
      "2023-12-06 14:42:25,085 : INFO : EPOCH 26: training on 99524 raw words (60201 effective words) took 0.3s, 239082 effective words/s\n",
      "2023-12-06 14:42:25,338 : INFO : EPOCH 27: training on 99524 raw words (60389 effective words) took 0.2s, 242046 effective words/s\n",
      "2023-12-06 14:42:25,596 : INFO : EPOCH 28: training on 99524 raw words (60361 effective words) took 0.3s, 238865 effective words/s\n",
      "2023-12-06 14:42:25,852 : INFO : EPOCH 29: training on 99524 raw words (60382 effective words) took 0.3s, 239937 effective words/s\n",
      "2023-12-06 14:42:26,107 : INFO : EPOCH 30: training on 99524 raw words (60384 effective words) took 0.3s, 240572 effective words/s\n",
      "2023-12-06 14:42:26,359 : INFO : EPOCH 31: training on 99524 raw words (60464 effective words) took 0.2s, 244279 effective words/s\n",
      "2023-12-06 14:42:26,612 : INFO : EPOCH 32: training on 99524 raw words (60335 effective words) took 0.2s, 242533 effective words/s\n",
      "2023-12-06 14:42:26,868 : INFO : EPOCH 33: training on 99524 raw words (60461 effective words) took 0.3s, 240856 effective words/s\n",
      "2023-12-06 14:42:27,122 : INFO : EPOCH 34: training on 99524 raw words (60517 effective words) took 0.2s, 242453 effective words/s\n",
      "2023-12-06 14:42:27,376 : INFO : EPOCH 35: training on 99524 raw words (60435 effective words) took 0.2s, 241838 effective words/s\n",
      "2023-12-06 14:42:27,631 : INFO : EPOCH 36: training on 99524 raw words (60243 effective words) took 0.3s, 240172 effective words/s\n",
      "2023-12-06 14:42:27,885 : INFO : EPOCH 37: training on 99524 raw words (60345 effective words) took 0.2s, 242026 effective words/s\n",
      "2023-12-06 14:42:28,138 : INFO : EPOCH 38: training on 99524 raw words (60427 effective words) took 0.2s, 242733 effective words/s\n",
      "2023-12-06 14:42:28,394 : INFO : EPOCH 39: training on 99524 raw words (60263 effective words) took 0.3s, 239363 effective words/s\n",
      "2023-12-06 14:42:28,648 : INFO : EPOCH 40: training on 99524 raw words (60372 effective words) took 0.2s, 242258 effective words/s\n",
      "2023-12-06 14:42:28,903 : INFO : EPOCH 41: training on 99524 raw words (60356 effective words) took 0.3s, 240866 effective words/s\n",
      "2023-12-06 14:42:29,152 : INFO : EPOCH 42: training on 99524 raw words (60524 effective words) took 0.2s, 247067 effective words/s\n",
      "2023-12-06 14:42:29,416 : INFO : EPOCH 43: training on 99524 raw words (60366 effective words) took 0.3s, 233342 effective words/s\n",
      "2023-12-06 14:42:29,674 : INFO : EPOCH 44: training on 99524 raw words (60453 effective words) took 0.3s, 238405 effective words/s\n",
      "2023-12-06 14:42:29,931 : INFO : EPOCH 45: training on 99524 raw words (60593 effective words) took 0.3s, 240304 effective words/s\n",
      "2023-12-06 14:42:30,195 : INFO : EPOCH 46: training on 99524 raw words (60361 effective words) took 0.3s, 232582 effective words/s\n",
      "2023-12-06 14:42:30,447 : INFO : EPOCH 47: training on 99524 raw words (60353 effective words) took 0.2s, 242518 effective words/s\n",
      "2023-12-06 14:42:30,707 : INFO : EPOCH 48: training on 99524 raw words (60284 effective words) took 0.3s, 235629 effective words/s\n",
      "2023-12-06 14:42:30,985 : INFO : EPOCH 49: training on 99524 raw words (60416 effective words) took 0.3s, 223272 effective words/s\n",
      "2023-12-06 14:42:30,986 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3019380 effective words) took 12.8s, 235953 effective words/s', 'datetime': '2023-12-06T14:42:30.986508', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:42:30,986 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:42:30.986508', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 39%|      | 189/486 [28:53<1:11:46, 14.50s/it]2023-12-06 14:42:35,127 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:42:35,127 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:42:35,148 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:42:35,149 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:42:35,156 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:42:35.156965', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:42:35,157 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:42:35.157965', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:42:35,168 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:42:35,168 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:42:35,168 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:42:35.168302', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:42:35,184 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:42:35,184 : INFO : resetting layer weights\n",
      "2023-12-06 14:42:35,187 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:42:35.187312', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:42:35,442 : INFO : EPOCH 0: training on 99524 raw words (65499 effective words) took 0.3s, 261800 effective words/s\n",
      "2023-12-06 14:42:35,675 : INFO : EPOCH 1: training on 99524 raw words (65509 effective words) took 0.2s, 286475 effective words/s\n",
      "2023-12-06 14:42:35,911 : INFO : EPOCH 2: training on 99524 raw words (65624 effective words) took 0.2s, 283980 effective words/s\n",
      "2023-12-06 14:42:36,153 : INFO : EPOCH 3: training on 99524 raw words (65534 effective words) took 0.2s, 276181 effective words/s\n",
      "2023-12-06 14:42:36,384 : INFO : EPOCH 4: training on 99524 raw words (65518 effective words) took 0.2s, 289310 effective words/s\n",
      "2023-12-06 14:42:36,621 : INFO : EPOCH 5: training on 99524 raw words (65509 effective words) took 0.2s, 280664 effective words/s\n",
      "2023-12-06 14:42:36,854 : INFO : EPOCH 6: training on 99524 raw words (65719 effective words) took 0.2s, 288021 effective words/s\n",
      "2023-12-06 14:42:37,092 : INFO : EPOCH 7: training on 99524 raw words (65499 effective words) took 0.2s, 280561 effective words/s\n",
      "2023-12-06 14:42:37,330 : INFO : EPOCH 8: training on 99524 raw words (65343 effective words) took 0.2s, 279054 effective words/s\n",
      "2023-12-06 14:42:37,569 : INFO : EPOCH 9: training on 99524 raw words (65403 effective words) took 0.2s, 279347 effective words/s\n",
      "2023-12-06 14:42:37,570 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655157 effective words) took 2.4s, 275049 effective words/s', 'datetime': '2023-12-06T14:42:37.570411', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:42:37,571 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:42:37.570411', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 39%|      | 190/486 [28:58<57:36, 11.68s/it]  2023-12-06 14:42:40,219 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:42:40,220 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:42:40,240 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:42:40,241 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:42:40,249 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:42:40.249893', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:42:40,250 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:42:40.250894', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:42:40,257 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:42:40,257 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:42:40,258 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:42:40.258893', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:42:40,268 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:42:40,269 : INFO : resetting layer weights\n",
      "2023-12-06 14:42:40,271 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:42:40.271894', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:42:40,536 : INFO : EPOCH 0: training on 99524 raw words (65513 effective words) took 0.3s, 251246 effective words/s\n",
      "2023-12-06 14:42:40,787 : INFO : EPOCH 1: training on 99524 raw words (65559 effective words) took 0.2s, 265514 effective words/s\n",
      "2023-12-06 14:42:41,042 : INFO : EPOCH 2: training on 99524 raw words (65556 effective words) took 0.3s, 262056 effective words/s\n",
      "2023-12-06 14:42:41,283 : INFO : EPOCH 3: training on 99524 raw words (65502 effective words) took 0.2s, 277303 effective words/s\n",
      "2023-12-06 14:42:41,532 : INFO : EPOCH 4: training on 99524 raw words (65393 effective words) took 0.2s, 267132 effective words/s\n",
      "2023-12-06 14:42:41,781 : INFO : EPOCH 5: training on 99524 raw words (65559 effective words) took 0.2s, 267062 effective words/s\n",
      "2023-12-06 14:42:42,030 : INFO : EPOCH 6: training on 99524 raw words (65601 effective words) took 0.2s, 268530 effective words/s\n",
      "2023-12-06 14:42:42,278 : INFO : EPOCH 7: training on 99524 raw words (65485 effective words) took 0.2s, 268226 effective words/s\n",
      "2023-12-06 14:42:42,525 : INFO : EPOCH 8: training on 99524 raw words (65424 effective words) took 0.2s, 269043 effective words/s\n",
      "2023-12-06 14:42:42,769 : INFO : EPOCH 9: training on 99524 raw words (65409 effective words) took 0.2s, 274348 effective words/s\n",
      "2023-12-06 14:42:42,770 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655001 effective words) took 2.5s, 262252 effective words/s', 'datetime': '2023-12-06T14:42:42.770667', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:42:42,770 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:42:42.770667', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 39%|      | 191/486 [29:04<47:59,  9.76s/it]2023-12-06 14:42:45,514 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:42:45,515 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:42:45,536 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:42:45,537 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:42:45,541 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:42:45.541011', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:42:45,542 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:42:45.542514', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:42:45,553 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:42:45,554 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:42:45,554 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:42:45.554041', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:42:45,570 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:42:45,570 : INFO : resetting layer weights\n",
      "2023-12-06 14:42:45,573 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:42:45.573041', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:42:45,848 : INFO : EPOCH 0: training on 99524 raw words (65586 effective words) took 0.3s, 241096 effective words/s\n",
      "2023-12-06 14:42:46,108 : INFO : EPOCH 1: training on 99524 raw words (65508 effective words) took 0.3s, 257129 effective words/s\n",
      "2023-12-06 14:42:46,384 : INFO : EPOCH 2: training on 99524 raw words (65562 effective words) took 0.3s, 242553 effective words/s\n",
      "2023-12-06 14:42:46,640 : INFO : EPOCH 3: training on 99524 raw words (65488 effective words) took 0.3s, 260276 effective words/s\n",
      "2023-12-06 14:42:46,904 : INFO : EPOCH 4: training on 99524 raw words (65514 effective words) took 0.3s, 253122 effective words/s\n",
      "2023-12-06 14:42:47,184 : INFO : EPOCH 5: training on 99524 raw words (65604 effective words) took 0.3s, 237751 effective words/s\n",
      "2023-12-06 14:42:47,442 : INFO : EPOCH 6: training on 99524 raw words (65565 effective words) took 0.3s, 258977 effective words/s\n",
      "2023-12-06 14:42:47,700 : INFO : EPOCH 7: training on 99524 raw words (65462 effective words) took 0.3s, 257798 effective words/s\n",
      "2023-12-06 14:42:47,965 : INFO : EPOCH 8: training on 99524 raw words (65600 effective words) took 0.3s, 252328 effective words/s\n",
      "2023-12-06 14:42:48,226 : INFO : EPOCH 9: training on 99524 raw words (65529 effective words) took 0.3s, 256096 effective words/s\n",
      "2023-12-06 14:42:48,227 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655418 effective words) took 2.7s, 247048 effective words/s', 'datetime': '2023-12-06T14:42:48.227040', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:42:48,227 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:42:48.227040', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 40%|      | 192/486 [29:09<41:41,  8.51s/it]2023-12-06 14:42:51,092 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:42:51,093 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:42:51,118 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:42:51,119 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:42:51,124 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:42:51.124390', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:42:51,124 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:42:51.124894', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:42:51,130 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:42:51,131 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:42:51,132 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:42:51.132906', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:42:51,148 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:42:51,149 : INFO : resetting layer weights\n",
      "2023-12-06 14:42:51,152 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:42:51.152319', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:42:51,406 : INFO : EPOCH 0: training on 99524 raw words (65571 effective words) took 0.3s, 261500 effective words/s\n",
      "2023-12-06 14:42:51,650 : INFO : EPOCH 1: training on 99524 raw words (65664 effective words) took 0.2s, 275143 effective words/s\n",
      "2023-12-06 14:42:51,890 : INFO : EPOCH 2: training on 99524 raw words (65688 effective words) took 0.2s, 278887 effective words/s\n",
      "2023-12-06 14:42:52,128 : INFO : EPOCH 3: training on 99524 raw words (65598 effective words) took 0.2s, 280849 effective words/s\n",
      "2023-12-06 14:42:52,371 : INFO : EPOCH 4: training on 99524 raw words (65473 effective words) took 0.2s, 275150 effective words/s\n",
      "2023-12-06 14:42:52,606 : INFO : EPOCH 5: training on 99524 raw words (65696 effective words) took 0.2s, 283833 effective words/s\n",
      "2023-12-06 14:42:52,837 : INFO : EPOCH 6: training on 99524 raw words (65516 effective words) took 0.2s, 289772 effective words/s\n",
      "2023-12-06 14:42:53,077 : INFO : EPOCH 7: training on 99524 raw words (65688 effective words) took 0.2s, 279332 effective words/s\n",
      "2023-12-06 14:42:53,312 : INFO : EPOCH 8: training on 99524 raw words (65528 effective words) took 0.2s, 282895 effective words/s\n",
      "2023-12-06 14:42:53,551 : INFO : EPOCH 9: training on 99524 raw words (65423 effective words) took 0.2s, 278694 effective words/s\n",
      "2023-12-06 14:42:53,791 : INFO : EPOCH 10: training on 99524 raw words (65571 effective words) took 0.2s, 278744 effective words/s\n",
      "2023-12-06 14:42:54,029 : INFO : EPOCH 11: training on 99524 raw words (65581 effective words) took 0.2s, 280336 effective words/s\n",
      "2023-12-06 14:42:54,267 : INFO : EPOCH 12: training on 99524 raw words (65743 effective words) took 0.2s, 281154 effective words/s\n",
      "2023-12-06 14:42:54,496 : INFO : EPOCH 13: training on 99524 raw words (65521 effective words) took 0.2s, 291766 effective words/s\n",
      "2023-12-06 14:42:54,737 : INFO : EPOCH 14: training on 99524 raw words (65673 effective words) took 0.2s, 276324 effective words/s\n",
      "2023-12-06 14:42:54,986 : INFO : EPOCH 15: training on 99524 raw words (65446 effective words) took 0.2s, 268377 effective words/s\n",
      "2023-12-06 14:42:55,227 : INFO : EPOCH 16: training on 99524 raw words (65441 effective words) took 0.2s, 275788 effective words/s\n",
      "2023-12-06 14:42:55,466 : INFO : EPOCH 17: training on 99524 raw words (65505 effective words) took 0.2s, 280975 effective words/s\n",
      "2023-12-06 14:42:55,699 : INFO : EPOCH 18: training on 99524 raw words (65465 effective words) took 0.2s, 286292 effective words/s\n",
      "2023-12-06 14:42:55,943 : INFO : EPOCH 19: training on 99524 raw words (65407 effective words) took 0.2s, 272280 effective words/s\n",
      "2023-12-06 14:42:56,183 : INFO : EPOCH 20: training on 99524 raw words (65487 effective words) took 0.2s, 279672 effective words/s\n",
      "2023-12-06 14:42:56,420 : INFO : EPOCH 21: training on 99524 raw words (65599 effective words) took 0.2s, 282571 effective words/s\n",
      "2023-12-06 14:42:56,659 : INFO : EPOCH 22: training on 99524 raw words (65549 effective words) took 0.2s, 278268 effective words/s\n",
      "2023-12-06 14:42:56,896 : INFO : EPOCH 23: training on 99524 raw words (65589 effective words) took 0.2s, 282155 effective words/s\n",
      "2023-12-06 14:42:57,132 : INFO : EPOCH 24: training on 99524 raw words (65520 effective words) took 0.2s, 283313 effective words/s\n",
      "2023-12-06 14:42:57,367 : INFO : EPOCH 25: training on 99524 raw words (65567 effective words) took 0.2s, 283172 effective words/s\n",
      "2023-12-06 14:42:57,614 : INFO : EPOCH 26: training on 99524 raw words (65620 effective words) took 0.2s, 271202 effective words/s\n",
      "2023-12-06 14:42:57,846 : INFO : EPOCH 27: training on 99524 raw words (65525 effective words) took 0.2s, 287620 effective words/s\n",
      "2023-12-06 14:42:58,086 : INFO : EPOCH 28: training on 99524 raw words (65561 effective words) took 0.2s, 276983 effective words/s\n",
      "2023-12-06 14:42:58,328 : INFO : EPOCH 29: training on 99524 raw words (65695 effective words) took 0.2s, 277786 effective words/s\n",
      "2023-12-06 14:42:58,329 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1966910 effective words) took 7.2s, 274064 effective words/s', 'datetime': '2023-12-06T14:42:58.329718', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:42:58,329 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:42:58.329718', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 40%|      | 193/486 [29:20<44:25,  9.10s/it]2023-12-06 14:43:01,566 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:43:01,567 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:43:01,588 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:43:01,589 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:43:01,594 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:43:01.594054', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:43:01,595 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:43:01.595054', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:43:01,605 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:43:01,605 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:43:01,606 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:43:01.606057', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:43:01,615 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:43:01,616 : INFO : resetting layer weights\n",
      "2023-12-06 14:43:01,619 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:43:01.619395', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:43:01,899 : INFO : EPOCH 0: training on 99524 raw words (65605 effective words) took 0.3s, 237347 effective words/s\n",
      "2023-12-06 14:43:02,146 : INFO : EPOCH 1: training on 99524 raw words (65519 effective words) took 0.2s, 270459 effective words/s\n",
      "2023-12-06 14:43:02,398 : INFO : EPOCH 2: training on 99524 raw words (65669 effective words) took 0.2s, 265182 effective words/s\n",
      "2023-12-06 14:43:02,642 : INFO : EPOCH 3: training on 99524 raw words (65468 effective words) took 0.2s, 273821 effective words/s\n",
      "2023-12-06 14:43:02,895 : INFO : EPOCH 4: training on 99524 raw words (65425 effective words) took 0.2s, 262439 effective words/s\n",
      "2023-12-06 14:43:03,153 : INFO : EPOCH 5: training on 99524 raw words (65328 effective words) took 0.3s, 259995 effective words/s\n",
      "2023-12-06 14:43:03,406 : INFO : EPOCH 6: training on 99524 raw words (65670 effective words) took 0.3s, 262383 effective words/s\n",
      "2023-12-06 14:43:03,652 : INFO : EPOCH 7: training on 99524 raw words (65401 effective words) took 0.2s, 271771 effective words/s\n",
      "2023-12-06 14:43:03,904 : INFO : EPOCH 8: training on 99524 raw words (65609 effective words) took 0.2s, 263357 effective words/s\n",
      "2023-12-06 14:43:04,174 : INFO : EPOCH 9: training on 99524 raw words (65477 effective words) took 0.3s, 247136 effective words/s\n",
      "2023-12-06 14:43:04,434 : INFO : EPOCH 10: training on 99524 raw words (65550 effective words) took 0.3s, 256857 effective words/s\n",
      "2023-12-06 14:43:04,682 : INFO : EPOCH 11: training on 99524 raw words (65475 effective words) took 0.2s, 268115 effective words/s\n",
      "2023-12-06 14:43:04,953 : INFO : EPOCH 12: training on 99524 raw words (65447 effective words) took 0.3s, 245732 effective words/s\n",
      "2023-12-06 14:43:05,200 : INFO : EPOCH 13: training on 99524 raw words (65471 effective words) took 0.2s, 269164 effective words/s\n",
      "2023-12-06 14:43:05,453 : INFO : EPOCH 14: training on 99524 raw words (65567 effective words) took 0.2s, 263163 effective words/s\n",
      "2023-12-06 14:43:05,716 : INFO : EPOCH 15: training on 99524 raw words (65605 effective words) took 0.3s, 254999 effective words/s\n",
      "2023-12-06 14:43:05,960 : INFO : EPOCH 16: training on 99524 raw words (65565 effective words) took 0.2s, 273579 effective words/s\n",
      "2023-12-06 14:43:06,226 : INFO : EPOCH 17: training on 99524 raw words (65477 effective words) took 0.3s, 250470 effective words/s\n",
      "2023-12-06 14:43:06,470 : INFO : EPOCH 18: training on 99524 raw words (65535 effective words) took 0.2s, 273040 effective words/s\n",
      "2023-12-06 14:43:06,723 : INFO : EPOCH 19: training on 99524 raw words (65605 effective words) took 0.2s, 264373 effective words/s\n",
      "2023-12-06 14:43:06,979 : INFO : EPOCH 20: training on 99524 raw words (65482 effective words) took 0.3s, 259467 effective words/s\n",
      "2023-12-06 14:43:07,224 : INFO : EPOCH 21: training on 99524 raw words (65474 effective words) took 0.2s, 271896 effective words/s\n",
      "2023-12-06 14:43:07,476 : INFO : EPOCH 22: training on 99524 raw words (65465 effective words) took 0.2s, 264672 effective words/s\n",
      "2023-12-06 14:43:07,722 : INFO : EPOCH 23: training on 99524 raw words (65546 effective words) took 0.2s, 270333 effective words/s\n",
      "2023-12-06 14:43:07,981 : INFO : EPOCH 24: training on 99524 raw words (65658 effective words) took 0.3s, 258444 effective words/s\n",
      "2023-12-06 14:43:08,230 : INFO : EPOCH 25: training on 99524 raw words (65462 effective words) took 0.2s, 268584 effective words/s\n",
      "2023-12-06 14:43:08,480 : INFO : EPOCH 26: training on 99524 raw words (65494 effective words) took 0.2s, 266488 effective words/s\n",
      "2023-12-06 14:43:08,726 : INFO : EPOCH 27: training on 99524 raw words (65620 effective words) took 0.2s, 270909 effective words/s\n",
      "2023-12-06 14:43:08,973 : INFO : EPOCH 28: training on 99524 raw words (65531 effective words) took 0.2s, 270176 effective words/s\n",
      "2023-12-06 14:43:09,220 : INFO : EPOCH 29: training on 99524 raw words (65599 effective words) took 0.2s, 270358 effective words/s\n",
      "2023-12-06 14:43:09,221 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965799 effective words) took 7.6s, 258595 effective words/s', 'datetime': '2023-12-06T14:43:09.221583', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:43:09,222 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:43:09.222583', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 40%|      | 194/486 [29:31<47:12,  9.70s/it]2023-12-06 14:43:12,673 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:43:12,674 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:43:12,694 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:43:12,695 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:43:12,703 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:43:12.703097', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:43:12,704 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:43:12.704255', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:43:12,711 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:43:12,711 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:43:12,712 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:43:12.712094', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:43:12,728 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:43:12,729 : INFO : resetting layer weights\n",
      "2023-12-06 14:43:12,732 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:43:12.732147', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:43:13,041 : INFO : EPOCH 0: training on 99524 raw words (65508 effective words) took 0.3s, 214420 effective words/s\n",
      "2023-12-06 14:43:13,314 : INFO : EPOCH 1: training on 99524 raw words (65565 effective words) took 0.3s, 249404 effective words/s\n",
      "2023-12-06 14:43:13,574 : INFO : EPOCH 2: training on 99524 raw words (65508 effective words) took 0.3s, 256680 effective words/s\n",
      "2023-12-06 14:43:13,855 : INFO : EPOCH 3: training on 99524 raw words (65638 effective words) took 0.3s, 238292 effective words/s\n",
      "2023-12-06 14:43:14,110 : INFO : EPOCH 4: training on 99524 raw words (65300 effective words) took 0.3s, 260976 effective words/s\n",
      "2023-12-06 14:43:14,365 : INFO : EPOCH 5: training on 99524 raw words (65373 effective words) took 0.3s, 259025 effective words/s\n",
      "2023-12-06 14:43:14,636 : INFO : EPOCH 6: training on 99524 raw words (65564 effective words) took 0.3s, 247482 effective words/s\n",
      "2023-12-06 14:43:14,908 : INFO : EPOCH 7: training on 99524 raw words (65412 effective words) took 0.3s, 244543 effective words/s\n",
      "2023-12-06 14:43:15,171 : INFO : EPOCH 8: training on 99524 raw words (65512 effective words) took 0.3s, 252510 effective words/s\n",
      "2023-12-06 14:43:15,439 : INFO : EPOCH 9: training on 99524 raw words (65487 effective words) took 0.3s, 248752 effective words/s\n",
      "2023-12-06 14:43:15,695 : INFO : EPOCH 10: training on 99524 raw words (65437 effective words) took 0.3s, 261481 effective words/s\n",
      "2023-12-06 14:43:15,961 : INFO : EPOCH 11: training on 99524 raw words (65457 effective words) took 0.3s, 248862 effective words/s\n",
      "2023-12-06 14:43:16,238 : INFO : EPOCH 12: training on 99524 raw words (65586 effective words) took 0.3s, 242789 effective words/s\n",
      "2023-12-06 14:43:16,495 : INFO : EPOCH 13: training on 99524 raw words (65671 effective words) took 0.3s, 258612 effective words/s\n",
      "2023-12-06 14:43:16,764 : INFO : EPOCH 14: training on 99524 raw words (65593 effective words) took 0.3s, 248943 effective words/s\n",
      "2023-12-06 14:43:17,025 : INFO : EPOCH 15: training on 99524 raw words (65431 effective words) took 0.3s, 255880 effective words/s\n",
      "2023-12-06 14:43:17,291 : INFO : EPOCH 16: training on 99524 raw words (65450 effective words) took 0.3s, 249900 effective words/s\n",
      "2023-12-06 14:43:17,566 : INFO : EPOCH 17: training on 99524 raw words (65709 effective words) took 0.3s, 244781 effective words/s\n",
      "2023-12-06 14:43:17,825 : INFO : EPOCH 18: training on 99524 raw words (65549 effective words) took 0.3s, 257279 effective words/s\n",
      "2023-12-06 14:43:18,087 : INFO : EPOCH 19: training on 99524 raw words (65199 effective words) took 0.3s, 252480 effective words/s\n",
      "2023-12-06 14:43:18,353 : INFO : EPOCH 20: training on 99524 raw words (65494 effective words) took 0.3s, 249942 effective words/s\n",
      "2023-12-06 14:43:18,620 : INFO : EPOCH 21: training on 99524 raw words (65627 effective words) took 0.3s, 251193 effective words/s\n",
      "2023-12-06 14:43:18,879 : INFO : EPOCH 22: training on 99524 raw words (65458 effective words) took 0.3s, 257195 effective words/s\n",
      "2023-12-06 14:43:19,133 : INFO : EPOCH 23: training on 99524 raw words (65502 effective words) took 0.3s, 261965 effective words/s\n",
      "2023-12-06 14:43:19,390 : INFO : EPOCH 24: training on 99524 raw words (65481 effective words) took 0.3s, 258707 effective words/s\n",
      "2023-12-06 14:43:19,651 : INFO : EPOCH 25: training on 99524 raw words (65335 effective words) took 0.3s, 254894 effective words/s\n",
      "2023-12-06 14:43:19,911 : INFO : EPOCH 26: training on 99524 raw words (65419 effective words) took 0.3s, 256002 effective words/s\n",
      "2023-12-06 14:43:20,177 : INFO : EPOCH 27: training on 99524 raw words (65539 effective words) took 0.3s, 250964 effective words/s\n",
      "2023-12-06 14:43:20,428 : INFO : EPOCH 28: training on 99524 raw words (65503 effective words) took 0.2s, 265467 effective words/s\n",
      "2023-12-06 14:43:20,690 : INFO : EPOCH 29: training on 99524 raw words (65420 effective words) took 0.3s, 254464 effective words/s\n",
      "2023-12-06 14:43:20,690 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1964727 effective words) took 8.0s, 246878 effective words/s', 'datetime': '2023-12-06T14:43:20.690999', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:43:20,692 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:43:20.692011', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 40%|      | 195/486 [29:43<50:03, 10.32s/it]2023-12-06 14:43:24,444 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:43:24,444 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:43:24,465 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:43:24,466 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:43:24,474 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:43:24.474142', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:43:24,475 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:43:24.475144', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:43:24,481 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:43:24,482 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:43:24,482 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:43:24.482142', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:43:24,497 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:43:24,497 : INFO : resetting layer weights\n",
      "2023-12-06 14:43:24,500 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:43:24.500842', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:43:24,776 : INFO : EPOCH 0: training on 99524 raw words (65650 effective words) took 0.3s, 241841 effective words/s\n",
      "2023-12-06 14:43:25,017 : INFO : EPOCH 1: training on 99524 raw words (65593 effective words) took 0.2s, 279992 effective words/s\n",
      "2023-12-06 14:43:25,254 : INFO : EPOCH 2: training on 99524 raw words (65459 effective words) took 0.2s, 280323 effective words/s\n",
      "2023-12-06 14:43:25,501 : INFO : EPOCH 3: training on 99524 raw words (65544 effective words) took 0.2s, 270955 effective words/s\n",
      "2023-12-06 14:43:25,736 : INFO : EPOCH 4: training on 99524 raw words (65594 effective words) took 0.2s, 285636 effective words/s\n",
      "2023-12-06 14:43:25,974 : INFO : EPOCH 5: training on 99524 raw words (65533 effective words) took 0.2s, 280216 effective words/s\n",
      "2023-12-06 14:43:26,209 : INFO : EPOCH 6: training on 99524 raw words (65614 effective words) took 0.2s, 283788 effective words/s\n",
      "2023-12-06 14:43:26,444 : INFO : EPOCH 7: training on 99524 raw words (65624 effective words) took 0.2s, 283920 effective words/s\n",
      "2023-12-06 14:43:26,681 : INFO : EPOCH 8: training on 99524 raw words (65579 effective words) took 0.2s, 282387 effective words/s\n",
      "2023-12-06 14:43:26,923 : INFO : EPOCH 9: training on 99524 raw words (65533 effective words) took 0.2s, 276926 effective words/s\n",
      "2023-12-06 14:43:27,166 : INFO : EPOCH 10: training on 99524 raw words (65577 effective words) took 0.2s, 275095 effective words/s\n",
      "2023-12-06 14:43:27,410 : INFO : EPOCH 11: training on 99524 raw words (65437 effective words) took 0.2s, 273564 effective words/s\n",
      "2023-12-06 14:43:27,644 : INFO : EPOCH 12: training on 99524 raw words (65396 effective words) took 0.2s, 284164 effective words/s\n",
      "2023-12-06 14:43:27,887 : INFO : EPOCH 13: training on 99524 raw words (65514 effective words) took 0.2s, 273938 effective words/s\n",
      "2023-12-06 14:43:28,128 : INFO : EPOCH 14: training on 99524 raw words (65564 effective words) took 0.2s, 277392 effective words/s\n",
      "2023-12-06 14:43:28,363 : INFO : EPOCH 15: training on 99524 raw words (65502 effective words) took 0.2s, 284121 effective words/s\n",
      "2023-12-06 14:43:28,609 : INFO : EPOCH 16: training on 99524 raw words (65472 effective words) took 0.2s, 271266 effective words/s\n",
      "2023-12-06 14:43:28,851 : INFO : EPOCH 17: training on 99524 raw words (65680 effective words) took 0.2s, 276123 effective words/s\n",
      "2023-12-06 14:43:29,087 : INFO : EPOCH 18: training on 99524 raw words (65471 effective words) took 0.2s, 282088 effective words/s\n",
      "2023-12-06 14:43:29,323 : INFO : EPOCH 19: training on 99524 raw words (65402 effective words) took 0.2s, 282208 effective words/s\n",
      "2023-12-06 14:43:29,563 : INFO : EPOCH 20: training on 99524 raw words (65560 effective words) took 0.2s, 279015 effective words/s\n",
      "2023-12-06 14:43:29,796 : INFO : EPOCH 21: training on 99524 raw words (65431 effective words) took 0.2s, 285805 effective words/s\n",
      "2023-12-06 14:43:30,041 : INFO : EPOCH 22: training on 99524 raw words (65300 effective words) took 0.2s, 270984 effective words/s\n",
      "2023-12-06 14:43:30,275 : INFO : EPOCH 23: training on 99524 raw words (65579 effective words) took 0.2s, 285851 effective words/s\n",
      "2023-12-06 14:43:30,519 : INFO : EPOCH 24: training on 99524 raw words (65374 effective words) took 0.2s, 272023 effective words/s\n",
      "2023-12-06 14:43:30,754 : INFO : EPOCH 25: training on 99524 raw words (65522 effective words) took 0.2s, 285816 effective words/s\n",
      "2023-12-06 14:43:30,994 : INFO : EPOCH 26: training on 99524 raw words (65352 effective words) took 0.2s, 277334 effective words/s\n",
      "2023-12-06 14:43:31,228 : INFO : EPOCH 27: training on 99524 raw words (65516 effective words) took 0.2s, 286326 effective words/s\n",
      "2023-12-06 14:43:31,470 : INFO : EPOCH 28: training on 99524 raw words (65358 effective words) took 0.2s, 274230 effective words/s\n",
      "2023-12-06 14:43:31,703 : INFO : EPOCH 29: training on 99524 raw words (65610 effective words) took 0.2s, 286934 effective words/s\n",
      "2023-12-06 14:43:31,951 : INFO : EPOCH 30: training on 99524 raw words (65563 effective words) took 0.2s, 268823 effective words/s\n",
      "2023-12-06 14:43:32,187 : INFO : EPOCH 31: training on 99524 raw words (65536 effective words) took 0.2s, 283777 effective words/s\n",
      "2023-12-06 14:43:32,436 : INFO : EPOCH 32: training on 99524 raw words (65479 effective words) took 0.2s, 268789 effective words/s\n",
      "2023-12-06 14:43:32,667 : INFO : EPOCH 33: training on 99524 raw words (65725 effective words) took 0.2s, 288645 effective words/s\n",
      "2023-12-06 14:43:32,910 : INFO : EPOCH 34: training on 99524 raw words (65410 effective words) took 0.2s, 274518 effective words/s\n",
      "2023-12-06 14:43:33,150 : INFO : EPOCH 35: training on 99524 raw words (65552 effective words) took 0.2s, 277756 effective words/s\n",
      "2023-12-06 14:43:33,384 : INFO : EPOCH 36: training on 99524 raw words (65463 effective words) took 0.2s, 286214 effective words/s\n",
      "2023-12-06 14:43:33,626 : INFO : EPOCH 37: training on 99524 raw words (65429 effective words) took 0.2s, 274345 effective words/s\n",
      "2023-12-06 14:43:33,867 : INFO : EPOCH 38: training on 99524 raw words (65530 effective words) took 0.2s, 276190 effective words/s\n",
      "2023-12-06 14:43:34,111 : INFO : EPOCH 39: training on 99524 raw words (65419 effective words) took 0.2s, 273483 effective words/s\n",
      "2023-12-06 14:43:34,347 : INFO : EPOCH 40: training on 99524 raw words (65511 effective words) took 0.2s, 281995 effective words/s\n",
      "2023-12-06 14:43:34,588 : INFO : EPOCH 41: training on 99524 raw words (65628 effective words) took 0.2s, 277893 effective words/s\n",
      "2023-12-06 14:43:34,827 : INFO : EPOCH 42: training on 99524 raw words (65701 effective words) took 0.2s, 280451 effective words/s\n",
      "2023-12-06 14:43:35,076 : INFO : EPOCH 43: training on 99524 raw words (65559 effective words) took 0.2s, 270167 effective words/s\n",
      "2023-12-06 14:43:35,321 : INFO : EPOCH 44: training on 99524 raw words (65546 effective words) took 0.2s, 272515 effective words/s\n",
      "2023-12-06 14:43:35,564 : INFO : EPOCH 45: training on 99524 raw words (65514 effective words) took 0.2s, 274449 effective words/s\n",
      "2023-12-06 14:43:35,805 : INFO : EPOCH 46: training on 99524 raw words (65543 effective words) took 0.2s, 276907 effective words/s\n",
      "2023-12-06 14:43:36,047 : INFO : EPOCH 47: training on 99524 raw words (65517 effective words) took 0.2s, 276180 effective words/s\n",
      "2023-12-06 14:43:36,282 : INFO : EPOCH 48: training on 99524 raw words (65397 effective words) took 0.2s, 281933 effective words/s\n",
      "2023-12-06 14:43:36,523 : INFO : EPOCH 49: training on 99524 raw words (65490 effective words) took 0.2s, 277391 effective words/s\n",
      "2023-12-06 14:43:36,524 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3275852 effective words) took 12.0s, 272478 effective words/s', 'datetime': '2023-12-06T14:43:36.524244', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:43:36,525 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:43:36.525244', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 40%|      | 196/486 [29:58<57:56, 11.99s/it]2023-12-06 14:43:40,321 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:43:40,322 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:43:40,342 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:43:40,343 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:43:40,351 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:43:40.351188', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:43:40,352 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:43:40.352203', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:43:40,358 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:43:40,358 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:43:40,359 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:43:40.359804', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:43:40,375 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:43:40,377 : INFO : resetting layer weights\n",
      "2023-12-06 14:43:40,381 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:43:40.381138', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:43:40,663 : INFO : EPOCH 0: training on 99524 raw words (65538 effective words) took 0.3s, 235127 effective words/s\n",
      "2023-12-06 14:43:40,913 : INFO : EPOCH 1: training on 99524 raw words (65478 effective words) took 0.2s, 266593 effective words/s\n",
      "2023-12-06 14:43:41,168 : INFO : EPOCH 2: training on 99524 raw words (65550 effective words) took 0.2s, 262348 effective words/s\n",
      "2023-12-06 14:43:41,424 : INFO : EPOCH 3: training on 99524 raw words (65466 effective words) took 0.3s, 261344 effective words/s\n",
      "2023-12-06 14:43:41,677 : INFO : EPOCH 4: training on 99524 raw words (65607 effective words) took 0.2s, 264545 effective words/s\n",
      "2023-12-06 14:43:41,929 : INFO : EPOCH 5: training on 99524 raw words (65580 effective words) took 0.2s, 264765 effective words/s\n",
      "2023-12-06 14:43:42,181 : INFO : EPOCH 6: training on 99524 raw words (65558 effective words) took 0.2s, 262846 effective words/s\n",
      "2023-12-06 14:43:42,447 : INFO : EPOCH 7: training on 99524 raw words (65556 effective words) took 0.3s, 251615 effective words/s\n",
      "2023-12-06 14:43:42,718 : INFO : EPOCH 8: training on 99524 raw words (65526 effective words) took 0.3s, 245956 effective words/s\n",
      "2023-12-06 14:43:42,985 : INFO : EPOCH 9: training on 99524 raw words (65523 effective words) took 0.3s, 249392 effective words/s\n",
      "2023-12-06 14:43:43,268 : INFO : EPOCH 10: training on 99524 raw words (65567 effective words) took 0.3s, 235954 effective words/s\n",
      "2023-12-06 14:43:43,536 : INFO : EPOCH 11: training on 99524 raw words (65669 effective words) took 0.3s, 249152 effective words/s\n",
      "2023-12-06 14:43:43,825 : INFO : EPOCH 12: training on 99524 raw words (65536 effective words) took 0.3s, 230181 effective words/s\n",
      "2023-12-06 14:43:44,101 : INFO : EPOCH 13: training on 99524 raw words (65557 effective words) took 0.3s, 240104 effective words/s\n",
      "2023-12-06 14:43:44,385 : INFO : EPOCH 14: training on 99524 raw words (65488 effective words) took 0.3s, 236638 effective words/s\n",
      "2023-12-06 14:43:44,635 : INFO : EPOCH 15: training on 99524 raw words (65490 effective words) took 0.2s, 266789 effective words/s\n",
      "2023-12-06 14:43:44,889 : INFO : EPOCH 16: training on 99524 raw words (65591 effective words) took 0.2s, 262501 effective words/s\n",
      "2023-12-06 14:43:45,156 : INFO : EPOCH 17: training on 99524 raw words (65443 effective words) took 0.3s, 250722 effective words/s\n",
      "2023-12-06 14:43:45,408 : INFO : EPOCH 18: training on 99524 raw words (65563 effective words) took 0.2s, 265317 effective words/s\n",
      "2023-12-06 14:43:45,659 : INFO : EPOCH 19: training on 99524 raw words (65598 effective words) took 0.2s, 266220 effective words/s\n",
      "2023-12-06 14:43:45,923 : INFO : EPOCH 20: training on 99524 raw words (65519 effective words) took 0.3s, 252500 effective words/s\n",
      "2023-12-06 14:43:46,185 : INFO : EPOCH 21: training on 99524 raw words (65573 effective words) took 0.3s, 257079 effective words/s\n",
      "2023-12-06 14:43:46,433 : INFO : EPOCH 22: training on 99524 raw words (65438 effective words) took 0.2s, 268520 effective words/s\n",
      "2023-12-06 14:43:46,681 : INFO : EPOCH 23: training on 99524 raw words (65579 effective words) took 0.2s, 268950 effective words/s\n",
      "2023-12-06 14:43:46,934 : INFO : EPOCH 24: training on 99524 raw words (65498 effective words) took 0.2s, 262551 effective words/s\n",
      "2023-12-06 14:43:47,183 : INFO : EPOCH 25: training on 99524 raw words (65595 effective words) took 0.2s, 268556 effective words/s\n",
      "2023-12-06 14:43:47,429 : INFO : EPOCH 26: training on 99524 raw words (65287 effective words) took 0.2s, 269882 effective words/s\n",
      "2023-12-06 14:43:47,690 : INFO : EPOCH 27: training on 99524 raw words (65664 effective words) took 0.3s, 256231 effective words/s\n",
      "2023-12-06 14:43:47,947 : INFO : EPOCH 28: training on 99524 raw words (65526 effective words) took 0.3s, 260407 effective words/s\n",
      "2023-12-06 14:43:48,213 : INFO : EPOCH 29: training on 99524 raw words (65570 effective words) took 0.3s, 252815 effective words/s\n",
      "2023-12-06 14:43:48,466 : INFO : EPOCH 30: training on 99524 raw words (65625 effective words) took 0.2s, 263477 effective words/s\n",
      "2023-12-06 14:43:48,726 : INFO : EPOCH 31: training on 99524 raw words (65430 effective words) took 0.3s, 255300 effective words/s\n",
      "2023-12-06 14:43:48,977 : INFO : EPOCH 32: training on 99524 raw words (65393 effective words) took 0.2s, 266033 effective words/s\n",
      "2023-12-06 14:43:49,227 : INFO : EPOCH 33: training on 99524 raw words (65387 effective words) took 0.2s, 265432 effective words/s\n",
      "2023-12-06 14:43:49,480 : INFO : EPOCH 34: training on 99524 raw words (65473 effective words) took 0.2s, 264638 effective words/s\n",
      "2023-12-06 14:43:49,728 : INFO : EPOCH 35: training on 99524 raw words (65593 effective words) took 0.2s, 268593 effective words/s\n",
      "2023-12-06 14:43:49,976 : INFO : EPOCH 36: training on 99524 raw words (65332 effective words) took 0.2s, 268485 effective words/s\n",
      "2023-12-06 14:43:50,226 : INFO : EPOCH 37: training on 99524 raw words (65573 effective words) took 0.2s, 267027 effective words/s\n",
      "2023-12-06 14:43:50,470 : INFO : EPOCH 38: training on 99524 raw words (65746 effective words) took 0.2s, 273412 effective words/s\n",
      "2023-12-06 14:43:50,720 : INFO : EPOCH 39: training on 99524 raw words (65415 effective words) took 0.2s, 267221 effective words/s\n",
      "2023-12-06 14:43:50,970 : INFO : EPOCH 40: training on 99524 raw words (65695 effective words) took 0.2s, 267510 effective words/s\n",
      "2023-12-06 14:43:51,212 : INFO : EPOCH 41: training on 99524 raw words (65559 effective words) took 0.2s, 276162 effective words/s\n",
      "2023-12-06 14:43:51,464 : INFO : EPOCH 42: training on 99524 raw words (65583 effective words) took 0.2s, 266320 effective words/s\n",
      "2023-12-06 14:43:51,712 : INFO : EPOCH 43: training on 99524 raw words (65566 effective words) took 0.2s, 268365 effective words/s\n",
      "2023-12-06 14:43:51,973 : INFO : EPOCH 44: training on 99524 raw words (65474 effective words) took 0.3s, 255730 effective words/s\n",
      "2023-12-06 14:43:52,221 : INFO : EPOCH 45: training on 99524 raw words (65414 effective words) took 0.2s, 268798 effective words/s\n",
      "2023-12-06 14:43:52,468 : INFO : EPOCH 46: training on 99524 raw words (65505 effective words) took 0.2s, 268575 effective words/s\n",
      "2023-12-06 14:43:52,715 : INFO : EPOCH 47: training on 99524 raw words (65655 effective words) took 0.2s, 271764 effective words/s\n",
      "2023-12-06 14:43:52,971 : INFO : EPOCH 48: training on 99524 raw words (65401 effective words) took 0.3s, 260006 effective words/s\n",
      "2023-12-06 14:43:53,216 : INFO : EPOCH 49: training on 99524 raw words (65664 effective words) took 0.2s, 273382 effective words/s\n",
      "2023-12-06 14:43:53,217 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276616 effective words) took 12.8s, 255269 effective words/s', 'datetime': '2023-12-06T14:43:53.217453', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:43:53,218 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:43:53.218483', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 41%|      | 197/486 [30:15<1:04:48, 13.45s/it]2023-12-06 14:43:57,196 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:43:57,196 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:43:57,218 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:43:57,218 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:43:57,223 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:43:57.223533', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:43:57,224 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:43:57.224535', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:43:57,230 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:43:57,231 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:43:57,231 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:43:57.231533', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:43:57,247 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:43:57,248 : INFO : resetting layer weights\n",
      "2023-12-06 14:43:57,250 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:43:57.250548', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:43:57,546 : INFO : EPOCH 0: training on 99524 raw words (65554 effective words) took 0.3s, 225684 effective words/s\n",
      "2023-12-06 14:43:57,804 : INFO : EPOCH 1: training on 99524 raw words (65405 effective words) took 0.3s, 257969 effective words/s\n",
      "2023-12-06 14:43:58,066 : INFO : EPOCH 2: training on 99524 raw words (65523 effective words) took 0.3s, 254056 effective words/s\n",
      "2023-12-06 14:43:58,323 : INFO : EPOCH 3: training on 99524 raw words (65541 effective words) took 0.3s, 258606 effective words/s\n",
      "2023-12-06 14:43:58,582 : INFO : EPOCH 4: training on 99524 raw words (65693 effective words) took 0.3s, 258555 effective words/s\n",
      "2023-12-06 14:43:58,837 : INFO : EPOCH 5: training on 99524 raw words (65566 effective words) took 0.3s, 260828 effective words/s\n",
      "2023-12-06 14:43:59,096 : INFO : EPOCH 6: training on 99524 raw words (65582 effective words) took 0.3s, 257912 effective words/s\n",
      "2023-12-06 14:43:59,352 : INFO : EPOCH 7: training on 99524 raw words (65336 effective words) took 0.3s, 259701 effective words/s\n",
      "2023-12-06 14:43:59,609 : INFO : EPOCH 8: training on 99524 raw words (65627 effective words) took 0.3s, 259860 effective words/s\n",
      "2023-12-06 14:43:59,876 : INFO : EPOCH 9: training on 99524 raw words (65353 effective words) took 0.3s, 248328 effective words/s\n",
      "2023-12-06 14:44:00,141 : INFO : EPOCH 10: training on 99524 raw words (65532 effective words) took 0.3s, 253411 effective words/s\n",
      "2023-12-06 14:44:00,402 : INFO : EPOCH 11: training on 99524 raw words (65636 effective words) took 0.3s, 256351 effective words/s\n",
      "2023-12-06 14:44:00,664 : INFO : EPOCH 12: training on 99524 raw words (65455 effective words) took 0.3s, 254743 effective words/s\n",
      "2023-12-06 14:44:00,927 : INFO : EPOCH 13: training on 99524 raw words (65363 effective words) took 0.3s, 252663 effective words/s\n",
      "2023-12-06 14:44:01,188 : INFO : EPOCH 14: training on 99524 raw words (65636 effective words) took 0.3s, 255965 effective words/s\n",
      "2023-12-06 14:44:01,446 : INFO : EPOCH 15: training on 99524 raw words (65654 effective words) took 0.3s, 259654 effective words/s\n",
      "2023-12-06 14:44:01,704 : INFO : EPOCH 16: training on 99524 raw words (65451 effective words) took 0.3s, 256780 effective words/s\n",
      "2023-12-06 14:44:01,960 : INFO : EPOCH 17: training on 99524 raw words (65396 effective words) took 0.3s, 260518 effective words/s\n",
      "2023-12-06 14:44:02,216 : INFO : EPOCH 18: training on 99524 raw words (65460 effective words) took 0.3s, 260338 effective words/s\n",
      "2023-12-06 14:44:02,471 : INFO : EPOCH 19: training on 99524 raw words (65592 effective words) took 0.3s, 262138 effective words/s\n",
      "2023-12-06 14:44:02,732 : INFO : EPOCH 20: training on 99524 raw words (65569 effective words) took 0.3s, 254621 effective words/s\n",
      "2023-12-06 14:44:02,991 : INFO : EPOCH 21: training on 99524 raw words (65704 effective words) took 0.3s, 258025 effective words/s\n",
      "2023-12-06 14:44:03,246 : INFO : EPOCH 22: training on 99524 raw words (65437 effective words) took 0.3s, 261498 effective words/s\n",
      "2023-12-06 14:44:03,502 : INFO : EPOCH 23: training on 99524 raw words (65358 effective words) took 0.3s, 259809 effective words/s\n",
      "2023-12-06 14:44:03,758 : INFO : EPOCH 24: training on 99524 raw words (65448 effective words) took 0.3s, 259729 effective words/s\n",
      "2023-12-06 14:44:04,037 : INFO : EPOCH 25: training on 99524 raw words (65567 effective words) took 0.3s, 239548 effective words/s\n",
      "2023-12-06 14:44:04,304 : INFO : EPOCH 26: training on 99524 raw words (65623 effective words) took 0.3s, 249819 effective words/s\n",
      "2023-12-06 14:44:04,574 : INFO : EPOCH 27: training on 99524 raw words (65499 effective words) took 0.3s, 247196 effective words/s\n",
      "2023-12-06 14:44:04,830 : INFO : EPOCH 28: training on 99524 raw words (65557 effective words) took 0.3s, 260381 effective words/s\n",
      "2023-12-06 14:44:05,092 : INFO : EPOCH 29: training on 99524 raw words (65381 effective words) took 0.3s, 253922 effective words/s\n",
      "2023-12-06 14:44:05,354 : INFO : EPOCH 30: training on 99524 raw words (65476 effective words) took 0.3s, 254634 effective words/s\n",
      "2023-12-06 14:44:05,612 : INFO : EPOCH 31: training on 99524 raw words (65480 effective words) took 0.3s, 258775 effective words/s\n",
      "2023-12-06 14:44:05,876 : INFO : EPOCH 32: training on 99524 raw words (65729 effective words) took 0.3s, 252231 effective words/s\n",
      "2023-12-06 14:44:06,130 : INFO : EPOCH 33: training on 99524 raw words (65459 effective words) took 0.2s, 262842 effective words/s\n",
      "2023-12-06 14:44:06,395 : INFO : EPOCH 34: training on 99524 raw words (65469 effective words) took 0.3s, 252662 effective words/s\n",
      "2023-12-06 14:44:06,653 : INFO : EPOCH 35: training on 99524 raw words (65555 effective words) took 0.3s, 258490 effective words/s\n",
      "2023-12-06 14:44:06,920 : INFO : EPOCH 36: training on 99524 raw words (65469 effective words) took 0.3s, 249396 effective words/s\n",
      "2023-12-06 14:44:07,174 : INFO : EPOCH 37: training on 99524 raw words (65518 effective words) took 0.2s, 263014 effective words/s\n",
      "2023-12-06 14:44:07,429 : INFO : EPOCH 38: training on 99524 raw words (65705 effective words) took 0.3s, 262387 effective words/s\n",
      "2023-12-06 14:44:07,685 : INFO : EPOCH 39: training on 99524 raw words (65532 effective words) took 0.3s, 260860 effective words/s\n",
      "2023-12-06 14:44:07,944 : INFO : EPOCH 40: training on 99524 raw words (65372 effective words) took 0.3s, 256946 effective words/s\n",
      "2023-12-06 14:44:08,201 : INFO : EPOCH 41: training on 99524 raw words (65456 effective words) took 0.3s, 258424 effective words/s\n",
      "2023-12-06 14:44:08,461 : INFO : EPOCH 42: training on 99524 raw words (65547 effective words) took 0.3s, 257162 effective words/s\n",
      "2023-12-06 14:44:08,719 : INFO : EPOCH 43: training on 99524 raw words (65576 effective words) took 0.3s, 258713 effective words/s\n",
      "2023-12-06 14:44:08,991 : INFO : EPOCH 44: training on 99524 raw words (65493 effective words) took 0.3s, 243833 effective words/s\n",
      "2023-12-06 14:44:09,272 : INFO : EPOCH 45: training on 99524 raw words (65641 effective words) took 0.3s, 237798 effective words/s\n",
      "2023-12-06 14:44:09,546 : INFO : EPOCH 46: training on 99524 raw words (65516 effective words) took 0.3s, 244088 effective words/s\n",
      "2023-12-06 14:44:09,806 : INFO : EPOCH 47: training on 99524 raw words (65622 effective words) took 0.3s, 256844 effective words/s\n",
      "2023-12-06 14:44:10,075 : INFO : EPOCH 48: training on 99524 raw words (65391 effective words) took 0.3s, 247498 effective words/s\n",
      "2023-12-06 14:44:10,333 : INFO : EPOCH 49: training on 99524 raw words (65456 effective words) took 0.3s, 257555 effective words/s\n",
      "2023-12-06 14:44:10,335 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3275960 effective words) took 13.1s, 250401 effective words/s', 'datetime': '2023-12-06T14:44:10.335003', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:44:10,335 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:44:10.335003', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 41%|      | 198/486 [30:33<1:10:18, 14.65s/it]2023-12-06 14:44:14,628 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:44:14,628 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:44:14,648 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:44:14,649 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:44:14,653 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:44:14.653796', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:44:14,654 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:44:14.654799', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:44:14,662 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:44:14,662 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:44:14,663 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:44:14.663796', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:44:14,671 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:44:14,671 : INFO : resetting layer weights\n",
      "2023-12-06 14:44:14,675 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:44:14.675797', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:44:14,945 : INFO : EPOCH 0: training on 99524 raw words (62691 effective words) took 0.3s, 235688 effective words/s\n",
      "2023-12-06 14:44:15,174 : INFO : EPOCH 1: training on 99524 raw words (62548 effective words) took 0.2s, 278082 effective words/s\n",
      "2023-12-06 14:44:15,410 : INFO : EPOCH 2: training on 99524 raw words (62876 effective words) took 0.2s, 272081 effective words/s\n",
      "2023-12-06 14:44:15,640 : INFO : EPOCH 3: training on 99524 raw words (62625 effective words) took 0.2s, 276654 effective words/s\n",
      "2023-12-06 14:44:15,876 : INFO : EPOCH 4: training on 99524 raw words (62781 effective words) took 0.2s, 271445 effective words/s\n",
      "2023-12-06 14:44:16,107 : INFO : EPOCH 5: training on 99524 raw words (62603 effective words) took 0.2s, 276761 effective words/s\n",
      "2023-12-06 14:44:16,342 : INFO : EPOCH 6: training on 99524 raw words (62802 effective words) took 0.2s, 272638 effective words/s\n",
      "2023-12-06 14:44:16,576 : INFO : EPOCH 7: training on 99524 raw words (62852 effective words) took 0.2s, 273290 effective words/s\n",
      "2023-12-06 14:44:16,813 : INFO : EPOCH 8: training on 99524 raw words (62808 effective words) took 0.2s, 270123 effective words/s\n",
      "2023-12-06 14:44:17,058 : INFO : EPOCH 9: training on 99524 raw words (62731 effective words) took 0.2s, 261582 effective words/s\n",
      "2023-12-06 14:44:17,059 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627317 effective words) took 2.4s, 263239 effective words/s', 'datetime': '2023-12-06T14:44:17.059154', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:44:17,059 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:44:17.059154', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 41%|      | 199/486 [30:38<56:21, 11.78s/it]  2023-12-06 14:44:19,727 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:44:19,728 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:44:19,750 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:44:19,750 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:44:19,755 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:44:19.755685', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:44:19,756 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:44:19.756685', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:44:19,761 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:44:19,761 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:44:19,762 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:44:19.762685', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:44:19,771 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:44:19,772 : INFO : resetting layer weights\n",
      "2023-12-06 14:44:19,775 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:44:19.775194', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:44:20,026 : INFO : EPOCH 0: training on 99524 raw words (62806 effective words) took 0.2s, 254579 effective words/s\n",
      "2023-12-06 14:44:20,268 : INFO : EPOCH 1: training on 99524 raw words (62681 effective words) took 0.2s, 262293 effective words/s\n",
      "2023-12-06 14:44:20,515 : INFO : EPOCH 2: training on 99524 raw words (62701 effective words) took 0.2s, 258655 effective words/s\n",
      "2023-12-06 14:44:20,758 : INFO : EPOCH 3: training on 99524 raw words (62745 effective words) took 0.2s, 264371 effective words/s\n",
      "2023-12-06 14:44:21,004 : INFO : EPOCH 4: training on 99524 raw words (62786 effective words) took 0.2s, 259305 effective words/s\n",
      "2023-12-06 14:44:21,247 : INFO : EPOCH 5: training on 99524 raw words (62760 effective words) took 0.2s, 262517 effective words/s\n",
      "2023-12-06 14:44:21,493 : INFO : EPOCH 6: training on 99524 raw words (62698 effective words) took 0.2s, 259823 effective words/s\n",
      "2023-12-06 14:44:21,740 : INFO : EPOCH 7: training on 99524 raw words (62907 effective words) took 0.2s, 258774 effective words/s\n",
      "2023-12-06 14:44:21,999 : INFO : EPOCH 8: training on 99524 raw words (62535 effective words) took 0.3s, 244666 effective words/s\n",
      "2023-12-06 14:44:22,252 : INFO : EPOCH 9: training on 99524 raw words (62883 effective words) took 0.2s, 254427 effective words/s\n",
      "2023-12-06 14:44:22,253 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627502 effective words) took 2.5s, 253173 effective words/s', 'datetime': '2023-12-06T14:44:22.253663', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:44:22,254 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:44:22.254663', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 41%|      | 200/486 [30:43<46:54,  9.84s/it]2023-12-06 14:44:25,034 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:44:25,034 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:44:25,055 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:44:25,056 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:44:25,062 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:44:25.062430', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:44:25,063 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:44:25.063430', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:44:25,071 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:44:25,071 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:44:25,072 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:44:25.072921', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:44:25,084 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:44:25,086 : INFO : resetting layer weights\n",
      "2023-12-06 14:44:25,089 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:44:25.089021', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:44:25,364 : INFO : EPOCH 0: training on 99524 raw words (62830 effective words) took 0.3s, 232173 effective words/s\n",
      "2023-12-06 14:44:25,622 : INFO : EPOCH 1: training on 99524 raw words (62741 effective words) took 0.3s, 246525 effective words/s\n",
      "2023-12-06 14:44:25,879 : INFO : EPOCH 2: training on 99524 raw words (62820 effective words) took 0.3s, 248100 effective words/s\n",
      "2023-12-06 14:44:26,142 : INFO : EPOCH 3: training on 99524 raw words (62916 effective words) took 0.3s, 244971 effective words/s\n",
      "2023-12-06 14:44:26,395 : INFO : EPOCH 4: training on 99524 raw words (62672 effective words) took 0.2s, 252104 effective words/s\n",
      "2023-12-06 14:44:26,649 : INFO : EPOCH 5: training on 99524 raw words (62721 effective words) took 0.2s, 251343 effective words/s\n",
      "2023-12-06 14:44:26,907 : INFO : EPOCH 6: training on 99524 raw words (62824 effective words) took 0.3s, 248024 effective words/s\n",
      "2023-12-06 14:44:27,167 : INFO : EPOCH 7: training on 99524 raw words (62617 effective words) took 0.3s, 244996 effective words/s\n",
      "2023-12-06 14:44:27,422 : INFO : EPOCH 8: training on 99524 raw words (62840 effective words) took 0.3s, 250550 effective words/s\n",
      "2023-12-06 14:44:27,679 : INFO : EPOCH 9: training on 99524 raw words (62797 effective words) took 0.3s, 249417 effective words/s\n",
      "2023-12-06 14:44:27,680 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627778 effective words) took 2.6s, 242344 effective words/s', 'datetime': '2023-12-06T14:44:27.680174', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:44:27,681 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:44:27.681196', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 41%|     | 201/486 [30:49<40:28,  8.52s/it]2023-12-06 14:44:30,472 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:44:30,472 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:44:30,492 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:44:30,494 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:44:30,499 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:44:30.499501', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:44:30,500 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:44:30.500506', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:44:30,506 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:44:30,506 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:44:30,507 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:44:30.507507', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:44:30,515 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:44:30,516 : INFO : resetting layer weights\n",
      "2023-12-06 14:44:30,519 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:44:30.519014', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:44:30,768 : INFO : EPOCH 0: training on 99524 raw words (62712 effective words) took 0.2s, 255901 effective words/s\n",
      "2023-12-06 14:44:31,000 : INFO : EPOCH 1: training on 99524 raw words (62743 effective words) took 0.2s, 274666 effective words/s\n",
      "2023-12-06 14:44:31,237 : INFO : EPOCH 2: training on 99524 raw words (62569 effective words) took 0.2s, 269881 effective words/s\n",
      "2023-12-06 14:44:31,466 : INFO : EPOCH 3: training on 99524 raw words (62581 effective words) took 0.2s, 277151 effective words/s\n",
      "2023-12-06 14:44:31,693 : INFO : EPOCH 4: training on 99524 raw words (62708 effective words) took 0.2s, 281621 effective words/s\n",
      "2023-12-06 14:44:31,935 : INFO : EPOCH 5: training on 99524 raw words (62638 effective words) took 0.2s, 263601 effective words/s\n",
      "2023-12-06 14:44:32,168 : INFO : EPOCH 6: training on 99524 raw words (62830 effective words) took 0.2s, 274546 effective words/s\n",
      "2023-12-06 14:44:32,406 : INFO : EPOCH 7: training on 99524 raw words (62708 effective words) took 0.2s, 269189 effective words/s\n",
      "2023-12-06 14:44:32,639 : INFO : EPOCH 8: training on 99524 raw words (62643 effective words) took 0.2s, 273630 effective words/s\n",
      "2023-12-06 14:44:32,879 : INFO : EPOCH 9: training on 99524 raw words (62840 effective words) took 0.2s, 266757 effective words/s\n",
      "2023-12-06 14:44:33,115 : INFO : EPOCH 10: training on 99524 raw words (62637 effective words) took 0.2s, 271509 effective words/s\n",
      "2023-12-06 14:44:33,348 : INFO : EPOCH 11: training on 99524 raw words (62723 effective words) took 0.2s, 274335 effective words/s\n",
      "2023-12-06 14:44:33,593 : INFO : EPOCH 12: training on 99524 raw words (62657 effective words) took 0.2s, 260392 effective words/s\n",
      "2023-12-06 14:44:33,825 : INFO : EPOCH 13: training on 99524 raw words (62832 effective words) took 0.2s, 276854 effective words/s\n",
      "2023-12-06 14:44:34,063 : INFO : EPOCH 14: training on 99524 raw words (62592 effective words) took 0.2s, 266851 effective words/s\n",
      "2023-12-06 14:44:34,294 : INFO : EPOCH 15: training on 99524 raw words (62787 effective words) took 0.2s, 277461 effective words/s\n",
      "2023-12-06 14:44:34,543 : INFO : EPOCH 16: training on 99524 raw words (62866 effective words) took 0.2s, 257027 effective words/s\n",
      "2023-12-06 14:44:34,776 : INFO : EPOCH 17: training on 99524 raw words (62681 effective words) took 0.2s, 274270 effective words/s\n",
      "2023-12-06 14:44:35,015 : INFO : EPOCH 18: training on 99524 raw words (62484 effective words) took 0.2s, 266483 effective words/s\n",
      "2023-12-06 14:44:35,252 : INFO : EPOCH 19: training on 99524 raw words (62690 effective words) took 0.2s, 268922 effective words/s\n",
      "2023-12-06 14:44:35,500 : INFO : EPOCH 20: training on 99524 raw words (62719 effective words) took 0.2s, 259587 effective words/s\n",
      "2023-12-06 14:44:35,732 : INFO : EPOCH 21: training on 99524 raw words (62704 effective words) took 0.2s, 274953 effective words/s\n",
      "2023-12-06 14:44:35,972 : INFO : EPOCH 22: training on 99524 raw words (62787 effective words) took 0.2s, 267300 effective words/s\n",
      "2023-12-06 14:44:36,207 : INFO : EPOCH 23: training on 99524 raw words (62850 effective words) took 0.2s, 272152 effective words/s\n",
      "2023-12-06 14:44:36,452 : INFO : EPOCH 24: training on 99524 raw words (62754 effective words) took 0.2s, 260138 effective words/s\n",
      "2023-12-06 14:44:36,690 : INFO : EPOCH 25: training on 99524 raw words (62947 effective words) took 0.2s, 269113 effective words/s\n",
      "2023-12-06 14:44:36,930 : INFO : EPOCH 26: training on 99524 raw words (62545 effective words) took 0.2s, 266563 effective words/s\n",
      "2023-12-06 14:44:37,167 : INFO : EPOCH 27: training on 99524 raw words (62684 effective words) took 0.2s, 269597 effective words/s\n",
      "2023-12-06 14:44:37,402 : INFO : EPOCH 28: training on 99524 raw words (62653 effective words) took 0.2s, 271931 effective words/s\n",
      "2023-12-06 14:44:37,637 : INFO : EPOCH 29: training on 99524 raw words (62639 effective words) took 0.2s, 272012 effective words/s\n",
      "2023-12-06 14:44:37,637 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881203 effective words) took 7.1s, 264268 effective words/s', 'datetime': '2023-12-06T14:44:37.637894', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:44:37,638 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:44:37.638894', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 42%|     | 202/486 [30:59<42:54,  9.07s/it]2023-12-06 14:44:40,812 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:44:40,813 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:44:40,845 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:44:40,846 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:44:40,852 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:44:40.852000', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:44:40,853 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:44:40.853000', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:44:40,861 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:44:40,862 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:44:40,862 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:44:40.862001', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:44:40,873 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:44:40,874 : INFO : resetting layer weights\n",
      "2023-12-06 14:44:40,878 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:44:40.878928', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:44:41,133 : INFO : EPOCH 0: training on 99524 raw words (62880 effective words) took 0.3s, 250925 effective words/s\n",
      "2023-12-06 14:44:41,379 : INFO : EPOCH 1: training on 99524 raw words (62809 effective words) took 0.2s, 259398 effective words/s\n",
      "2023-12-06 14:44:41,621 : INFO : EPOCH 2: training on 99524 raw words (62742 effective words) took 0.2s, 263724 effective words/s\n",
      "2023-12-06 14:44:41,862 : INFO : EPOCH 3: training on 99524 raw words (62675 effective words) took 0.2s, 265747 effective words/s\n",
      "2023-12-06 14:44:42,104 : INFO : EPOCH 4: training on 99524 raw words (62780 effective words) took 0.2s, 263905 effective words/s\n",
      "2023-12-06 14:44:42,350 : INFO : EPOCH 5: training on 99524 raw words (62719 effective words) took 0.2s, 260255 effective words/s\n",
      "2023-12-06 14:44:42,593 : INFO : EPOCH 6: training on 99524 raw words (62790 effective words) took 0.2s, 263205 effective words/s\n",
      "2023-12-06 14:44:42,838 : INFO : EPOCH 7: training on 99524 raw words (62731 effective words) took 0.2s, 260465 effective words/s\n",
      "2023-12-06 14:44:43,082 : INFO : EPOCH 8: training on 99524 raw words (62616 effective words) took 0.2s, 261126 effective words/s\n",
      "2023-12-06 14:44:43,330 : INFO : EPOCH 9: training on 99524 raw words (62657 effective words) took 0.2s, 257230 effective words/s\n",
      "2023-12-06 14:44:43,576 : INFO : EPOCH 10: training on 99524 raw words (62665 effective words) took 0.2s, 259122 effective words/s\n",
      "2023-12-06 14:44:43,822 : INFO : EPOCH 11: training on 99524 raw words (62591 effective words) took 0.2s, 259168 effective words/s\n",
      "2023-12-06 14:44:44,068 : INFO : EPOCH 12: training on 99524 raw words (62781 effective words) took 0.2s, 260396 effective words/s\n",
      "2023-12-06 14:44:44,316 : INFO : EPOCH 13: training on 99524 raw words (62757 effective words) took 0.2s, 257453 effective words/s\n",
      "2023-12-06 14:44:44,564 : INFO : EPOCH 14: training on 99524 raw words (62709 effective words) took 0.2s, 257621 effective words/s\n",
      "2023-12-06 14:44:44,808 : INFO : EPOCH 15: training on 99524 raw words (62826 effective words) took 0.2s, 262230 effective words/s\n",
      "2023-12-06 14:44:45,051 : INFO : EPOCH 16: training on 99524 raw words (62883 effective words) took 0.2s, 263165 effective words/s\n",
      "2023-12-06 14:44:45,292 : INFO : EPOCH 17: training on 99524 raw words (62676 effective words) took 0.2s, 265224 effective words/s\n",
      "2023-12-06 14:44:45,536 : INFO : EPOCH 18: training on 99524 raw words (62719 effective words) took 0.2s, 260322 effective words/s\n",
      "2023-12-06 14:44:45,778 : INFO : EPOCH 19: training on 99524 raw words (62832 effective words) took 0.2s, 264961 effective words/s\n",
      "2023-12-06 14:44:46,028 : INFO : EPOCH 20: training on 99524 raw words (62586 effective words) took 0.2s, 255922 effective words/s\n",
      "2023-12-06 14:44:46,275 : INFO : EPOCH 21: training on 99524 raw words (62686 effective words) took 0.2s, 257661 effective words/s\n",
      "2023-12-06 14:44:46,528 : INFO : EPOCH 22: training on 99524 raw words (62656 effective words) took 0.2s, 251788 effective words/s\n",
      "2023-12-06 14:44:46,771 : INFO : EPOCH 23: training on 99524 raw words (62635 effective words) took 0.2s, 261947 effective words/s\n",
      "2023-12-06 14:44:47,016 : INFO : EPOCH 24: training on 99524 raw words (62638 effective words) took 0.2s, 261206 effective words/s\n",
      "2023-12-06 14:44:47,259 : INFO : EPOCH 25: training on 99524 raw words (62704 effective words) took 0.2s, 262839 effective words/s\n",
      "2023-12-06 14:44:47,507 : INFO : EPOCH 26: training on 99524 raw words (62640 effective words) took 0.2s, 257120 effective words/s\n",
      "2023-12-06 14:44:47,752 : INFO : EPOCH 27: training on 99524 raw words (62893 effective words) took 0.2s, 260174 effective words/s\n",
      "2023-12-06 14:44:47,998 : INFO : EPOCH 28: training on 99524 raw words (62749 effective words) took 0.2s, 259634 effective words/s\n",
      "2023-12-06 14:44:48,244 : INFO : EPOCH 29: training on 99524 raw words (62764 effective words) took 0.2s, 259456 effective words/s\n",
      "2023-12-06 14:44:48,245 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881789 effective words) took 7.4s, 255449 effective words/s', 'datetime': '2023-12-06T14:44:48.245992', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:44:48,247 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:44:48.247000', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 42%|     | 203/486 [31:10<45:19,  9.61s/it]2023-12-06 14:44:51,693 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:44:51,693 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:44:51,714 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:44:51,714 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:44:51,722 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:44:51.721188', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:44:51,722 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:44:51.722639', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:44:51,728 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:44:51,728 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:44:51,729 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:44:51.729284', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:44:51,736 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:44:51,737 : INFO : resetting layer weights\n",
      "2023-12-06 14:44:51,739 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:44:51.739963', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:44:52,013 : INFO : EPOCH 0: training on 99524 raw words (62705 effective words) took 0.3s, 232894 effective words/s\n",
      "2023-12-06 14:44:52,270 : INFO : EPOCH 1: training on 99524 raw words (62594 effective words) took 0.3s, 248125 effective words/s\n",
      "2023-12-06 14:44:52,526 : INFO : EPOCH 2: training on 99524 raw words (62664 effective words) took 0.3s, 248564 effective words/s\n",
      "2023-12-06 14:44:52,779 : INFO : EPOCH 3: training on 99524 raw words (62790 effective words) took 0.2s, 252097 effective words/s\n",
      "2023-12-06 14:44:53,036 : INFO : EPOCH 4: training on 99524 raw words (62696 effective words) took 0.3s, 248135 effective words/s\n",
      "2023-12-06 14:44:53,289 : INFO : EPOCH 5: training on 99524 raw words (62582 effective words) took 0.2s, 252003 effective words/s\n",
      "2023-12-06 14:44:53,545 : INFO : EPOCH 6: training on 99524 raw words (62726 effective words) took 0.3s, 249155 effective words/s\n",
      "2023-12-06 14:44:53,802 : INFO : EPOCH 7: training on 99524 raw words (62834 effective words) took 0.3s, 249239 effective words/s\n",
      "2023-12-06 14:44:54,057 : INFO : EPOCH 8: training on 99524 raw words (62732 effective words) took 0.3s, 250490 effective words/s\n",
      "2023-12-06 14:44:54,311 : INFO : EPOCH 9: training on 99524 raw words (63033 effective words) took 0.3s, 251756 effective words/s\n",
      "2023-12-06 14:44:54,567 : INFO : EPOCH 10: training on 99524 raw words (62649 effective words) took 0.3s, 248948 effective words/s\n",
      "2023-12-06 14:44:54,829 : INFO : EPOCH 11: training on 99524 raw words (62818 effective words) took 0.3s, 244723 effective words/s\n",
      "2023-12-06 14:44:55,088 : INFO : EPOCH 12: training on 99524 raw words (62749 effective words) took 0.3s, 246565 effective words/s\n",
      "2023-12-06 14:44:55,345 : INFO : EPOCH 13: training on 99524 raw words (62730 effective words) took 0.3s, 248708 effective words/s\n",
      "2023-12-06 14:44:55,597 : INFO : EPOCH 14: training on 99524 raw words (62659 effective words) took 0.2s, 252660 effective words/s\n",
      "2023-12-06 14:44:55,850 : INFO : EPOCH 15: training on 99524 raw words (62838 effective words) took 0.2s, 252141 effective words/s\n",
      "2023-12-06 14:44:56,104 : INFO : EPOCH 16: training on 99524 raw words (62806 effective words) took 0.2s, 252676 effective words/s\n",
      "2023-12-06 14:44:56,358 : INFO : EPOCH 17: training on 99524 raw words (62711 effective words) took 0.3s, 250800 effective words/s\n",
      "2023-12-06 14:44:56,612 : INFO : EPOCH 18: training on 99524 raw words (62748 effective words) took 0.3s, 250608 effective words/s\n",
      "2023-12-06 14:44:56,869 : INFO : EPOCH 19: training on 99524 raw words (62591 effective words) took 0.3s, 249509 effective words/s\n",
      "2023-12-06 14:44:57,139 : INFO : EPOCH 20: training on 99524 raw words (62758 effective words) took 0.3s, 236389 effective words/s\n",
      "2023-12-06 14:44:57,399 : INFO : EPOCH 21: training on 99524 raw words (62877 effective words) took 0.3s, 246340 effective words/s\n",
      "2023-12-06 14:44:57,656 : INFO : EPOCH 22: training on 99524 raw words (62760 effective words) took 0.3s, 248109 effective words/s\n",
      "2023-12-06 14:44:57,918 : INFO : EPOCH 23: training on 99524 raw words (62905 effective words) took 0.3s, 244422 effective words/s\n",
      "2023-12-06 14:44:58,174 : INFO : EPOCH 24: training on 99524 raw words (62880 effective words) took 0.3s, 249882 effective words/s\n",
      "2023-12-06 14:44:58,428 : INFO : EPOCH 25: training on 99524 raw words (62708 effective words) took 0.2s, 250875 effective words/s\n",
      "2023-12-06 14:44:58,683 : INFO : EPOCH 26: training on 99524 raw words (62974 effective words) took 0.3s, 251045 effective words/s\n",
      "2023-12-06 14:44:58,939 : INFO : EPOCH 27: training on 99524 raw words (62725 effective words) took 0.3s, 250157 effective words/s\n",
      "2023-12-06 14:44:59,198 : INFO : EPOCH 28: training on 99524 raw words (62681 effective words) took 0.3s, 246226 effective words/s\n",
      "2023-12-06 14:44:59,455 : INFO : EPOCH 29: training on 99524 raw words (62760 effective words) took 0.3s, 248543 effective words/s\n",
      "2023-12-06 14:44:59,456 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1882683 effective words) took 7.7s, 244001 effective words/s', 'datetime': '2023-12-06T14:44:59.456756', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:44:59,457 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:44:59.456756', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 42%|     | 204/486 [31:21<47:34, 10.12s/it]2023-12-06 14:45:03,008 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:45:03,008 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:45:03,028 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:45:03,028 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:45:03,032 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:45:03.032924', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:45:03,033 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:45:03.033924', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:45:03,041 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:45:03,041 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:45:03,042 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:45:03.042927', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:45:03,054 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:45:03,056 : INFO : resetting layer weights\n",
      "2023-12-06 14:45:03,059 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:45:03.059689', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:45:03,316 : INFO : EPOCH 0: training on 99524 raw words (62694 effective words) took 0.3s, 248663 effective words/s\n",
      "2023-12-06 14:45:03,553 : INFO : EPOCH 1: training on 99524 raw words (62769 effective words) took 0.2s, 270213 effective words/s\n",
      "2023-12-06 14:45:03,790 : INFO : EPOCH 2: training on 99524 raw words (62831 effective words) took 0.2s, 269240 effective words/s\n",
      "2023-12-06 14:45:04,022 : INFO : EPOCH 3: training on 99524 raw words (62843 effective words) took 0.2s, 277442 effective words/s\n",
      "2023-12-06 14:45:04,257 : INFO : EPOCH 4: training on 99524 raw words (62680 effective words) took 0.2s, 272701 effective words/s\n",
      "2023-12-06 14:45:04,492 : INFO : EPOCH 5: training on 99524 raw words (62734 effective words) took 0.2s, 271644 effective words/s\n",
      "2023-12-06 14:45:04,725 : INFO : EPOCH 6: training on 99524 raw words (62834 effective words) took 0.2s, 275247 effective words/s\n",
      "2023-12-06 14:45:04,962 : INFO : EPOCH 7: training on 99524 raw words (62693 effective words) took 0.2s, 269104 effective words/s\n",
      "2023-12-06 14:45:05,208 : INFO : EPOCH 8: training on 99524 raw words (62708 effective words) took 0.2s, 258639 effective words/s\n",
      "2023-12-06 14:45:05,442 : INFO : EPOCH 9: training on 99524 raw words (62710 effective words) took 0.2s, 273458 effective words/s\n",
      "2023-12-06 14:45:05,681 : INFO : EPOCH 10: training on 99524 raw words (62572 effective words) took 0.2s, 266306 effective words/s\n",
      "2023-12-06 14:45:05,911 : INFO : EPOCH 11: training on 99524 raw words (62734 effective words) took 0.2s, 279085 effective words/s\n",
      "2023-12-06 14:45:06,155 : INFO : EPOCH 12: training on 99524 raw words (62874 effective words) took 0.2s, 262630 effective words/s\n",
      "2023-12-06 14:45:06,386 : INFO : EPOCH 13: training on 99524 raw words (62583 effective words) took 0.2s, 276862 effective words/s\n",
      "2023-12-06 14:45:06,619 : INFO : EPOCH 14: training on 99524 raw words (62744 effective words) took 0.2s, 274772 effective words/s\n",
      "2023-12-06 14:45:06,847 : INFO : EPOCH 15: training on 99524 raw words (62671 effective words) took 0.2s, 280358 effective words/s\n",
      "2023-12-06 14:45:07,081 : INFO : EPOCH 16: training on 99524 raw words (62799 effective words) took 0.2s, 274159 effective words/s\n",
      "2023-12-06 14:45:07,312 : INFO : EPOCH 17: training on 99524 raw words (62652 effective words) took 0.2s, 278107 effective words/s\n",
      "2023-12-06 14:45:07,548 : INFO : EPOCH 18: training on 99524 raw words (62669 effective words) took 0.2s, 270060 effective words/s\n",
      "2023-12-06 14:45:07,778 : INFO : EPOCH 19: training on 99524 raw words (62670 effective words) took 0.2s, 277317 effective words/s\n",
      "2023-12-06 14:45:08,015 : INFO : EPOCH 20: training on 99524 raw words (62720 effective words) took 0.2s, 270181 effective words/s\n",
      "2023-12-06 14:45:08,249 : INFO : EPOCH 21: training on 99524 raw words (62817 effective words) took 0.2s, 273796 effective words/s\n",
      "2023-12-06 14:45:08,481 : INFO : EPOCH 22: training on 99524 raw words (62863 effective words) took 0.2s, 275574 effective words/s\n",
      "2023-12-06 14:45:08,719 : INFO : EPOCH 23: training on 99524 raw words (62691 effective words) took 0.2s, 267785 effective words/s\n",
      "2023-12-06 14:45:08,966 : INFO : EPOCH 24: training on 99524 raw words (62645 effective words) took 0.2s, 259777 effective words/s\n",
      "2023-12-06 14:45:09,199 : INFO : EPOCH 25: training on 99524 raw words (62933 effective words) took 0.2s, 274744 effective words/s\n",
      "2023-12-06 14:45:09,433 : INFO : EPOCH 26: training on 99524 raw words (62749 effective words) took 0.2s, 273539 effective words/s\n",
      "2023-12-06 14:45:09,666 : INFO : EPOCH 27: training on 99524 raw words (62679 effective words) took 0.2s, 273144 effective words/s\n",
      "2023-12-06 14:45:09,901 : INFO : EPOCH 28: training on 99524 raw words (62568 effective words) took 0.2s, 271895 effective words/s\n",
      "2023-12-06 14:45:10,128 : INFO : EPOCH 29: training on 99524 raw words (62693 effective words) took 0.2s, 281324 effective words/s\n",
      "2023-12-06 14:45:10,361 : INFO : EPOCH 30: training on 99524 raw words (62675 effective words) took 0.2s, 274830 effective words/s\n",
      "2023-12-06 14:45:10,595 : INFO : EPOCH 31: training on 99524 raw words (62847 effective words) took 0.2s, 272584 effective words/s\n",
      "2023-12-06 14:45:10,828 : INFO : EPOCH 32: training on 99524 raw words (62806 effective words) took 0.2s, 275394 effective words/s\n",
      "2023-12-06 14:45:11,065 : INFO : EPOCH 33: training on 99524 raw words (62644 effective words) took 0.2s, 268926 effective words/s\n",
      "2023-12-06 14:45:11,293 : INFO : EPOCH 34: training on 99524 raw words (62487 effective words) took 0.2s, 280247 effective words/s\n",
      "2023-12-06 14:45:11,537 : INFO : EPOCH 35: training on 99524 raw words (62778 effective words) took 0.2s, 262497 effective words/s\n",
      "2023-12-06 14:45:11,768 : INFO : EPOCH 36: training on 99524 raw words (62796 effective words) took 0.2s, 277559 effective words/s\n",
      "2023-12-06 14:45:12,000 : INFO : EPOCH 37: training on 99524 raw words (62844 effective words) took 0.2s, 276035 effective words/s\n",
      "2023-12-06 14:45:12,230 : INFO : EPOCH 38: training on 99524 raw words (62688 effective words) took 0.2s, 277343 effective words/s\n",
      "2023-12-06 14:45:12,460 : INFO : EPOCH 39: training on 99524 raw words (62541 effective words) took 0.2s, 278935 effective words/s\n",
      "2023-12-06 14:45:12,693 : INFO : EPOCH 40: training on 99524 raw words (62802 effective words) took 0.2s, 274062 effective words/s\n",
      "2023-12-06 14:45:12,925 : INFO : EPOCH 41: training on 99524 raw words (62712 effective words) took 0.2s, 275046 effective words/s\n",
      "2023-12-06 14:45:13,159 : INFO : EPOCH 42: training on 99524 raw words (62685 effective words) took 0.2s, 273385 effective words/s\n",
      "2023-12-06 14:45:13,398 : INFO : EPOCH 43: training on 99524 raw words (62728 effective words) took 0.2s, 267620 effective words/s\n",
      "2023-12-06 14:45:13,636 : INFO : EPOCH 44: training on 99524 raw words (62844 effective words) took 0.2s, 268090 effective words/s\n",
      "2023-12-06 14:45:13,867 : INFO : EPOCH 45: training on 99524 raw words (62774 effective words) took 0.2s, 276658 effective words/s\n",
      "2023-12-06 14:45:14,102 : INFO : EPOCH 46: training on 99524 raw words (62677 effective words) took 0.2s, 273496 effective words/s\n",
      "2023-12-06 14:45:14,349 : INFO : EPOCH 47: training on 99524 raw words (62754 effective words) took 0.2s, 257931 effective words/s\n",
      "2023-12-06 14:45:14,584 : INFO : EPOCH 48: training on 99524 raw words (62836 effective words) took 0.2s, 272802 effective words/s\n",
      "2023-12-06 14:45:14,820 : INFO : EPOCH 49: training on 99524 raw words (62715 effective words) took 0.2s, 271423 effective words/s\n",
      "2023-12-06 14:45:14,821 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136455 effective words) took 11.8s, 266687 effective words/s', 'datetime': '2023-12-06T14:45:14.821536', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:45:14,822 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:45:14.822535', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 42%|     | 205/486 [31:37<55:03, 11.75s/it]2023-12-06 14:45:18,573 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:45:18,574 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:45:18,595 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:45:18,596 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:45:18,602 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:45:18.602627', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:45:18,603 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:45:18.603628', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:45:18,611 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:45:18,611 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:45:18,612 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:45:18.612450', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:45:18,619 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:45:18,621 : INFO : resetting layer weights\n",
      "2023-12-06 14:45:18,624 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:45:18.624610', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:45:18,881 : INFO : EPOCH 0: training on 99524 raw words (62865 effective words) took 0.3s, 247963 effective words/s\n",
      "2023-12-06 14:45:19,132 : INFO : EPOCH 1: training on 99524 raw words (62621 effective words) took 0.2s, 256854 effective words/s\n",
      "2023-12-06 14:45:19,375 : INFO : EPOCH 2: training on 99524 raw words (62456 effective words) took 0.2s, 260819 effective words/s\n",
      "2023-12-06 14:45:19,617 : INFO : EPOCH 3: training on 99524 raw words (62630 effective words) took 0.2s, 263567 effective words/s\n",
      "2023-12-06 14:45:19,860 : INFO : EPOCH 4: training on 99524 raw words (62933 effective words) took 0.2s, 263085 effective words/s\n",
      "2023-12-06 14:45:20,102 : INFO : EPOCH 5: training on 99524 raw words (62728 effective words) took 0.2s, 264015 effective words/s\n",
      "2023-12-06 14:45:20,348 : INFO : EPOCH 6: training on 99524 raw words (62709 effective words) took 0.2s, 260764 effective words/s\n",
      "2023-12-06 14:45:20,596 : INFO : EPOCH 7: training on 99524 raw words (62738 effective words) took 0.2s, 259250 effective words/s\n",
      "2023-12-06 14:45:20,838 : INFO : EPOCH 8: training on 99524 raw words (62615 effective words) took 0.2s, 262900 effective words/s\n",
      "2023-12-06 14:45:21,092 : INFO : EPOCH 9: training on 99524 raw words (62758 effective words) took 0.2s, 251131 effective words/s\n",
      "2023-12-06 14:45:21,339 : INFO : EPOCH 10: training on 99524 raw words (62794 effective words) took 0.2s, 259541 effective words/s\n",
      "2023-12-06 14:45:21,586 : INFO : EPOCH 11: training on 99524 raw words (62715 effective words) took 0.2s, 258202 effective words/s\n",
      "2023-12-06 14:45:21,843 : INFO : EPOCH 12: training on 99524 raw words (62638 effective words) took 0.3s, 247647 effective words/s\n",
      "2023-12-06 14:45:22,083 : INFO : EPOCH 13: training on 99524 raw words (62669 effective words) took 0.2s, 265645 effective words/s\n",
      "2023-12-06 14:45:22,330 : INFO : EPOCH 14: training on 99524 raw words (62802 effective words) took 0.2s, 259117 effective words/s\n",
      "2023-12-06 14:45:22,576 : INFO : EPOCH 15: training on 99524 raw words (62648 effective words) took 0.2s, 258968 effective words/s\n",
      "2023-12-06 14:45:22,821 : INFO : EPOCH 16: training on 99524 raw words (62786 effective words) took 0.2s, 261101 effective words/s\n",
      "2023-12-06 14:45:23,067 : INFO : EPOCH 17: training on 99524 raw words (62657 effective words) took 0.2s, 260239 effective words/s\n",
      "2023-12-06 14:45:23,313 : INFO : EPOCH 18: training on 99524 raw words (62616 effective words) took 0.2s, 258883 effective words/s\n",
      "2023-12-06 14:45:23,561 : INFO : EPOCH 19: training on 99524 raw words (62567 effective words) took 0.2s, 257569 effective words/s\n",
      "2023-12-06 14:45:23,806 : INFO : EPOCH 20: training on 99524 raw words (62840 effective words) took 0.2s, 260159 effective words/s\n",
      "2023-12-06 14:45:24,055 : INFO : EPOCH 21: training on 99524 raw words (62722 effective words) took 0.2s, 257086 effective words/s\n",
      "2023-12-06 14:45:24,300 : INFO : EPOCH 22: training on 99524 raw words (62698 effective words) took 0.2s, 260090 effective words/s\n",
      "2023-12-06 14:45:24,543 : INFO : EPOCH 23: training on 99524 raw words (62707 effective words) took 0.2s, 263185 effective words/s\n",
      "2023-12-06 14:45:24,793 : INFO : EPOCH 24: training on 99524 raw words (62650 effective words) took 0.2s, 255391 effective words/s\n",
      "2023-12-06 14:45:25,041 : INFO : EPOCH 25: training on 99524 raw words (62844 effective words) took 0.2s, 257784 effective words/s\n",
      "2023-12-06 14:45:25,289 : INFO : EPOCH 26: training on 99524 raw words (62699 effective words) took 0.2s, 257655 effective words/s\n",
      "2023-12-06 14:45:25,534 : INFO : EPOCH 27: training on 99524 raw words (62671 effective words) took 0.2s, 260888 effective words/s\n",
      "2023-12-06 14:45:25,776 : INFO : EPOCH 28: training on 99524 raw words (62818 effective words) took 0.2s, 263434 effective words/s\n",
      "2023-12-06 14:45:26,028 : INFO : EPOCH 29: training on 99524 raw words (62672 effective words) took 0.2s, 254135 effective words/s\n",
      "2023-12-06 14:45:26,276 : INFO : EPOCH 30: training on 99524 raw words (62612 effective words) took 0.2s, 256854 effective words/s\n",
      "2023-12-06 14:45:26,521 : INFO : EPOCH 31: training on 99524 raw words (62833 effective words) took 0.2s, 261719 effective words/s\n",
      "2023-12-06 14:45:26,775 : INFO : EPOCH 32: training on 99524 raw words (62815 effective words) took 0.2s, 251602 effective words/s\n",
      "2023-12-06 14:45:27,027 : INFO : EPOCH 33: training on 99524 raw words (62788 effective words) took 0.2s, 253466 effective words/s\n",
      "2023-12-06 14:45:27,273 : INFO : EPOCH 34: training on 99524 raw words (62632 effective words) took 0.2s, 259284 effective words/s\n",
      "2023-12-06 14:45:27,524 : INFO : EPOCH 35: training on 99524 raw words (62663 effective words) took 0.2s, 254221 effective words/s\n",
      "2023-12-06 14:45:27,764 : INFO : EPOCH 36: training on 99524 raw words (62808 effective words) took 0.2s, 267169 effective words/s\n",
      "2023-12-06 14:45:28,008 : INFO : EPOCH 37: training on 99524 raw words (62879 effective words) took 0.2s, 261742 effective words/s\n",
      "2023-12-06 14:45:28,254 : INFO : EPOCH 38: training on 99524 raw words (62663 effective words) took 0.2s, 260710 effective words/s\n",
      "2023-12-06 14:45:28,500 : INFO : EPOCH 39: training on 99524 raw words (62741 effective words) took 0.2s, 259404 effective words/s\n",
      "2023-12-06 14:45:28,749 : INFO : EPOCH 40: training on 99524 raw words (62909 effective words) took 0.2s, 257251 effective words/s\n",
      "2023-12-06 14:45:28,994 : INFO : EPOCH 41: training on 99524 raw words (62765 effective words) took 0.2s, 261730 effective words/s\n",
      "2023-12-06 14:45:29,239 : INFO : EPOCH 42: training on 99524 raw words (62798 effective words) took 0.2s, 261354 effective words/s\n",
      "2023-12-06 14:45:29,485 : INFO : EPOCH 43: training on 99524 raw words (62671 effective words) took 0.2s, 258953 effective words/s\n",
      "2023-12-06 14:45:29,736 : INFO : EPOCH 44: training on 99524 raw words (62776 effective words) took 0.2s, 253665 effective words/s\n",
      "2023-12-06 14:45:29,985 : INFO : EPOCH 45: training on 99524 raw words (62865 effective words) took 0.2s, 257244 effective words/s\n",
      "2023-12-06 14:45:30,229 : INFO : EPOCH 46: training on 99524 raw words (62745 effective words) took 0.2s, 262822 effective words/s\n",
      "2023-12-06 14:45:30,472 : INFO : EPOCH 47: training on 99524 raw words (62828 effective words) took 0.2s, 262048 effective words/s\n",
      "2023-12-06 14:45:30,719 : INFO : EPOCH 48: training on 99524 raw words (62773 effective words) took 0.2s, 259366 effective words/s\n",
      "2023-12-06 14:45:30,961 : INFO : EPOCH 49: training on 99524 raw words (62792 effective words) took 0.2s, 264310 effective words/s\n",
      "2023-12-06 14:45:30,962 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136622 effective words) took 12.3s, 254237 effective words/s', 'datetime': '2023-12-06T14:45:30.962647', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:45:30,962 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:45:30.962647', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 42%|     | 206/486 [31:53<1:01:19, 13.14s/it]2023-12-06 14:45:34,954 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:45:34,954 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:45:34,975 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:45:34,976 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:45:34,981 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:45:34.981349', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:45:34,982 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:45:34.982348', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:45:34,990 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:45:34,990 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:45:34,991 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:45:34.991909', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:45:35,003 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:45:35,004 : INFO : resetting layer weights\n",
      "2023-12-06 14:45:35,007 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:45:35.007777', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:45:35,286 : INFO : EPOCH 0: training on 99524 raw words (62672 effective words) took 0.3s, 228042 effective words/s\n",
      "2023-12-06 14:45:35,547 : INFO : EPOCH 1: training on 99524 raw words (62802 effective words) took 0.3s, 244931 effective words/s\n",
      "2023-12-06 14:45:35,804 : INFO : EPOCH 2: training on 99524 raw words (62608 effective words) took 0.3s, 248201 effective words/s\n",
      "2023-12-06 14:45:36,059 : INFO : EPOCH 3: training on 99524 raw words (62617 effective words) took 0.3s, 249840 effective words/s\n",
      "2023-12-06 14:45:36,313 : INFO : EPOCH 4: training on 99524 raw words (62460 effective words) took 0.3s, 249760 effective words/s\n",
      "2023-12-06 14:45:36,569 : INFO : EPOCH 5: training on 99524 raw words (62795 effective words) took 0.3s, 249755 effective words/s\n",
      "2023-12-06 14:45:36,824 : INFO : EPOCH 6: training on 99524 raw words (62750 effective words) took 0.3s, 250022 effective words/s\n",
      "2023-12-06 14:45:37,096 : INFO : EPOCH 7: training on 99524 raw words (62699 effective words) took 0.3s, 235064 effective words/s\n",
      "2023-12-06 14:45:37,353 : INFO : EPOCH 8: training on 99524 raw words (62712 effective words) took 0.3s, 248853 effective words/s\n",
      "2023-12-06 14:45:37,611 : INFO : EPOCH 9: training on 99524 raw words (62694 effective words) took 0.3s, 248361 effective words/s\n",
      "2023-12-06 14:45:37,867 : INFO : EPOCH 10: training on 99524 raw words (62680 effective words) took 0.3s, 248007 effective words/s\n",
      "2023-12-06 14:45:38,121 : INFO : EPOCH 11: training on 99524 raw words (62688 effective words) took 0.2s, 251247 effective words/s\n",
      "2023-12-06 14:45:38,381 : INFO : EPOCH 12: training on 99524 raw words (62735 effective words) took 0.3s, 245707 effective words/s\n",
      "2023-12-06 14:45:38,639 : INFO : EPOCH 13: training on 99524 raw words (62709 effective words) took 0.3s, 246376 effective words/s\n",
      "2023-12-06 14:45:38,896 : INFO : EPOCH 14: training on 99524 raw words (62801 effective words) took 0.3s, 249039 effective words/s\n",
      "2023-12-06 14:45:39,149 : INFO : EPOCH 15: training on 99524 raw words (62825 effective words) took 0.2s, 252917 effective words/s\n",
      "2023-12-06 14:45:39,405 : INFO : EPOCH 16: training on 99524 raw words (62815 effective words) took 0.3s, 250134 effective words/s\n",
      "2023-12-06 14:45:39,660 : INFO : EPOCH 17: training on 99524 raw words (62708 effective words) took 0.3s, 250307 effective words/s\n",
      "2023-12-06 14:45:39,917 : INFO : EPOCH 18: training on 99524 raw words (62815 effective words) took 0.3s, 249163 effective words/s\n",
      "2023-12-06 14:45:40,176 : INFO : EPOCH 19: training on 99524 raw words (62709 effective words) took 0.3s, 249560 effective words/s\n",
      "2023-12-06 14:45:40,431 : INFO : EPOCH 20: training on 99524 raw words (62654 effective words) took 0.3s, 249499 effective words/s\n",
      "2023-12-06 14:45:40,692 : INFO : EPOCH 21: training on 99524 raw words (62678 effective words) took 0.3s, 244439 effective words/s\n",
      "2023-12-06 14:45:40,948 : INFO : EPOCH 22: training on 99524 raw words (62701 effective words) took 0.3s, 249520 effective words/s\n",
      "2023-12-06 14:45:41,202 : INFO : EPOCH 23: training on 99524 raw words (62708 effective words) took 0.2s, 251354 effective words/s\n",
      "2023-12-06 14:45:41,456 : INFO : EPOCH 24: training on 99524 raw words (62750 effective words) took 0.2s, 251532 effective words/s\n",
      "2023-12-06 14:45:41,711 : INFO : EPOCH 25: training on 99524 raw words (62720 effective words) took 0.3s, 249462 effective words/s\n",
      "2023-12-06 14:45:41,968 : INFO : EPOCH 26: training on 99524 raw words (62598 effective words) took 0.3s, 248074 effective words/s\n",
      "2023-12-06 14:45:42,220 : INFO : EPOCH 27: training on 99524 raw words (62701 effective words) took 0.2s, 253546 effective words/s\n",
      "2023-12-06 14:45:42,477 : INFO : EPOCH 28: training on 99524 raw words (62777 effective words) took 0.3s, 248231 effective words/s\n",
      "2023-12-06 14:45:42,732 : INFO : EPOCH 29: training on 99524 raw words (62727 effective words) took 0.2s, 251163 effective words/s\n",
      "2023-12-06 14:45:42,993 : INFO : EPOCH 30: training on 99524 raw words (62791 effective words) took 0.3s, 244200 effective words/s\n",
      "2023-12-06 14:45:43,247 : INFO : EPOCH 31: training on 99524 raw words (62795 effective words) took 0.2s, 252489 effective words/s\n",
      "2023-12-06 14:45:43,504 : INFO : EPOCH 32: training on 99524 raw words (62675 effective words) took 0.3s, 248394 effective words/s\n",
      "2023-12-06 14:45:43,759 : INFO : EPOCH 33: training on 99524 raw words (62813 effective words) took 0.3s, 249392 effective words/s\n",
      "2023-12-06 14:45:44,014 : INFO : EPOCH 34: training on 99524 raw words (62812 effective words) took 0.3s, 250486 effective words/s\n",
      "2023-12-06 14:45:44,269 : INFO : EPOCH 35: training on 99524 raw words (62620 effective words) took 0.2s, 251440 effective words/s\n",
      "2023-12-06 14:45:44,524 : INFO : EPOCH 36: training on 99524 raw words (62830 effective words) took 0.3s, 249732 effective words/s\n",
      "2023-12-06 14:45:44,783 : INFO : EPOCH 37: training on 99524 raw words (62736 effective words) took 0.3s, 246505 effective words/s\n",
      "2023-12-06 14:45:45,039 : INFO : EPOCH 38: training on 99524 raw words (62679 effective words) took 0.3s, 250675 effective words/s\n",
      "2023-12-06 14:45:45,294 : INFO : EPOCH 39: training on 99524 raw words (62826 effective words) took 0.3s, 249512 effective words/s\n",
      "2023-12-06 14:45:45,552 : INFO : EPOCH 40: training on 99524 raw words (62726 effective words) took 0.3s, 247816 effective words/s\n",
      "2023-12-06 14:45:45,806 : INFO : EPOCH 41: training on 99524 raw words (62724 effective words) took 0.3s, 250610 effective words/s\n",
      "2023-12-06 14:45:46,065 : INFO : EPOCH 42: training on 99524 raw words (62740 effective words) took 0.3s, 246820 effective words/s\n",
      "2023-12-06 14:45:46,323 : INFO : EPOCH 43: training on 99524 raw words (62635 effective words) took 0.3s, 246584 effective words/s\n",
      "2023-12-06 14:45:46,579 : INFO : EPOCH 44: training on 99524 raw words (62833 effective words) took 0.3s, 250222 effective words/s\n",
      "2023-12-06 14:45:46,832 : INFO : EPOCH 45: training on 99524 raw words (62865 effective words) took 0.2s, 252973 effective words/s\n",
      "2023-12-06 14:45:47,089 : INFO : EPOCH 46: training on 99524 raw words (62580 effective words) took 0.3s, 247816 effective words/s\n",
      "2023-12-06 14:45:47,344 : INFO : EPOCH 47: training on 99524 raw words (62829 effective words) took 0.3s, 250878 effective words/s\n",
      "2023-12-06 14:45:47,601 : INFO : EPOCH 48: training on 99524 raw words (62602 effective words) took 0.3s, 249152 effective words/s\n",
      "2023-12-06 14:45:47,858 : INFO : EPOCH 49: training on 99524 raw words (62761 effective words) took 0.3s, 248033 effective words/s\n",
      "2023-12-06 14:45:47,858 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136180 effective words) took 12.9s, 244057 effective words/s', 'datetime': '2023-12-06T14:45:47.858439', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:45:47,859 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:45:47.859439', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 43%|     | 207/486 [32:10<1:06:43, 14.35s/it]2023-12-06 14:45:52,115 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:45:52,116 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:45:52,135 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:45:52,136 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:45:52,142 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:45:52.142573', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:45:52,143 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:45:52.143576', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:45:52,148 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:45:52,148 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:45:52,149 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:45:52.149574', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:45:52,155 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:45:52,156 : INFO : resetting layer weights\n",
      "2023-12-06 14:45:52,159 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:45:52.159575', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:45:52,404 : INFO : EPOCH 0: training on 99524 raw words (60409 effective words) took 0.2s, 251490 effective words/s\n",
      "2023-12-06 14:45:52,646 : INFO : EPOCH 1: training on 99524 raw words (60397 effective words) took 0.2s, 257301 effective words/s\n",
      "2023-12-06 14:45:52,883 : INFO : EPOCH 2: training on 99524 raw words (60515 effective words) took 0.2s, 259472 effective words/s\n",
      "2023-12-06 14:45:53,123 : INFO : EPOCH 3: training on 99524 raw words (60410 effective words) took 0.2s, 256137 effective words/s\n",
      "2023-12-06 14:45:53,356 : INFO : EPOCH 4: training on 99524 raw words (60453 effective words) took 0.2s, 264633 effective words/s\n",
      "2023-12-06 14:45:53,589 : INFO : EPOCH 5: training on 99524 raw words (60206 effective words) took 0.2s, 263497 effective words/s\n",
      "2023-12-06 14:45:53,823 : INFO : EPOCH 6: training on 99524 raw words (60447 effective words) took 0.2s, 263722 effective words/s\n",
      "2023-12-06 14:45:54,056 : INFO : EPOCH 7: training on 99524 raw words (60382 effective words) took 0.2s, 265062 effective words/s\n",
      "2023-12-06 14:45:54,293 : INFO : EPOCH 8: training on 99524 raw words (60478 effective words) took 0.2s, 258913 effective words/s\n",
      "2023-12-06 14:45:54,537 : INFO : EPOCH 9: training on 99524 raw words (60448 effective words) took 0.2s, 252888 effective words/s\n",
      "2023-12-06 14:45:54,538 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604145 effective words) took 2.4s, 254046 effective words/s', 'datetime': '2023-12-06T14:45:54.538701', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:45:54,538 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:45:54.538701', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 43%|     | 208/486 [32:15<53:38, 11.58s/it]  2023-12-06 14:45:57,229 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:45:57,230 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:45:57,254 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:45:57,255 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:45:57,259 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:45:57.259993', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:45:57,259 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:45:57.259993', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:45:57,264 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:45:57,265 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:45:57,265 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:45:57.265986', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:45:57,274 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:45:57,274 : INFO : resetting layer weights\n",
      "2023-12-06 14:45:57,277 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:45:57.277177', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:45:57,534 : INFO : EPOCH 0: training on 99524 raw words (60395 effective words) took 0.3s, 238398 effective words/s\n",
      "2023-12-06 14:45:57,777 : INFO : EPOCH 1: training on 99524 raw words (60440 effective words) took 0.2s, 252696 effective words/s\n",
      "2023-12-06 14:45:58,021 : INFO : EPOCH 2: training on 99524 raw words (60338 effective words) took 0.2s, 251824 effective words/s\n",
      "2023-12-06 14:45:58,258 : INFO : EPOCH 3: training on 99524 raw words (60510 effective words) took 0.2s, 260014 effective words/s\n",
      "2023-12-06 14:45:58,499 : INFO : EPOCH 4: training on 99524 raw words (60371 effective words) took 0.2s, 255657 effective words/s\n",
      "2023-12-06 14:45:58,742 : INFO : EPOCH 5: training on 99524 raw words (60545 effective words) took 0.2s, 254058 effective words/s\n",
      "2023-12-06 14:45:58,980 : INFO : EPOCH 6: training on 99524 raw words (60489 effective words) took 0.2s, 257976 effective words/s\n",
      "2023-12-06 14:45:59,222 : INFO : EPOCH 7: training on 99524 raw words (60543 effective words) took 0.2s, 254868 effective words/s\n",
      "2023-12-06 14:45:59,464 : INFO : EPOCH 8: training on 99524 raw words (60514 effective words) took 0.2s, 254804 effective words/s\n",
      "2023-12-06 14:45:59,705 : INFO : EPOCH 9: training on 99524 raw words (60410 effective words) took 0.2s, 255389 effective words/s\n",
      "2023-12-06 14:45:59,706 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604555 effective words) took 2.4s, 248886 effective words/s', 'datetime': '2023-12-06T14:45:59.706040', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:45:59,707 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:45:59.707041', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 43%|     | 209/486 [32:21<44:46,  9.70s/it]2023-12-06 14:46:02,541 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:46:02,542 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:46:02,565 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:46:02,566 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:46:02,570 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:46:02.570276', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:46:02,570 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:46:02.570276', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:46:02,574 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:46:02,577 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:46:02,577 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:46:02.577005', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:46:02,587 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:46:02,588 : INFO : resetting layer weights\n",
      "2023-12-06 14:46:02,590 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:46:02.590005', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:46:02,853 : INFO : EPOCH 0: training on 99524 raw words (60487 effective words) took 0.3s, 233291 effective words/s\n",
      "2023-12-06 14:46:03,109 : INFO : EPOCH 1: training on 99524 raw words (60469 effective words) took 0.3s, 240769 effective words/s\n",
      "2023-12-06 14:46:03,359 : INFO : EPOCH 2: training on 99524 raw words (60169 effective words) took 0.2s, 244774 effective words/s\n",
      "2023-12-06 14:46:03,612 : INFO : EPOCH 3: training on 99524 raw words (60368 effective words) took 0.2s, 243089 effective words/s\n",
      "2023-12-06 14:46:03,865 : INFO : EPOCH 4: training on 99524 raw words (60493 effective words) took 0.2s, 242730 effective words/s\n",
      "2023-12-06 14:46:04,118 : INFO : EPOCH 5: training on 99524 raw words (60228 effective words) took 0.2s, 242179 effective words/s\n",
      "2023-12-06 14:46:04,370 : INFO : EPOCH 6: training on 99524 raw words (60441 effective words) took 0.2s, 244938 effective words/s\n",
      "2023-12-06 14:46:04,625 : INFO : EPOCH 7: training on 99524 raw words (60298 effective words) took 0.3s, 240225 effective words/s\n",
      "2023-12-06 14:46:04,882 : INFO : EPOCH 8: training on 99524 raw words (60227 effective words) took 0.3s, 238728 effective words/s\n",
      "2023-12-06 14:46:05,139 : INFO : EPOCH 9: training on 99524 raw words (60358 effective words) took 0.3s, 238385 effective words/s\n",
      "2023-12-06 14:46:05,140 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603538 effective words) took 2.5s, 236690 effective words/s', 'datetime': '2023-12-06T14:46:05.140814', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:46:05,141 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:46:05.141812', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 43%|     | 210/486 [32:26<38:42,  8.41s/it]2023-12-06 14:46:07,955 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:46:07,956 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:46:07,976 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:46:07,977 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:46:07,984 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:46:07.984378', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:46:07,986 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:46:07.986379', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:46:07,993 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:46:07,994 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:46:07,995 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:46:07.995378', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:46:08,005 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:46:08,005 : INFO : resetting layer weights\n",
      "2023-12-06 14:46:08,008 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:46:08.008885', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:46:08,253 : INFO : EPOCH 0: training on 99524 raw words (60381 effective words) took 0.2s, 252606 effective words/s\n",
      "2023-12-06 14:46:08,484 : INFO : EPOCH 1: training on 99524 raw words (60481 effective words) took 0.2s, 266476 effective words/s\n",
      "2023-12-06 14:46:08,718 : INFO : EPOCH 2: training on 99524 raw words (60477 effective words) took 0.2s, 263272 effective words/s\n",
      "2023-12-06 14:46:08,949 : INFO : EPOCH 3: training on 99524 raw words (60453 effective words) took 0.2s, 267030 effective words/s\n",
      "2023-12-06 14:46:09,197 : INFO : EPOCH 4: training on 99524 raw words (60304 effective words) took 0.2s, 248858 effective words/s\n",
      "2023-12-06 14:46:09,430 : INFO : EPOCH 5: training on 99524 raw words (60394 effective words) took 0.2s, 265052 effective words/s\n",
      "2023-12-06 14:46:09,665 : INFO : EPOCH 6: training on 99524 raw words (60510 effective words) took 0.2s, 261544 effective words/s\n",
      "2023-12-06 14:46:09,895 : INFO : EPOCH 7: training on 99524 raw words (60445 effective words) took 0.2s, 268087 effective words/s\n",
      "2023-12-06 14:46:10,132 : INFO : EPOCH 8: training on 99524 raw words (60544 effective words) took 0.2s, 260372 effective words/s\n",
      "2023-12-06 14:46:10,364 : INFO : EPOCH 9: training on 99524 raw words (60238 effective words) took 0.2s, 264880 effective words/s\n",
      "2023-12-06 14:46:10,604 : INFO : EPOCH 10: training on 99524 raw words (60423 effective words) took 0.2s, 257404 effective words/s\n",
      "2023-12-06 14:46:10,842 : INFO : EPOCH 11: training on 99524 raw words (60229 effective words) took 0.2s, 256497 effective words/s\n",
      "2023-12-06 14:46:11,085 : INFO : EPOCH 12: training on 99524 raw words (60300 effective words) took 0.2s, 253619 effective words/s\n",
      "2023-12-06 14:46:11,321 : INFO : EPOCH 13: training on 99524 raw words (60302 effective words) took 0.2s, 260954 effective words/s\n",
      "2023-12-06 14:46:11,555 : INFO : EPOCH 14: training on 99524 raw words (60456 effective words) took 0.2s, 263034 effective words/s\n",
      "2023-12-06 14:46:11,791 : INFO : EPOCH 15: training on 99524 raw words (60375 effective words) took 0.2s, 260410 effective words/s\n",
      "2023-12-06 14:46:12,026 : INFO : EPOCH 16: training on 99524 raw words (60249 effective words) took 0.2s, 261136 effective words/s\n",
      "2023-12-06 14:46:12,261 : INFO : EPOCH 17: training on 99524 raw words (60369 effective words) took 0.2s, 261890 effective words/s\n",
      "2023-12-06 14:46:12,497 : INFO : EPOCH 18: training on 99524 raw words (60362 effective words) took 0.2s, 261884 effective words/s\n",
      "2023-12-06 14:46:12,735 : INFO : EPOCH 19: training on 99524 raw words (60409 effective words) took 0.2s, 257912 effective words/s\n",
      "2023-12-06 14:46:12,974 : INFO : EPOCH 20: training on 99524 raw words (60487 effective words) took 0.2s, 258302 effective words/s\n",
      "2023-12-06 14:46:13,208 : INFO : EPOCH 21: training on 99524 raw words (60263 effective words) took 0.2s, 261850 effective words/s\n",
      "2023-12-06 14:46:13,436 : INFO : EPOCH 22: training on 99524 raw words (60477 effective words) took 0.2s, 271603 effective words/s\n",
      "2023-12-06 14:46:13,669 : INFO : EPOCH 23: training on 99524 raw words (60271 effective words) took 0.2s, 263165 effective words/s\n",
      "2023-12-06 14:46:13,896 : INFO : EPOCH 24: training on 99524 raw words (60360 effective words) took 0.2s, 271341 effective words/s\n",
      "2023-12-06 14:46:14,128 : INFO : EPOCH 25: training on 99524 raw words (60547 effective words) took 0.2s, 266103 effective words/s\n",
      "2023-12-06 14:46:14,362 : INFO : EPOCH 26: training on 99524 raw words (60552 effective words) took 0.2s, 263190 effective words/s\n",
      "2023-12-06 14:46:14,601 : INFO : EPOCH 27: training on 99524 raw words (60585 effective words) took 0.2s, 258603 effective words/s\n",
      "2023-12-06 14:46:14,844 : INFO : EPOCH 28: training on 99524 raw words (60227 effective words) took 0.2s, 252611 effective words/s\n",
      "2023-12-06 14:46:15,081 : INFO : EPOCH 29: training on 99524 raw words (60310 effective words) took 0.2s, 258540 effective words/s\n",
      "2023-12-06 14:46:15,082 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811780 effective words) took 7.1s, 256141 effective words/s', 'datetime': '2023-12-06T14:46:15.082802', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:46:15,082 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:46:15.082802', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 43%|     | 211/486 [32:36<41:14,  9.00s/it]2023-12-06 14:46:18,317 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:46:18,318 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:46:18,338 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:46:18,339 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:46:18,343 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:46:18.343567', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:46:18,343 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:46:18.343567', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:46:18,348 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:46:18,349 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:46:18,350 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:46:18.350194', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:46:18,356 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:46:18,357 : INFO : resetting layer weights\n",
      "2023-12-06 14:46:18,360 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:46:18.360705', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:46:18,605 : INFO : EPOCH 0: training on 99524 raw words (60463 effective words) took 0.2s, 250899 effective words/s\n",
      "2023-12-06 14:46:18,855 : INFO : EPOCH 1: training on 99524 raw words (60379 effective words) took 0.2s, 247354 effective words/s\n",
      "2023-12-06 14:46:19,092 : INFO : EPOCH 2: training on 99524 raw words (60232 effective words) took 0.2s, 258382 effective words/s\n",
      "2023-12-06 14:46:19,333 : INFO : EPOCH 3: training on 99524 raw words (60320 effective words) took 0.2s, 255768 effective words/s\n",
      "2023-12-06 14:46:19,571 : INFO : EPOCH 4: training on 99524 raw words (60282 effective words) took 0.2s, 258006 effective words/s\n",
      "2023-12-06 14:46:19,810 : INFO : EPOCH 5: training on 99524 raw words (60282 effective words) took 0.2s, 257657 effective words/s\n",
      "2023-12-06 14:46:20,052 : INFO : EPOCH 6: training on 99524 raw words (60255 effective words) took 0.2s, 253496 effective words/s\n",
      "2023-12-06 14:46:20,292 : INFO : EPOCH 7: training on 99524 raw words (60565 effective words) took 0.2s, 256814 effective words/s\n",
      "2023-12-06 14:46:20,535 : INFO : EPOCH 8: training on 99524 raw words (60455 effective words) took 0.2s, 253814 effective words/s\n",
      "2023-12-06 14:46:20,778 : INFO : EPOCH 9: training on 99524 raw words (60482 effective words) took 0.2s, 253734 effective words/s\n",
      "2023-12-06 14:46:21,020 : INFO : EPOCH 10: training on 99524 raw words (60272 effective words) took 0.2s, 253762 effective words/s\n",
      "2023-12-06 14:46:21,260 : INFO : EPOCH 11: training on 99524 raw words (60429 effective words) took 0.2s, 256876 effective words/s\n",
      "2023-12-06 14:46:21,505 : INFO : EPOCH 12: training on 99524 raw words (60317 effective words) took 0.2s, 249793 effective words/s\n",
      "2023-12-06 14:46:21,746 : INFO : EPOCH 13: training on 99524 raw words (60349 effective words) took 0.2s, 255504 effective words/s\n",
      "2023-12-06 14:46:21,990 : INFO : EPOCH 14: training on 99524 raw words (60283 effective words) took 0.2s, 251829 effective words/s\n",
      "2023-12-06 14:46:22,236 : INFO : EPOCH 15: training on 99524 raw words (60316 effective words) took 0.2s, 250453 effective words/s\n",
      "2023-12-06 14:46:22,476 : INFO : EPOCH 16: training on 99524 raw words (60560 effective words) took 0.2s, 256213 effective words/s\n",
      "2023-12-06 14:46:22,720 : INFO : EPOCH 17: training on 99524 raw words (60459 effective words) took 0.2s, 253043 effective words/s\n",
      "2023-12-06 14:46:22,966 : INFO : EPOCH 18: training on 99524 raw words (60505 effective words) took 0.2s, 249927 effective words/s\n",
      "2023-12-06 14:46:23,203 : INFO : EPOCH 19: training on 99524 raw words (60287 effective words) took 0.2s, 259712 effective words/s\n",
      "2023-12-06 14:46:23,442 : INFO : EPOCH 20: training on 99524 raw words (60609 effective words) took 0.2s, 257854 effective words/s\n",
      "2023-12-06 14:46:23,686 : INFO : EPOCH 21: training on 99524 raw words (60455 effective words) took 0.2s, 252096 effective words/s\n",
      "2023-12-06 14:46:23,928 : INFO : EPOCH 22: training on 99524 raw words (60458 effective words) took 0.2s, 254904 effective words/s\n",
      "2023-12-06 14:46:24,169 : INFO : EPOCH 23: training on 99524 raw words (60353 effective words) took 0.2s, 254877 effective words/s\n",
      "2023-12-06 14:46:24,415 : INFO : EPOCH 24: training on 99524 raw words (60347 effective words) took 0.2s, 249458 effective words/s\n",
      "2023-12-06 14:46:24,656 : INFO : EPOCH 25: training on 99524 raw words (60526 effective words) took 0.2s, 255756 effective words/s\n",
      "2023-12-06 14:46:24,898 : INFO : EPOCH 26: training on 99524 raw words (60511 effective words) took 0.2s, 255444 effective words/s\n",
      "2023-12-06 14:46:25,153 : INFO : EPOCH 27: training on 99524 raw words (60451 effective words) took 0.3s, 240686 effective words/s\n",
      "2023-12-06 14:46:25,401 : INFO : EPOCH 28: training on 99524 raw words (60347 effective words) took 0.2s, 247612 effective words/s\n",
      "2023-12-06 14:46:25,646 : INFO : EPOCH 29: training on 99524 raw words (60259 effective words) took 0.2s, 250470 effective words/s\n",
      "2023-12-06 14:46:25,647 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811808 effective words) took 7.3s, 248635 effective words/s', 'datetime': '2023-12-06T14:46:25.647937', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:46:25,648 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:46:25.648937', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 44%|     | 212/486 [32:47<43:29,  9.52s/it]2023-12-06 14:46:29,066 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:46:29,067 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:46:29,096 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:46:29,097 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:46:29,102 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:46:29.102660', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:46:29,102 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:46:29.102660', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:46:29,107 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:46:29,108 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:46:29,109 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:46:29.109730', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:46:29,117 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:46:29,118 : INFO : resetting layer weights\n",
      "2023-12-06 14:46:29,122 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:46:29.122439', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:46:29,415 : INFO : EPOCH 0: training on 99524 raw words (60424 effective words) took 0.3s, 209553 effective words/s\n",
      "2023-12-06 14:46:29,680 : INFO : EPOCH 1: training on 99524 raw words (60626 effective words) took 0.3s, 232829 effective words/s\n",
      "2023-12-06 14:46:29,953 : INFO : EPOCH 2: training on 99524 raw words (60416 effective words) took 0.3s, 225879 effective words/s\n",
      "2023-12-06 14:46:30,205 : INFO : EPOCH 3: training on 99524 raw words (60337 effective words) took 0.2s, 243316 effective words/s\n",
      "2023-12-06 14:46:30,464 : INFO : EPOCH 4: training on 99524 raw words (60546 effective words) took 0.3s, 238101 effective words/s\n",
      "2023-12-06 14:46:30,723 : INFO : EPOCH 5: training on 99524 raw words (60288 effective words) took 0.3s, 236816 effective words/s\n",
      "2023-12-06 14:46:30,985 : INFO : EPOCH 6: training on 99524 raw words (60417 effective words) took 0.3s, 235285 effective words/s\n",
      "2023-12-06 14:46:31,246 : INFO : EPOCH 7: training on 99524 raw words (60358 effective words) took 0.3s, 235562 effective words/s\n",
      "2023-12-06 14:46:31,498 : INFO : EPOCH 8: training on 99524 raw words (60449 effective words) took 0.2s, 244519 effective words/s\n",
      "2023-12-06 14:46:31,756 : INFO : EPOCH 9: training on 99524 raw words (60349 effective words) took 0.3s, 237303 effective words/s\n",
      "2023-12-06 14:46:32,029 : INFO : EPOCH 10: training on 99524 raw words (60433 effective words) took 0.3s, 226788 effective words/s\n",
      "2023-12-06 14:46:32,288 : INFO : EPOCH 11: training on 99524 raw words (60376 effective words) took 0.3s, 236317 effective words/s\n",
      "2023-12-06 14:46:32,568 : INFO : EPOCH 12: training on 99524 raw words (60451 effective words) took 0.3s, 222066 effective words/s\n",
      "2023-12-06 14:46:32,833 : INFO : EPOCH 13: training on 99524 raw words (60292 effective words) took 0.3s, 231732 effective words/s\n",
      "2023-12-06 14:46:33,117 : INFO : EPOCH 14: training on 99524 raw words (60277 effective words) took 0.3s, 215050 effective words/s\n",
      "2023-12-06 14:46:33,375 : INFO : EPOCH 15: training on 99524 raw words (60372 effective words) took 0.3s, 238324 effective words/s\n",
      "2023-12-06 14:46:33,661 : INFO : EPOCH 16: training on 99524 raw words (60460 effective words) took 0.3s, 214940 effective words/s\n",
      "2023-12-06 14:46:33,951 : INFO : EPOCH 17: training on 99524 raw words (60342 effective words) took 0.3s, 211092 effective words/s\n",
      "2023-12-06 14:46:34,215 : INFO : EPOCH 18: training on 99524 raw words (60126 effective words) took 0.3s, 234151 effective words/s\n",
      "2023-12-06 14:46:34,466 : INFO : EPOCH 19: training on 99524 raw words (60366 effective words) took 0.2s, 243633 effective words/s\n",
      "2023-12-06 14:46:34,722 : INFO : EPOCH 20: training on 99524 raw words (60437 effective words) took 0.3s, 240793 effective words/s\n",
      "2023-12-06 14:46:34,980 : INFO : EPOCH 21: training on 99524 raw words (60371 effective words) took 0.3s, 237241 effective words/s\n",
      "2023-12-06 14:46:35,243 : INFO : EPOCH 22: training on 99524 raw words (60234 effective words) took 0.3s, 234009 effective words/s\n",
      "2023-12-06 14:46:35,500 : INFO : EPOCH 23: training on 99524 raw words (60439 effective words) took 0.3s, 239153 effective words/s\n",
      "2023-12-06 14:46:35,756 : INFO : EPOCH 24: training on 99524 raw words (60253 effective words) took 0.3s, 239386 effective words/s\n",
      "2023-12-06 14:46:36,013 : INFO : EPOCH 25: training on 99524 raw words (60360 effective words) took 0.3s, 239735 effective words/s\n",
      "2023-12-06 14:46:36,293 : INFO : EPOCH 26: training on 99524 raw words (60349 effective words) took 0.3s, 219354 effective words/s\n",
      "2023-12-06 14:46:36,560 : INFO : EPOCH 27: training on 99524 raw words (60391 effective words) took 0.3s, 230721 effective words/s\n",
      "2023-12-06 14:46:36,845 : INFO : EPOCH 28: training on 99524 raw words (60612 effective words) took 0.3s, 215848 effective words/s\n",
      "2023-12-06 14:46:37,115 : INFO : EPOCH 29: training on 99524 raw words (60434 effective words) took 0.3s, 227779 effective words/s\n",
      "2023-12-06 14:46:37,116 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811585 effective words) took 8.0s, 226631 effective words/s', 'datetime': '2023-12-06T14:46:37.116713', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:46:37,116 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:46:37.116713', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 44%|     | 213/486 [32:59<46:15, 10.17s/it]2023-12-06 14:46:40,737 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:46:40,738 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:46:40,763 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:46:40,764 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:46:40,771 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:46:40.771431', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:46:40,771 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:46:40.771431', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:46:40,778 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:46:40,778 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:46:40,779 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:46:40.779431', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:46:40,788 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:46:40,788 : INFO : resetting layer weights\n",
      "2023-12-06 14:46:40,791 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:46:40.791939', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:46:41,058 : INFO : EPOCH 0: training on 99524 raw words (60252 effective words) took 0.3s, 229334 effective words/s\n",
      "2023-12-06 14:46:41,310 : INFO : EPOCH 1: training on 99524 raw words (60644 effective words) took 0.2s, 246594 effective words/s\n",
      "2023-12-06 14:46:41,572 : INFO : EPOCH 2: training on 99524 raw words (60563 effective words) took 0.3s, 236686 effective words/s\n",
      "2023-12-06 14:46:41,813 : INFO : EPOCH 3: training on 99524 raw words (60386 effective words) took 0.2s, 254798 effective words/s\n",
      "2023-12-06 14:46:42,067 : INFO : EPOCH 4: training on 99524 raw words (60492 effective words) took 0.3s, 241798 effective words/s\n",
      "2023-12-06 14:46:42,322 : INFO : EPOCH 5: training on 99524 raw words (60378 effective words) took 0.2s, 241777 effective words/s\n",
      "2023-12-06 14:46:42,556 : INFO : EPOCH 6: training on 99524 raw words (60274 effective words) took 0.2s, 263039 effective words/s\n",
      "2023-12-06 14:46:42,811 : INFO : EPOCH 7: training on 99524 raw words (60502 effective words) took 0.3s, 241148 effective words/s\n",
      "2023-12-06 14:46:43,051 : INFO : EPOCH 8: training on 99524 raw words (60336 effective words) took 0.2s, 258370 effective words/s\n",
      "2023-12-06 14:46:43,285 : INFO : EPOCH 9: training on 99524 raw words (60368 effective words) took 0.2s, 261406 effective words/s\n",
      "2023-12-06 14:46:43,515 : INFO : EPOCH 10: training on 99524 raw words (60405 effective words) took 0.2s, 267370 effective words/s\n",
      "2023-12-06 14:46:43,758 : INFO : EPOCH 11: training on 99524 raw words (60425 effective words) took 0.2s, 254696 effective words/s\n",
      "2023-12-06 14:46:43,987 : INFO : EPOCH 12: training on 99524 raw words (60449 effective words) took 0.2s, 267945 effective words/s\n",
      "2023-12-06 14:46:44,239 : INFO : EPOCH 13: training on 99524 raw words (60338 effective words) took 0.2s, 244246 effective words/s\n",
      "2023-12-06 14:46:44,494 : INFO : EPOCH 14: training on 99524 raw words (60572 effective words) took 0.3s, 241894 effective words/s\n",
      "2023-12-06 14:46:44,732 : INFO : EPOCH 15: training on 99524 raw words (60257 effective words) took 0.2s, 259210 effective words/s\n",
      "2023-12-06 14:46:44,969 : INFO : EPOCH 16: training on 99524 raw words (60607 effective words) took 0.2s, 259761 effective words/s\n",
      "2023-12-06 14:46:45,224 : INFO : EPOCH 17: training on 99524 raw words (60526 effective words) took 0.2s, 242377 effective words/s\n",
      "2023-12-06 14:46:45,467 : INFO : EPOCH 18: training on 99524 raw words (60273 effective words) took 0.2s, 252801 effective words/s\n",
      "2023-12-06 14:46:45,713 : INFO : EPOCH 19: training on 99524 raw words (60273 effective words) took 0.2s, 250044 effective words/s\n",
      "2023-12-06 14:46:45,950 : INFO : EPOCH 20: training on 99524 raw words (60525 effective words) took 0.2s, 259647 effective words/s\n",
      "2023-12-06 14:46:46,185 : INFO : EPOCH 21: training on 99524 raw words (60363 effective words) took 0.2s, 261875 effective words/s\n",
      "2023-12-06 14:46:46,445 : INFO : EPOCH 22: training on 99524 raw words (60432 effective words) took 0.3s, 236869 effective words/s\n",
      "2023-12-06 14:46:46,692 : INFO : EPOCH 23: training on 99524 raw words (60277 effective words) took 0.2s, 250245 effective words/s\n",
      "2023-12-06 14:46:46,926 : INFO : EPOCH 24: training on 99524 raw words (60349 effective words) took 0.2s, 262640 effective words/s\n",
      "2023-12-06 14:46:47,163 : INFO : EPOCH 25: training on 99524 raw words (60339 effective words) took 0.2s, 259303 effective words/s\n",
      "2023-12-06 14:46:47,395 : INFO : EPOCH 26: training on 99524 raw words (60395 effective words) took 0.2s, 265259 effective words/s\n",
      "2023-12-06 14:46:47,649 : INFO : EPOCH 27: training on 99524 raw words (60507 effective words) took 0.2s, 243592 effective words/s\n",
      "2023-12-06 14:46:47,884 : INFO : EPOCH 28: training on 99524 raw words (60333 effective words) took 0.2s, 262172 effective words/s\n",
      "2023-12-06 14:46:48,123 : INFO : EPOCH 29: training on 99524 raw words (60460 effective words) took 0.2s, 257106 effective words/s\n",
      "2023-12-06 14:46:48,353 : INFO : EPOCH 30: training on 99524 raw words (60267 effective words) took 0.2s, 268503 effective words/s\n",
      "2023-12-06 14:46:48,586 : INFO : EPOCH 31: training on 99524 raw words (60412 effective words) took 0.2s, 264339 effective words/s\n",
      "2023-12-06 14:46:48,831 : INFO : EPOCH 32: training on 99524 raw words (60410 effective words) took 0.2s, 251119 effective words/s\n",
      "2023-12-06 14:46:49,124 : INFO : EPOCH 33: training on 99524 raw words (60253 effective words) took 0.3s, 208630 effective words/s\n",
      "2023-12-06 14:46:49,404 : INFO : EPOCH 34: training on 99524 raw words (60258 effective words) took 0.3s, 220028 effective words/s\n",
      "2023-12-06 14:46:49,655 : INFO : EPOCH 35: training on 99524 raw words (60387 effective words) took 0.2s, 243965 effective words/s\n",
      "2023-12-06 14:46:49,894 : INFO : EPOCH 36: training on 99524 raw words (60341 effective words) took 0.2s, 256670 effective words/s\n",
      "2023-12-06 14:46:50,144 : INFO : EPOCH 37: training on 99524 raw words (60242 effective words) took 0.2s, 247320 effective words/s\n",
      "2023-12-06 14:46:50,393 : INFO : EPOCH 38: training on 99524 raw words (60465 effective words) took 0.2s, 246824 effective words/s\n",
      "2023-12-06 14:46:50,644 : INFO : EPOCH 39: training on 99524 raw words (60613 effective words) took 0.2s, 246499 effective words/s\n",
      "2023-12-06 14:46:50,912 : INFO : EPOCH 40: training on 99524 raw words (60447 effective words) took 0.3s, 230407 effective words/s\n",
      "2023-12-06 14:46:51,175 : INFO : EPOCH 41: training on 99524 raw words (60199 effective words) took 0.3s, 234545 effective words/s\n",
      "2023-12-06 14:46:51,446 : INFO : EPOCH 42: training on 99524 raw words (60396 effective words) took 0.3s, 229054 effective words/s\n",
      "2023-12-06 14:46:51,690 : INFO : EPOCH 43: training on 99524 raw words (60400 effective words) took 0.2s, 254961 effective words/s\n",
      "2023-12-06 14:46:51,928 : INFO : EPOCH 44: training on 99524 raw words (60483 effective words) took 0.2s, 259670 effective words/s\n",
      "2023-12-06 14:46:52,166 : INFO : EPOCH 45: training on 99524 raw words (60242 effective words) took 0.2s, 257101 effective words/s\n",
      "2023-12-06 14:46:52,413 : INFO : EPOCH 46: training on 99524 raw words (60486 effective words) took 0.2s, 250394 effective words/s\n",
      "2023-12-06 14:46:52,648 : INFO : EPOCH 47: training on 99524 raw words (60291 effective words) took 0.2s, 262036 effective words/s\n",
      "2023-12-06 14:46:52,888 : INFO : EPOCH 48: training on 99524 raw words (60280 effective words) took 0.2s, 254614 effective words/s\n",
      "2023-12-06 14:46:53,115 : INFO : EPOCH 49: training on 99524 raw words (60272 effective words) took 0.2s, 271285 effective words/s\n",
      "2023-12-06 14:46:53,116 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3019444 effective words) took 12.3s, 244994 effective words/s', 'datetime': '2023-12-06T14:46:53.116614', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:46:53,117 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:46:53.117617', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 44%|     | 214/486 [33:15<54:07, 11.94s/it]2023-12-06 14:46:56,814 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:46:56,814 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:46:56,835 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:46:56,836 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:46:56,841 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:46:56.841025', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:46:56,842 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:46:56.842024', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:46:56,846 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:46:56,846 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:46:56,847 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:46:56.847534', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:46:56,853 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:46:56,854 : INFO : resetting layer weights\n",
      "2023-12-06 14:46:56,856 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:46:56.856638', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:46:57,129 : INFO : EPOCH 0: training on 99524 raw words (60533 effective words) took 0.3s, 225399 effective words/s\n",
      "2023-12-06 14:46:57,376 : INFO : EPOCH 1: training on 99524 raw words (60567 effective words) took 0.2s, 249742 effective words/s\n",
      "2023-12-06 14:46:57,615 : INFO : EPOCH 2: training on 99524 raw words (60349 effective words) took 0.2s, 258314 effective words/s\n",
      "2023-12-06 14:46:57,860 : INFO : EPOCH 3: training on 99524 raw words (60480 effective words) took 0.2s, 251214 effective words/s\n",
      "2023-12-06 14:46:58,098 : INFO : EPOCH 4: training on 99524 raw words (60568 effective words) took 0.2s, 258759 effective words/s\n",
      "2023-12-06 14:46:58,341 : INFO : EPOCH 5: training on 99524 raw words (60385 effective words) took 0.2s, 253584 effective words/s\n",
      "2023-12-06 14:46:58,589 : INFO : EPOCH 6: training on 99524 raw words (60512 effective words) took 0.2s, 247916 effective words/s\n",
      "2023-12-06 14:46:58,836 : INFO : EPOCH 7: training on 99524 raw words (60471 effective words) took 0.2s, 249541 effective words/s\n",
      "2023-12-06 14:46:59,075 : INFO : EPOCH 8: training on 99524 raw words (60357 effective words) took 0.2s, 257241 effective words/s\n",
      "2023-12-06 14:46:59,329 : INFO : EPOCH 9: training on 99524 raw words (60316 effective words) took 0.2s, 241758 effective words/s\n",
      "2023-12-06 14:46:59,569 : INFO : EPOCH 10: training on 99524 raw words (60344 effective words) took 0.2s, 256399 effective words/s\n",
      "2023-12-06 14:46:59,811 : INFO : EPOCH 11: training on 99524 raw words (60456 effective words) took 0.2s, 254935 effective words/s\n",
      "2023-12-06 14:47:00,058 : INFO : EPOCH 12: training on 99524 raw words (60407 effective words) took 0.2s, 249209 effective words/s\n",
      "2023-12-06 14:47:00,307 : INFO : EPOCH 13: training on 99524 raw words (60355 effective words) took 0.2s, 247273 effective words/s\n",
      "2023-12-06 14:47:00,560 : INFO : EPOCH 14: training on 99524 raw words (60526 effective words) took 0.2s, 244236 effective words/s\n",
      "2023-12-06 14:47:00,802 : INFO : EPOCH 15: training on 99524 raw words (60368 effective words) took 0.2s, 254291 effective words/s\n",
      "2023-12-06 14:47:01,043 : INFO : EPOCH 16: training on 99524 raw words (60308 effective words) took 0.2s, 254806 effective words/s\n",
      "2023-12-06 14:47:01,284 : INFO : EPOCH 17: training on 99524 raw words (60494 effective words) took 0.2s, 255316 effective words/s\n",
      "2023-12-06 14:47:01,532 : INFO : EPOCH 18: training on 99524 raw words (60353 effective words) took 0.2s, 247949 effective words/s\n",
      "2023-12-06 14:47:01,778 : INFO : EPOCH 19: training on 99524 raw words (60364 effective words) took 0.2s, 250824 effective words/s\n",
      "2023-12-06 14:47:02,028 : INFO : EPOCH 20: training on 99524 raw words (60288 effective words) took 0.2s, 245603 effective words/s\n",
      "2023-12-06 14:47:02,269 : INFO : EPOCH 21: training on 99524 raw words (60395 effective words) took 0.2s, 254791 effective words/s\n",
      "2023-12-06 14:47:02,513 : INFO : EPOCH 22: training on 99524 raw words (60360 effective words) took 0.2s, 251659 effective words/s\n",
      "2023-12-06 14:47:02,748 : INFO : EPOCH 23: training on 99524 raw words (60496 effective words) took 0.2s, 261968 effective words/s\n",
      "2023-12-06 14:47:02,992 : INFO : EPOCH 24: training on 99524 raw words (60353 effective words) took 0.2s, 252673 effective words/s\n",
      "2023-12-06 14:47:03,237 : INFO : EPOCH 25: training on 99524 raw words (60431 effective words) took 0.2s, 249817 effective words/s\n",
      "2023-12-06 14:47:03,479 : INFO : EPOCH 26: training on 99524 raw words (60390 effective words) took 0.2s, 255526 effective words/s\n",
      "2023-12-06 14:47:03,716 : INFO : EPOCH 27: training on 99524 raw words (60291 effective words) took 0.2s, 258679 effective words/s\n",
      "2023-12-06 14:47:03,960 : INFO : EPOCH 28: training on 99524 raw words (60426 effective words) took 0.2s, 252377 effective words/s\n",
      "2023-12-06 14:47:04,199 : INFO : EPOCH 29: training on 99524 raw words (60258 effective words) took 0.2s, 257204 effective words/s\n",
      "2023-12-06 14:47:04,443 : INFO : EPOCH 30: training on 99524 raw words (60144 effective words) took 0.2s, 250619 effective words/s\n",
      "2023-12-06 14:47:04,688 : INFO : EPOCH 31: training on 99524 raw words (60432 effective words) took 0.2s, 251382 effective words/s\n",
      "2023-12-06 14:47:04,929 : INFO : EPOCH 32: training on 99524 raw words (60421 effective words) took 0.2s, 255377 effective words/s\n",
      "2023-12-06 14:47:05,185 : INFO : EPOCH 33: training on 99524 raw words (60357 effective words) took 0.3s, 239468 effective words/s\n",
      "2023-12-06 14:47:05,439 : INFO : EPOCH 34: training on 99524 raw words (60324 effective words) took 0.2s, 241808 effective words/s\n",
      "2023-12-06 14:47:05,688 : INFO : EPOCH 35: training on 99524 raw words (60337 effective words) took 0.2s, 247766 effective words/s\n",
      "2023-12-06 14:47:05,932 : INFO : EPOCH 36: training on 99524 raw words (60505 effective words) took 0.2s, 251963 effective words/s\n",
      "2023-12-06 14:47:06,172 : INFO : EPOCH 37: training on 99524 raw words (60331 effective words) took 0.2s, 256292 effective words/s\n",
      "2023-12-06 14:47:06,418 : INFO : EPOCH 38: training on 99524 raw words (60342 effective words) took 0.2s, 249774 effective words/s\n",
      "2023-12-06 14:47:06,663 : INFO : EPOCH 39: training on 99524 raw words (60415 effective words) took 0.2s, 251095 effective words/s\n",
      "2023-12-06 14:47:06,905 : INFO : EPOCH 40: training on 99524 raw words (60237 effective words) took 0.2s, 253072 effective words/s\n",
      "2023-12-06 14:47:07,148 : INFO : EPOCH 41: training on 99524 raw words (60495 effective words) took 0.2s, 254028 effective words/s\n",
      "2023-12-06 14:47:07,398 : INFO : EPOCH 42: training on 99524 raw words (60401 effective words) took 0.2s, 246590 effective words/s\n",
      "2023-12-06 14:47:07,641 : INFO : EPOCH 43: training on 99524 raw words (60316 effective words) took 0.2s, 252094 effective words/s\n",
      "2023-12-06 14:47:07,892 : INFO : EPOCH 44: training on 99524 raw words (60323 effective words) took 0.2s, 245828 effective words/s\n",
      "2023-12-06 14:47:08,137 : INFO : EPOCH 45: training on 99524 raw words (60357 effective words) took 0.2s, 250490 effective words/s\n",
      "2023-12-06 14:47:08,380 : INFO : EPOCH 46: training on 99524 raw words (60459 effective words) took 0.2s, 253182 effective words/s\n",
      "2023-12-06 14:47:08,625 : INFO : EPOCH 47: training on 99524 raw words (60473 effective words) took 0.2s, 251598 effective words/s\n",
      "2023-12-06 14:47:08,876 : INFO : EPOCH 48: training on 99524 raw words (60373 effective words) took 0.2s, 246166 effective words/s\n",
      "2023-12-06 14:47:09,116 : INFO : EPOCH 49: training on 99524 raw words (60406 effective words) took 0.2s, 255443 effective words/s\n",
      "2023-12-06 14:47:09,116 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3019649 effective words) took 12.3s, 246304 effective words/s', 'datetime': '2023-12-06T14:47:09.116993', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:47:09,118 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:47:09.118276', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 44%|     | 215/486 [33:31<59:45, 13.23s/it]2023-12-06 14:47:13,059 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:47:13,060 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:47:13,080 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:47:13,082 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:47:13,087 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:47:13.087687', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:47:13,088 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:47:13.088693', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:47:13,094 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:47:13,095 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:47:13,095 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:47:13.095558', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:47:13,102 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:47:13,103 : INFO : resetting layer weights\n",
      "2023-12-06 14:47:13,106 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:47:13.106002', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:47:13,386 : INFO : EPOCH 0: training on 99524 raw words (60266 effective words) took 0.3s, 218223 effective words/s\n",
      "2023-12-06 14:47:13,655 : INFO : EPOCH 1: training on 99524 raw words (60281 effective words) took 0.3s, 229023 effective words/s\n",
      "2023-12-06 14:47:13,908 : INFO : EPOCH 2: training on 99524 raw words (60237 effective words) took 0.2s, 241359 effective words/s\n",
      "2023-12-06 14:47:14,165 : INFO : EPOCH 3: training on 99524 raw words (60262 effective words) took 0.3s, 239692 effective words/s\n",
      "2023-12-06 14:47:14,412 : INFO : EPOCH 4: training on 99524 raw words (60256 effective words) took 0.2s, 247955 effective words/s\n",
      "2023-12-06 14:47:14,668 : INFO : EPOCH 5: training on 99524 raw words (60541 effective words) took 0.3s, 240152 effective words/s\n",
      "2023-12-06 14:47:14,919 : INFO : EPOCH 6: training on 99524 raw words (60282 effective words) took 0.2s, 244001 effective words/s\n",
      "2023-12-06 14:47:15,175 : INFO : EPOCH 7: training on 99524 raw words (60382 effective words) took 0.3s, 241154 effective words/s\n",
      "2023-12-06 14:47:15,426 : INFO : EPOCH 8: training on 99524 raw words (60360 effective words) took 0.2s, 244212 effective words/s\n",
      "2023-12-06 14:47:15,687 : INFO : EPOCH 9: training on 99524 raw words (60457 effective words) took 0.3s, 236644 effective words/s\n",
      "2023-12-06 14:47:15,947 : INFO : EPOCH 10: training on 99524 raw words (60367 effective words) took 0.3s, 236612 effective words/s\n",
      "2023-12-06 14:47:16,203 : INFO : EPOCH 11: training on 99524 raw words (60291 effective words) took 0.3s, 239493 effective words/s\n",
      "2023-12-06 14:47:16,459 : INFO : EPOCH 12: training on 99524 raw words (60320 effective words) took 0.3s, 240084 effective words/s\n",
      "2023-12-06 14:47:16,713 : INFO : EPOCH 13: training on 99524 raw words (60520 effective words) took 0.2s, 242333 effective words/s\n",
      "2023-12-06 14:47:16,969 : INFO : EPOCH 14: training on 99524 raw words (60420 effective words) took 0.3s, 240747 effective words/s\n",
      "2023-12-06 14:47:17,222 : INFO : EPOCH 15: training on 99524 raw words (60377 effective words) took 0.2s, 242587 effective words/s\n",
      "2023-12-06 14:47:17,479 : INFO : EPOCH 16: training on 99524 raw words (60415 effective words) took 0.3s, 239446 effective words/s\n",
      "2023-12-06 14:47:17,731 : INFO : EPOCH 17: training on 99524 raw words (60420 effective words) took 0.2s, 243379 effective words/s\n",
      "2023-12-06 14:47:17,984 : INFO : EPOCH 18: training on 99524 raw words (60388 effective words) took 0.2s, 244064 effective words/s\n",
      "2023-12-06 14:47:18,233 : INFO : EPOCH 19: training on 99524 raw words (60371 effective words) took 0.2s, 245891 effective words/s\n",
      "2023-12-06 14:47:18,493 : INFO : EPOCH 20: training on 99524 raw words (60454 effective words) took 0.3s, 237725 effective words/s\n",
      "2023-12-06 14:47:18,747 : INFO : EPOCH 21: training on 99524 raw words (60476 effective words) took 0.2s, 242783 effective words/s\n",
      "2023-12-06 14:47:19,001 : INFO : EPOCH 22: training on 99524 raw words (60417 effective words) took 0.3s, 240591 effective words/s\n",
      "2023-12-06 14:47:19,255 : INFO : EPOCH 23: training on 99524 raw words (60431 effective words) took 0.2s, 243327 effective words/s\n",
      "2023-12-06 14:47:19,503 : INFO : EPOCH 24: training on 99524 raw words (60314 effective words) took 0.2s, 247257 effective words/s\n",
      "2023-12-06 14:47:19,759 : INFO : EPOCH 25: training on 99524 raw words (60405 effective words) took 0.3s, 239528 effective words/s\n",
      "2023-12-06 14:47:20,018 : INFO : EPOCH 26: training on 99524 raw words (60345 effective words) took 0.3s, 238450 effective words/s\n",
      "2023-12-06 14:47:20,273 : INFO : EPOCH 27: training on 99524 raw words (60516 effective words) took 0.3s, 241103 effective words/s\n",
      "2023-12-06 14:47:20,527 : INFO : EPOCH 28: training on 99524 raw words (60453 effective words) took 0.2s, 241938 effective words/s\n",
      "2023-12-06 14:47:20,780 : INFO : EPOCH 29: training on 99524 raw words (60494 effective words) took 0.2s, 242300 effective words/s\n",
      "2023-12-06 14:47:21,035 : INFO : EPOCH 30: training on 99524 raw words (60357 effective words) took 0.2s, 242167 effective words/s\n",
      "2023-12-06 14:47:21,307 : INFO : EPOCH 31: training on 99524 raw words (60525 effective words) took 0.3s, 227035 effective words/s\n",
      "2023-12-06 14:47:21,572 : INFO : EPOCH 32: training on 99524 raw words (60377 effective words) took 0.3s, 231780 effective words/s\n",
      "2023-12-06 14:47:21,835 : INFO : EPOCH 33: training on 99524 raw words (60335 effective words) took 0.3s, 233946 effective words/s\n",
      "2023-12-06 14:47:22,082 : INFO : EPOCH 34: training on 99524 raw words (60385 effective words) took 0.2s, 247881 effective words/s\n",
      "2023-12-06 14:47:22,345 : INFO : EPOCH 35: training on 99524 raw words (60396 effective words) took 0.3s, 235219 effective words/s\n",
      "2023-12-06 14:47:22,595 : INFO : EPOCH 36: training on 99524 raw words (60417 effective words) took 0.2s, 245968 effective words/s\n",
      "2023-12-06 14:47:22,853 : INFO : EPOCH 37: training on 99524 raw words (60364 effective words) took 0.3s, 239290 effective words/s\n",
      "2023-12-06 14:47:23,110 : INFO : EPOCH 38: training on 99524 raw words (60635 effective words) took 0.3s, 239781 effective words/s\n",
      "2023-12-06 14:47:23,359 : INFO : EPOCH 39: training on 99524 raw words (60325 effective words) took 0.2s, 246543 effective words/s\n",
      "2023-12-06 14:47:23,617 : INFO : EPOCH 40: training on 99524 raw words (60271 effective words) took 0.3s, 237976 effective words/s\n",
      "2023-12-06 14:47:23,868 : INFO : EPOCH 41: training on 99524 raw words (60299 effective words) took 0.2s, 244215 effective words/s\n",
      "2023-12-06 14:47:24,123 : INFO : EPOCH 42: training on 99524 raw words (60274 effective words) took 0.3s, 240890 effective words/s\n",
      "2023-12-06 14:47:24,379 : INFO : EPOCH 43: training on 99524 raw words (60165 effective words) took 0.3s, 239061 effective words/s\n",
      "2023-12-06 14:47:24,634 : INFO : EPOCH 44: training on 99524 raw words (60669 effective words) took 0.3s, 242149 effective words/s\n",
      "2023-12-06 14:47:24,884 : INFO : EPOCH 45: training on 99524 raw words (60493 effective words) took 0.2s, 246280 effective words/s\n",
      "2023-12-06 14:47:25,139 : INFO : EPOCH 46: training on 99524 raw words (60386 effective words) took 0.3s, 241310 effective words/s\n",
      "2023-12-06 14:47:25,393 : INFO : EPOCH 47: training on 99524 raw words (60393 effective words) took 0.3s, 241367 effective words/s\n",
      "2023-12-06 14:47:25,649 : INFO : EPOCH 48: training on 99524 raw words (60454 effective words) took 0.3s, 240859 effective words/s\n",
      "2023-12-06 14:47:25,900 : INFO : EPOCH 49: training on 99524 raw words (60422 effective words) took 0.2s, 244620 effective words/s\n",
      "2023-12-06 14:47:25,901 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3019460 effective words) took 12.8s, 235987 effective words/s', 'datetime': '2023-12-06T14:47:25.901162', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:47:25,902 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:47:25.902290', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 44%|     | 216/486 [33:48<1:04:46, 14.39s/it]2023-12-06 14:47:30,161 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:47:30,163 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:47:30,187 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:47:30,188 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:47:30,193 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:47:30.193725', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:47:30,193 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:47:30.193725', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:47:30,203 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:47:30,204 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:47:30,205 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:47:30.205038', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:47:30,220 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:47:30,220 : INFO : resetting layer weights\n",
      "2023-12-06 14:47:30,225 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:47:30.225110', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:47:30,504 : INFO : EPOCH 0: training on 99524 raw words (65652 effective words) took 0.3s, 238871 effective words/s\n",
      "2023-12-06 14:47:30,750 : INFO : EPOCH 1: training on 99524 raw words (65476 effective words) took 0.2s, 275224 effective words/s\n",
      "2023-12-06 14:47:30,988 : INFO : EPOCH 2: training on 99524 raw words (65580 effective words) took 0.2s, 280291 effective words/s\n",
      "2023-12-06 14:47:31,225 : INFO : EPOCH 3: training on 99524 raw words (65497 effective words) took 0.2s, 281738 effective words/s\n",
      "2023-12-06 14:47:31,460 : INFO : EPOCH 4: training on 99524 raw words (65571 effective words) took 0.2s, 285166 effective words/s\n",
      "2023-12-06 14:47:31,698 : INFO : EPOCH 5: training on 99524 raw words (65596 effective words) took 0.2s, 279522 effective words/s\n",
      "2023-12-06 14:47:31,936 : INFO : EPOCH 6: training on 99524 raw words (65331 effective words) took 0.2s, 281133 effective words/s\n",
      "2023-12-06 14:47:32,174 : INFO : EPOCH 7: training on 99524 raw words (65407 effective words) took 0.2s, 278073 effective words/s\n",
      "2023-12-06 14:47:32,415 : INFO : EPOCH 8: training on 99524 raw words (65590 effective words) took 0.2s, 277909 effective words/s\n",
      "2023-12-06 14:47:32,654 : INFO : EPOCH 9: training on 99524 raw words (65433 effective words) took 0.2s, 278451 effective words/s\n",
      "2023-12-06 14:47:32,655 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655133 effective words) took 2.4s, 269629 effective words/s', 'datetime': '2023-12-06T14:47:32.655396', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:47:32,656 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:47:32.656396', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 45%|     | 217/486 [33:53<52:07, 11.63s/it]  2023-12-06 14:47:35,332 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:47:35,332 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:47:35,353 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:47:35,354 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:47:35,359 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:47:35.359390', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:47:35,360 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:47:35.360390', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:47:35,367 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:47:35,368 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:47:35,368 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:47:35.368393', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:47:35,378 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:47:35,379 : INFO : resetting layer weights\n",
      "2023-12-06 14:47:35,381 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:47:35.381690', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:47:35,646 : INFO : EPOCH 0: training on 99524 raw words (65629 effective words) took 0.3s, 252905 effective words/s\n",
      "2023-12-06 14:47:35,898 : INFO : EPOCH 1: training on 99524 raw words (65576 effective words) took 0.2s, 264666 effective words/s\n",
      "2023-12-06 14:47:36,152 : INFO : EPOCH 2: training on 99524 raw words (65413 effective words) took 0.2s, 261799 effective words/s\n",
      "2023-12-06 14:47:36,396 : INFO : EPOCH 3: training on 99524 raw words (65401 effective words) took 0.2s, 273505 effective words/s\n",
      "2023-12-06 14:47:36,645 : INFO : EPOCH 4: training on 99524 raw words (65676 effective words) took 0.2s, 268139 effective words/s\n",
      "2023-12-06 14:47:36,892 : INFO : EPOCH 5: training on 99524 raw words (65410 effective words) took 0.2s, 270689 effective words/s\n",
      "2023-12-06 14:47:37,160 : INFO : EPOCH 6: training on 99524 raw words (65378 effective words) took 0.3s, 247638 effective words/s\n",
      "2023-12-06 14:47:37,414 : INFO : EPOCH 7: training on 99524 raw words (65566 effective words) took 0.2s, 262513 effective words/s\n",
      "2023-12-06 14:47:37,673 : INFO : EPOCH 8: training on 99524 raw words (65501 effective words) took 0.3s, 257318 effective words/s\n",
      "2023-12-06 14:47:37,930 : INFO : EPOCH 9: training on 99524 raw words (65522 effective words) took 0.3s, 259004 effective words/s\n",
      "2023-12-06 14:47:37,931 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655072 effective words) took 2.5s, 256963 effective words/s', 'datetime': '2023-12-06T14:47:37.931895', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:47:37,932 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:47:37.932896', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 45%|     | 218/486 [33:59<43:34,  9.75s/it]2023-12-06 14:47:40,717 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:47:40,718 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:47:40,737 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:47:40,738 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:47:40,747 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:47:40.747049', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:47:40,748 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:47:40.748051', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:47:40,755 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:47:40,755 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:47:40,756 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:47:40.756499', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:47:40,766 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:47:40,767 : INFO : resetting layer weights\n",
      "2023-12-06 14:47:40,770 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:47:40.770943', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:47:41,076 : INFO : EPOCH 0: training on 99524 raw words (65517 effective words) took 0.3s, 218075 effective words/s\n",
      "2023-12-06 14:47:41,345 : INFO : EPOCH 1: training on 99524 raw words (65499 effective words) took 0.3s, 249585 effective words/s\n",
      "2023-12-06 14:47:41,603 : INFO : EPOCH 2: training on 99524 raw words (65727 effective words) took 0.3s, 258835 effective words/s\n",
      "2023-12-06 14:47:41,863 : INFO : EPOCH 3: training on 99524 raw words (65571 effective words) took 0.3s, 257175 effective words/s\n",
      "2023-12-06 14:47:42,120 : INFO : EPOCH 4: training on 99524 raw words (65426 effective words) took 0.3s, 258404 effective words/s\n",
      "2023-12-06 14:47:42,379 : INFO : EPOCH 5: training on 99524 raw words (65558 effective words) took 0.3s, 257259 effective words/s\n",
      "2023-12-06 14:47:42,641 : INFO : EPOCH 6: training on 99524 raw words (65555 effective words) took 0.3s, 254051 effective words/s\n",
      "2023-12-06 14:47:42,902 : INFO : EPOCH 7: training on 99524 raw words (65350 effective words) took 0.3s, 255057 effective words/s\n",
      "2023-12-06 14:47:43,169 : INFO : EPOCH 8: training on 99524 raw words (65599 effective words) took 0.3s, 249611 effective words/s\n",
      "2023-12-06 14:47:43,430 : INFO : EPOCH 9: training on 99524 raw words (65511 effective words) took 0.3s, 255362 effective words/s\n",
      "2023-12-06 14:47:43,431 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655313 effective words) took 2.7s, 246356 effective words/s', 'datetime': '2023-12-06T14:47:43.431932', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:47:43,431 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:47:43.431932', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 45%|     | 219/486 [34:04<37:54,  8.52s/it]2023-12-06 14:47:46,725 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:47:46,726 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:47:46,747 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:47:46,748 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:47:46,756 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:47:46.756496', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:47:46,756 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:47:46.756496', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:47:46,766 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:47:46,767 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:47:46,768 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:47:46.768024', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:47:46,786 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:47:46,787 : INFO : resetting layer weights\n",
      "2023-12-06 14:47:46,790 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:47:46.790024', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:47:47,058 : INFO : EPOCH 0: training on 99524 raw words (65423 effective words) took 0.3s, 250193 effective words/s\n",
      "2023-12-06 14:47:47,292 : INFO : EPOCH 1: training on 99524 raw words (65408 effective words) took 0.2s, 284472 effective words/s\n",
      "2023-12-06 14:47:47,532 : INFO : EPOCH 2: training on 99524 raw words (65608 effective words) took 0.2s, 279651 effective words/s\n",
      "2023-12-06 14:47:47,766 : INFO : EPOCH 3: training on 99524 raw words (65551 effective words) took 0.2s, 284736 effective words/s\n",
      "2023-12-06 14:47:48,003 : INFO : EPOCH 4: training on 99524 raw words (65440 effective words) took 0.2s, 280921 effective words/s\n",
      "2023-12-06 14:47:48,239 : INFO : EPOCH 5: training on 99524 raw words (65613 effective words) took 0.2s, 283572 effective words/s\n",
      "2023-12-06 14:47:48,476 : INFO : EPOCH 6: training on 99524 raw words (65592 effective words) took 0.2s, 281653 effective words/s\n",
      "2023-12-06 14:47:48,707 : INFO : EPOCH 7: training on 99524 raw words (65394 effective words) took 0.2s, 289086 effective words/s\n",
      "2023-12-06 14:47:48,946 : INFO : EPOCH 8: training on 99524 raw words (65499 effective words) took 0.2s, 279707 effective words/s\n",
      "2023-12-06 14:47:49,180 : INFO : EPOCH 9: training on 99524 raw words (65467 effective words) took 0.2s, 283137 effective words/s\n",
      "2023-12-06 14:47:49,422 : INFO : EPOCH 10: training on 99524 raw words (65444 effective words) took 0.2s, 275315 effective words/s\n",
      "2023-12-06 14:47:49,664 : INFO : EPOCH 11: training on 99524 raw words (65452 effective words) took 0.2s, 276907 effective words/s\n",
      "2023-12-06 14:47:49,906 : INFO : EPOCH 12: training on 99524 raw words (65635 effective words) took 0.2s, 276095 effective words/s\n",
      "2023-12-06 14:47:50,148 : INFO : EPOCH 13: training on 99524 raw words (65415 effective words) took 0.2s, 275073 effective words/s\n",
      "2023-12-06 14:47:50,389 : INFO : EPOCH 14: training on 99524 raw words (65697 effective words) took 0.2s, 277004 effective words/s\n",
      "2023-12-06 14:47:50,624 : INFO : EPOCH 15: training on 99524 raw words (65576 effective words) took 0.2s, 285558 effective words/s\n",
      "2023-12-06 14:47:50,860 : INFO : EPOCH 16: training on 99524 raw words (65470 effective words) took 0.2s, 281564 effective words/s\n",
      "2023-12-06 14:47:51,100 : INFO : EPOCH 17: training on 99524 raw words (65632 effective words) took 0.2s, 279249 effective words/s\n",
      "2023-12-06 14:47:51,341 : INFO : EPOCH 18: training on 99524 raw words (65556 effective words) took 0.2s, 277477 effective words/s\n",
      "2023-12-06 14:47:51,583 : INFO : EPOCH 19: training on 99524 raw words (65560 effective words) took 0.2s, 275080 effective words/s\n",
      "2023-12-06 14:47:51,825 : INFO : EPOCH 20: training on 99524 raw words (65450 effective words) took 0.2s, 275594 effective words/s\n",
      "2023-12-06 14:47:52,067 : INFO : EPOCH 21: training on 99524 raw words (65466 effective words) took 0.2s, 276247 effective words/s\n",
      "2023-12-06 14:47:52,311 : INFO : EPOCH 22: training on 99524 raw words (65659 effective words) took 0.2s, 273693 effective words/s\n",
      "2023-12-06 14:47:52,551 : INFO : EPOCH 23: training on 99524 raw words (65360 effective words) took 0.2s, 277254 effective words/s\n",
      "2023-12-06 14:47:52,795 : INFO : EPOCH 24: training on 99524 raw words (65542 effective words) took 0.2s, 274390 effective words/s\n",
      "2023-12-06 14:47:53,027 : INFO : EPOCH 25: training on 99524 raw words (65644 effective words) took 0.2s, 286906 effective words/s\n",
      "2023-12-06 14:47:53,266 : INFO : EPOCH 26: training on 99524 raw words (65630 effective words) took 0.2s, 279281 effective words/s\n",
      "2023-12-06 14:47:53,503 : INFO : EPOCH 27: training on 99524 raw words (65459 effective words) took 0.2s, 282079 effective words/s\n",
      "2023-12-06 14:47:53,741 : INFO : EPOCH 28: training on 99524 raw words (65456 effective words) took 0.2s, 280731 effective words/s\n",
      "2023-12-06 14:47:53,976 : INFO : EPOCH 29: training on 99524 raw words (65406 effective words) took 0.2s, 284492 effective words/s\n",
      "2023-12-06 14:47:53,977 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965504 effective words) took 7.2s, 273546 effective words/s', 'datetime': '2023-12-06T14:47:53.977132', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:47:53,977 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:47:53.977132', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 45%|     | 220/486 [34:15<40:51,  9.22s/it]2023-12-06 14:47:57,202 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:47:57,202 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:47:57,222 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:47:57,223 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:47:57,228 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:47:57.228688', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:47:57,228 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:47:57.228688', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:47:57,238 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:47:57,239 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:47:57,240 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:47:57.240691', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:47:57,256 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:47:57,257 : INFO : resetting layer weights\n",
      "2023-12-06 14:47:57,261 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:47:57.261070', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:47:57,535 : INFO : EPOCH 0: training on 99524 raw words (65616 effective words) took 0.3s, 242164 effective words/s\n",
      "2023-12-06 14:47:57,782 : INFO : EPOCH 1: training on 99524 raw words (65592 effective words) took 0.2s, 271014 effective words/s\n",
      "2023-12-06 14:47:58,035 : INFO : EPOCH 2: training on 99524 raw words (65398 effective words) took 0.2s, 263331 effective words/s\n",
      "2023-12-06 14:47:58,282 : INFO : EPOCH 3: training on 99524 raw words (65568 effective words) took 0.2s, 270246 effective words/s\n",
      "2023-12-06 14:47:58,533 : INFO : EPOCH 4: training on 99524 raw words (65510 effective words) took 0.2s, 266875 effective words/s\n",
      "2023-12-06 14:47:58,785 : INFO : EPOCH 5: training on 99524 raw words (65452 effective words) took 0.2s, 264149 effective words/s\n",
      "2023-12-06 14:47:59,035 : INFO : EPOCH 6: training on 99524 raw words (65471 effective words) took 0.2s, 265654 effective words/s\n",
      "2023-12-06 14:47:59,285 : INFO : EPOCH 7: training on 99524 raw words (65496 effective words) took 0.2s, 267575 effective words/s\n",
      "2023-12-06 14:47:59,531 : INFO : EPOCH 8: training on 99524 raw words (65612 effective words) took 0.2s, 271461 effective words/s\n",
      "2023-12-06 14:47:59,785 : INFO : EPOCH 9: training on 99524 raw words (65574 effective words) took 0.2s, 263833 effective words/s\n",
      "2023-12-06 14:48:00,041 : INFO : EPOCH 10: training on 99524 raw words (65597 effective words) took 0.3s, 261357 effective words/s\n",
      "2023-12-06 14:48:00,292 : INFO : EPOCH 11: training on 99524 raw words (65531 effective words) took 0.2s, 266146 effective words/s\n",
      "2023-12-06 14:48:00,542 : INFO : EPOCH 12: training on 99524 raw words (65770 effective words) took 0.2s, 268374 effective words/s\n",
      "2023-12-06 14:48:00,789 : INFO : EPOCH 13: training on 99524 raw words (65562 effective words) took 0.2s, 269851 effective words/s\n",
      "2023-12-06 14:48:01,044 : INFO : EPOCH 14: training on 99524 raw words (65543 effective words) took 0.3s, 261567 effective words/s\n",
      "2023-12-06 14:48:01,311 : INFO : EPOCH 15: training on 99524 raw words (65443 effective words) took 0.3s, 249840 effective words/s\n",
      "2023-12-06 14:48:01,567 : INFO : EPOCH 16: training on 99524 raw words (65486 effective words) took 0.3s, 261317 effective words/s\n",
      "2023-12-06 14:48:01,828 : INFO : EPOCH 17: training on 99524 raw words (65617 effective words) took 0.3s, 255409 effective words/s\n",
      "2023-12-06 14:48:02,088 : INFO : EPOCH 18: training on 99524 raw words (65609 effective words) took 0.3s, 256607 effective words/s\n",
      "2023-12-06 14:48:02,337 : INFO : EPOCH 19: training on 99524 raw words (65585 effective words) took 0.2s, 268074 effective words/s\n",
      "2023-12-06 14:48:02,588 : INFO : EPOCH 20: training on 99524 raw words (65545 effective words) took 0.2s, 264885 effective words/s\n",
      "2023-12-06 14:48:02,844 : INFO : EPOCH 21: training on 99524 raw words (65568 effective words) took 0.2s, 262778 effective words/s\n",
      "2023-12-06 14:48:03,084 : INFO : EPOCH 22: training on 99524 raw words (65600 effective words) took 0.2s, 278594 effective words/s\n",
      "2023-12-06 14:48:03,293 : INFO : EPOCH 23: training on 99524 raw words (65473 effective words) took 0.2s, 320526 effective words/s\n",
      "2023-12-06 14:48:03,512 : INFO : EPOCH 24: training on 99524 raw words (65668 effective words) took 0.2s, 305114 effective words/s\n",
      "2023-12-06 14:48:03,763 : INFO : EPOCH 25: training on 99524 raw words (65337 effective words) took 0.2s, 264573 effective words/s\n",
      "2023-12-06 14:48:04,026 : INFO : EPOCH 26: training on 99524 raw words (65580 effective words) took 0.3s, 253975 effective words/s\n",
      "2023-12-06 14:48:04,278 : INFO : EPOCH 27: training on 99524 raw words (65544 effective words) took 0.2s, 264771 effective words/s\n",
      "2023-12-06 14:48:04,528 : INFO : EPOCH 28: training on 99524 raw words (65505 effective words) took 0.2s, 265374 effective words/s\n",
      "2023-12-06 14:48:04,779 : INFO : EPOCH 29: training on 99524 raw words (65389 effective words) took 0.2s, 265869 effective words/s\n",
      "2023-12-06 14:48:04,780 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1966241 effective words) took 7.5s, 261499 effective words/s', 'datetime': '2023-12-06T14:48:04.780800', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:48:04,781 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:48:04.781820', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 45%|     | 221/486 [34:26<43:02,  9.75s/it]2023-12-06 14:48:08,183 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:48:08,184 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:48:08,204 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:48:08,205 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:48:08,212 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:48:08.212415', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:48:08,213 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:48:08.213418', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:48:08,223 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:48:08,223 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:48:08,224 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:48:08.224420', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:48:08,234 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:48:08,234 : INFO : resetting layer weights\n",
      "2023-12-06 14:48:08,238 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:48:08.238136', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:48:08,534 : INFO : EPOCH 0: training on 99524 raw words (65476 effective words) took 0.3s, 224399 effective words/s\n",
      "2023-12-06 14:48:08,792 : INFO : EPOCH 1: training on 99524 raw words (65483 effective words) took 0.3s, 258256 effective words/s\n",
      "2023-12-06 14:48:09,067 : INFO : EPOCH 2: training on 99524 raw words (65566 effective words) took 0.3s, 243130 effective words/s\n",
      "2023-12-06 14:48:09,331 : INFO : EPOCH 3: training on 99524 raw words (65512 effective words) took 0.3s, 251125 effective words/s\n",
      "2023-12-06 14:48:09,604 : INFO : EPOCH 4: training on 99524 raw words (65655 effective words) took 0.3s, 244141 effective words/s\n",
      "2023-12-06 14:48:09,873 : INFO : EPOCH 5: training on 99524 raw words (65387 effective words) took 0.3s, 248055 effective words/s\n",
      "2023-12-06 14:48:10,131 : INFO : EPOCH 6: training on 99524 raw words (65631 effective words) took 0.3s, 258600 effective words/s\n",
      "2023-12-06 14:48:10,391 : INFO : EPOCH 7: training on 99524 raw words (65500 effective words) took 0.3s, 255683 effective words/s\n",
      "2023-12-06 14:48:10,670 : INFO : EPOCH 8: training on 99524 raw words (65543 effective words) took 0.3s, 239671 effective words/s\n",
      "2023-12-06 14:48:10,929 : INFO : EPOCH 9: training on 99524 raw words (65535 effective words) took 0.3s, 257121 effective words/s\n",
      "2023-12-06 14:48:11,188 : INFO : EPOCH 10: training on 99524 raw words (65615 effective words) took 0.3s, 257797 effective words/s\n",
      "2023-12-06 14:48:11,451 : INFO : EPOCH 11: training on 99524 raw words (65489 effective words) took 0.3s, 253849 effective words/s\n",
      "2023-12-06 14:48:11,710 : INFO : EPOCH 12: training on 99524 raw words (65582 effective words) took 0.3s, 257527 effective words/s\n",
      "2023-12-06 14:48:11,968 : INFO : EPOCH 13: training on 99524 raw words (65533 effective words) took 0.3s, 258090 effective words/s\n",
      "2023-12-06 14:48:12,225 : INFO : EPOCH 14: training on 99524 raw words (65641 effective words) took 0.3s, 259467 effective words/s\n",
      "2023-12-06 14:48:12,488 : INFO : EPOCH 15: training on 99524 raw words (65554 effective words) took 0.3s, 254945 effective words/s\n",
      "2023-12-06 14:48:12,749 : INFO : EPOCH 16: training on 99524 raw words (65618 effective words) took 0.3s, 255940 effective words/s\n",
      "2023-12-06 14:48:13,004 : INFO : EPOCH 17: training on 99524 raw words (65499 effective words) took 0.3s, 260862 effective words/s\n",
      "2023-12-06 14:48:13,262 : INFO : EPOCH 18: training on 99524 raw words (65635 effective words) took 0.3s, 260153 effective words/s\n",
      "2023-12-06 14:48:13,527 : INFO : EPOCH 19: training on 99524 raw words (65709 effective words) took 0.3s, 251341 effective words/s\n",
      "2023-12-06 14:48:13,788 : INFO : EPOCH 20: training on 99524 raw words (65663 effective words) took 0.3s, 255090 effective words/s\n",
      "2023-12-06 14:48:14,052 : INFO : EPOCH 21: training on 99524 raw words (65551 effective words) took 0.3s, 253335 effective words/s\n",
      "2023-12-06 14:48:14,307 : INFO : EPOCH 22: training on 99524 raw words (65516 effective words) took 0.3s, 261765 effective words/s\n",
      "2023-12-06 14:48:14,568 : INFO : EPOCH 23: training on 99524 raw words (65449 effective words) took 0.3s, 254875 effective words/s\n",
      "2023-12-06 14:48:14,827 : INFO : EPOCH 24: training on 99524 raw words (65566 effective words) took 0.3s, 257382 effective words/s\n",
      "2023-12-06 14:48:15,086 : INFO : EPOCH 25: training on 99524 raw words (65519 effective words) took 0.3s, 256414 effective words/s\n",
      "2023-12-06 14:48:15,346 : INFO : EPOCH 26: training on 99524 raw words (65535 effective words) took 0.3s, 257656 effective words/s\n",
      "2023-12-06 14:48:15,605 : INFO : EPOCH 27: training on 99524 raw words (65527 effective words) took 0.3s, 257497 effective words/s\n",
      "2023-12-06 14:48:15,867 : INFO : EPOCH 28: training on 99524 raw words (65545 effective words) took 0.3s, 254010 effective words/s\n",
      "2023-12-06 14:48:16,132 : INFO : EPOCH 29: training on 99524 raw words (65598 effective words) took 0.3s, 252634 effective words/s\n",
      "2023-12-06 14:48:16,133 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1966632 effective words) took 7.9s, 249124 effective words/s', 'datetime': '2023-12-06T14:48:16.133211', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:48:16,134 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:48:16.134212', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 46%|     | 222/486 [34:38<45:14, 10.28s/it]2023-12-06 14:48:19,711 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:48:19,712 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:48:19,742 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:48:19,743 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:48:19,751 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:48:19.751899', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:48:19,752 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:48:19.752899', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:48:19,762 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:48:19,762 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:48:19,763 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:48:19.763060', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:48:19,774 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:48:19,774 : INFO : resetting layer weights\n",
      "2023-12-06 14:48:19,778 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:48:19.778568', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:48:20,033 : INFO : EPOCH 0: training on 99524 raw words (65574 effective words) took 0.3s, 261330 effective words/s\n",
      "2023-12-06 14:48:20,266 : INFO : EPOCH 1: training on 99524 raw words (65492 effective words) took 0.2s, 286284 effective words/s\n",
      "2023-12-06 14:48:20,509 : INFO : EPOCH 2: training on 99524 raw words (65440 effective words) took 0.2s, 274816 effective words/s\n",
      "2023-12-06 14:48:20,742 : INFO : EPOCH 3: training on 99524 raw words (65498 effective words) took 0.2s, 285102 effective words/s\n",
      "2023-12-06 14:48:20,979 : INFO : EPOCH 4: training on 99524 raw words (65689 effective words) took 0.2s, 283172 effective words/s\n",
      "2023-12-06 14:48:21,214 : INFO : EPOCH 5: training on 99524 raw words (65531 effective words) took 0.2s, 283704 effective words/s\n",
      "2023-12-06 14:48:21,450 : INFO : EPOCH 6: training on 99524 raw words (65534 effective words) took 0.2s, 282713 effective words/s\n",
      "2023-12-06 14:48:21,684 : INFO : EPOCH 7: training on 99524 raw words (65537 effective words) took 0.2s, 285462 effective words/s\n",
      "2023-12-06 14:48:21,924 : INFO : EPOCH 8: training on 99524 raw words (65806 effective words) took 0.2s, 278818 effective words/s\n",
      "2023-12-06 14:48:22,166 : INFO : EPOCH 9: training on 99524 raw words (65587 effective words) took 0.2s, 276325 effective words/s\n",
      "2023-12-06 14:48:22,403 : INFO : EPOCH 10: training on 99524 raw words (65490 effective words) took 0.2s, 280460 effective words/s\n",
      "2023-12-06 14:48:22,655 : INFO : EPOCH 11: training on 99524 raw words (65488 effective words) took 0.2s, 265385 effective words/s\n",
      "2023-12-06 14:48:22,892 : INFO : EPOCH 12: training on 99524 raw words (65520 effective words) took 0.2s, 281191 effective words/s\n",
      "2023-12-06 14:48:23,131 : INFO : EPOCH 13: training on 99524 raw words (65621 effective words) took 0.2s, 279214 effective words/s\n",
      "2023-12-06 14:48:23,370 : INFO : EPOCH 14: training on 99524 raw words (65443 effective words) took 0.2s, 280090 effective words/s\n",
      "2023-12-06 14:48:23,608 : INFO : EPOCH 15: training on 99524 raw words (65536 effective words) took 0.2s, 279686 effective words/s\n",
      "2023-12-06 14:48:23,846 : INFO : EPOCH 16: training on 99524 raw words (65525 effective words) took 0.2s, 279978 effective words/s\n",
      "2023-12-06 14:48:24,084 : INFO : EPOCH 17: training on 99524 raw words (65588 effective words) took 0.2s, 280585 effective words/s\n",
      "2023-12-06 14:48:24,315 : INFO : EPOCH 18: training on 99524 raw words (65538 effective words) took 0.2s, 289049 effective words/s\n",
      "2023-12-06 14:48:24,554 : INFO : EPOCH 19: training on 99524 raw words (65440 effective words) took 0.2s, 278994 effective words/s\n",
      "2023-12-06 14:48:24,798 : INFO : EPOCH 20: training on 99524 raw words (65598 effective words) took 0.2s, 273853 effective words/s\n",
      "2023-12-06 14:48:25,039 : INFO : EPOCH 21: training on 99524 raw words (65594 effective words) took 0.2s, 276174 effective words/s\n",
      "2023-12-06 14:48:25,277 : INFO : EPOCH 22: training on 99524 raw words (65593 effective words) took 0.2s, 281359 effective words/s\n",
      "2023-12-06 14:48:25,519 : INFO : EPOCH 23: training on 99524 raw words (65230 effective words) took 0.2s, 274804 effective words/s\n",
      "2023-12-06 14:48:25,759 : INFO : EPOCH 24: training on 99524 raw words (65490 effective words) took 0.2s, 277350 effective words/s\n",
      "2023-12-06 14:48:25,996 : INFO : EPOCH 25: training on 99524 raw words (65542 effective words) took 0.2s, 281641 effective words/s\n",
      "2023-12-06 14:48:26,240 : INFO : EPOCH 26: training on 99524 raw words (65587 effective words) took 0.2s, 274898 effective words/s\n",
      "2023-12-06 14:48:26,473 : INFO : EPOCH 27: training on 99524 raw words (65457 effective words) took 0.2s, 286106 effective words/s\n",
      "2023-12-06 14:48:26,707 : INFO : EPOCH 28: training on 99524 raw words (65503 effective words) took 0.2s, 285031 effective words/s\n",
      "2023-12-06 14:48:26,954 : INFO : EPOCH 29: training on 99524 raw words (65443 effective words) took 0.2s, 269530 effective words/s\n",
      "2023-12-06 14:48:27,192 : INFO : EPOCH 30: training on 99524 raw words (65554 effective words) took 0.2s, 279657 effective words/s\n",
      "2023-12-06 14:48:27,427 : INFO : EPOCH 31: training on 99524 raw words (65393 effective words) took 0.2s, 283383 effective words/s\n",
      "2023-12-06 14:48:27,675 : INFO : EPOCH 32: training on 99524 raw words (65532 effective words) took 0.2s, 269116 effective words/s\n",
      "2023-12-06 14:48:27,911 : INFO : EPOCH 33: training on 99524 raw words (65633 effective words) took 0.2s, 284055 effective words/s\n",
      "2023-12-06 14:48:28,146 : INFO : EPOCH 34: training on 99524 raw words (65557 effective words) took 0.2s, 283855 effective words/s\n",
      "2023-12-06 14:48:28,382 : INFO : EPOCH 35: training on 99524 raw words (65513 effective words) took 0.2s, 282356 effective words/s\n",
      "2023-12-06 14:48:28,618 : INFO : EPOCH 36: training on 99524 raw words (65381 effective words) took 0.2s, 282840 effective words/s\n",
      "2023-12-06 14:48:28,857 : INFO : EPOCH 37: training on 99524 raw words (65433 effective words) took 0.2s, 277615 effective words/s\n",
      "2023-12-06 14:48:29,105 : INFO : EPOCH 38: training on 99524 raw words (65443 effective words) took 0.2s, 268801 effective words/s\n",
      "2023-12-06 14:48:29,340 : INFO : EPOCH 39: training on 99524 raw words (65428 effective words) took 0.2s, 283522 effective words/s\n",
      "2023-12-06 14:48:29,582 : INFO : EPOCH 40: training on 99524 raw words (65498 effective words) took 0.2s, 277663 effective words/s\n",
      "2023-12-06 14:48:29,819 : INFO : EPOCH 41: training on 99524 raw words (65615 effective words) took 0.2s, 280616 effective words/s\n",
      "2023-12-06 14:48:30,059 : INFO : EPOCH 42: training on 99524 raw words (65456 effective words) took 0.2s, 277396 effective words/s\n",
      "2023-12-06 14:48:30,294 : INFO : EPOCH 43: training on 99524 raw words (65546 effective words) took 0.2s, 285073 effective words/s\n",
      "2023-12-06 14:48:30,529 : INFO : EPOCH 44: training on 99524 raw words (65535 effective words) took 0.2s, 283392 effective words/s\n",
      "2023-12-06 14:48:30,766 : INFO : EPOCH 45: training on 99524 raw words (65497 effective words) took 0.2s, 283158 effective words/s\n",
      "2023-12-06 14:48:31,001 : INFO : EPOCH 46: training on 99524 raw words (65513 effective words) took 0.2s, 282447 effective words/s\n",
      "2023-12-06 14:48:31,246 : INFO : EPOCH 47: training on 99524 raw words (65466 effective words) took 0.2s, 273600 effective words/s\n",
      "2023-12-06 14:48:31,481 : INFO : EPOCH 48: training on 99524 raw words (65442 effective words) took 0.2s, 282303 effective words/s\n",
      "2023-12-06 14:48:31,718 : INFO : EPOCH 49: training on 99524 raw words (65366 effective words) took 0.2s, 281245 effective words/s\n",
      "2023-12-06 14:48:31,719 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3275715 effective words) took 11.9s, 274324 effective words/s', 'datetime': '2023-12-06T14:48:31.719743', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:48:31,721 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:48:31.721084', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 46%|     | 223/486 [34:54<52:15, 11.92s/it]2023-12-06 14:48:35,456 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:48:35,456 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:48:35,477 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:48:35,478 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:48:35,485 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:48:35.485745', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:48:35,486 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:48:35.486746', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:48:35,492 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:48:35,493 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:48:35,493 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:48:35.493744', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:48:35,504 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:48:35,505 : INFO : resetting layer weights\n",
      "2023-12-06 14:48:35,508 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:48:35.507857', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:48:35,781 : INFO : EPOCH 0: training on 99524 raw words (65526 effective words) took 0.3s, 243621 effective words/s\n",
      "2023-12-06 14:48:36,030 : INFO : EPOCH 1: training on 99524 raw words (65533 effective words) took 0.2s, 268209 effective words/s\n",
      "2023-12-06 14:48:36,280 : INFO : EPOCH 2: training on 99524 raw words (65437 effective words) took 0.2s, 265656 effective words/s\n",
      "2023-12-06 14:48:36,528 : INFO : EPOCH 3: training on 99524 raw words (65560 effective words) took 0.2s, 269470 effective words/s\n",
      "2023-12-06 14:48:36,778 : INFO : EPOCH 4: training on 99524 raw words (65450 effective words) took 0.2s, 265694 effective words/s\n",
      "2023-12-06 14:48:37,033 : INFO : EPOCH 5: training on 99524 raw words (65441 effective words) took 0.2s, 262166 effective words/s\n",
      "2023-12-06 14:48:37,284 : INFO : EPOCH 6: training on 99524 raw words (65531 effective words) took 0.2s, 265525 effective words/s\n",
      "2023-12-06 14:48:37,534 : INFO : EPOCH 7: training on 99524 raw words (65612 effective words) took 0.2s, 266890 effective words/s\n",
      "2023-12-06 14:48:37,786 : INFO : EPOCH 8: training on 99524 raw words (65581 effective words) took 0.2s, 264189 effective words/s\n",
      "2023-12-06 14:48:38,036 : INFO : EPOCH 9: training on 99524 raw words (65627 effective words) took 0.2s, 267760 effective words/s\n",
      "2023-12-06 14:48:38,288 : INFO : EPOCH 10: training on 99524 raw words (65581 effective words) took 0.2s, 265250 effective words/s\n",
      "2023-12-06 14:48:38,546 : INFO : EPOCH 11: training on 99524 raw words (65379 effective words) took 0.3s, 257570 effective words/s\n",
      "2023-12-06 14:48:38,796 : INFO : EPOCH 12: training on 99524 raw words (65467 effective words) took 0.2s, 266708 effective words/s\n",
      "2023-12-06 14:48:39,047 : INFO : EPOCH 13: training on 99524 raw words (65458 effective words) took 0.2s, 266056 effective words/s\n",
      "2023-12-06 14:48:39,294 : INFO : EPOCH 14: training on 99524 raw words (65561 effective words) took 0.2s, 269616 effective words/s\n",
      "2023-12-06 14:48:39,544 : INFO : EPOCH 15: training on 99524 raw words (65684 effective words) took 0.2s, 267337 effective words/s\n",
      "2023-12-06 14:48:39,794 : INFO : EPOCH 16: training on 99524 raw words (65562 effective words) took 0.2s, 266430 effective words/s\n",
      "2023-12-06 14:48:40,046 : INFO : EPOCH 17: training on 99524 raw words (65546 effective words) took 0.2s, 265005 effective words/s\n",
      "2023-12-06 14:48:40,294 : INFO : EPOCH 18: training on 99524 raw words (65447 effective words) took 0.2s, 268450 effective words/s\n",
      "2023-12-06 14:48:40,544 : INFO : EPOCH 19: training on 99524 raw words (65524 effective words) took 0.2s, 267095 effective words/s\n",
      "2023-12-06 14:48:40,790 : INFO : EPOCH 20: training on 99524 raw words (65483 effective words) took 0.2s, 270708 effective words/s\n",
      "2023-12-06 14:48:41,041 : INFO : EPOCH 21: training on 99524 raw words (65661 effective words) took 0.2s, 265687 effective words/s\n",
      "2023-12-06 14:48:41,297 : INFO : EPOCH 22: training on 99524 raw words (65539 effective words) took 0.3s, 261821 effective words/s\n",
      "2023-12-06 14:48:41,548 : INFO : EPOCH 23: training on 99524 raw words (65486 effective words) took 0.2s, 265021 effective words/s\n",
      "2023-12-06 14:48:41,798 : INFO : EPOCH 24: training on 99524 raw words (65449 effective words) took 0.2s, 266045 effective words/s\n",
      "2023-12-06 14:48:42,050 : INFO : EPOCH 25: training on 99524 raw words (65659 effective words) took 0.2s, 264019 effective words/s\n",
      "2023-12-06 14:48:42,304 : INFO : EPOCH 26: training on 99524 raw words (65482 effective words) took 0.2s, 263351 effective words/s\n",
      "2023-12-06 14:48:42,558 : INFO : EPOCH 27: training on 99524 raw words (65570 effective words) took 0.2s, 262923 effective words/s\n",
      "2023-12-06 14:48:42,807 : INFO : EPOCH 28: training on 99524 raw words (65547 effective words) took 0.2s, 268025 effective words/s\n",
      "2023-12-06 14:48:43,053 : INFO : EPOCH 29: training on 99524 raw words (65479 effective words) took 0.2s, 271518 effective words/s\n",
      "2023-12-06 14:48:43,308 : INFO : EPOCH 30: training on 99524 raw words (65426 effective words) took 0.3s, 260991 effective words/s\n",
      "2023-12-06 14:48:43,558 : INFO : EPOCH 31: training on 99524 raw words (65491 effective words) took 0.2s, 265050 effective words/s\n",
      "2023-12-06 14:48:43,815 : INFO : EPOCH 32: training on 99524 raw words (65623 effective words) took 0.3s, 259710 effective words/s\n",
      "2023-12-06 14:48:44,068 : INFO : EPOCH 33: training on 99524 raw words (65461 effective words) took 0.2s, 264405 effective words/s\n",
      "2023-12-06 14:48:44,320 : INFO : EPOCH 34: training on 99524 raw words (65485 effective words) took 0.2s, 263146 effective words/s\n",
      "2023-12-06 14:48:44,568 : INFO : EPOCH 35: training on 99524 raw words (65497 effective words) took 0.2s, 270559 effective words/s\n",
      "2023-12-06 14:48:44,816 : INFO : EPOCH 36: training on 99524 raw words (65451 effective words) took 0.2s, 267143 effective words/s\n",
      "2023-12-06 14:48:45,065 : INFO : EPOCH 37: training on 99524 raw words (65456 effective words) took 0.2s, 268615 effective words/s\n",
      "2023-12-06 14:48:45,315 : INFO : EPOCH 38: training on 99524 raw words (65611 effective words) took 0.2s, 265932 effective words/s\n",
      "2023-12-06 14:48:45,567 : INFO : EPOCH 39: training on 99524 raw words (65622 effective words) took 0.2s, 266493 effective words/s\n",
      "2023-12-06 14:48:45,818 : INFO : EPOCH 40: training on 99524 raw words (65607 effective words) took 0.2s, 265039 effective words/s\n",
      "2023-12-06 14:48:46,077 : INFO : EPOCH 41: training on 99524 raw words (65731 effective words) took 0.3s, 259518 effective words/s\n",
      "2023-12-06 14:48:46,329 : INFO : EPOCH 42: training on 99524 raw words (65612 effective words) took 0.2s, 264313 effective words/s\n",
      "2023-12-06 14:48:46,586 : INFO : EPOCH 43: training on 99524 raw words (65564 effective words) took 0.3s, 260722 effective words/s\n",
      "2023-12-06 14:48:46,839 : INFO : EPOCH 44: training on 99524 raw words (65586 effective words) took 0.2s, 263308 effective words/s\n",
      "2023-12-06 14:48:47,092 : INFO : EPOCH 45: training on 99524 raw words (65496 effective words) took 0.2s, 263410 effective words/s\n",
      "2023-12-06 14:48:47,343 : INFO : EPOCH 46: training on 99524 raw words (65547 effective words) took 0.2s, 265137 effective words/s\n",
      "2023-12-06 14:48:47,592 : INFO : EPOCH 47: training on 99524 raw words (65494 effective words) took 0.2s, 268056 effective words/s\n",
      "2023-12-06 14:48:47,844 : INFO : EPOCH 48: training on 99524 raw words (65635 effective words) took 0.2s, 264756 effective words/s\n",
      "2023-12-06 14:48:48,097 : INFO : EPOCH 49: training on 99524 raw words (65533 effective words) took 0.2s, 263524 effective words/s\n",
      "2023-12-06 14:48:48,098 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276790 effective words) took 12.6s, 260278 effective words/s', 'datetime': '2023-12-06T14:48:48.098442', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:48:48,098 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:48:48.098442', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 46%|     | 224/486 [35:10<58:19, 13.36s/it]2023-12-06 14:48:52,162 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:48:52,163 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:48:52,185 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:48:52,186 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:48:52,193 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:48:52.193725', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:48:52,194 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:48:52.194733', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:48:52,201 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:48:52,201 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:48:52,202 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:48:52.202390', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:48:52,213 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:48:52,214 : INFO : resetting layer weights\n",
      "2023-12-06 14:48:52,216 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:48:52.216592', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:48:52,488 : INFO : EPOCH 0: training on 99524 raw words (65576 effective words) took 0.3s, 244807 effective words/s\n",
      "2023-12-06 14:48:52,747 : INFO : EPOCH 1: training on 99524 raw words (65341 effective words) took 0.3s, 256497 effective words/s\n",
      "2023-12-06 14:48:53,009 : INFO : EPOCH 2: training on 99524 raw words (65551 effective words) took 0.3s, 254128 effective words/s\n",
      "2023-12-06 14:48:53,266 : INFO : EPOCH 3: training on 99524 raw words (65581 effective words) took 0.3s, 260614 effective words/s\n",
      "2023-12-06 14:48:53,531 : INFO : EPOCH 4: training on 99524 raw words (65606 effective words) took 0.3s, 250949 effective words/s\n",
      "2023-12-06 14:48:53,789 : INFO : EPOCH 5: training on 99524 raw words (65419 effective words) took 0.3s, 259716 effective words/s\n",
      "2023-12-06 14:48:54,049 : INFO : EPOCH 6: training on 99524 raw words (65353 effective words) took 0.3s, 255678 effective words/s\n",
      "2023-12-06 14:48:54,309 : INFO : EPOCH 7: training on 99524 raw words (65507 effective words) took 0.3s, 255941 effective words/s\n",
      "2023-12-06 14:48:54,571 : INFO : EPOCH 8: training on 99524 raw words (65445 effective words) took 0.3s, 254012 effective words/s\n",
      "2023-12-06 14:48:54,829 : INFO : EPOCH 9: training on 99524 raw words (65543 effective words) took 0.3s, 257968 effective words/s\n",
      "2023-12-06 14:48:55,089 : INFO : EPOCH 10: training on 99524 raw words (65576 effective words) took 0.3s, 257042 effective words/s\n",
      "2023-12-06 14:48:55,356 : INFO : EPOCH 11: training on 99524 raw words (65506 effective words) took 0.3s, 248928 effective words/s\n",
      "2023-12-06 14:48:55,615 : INFO : EPOCH 12: training on 99524 raw words (65665 effective words) took 0.3s, 258623 effective words/s\n",
      "2023-12-06 14:48:55,877 : INFO : EPOCH 13: training on 99524 raw words (65585 effective words) took 0.3s, 253878 effective words/s\n",
      "2023-12-06 14:48:56,137 : INFO : EPOCH 14: training on 99524 raw words (65506 effective words) took 0.3s, 256316 effective words/s\n",
      "2023-12-06 14:48:56,397 : INFO : EPOCH 15: training on 99524 raw words (65496 effective words) took 0.3s, 256399 effective words/s\n",
      "2023-12-06 14:48:56,659 : INFO : EPOCH 16: training on 99524 raw words (65475 effective words) took 0.3s, 254592 effective words/s\n",
      "2023-12-06 14:48:56,919 : INFO : EPOCH 17: training on 99524 raw words (65403 effective words) took 0.3s, 255196 effective words/s\n",
      "2023-12-06 14:48:57,179 : INFO : EPOCH 18: training on 99524 raw words (65416 effective words) took 0.3s, 255776 effective words/s\n",
      "2023-12-06 14:48:57,443 : INFO : EPOCH 19: training on 99524 raw words (65542 effective words) took 0.3s, 252955 effective words/s\n",
      "2023-12-06 14:48:57,703 : INFO : EPOCH 20: training on 99524 raw words (65408 effective words) took 0.3s, 255119 effective words/s\n",
      "2023-12-06 14:48:57,966 : INFO : EPOCH 21: training on 99524 raw words (65463 effective words) took 0.3s, 254237 effective words/s\n",
      "2023-12-06 14:48:58,235 : INFO : EPOCH 22: training on 99524 raw words (65472 effective words) took 0.3s, 246814 effective words/s\n",
      "2023-12-06 14:48:58,501 : INFO : EPOCH 23: training on 99524 raw words (65635 effective words) took 0.3s, 251149 effective words/s\n",
      "2023-12-06 14:48:58,767 : INFO : EPOCH 24: training on 99524 raw words (65629 effective words) took 0.3s, 251371 effective words/s\n",
      "2023-12-06 14:48:58,982 : INFO : EPOCH 25: training on 99524 raw words (65439 effective words) took 0.2s, 310009 effective words/s\n",
      "2023-12-06 14:48:59,190 : INFO : EPOCH 26: training on 99524 raw words (65509 effective words) took 0.2s, 322024 effective words/s\n",
      "2023-12-06 14:48:59,432 : INFO : EPOCH 27: training on 99524 raw words (65548 effective words) took 0.2s, 277583 effective words/s\n",
      "2023-12-06 14:48:59,696 : INFO : EPOCH 28: training on 99524 raw words (65546 effective words) took 0.3s, 251614 effective words/s\n",
      "2023-12-06 14:48:59,981 : INFO : EPOCH 29: training on 99524 raw words (65521 effective words) took 0.3s, 234448 effective words/s\n",
      "2023-12-06 14:49:00,254 : INFO : EPOCH 30: training on 99524 raw words (65585 effective words) took 0.3s, 244574 effective words/s\n",
      "2023-12-06 14:49:00,519 : INFO : EPOCH 31: training on 99524 raw words (65506 effective words) took 0.3s, 251689 effective words/s\n",
      "2023-12-06 14:49:00,779 : INFO : EPOCH 32: training on 99524 raw words (65540 effective words) took 0.3s, 255766 effective words/s\n",
      "2023-12-06 14:49:01,046 : INFO : EPOCH 33: training on 99524 raw words (65583 effective words) took 0.3s, 249416 effective words/s\n",
      "2023-12-06 14:49:01,311 : INFO : EPOCH 34: training on 99524 raw words (65502 effective words) took 0.3s, 252248 effective words/s\n",
      "2023-12-06 14:49:01,575 : INFO : EPOCH 35: training on 99524 raw words (65646 effective words) took 0.3s, 253382 effective words/s\n",
      "2023-12-06 14:49:01,835 : INFO : EPOCH 36: training on 99524 raw words (65445 effective words) took 0.3s, 255589 effective words/s\n",
      "2023-12-06 14:49:02,098 : INFO : EPOCH 37: training on 99524 raw words (65572 effective words) took 0.3s, 253829 effective words/s\n",
      "2023-12-06 14:49:02,358 : INFO : EPOCH 38: training on 99524 raw words (65270 effective words) took 0.3s, 255443 effective words/s\n",
      "2023-12-06 14:49:02,614 : INFO : EPOCH 39: training on 99524 raw words (65565 effective words) took 0.3s, 261031 effective words/s\n",
      "2023-12-06 14:49:02,880 : INFO : EPOCH 40: training on 99524 raw words (65708 effective words) took 0.3s, 251652 effective words/s\n",
      "2023-12-06 14:49:03,137 : INFO : EPOCH 41: training on 99524 raw words (65665 effective words) took 0.3s, 259947 effective words/s\n",
      "2023-12-06 14:49:03,396 : INFO : EPOCH 42: training on 99524 raw words (65457 effective words) took 0.3s, 256556 effective words/s\n",
      "2023-12-06 14:49:03,657 : INFO : EPOCH 43: training on 99524 raw words (65573 effective words) took 0.3s, 255972 effective words/s\n",
      "2023-12-06 14:49:03,925 : INFO : EPOCH 44: training on 99524 raw words (65486 effective words) took 0.3s, 247961 effective words/s\n",
      "2023-12-06 14:49:04,183 : INFO : EPOCH 45: training on 99524 raw words (65518 effective words) took 0.3s, 258072 effective words/s\n",
      "2023-12-06 14:49:04,446 : INFO : EPOCH 46: training on 99524 raw words (65486 effective words) took 0.3s, 253033 effective words/s\n",
      "2023-12-06 14:49:04,706 : INFO : EPOCH 47: training on 99524 raw words (65488 effective words) took 0.3s, 256523 effective words/s\n",
      "2023-12-06 14:49:04,967 : INFO : EPOCH 48: training on 99524 raw words (65567 effective words) took 0.3s, 256057 effective words/s\n",
      "2023-12-06 14:49:05,222 : INFO : EPOCH 49: training on 99524 raw words (65400 effective words) took 0.3s, 260767 effective words/s\n",
      "2023-12-06 14:49:05,224 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3275824 effective words) took 13.0s, 251849 effective words/s', 'datetime': '2023-12-06T14:49:05.224206', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:49:05,224 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:49:05.224206', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 46%|     | 225/486 [35:28<1:03:56, 14.70s/it]2023-12-06 14:49:09,995 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:49:09,996 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:49:10,024 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:49:10,025 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:49:10,032 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:49:10.032014', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:49:10,033 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:49:10.033015', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:49:10,039 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:49:10,040 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:49:10,041 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:49:10.041244', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:49:10,049 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:49:10,049 : INFO : resetting layer weights\n",
      "2023-12-06 14:49:10,053 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:49:10.053423', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:49:10,300 : INFO : EPOCH 0: training on 99524 raw words (62738 effective words) took 0.2s, 257246 effective words/s\n",
      "2023-12-06 14:49:10,538 : INFO : EPOCH 1: training on 99524 raw words (62852 effective words) took 0.2s, 269485 effective words/s\n",
      "2023-12-06 14:49:10,776 : INFO : EPOCH 2: training on 99524 raw words (62826 effective words) took 0.2s, 268933 effective words/s\n",
      "2023-12-06 14:49:11,006 : INFO : EPOCH 3: training on 99524 raw words (62740 effective words) took 0.2s, 277358 effective words/s\n",
      "2023-12-06 14:49:11,245 : INFO : EPOCH 4: training on 99524 raw words (62640 effective words) took 0.2s, 268283 effective words/s\n",
      "2023-12-06 14:49:11,479 : INFO : EPOCH 5: training on 99524 raw words (62761 effective words) took 0.2s, 273116 effective words/s\n",
      "2023-12-06 14:49:11,713 : INFO : EPOCH 6: training on 99524 raw words (62825 effective words) took 0.2s, 274956 effective words/s\n",
      "2023-12-06 14:49:11,947 : INFO : EPOCH 7: training on 99524 raw words (62936 effective words) took 0.2s, 272810 effective words/s\n",
      "2023-12-06 14:49:12,186 : INFO : EPOCH 8: training on 99524 raw words (62747 effective words) took 0.2s, 267909 effective words/s\n",
      "2023-12-06 14:49:12,423 : INFO : EPOCH 9: training on 99524 raw words (62876 effective words) took 0.2s, 271026 effective words/s\n",
      "2023-12-06 14:49:12,424 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627941 effective words) took 2.4s, 264889 effective words/s', 'datetime': '2023-12-06T14:49:12.424551', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:49:12,424 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:49:12.424551', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 47%|     | 226/486 [35:33<51:20, 11.85s/it]  2023-12-06 14:49:15,188 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:49:15,188 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:49:15,209 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:49:15,210 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:49:15,215 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:49:15.215471', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:49:15,216 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:49:15.216471', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:49:15,221 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:49:15,222 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:49:15,222 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:49:15.222476', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:49:15,235 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:49:15,236 : INFO : resetting layer weights\n",
      "2023-12-06 14:49:15,238 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:49:15.238019', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:49:15,503 : INFO : EPOCH 0: training on 99524 raw words (62832 effective words) took 0.3s, 240661 effective words/s\n",
      "2023-12-06 14:49:15,750 : INFO : EPOCH 1: training on 99524 raw words (62597 effective words) took 0.2s, 258371 effective words/s\n",
      "2023-12-06 14:49:15,998 : INFO : EPOCH 2: training on 99524 raw words (62670 effective words) took 0.2s, 257045 effective words/s\n",
      "2023-12-06 14:49:16,246 : INFO : EPOCH 3: training on 99524 raw words (62709 effective words) took 0.2s, 257759 effective words/s\n",
      "2023-12-06 14:49:16,497 : INFO : EPOCH 4: training on 99524 raw words (62606 effective words) took 0.2s, 254422 effective words/s\n",
      "2023-12-06 14:49:16,744 : INFO : EPOCH 5: training on 99524 raw words (62761 effective words) took 0.2s, 258302 effective words/s\n",
      "2023-12-06 14:49:16,987 : INFO : EPOCH 6: training on 99524 raw words (62721 effective words) took 0.2s, 262096 effective words/s\n",
      "2023-12-06 14:49:17,238 : INFO : EPOCH 7: training on 99524 raw words (62815 effective words) took 0.2s, 255511 effective words/s\n",
      "2023-12-06 14:49:17,486 : INFO : EPOCH 8: training on 99524 raw words (62694 effective words) took 0.2s, 257485 effective words/s\n",
      "2023-12-06 14:49:17,733 : INFO : EPOCH 9: training on 99524 raw words (62621 effective words) took 0.2s, 256952 effective words/s\n",
      "2023-12-06 14:49:17,734 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627026 effective words) took 2.5s, 251203 effective words/s', 'datetime': '2023-12-06T14:49:17.734730', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:49:17,735 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:49:17.735731', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 47%|     | 227/486 [35:39<42:40,  9.88s/it]2023-12-06 14:49:20,493 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:49:20,494 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:49:20,516 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:49:20,517 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:49:20,524 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:49:20.524333', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:49:20,524 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:49:20.524333', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:49:20,529 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:49:20,529 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:49:20,530 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:49:20.530845', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:49:20,538 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:49:20,538 : INFO : resetting layer weights\n",
      "2023-12-06 14:49:20,541 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:49:20.541977', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:49:20,813 : INFO : EPOCH 0: training on 99524 raw words (62621 effective words) took 0.3s, 233958 effective words/s\n",
      "2023-12-06 14:49:21,075 : INFO : EPOCH 1: training on 99524 raw words (62613 effective words) took 0.3s, 242901 effective words/s\n",
      "2023-12-06 14:49:21,332 : INFO : EPOCH 2: training on 99524 raw words (62662 effective words) took 0.3s, 247768 effective words/s\n",
      "2023-12-06 14:49:21,591 : INFO : EPOCH 3: training on 99524 raw words (62576 effective words) took 0.3s, 246651 effective words/s\n",
      "2023-12-06 14:49:21,852 : INFO : EPOCH 4: training on 99524 raw words (62783 effective words) took 0.3s, 244004 effective words/s\n",
      "2023-12-06 14:49:22,108 : INFO : EPOCH 5: training on 99524 raw words (62720 effective words) took 0.3s, 248748 effective words/s\n",
      "2023-12-06 14:49:22,368 : INFO : EPOCH 6: training on 99524 raw words (62689 effective words) took 0.3s, 245879 effective words/s\n",
      "2023-12-06 14:49:22,624 : INFO : EPOCH 7: training on 99524 raw words (62808 effective words) took 0.3s, 249756 effective words/s\n",
      "2023-12-06 14:49:22,881 : INFO : EPOCH 8: training on 99524 raw words (62701 effective words) took 0.3s, 247647 effective words/s\n",
      "2023-12-06 14:49:23,136 : INFO : EPOCH 9: training on 99524 raw words (62543 effective words) took 0.3s, 249888 effective words/s\n",
      "2023-12-06 14:49:23,137 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (626716 effective words) took 2.6s, 241584 effective words/s', 'datetime': '2023-12-06T14:49:23.137417', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:49:23,137 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:49:23.137417', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 47%|     | 228/486 [35:44<36:48,  8.56s/it]2023-12-06 14:49:25,961 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:49:25,961 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:49:25,985 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:49:25,986 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:49:25,990 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:49:25.990899', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:49:25,991 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:49:25.991899', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:49:25,996 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:49:25,996 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:49:25,997 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:49:25.997899', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:49:26,006 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:49:26,007 : INFO : resetting layer weights\n",
      "2023-12-06 14:49:26,010 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:49:26.010077', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:49:26,262 : INFO : EPOCH 0: training on 99524 raw words (62787 effective words) took 0.2s, 254048 effective words/s\n",
      "2023-12-06 14:49:26,504 : INFO : EPOCH 1: training on 99524 raw words (62631 effective words) took 0.2s, 265583 effective words/s\n",
      "2023-12-06 14:49:26,743 : INFO : EPOCH 2: training on 99524 raw words (62599 effective words) took 0.2s, 266654 effective words/s\n",
      "2023-12-06 14:49:26,986 : INFO : EPOCH 3: training on 99524 raw words (62672 effective words) took 0.2s, 261873 effective words/s\n",
      "2023-12-06 14:49:27,220 : INFO : EPOCH 4: training on 99524 raw words (62672 effective words) took 0.2s, 273429 effective words/s\n",
      "2023-12-06 14:49:27,455 : INFO : EPOCH 5: training on 99524 raw words (62595 effective words) took 0.2s, 272010 effective words/s\n",
      "2023-12-06 14:49:27,689 : INFO : EPOCH 6: training on 99524 raw words (62775 effective words) took 0.2s, 273564 effective words/s\n",
      "2023-12-06 14:49:27,924 : INFO : EPOCH 7: training on 99524 raw words (62854 effective words) took 0.2s, 271604 effective words/s\n",
      "2023-12-06 14:49:28,161 : INFO : EPOCH 8: training on 99524 raw words (62594 effective words) took 0.2s, 268444 effective words/s\n",
      "2023-12-06 14:49:28,401 : INFO : EPOCH 9: training on 99524 raw words (62641 effective words) took 0.2s, 266558 effective words/s\n",
      "2023-12-06 14:49:28,641 : INFO : EPOCH 10: training on 99524 raw words (62860 effective words) took 0.2s, 266511 effective words/s\n",
      "2023-12-06 14:49:28,886 : INFO : EPOCH 11: training on 99524 raw words (62860 effective words) took 0.2s, 261382 effective words/s\n",
      "2023-12-06 14:49:29,124 : INFO : EPOCH 12: training on 99524 raw words (62692 effective words) took 0.2s, 267198 effective words/s\n",
      "2023-12-06 14:49:29,357 : INFO : EPOCH 13: training on 99524 raw words (62805 effective words) took 0.2s, 275805 effective words/s\n",
      "2023-12-06 14:49:29,597 : INFO : EPOCH 14: training on 99524 raw words (62770 effective words) took 0.2s, 265576 effective words/s\n",
      "2023-12-06 14:49:29,832 : INFO : EPOCH 15: training on 99524 raw words (62595 effective words) took 0.2s, 271385 effective words/s\n",
      "2023-12-06 14:49:30,070 : INFO : EPOCH 16: training on 99524 raw words (62579 effective words) took 0.2s, 267471 effective words/s\n",
      "2023-12-06 14:49:30,311 : INFO : EPOCH 17: training on 99524 raw words (62559 effective words) took 0.2s, 265205 effective words/s\n",
      "2023-12-06 14:49:30,549 : INFO : EPOCH 18: training on 99524 raw words (62619 effective words) took 0.2s, 268374 effective words/s\n",
      "2023-12-06 14:49:30,783 : INFO : EPOCH 19: training on 99524 raw words (62832 effective words) took 0.2s, 272517 effective words/s\n",
      "2023-12-06 14:49:31,022 : INFO : EPOCH 20: training on 99524 raw words (62818 effective words) took 0.2s, 267772 effective words/s\n",
      "2023-12-06 14:49:31,271 : INFO : EPOCH 21: training on 99524 raw words (62557 effective words) took 0.2s, 255988 effective words/s\n",
      "2023-12-06 14:49:31,521 : INFO : EPOCH 22: training on 99524 raw words (62732 effective words) took 0.2s, 255594 effective words/s\n",
      "2023-12-06 14:49:31,752 : INFO : EPOCH 23: training on 99524 raw words (62602 effective words) took 0.2s, 275796 effective words/s\n",
      "2023-12-06 14:49:31,988 : INFO : EPOCH 24: training on 99524 raw words (62680 effective words) took 0.2s, 270462 effective words/s\n",
      "2023-12-06 14:49:32,229 : INFO : EPOCH 25: training on 99524 raw words (62825 effective words) took 0.2s, 266262 effective words/s\n",
      "2023-12-06 14:49:32,464 : INFO : EPOCH 26: training on 99524 raw words (62802 effective words) took 0.2s, 271275 effective words/s\n",
      "2023-12-06 14:49:32,693 : INFO : EPOCH 27: training on 99524 raw words (62712 effective words) took 0.2s, 279525 effective words/s\n",
      "2023-12-06 14:49:32,927 : INFO : EPOCH 28: training on 99524 raw words (62696 effective words) took 0.2s, 272778 effective words/s\n",
      "2023-12-06 14:49:33,161 : INFO : EPOCH 29: training on 99524 raw words (62642 effective words) took 0.2s, 272873 effective words/s\n",
      "2023-12-06 14:49:33,162 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881057 effective words) took 7.2s, 263010 effective words/s', 'datetime': '2023-12-06T14:49:33.162207', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:49:33,163 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:49:33.163208', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 47%|     | 229/486 [35:55<39:04,  9.12s/it]2023-12-06 14:49:36,392 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:49:36,393 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:49:36,421 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:49:36,422 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:49:36,428 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:49:36.428061', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:49:36,429 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:49:36.429061', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:49:36,437 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:49:36,438 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:49:36,438 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:49:36.438060', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:49:36,447 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:49:36,448 : INFO : resetting layer weights\n",
      "2023-12-06 14:49:36,452 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:49:36.452138', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:49:36,707 : INFO : EPOCH 0: training on 99524 raw words (62899 effective words) took 0.3s, 250008 effective words/s\n",
      "2023-12-06 14:49:36,952 : INFO : EPOCH 1: training on 99524 raw words (62651 effective words) took 0.2s, 261421 effective words/s\n",
      "2023-12-06 14:49:37,202 : INFO : EPOCH 2: training on 99524 raw words (62907 effective words) took 0.2s, 256420 effective words/s\n",
      "2023-12-06 14:49:37,450 : INFO : EPOCH 3: training on 99524 raw words (62804 effective words) took 0.2s, 257869 effective words/s\n",
      "2023-12-06 14:49:37,698 : INFO : EPOCH 4: training on 99524 raw words (62858 effective words) took 0.2s, 258328 effective words/s\n",
      "2023-12-06 14:49:37,947 : INFO : EPOCH 5: training on 99524 raw words (62697 effective words) took 0.2s, 255597 effective words/s\n",
      "2023-12-06 14:49:38,195 : INFO : EPOCH 6: training on 99524 raw words (62895 effective words) took 0.2s, 257973 effective words/s\n",
      "2023-12-06 14:49:38,439 : INFO : EPOCH 7: training on 99524 raw words (62600 effective words) took 0.2s, 260911 effective words/s\n",
      "2023-12-06 14:49:38,684 : INFO : EPOCH 8: training on 99524 raw words (62652 effective words) took 0.2s, 260686 effective words/s\n",
      "2023-12-06 14:49:38,933 : INFO : EPOCH 9: training on 99524 raw words (62745 effective words) took 0.2s, 256303 effective words/s\n",
      "2023-12-06 14:49:39,191 : INFO : EPOCH 10: training on 99524 raw words (62816 effective words) took 0.3s, 247893 effective words/s\n",
      "2023-12-06 14:49:39,451 : INFO : EPOCH 11: training on 99524 raw words (62628 effective words) took 0.3s, 244166 effective words/s\n",
      "2023-12-06 14:49:39,699 : INFO : EPOCH 12: training on 99524 raw words (62720 effective words) took 0.2s, 257734 effective words/s\n",
      "2023-12-06 14:49:39,948 : INFO : EPOCH 13: training on 99524 raw words (62840 effective words) took 0.2s, 256491 effective words/s\n",
      "2023-12-06 14:49:40,195 : INFO : EPOCH 14: training on 99524 raw words (62735 effective words) took 0.2s, 259011 effective words/s\n",
      "2023-12-06 14:49:40,445 : INFO : EPOCH 15: training on 99524 raw words (62619 effective words) took 0.2s, 255481 effective words/s\n",
      "2023-12-06 14:49:40,685 : INFO : EPOCH 16: training on 99524 raw words (62762 effective words) took 0.2s, 266529 effective words/s\n",
      "2023-12-06 14:49:40,932 : INFO : EPOCH 17: training on 99524 raw words (62703 effective words) took 0.2s, 257350 effective words/s\n",
      "2023-12-06 14:49:41,182 : INFO : EPOCH 18: training on 99524 raw words (62692 effective words) took 0.2s, 255176 effective words/s\n",
      "2023-12-06 14:49:41,431 : INFO : EPOCH 19: training on 99524 raw words (62845 effective words) took 0.2s, 257750 effective words/s\n",
      "2023-12-06 14:49:41,678 : INFO : EPOCH 20: training on 99524 raw words (62519 effective words) took 0.2s, 257793 effective words/s\n",
      "2023-12-06 14:49:41,927 : INFO : EPOCH 21: training on 99524 raw words (62774 effective words) took 0.2s, 256364 effective words/s\n",
      "2023-12-06 14:49:42,183 : INFO : EPOCH 22: training on 99524 raw words (62718 effective words) took 0.3s, 249189 effective words/s\n",
      "2023-12-06 14:49:42,432 : INFO : EPOCH 23: training on 99524 raw words (62707 effective words) took 0.2s, 256218 effective words/s\n",
      "2023-12-06 14:49:42,681 : INFO : EPOCH 24: training on 99524 raw words (62648 effective words) took 0.2s, 256382 effective words/s\n",
      "2023-12-06 14:49:42,926 : INFO : EPOCH 25: training on 99524 raw words (62633 effective words) took 0.2s, 260073 effective words/s\n",
      "2023-12-06 14:49:43,175 : INFO : EPOCH 26: training on 99524 raw words (62597 effective words) took 0.2s, 256518 effective words/s\n",
      "2023-12-06 14:49:43,424 : INFO : EPOCH 27: training on 99524 raw words (62576 effective words) took 0.2s, 255889 effective words/s\n",
      "2023-12-06 14:49:43,668 : INFO : EPOCH 28: training on 99524 raw words (62662 effective words) took 0.2s, 261570 effective words/s\n",
      "2023-12-06 14:49:43,917 : INFO : EPOCH 29: training on 99524 raw words (62950 effective words) took 0.2s, 257300 effective words/s\n",
      "2023-12-06 14:49:43,918 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881852 effective words) took 7.5s, 252059 effective words/s', 'datetime': '2023-12-06T14:49:43.918767', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:49:43,918 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:49:43.918767', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 47%|     | 230/486 [36:05<41:11,  9.65s/it]2023-12-06 14:49:47,285 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:49:47,286 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:49:47,311 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:49:47,312 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:49:47,316 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:49:47.316386', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:49:47,317 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:49:47.317388', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:49:47,324 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:49:47,325 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:49:47,325 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:49:47.325896', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:49:47,333 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:49:47,334 : INFO : resetting layer weights\n",
      "2023-12-06 14:49:47,338 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:49:47.338404', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:49:47,603 : INFO : EPOCH 0: training on 99524 raw words (62620 effective words) took 0.3s, 239642 effective words/s\n",
      "2023-12-06 14:49:47,870 : INFO : EPOCH 1: training on 99524 raw words (62645 effective words) took 0.3s, 240940 effective words/s\n",
      "2023-12-06 14:49:48,128 : INFO : EPOCH 2: training on 99524 raw words (62768 effective words) took 0.3s, 248272 effective words/s\n",
      "2023-12-06 14:49:48,386 : INFO : EPOCH 3: training on 99524 raw words (62899 effective words) took 0.3s, 247354 effective words/s\n",
      "2023-12-06 14:49:48,644 : INFO : EPOCH 4: training on 99524 raw words (62789 effective words) took 0.3s, 247614 effective words/s\n",
      "2023-12-06 14:49:48,899 : INFO : EPOCH 5: training on 99524 raw words (62796 effective words) took 0.3s, 249279 effective words/s\n",
      "2023-12-06 14:49:49,161 : INFO : EPOCH 6: training on 99524 raw words (62779 effective words) took 0.3s, 244625 effective words/s\n",
      "2023-12-06 14:49:49,419 : INFO : EPOCH 7: training on 99524 raw words (62743 effective words) took 0.3s, 246463 effective words/s\n",
      "2023-12-06 14:49:49,676 : INFO : EPOCH 8: training on 99524 raw words (62566 effective words) took 0.3s, 248227 effective words/s\n",
      "2023-12-06 14:49:49,937 : INFO : EPOCH 9: training on 99524 raw words (62773 effective words) took 0.3s, 245274 effective words/s\n",
      "2023-12-06 14:49:50,192 : INFO : EPOCH 10: training on 99524 raw words (62652 effective words) took 0.3s, 248878 effective words/s\n",
      "2023-12-06 14:49:50,461 : INFO : EPOCH 11: training on 99524 raw words (62750 effective words) took 0.3s, 237103 effective words/s\n",
      "2023-12-06 14:49:50,720 : INFO : EPOCH 12: training on 99524 raw words (62777 effective words) took 0.3s, 247176 effective words/s\n",
      "2023-12-06 14:49:50,976 : INFO : EPOCH 13: training on 99524 raw words (62726 effective words) took 0.3s, 247954 effective words/s\n",
      "2023-12-06 14:49:51,233 : INFO : EPOCH 14: training on 99524 raw words (62763 effective words) took 0.3s, 248940 effective words/s\n",
      "2023-12-06 14:49:51,490 : INFO : EPOCH 15: training on 99524 raw words (62822 effective words) took 0.3s, 249348 effective words/s\n",
      "2023-12-06 14:49:51,747 : INFO : EPOCH 16: training on 99524 raw words (62853 effective words) took 0.3s, 248212 effective words/s\n",
      "2023-12-06 14:49:52,006 : INFO : EPOCH 17: training on 99524 raw words (62836 effective words) took 0.3s, 247012 effective words/s\n",
      "2023-12-06 14:49:52,266 : INFO : EPOCH 18: training on 99524 raw words (62947 effective words) took 0.3s, 247156 effective words/s\n",
      "2023-12-06 14:49:52,522 : INFO : EPOCH 19: training on 99524 raw words (62788 effective words) took 0.3s, 248737 effective words/s\n",
      "2023-12-06 14:49:52,782 : INFO : EPOCH 20: training on 99524 raw words (62581 effective words) took 0.3s, 246241 effective words/s\n",
      "2023-12-06 14:49:53,045 : INFO : EPOCH 21: training on 99524 raw words (62719 effective words) took 0.3s, 241846 effective words/s\n",
      "2023-12-06 14:49:53,297 : INFO : EPOCH 22: training on 99524 raw words (62619 effective words) took 0.2s, 252784 effective words/s\n",
      "2023-12-06 14:49:53,555 : INFO : EPOCH 23: training on 99524 raw words (62649 effective words) took 0.3s, 246787 effective words/s\n",
      "2023-12-06 14:49:53,813 : INFO : EPOCH 24: training on 99524 raw words (62709 effective words) took 0.3s, 248194 effective words/s\n",
      "2023-12-06 14:49:54,070 : INFO : EPOCH 25: training on 99524 raw words (62765 effective words) took 0.3s, 248043 effective words/s\n",
      "2023-12-06 14:49:54,328 : INFO : EPOCH 26: training on 99524 raw words (62664 effective words) took 0.3s, 247937 effective words/s\n",
      "2023-12-06 14:49:54,586 : INFO : EPOCH 27: training on 99524 raw words (62865 effective words) took 0.3s, 248374 effective words/s\n",
      "2023-12-06 14:49:54,842 : INFO : EPOCH 28: training on 99524 raw words (62853 effective words) took 0.3s, 250037 effective words/s\n",
      "2023-12-06 14:49:55,095 : INFO : EPOCH 29: training on 99524 raw words (62627 effective words) took 0.2s, 251013 effective words/s\n",
      "2023-12-06 14:49:55,096 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1882343 effective words) took 7.8s, 242638 effective words/s', 'datetime': '2023-12-06T14:49:55.096437', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:49:55,097 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:49:55.097467', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 48%|     | 231/486 [36:17<43:11, 10.16s/it]2023-12-06 14:49:58,639 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:49:58,640 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:49:58,659 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:49:58,659 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:49:58,667 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:49:58.667154', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:49:58,668 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:49:58.668154', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:49:58,673 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:49:58,674 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:49:58,674 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:49:58.674154', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:49:58,682 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:49:58,683 : INFO : resetting layer weights\n",
      "2023-12-06 14:49:58,687 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:49:58.687802', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:49:58,933 : INFO : EPOCH 0: training on 99524 raw words (62535 effective words) took 0.2s, 259658 effective words/s\n",
      "2023-12-06 14:49:59,172 : INFO : EPOCH 1: training on 99524 raw words (62689 effective words) took 0.2s, 269488 effective words/s\n",
      "2023-12-06 14:49:59,412 : INFO : EPOCH 2: training on 99524 raw words (62769 effective words) took 0.2s, 268415 effective words/s\n",
      "2023-12-06 14:49:59,648 : INFO : EPOCH 3: training on 99524 raw words (62742 effective words) took 0.2s, 269293 effective words/s\n",
      "2023-12-06 14:49:59,880 : INFO : EPOCH 4: training on 99524 raw words (62725 effective words) took 0.2s, 276150 effective words/s\n",
      "2023-12-06 14:50:00,122 : INFO : EPOCH 5: training on 99524 raw words (62705 effective words) took 0.2s, 263428 effective words/s\n",
      "2023-12-06 14:50:00,358 : INFO : EPOCH 6: training on 99524 raw words (62604 effective words) took 0.2s, 270928 effective words/s\n",
      "2023-12-06 14:50:00,595 : INFO : EPOCH 7: training on 99524 raw words (62699 effective words) took 0.2s, 270294 effective words/s\n",
      "2023-12-06 14:50:00,831 : INFO : EPOCH 8: training on 99524 raw words (62576 effective words) took 0.2s, 270913 effective words/s\n",
      "2023-12-06 14:50:01,073 : INFO : EPOCH 9: training on 99524 raw words (62847 effective words) took 0.2s, 262787 effective words/s\n",
      "2023-12-06 14:50:01,309 : INFO : EPOCH 10: training on 99524 raw words (62805 effective words) took 0.2s, 272127 effective words/s\n",
      "2023-12-06 14:50:01,545 : INFO : EPOCH 11: training on 99524 raw words (62746 effective words) took 0.2s, 270683 effective words/s\n",
      "2023-12-06 14:50:01,780 : INFO : EPOCH 12: training on 99524 raw words (62759 effective words) took 0.2s, 271895 effective words/s\n",
      "2023-12-06 14:50:02,019 : INFO : EPOCH 13: training on 99524 raw words (62735 effective words) took 0.2s, 267737 effective words/s\n",
      "2023-12-06 14:50:02,255 : INFO : EPOCH 14: training on 99524 raw words (62655 effective words) took 0.2s, 271083 effective words/s\n",
      "2023-12-06 14:50:02,492 : INFO : EPOCH 15: training on 99524 raw words (62657 effective words) took 0.2s, 268836 effective words/s\n",
      "2023-12-06 14:50:02,733 : INFO : EPOCH 16: training on 99524 raw words (62752 effective words) took 0.2s, 265000 effective words/s\n",
      "2023-12-06 14:50:02,963 : INFO : EPOCH 17: training on 99524 raw words (62609 effective words) took 0.2s, 277218 effective words/s\n",
      "2023-12-06 14:50:03,202 : INFO : EPOCH 18: training on 99524 raw words (62656 effective words) took 0.2s, 267242 effective words/s\n",
      "2023-12-06 14:50:03,439 : INFO : EPOCH 19: training on 99524 raw words (62568 effective words) took 0.2s, 268821 effective words/s\n",
      "2023-12-06 14:50:03,688 : INFO : EPOCH 20: training on 99524 raw words (62704 effective words) took 0.2s, 256755 effective words/s\n",
      "2023-12-06 14:50:03,927 : INFO : EPOCH 21: training on 99524 raw words (62726 effective words) took 0.2s, 267267 effective words/s\n",
      "2023-12-06 14:50:04,169 : INFO : EPOCH 22: training on 99524 raw words (62749 effective words) took 0.2s, 265276 effective words/s\n",
      "2023-12-06 14:50:04,399 : INFO : EPOCH 23: training on 99524 raw words (62620 effective words) took 0.2s, 276019 effective words/s\n",
      "2023-12-06 14:50:04,635 : INFO : EPOCH 24: training on 99524 raw words (62651 effective words) took 0.2s, 269461 effective words/s\n",
      "2023-12-06 14:50:04,870 : INFO : EPOCH 25: training on 99524 raw words (62752 effective words) took 0.2s, 273277 effective words/s\n",
      "2023-12-06 14:50:05,106 : INFO : EPOCH 26: training on 99524 raw words (62711 effective words) took 0.2s, 270266 effective words/s\n",
      "2023-12-06 14:50:05,340 : INFO : EPOCH 27: training on 99524 raw words (62664 effective words) took 0.2s, 272911 effective words/s\n",
      "2023-12-06 14:50:05,570 : INFO : EPOCH 28: training on 99524 raw words (62725 effective words) took 0.2s, 278130 effective words/s\n",
      "2023-12-06 14:50:05,814 : INFO : EPOCH 29: training on 99524 raw words (62722 effective words) took 0.2s, 261735 effective words/s\n",
      "2023-12-06 14:50:06,057 : INFO : EPOCH 30: training on 99524 raw words (62539 effective words) took 0.2s, 263079 effective words/s\n",
      "2023-12-06 14:50:06,290 : INFO : EPOCH 31: training on 99524 raw words (62648 effective words) took 0.2s, 273616 effective words/s\n",
      "2023-12-06 14:50:06,525 : INFO : EPOCH 32: training on 99524 raw words (62832 effective words) took 0.2s, 270961 effective words/s\n",
      "2023-12-06 14:50:06,761 : INFO : EPOCH 33: training on 99524 raw words (62626 effective words) took 0.2s, 270474 effective words/s\n",
      "2023-12-06 14:50:06,998 : INFO : EPOCH 34: training on 99524 raw words (62804 effective words) took 0.2s, 270501 effective words/s\n",
      "2023-12-06 14:50:07,230 : INFO : EPOCH 35: training on 99524 raw words (62736 effective words) took 0.2s, 276024 effective words/s\n",
      "2023-12-06 14:50:07,465 : INFO : EPOCH 36: training on 99524 raw words (62735 effective words) took 0.2s, 272474 effective words/s\n",
      "2023-12-06 14:50:07,701 : INFO : EPOCH 37: training on 99524 raw words (62577 effective words) took 0.2s, 270033 effective words/s\n",
      "2023-12-06 14:50:07,942 : INFO : EPOCH 38: training on 99524 raw words (62804 effective words) took 0.2s, 264613 effective words/s\n",
      "2023-12-06 14:50:08,181 : INFO : EPOCH 39: training on 99524 raw words (62720 effective words) took 0.2s, 268370 effective words/s\n",
      "2023-12-06 14:50:08,414 : INFO : EPOCH 40: training on 99524 raw words (62664 effective words) took 0.2s, 275414 effective words/s\n",
      "2023-12-06 14:50:08,652 : INFO : EPOCH 41: training on 99524 raw words (62650 effective words) took 0.2s, 266592 effective words/s\n",
      "2023-12-06 14:50:08,889 : INFO : EPOCH 42: training on 99524 raw words (62809 effective words) took 0.2s, 271521 effective words/s\n",
      "2023-12-06 14:50:09,118 : INFO : EPOCH 43: training on 99524 raw words (62566 effective words) took 0.2s, 277690 effective words/s\n",
      "2023-12-06 14:50:09,356 : INFO : EPOCH 44: training on 99524 raw words (62809 effective words) took 0.2s, 269483 effective words/s\n",
      "2023-12-06 14:50:09,590 : INFO : EPOCH 45: training on 99524 raw words (62742 effective words) took 0.2s, 272755 effective words/s\n",
      "2023-12-06 14:50:09,822 : INFO : EPOCH 46: training on 99524 raw words (62714 effective words) took 0.2s, 274907 effective words/s\n",
      "2023-12-06 14:50:10,058 : INFO : EPOCH 47: training on 99524 raw words (62666 effective words) took 0.2s, 270521 effective words/s\n",
      "2023-12-06 14:50:10,296 : INFO : EPOCH 48: training on 99524 raw words (62631 effective words) took 0.2s, 268258 effective words/s\n",
      "2023-12-06 14:50:10,550 : INFO : EPOCH 49: training on 99524 raw words (62705 effective words) took 0.3s, 250809 effective words/s\n",
      "2023-12-06 14:50:10,551 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3134834 effective words) took 11.9s, 264247 effective words/s', 'datetime': '2023-12-06T14:50:10.551742', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:50:10,551 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:50:10.551742', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 48%|     | 232/486 [36:33<50:05, 11.83s/it]2023-12-06 14:50:14,368 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:50:14,368 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:50:14,391 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:50:14,391 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:50:14,397 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:50:14.397109', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:50:14,397 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:50:14.397109', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:50:14,403 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:50:14,403 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:50:14,404 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:50:14.404645', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:50:14,413 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:50:14,414 : INFO : resetting layer weights\n",
      "2023-12-06 14:50:14,416 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:50:14.416070', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:50:14,691 : INFO : EPOCH 0: training on 99524 raw words (62628 effective words) took 0.3s, 231846 effective words/s\n",
      "2023-12-06 14:50:14,943 : INFO : EPOCH 1: training on 99524 raw words (62808 effective words) took 0.2s, 254335 effective words/s\n",
      "2023-12-06 14:50:15,191 : INFO : EPOCH 2: training on 99524 raw words (62900 effective words) took 0.2s, 258868 effective words/s\n",
      "2023-12-06 14:50:15,444 : INFO : EPOCH 3: training on 99524 raw words (62735 effective words) took 0.2s, 252771 effective words/s\n",
      "2023-12-06 14:50:15,693 : INFO : EPOCH 4: training on 99524 raw words (62770 effective words) took 0.2s, 256335 effective words/s\n",
      "2023-12-06 14:50:15,938 : INFO : EPOCH 5: training on 99524 raw words (62941 effective words) took 0.2s, 260720 effective words/s\n",
      "2023-12-06 14:50:16,187 : INFO : EPOCH 6: training on 99524 raw words (62724 effective words) took 0.2s, 257472 effective words/s\n",
      "2023-12-06 14:50:16,438 : INFO : EPOCH 7: training on 99524 raw words (62712 effective words) took 0.2s, 253978 effective words/s\n",
      "2023-12-06 14:50:16,681 : INFO : EPOCH 8: training on 99524 raw words (62547 effective words) took 0.2s, 262244 effective words/s\n",
      "2023-12-06 14:50:16,924 : INFO : EPOCH 9: training on 99524 raw words (62677 effective words) took 0.2s, 262180 effective words/s\n",
      "2023-12-06 14:50:17,178 : INFO : EPOCH 10: training on 99524 raw words (62699 effective words) took 0.2s, 251999 effective words/s\n",
      "2023-12-06 14:50:17,421 : INFO : EPOCH 11: training on 99524 raw words (62601 effective words) took 0.2s, 261956 effective words/s\n",
      "2023-12-06 14:50:17,672 : INFO : EPOCH 12: training on 99524 raw words (62736 effective words) took 0.2s, 255057 effective words/s\n",
      "2023-12-06 14:50:17,926 : INFO : EPOCH 13: training on 99524 raw words (62621 effective words) took 0.2s, 250685 effective words/s\n",
      "2023-12-06 14:50:18,175 : INFO : EPOCH 14: training on 99524 raw words (62885 effective words) took 0.2s, 256095 effective words/s\n",
      "2023-12-06 14:50:18,427 : INFO : EPOCH 15: training on 99524 raw words (62825 effective words) took 0.2s, 254411 effective words/s\n",
      "2023-12-06 14:50:18,674 : INFO : EPOCH 16: training on 99524 raw words (62608 effective words) took 0.2s, 258199 effective words/s\n",
      "2023-12-06 14:50:18,921 : INFO : EPOCH 17: training on 99524 raw words (62738 effective words) took 0.2s, 258584 effective words/s\n",
      "2023-12-06 14:50:19,170 : INFO : EPOCH 18: training on 99524 raw words (62634 effective words) took 0.2s, 256649 effective words/s\n",
      "2023-12-06 14:50:19,417 : INFO : EPOCH 19: training on 99524 raw words (62781 effective words) took 0.2s, 258319 effective words/s\n",
      "2023-12-06 14:50:19,668 : INFO : EPOCH 20: training on 99524 raw words (62609 effective words) took 0.2s, 253927 effective words/s\n",
      "2023-12-06 14:50:19,916 : INFO : EPOCH 21: training on 99524 raw words (62683 effective words) took 0.2s, 257858 effective words/s\n",
      "2023-12-06 14:50:20,165 : INFO : EPOCH 22: training on 99524 raw words (62742 effective words) took 0.2s, 256210 effective words/s\n",
      "2023-12-06 14:50:20,414 : INFO : EPOCH 23: training on 99524 raw words (62673 effective words) took 0.2s, 256265 effective words/s\n",
      "2023-12-06 14:50:20,659 : INFO : EPOCH 24: training on 99524 raw words (62599 effective words) took 0.2s, 260752 effective words/s\n",
      "2023-12-06 14:50:20,908 : INFO : EPOCH 25: training on 99524 raw words (62697 effective words) took 0.2s, 255584 effective words/s\n",
      "2023-12-06 14:50:21,158 : INFO : EPOCH 26: training on 99524 raw words (62739 effective words) took 0.2s, 255106 effective words/s\n",
      "2023-12-06 14:50:21,403 : INFO : EPOCH 27: training on 99524 raw words (62602 effective words) took 0.2s, 260810 effective words/s\n",
      "2023-12-06 14:50:21,652 : INFO : EPOCH 28: training on 99524 raw words (62637 effective words) took 0.2s, 255936 effective words/s\n",
      "2023-12-06 14:50:21,903 : INFO : EPOCH 29: training on 99524 raw words (62780 effective words) took 0.2s, 253894 effective words/s\n",
      "2023-12-06 14:50:22,161 : INFO : EPOCH 30: training on 99524 raw words (62535 effective words) took 0.3s, 247483 effective words/s\n",
      "2023-12-06 14:50:22,411 : INFO : EPOCH 31: training on 99524 raw words (62586 effective words) took 0.2s, 255210 effective words/s\n",
      "2023-12-06 14:50:22,657 : INFO : EPOCH 32: training on 99524 raw words (62703 effective words) took 0.2s, 258826 effective words/s\n",
      "2023-12-06 14:50:22,909 : INFO : EPOCH 33: training on 99524 raw words (62634 effective words) took 0.2s, 252353 effective words/s\n",
      "2023-12-06 14:50:23,162 : INFO : EPOCH 34: training on 99524 raw words (62487 effective words) took 0.2s, 251862 effective words/s\n",
      "2023-12-06 14:50:23,410 : INFO : EPOCH 35: training on 99524 raw words (62577 effective words) took 0.2s, 256145 effective words/s\n",
      "2023-12-06 14:50:23,660 : INFO : EPOCH 36: training on 99524 raw words (62647 effective words) took 0.2s, 255601 effective words/s\n",
      "2023-12-06 14:50:23,910 : INFO : EPOCH 37: training on 99524 raw words (62792 effective words) took 0.2s, 255976 effective words/s\n",
      "2023-12-06 14:50:24,157 : INFO : EPOCH 38: training on 99524 raw words (62642 effective words) took 0.2s, 257421 effective words/s\n",
      "2023-12-06 14:50:24,411 : INFO : EPOCH 39: training on 99524 raw words (62786 effective words) took 0.3s, 250736 effective words/s\n",
      "2023-12-06 14:50:24,658 : INFO : EPOCH 40: training on 99524 raw words (62644 effective words) took 0.2s, 258978 effective words/s\n",
      "2023-12-06 14:50:24,909 : INFO : EPOCH 41: training on 99524 raw words (62759 effective words) took 0.2s, 253651 effective words/s\n",
      "2023-12-06 14:50:25,159 : INFO : EPOCH 42: training on 99524 raw words (62836 effective words) took 0.2s, 256458 effective words/s\n",
      "2023-12-06 14:50:25,409 : INFO : EPOCH 43: training on 99524 raw words (62837 effective words) took 0.2s, 255182 effective words/s\n",
      "2023-12-06 14:50:25,658 : INFO : EPOCH 44: training on 99524 raw words (62521 effective words) took 0.2s, 255582 effective words/s\n",
      "2023-12-06 14:50:25,907 : INFO : EPOCH 45: training on 99524 raw words (62694 effective words) took 0.2s, 257275 effective words/s\n",
      "2023-12-06 14:50:26,150 : INFO : EPOCH 46: training on 99524 raw words (62769 effective words) took 0.2s, 262801 effective words/s\n",
      "2023-12-06 14:50:26,403 : INFO : EPOCH 47: training on 99524 raw words (62837 effective words) took 0.2s, 251849 effective words/s\n",
      "2023-12-06 14:50:26,650 : INFO : EPOCH 48: training on 99524 raw words (62735 effective words) took 0.2s, 258285 effective words/s\n",
      "2023-12-06 14:50:26,901 : INFO : EPOCH 49: training on 99524 raw words (62715 effective words) took 0.2s, 254562 effective words/s\n",
      "2023-12-06 14:50:26,902 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3135067 effective words) took 12.5s, 251098 effective words/s', 'datetime': '2023-12-06T14:50:26.902541', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:50:26,902 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:50:26.902541', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 48%|     | 233/486 [36:49<55:48, 13.23s/it]2023-12-06 14:50:30,872 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:50:30,873 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:50:30,893 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:50:30,895 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:50:30,900 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:50:30.900153', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:50:30,900 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:50:30.900153', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:50:30,905 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:50:30,906 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:50:30,906 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:50:30.906153', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:50:30,914 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:50:30,915 : INFO : resetting layer weights\n",
      "2023-12-06 14:50:30,917 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:50:30.917153', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:50:31,183 : INFO : EPOCH 0: training on 99524 raw words (62642 effective words) took 0.3s, 239533 effective words/s\n",
      "2023-12-06 14:50:31,446 : INFO : EPOCH 1: training on 99524 raw words (62601 effective words) took 0.3s, 245293 effective words/s\n",
      "2023-12-06 14:50:31,706 : INFO : EPOCH 2: training on 99524 raw words (62813 effective words) took 0.3s, 244991 effective words/s\n",
      "2023-12-06 14:50:31,977 : INFO : EPOCH 3: training on 99524 raw words (62490 effective words) took 0.3s, 234754 effective words/s\n",
      "2023-12-06 14:50:32,238 : INFO : EPOCH 4: training on 99524 raw words (62656 effective words) took 0.3s, 244265 effective words/s\n",
      "2023-12-06 14:50:32,494 : INFO : EPOCH 5: training on 99524 raw words (62811 effective words) took 0.3s, 249626 effective words/s\n",
      "2023-12-06 14:50:32,751 : INFO : EPOCH 6: training on 99524 raw words (62725 effective words) took 0.3s, 248256 effective words/s\n",
      "2023-12-06 14:50:33,013 : INFO : EPOCH 7: training on 99524 raw words (62773 effective words) took 0.3s, 244579 effective words/s\n",
      "2023-12-06 14:50:33,271 : INFO : EPOCH 8: training on 99524 raw words (62527 effective words) took 0.3s, 245824 effective words/s\n",
      "2023-12-06 14:50:33,528 : INFO : EPOCH 9: training on 99524 raw words (62788 effective words) took 0.3s, 249527 effective words/s\n",
      "2023-12-06 14:50:33,789 : INFO : EPOCH 10: training on 99524 raw words (62648 effective words) took 0.3s, 244379 effective words/s\n",
      "2023-12-06 14:50:34,050 : INFO : EPOCH 11: training on 99524 raw words (62811 effective words) took 0.3s, 244508 effective words/s\n",
      "2023-12-06 14:50:34,309 : INFO : EPOCH 12: training on 99524 raw words (62709 effective words) took 0.3s, 247593 effective words/s\n",
      "2023-12-06 14:50:34,570 : INFO : EPOCH 13: training on 99524 raw words (62593 effective words) took 0.3s, 243870 effective words/s\n",
      "2023-12-06 14:50:34,829 : INFO : EPOCH 14: training on 99524 raw words (62744 effective words) took 0.3s, 246009 effective words/s\n",
      "2023-12-06 14:50:35,086 : INFO : EPOCH 15: training on 99524 raw words (62666 effective words) took 0.3s, 248474 effective words/s\n",
      "2023-12-06 14:50:35,347 : INFO : EPOCH 16: training on 99524 raw words (62716 effective words) took 0.3s, 245220 effective words/s\n",
      "2023-12-06 14:50:35,604 : INFO : EPOCH 17: training on 99524 raw words (62798 effective words) took 0.3s, 249041 effective words/s\n",
      "2023-12-06 14:50:35,865 : INFO : EPOCH 18: training on 99524 raw words (62687 effective words) took 0.3s, 242798 effective words/s\n",
      "2023-12-06 14:50:36,125 : INFO : EPOCH 19: training on 99524 raw words (62816 effective words) took 0.3s, 247445 effective words/s\n",
      "2023-12-06 14:50:36,380 : INFO : EPOCH 20: training on 99524 raw words (62714 effective words) took 0.3s, 248630 effective words/s\n",
      "2023-12-06 14:50:36,637 : INFO : EPOCH 21: training on 99524 raw words (62567 effective words) took 0.3s, 248713 effective words/s\n",
      "2023-12-06 14:50:36,895 : INFO : EPOCH 22: training on 99524 raw words (62744 effective words) took 0.3s, 247566 effective words/s\n",
      "2023-12-06 14:50:37,157 : INFO : EPOCH 23: training on 99524 raw words (62742 effective words) took 0.3s, 244015 effective words/s\n",
      "2023-12-06 14:50:37,410 : INFO : EPOCH 24: training on 99524 raw words (62734 effective words) took 0.2s, 251199 effective words/s\n",
      "2023-12-06 14:50:37,670 : INFO : EPOCH 25: training on 99524 raw words (62714 effective words) took 0.3s, 245634 effective words/s\n",
      "2023-12-06 14:50:37,927 : INFO : EPOCH 26: training on 99524 raw words (62816 effective words) took 0.3s, 249383 effective words/s\n",
      "2023-12-06 14:50:38,191 : INFO : EPOCH 27: training on 99524 raw words (62774 effective words) took 0.3s, 242099 effective words/s\n",
      "2023-12-06 14:50:38,450 : INFO : EPOCH 28: training on 99524 raw words (62739 effective words) took 0.3s, 246573 effective words/s\n",
      "2023-12-06 14:50:38,709 : INFO : EPOCH 29: training on 99524 raw words (62679 effective words) took 0.3s, 246511 effective words/s\n",
      "2023-12-06 14:50:38,961 : INFO : EPOCH 30: training on 99524 raw words (62614 effective words) took 0.2s, 252086 effective words/s\n",
      "2023-12-06 14:50:39,222 : INFO : EPOCH 31: training on 99524 raw words (62690 effective words) took 0.3s, 244572 effective words/s\n",
      "2023-12-06 14:50:39,483 : INFO : EPOCH 32: training on 99524 raw words (62697 effective words) took 0.3s, 244812 effective words/s\n",
      "2023-12-06 14:50:39,741 : INFO : EPOCH 33: training on 99524 raw words (62589 effective words) took 0.3s, 246285 effective words/s\n",
      "2023-12-06 14:50:40,000 : INFO : EPOCH 34: training on 99524 raw words (62600 effective words) took 0.3s, 246059 effective words/s\n",
      "2023-12-06 14:50:40,263 : INFO : EPOCH 35: training on 99524 raw words (62595 effective words) took 0.3s, 242800 effective words/s\n",
      "2023-12-06 14:50:40,518 : INFO : EPOCH 36: training on 99524 raw words (62831 effective words) took 0.3s, 250667 effective words/s\n",
      "2023-12-06 14:50:40,773 : INFO : EPOCH 37: training on 99524 raw words (62573 effective words) took 0.3s, 249218 effective words/s\n",
      "2023-12-06 14:50:41,029 : INFO : EPOCH 38: training on 99524 raw words (62693 effective words) took 0.3s, 249702 effective words/s\n",
      "2023-12-06 14:50:41,283 : INFO : EPOCH 39: training on 99524 raw words (62779 effective words) took 0.2s, 252245 effective words/s\n",
      "2023-12-06 14:50:41,540 : INFO : EPOCH 40: training on 99524 raw words (62783 effective words) took 0.3s, 247860 effective words/s\n",
      "2023-12-06 14:50:41,795 : INFO : EPOCH 41: training on 99524 raw words (62660 effective words) took 0.3s, 249838 effective words/s\n",
      "2023-12-06 14:50:42,050 : INFO : EPOCH 42: training on 99524 raw words (62709 effective words) took 0.3s, 250508 effective words/s\n",
      "2023-12-06 14:50:42,310 : INFO : EPOCH 43: training on 99524 raw words (62630 effective words) took 0.3s, 245223 effective words/s\n",
      "2023-12-06 14:50:42,576 : INFO : EPOCH 44: training on 99524 raw words (62625 effective words) took 0.3s, 239764 effective words/s\n",
      "2023-12-06 14:50:42,832 : INFO : EPOCH 45: training on 99524 raw words (62751 effective words) took 0.3s, 249754 effective words/s\n",
      "2023-12-06 14:50:43,090 : INFO : EPOCH 46: training on 99524 raw words (62715 effective words) took 0.3s, 246374 effective words/s\n",
      "2023-12-06 14:50:43,351 : INFO : EPOCH 47: training on 99524 raw words (62769 effective words) took 0.3s, 245125 effective words/s\n",
      "2023-12-06 14:50:43,608 : INFO : EPOCH 48: training on 99524 raw words (62621 effective words) took 0.3s, 248012 effective words/s\n",
      "2023-12-06 14:50:43,864 : INFO : EPOCH 49: training on 99524 raw words (62676 effective words) took 0.3s, 249874 effective words/s\n",
      "2023-12-06 14:50:43,865 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3134837 effective words) took 12.9s, 242121 effective words/s', 'datetime': '2023-12-06T14:50:43.865937', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:50:43,865 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:50:43.865937', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 48%|     | 234/486 [37:06<1:00:41, 14.45s/it]2023-12-06 14:50:48,163 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:50:48,164 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:50:48,183 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:50:48,184 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:50:48,188 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:50:48.188493', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:50:48,189 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:50:48.189493', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:50:48,194 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:50:48,195 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:50:48,195 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:50:48.195004', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:50:48,202 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:50:48,203 : INFO : resetting layer weights\n",
      "2023-12-06 14:50:48,205 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:50:48.205086', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:50:48,447 : INFO : EPOCH 0: training on 99524 raw words (60284 effective words) took 0.2s, 252761 effective words/s\n",
      "2023-12-06 14:50:48,684 : INFO : EPOCH 1: training on 99524 raw words (60438 effective words) took 0.2s, 259572 effective words/s\n",
      "2023-12-06 14:50:48,921 : INFO : EPOCH 2: training on 99524 raw words (60534 effective words) took 0.2s, 260756 effective words/s\n",
      "2023-12-06 14:50:49,157 : INFO : EPOCH 3: training on 99524 raw words (60599 effective words) took 0.2s, 262064 effective words/s\n",
      "2023-12-06 14:50:49,388 : INFO : EPOCH 4: training on 99524 raw words (60295 effective words) took 0.2s, 265650 effective words/s\n",
      "2023-12-06 14:50:49,630 : INFO : EPOCH 5: training on 99524 raw words (60231 effective words) took 0.2s, 254685 effective words/s\n",
      "2023-12-06 14:50:49,863 : INFO : EPOCH 6: training on 99524 raw words (60404 effective words) took 0.2s, 264129 effective words/s\n",
      "2023-12-06 14:50:50,097 : INFO : EPOCH 7: training on 99524 raw words (60216 effective words) took 0.2s, 260875 effective words/s\n",
      "2023-12-06 14:50:50,336 : INFO : EPOCH 8: training on 99524 raw words (60454 effective words) took 0.2s, 258874 effective words/s\n",
      "2023-12-06 14:50:50,579 : INFO : EPOCH 9: training on 99524 raw words (60385 effective words) took 0.2s, 253028 effective words/s\n",
      "2023-12-06 14:50:50,579 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603840 effective words) took 2.4s, 254365 effective words/s', 'datetime': '2023-12-06T14:50:50.579296', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:50:50,580 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:50:50.580297', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 48%|     | 235/486 [37:11<48:42, 11.64s/it]  2023-12-06 14:50:53,253 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:50:53,253 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:50:53,282 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:50:53,283 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:50:53,291 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:50:53.291311', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:50:53,291 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:50:53.291311', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:50:53,297 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:50:53,298 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:50:53,299 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:50:53.299239', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:50:53,308 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:50:53,309 : INFO : resetting layer weights\n",
      "2023-12-06 14:50:53,311 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:50:53.311748', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:50:53,565 : INFO : EPOCH 0: training on 99524 raw words (60443 effective words) took 0.2s, 243064 effective words/s\n",
      "2023-12-06 14:50:53,814 : INFO : EPOCH 1: training on 99524 raw words (60282 effective words) took 0.2s, 247419 effective words/s\n",
      "2023-12-06 14:50:54,060 : INFO : EPOCH 2: training on 99524 raw words (60400 effective words) took 0.2s, 250613 effective words/s\n",
      "2023-12-06 14:50:54,307 : INFO : EPOCH 3: training on 99524 raw words (60522 effective words) took 0.2s, 250847 effective words/s\n",
      "2023-12-06 14:50:54,552 : INFO : EPOCH 4: training on 99524 raw words (60306 effective words) took 0.2s, 250171 effective words/s\n",
      "2023-12-06 14:50:54,797 : INFO : EPOCH 5: training on 99524 raw words (60352 effective words) took 0.2s, 251051 effective words/s\n",
      "2023-12-06 14:50:55,041 : INFO : EPOCH 6: training on 99524 raw words (60429 effective words) took 0.2s, 252051 effective words/s\n",
      "2023-12-06 14:50:55,284 : INFO : EPOCH 7: training on 99524 raw words (60444 effective words) took 0.2s, 254047 effective words/s\n",
      "2023-12-06 14:50:55,524 : INFO : EPOCH 8: training on 99524 raw words (60442 effective words) took 0.2s, 255532 effective words/s\n",
      "2023-12-06 14:50:55,774 : INFO : EPOCH 9: training on 99524 raw words (60416 effective words) took 0.2s, 245188 effective words/s\n",
      "2023-12-06 14:50:55,776 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604036 effective words) took 2.5s, 245189 effective words/s', 'datetime': '2023-12-06T14:50:55.776153', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:50:55,777 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:50:55.777171', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 49%|     | 236/486 [37:17<40:30,  9.72s/it]2023-12-06 14:50:58,494 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:50:58,495 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:50:58,519 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:50:58,520 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:50:58,524 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:50:58.524793', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:50:58,524 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:50:58.524793', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:50:58,531 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:50:58,532 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:50:58,532 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:50:58.532069', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:50:58,539 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:50:58,540 : INFO : resetting layer weights\n",
      "2023-12-06 14:50:58,543 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:50:58.543865', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:50:58,814 : INFO : EPOCH 0: training on 99524 raw words (60412 effective words) took 0.3s, 226162 effective words/s\n",
      "2023-12-06 14:50:59,080 : INFO : EPOCH 1: training on 99524 raw words (60399 effective words) took 0.3s, 230840 effective words/s\n",
      "2023-12-06 14:50:59,349 : INFO : EPOCH 2: training on 99524 raw words (60536 effective words) took 0.3s, 230284 effective words/s\n",
      "2023-12-06 14:50:59,608 : INFO : EPOCH 3: training on 99524 raw words (60394 effective words) took 0.3s, 237694 effective words/s\n",
      "2023-12-06 14:50:59,864 : INFO : EPOCH 4: training on 99524 raw words (60448 effective words) took 0.3s, 239647 effective words/s\n",
      "2023-12-06 14:51:00,119 : INFO : EPOCH 5: training on 99524 raw words (60328 effective words) took 0.3s, 240445 effective words/s\n",
      "2023-12-06 14:51:00,379 : INFO : EPOCH 6: training on 99524 raw words (60548 effective words) took 0.3s, 236978 effective words/s\n",
      "2023-12-06 14:51:00,638 : INFO : EPOCH 7: training on 99524 raw words (60544 effective words) took 0.3s, 237559 effective words/s\n",
      "2023-12-06 14:51:00,896 : INFO : EPOCH 8: training on 99524 raw words (60435 effective words) took 0.3s, 238312 effective words/s\n",
      "2023-12-06 14:51:01,160 : INFO : EPOCH 9: training on 99524 raw words (60384 effective words) took 0.3s, 232829 effective words/s\n",
      "2023-12-06 14:51:01,161 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604428 effective words) took 2.6s, 230918 effective words/s', 'datetime': '2023-12-06T14:51:01.161405', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:51:01,162 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:51:01.162541', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 49%|     | 237/486 [37:22<35:01,  8.44s/it]2023-12-06 14:51:03,940 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:51:03,941 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:51:03,971 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:51:03,971 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:51:03,977 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:51:03.977309', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:51:03,978 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:51:03.978309', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:51:03,982 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:51:03,983 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:51:03,983 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:51:03.983310', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:51:03,993 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:51:03,995 : INFO : resetting layer weights\n",
      "2023-12-06 14:51:03,996 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:51:03.996980', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:51:04,250 : INFO : EPOCH 0: training on 99524 raw words (60432 effective words) took 0.2s, 242249 effective words/s\n",
      "2023-12-06 14:51:04,491 : INFO : EPOCH 1: training on 99524 raw words (60454 effective words) took 0.2s, 255926 effective words/s\n",
      "2023-12-06 14:51:04,732 : INFO : EPOCH 2: training on 99524 raw words (60490 effective words) took 0.2s, 255607 effective words/s\n",
      "2023-12-06 14:51:04,969 : INFO : EPOCH 3: training on 99524 raw words (60352 effective words) took 0.2s, 259721 effective words/s\n",
      "2023-12-06 14:51:05,200 : INFO : EPOCH 4: training on 99524 raw words (60401 effective words) took 0.2s, 266253 effective words/s\n",
      "2023-12-06 14:51:05,438 : INFO : EPOCH 5: training on 99524 raw words (60391 effective words) took 0.2s, 259088 effective words/s\n",
      "2023-12-06 14:51:05,676 : INFO : EPOCH 6: training on 99524 raw words (60381 effective words) took 0.2s, 257507 effective words/s\n",
      "2023-12-06 14:51:05,913 : INFO : EPOCH 7: training on 99524 raw words (60388 effective words) took 0.2s, 260111 effective words/s\n",
      "2023-12-06 14:51:06,157 : INFO : EPOCH 8: training on 99524 raw words (60381 effective words) took 0.2s, 252818 effective words/s\n",
      "2023-12-06 14:51:06,392 : INFO : EPOCH 9: training on 99524 raw words (60494 effective words) took 0.2s, 261837 effective words/s\n",
      "2023-12-06 14:51:06,622 : INFO : EPOCH 10: training on 99524 raw words (60350 effective words) took 0.2s, 266985 effective words/s\n",
      "2023-12-06 14:51:06,857 : INFO : EPOCH 11: training on 99524 raw words (60530 effective words) took 0.2s, 263412 effective words/s\n",
      "2023-12-06 14:51:07,094 : INFO : EPOCH 12: training on 99524 raw words (60372 effective words) took 0.2s, 260234 effective words/s\n",
      "2023-12-06 14:51:07,325 : INFO : EPOCH 13: training on 99524 raw words (60415 effective words) took 0.2s, 265944 effective words/s\n",
      "2023-12-06 14:51:07,564 : INFO : EPOCH 14: training on 99524 raw words (60327 effective words) took 0.2s, 257029 effective words/s\n",
      "2023-12-06 14:51:07,801 : INFO : EPOCH 15: training on 99524 raw words (60452 effective words) took 0.2s, 259470 effective words/s\n",
      "2023-12-06 14:51:08,041 : INFO : EPOCH 16: training on 99524 raw words (60380 effective words) took 0.2s, 256475 effective words/s\n",
      "2023-12-06 14:51:08,280 : INFO : EPOCH 17: training on 99524 raw words (60350 effective words) took 0.2s, 257063 effective words/s\n",
      "2023-12-06 14:51:08,515 : INFO : EPOCH 18: training on 99524 raw words (60308 effective words) took 0.2s, 261483 effective words/s\n",
      "2023-12-06 14:51:08,746 : INFO : EPOCH 19: training on 99524 raw words (60553 effective words) took 0.2s, 267972 effective words/s\n",
      "2023-12-06 14:51:08,981 : INFO : EPOCH 20: training on 99524 raw words (60229 effective words) took 0.2s, 260967 effective words/s\n",
      "2023-12-06 14:51:09,216 : INFO : EPOCH 21: training on 99524 raw words (60236 effective words) took 0.2s, 260698 effective words/s\n",
      "2023-12-06 14:51:09,458 : INFO : EPOCH 22: training on 99524 raw words (60385 effective words) took 0.2s, 254822 effective words/s\n",
      "2023-12-06 14:51:09,686 : INFO : EPOCH 23: training on 99524 raw words (60188 effective words) took 0.2s, 268855 effective words/s\n",
      "2023-12-06 14:51:09,922 : INFO : EPOCH 24: training on 99524 raw words (60415 effective words) took 0.2s, 261099 effective words/s\n",
      "2023-12-06 14:51:10,155 : INFO : EPOCH 25: training on 99524 raw words (60348 effective words) took 0.2s, 263169 effective words/s\n",
      "2023-12-06 14:51:10,398 : INFO : EPOCH 26: training on 99524 raw words (60376 effective words) took 0.2s, 253229 effective words/s\n",
      "2023-12-06 14:51:10,628 : INFO : EPOCH 27: training on 99524 raw words (60584 effective words) took 0.2s, 267844 effective words/s\n",
      "2023-12-06 14:51:10,861 : INFO : EPOCH 28: training on 99524 raw words (60272 effective words) took 0.2s, 263300 effective words/s\n",
      "2023-12-06 14:51:11,104 : INFO : EPOCH 29: training on 99524 raw words (60326 effective words) took 0.2s, 252327 effective words/s\n",
      "2023-12-06 14:51:11,105 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811560 effective words) took 7.1s, 254854 effective words/s', 'datetime': '2023-12-06T14:51:11.105912', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:51:11,106 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:51:11.106912', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 49%|     | 238/486 [37:32<37:14,  9.01s/it]2023-12-06 14:51:14,275 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:51:14,275 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:51:14,295 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:51:14,296 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:51:14,300 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:51:14.300375', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:51:14,301 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:51:14.301383', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:51:14,306 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:51:14,306 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:51:14,307 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:51:14.307025', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:51:14,314 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:51:14,314 : INFO : resetting layer weights\n",
      "2023-12-06 14:51:14,318 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:51:14.317171', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:51:14,565 : INFO : EPOCH 0: training on 99524 raw words (60368 effective words) took 0.2s, 247160 effective words/s\n",
      "2023-12-06 14:51:14,818 : INFO : EPOCH 1: training on 99524 raw words (60454 effective words) took 0.2s, 246504 effective words/s\n",
      "2023-12-06 14:51:15,064 : INFO : EPOCH 2: training on 99524 raw words (60426 effective words) took 0.2s, 249324 effective words/s\n",
      "2023-12-06 14:51:15,310 : INFO : EPOCH 3: training on 99524 raw words (60258 effective words) took 0.2s, 251037 effective words/s\n",
      "2023-12-06 14:51:15,553 : INFO : EPOCH 4: training on 99524 raw words (60484 effective words) took 0.2s, 253270 effective words/s\n",
      "2023-12-06 14:51:15,796 : INFO : EPOCH 5: training on 99524 raw words (60487 effective words) took 0.2s, 253708 effective words/s\n",
      "2023-12-06 14:51:16,040 : INFO : EPOCH 6: training on 99524 raw words (60461 effective words) took 0.2s, 252615 effective words/s\n",
      "2023-12-06 14:51:16,289 : INFO : EPOCH 7: training on 99524 raw words (60340 effective words) took 0.2s, 245795 effective words/s\n",
      "2023-12-06 14:51:16,536 : INFO : EPOCH 8: training on 99524 raw words (60374 effective words) took 0.2s, 248782 effective words/s\n",
      "2023-12-06 14:51:16,780 : INFO : EPOCH 9: training on 99524 raw words (60299 effective words) took 0.2s, 251320 effective words/s\n",
      "2023-12-06 14:51:17,022 : INFO : EPOCH 10: training on 99524 raw words (60308 effective words) took 0.2s, 253186 effective words/s\n",
      "2023-12-06 14:51:17,268 : INFO : EPOCH 11: training on 99524 raw words (60283 effective words) took 0.2s, 249287 effective words/s\n",
      "2023-12-06 14:51:17,516 : INFO : EPOCH 12: training on 99524 raw words (60489 effective words) took 0.2s, 248891 effective words/s\n",
      "2023-12-06 14:51:17,760 : INFO : EPOCH 13: training on 99524 raw words (60311 effective words) took 0.2s, 250977 effective words/s\n",
      "2023-12-06 14:51:18,004 : INFO : EPOCH 14: training on 99524 raw words (60600 effective words) took 0.2s, 253540 effective words/s\n",
      "2023-12-06 14:51:18,259 : INFO : EPOCH 15: training on 99524 raw words (60322 effective words) took 0.3s, 240249 effective words/s\n",
      "2023-12-06 14:51:18,505 : INFO : EPOCH 16: training on 99524 raw words (60484 effective words) took 0.2s, 250834 effective words/s\n",
      "2023-12-06 14:51:18,759 : INFO : EPOCH 17: training on 99524 raw words (60588 effective words) took 0.2s, 243535 effective words/s\n",
      "2023-12-06 14:51:19,001 : INFO : EPOCH 18: training on 99524 raw words (60357 effective words) took 0.2s, 253334 effective words/s\n",
      "2023-12-06 14:51:19,249 : INFO : EPOCH 19: training on 99524 raw words (60368 effective words) took 0.2s, 248093 effective words/s\n",
      "2023-12-06 14:51:19,495 : INFO : EPOCH 20: training on 99524 raw words (60354 effective words) took 0.2s, 249476 effective words/s\n",
      "2023-12-06 14:51:19,746 : INFO : EPOCH 21: training on 99524 raw words (60285 effective words) took 0.2s, 244522 effective words/s\n",
      "2023-12-06 14:51:19,991 : INFO : EPOCH 22: training on 99524 raw words (60464 effective words) took 0.2s, 252024 effective words/s\n",
      "2023-12-06 14:51:20,244 : INFO : EPOCH 23: training on 99524 raw words (60388 effective words) took 0.2s, 242947 effective words/s\n",
      "2023-12-06 14:51:20,494 : INFO : EPOCH 24: training on 99524 raw words (60439 effective words) took 0.2s, 245994 effective words/s\n",
      "2023-12-06 14:51:20,739 : INFO : EPOCH 25: training on 99524 raw words (60283 effective words) took 0.2s, 250619 effective words/s\n",
      "2023-12-06 14:51:20,983 : INFO : EPOCH 26: training on 99524 raw words (60407 effective words) took 0.2s, 253189 effective words/s\n",
      "2023-12-06 14:51:21,230 : INFO : EPOCH 27: training on 99524 raw words (60318 effective words) took 0.2s, 247859 effective words/s\n",
      "2023-12-06 14:51:21,472 : INFO : EPOCH 28: training on 99524 raw words (60436 effective words) took 0.2s, 253922 effective words/s\n",
      "2023-12-06 14:51:21,717 : INFO : EPOCH 29: training on 99524 raw words (60432 effective words) took 0.2s, 250913 effective words/s\n",
      "2023-12-06 14:51:21,718 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811867 effective words) took 7.4s, 244833 effective words/s', 'datetime': '2023-12-06T14:51:21.718493', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:51:21,719 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:51:21.719491', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 49%|     | 239/486 [37:43<39:17,  9.54s/it]2023-12-06 14:51:25,065 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:51:25,065 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:51:25,092 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:51:25,093 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:51:25,099 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:51:25.099639', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:51:25,101 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:51:25.101639', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:51:25,108 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:51:25,108 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:51:25,109 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:51:25.109671', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:51:25,120 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:51:25,121 : INFO : resetting layer weights\n",
      "2023-12-06 14:51:25,124 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:51:25.124102', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:51:25,384 : INFO : EPOCH 0: training on 99524 raw words (60410 effective words) took 0.3s, 235733 effective words/s\n",
      "2023-12-06 14:51:25,635 : INFO : EPOCH 1: training on 99524 raw words (60244 effective words) took 0.2s, 243896 effective words/s\n",
      "2023-12-06 14:51:25,894 : INFO : EPOCH 2: training on 99524 raw words (60310 effective words) took 0.3s, 236954 effective words/s\n",
      "2023-12-06 14:51:26,154 : INFO : EPOCH 3: training on 99524 raw words (60421 effective words) took 0.3s, 236226 effective words/s\n",
      "2023-12-06 14:51:26,411 : INFO : EPOCH 4: training on 99524 raw words (60260 effective words) took 0.3s, 239014 effective words/s\n",
      "2023-12-06 14:51:26,669 : INFO : EPOCH 5: training on 99524 raw words (60495 effective words) took 0.3s, 238463 effective words/s\n",
      "2023-12-06 14:51:26,925 : INFO : EPOCH 6: training on 99524 raw words (60380 effective words) took 0.3s, 240177 effective words/s\n",
      "2023-12-06 14:51:27,181 : INFO : EPOCH 7: training on 99524 raw words (60373 effective words) took 0.3s, 239946 effective words/s\n",
      "2023-12-06 14:51:27,443 : INFO : EPOCH 8: training on 99524 raw words (60352 effective words) took 0.3s, 234116 effective words/s\n",
      "2023-12-06 14:51:27,698 : INFO : EPOCH 9: training on 99524 raw words (60439 effective words) took 0.3s, 240707 effective words/s\n",
      "2023-12-06 14:51:27,950 : INFO : EPOCH 10: training on 99524 raw words (60465 effective words) took 0.2s, 244238 effective words/s\n",
      "2023-12-06 14:51:28,212 : INFO : EPOCH 11: training on 99524 raw words (60453 effective words) took 0.3s, 234300 effective words/s\n",
      "2023-12-06 14:51:28,467 : INFO : EPOCH 12: training on 99524 raw words (60371 effective words) took 0.3s, 241478 effective words/s\n",
      "2023-12-06 14:51:28,725 : INFO : EPOCH 13: training on 99524 raw words (60290 effective words) took 0.3s, 237108 effective words/s\n",
      "2023-12-06 14:51:28,985 : INFO : EPOCH 14: training on 99524 raw words (60439 effective words) took 0.3s, 235605 effective words/s\n",
      "2023-12-06 14:51:29,241 : INFO : EPOCH 15: training on 99524 raw words (60410 effective words) took 0.3s, 240755 effective words/s\n",
      "2023-12-06 14:51:29,492 : INFO : EPOCH 16: training on 99524 raw words (60331 effective words) took 0.2s, 244159 effective words/s\n",
      "2023-12-06 14:51:29,755 : INFO : EPOCH 17: training on 99524 raw words (60418 effective words) took 0.3s, 234426 effective words/s\n",
      "2023-12-06 14:51:30,012 : INFO : EPOCH 18: training on 99524 raw words (60338 effective words) took 0.3s, 239334 effective words/s\n",
      "2023-12-06 14:51:30,267 : INFO : EPOCH 19: training on 99524 raw words (60492 effective words) took 0.3s, 241432 effective words/s\n",
      "2023-12-06 14:51:30,524 : INFO : EPOCH 20: training on 99524 raw words (60525 effective words) took 0.3s, 239025 effective words/s\n",
      "2023-12-06 14:51:30,778 : INFO : EPOCH 21: training on 99524 raw words (60413 effective words) took 0.3s, 241564 effective words/s\n",
      "2023-12-06 14:51:31,036 : INFO : EPOCH 22: training on 99524 raw words (60177 effective words) took 0.3s, 237602 effective words/s\n",
      "2023-12-06 14:51:31,305 : INFO : EPOCH 23: training on 99524 raw words (60250 effective words) took 0.3s, 228161 effective words/s\n",
      "2023-12-06 14:51:31,564 : INFO : EPOCH 24: training on 99524 raw words (60324 effective words) took 0.3s, 238178 effective words/s\n",
      "2023-12-06 14:51:31,825 : INFO : EPOCH 25: training on 99524 raw words (60425 effective words) took 0.3s, 235363 effective words/s\n",
      "2023-12-06 14:51:32,080 : INFO : EPOCH 26: training on 99524 raw words (60378 effective words) took 0.3s, 240893 effective words/s\n",
      "2023-12-06 14:51:32,341 : INFO : EPOCH 27: training on 99524 raw words (60301 effective words) took 0.3s, 235046 effective words/s\n",
      "2023-12-06 14:51:32,603 : INFO : EPOCH 28: training on 99524 raw words (60382 effective words) took 0.3s, 235223 effective words/s\n",
      "2023-12-06 14:51:32,862 : INFO : EPOCH 29: training on 99524 raw words (60375 effective words) took 0.3s, 236558 effective words/s\n",
      "2023-12-06 14:51:32,863 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811241 effective words) took 7.7s, 234029 effective words/s', 'datetime': '2023-12-06T14:51:32.863504', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:51:32,864 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:51:32.864504', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 49%|     | 240/486 [37:55<41:17, 10.07s/it]2023-12-06 14:51:36,368 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:51:36,369 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:51:36,391 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:51:36,392 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:51:36,396 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:51:36.396286', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:51:36,397 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:51:36.397284', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:51:36,403 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:51:36,404 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:51:36,404 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:51:36.404284', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:51:36,414 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:51:36,415 : INFO : resetting layer weights\n",
      "2023-12-06 14:51:36,418 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:51:36.417815', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:51:36,658 : INFO : EPOCH 0: training on 99524 raw words (60380 effective words) took 0.2s, 256469 effective words/s\n",
      "2023-12-06 14:51:36,907 : INFO : EPOCH 1: training on 99524 raw words (60344 effective words) took 0.2s, 249645 effective words/s\n",
      "2023-12-06 14:51:37,160 : INFO : EPOCH 2: training on 99524 raw words (60492 effective words) took 0.2s, 243136 effective words/s\n",
      "2023-12-06 14:51:37,399 : INFO : EPOCH 3: training on 99524 raw words (60313 effective words) took 0.2s, 257525 effective words/s\n",
      "2023-12-06 14:51:37,632 : INFO : EPOCH 4: training on 99524 raw words (60412 effective words) took 0.2s, 264984 effective words/s\n",
      "2023-12-06 14:51:37,870 : INFO : EPOCH 5: training on 99524 raw words (60267 effective words) took 0.2s, 258277 effective words/s\n",
      "2023-12-06 14:51:38,108 : INFO : EPOCH 6: training on 99524 raw words (60419 effective words) took 0.2s, 258936 effective words/s\n",
      "2023-12-06 14:51:38,340 : INFO : EPOCH 7: training on 99524 raw words (60309 effective words) took 0.2s, 264435 effective words/s\n",
      "2023-12-06 14:51:38,579 : INFO : EPOCH 8: training on 99524 raw words (60221 effective words) took 0.2s, 256459 effective words/s\n",
      "2023-12-06 14:51:38,822 : INFO : EPOCH 9: training on 99524 raw words (60384 effective words) took 0.2s, 254807 effective words/s\n",
      "2023-12-06 14:51:39,056 : INFO : EPOCH 10: training on 99524 raw words (60489 effective words) took 0.2s, 262733 effective words/s\n",
      "2023-12-06 14:51:39,292 : INFO : EPOCH 11: training on 99524 raw words (60428 effective words) took 0.2s, 260631 effective words/s\n",
      "2023-12-06 14:51:39,528 : INFO : EPOCH 12: training on 99524 raw words (60366 effective words) took 0.2s, 261146 effective words/s\n",
      "2023-12-06 14:51:39,765 : INFO : EPOCH 13: training on 99524 raw words (60253 effective words) took 0.2s, 258788 effective words/s\n",
      "2023-12-06 14:51:39,998 : INFO : EPOCH 14: training on 99524 raw words (60523 effective words) took 0.2s, 263618 effective words/s\n",
      "2023-12-06 14:51:40,236 : INFO : EPOCH 15: training on 99524 raw words (60598 effective words) took 0.2s, 260469 effective words/s\n",
      "2023-12-06 14:51:40,474 : INFO : EPOCH 16: training on 99524 raw words (60337 effective words) took 0.2s, 258592 effective words/s\n",
      "2023-12-06 14:51:40,708 : INFO : EPOCH 17: training on 99524 raw words (60469 effective words) took 0.2s, 262840 effective words/s\n",
      "2023-12-06 14:51:40,945 : INFO : EPOCH 18: training on 99524 raw words (60483 effective words) took 0.2s, 259945 effective words/s\n",
      "2023-12-06 14:51:41,187 : INFO : EPOCH 19: training on 99524 raw words (60511 effective words) took 0.2s, 253803 effective words/s\n",
      "2023-12-06 14:51:41,421 : INFO : EPOCH 20: training on 99524 raw words (60389 effective words) took 0.2s, 263293 effective words/s\n",
      "2023-12-06 14:51:41,661 : INFO : EPOCH 21: training on 99524 raw words (60363 effective words) took 0.2s, 256577 effective words/s\n",
      "2023-12-06 14:51:41,901 : INFO : EPOCH 22: training on 99524 raw words (60408 effective words) took 0.2s, 255676 effective words/s\n",
      "2023-12-06 14:51:42,137 : INFO : EPOCH 23: training on 99524 raw words (60555 effective words) took 0.2s, 261612 effective words/s\n",
      "2023-12-06 14:51:42,369 : INFO : EPOCH 24: training on 99524 raw words (60344 effective words) took 0.2s, 266155 effective words/s\n",
      "2023-12-06 14:51:42,603 : INFO : EPOCH 25: training on 99524 raw words (60444 effective words) took 0.2s, 262878 effective words/s\n",
      "2023-12-06 14:51:42,838 : INFO : EPOCH 26: training on 99524 raw words (60397 effective words) took 0.2s, 261416 effective words/s\n",
      "2023-12-06 14:51:43,087 : INFO : EPOCH 27: training on 99524 raw words (60375 effective words) took 0.2s, 247739 effective words/s\n",
      "2023-12-06 14:51:43,330 : INFO : EPOCH 28: training on 99524 raw words (60483 effective words) took 0.2s, 253900 effective words/s\n",
      "2023-12-06 14:51:43,567 : INFO : EPOCH 29: training on 99524 raw words (60453 effective words) took 0.2s, 259739 effective words/s\n",
      "2023-12-06 14:51:43,804 : INFO : EPOCH 30: training on 99524 raw words (60418 effective words) took 0.2s, 259424 effective words/s\n",
      "2023-12-06 14:51:44,044 : INFO : EPOCH 31: training on 99524 raw words (60296 effective words) took 0.2s, 257512 effective words/s\n",
      "2023-12-06 14:51:44,276 : INFO : EPOCH 32: training on 99524 raw words (60462 effective words) took 0.2s, 264907 effective words/s\n",
      "2023-12-06 14:51:44,516 : INFO : EPOCH 33: training on 99524 raw words (60557 effective words) took 0.2s, 256666 effective words/s\n",
      "2023-12-06 14:51:44,754 : INFO : EPOCH 34: training on 99524 raw words (60427 effective words) took 0.2s, 259542 effective words/s\n",
      "2023-12-06 14:51:44,993 : INFO : EPOCH 35: training on 99524 raw words (60451 effective words) took 0.2s, 256918 effective words/s\n",
      "2023-12-06 14:51:45,227 : INFO : EPOCH 36: training on 99524 raw words (60416 effective words) took 0.2s, 263813 effective words/s\n",
      "2023-12-06 14:51:45,472 : INFO : EPOCH 37: training on 99524 raw words (60456 effective words) took 0.2s, 251017 effective words/s\n",
      "2023-12-06 14:51:45,713 : INFO : EPOCH 38: training on 99524 raw words (60366 effective words) took 0.2s, 256135 effective words/s\n",
      "2023-12-06 14:51:45,952 : INFO : EPOCH 39: training on 99524 raw words (60251 effective words) took 0.2s, 255997 effective words/s\n",
      "2023-12-06 14:51:46,195 : INFO : EPOCH 40: training on 99524 raw words (60232 effective words) took 0.2s, 252004 effective words/s\n",
      "2023-12-06 14:51:46,436 : INFO : EPOCH 41: training on 99524 raw words (60358 effective words) took 0.2s, 257001 effective words/s\n",
      "2023-12-06 14:51:46,669 : INFO : EPOCH 42: training on 99524 raw words (60229 effective words) took 0.2s, 262209 effective words/s\n",
      "2023-12-06 14:51:46,910 : INFO : EPOCH 43: training on 99524 raw words (60341 effective words) took 0.2s, 254654 effective words/s\n",
      "2023-12-06 14:51:47,160 : INFO : EPOCH 44: training on 99524 raw words (60329 effective words) took 0.2s, 246856 effective words/s\n",
      "2023-12-06 14:51:47,402 : INFO : EPOCH 45: training on 99524 raw words (60254 effective words) took 0.2s, 253615 effective words/s\n",
      "2023-12-06 14:51:47,640 : INFO : EPOCH 46: training on 99524 raw words (60450 effective words) took 0.2s, 258730 effective words/s\n",
      "2023-12-06 14:51:47,878 : INFO : EPOCH 47: training on 99524 raw words (60436 effective words) took 0.2s, 258266 effective words/s\n",
      "2023-12-06 14:51:48,118 : INFO : EPOCH 48: training on 99524 raw words (60554 effective words) took 0.2s, 257105 effective words/s\n",
      "2023-12-06 14:51:48,349 : INFO : EPOCH 49: training on 99524 raw words (60335 effective words) took 0.2s, 266382 effective words/s\n",
      "2023-12-06 14:51:48,350 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3019827 effective words) took 11.9s, 253101 effective words/s', 'datetime': '2023-12-06T14:51:48.350719', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:51:48,350 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n5,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:51:48.350719', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 50%|     | 241/486 [38:10<48:00, 11.76s/it]2023-12-06 14:51:52,053 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:51:52,054 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:51:52,074 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:51:52,075 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:51:52,080 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:51:52.080087', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:51:52,081 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:51:52.081089', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:51:52,088 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:51:52,089 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:51:52,089 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:51:52.089087', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:51:52,095 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:51:52,096 : INFO : resetting layer weights\n",
      "2023-12-06 14:51:52,100 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:51:52.100707', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:51:52,365 : INFO : EPOCH 0: training on 99524 raw words (60420 effective words) took 0.3s, 231300 effective words/s\n",
      "2023-12-06 14:51:52,615 : INFO : EPOCH 1: training on 99524 raw words (60433 effective words) took 0.2s, 245951 effective words/s\n",
      "2023-12-06 14:51:52,861 : INFO : EPOCH 2: training on 99524 raw words (60435 effective words) took 0.2s, 250602 effective words/s\n",
      "2023-12-06 14:51:53,109 : INFO : EPOCH 3: training on 99524 raw words (60536 effective words) took 0.2s, 248693 effective words/s\n",
      "2023-12-06 14:51:53,349 : INFO : EPOCH 4: training on 99524 raw words (60280 effective words) took 0.2s, 255499 effective words/s\n",
      "2023-12-06 14:51:53,594 : INFO : EPOCH 5: training on 99524 raw words (60480 effective words) took 0.2s, 251176 effective words/s\n",
      "2023-12-06 14:51:53,842 : INFO : EPOCH 6: training on 99524 raw words (60559 effective words) took 0.2s, 248672 effective words/s\n",
      "2023-12-06 14:51:54,084 : INFO : EPOCH 7: training on 99524 raw words (60402 effective words) took 0.2s, 253811 effective words/s\n",
      "2023-12-06 14:51:54,334 : INFO : EPOCH 8: training on 99524 raw words (60477 effective words) took 0.2s, 248080 effective words/s\n",
      "2023-12-06 14:51:54,583 : INFO : EPOCH 9: training on 99524 raw words (60482 effective words) took 0.2s, 246991 effective words/s\n",
      "2023-12-06 14:51:54,833 : INFO : EPOCH 10: training on 99524 raw words (60392 effective words) took 0.2s, 246337 effective words/s\n",
      "2023-12-06 14:51:55,083 : INFO : EPOCH 11: training on 99524 raw words (60356 effective words) took 0.2s, 245520 effective words/s\n",
      "2023-12-06 14:51:55,330 : INFO : EPOCH 12: training on 99524 raw words (60240 effective words) took 0.2s, 249170 effective words/s\n",
      "2023-12-06 14:51:55,580 : INFO : EPOCH 13: training on 99524 raw words (60247 effective words) took 0.2s, 244873 effective words/s\n",
      "2023-12-06 14:51:55,826 : INFO : EPOCH 14: training on 99524 raw words (60476 effective words) took 0.2s, 250563 effective words/s\n",
      "2023-12-06 14:51:56,074 : INFO : EPOCH 15: training on 99524 raw words (60358 effective words) took 0.2s, 248393 effective words/s\n",
      "2023-12-06 14:51:56,319 : INFO : EPOCH 16: training on 99524 raw words (60417 effective words) took 0.2s, 250469 effective words/s\n",
      "2023-12-06 14:51:56,575 : INFO : EPOCH 17: training on 99524 raw words (60434 effective words) took 0.3s, 240606 effective words/s\n",
      "2023-12-06 14:51:56,821 : INFO : EPOCH 18: training on 99524 raw words (60466 effective words) took 0.2s, 250705 effective words/s\n",
      "2023-12-06 14:51:57,067 : INFO : EPOCH 19: training on 99524 raw words (60227 effective words) took 0.2s, 249131 effective words/s\n",
      "2023-12-06 14:51:57,311 : INFO : EPOCH 20: training on 99524 raw words (60399 effective words) took 0.2s, 252362 effective words/s\n",
      "2023-12-06 14:51:57,554 : INFO : EPOCH 21: training on 99524 raw words (60278 effective words) took 0.2s, 252017 effective words/s\n",
      "2023-12-06 14:51:57,801 : INFO : EPOCH 22: training on 99524 raw words (60462 effective words) took 0.2s, 248771 effective words/s\n",
      "2023-12-06 14:51:58,047 : INFO : EPOCH 23: training on 99524 raw words (60350 effective words) took 0.2s, 249757 effective words/s\n",
      "2023-12-06 14:51:58,295 : INFO : EPOCH 24: training on 99524 raw words (60454 effective words) took 0.2s, 248561 effective words/s\n",
      "2023-12-06 14:51:58,544 : INFO : EPOCH 25: training on 99524 raw words (60516 effective words) took 0.2s, 247569 effective words/s\n",
      "2023-12-06 14:51:58,792 : INFO : EPOCH 26: training on 99524 raw words (60278 effective words) took 0.2s, 247817 effective words/s\n",
      "2023-12-06 14:51:59,042 : INFO : EPOCH 27: training on 99524 raw words (60438 effective words) took 0.2s, 245669 effective words/s\n",
      "2023-12-06 14:51:59,285 : INFO : EPOCH 28: training on 99524 raw words (60288 effective words) took 0.2s, 253043 effective words/s\n",
      "2023-12-06 14:51:59,531 : INFO : EPOCH 29: training on 99524 raw words (60461 effective words) took 0.2s, 249859 effective words/s\n",
      "2023-12-06 14:51:59,775 : INFO : EPOCH 30: training on 99524 raw words (60498 effective words) took 0.2s, 251945 effective words/s\n",
      "2023-12-06 14:52:00,023 : INFO : EPOCH 31: training on 99524 raw words (60445 effective words) took 0.2s, 248138 effective words/s\n",
      "2023-12-06 14:52:00,268 : INFO : EPOCH 32: training on 99524 raw words (60335 effective words) took 0.2s, 250692 effective words/s\n",
      "2023-12-06 14:52:00,522 : INFO : EPOCH 33: training on 99524 raw words (60359 effective words) took 0.2s, 243177 effective words/s\n",
      "2023-12-06 14:52:00,771 : INFO : EPOCH 34: training on 99524 raw words (60326 effective words) took 0.2s, 246383 effective words/s\n",
      "2023-12-06 14:52:01,020 : INFO : EPOCH 35: training on 99524 raw words (60443 effective words) took 0.2s, 247550 effective words/s\n",
      "2023-12-06 14:52:01,268 : INFO : EPOCH 36: training on 99524 raw words (60365 effective words) took 0.2s, 248458 effective words/s\n",
      "2023-12-06 14:52:01,512 : INFO : EPOCH 37: training on 99524 raw words (60575 effective words) took 0.2s, 252598 effective words/s\n",
      "2023-12-06 14:52:01,760 : INFO : EPOCH 38: training on 99524 raw words (60349 effective words) took 0.2s, 247636 effective words/s\n",
      "2023-12-06 14:52:02,005 : INFO : EPOCH 39: training on 99524 raw words (60441 effective words) took 0.2s, 251526 effective words/s\n",
      "2023-12-06 14:52:02,257 : INFO : EPOCH 40: training on 99524 raw words (60418 effective words) took 0.2s, 243559 effective words/s\n",
      "2023-12-06 14:52:02,502 : INFO : EPOCH 41: training on 99524 raw words (60283 effective words) took 0.2s, 251405 effective words/s\n",
      "2023-12-06 14:52:02,747 : INFO : EPOCH 42: training on 99524 raw words (60446 effective words) took 0.2s, 250706 effective words/s\n",
      "2023-12-06 14:52:02,993 : INFO : EPOCH 43: training on 99524 raw words (60235 effective words) took 0.2s, 248649 effective words/s\n",
      "2023-12-06 14:52:03,249 : INFO : EPOCH 44: training on 99524 raw words (60335 effective words) took 0.3s, 240490 effective words/s\n",
      "2023-12-06 14:52:03,499 : INFO : EPOCH 45: training on 99524 raw words (60398 effective words) took 0.2s, 246613 effective words/s\n",
      "2023-12-06 14:52:03,739 : INFO : EPOCH 46: training on 99524 raw words (60370 effective words) took 0.2s, 255493 effective words/s\n",
      "2023-12-06 14:52:03,987 : INFO : EPOCH 47: training on 99524 raw words (60459 effective words) took 0.2s, 248541 effective words/s\n",
      "2023-12-06 14:52:04,228 : INFO : EPOCH 48: training on 99524 raw words (60424 effective words) took 0.2s, 255092 effective words/s\n",
      "2023-12-06 14:52:04,476 : INFO : EPOCH 49: training on 99524 raw words (60438 effective words) took 0.2s, 248305 effective words/s\n",
      "2023-12-06 14:52:04,477 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3019983 effective words) took 12.4s, 244013 effective words/s', 'datetime': '2023-12-06T14:52:04.477370', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:52:04,478 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n10,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:52:04.478370', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 50%|     | 242/486 [38:27<53:27, 13.14s/it]2023-12-06 14:52:08,440 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:52:08,440 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:52:08,460 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:52:08,461 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:52:08,466 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:52:08.466528', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:52:08,467 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:52:08.467526', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:52:08,474 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:52:08,474 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:52:08,475 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:52:08.475034', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:52:08,480 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:52:08,481 : INFO : resetting layer weights\n",
      "2023-12-06 14:52:08,483 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:52:08.483985', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:52:08,736 : INFO : EPOCH 0: training on 99524 raw words (60427 effective words) took 0.2s, 243661 effective words/s\n",
      "2023-12-06 14:52:08,994 : INFO : EPOCH 1: training on 99524 raw words (60407 effective words) took 0.3s, 239800 effective words/s\n",
      "2023-12-06 14:52:09,246 : INFO : EPOCH 2: training on 99524 raw words (60472 effective words) took 0.2s, 242623 effective words/s\n",
      "2023-12-06 14:52:09,501 : INFO : EPOCH 3: training on 99524 raw words (60286 effective words) took 0.2s, 241865 effective words/s\n",
      "2023-12-06 14:52:09,755 : INFO : EPOCH 4: training on 99524 raw words (60281 effective words) took 0.3s, 240748 effective words/s\n",
      "2023-12-06 14:52:10,014 : INFO : EPOCH 5: training on 99524 raw words (60420 effective words) took 0.3s, 237306 effective words/s\n",
      "2023-12-06 14:52:10,270 : INFO : EPOCH 6: training on 99524 raw words (60485 effective words) took 0.3s, 240762 effective words/s\n",
      "2023-12-06 14:52:10,527 : INFO : EPOCH 7: training on 99524 raw words (60373 effective words) took 0.3s, 239277 effective words/s\n",
      "2023-12-06 14:52:10,780 : INFO : EPOCH 8: training on 99524 raw words (60304 effective words) took 0.2s, 241842 effective words/s\n",
      "2023-12-06 14:52:11,036 : INFO : EPOCH 9: training on 99524 raw words (60322 effective words) took 0.3s, 240858 effective words/s\n",
      "2023-12-06 14:52:11,297 : INFO : EPOCH 10: training on 99524 raw words (60398 effective words) took 0.3s, 234320 effective words/s\n",
      "2023-12-06 14:52:11,552 : INFO : EPOCH 11: training on 99524 raw words (60356 effective words) took 0.3s, 240415 effective words/s\n",
      "2023-12-06 14:52:11,806 : INFO : EPOCH 12: training on 99524 raw words (60404 effective words) took 0.2s, 241895 effective words/s\n",
      "2023-12-06 14:52:12,063 : INFO : EPOCH 13: training on 99524 raw words (60327 effective words) took 0.3s, 239409 effective words/s\n",
      "2023-12-06 14:52:12,319 : INFO : EPOCH 14: training on 99524 raw words (60361 effective words) took 0.3s, 240362 effective words/s\n",
      "2023-12-06 14:52:12,573 : INFO : EPOCH 15: training on 99524 raw words (60407 effective words) took 0.3s, 241192 effective words/s\n",
      "2023-12-06 14:52:12,831 : INFO : EPOCH 16: training on 99524 raw words (60418 effective words) took 0.3s, 238254 effective words/s\n",
      "2023-12-06 14:52:13,085 : INFO : EPOCH 17: training on 99524 raw words (60487 effective words) took 0.3s, 241594 effective words/s\n",
      "2023-12-06 14:52:13,340 : INFO : EPOCH 18: training on 99524 raw words (60293 effective words) took 0.3s, 241058 effective words/s\n",
      "2023-12-06 14:52:13,595 : INFO : EPOCH 19: training on 99524 raw words (60294 effective words) took 0.2s, 241232 effective words/s\n",
      "2023-12-06 14:52:13,854 : INFO : EPOCH 20: training on 99524 raw words (60245 effective words) took 0.3s, 235975 effective words/s\n",
      "2023-12-06 14:52:14,113 : INFO : EPOCH 21: training on 99524 raw words (60570 effective words) took 0.3s, 239497 effective words/s\n",
      "2023-12-06 14:52:14,366 : INFO : EPOCH 22: training on 99524 raw words (60224 effective words) took 0.2s, 242755 effective words/s\n",
      "2023-12-06 14:52:14,621 : INFO : EPOCH 23: training on 99524 raw words (60262 effective words) took 0.3s, 240714 effective words/s\n",
      "2023-12-06 14:52:14,875 : INFO : EPOCH 24: training on 99524 raw words (60327 effective words) took 0.2s, 242443 effective words/s\n",
      "2023-12-06 14:52:15,129 : INFO : EPOCH 25: training on 99524 raw words (60271 effective words) took 0.2s, 241516 effective words/s\n",
      "2023-12-06 14:52:15,382 : INFO : EPOCH 26: training on 99524 raw words (60248 effective words) took 0.2s, 241009 effective words/s\n",
      "2023-12-06 14:52:15,639 : INFO : EPOCH 27: training on 99524 raw words (60373 effective words) took 0.3s, 239372 effective words/s\n",
      "2023-12-06 14:52:15,892 : INFO : EPOCH 28: training on 99524 raw words (60345 effective words) took 0.2s, 242711 effective words/s\n",
      "2023-12-06 14:52:16,153 : INFO : EPOCH 29: training on 99524 raw words (60187 effective words) took 0.3s, 235037 effective words/s\n",
      "2023-12-06 14:52:16,407 : INFO : EPOCH 30: training on 99524 raw words (60384 effective words) took 0.3s, 240820 effective words/s\n",
      "2023-12-06 14:52:16,661 : INFO : EPOCH 31: training on 99524 raw words (60225 effective words) took 0.2s, 241730 effective words/s\n",
      "2023-12-06 14:52:16,919 : INFO : EPOCH 32: training on 99524 raw words (60392 effective words) took 0.3s, 238043 effective words/s\n",
      "2023-12-06 14:52:17,175 : INFO : EPOCH 33: training on 99524 raw words (60520 effective words) took 0.3s, 240741 effective words/s\n",
      "2023-12-06 14:52:17,433 : INFO : EPOCH 34: training on 99524 raw words (60274 effective words) took 0.3s, 237783 effective words/s\n",
      "2023-12-06 14:52:17,690 : INFO : EPOCH 35: training on 99524 raw words (60381 effective words) took 0.3s, 238986 effective words/s\n",
      "2023-12-06 14:52:17,945 : INFO : EPOCH 36: training on 99524 raw words (60688 effective words) took 0.3s, 242739 effective words/s\n",
      "2023-12-06 14:52:18,200 : INFO : EPOCH 37: training on 99524 raw words (60385 effective words) took 0.3s, 240939 effective words/s\n",
      "2023-12-06 14:52:18,453 : INFO : EPOCH 38: training on 99524 raw words (60455 effective words) took 0.2s, 242916 effective words/s\n",
      "2023-12-06 14:52:18,711 : INFO : EPOCH 39: training on 99524 raw words (60443 effective words) took 0.3s, 238216 effective words/s\n",
      "2023-12-06 14:52:18,970 : INFO : EPOCH 40: training on 99524 raw words (60353 effective words) took 0.3s, 236609 effective words/s\n",
      "2023-12-06 14:52:19,224 : INFO : EPOCH 41: training on 99524 raw words (60302 effective words) took 0.2s, 241789 effective words/s\n",
      "2023-12-06 14:52:19,480 : INFO : EPOCH 42: training on 99524 raw words (60378 effective words) took 0.3s, 240213 effective words/s\n",
      "2023-12-06 14:52:19,734 : INFO : EPOCH 43: training on 99524 raw words (60411 effective words) took 0.3s, 241631 effective words/s\n",
      "2023-12-06 14:52:19,999 : INFO : EPOCH 44: training on 99524 raw words (60417 effective words) took 0.3s, 232335 effective words/s\n",
      "2023-12-06 14:52:20,257 : INFO : EPOCH 45: training on 99524 raw words (60329 effective words) took 0.3s, 238587 effective words/s\n",
      "2023-12-06 14:52:20,516 : INFO : EPOCH 46: training on 99524 raw words (60414 effective words) took 0.3s, 236909 effective words/s\n",
      "2023-12-06 14:52:20,771 : INFO : EPOCH 47: training on 99524 raw words (60434 effective words) took 0.3s, 240877 effective words/s\n",
      "2023-12-06 14:52:21,032 : INFO : EPOCH 48: training on 99524 raw words (60206 effective words) took 0.3s, 235783 effective words/s\n",
      "2023-12-06 14:52:21,287 : INFO : EPOCH 49: training on 99524 raw words (60470 effective words) took 0.3s, 240612 effective words/s\n",
      "2023-12-06 14:52:21,288 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3018435 effective words) took 12.8s, 235747 effective words/s', 'datetime': '2023-12-06T14:52:21.288816', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:52:21,288 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d100,n15,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:52:21.288816', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 50%|     | 243/486 [38:44<57:57, 14.31s/it]2023-12-06 14:52:25,475 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:52:25,476 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:52:25,498 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:52:25,499 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:52:25,508 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:52:25.508054', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:52:25,509 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:52:25.509054', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:52:25,521 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:52:25,522 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:52:25,522 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:52:25.522053', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:52:25,540 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:52:25,540 : INFO : resetting layer weights\n",
      "2023-12-06 14:52:25,544 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:52:25.544632', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:52:25,695 : INFO : EPOCH 0: training on 99524 raw words (65407 effective words) took 0.1s, 441713 effective words/s\n",
      "2023-12-06 14:52:25,859 : INFO : EPOCH 1: training on 99524 raw words (65634 effective words) took 0.2s, 419072 effective words/s\n",
      "2023-12-06 14:52:26,002 : INFO : EPOCH 2: training on 99524 raw words (65586 effective words) took 0.1s, 471216 effective words/s\n",
      "2023-12-06 14:52:26,153 : INFO : EPOCH 3: training on 99524 raw words (65558 effective words) took 0.1s, 447360 effective words/s\n",
      "2023-12-06 14:52:26,304 : INFO : EPOCH 4: training on 99524 raw words (65427 effective words) took 0.1s, 447701 effective words/s\n",
      "2023-12-06 14:52:26,455 : INFO : EPOCH 5: training on 99524 raw words (65253 effective words) took 0.1s, 446058 effective words/s\n",
      "2023-12-06 14:52:26,599 : INFO : EPOCH 6: training on 99524 raw words (65410 effective words) took 0.1s, 464911 effective words/s\n",
      "2023-12-06 14:52:26,749 : INFO : EPOCH 7: training on 99524 raw words (65451 effective words) took 0.1s, 450687 effective words/s\n",
      "2023-12-06 14:52:26,899 : INFO : EPOCH 8: training on 99524 raw words (65421 effective words) took 0.1s, 447358 effective words/s\n",
      "2023-12-06 14:52:27,051 : INFO : EPOCH 9: training on 99524 raw words (65417 effective words) took 0.1s, 444616 effective words/s\n",
      "2023-12-06 14:52:27,052 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (654564 effective words) took 1.5s, 434119 effective words/s', 'datetime': '2023-12-06T14:52:27.052917', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:52:27,053 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:52:27.053916', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 50%|     | 244/486 [38:48<45:23, 11.25s/it]2023-12-06 14:52:29,593 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:52:29,593 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:52:29,614 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:52:29,614 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:52:29,621 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:52:29.621047', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:52:29,621 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:52:29.621047', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:52:29,628 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:52:29,629 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:52:29,629 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:52:29.629880', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:52:29,645 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:52:29,646 : INFO : resetting layer weights\n",
      "2023-12-06 14:52:29,648 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:52:29.648535', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:52:29,790 : INFO : EPOCH 0: training on 99524 raw words (65453 effective words) took 0.1s, 474732 effective words/s\n",
      "2023-12-06 14:52:29,963 : INFO : EPOCH 1: training on 99524 raw words (65638 effective words) took 0.2s, 396292 effective words/s\n",
      "2023-12-06 14:52:30,118 : INFO : EPOCH 2: training on 99524 raw words (65575 effective words) took 0.2s, 432993 effective words/s\n",
      "2023-12-06 14:52:30,271 : INFO : EPOCH 3: training on 99524 raw words (65622 effective words) took 0.1s, 441276 effective words/s\n",
      "2023-12-06 14:52:30,422 : INFO : EPOCH 4: training on 99524 raw words (65503 effective words) took 0.1s, 446241 effective words/s\n",
      "2023-12-06 14:52:30,577 : INFO : EPOCH 5: training on 99524 raw words (65546 effective words) took 0.1s, 440376 effective words/s\n",
      "2023-12-06 14:52:30,728 : INFO : EPOCH 6: training on 99524 raw words (65472 effective words) took 0.1s, 447018 effective words/s\n",
      "2023-12-06 14:52:30,883 : INFO : EPOCH 7: training on 99524 raw words (65608 effective words) took 0.2s, 435741 effective words/s\n",
      "2023-12-06 14:52:31,036 : INFO : EPOCH 8: training on 99524 raw words (65527 effective words) took 0.1s, 437986 effective words/s\n",
      "2023-12-06 14:52:31,191 : INFO : EPOCH 9: training on 99524 raw words (65478 effective words) took 0.2s, 435733 effective words/s\n",
      "2023-12-06 14:52:31,192 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655422 effective words) took 1.5s, 424504 effective words/s', 'datetime': '2023-12-06T14:52:31.192920', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:52:31,193 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:52:31.193931', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 50%|     | 245/486 [38:52<36:41,  9.13s/it]2023-12-06 14:52:33,781 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:52:33,782 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:52:33,806 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:52:33,807 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:52:33,812 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:52:33.812935', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:52:33,812 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:52:33.812935', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:52:33,823 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:52:33,824 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:52:33,825 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:52:33.825894', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:52:33,835 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:52:33,836 : INFO : resetting layer weights\n",
      "2023-12-06 14:52:33,839 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:52:33.839440', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:52:34,000 : INFO : EPOCH 0: training on 99524 raw words (65381 effective words) took 0.2s, 420539 effective words/s\n",
      "2023-12-06 14:52:34,166 : INFO : EPOCH 1: training on 99524 raw words (65515 effective words) took 0.2s, 406902 effective words/s\n",
      "2023-12-06 14:52:34,320 : INFO : EPOCH 2: training on 99524 raw words (65703 effective words) took 0.1s, 442781 effective words/s\n",
      "2023-12-06 14:52:34,472 : INFO : EPOCH 3: training on 99524 raw words (65415 effective words) took 0.1s, 440944 effective words/s\n",
      "2023-12-06 14:52:34,627 : INFO : EPOCH 4: training on 99524 raw words (65612 effective words) took 0.2s, 436600 effective words/s\n",
      "2023-12-06 14:52:34,780 : INFO : EPOCH 5: training on 99524 raw words (65485 effective words) took 0.1s, 441241 effective words/s\n",
      "2023-12-06 14:52:34,933 : INFO : EPOCH 6: training on 99524 raw words (65435 effective words) took 0.1s, 437504 effective words/s\n",
      "2023-12-06 14:52:35,086 : INFO : EPOCH 7: training on 99524 raw words (65362 effective words) took 0.1s, 440895 effective words/s\n",
      "2023-12-06 14:52:35,241 : INFO : EPOCH 8: training on 99524 raw words (65450 effective words) took 0.2s, 434621 effective words/s\n",
      "2023-12-06 14:52:35,395 : INFO : EPOCH 9: training on 99524 raw words (65674 effective words) took 0.1s, 439755 effective words/s\n",
      "2023-12-06 14:52:35,395 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655032 effective words) took 1.6s, 421104 effective words/s', 'datetime': '2023-12-06T14:52:35.395478', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:52:35,396 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:52:35.396815', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 51%|     | 246/486 [38:56<30:41,  7.67s/it]2023-12-06 14:52:38,041 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:52:38,042 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:52:38,065 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:52:38,066 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:52:38,073 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:52:38.073134', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:52:38,074 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:52:38.074134', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:52:38,084 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:52:38,084 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:52:38,085 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:52:38.085156', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:52:38,100 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:52:38,101 : INFO : resetting layer weights\n",
      "2023-12-06 14:52:38,104 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:52:38.104032', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:52:38,250 : INFO : EPOCH 0: training on 99524 raw words (65619 effective words) took 0.1s, 460697 effective words/s\n",
      "2023-12-06 14:52:38,413 : INFO : EPOCH 1: training on 99524 raw words (65532 effective words) took 0.2s, 417527 effective words/s\n",
      "2023-12-06 14:52:38,563 : INFO : EPOCH 2: training on 99524 raw words (65469 effective words) took 0.1s, 449732 effective words/s\n",
      "2023-12-06 14:52:38,709 : INFO : EPOCH 3: training on 99524 raw words (65518 effective words) took 0.1s, 465248 effective words/s\n",
      "2023-12-06 14:52:38,856 : INFO : EPOCH 4: training on 99524 raw words (65648 effective words) took 0.1s, 458868 effective words/s\n",
      "2023-12-06 14:52:39,009 : INFO : EPOCH 5: training on 99524 raw words (65644 effective words) took 0.1s, 443442 effective words/s\n",
      "2023-12-06 14:52:39,155 : INFO : EPOCH 6: training on 99524 raw words (65512 effective words) took 0.1s, 458788 effective words/s\n",
      "2023-12-06 14:52:39,299 : INFO : EPOCH 7: training on 99524 raw words (65537 effective words) took 0.1s, 469466 effective words/s\n",
      "2023-12-06 14:52:39,448 : INFO : EPOCH 8: training on 99524 raw words (65524 effective words) took 0.1s, 455565 effective words/s\n",
      "2023-12-06 14:52:39,599 : INFO : EPOCH 9: training on 99524 raw words (65680 effective words) took 0.1s, 447995 effective words/s\n",
      "2023-12-06 14:52:39,746 : INFO : EPOCH 10: training on 99524 raw words (65343 effective words) took 0.1s, 460242 effective words/s\n",
      "2023-12-06 14:52:39,898 : INFO : EPOCH 11: training on 99524 raw words (65552 effective words) took 0.1s, 443157 effective words/s\n",
      "2023-12-06 14:52:40,048 : INFO : EPOCH 12: training on 99524 raw words (65574 effective words) took 0.1s, 450049 effective words/s\n",
      "2023-12-06 14:52:40,199 : INFO : EPOCH 13: training on 99524 raw words (65443 effective words) took 0.1s, 451227 effective words/s\n",
      "2023-12-06 14:52:40,348 : INFO : EPOCH 14: training on 99524 raw words (65492 effective words) took 0.1s, 448907 effective words/s\n",
      "2023-12-06 14:52:40,500 : INFO : EPOCH 15: training on 99524 raw words (65697 effective words) took 0.1s, 448696 effective words/s\n",
      "2023-12-06 14:52:40,649 : INFO : EPOCH 16: training on 99524 raw words (65503 effective words) took 0.1s, 450779 effective words/s\n",
      "2023-12-06 14:52:40,798 : INFO : EPOCH 17: training on 99524 raw words (65614 effective words) took 0.1s, 454976 effective words/s\n",
      "2023-12-06 14:52:40,947 : INFO : EPOCH 18: training on 99524 raw words (65427 effective words) took 0.1s, 449895 effective words/s\n",
      "2023-12-06 14:52:41,096 : INFO : EPOCH 19: training on 99524 raw words (65637 effective words) took 0.1s, 452717 effective words/s\n",
      "2023-12-06 14:52:41,245 : INFO : EPOCH 20: training on 99524 raw words (65365 effective words) took 0.1s, 449280 effective words/s\n",
      "2023-12-06 14:52:41,399 : INFO : EPOCH 21: training on 99524 raw words (65520 effective words) took 0.1s, 442772 effective words/s\n",
      "2023-12-06 14:52:41,547 : INFO : EPOCH 22: training on 99524 raw words (65637 effective words) took 0.1s, 459463 effective words/s\n",
      "2023-12-06 14:52:41,689 : INFO : EPOCH 23: training on 99524 raw words (65667 effective words) took 0.1s, 471886 effective words/s\n",
      "2023-12-06 14:52:41,840 : INFO : EPOCH 24: training on 99524 raw words (65596 effective words) took 0.1s, 446508 effective words/s\n",
      "2023-12-06 14:52:41,988 : INFO : EPOCH 25: training on 99524 raw words (65487 effective words) took 0.1s, 459126 effective words/s\n",
      "2023-12-06 14:52:42,138 : INFO : EPOCH 26: training on 99524 raw words (65648 effective words) took 0.1s, 451824 effective words/s\n",
      "2023-12-06 14:52:42,283 : INFO : EPOCH 27: training on 99524 raw words (65646 effective words) took 0.1s, 467559 effective words/s\n",
      "2023-12-06 14:52:42,431 : INFO : EPOCH 28: training on 99524 raw words (65546 effective words) took 0.1s, 452569 effective words/s\n",
      "2023-12-06 14:52:42,575 : INFO : EPOCH 29: training on 99524 raw words (65624 effective words) took 0.1s, 469926 effective words/s\n",
      "2023-12-06 14:52:42,576 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1966701 effective words) took 4.5s, 439775 effective words/s', 'datetime': '2023-12-06T14:52:42.576829', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:52:42,577 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:52:42.577829', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 51%|     | 247/486 [39:04<30:14,  7.59s/it]2023-12-06 14:52:45,445 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:52:45,446 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:52:45,464 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:52:45,465 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:52:45,470 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:52:45.470871', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:52:45,471 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:52:45.471871', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:52:45,478 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:52:45,479 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:52:45,480 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:52:45.480532', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:52:45,496 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:52:45,497 : INFO : resetting layer weights\n",
      "2023-12-06 14:52:45,500 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:52:45.500549', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:52:45,660 : INFO : EPOCH 0: training on 99524 raw words (65437 effective words) took 0.2s, 418294 effective words/s\n",
      "2023-12-06 14:52:45,826 : INFO : EPOCH 1: training on 99524 raw words (65596 effective words) took 0.2s, 412729 effective words/s\n",
      "2023-12-06 14:52:45,978 : INFO : EPOCH 2: training on 99524 raw words (65566 effective words) took 0.1s, 443398 effective words/s\n",
      "2023-12-06 14:52:46,134 : INFO : EPOCH 3: training on 99524 raw words (65322 effective words) took 0.2s, 433952 effective words/s\n",
      "2023-12-06 14:52:46,290 : INFO : EPOCH 4: training on 99524 raw words (65456 effective words) took 0.2s, 431748 effective words/s\n",
      "2023-12-06 14:52:46,446 : INFO : EPOCH 5: training on 99524 raw words (65578 effective words) took 0.2s, 434100 effective words/s\n",
      "2023-12-06 14:52:46,601 : INFO : EPOCH 6: training on 99524 raw words (65594 effective words) took 0.2s, 434191 effective words/s\n",
      "2023-12-06 14:52:46,754 : INFO : EPOCH 7: training on 99524 raw words (65595 effective words) took 0.1s, 440178 effective words/s\n",
      "2023-12-06 14:52:46,912 : INFO : EPOCH 8: training on 99524 raw words (65487 effective words) took 0.2s, 427340 effective words/s\n",
      "2023-12-06 14:52:47,069 : INFO : EPOCH 9: training on 99524 raw words (65475 effective words) took 0.2s, 428573 effective words/s\n",
      "2023-12-06 14:52:47,225 : INFO : EPOCH 10: training on 99524 raw words (65393 effective words) took 0.2s, 431896 effective words/s\n",
      "2023-12-06 14:52:47,389 : INFO : EPOCH 11: training on 99524 raw words (65439 effective words) took 0.2s, 410246 effective words/s\n",
      "2023-12-06 14:52:47,541 : INFO : EPOCH 12: training on 99524 raw words (65626 effective words) took 0.1s, 445140 effective words/s\n",
      "2023-12-06 14:52:47,696 : INFO : EPOCH 13: training on 99524 raw words (65457 effective words) took 0.2s, 434814 effective words/s\n",
      "2023-12-06 14:52:47,853 : INFO : EPOCH 14: training on 99524 raw words (65563 effective words) took 0.2s, 431810 effective words/s\n",
      "2023-12-06 14:52:48,008 : INFO : EPOCH 15: training on 99524 raw words (65517 effective words) took 0.2s, 434513 effective words/s\n",
      "2023-12-06 14:52:48,161 : INFO : EPOCH 16: training on 99524 raw words (65542 effective words) took 0.1s, 438344 effective words/s\n",
      "2023-12-06 14:52:48,321 : INFO : EPOCH 17: training on 99524 raw words (65529 effective words) took 0.2s, 422128 effective words/s\n",
      "2023-12-06 14:52:48,477 : INFO : EPOCH 18: training on 99524 raw words (65479 effective words) took 0.2s, 432825 effective words/s\n",
      "2023-12-06 14:52:48,631 : INFO : EPOCH 19: training on 99524 raw words (65437 effective words) took 0.2s, 433815 effective words/s\n",
      "2023-12-06 14:52:48,788 : INFO : EPOCH 20: training on 99524 raw words (65497 effective words) took 0.2s, 430724 effective words/s\n",
      "2023-12-06 14:52:48,948 : INFO : EPOCH 21: training on 99524 raw words (65604 effective words) took 0.2s, 422961 effective words/s\n",
      "2023-12-06 14:52:49,100 : INFO : EPOCH 22: training on 99524 raw words (65472 effective words) took 0.1s, 443567 effective words/s\n",
      "2023-12-06 14:52:49,259 : INFO : EPOCH 23: training on 99524 raw words (65644 effective words) took 0.2s, 426792 effective words/s\n",
      "2023-12-06 14:52:49,416 : INFO : EPOCH 24: training on 99524 raw words (65463 effective words) took 0.2s, 429635 effective words/s\n",
      "2023-12-06 14:52:49,571 : INFO : EPOCH 25: training on 99524 raw words (65561 effective words) took 0.2s, 434155 effective words/s\n",
      "2023-12-06 14:52:49,724 : INFO : EPOCH 26: training on 99524 raw words (65741 effective words) took 0.1s, 443825 effective words/s\n",
      "2023-12-06 14:52:49,881 : INFO : EPOCH 27: training on 99524 raw words (65534 effective words) took 0.2s, 428171 effective words/s\n",
      "2023-12-06 14:52:50,042 : INFO : EPOCH 28: training on 99524 raw words (65602 effective words) took 0.2s, 419393 effective words/s\n",
      "2023-12-06 14:52:50,203 : INFO : EPOCH 29: training on 99524 raw words (65498 effective words) took 0.2s, 418418 effective words/s\n",
      "2023-12-06 14:52:50,204 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965704 effective words) took 4.7s, 417971 effective words/s', 'datetime': '2023-12-06T14:52:50.204540', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:52:50,204 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:52:50.204540', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 51%|     | 248/486 [39:11<30:19,  7.64s/it]2023-12-06 14:52:53,214 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:52:53,214 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:52:53,235 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:52:53,236 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:52:53,244 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:52:53.244043', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:52:53,244 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:52:53.244043', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:52:53,253 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:52:53,254 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:52:53,254 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:52:53.254974', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:52:53,266 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:52:53,267 : INFO : resetting layer weights\n",
      "2023-12-06 14:52:53,270 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:52:53.270897', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:52:53,427 : INFO : EPOCH 0: training on 99524 raw words (65516 effective words) took 0.2s, 430403 effective words/s\n",
      "2023-12-06 14:52:53,595 : INFO : EPOCH 1: training on 99524 raw words (65548 effective words) took 0.2s, 404297 effective words/s\n",
      "2023-12-06 14:52:53,745 : INFO : EPOCH 2: training on 99524 raw words (65586 effective words) took 0.1s, 450015 effective words/s\n",
      "2023-12-06 14:52:53,899 : INFO : EPOCH 3: training on 99524 raw words (65529 effective words) took 0.1s, 437569 effective words/s\n",
      "2023-12-06 14:52:54,052 : INFO : EPOCH 4: training on 99524 raw words (65593 effective words) took 0.1s, 440090 effective words/s\n",
      "2023-12-06 14:52:54,207 : INFO : EPOCH 5: training on 99524 raw words (65590 effective words) took 0.2s, 435367 effective words/s\n",
      "2023-12-06 14:52:54,357 : INFO : EPOCH 6: training on 99524 raw words (65595 effective words) took 0.1s, 451036 effective words/s\n",
      "2023-12-06 14:52:54,511 : INFO : EPOCH 7: training on 99524 raw words (65508 effective words) took 0.1s, 438976 effective words/s\n",
      "2023-12-06 14:52:54,662 : INFO : EPOCH 8: training on 99524 raw words (65398 effective words) took 0.1s, 443676 effective words/s\n",
      "2023-12-06 14:52:54,823 : INFO : EPOCH 9: training on 99524 raw words (65538 effective words) took 0.2s, 418169 effective words/s\n",
      "2023-12-06 14:52:54,977 : INFO : EPOCH 10: training on 99524 raw words (65479 effective words) took 0.1s, 437834 effective words/s\n",
      "2023-12-06 14:52:55,135 : INFO : EPOCH 11: training on 99524 raw words (65698 effective words) took 0.2s, 425842 effective words/s\n",
      "2023-12-06 14:52:55,289 : INFO : EPOCH 12: training on 99524 raw words (65720 effective words) took 0.1s, 440657 effective words/s\n",
      "2023-12-06 14:52:55,444 : INFO : EPOCH 13: training on 99524 raw words (65528 effective words) took 0.1s, 439346 effective words/s\n",
      "2023-12-06 14:52:55,597 : INFO : EPOCH 14: training on 99524 raw words (65506 effective words) took 0.1s, 439383 effective words/s\n",
      "2023-12-06 14:52:55,750 : INFO : EPOCH 15: training on 99524 raw words (65605 effective words) took 0.1s, 441876 effective words/s\n",
      "2023-12-06 14:52:55,899 : INFO : EPOCH 16: training on 99524 raw words (65522 effective words) took 0.1s, 455447 effective words/s\n",
      "2023-12-06 14:52:56,052 : INFO : EPOCH 17: training on 99524 raw words (65398 effective words) took 0.1s, 438329 effective words/s\n",
      "2023-12-06 14:52:56,207 : INFO : EPOCH 18: training on 99524 raw words (65405 effective words) took 0.1s, 436647 effective words/s\n",
      "2023-12-06 14:52:56,362 : INFO : EPOCH 19: training on 99524 raw words (65625 effective words) took 0.2s, 435092 effective words/s\n",
      "2023-12-06 14:52:56,515 : INFO : EPOCH 20: training on 99524 raw words (65573 effective words) took 0.1s, 441537 effective words/s\n",
      "2023-12-06 14:52:56,667 : INFO : EPOCH 21: training on 99524 raw words (65458 effective words) took 0.1s, 444369 effective words/s\n",
      "2023-12-06 14:52:56,821 : INFO : EPOCH 22: training on 99524 raw words (65617 effective words) took 0.1s, 440893 effective words/s\n",
      "2023-12-06 14:52:56,970 : INFO : EPOCH 23: training on 99524 raw words (65535 effective words) took 0.1s, 450105 effective words/s\n",
      "2023-12-06 14:52:57,126 : INFO : EPOCH 24: training on 99524 raw words (65530 effective words) took 0.2s, 435306 effective words/s\n",
      "2023-12-06 14:52:57,274 : INFO : EPOCH 25: training on 99524 raw words (65524 effective words) took 0.1s, 455541 effective words/s\n",
      "2023-12-06 14:52:57,427 : INFO : EPOCH 26: training on 99524 raw words (65747 effective words) took 0.1s, 443529 effective words/s\n",
      "2023-12-06 14:52:57,576 : INFO : EPOCH 27: training on 99524 raw words (65527 effective words) took 0.1s, 453138 effective words/s\n",
      "2023-12-06 14:52:57,735 : INFO : EPOCH 28: training on 99524 raw words (65365 effective words) took 0.2s, 421834 effective words/s\n",
      "2023-12-06 14:52:57,884 : INFO : EPOCH 29: training on 99524 raw words (65372 effective words) took 0.1s, 451001 effective words/s\n",
      "2023-12-06 14:52:57,885 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1966135 effective words) took 4.6s, 426076 effective words/s', 'datetime': '2023-12-06T14:52:57.885634', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:52:57,886 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:52:57.886637', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 51%|     | 249/486 [39:19<30:29,  7.72s/it]2023-12-06 14:53:01,106 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:53:01,106 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:53:01,128 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:53:01,128 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:53:01,136 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:53:01.136448', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:53:01,137 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:53:01.137449', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:53:01,146 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:53:01,147 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:53:01,148 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:53:01.148448', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:53:01,158 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:53:01,159 : INFO : resetting layer weights\n",
      "2023-12-06 14:53:01,163 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:53:01.163478', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:53:01,315 : INFO : EPOCH 0: training on 99524 raw words (65488 effective words) took 0.1s, 442018 effective words/s\n",
      "2023-12-06 14:53:01,480 : INFO : EPOCH 1: training on 99524 raw words (65580 effective words) took 0.2s, 411224 effective words/s\n",
      "2023-12-06 14:53:01,627 : INFO : EPOCH 2: training on 99524 raw words (65653 effective words) took 0.1s, 464756 effective words/s\n",
      "2023-12-06 14:53:01,774 : INFO : EPOCH 3: training on 99524 raw words (65469 effective words) took 0.1s, 456492 effective words/s\n",
      "2023-12-06 14:53:01,918 : INFO : EPOCH 4: training on 99524 raw words (65592 effective words) took 0.1s, 472292 effective words/s\n",
      "2023-12-06 14:53:02,066 : INFO : EPOCH 5: training on 99524 raw words (65262 effective words) took 0.1s, 453876 effective words/s\n",
      "2023-12-06 14:53:02,209 : INFO : EPOCH 6: training on 99524 raw words (65451 effective words) took 0.1s, 470759 effective words/s\n",
      "2023-12-06 14:53:02,358 : INFO : EPOCH 7: training on 99524 raw words (65502 effective words) took 0.1s, 452945 effective words/s\n",
      "2023-12-06 14:53:02,513 : INFO : EPOCH 8: training on 99524 raw words (65466 effective words) took 0.2s, 435140 effective words/s\n",
      "2023-12-06 14:53:02,662 : INFO : EPOCH 9: training on 99524 raw words (65554 effective words) took 0.1s, 451726 effective words/s\n",
      "2023-12-06 14:53:02,811 : INFO : EPOCH 10: training on 99524 raw words (65334 effective words) took 0.1s, 451828 effective words/s\n",
      "2023-12-06 14:53:02,965 : INFO : EPOCH 11: training on 99524 raw words (65631 effective words) took 0.1s, 438220 effective words/s\n",
      "2023-12-06 14:53:03,114 : INFO : EPOCH 12: training on 99524 raw words (65476 effective words) took 0.1s, 454901 effective words/s\n",
      "2023-12-06 14:53:03,264 : INFO : EPOCH 13: training on 99524 raw words (65482 effective words) took 0.1s, 450559 effective words/s\n",
      "2023-12-06 14:53:03,413 : INFO : EPOCH 14: training on 99524 raw words (65513 effective words) took 0.1s, 450655 effective words/s\n",
      "2023-12-06 14:53:03,565 : INFO : EPOCH 15: training on 99524 raw words (65531 effective words) took 0.1s, 447167 effective words/s\n",
      "2023-12-06 14:53:03,709 : INFO : EPOCH 16: training on 99524 raw words (65535 effective words) took 0.1s, 470666 effective words/s\n",
      "2023-12-06 14:53:03,859 : INFO : EPOCH 17: training on 99524 raw words (65455 effective words) took 0.1s, 445821 effective words/s\n",
      "2023-12-06 14:53:04,018 : INFO : EPOCH 18: training on 99524 raw words (65565 effective words) took 0.2s, 426883 effective words/s\n",
      "2023-12-06 14:53:04,167 : INFO : EPOCH 19: training on 99524 raw words (65575 effective words) took 0.1s, 451189 effective words/s\n",
      "2023-12-06 14:53:04,313 : INFO : EPOCH 20: training on 99524 raw words (65429 effective words) took 0.1s, 462071 effective words/s\n",
      "2023-12-06 14:53:04,466 : INFO : EPOCH 21: training on 99524 raw words (65553 effective words) took 0.1s, 440870 effective words/s\n",
      "2023-12-06 14:53:04,616 : INFO : EPOCH 22: training on 99524 raw words (65748 effective words) took 0.1s, 450273 effective words/s\n",
      "2023-12-06 14:53:04,766 : INFO : EPOCH 23: training on 99524 raw words (65686 effective words) took 0.1s, 450031 effective words/s\n",
      "2023-12-06 14:53:04,915 : INFO : EPOCH 24: training on 99524 raw words (65534 effective words) took 0.1s, 452675 effective words/s\n",
      "2023-12-06 14:53:05,064 : INFO : EPOCH 25: training on 99524 raw words (65390 effective words) took 0.1s, 453624 effective words/s\n",
      "2023-12-06 14:53:05,214 : INFO : EPOCH 26: training on 99524 raw words (65717 effective words) took 0.1s, 450496 effective words/s\n",
      "2023-12-06 14:53:05,363 : INFO : EPOCH 27: training on 99524 raw words (65667 effective words) took 0.1s, 453702 effective words/s\n",
      "2023-12-06 14:53:05,521 : INFO : EPOCH 28: training on 99524 raw words (65545 effective words) took 0.2s, 426355 effective words/s\n",
      "2023-12-06 14:53:05,673 : INFO : EPOCH 29: training on 99524 raw words (65565 effective words) took 0.1s, 445397 effective words/s\n",
      "2023-12-06 14:53:05,825 : INFO : EPOCH 30: training on 99524 raw words (65307 effective words) took 0.1s, 442309 effective words/s\n",
      "2023-12-06 14:53:05,970 : INFO : EPOCH 31: training on 99524 raw words (65513 effective words) took 0.1s, 465661 effective words/s\n",
      "2023-12-06 14:53:06,121 : INFO : EPOCH 32: training on 99524 raw words (65537 effective words) took 0.1s, 448247 effective words/s\n",
      "2023-12-06 14:53:06,264 : INFO : EPOCH 33: training on 99524 raw words (65620 effective words) took 0.1s, 470546 effective words/s\n",
      "2023-12-06 14:53:06,413 : INFO : EPOCH 34: training on 99524 raw words (65452 effective words) took 0.1s, 453788 effective words/s\n",
      "2023-12-06 14:53:06,558 : INFO : EPOCH 35: training on 99524 raw words (65705 effective words) took 0.1s, 467657 effective words/s\n",
      "2023-12-06 14:53:06,708 : INFO : EPOCH 36: training on 99524 raw words (65383 effective words) took 0.1s, 453400 effective words/s\n",
      "2023-12-06 14:53:06,858 : INFO : EPOCH 37: training on 99524 raw words (65389 effective words) took 0.1s, 447943 effective words/s\n",
      "2023-12-06 14:53:07,015 : INFO : EPOCH 38: training on 99524 raw words (65626 effective words) took 0.2s, 427841 effective words/s\n",
      "2023-12-06 14:53:07,161 : INFO : EPOCH 39: training on 99524 raw words (65557 effective words) took 0.1s, 463433 effective words/s\n",
      "2023-12-06 14:53:07,317 : INFO : EPOCH 40: training on 99524 raw words (65394 effective words) took 0.1s, 436160 effective words/s\n",
      "2023-12-06 14:53:07,468 : INFO : EPOCH 41: training on 99524 raw words (65511 effective words) took 0.1s, 446331 effective words/s\n",
      "2023-12-06 14:53:07,618 : INFO : EPOCH 42: training on 99524 raw words (65447 effective words) took 0.1s, 449622 effective words/s\n",
      "2023-12-06 14:53:07,766 : INFO : EPOCH 43: training on 99524 raw words (65487 effective words) took 0.1s, 454528 effective words/s\n",
      "2023-12-06 14:53:07,916 : INFO : EPOCH 44: training on 99524 raw words (65442 effective words) took 0.1s, 450915 effective words/s\n",
      "2023-12-06 14:53:08,065 : INFO : EPOCH 45: training on 99524 raw words (65499 effective words) took 0.1s, 452715 effective words/s\n",
      "2023-12-06 14:53:08,223 : INFO : EPOCH 46: training on 99524 raw words (65571 effective words) took 0.2s, 430454 effective words/s\n",
      "2023-12-06 14:53:08,368 : INFO : EPOCH 47: training on 99524 raw words (65585 effective words) took 0.1s, 467157 effective words/s\n",
      "2023-12-06 14:53:08,516 : INFO : EPOCH 48: training on 99524 raw words (65591 effective words) took 0.1s, 454119 effective words/s\n",
      "2023-12-06 14:53:08,670 : INFO : EPOCH 49: training on 99524 raw words (65581 effective words) took 0.1s, 440152 effective words/s\n",
      "2023-12-06 14:53:08,670 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276145 effective words) took 7.5s, 436422 effective words/s', 'datetime': '2023-12-06T14:53:08.670631', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:53:08,671 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:53:08.671635', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 51%|    | 250/486 [39:30<33:52,  8.61s/it]2023-12-06 14:53:11,803 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:53:11,804 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:53:11,835 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:53:11,836 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:53:11,841 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:53:11.841503', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:53:11,842 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:53:11.842503', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:53:11,853 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:53:11,854 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:53:11,854 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:53:11.854028', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:53:11,870 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:53:11,871 : INFO : resetting layer weights\n",
      "2023-12-06 14:53:11,874 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:53:11.874409', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:53:12,024 : INFO : EPOCH 0: training on 99524 raw words (65532 effective words) took 0.1s, 449467 effective words/s\n",
      "2023-12-06 14:53:12,192 : INFO : EPOCH 1: training on 99524 raw words (65634 effective words) took 0.2s, 402846 effective words/s\n",
      "2023-12-06 14:53:12,345 : INFO : EPOCH 2: training on 99524 raw words (65489 effective words) took 0.1s, 444677 effective words/s\n",
      "2023-12-06 14:53:12,501 : INFO : EPOCH 3: training on 99524 raw words (65442 effective words) took 0.2s, 429984 effective words/s\n",
      "2023-12-06 14:53:12,655 : INFO : EPOCH 4: training on 99524 raw words (65393 effective words) took 0.1s, 436213 effective words/s\n",
      "2023-12-06 14:53:12,811 : INFO : EPOCH 5: training on 99524 raw words (65520 effective words) took 0.2s, 432409 effective words/s\n",
      "2023-12-06 14:53:12,964 : INFO : EPOCH 6: training on 99524 raw words (65394 effective words) took 0.1s, 442153 effective words/s\n",
      "2023-12-06 14:53:13,120 : INFO : EPOCH 7: training on 99524 raw words (65479 effective words) took 0.2s, 429557 effective words/s\n",
      "2023-12-06 14:53:13,272 : INFO : EPOCH 8: training on 99524 raw words (65410 effective words) took 0.1s, 442539 effective words/s\n",
      "2023-12-06 14:53:13,434 : INFO : EPOCH 9: training on 99524 raw words (65544 effective words) took 0.2s, 415343 effective words/s\n",
      "2023-12-06 14:53:13,587 : INFO : EPOCH 10: training on 99524 raw words (65336 effective words) took 0.1s, 439801 effective words/s\n",
      "2023-12-06 14:53:13,743 : INFO : EPOCH 11: training on 99524 raw words (65391 effective words) took 0.2s, 430868 effective words/s\n",
      "2023-12-06 14:53:13,900 : INFO : EPOCH 12: training on 99524 raw words (65553 effective words) took 0.2s, 430717 effective words/s\n",
      "2023-12-06 14:53:14,055 : INFO : EPOCH 13: training on 99524 raw words (65325 effective words) took 0.2s, 432715 effective words/s\n",
      "2023-12-06 14:53:14,207 : INFO : EPOCH 14: training on 99524 raw words (65553 effective words) took 0.1s, 443982 effective words/s\n",
      "2023-12-06 14:53:14,365 : INFO : EPOCH 15: training on 99524 raw words (65536 effective words) took 0.2s, 429095 effective words/s\n",
      "2023-12-06 14:53:14,522 : INFO : EPOCH 16: training on 99524 raw words (65436 effective words) took 0.2s, 428193 effective words/s\n",
      "2023-12-06 14:53:14,677 : INFO : EPOCH 17: training on 99524 raw words (65456 effective words) took 0.2s, 432837 effective words/s\n",
      "2023-12-06 14:53:14,834 : INFO : EPOCH 18: training on 99524 raw words (65436 effective words) took 0.2s, 428147 effective words/s\n",
      "2023-12-06 14:53:14,995 : INFO : EPOCH 19: training on 99524 raw words (65686 effective words) took 0.2s, 422967 effective words/s\n",
      "2023-12-06 14:53:15,149 : INFO : EPOCH 20: training on 99524 raw words (65459 effective words) took 0.1s, 436768 effective words/s\n",
      "2023-12-06 14:53:15,305 : INFO : EPOCH 21: training on 99524 raw words (65529 effective words) took 0.2s, 434644 effective words/s\n",
      "2023-12-06 14:53:15,460 : INFO : EPOCH 22: training on 99524 raw words (65635 effective words) took 0.2s, 433315 effective words/s\n",
      "2023-12-06 14:53:15,611 : INFO : EPOCH 23: training on 99524 raw words (65521 effective words) took 0.1s, 446783 effective words/s\n",
      "2023-12-06 14:53:15,768 : INFO : EPOCH 24: training on 99524 raw words (65512 effective words) took 0.2s, 429216 effective words/s\n",
      "2023-12-06 14:53:15,922 : INFO : EPOCH 25: training on 99524 raw words (65470 effective words) took 0.1s, 437320 effective words/s\n",
      "2023-12-06 14:53:16,078 : INFO : EPOCH 26: training on 99524 raw words (65667 effective words) took 0.2s, 433431 effective words/s\n",
      "2023-12-06 14:53:16,243 : INFO : EPOCH 27: training on 99524 raw words (65678 effective words) took 0.2s, 407813 effective words/s\n",
      "2023-12-06 14:53:16,400 : INFO : EPOCH 28: training on 99524 raw words (65384 effective words) took 0.2s, 429638 effective words/s\n",
      "2023-12-06 14:53:16,559 : INFO : EPOCH 29: training on 99524 raw words (65617 effective words) took 0.2s, 425693 effective words/s\n",
      "2023-12-06 14:53:16,715 : INFO : EPOCH 30: training on 99524 raw words (65577 effective words) took 0.2s, 432685 effective words/s\n",
      "2023-12-06 14:53:16,870 : INFO : EPOCH 31: training on 99524 raw words (65636 effective words) took 0.2s, 433671 effective words/s\n",
      "2023-12-06 14:53:17,026 : INFO : EPOCH 32: training on 99524 raw words (65426 effective words) took 0.2s, 432940 effective words/s\n",
      "2023-12-06 14:53:17,182 : INFO : EPOCH 33: training on 99524 raw words (65586 effective words) took 0.2s, 430193 effective words/s\n",
      "2023-12-06 14:53:17,335 : INFO : EPOCH 34: training on 99524 raw words (65575 effective words) took 0.1s, 444062 effective words/s\n",
      "2023-12-06 14:53:17,488 : INFO : EPOCH 35: training on 99524 raw words (65667 effective words) took 0.1s, 438515 effective words/s\n",
      "2023-12-06 14:53:17,649 : INFO : EPOCH 36: training on 99524 raw words (65479 effective words) took 0.2s, 420021 effective words/s\n",
      "2023-12-06 14:53:17,801 : INFO : EPOCH 37: training on 99524 raw words (65615 effective words) took 0.1s, 443622 effective words/s\n",
      "2023-12-06 14:53:17,957 : INFO : EPOCH 38: training on 99524 raw words (65355 effective words) took 0.2s, 433461 effective words/s\n",
      "2023-12-06 14:53:18,110 : INFO : EPOCH 39: training on 99524 raw words (65540 effective words) took 0.1s, 439350 effective words/s\n",
      "2023-12-06 14:53:18,267 : INFO : EPOCH 40: training on 99524 raw words (65536 effective words) took 0.2s, 432211 effective words/s\n",
      "2023-12-06 14:53:18,418 : INFO : EPOCH 41: training on 99524 raw words (65775 effective words) took 0.1s, 448967 effective words/s\n",
      "2023-12-06 14:53:18,575 : INFO : EPOCH 42: training on 99524 raw words (65719 effective words) took 0.2s, 431679 effective words/s\n",
      "2023-12-06 14:53:18,729 : INFO : EPOCH 43: training on 99524 raw words (65701 effective words) took 0.1s, 439797 effective words/s\n",
      "2023-12-06 14:53:18,891 : INFO : EPOCH 44: training on 99524 raw words (65406 effective words) took 0.2s, 415811 effective words/s\n",
      "2023-12-06 14:53:19,046 : INFO : EPOCH 45: training on 99524 raw words (65475 effective words) took 0.1s, 437266 effective words/s\n",
      "2023-12-06 14:53:19,201 : INFO : EPOCH 46: training on 99524 raw words (65503 effective words) took 0.2s, 433827 effective words/s\n",
      "2023-12-06 14:53:19,357 : INFO : EPOCH 47: training on 99524 raw words (65428 effective words) took 0.2s, 431767 effective words/s\n",
      "2023-12-06 14:53:19,517 : INFO : EPOCH 48: training on 99524 raw words (65525 effective words) took 0.2s, 421098 effective words/s\n",
      "2023-12-06 14:53:19,671 : INFO : EPOCH 49: training on 99524 raw words (65574 effective words) took 0.1s, 438630 effective words/s\n",
      "2023-12-06 14:53:19,673 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276115 effective words) took 7.8s, 420158 effective words/s', 'datetime': '2023-12-06T14:53:19.672059', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:53:19,673 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:53:19.673061', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 52%|    | 251/486 [39:41<36:53,  9.42s/it]2023-12-06 14:53:23,104 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:53:23,104 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:53:23,125 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:53:23,126 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:53:23,134 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:53:23.134674', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:53:23,135 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:53:23.135675', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:53:23,143 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:53:23,143 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:53:23,144 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:53:23.144495', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:53:23,154 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:53:23,155 : INFO : resetting layer weights\n",
      "2023-12-06 14:53:23,158 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:53:23.158215', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:53:23,308 : INFO : EPOCH 0: training on 99524 raw words (65433 effective words) took 0.1s, 449316 effective words/s\n",
      "2023-12-06 14:53:23,479 : INFO : EPOCH 1: training on 99524 raw words (65566 effective words) took 0.2s, 395768 effective words/s\n",
      "2023-12-06 14:53:23,633 : INFO : EPOCH 2: training on 99524 raw words (65599 effective words) took 0.1s, 439263 effective words/s\n",
      "2023-12-06 14:53:23,788 : INFO : EPOCH 3: training on 99524 raw words (65366 effective words) took 0.1s, 435996 effective words/s\n",
      "2023-12-06 14:53:23,937 : INFO : EPOCH 4: training on 99524 raw words (65587 effective words) took 0.1s, 451990 effective words/s\n",
      "2023-12-06 14:53:24,091 : INFO : EPOCH 5: training on 99524 raw words (65353 effective words) took 0.1s, 437584 effective words/s\n",
      "2023-12-06 14:53:24,246 : INFO : EPOCH 6: training on 99524 raw words (65672 effective words) took 0.2s, 436348 effective words/s\n",
      "2023-12-06 14:53:24,398 : INFO : EPOCH 7: training on 99524 raw words (65557 effective words) took 0.1s, 444469 effective words/s\n",
      "2023-12-06 14:53:24,552 : INFO : EPOCH 8: training on 99524 raw words (65521 effective words) took 0.1s, 438936 effective words/s\n",
      "2023-12-06 14:53:24,706 : INFO : EPOCH 9: training on 99524 raw words (65678 effective words) took 0.1s, 437907 effective words/s\n",
      "2023-12-06 14:53:24,863 : INFO : EPOCH 10: training on 99524 raw words (65403 effective words) took 0.2s, 430686 effective words/s\n",
      "2023-12-06 14:53:25,022 : INFO : EPOCH 11: training on 99524 raw words (65403 effective words) took 0.2s, 422062 effective words/s\n",
      "2023-12-06 14:53:25,177 : INFO : EPOCH 12: training on 99524 raw words (65642 effective words) took 0.2s, 436724 effective words/s\n",
      "2023-12-06 14:53:25,332 : INFO : EPOCH 13: training on 99524 raw words (65519 effective words) took 0.1s, 437110 effective words/s\n",
      "2023-12-06 14:53:25,488 : INFO : EPOCH 14: training on 99524 raw words (65601 effective words) took 0.2s, 436999 effective words/s\n",
      "2023-12-06 14:53:25,640 : INFO : EPOCH 15: training on 99524 raw words (65541 effective words) took 0.1s, 441917 effective words/s\n",
      "2023-12-06 14:53:25,794 : INFO : EPOCH 16: training on 99524 raw words (65531 effective words) took 0.1s, 437371 effective words/s\n",
      "2023-12-06 14:53:25,945 : INFO : EPOCH 17: training on 99524 raw words (65521 effective words) took 0.1s, 445305 effective words/s\n",
      "2023-12-06 14:53:26,098 : INFO : EPOCH 18: training on 99524 raw words (65501 effective words) took 0.1s, 441377 effective words/s\n",
      "2023-12-06 14:53:26,252 : INFO : EPOCH 19: training on 99524 raw words (65607 effective words) took 0.1s, 439256 effective words/s\n",
      "2023-12-06 14:53:26,415 : INFO : EPOCH 20: training on 99524 raw words (65494 effective words) took 0.2s, 413757 effective words/s\n",
      "2023-12-06 14:53:26,569 : INFO : EPOCH 21: training on 99524 raw words (65623 effective words) took 0.1s, 439624 effective words/s\n",
      "2023-12-06 14:53:26,722 : INFO : EPOCH 22: training on 99524 raw words (65477 effective words) took 0.1s, 440228 effective words/s\n",
      "2023-12-06 14:53:26,876 : INFO : EPOCH 23: training on 99524 raw words (65776 effective words) took 0.1s, 438783 effective words/s\n",
      "2023-12-06 14:53:27,024 : INFO : EPOCH 24: training on 99524 raw words (65495 effective words) took 0.1s, 452692 effective words/s\n",
      "2023-12-06 14:53:27,180 : INFO : EPOCH 25: training on 99524 raw words (65526 effective words) took 0.1s, 437124 effective words/s\n",
      "2023-12-06 14:53:27,331 : INFO : EPOCH 26: training on 99524 raw words (65738 effective words) took 0.1s, 445529 effective words/s\n",
      "2023-12-06 14:53:27,486 : INFO : EPOCH 27: training on 99524 raw words (65597 effective words) took 0.2s, 437143 effective words/s\n",
      "2023-12-06 14:53:27,634 : INFO : EPOCH 28: training on 99524 raw words (65519 effective words) took 0.1s, 454124 effective words/s\n",
      "2023-12-06 14:53:27,796 : INFO : EPOCH 29: training on 99524 raw words (65558 effective words) took 0.2s, 418685 effective words/s\n",
      "2023-12-06 14:53:27,950 : INFO : EPOCH 30: training on 99524 raw words (65579 effective words) took 0.1s, 437635 effective words/s\n",
      "2023-12-06 14:53:28,104 : INFO : EPOCH 31: training on 99524 raw words (65546 effective words) took 0.2s, 436952 effective words/s\n",
      "2023-12-06 14:53:28,261 : INFO : EPOCH 32: training on 99524 raw words (65542 effective words) took 0.2s, 433106 effective words/s\n",
      "2023-12-06 14:53:28,416 : INFO : EPOCH 33: training on 99524 raw words (65887 effective words) took 0.2s, 435310 effective words/s\n",
      "2023-12-06 14:53:28,578 : INFO : EPOCH 34: training on 99524 raw words (65518 effective words) took 0.2s, 416824 effective words/s\n",
      "2023-12-06 14:53:28,729 : INFO : EPOCH 35: training on 99524 raw words (65629 effective words) took 0.1s, 447241 effective words/s\n",
      "2023-12-06 14:53:28,884 : INFO : EPOCH 36: training on 99524 raw words (65440 effective words) took 0.1s, 436538 effective words/s\n",
      "2023-12-06 14:53:29,035 : INFO : EPOCH 37: training on 99524 raw words (65379 effective words) took 0.1s, 445848 effective words/s\n",
      "2023-12-06 14:53:29,196 : INFO : EPOCH 38: training on 99524 raw words (65566 effective words) took 0.2s, 416240 effective words/s\n",
      "2023-12-06 14:53:29,346 : INFO : EPOCH 39: training on 99524 raw words (65326 effective words) took 0.1s, 450117 effective words/s\n",
      "2023-12-06 14:53:29,501 : INFO : EPOCH 40: training on 99524 raw words (65574 effective words) took 0.1s, 439987 effective words/s\n",
      "2023-12-06 14:53:29,653 : INFO : EPOCH 41: training on 99524 raw words (65705 effective words) took 0.1s, 442160 effective words/s\n",
      "2023-12-06 14:53:29,807 : INFO : EPOCH 42: training on 99524 raw words (65674 effective words) took 0.1s, 442587 effective words/s\n",
      "2023-12-06 14:53:29,960 : INFO : EPOCH 43: training on 99524 raw words (65453 effective words) took 0.1s, 440359 effective words/s\n",
      "2023-12-06 14:53:30,114 : INFO : EPOCH 44: training on 99524 raw words (65525 effective words) took 0.1s, 439116 effective words/s\n",
      "2023-12-06 14:53:30,270 : INFO : EPOCH 45: training on 99524 raw words (65377 effective words) took 0.2s, 432392 effective words/s\n",
      "2023-12-06 14:53:30,424 : INFO : EPOCH 46: training on 99524 raw words (65426 effective words) took 0.2s, 435133 effective words/s\n",
      "2023-12-06 14:53:30,584 : INFO : EPOCH 47: training on 99524 raw words (65421 effective words) took 0.2s, 422427 effective words/s\n",
      "2023-12-06 14:53:30,737 : INFO : EPOCH 48: training on 99524 raw words (65485 effective words) took 0.1s, 436720 effective words/s\n",
      "2023-12-06 14:53:30,895 : INFO : EPOCH 49: training on 99524 raw words (65627 effective words) took 0.2s, 429127 effective words/s\n",
      "2023-12-06 14:53:30,896 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3277083 effective words) took 7.7s, 423534 effective words/s', 'datetime': '2023-12-06T14:53:30.896447', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:53:30,897 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:53:30.897447', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 52%|    | 252/486 [39:53<39:07, 10.03s/it]2023-12-06 14:53:34,877 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:53:34,877 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:53:34,897 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:53:34,898 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:53:34,905 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:53:34.905042', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:53:34,907 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:53:34.907047', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:53:34,914 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:53:34,915 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:53:34,916 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:53:34.916002', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:53:34,923 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:53:34,924 : INFO : resetting layer weights\n",
      "2023-12-06 14:53:34,927 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:53:34.927784', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:53:35,078 : INFO : EPOCH 0: training on 99524 raw words (62691 effective words) took 0.1s, 429581 effective words/s\n",
      "2023-12-06 14:53:35,238 : INFO : EPOCH 1: training on 99524 raw words (62817 effective words) took 0.2s, 406066 effective words/s\n",
      "2023-12-06 14:53:35,381 : INFO : EPOCH 2: training on 99524 raw words (62650 effective words) took 0.1s, 452011 effective words/s\n",
      "2023-12-06 14:53:35,530 : INFO : EPOCH 3: training on 99524 raw words (62655 effective words) took 0.1s, 434472 effective words/s\n",
      "2023-12-06 14:53:35,671 : INFO : EPOCH 4: training on 99524 raw words (62696 effective words) took 0.1s, 459209 effective words/s\n",
      "2023-12-06 14:53:35,816 : INFO : EPOCH 5: training on 99524 raw words (62664 effective words) took 0.1s, 444549 effective words/s\n",
      "2023-12-06 14:53:35,965 : INFO : EPOCH 6: training on 99524 raw words (62664 effective words) took 0.1s, 436194 effective words/s\n",
      "2023-12-06 14:53:36,114 : INFO : EPOCH 7: training on 99524 raw words (62752 effective words) took 0.1s, 433807 effective words/s\n",
      "2023-12-06 14:53:36,264 : INFO : EPOCH 8: training on 99524 raw words (62721 effective words) took 0.1s, 429333 effective words/s\n",
      "2023-12-06 14:53:36,412 : INFO : EPOCH 9: training on 99524 raw words (62861 effective words) took 0.1s, 437766 effective words/s\n",
      "2023-12-06 14:53:36,413 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627171 effective words) took 1.5s, 422406 effective words/s', 'datetime': '2023-12-06T14:53:36.413723', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:53:36,414 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:53:36.414721', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 52%|    | 253/486 [39:57<32:21,  8.33s/it]2023-12-06 14:53:38,940 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:53:38,941 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:53:38,960 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:53:38,961 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:53:38,968 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:53:38.968838', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:53:38,968 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:53:38.968838', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:53:38,973 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:53:38,974 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:53:38,974 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:53:38.974838', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:53:38,986 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:53:38,988 : INFO : resetting layer weights\n",
      "2023-12-06 14:53:38,992 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:53:38.991357', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:53:39,133 : INFO : EPOCH 0: training on 99524 raw words (62629 effective words) took 0.1s, 457105 effective words/s\n",
      "2023-12-06 14:53:39,306 : INFO : EPOCH 1: training on 99524 raw words (62652 effective words) took 0.2s, 375035 effective words/s\n",
      "2023-12-06 14:53:39,463 : INFO : EPOCH 2: training on 99524 raw words (62757 effective words) took 0.2s, 408127 effective words/s\n",
      "2023-12-06 14:53:39,614 : INFO : EPOCH 3: training on 99524 raw words (62682 effective words) took 0.1s, 429215 effective words/s\n",
      "2023-12-06 14:53:39,771 : INFO : EPOCH 4: training on 99524 raw words (62712 effective words) took 0.2s, 411966 effective words/s\n",
      "2023-12-06 14:53:39,924 : INFO : EPOCH 5: training on 99524 raw words (62791 effective words) took 0.1s, 422936 effective words/s\n",
      "2023-12-06 14:53:40,080 : INFO : EPOCH 6: training on 99524 raw words (62700 effective words) took 0.2s, 416060 effective words/s\n",
      "2023-12-06 14:53:40,232 : INFO : EPOCH 7: training on 99524 raw words (62682 effective words) took 0.1s, 421880 effective words/s\n",
      "2023-12-06 14:53:40,383 : INFO : EPOCH 8: training on 99524 raw words (62787 effective words) took 0.1s, 430438 effective words/s\n",
      "2023-12-06 14:53:40,534 : INFO : EPOCH 9: training on 99524 raw words (62677 effective words) took 0.1s, 425984 effective words/s\n",
      "2023-12-06 14:53:40,535 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627069 effective words) took 1.5s, 406358 effective words/s', 'datetime': '2023-12-06T14:53:40.535482', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:53:40,536 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:53:40.536986', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 52%|    | 254/486 [40:01<27:25,  7.09s/it]2023-12-06 14:53:43,131 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:53:43,132 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:53:43,162 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:53:43,163 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:53:43,168 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:53:43.168103', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:53:43,169 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:53:43.169105', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:53:43,178 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:53:43,179 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:53:43,179 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:53:43.179614', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:53:43,188 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:53:43,188 : INFO : resetting layer weights\n",
      "2023-12-06 14:53:43,192 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:53:43.192245', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:53:43,342 : INFO : EPOCH 0: training on 99524 raw words (62557 effective words) took 0.1s, 428657 effective words/s\n",
      "2023-12-06 14:53:43,506 : INFO : EPOCH 1: training on 99524 raw words (62804 effective words) took 0.2s, 398554 effective words/s\n",
      "2023-12-06 14:53:43,658 : INFO : EPOCH 2: training on 99524 raw words (62832 effective words) took 0.1s, 424489 effective words/s\n",
      "2023-12-06 14:53:43,805 : INFO : EPOCH 3: training on 99524 raw words (62643 effective words) took 0.1s, 439949 effective words/s\n",
      "2023-12-06 14:53:43,956 : INFO : EPOCH 4: training on 99524 raw words (62753 effective words) took 0.1s, 426390 effective words/s\n",
      "2023-12-06 14:53:44,109 : INFO : EPOCH 5: training on 99524 raw words (62645 effective words) took 0.1s, 422083 effective words/s\n",
      "2023-12-06 14:53:44,262 : INFO : EPOCH 6: training on 99524 raw words (62658 effective words) took 0.1s, 420672 effective words/s\n",
      "2023-12-06 14:53:44,415 : INFO : EPOCH 7: training on 99524 raw words (62811 effective words) took 0.1s, 424301 effective words/s\n",
      "2023-12-06 14:53:44,568 : INFO : EPOCH 8: training on 99524 raw words (62734 effective words) took 0.1s, 424337 effective words/s\n",
      "2023-12-06 14:53:44,717 : INFO : EPOCH 9: training on 99524 raw words (62708 effective words) took 0.1s, 433389 effective words/s\n",
      "2023-12-06 14:53:44,718 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627145 effective words) took 1.5s, 411108 effective words/s', 'datetime': '2023-12-06T14:53:44.718271', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:53:44,719 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:53:44.719431', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 52%|    | 255/486 [40:06<24:08,  6.27s/it]2023-12-06 14:53:47,493 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:53:47,494 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:53:47,513 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:53:47,514 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:53:47,519 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:53:47.519719', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:53:47,519 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:53:47.519719', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:53:47,525 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:53:47,526 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:53:47,526 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:53:47.526441', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:53:47,534 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:53:47,535 : INFO : resetting layer weights\n",
      "2023-12-06 14:53:47,537 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:53:47.537704', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:53:47,673 : INFO : EPOCH 0: training on 99524 raw words (62692 effective words) took 0.1s, 479023 effective words/s\n",
      "2023-12-06 14:53:47,846 : INFO : EPOCH 1: training on 99524 raw words (62878 effective words) took 0.2s, 373705 effective words/s\n",
      "2023-12-06 14:53:47,998 : INFO : EPOCH 2: training on 99524 raw words (62810 effective words) took 0.1s, 434598 effective words/s\n",
      "2023-12-06 14:53:48,143 : INFO : EPOCH 3: training on 99524 raw words (62619 effective words) took 0.1s, 445270 effective words/s\n",
      "2023-12-06 14:53:48,289 : INFO : EPOCH 4: training on 99524 raw words (62770 effective words) took 0.1s, 442255 effective words/s\n",
      "2023-12-06 14:53:48,436 : INFO : EPOCH 5: training on 99524 raw words (62761 effective words) took 0.1s, 440405 effective words/s\n",
      "2023-12-06 14:53:48,584 : INFO : EPOCH 6: training on 99524 raw words (62770 effective words) took 0.1s, 437642 effective words/s\n",
      "2023-12-06 14:53:48,734 : INFO : EPOCH 7: training on 99524 raw words (62688 effective words) took 0.1s, 432701 effective words/s\n",
      "2023-12-06 14:53:48,880 : INFO : EPOCH 8: training on 99524 raw words (62647 effective words) took 0.1s, 441490 effective words/s\n",
      "2023-12-06 14:53:49,027 : INFO : EPOCH 9: training on 99524 raw words (62808 effective words) took 0.1s, 439698 effective words/s\n",
      "2023-12-06 14:53:49,175 : INFO : EPOCH 10: training on 99524 raw words (62680 effective words) took 0.1s, 435420 effective words/s\n",
      "2023-12-06 14:53:49,328 : INFO : EPOCH 11: training on 99524 raw words (62648 effective words) took 0.1s, 423843 effective words/s\n",
      "2023-12-06 14:53:49,474 : INFO : EPOCH 12: training on 99524 raw words (62703 effective words) took 0.1s, 443140 effective words/s\n",
      "2023-12-06 14:53:49,621 : INFO : EPOCH 13: training on 99524 raw words (62655 effective words) took 0.1s, 438819 effective words/s\n",
      "2023-12-06 14:53:49,768 : INFO : EPOCH 14: training on 99524 raw words (62792 effective words) took 0.1s, 440311 effective words/s\n",
      "2023-12-06 14:53:49,916 : INFO : EPOCH 15: training on 99524 raw words (62632 effective words) took 0.1s, 434852 effective words/s\n",
      "2023-12-06 14:53:50,062 : INFO : EPOCH 16: training on 99524 raw words (62799 effective words) took 0.1s, 442198 effective words/s\n",
      "2023-12-06 14:53:50,205 : INFO : EPOCH 17: training on 99524 raw words (62631 effective words) took 0.1s, 454076 effective words/s\n",
      "2023-12-06 14:53:50,356 : INFO : EPOCH 18: training on 99524 raw words (62603 effective words) took 0.1s, 427863 effective words/s\n",
      "2023-12-06 14:53:50,505 : INFO : EPOCH 19: training on 99524 raw words (62888 effective words) took 0.1s, 435312 effective words/s\n",
      "2023-12-06 14:53:50,651 : INFO : EPOCH 20: training on 99524 raw words (62701 effective words) took 0.1s, 442604 effective words/s\n",
      "2023-12-06 14:53:50,802 : INFO : EPOCH 21: training on 99524 raw words (62802 effective words) took 0.1s, 425932 effective words/s\n",
      "2023-12-06 14:53:50,951 : INFO : EPOCH 22: training on 99524 raw words (62890 effective words) took 0.1s, 437939 effective words/s\n",
      "2023-12-06 14:53:51,099 : INFO : EPOCH 23: training on 99524 raw words (62782 effective words) took 0.1s, 435778 effective words/s\n",
      "2023-12-06 14:53:51,244 : INFO : EPOCH 24: training on 99524 raw words (62866 effective words) took 0.1s, 448637 effective words/s\n",
      "2023-12-06 14:53:51,396 : INFO : EPOCH 25: training on 99524 raw words (62746 effective words) took 0.1s, 426730 effective words/s\n",
      "2023-12-06 14:53:51,541 : INFO : EPOCH 26: training on 99524 raw words (62788 effective words) took 0.1s, 445269 effective words/s\n",
      "2023-12-06 14:53:51,692 : INFO : EPOCH 27: training on 99524 raw words (62863 effective words) took 0.1s, 430987 effective words/s\n",
      "2023-12-06 14:53:51,845 : INFO : EPOCH 28: training on 99524 raw words (62728 effective words) took 0.2s, 417850 effective words/s\n",
      "2023-12-06 14:53:51,994 : INFO : EPOCH 29: training on 99524 raw words (62684 effective words) took 0.1s, 434907 effective words/s\n",
      "2023-12-06 14:53:51,995 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1882324 effective words) took 4.5s, 422296 effective words/s', 'datetime': '2023-12-06T14:53:51.995304', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:53:51,996 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:53:51.996624', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 53%|    | 256/486 [40:13<25:17,  6.60s/it]2023-12-06 14:53:54,844 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:53:54,845 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:53:54,867 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:53:54,868 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:53:54,872 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:53:54.872491', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:53:54,873 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:53:54.873494', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:53:54,878 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:53:54,879 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:53:54,879 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:53:54.879694', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:53:54,888 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:53:54,888 : INFO : resetting layer weights\n",
      "2023-12-06 14:53:54,891 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:53:54.891384', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:53:55,035 : INFO : EPOCH 0: training on 99524 raw words (62794 effective words) took 0.1s, 445420 effective words/s\n",
      "2023-12-06 14:53:55,206 : INFO : EPOCH 1: training on 99524 raw words (62666 effective words) took 0.2s, 382316 effective words/s\n",
      "2023-12-06 14:53:55,375 : INFO : EPOCH 2: training on 99524 raw words (62773 effective words) took 0.2s, 378214 effective words/s\n",
      "2023-12-06 14:53:55,531 : INFO : EPOCH 3: training on 99524 raw words (62587 effective words) took 0.1s, 418067 effective words/s\n",
      "2023-12-06 14:53:55,687 : INFO : EPOCH 4: training on 99524 raw words (62711 effective words) took 0.2s, 413077 effective words/s\n",
      "2023-12-06 14:53:55,842 : INFO : EPOCH 5: training on 99524 raw words (62738 effective words) took 0.2s, 416201 effective words/s\n",
      "2023-12-06 14:53:55,998 : INFO : EPOCH 6: training on 99524 raw words (62640 effective words) took 0.2s, 414443 effective words/s\n",
      "2023-12-06 14:53:56,156 : INFO : EPOCH 7: training on 99524 raw words (62597 effective words) took 0.2s, 408931 effective words/s\n",
      "2023-12-06 14:53:56,309 : INFO : EPOCH 8: training on 99524 raw words (62527 effective words) took 0.1s, 422409 effective words/s\n",
      "2023-12-06 14:53:56,470 : INFO : EPOCH 9: training on 99524 raw words (62774 effective words) took 0.2s, 402930 effective words/s\n",
      "2023-12-06 14:53:56,624 : INFO : EPOCH 10: training on 99524 raw words (62595 effective words) took 0.1s, 418216 effective words/s\n",
      "2023-12-06 14:53:56,787 : INFO : EPOCH 11: training on 99524 raw words (62801 effective words) took 0.2s, 398351 effective words/s\n",
      "2023-12-06 14:53:56,941 : INFO : EPOCH 12: training on 99524 raw words (62755 effective words) took 0.1s, 419811 effective words/s\n",
      "2023-12-06 14:53:57,097 : INFO : EPOCH 13: training on 99524 raw words (62722 effective words) took 0.2s, 412889 effective words/s\n",
      "2023-12-06 14:53:57,249 : INFO : EPOCH 14: training on 99524 raw words (62672 effective words) took 0.1s, 427921 effective words/s\n",
      "2023-12-06 14:53:57,409 : INFO : EPOCH 15: training on 99524 raw words (62565 effective words) took 0.2s, 399132 effective words/s\n",
      "2023-12-06 14:53:57,571 : INFO : EPOCH 16: training on 99524 raw words (62732 effective words) took 0.2s, 399763 effective words/s\n",
      "2023-12-06 14:53:57,740 : INFO : EPOCH 17: training on 99524 raw words (62663 effective words) took 0.2s, 382002 effective words/s\n",
      "2023-12-06 14:53:57,907 : INFO : EPOCH 18: training on 99524 raw words (62576 effective words) took 0.2s, 386167 effective words/s\n",
      "2023-12-06 14:53:58,066 : INFO : EPOCH 19: training on 99524 raw words (62738 effective words) took 0.2s, 406898 effective words/s\n",
      "2023-12-06 14:53:58,227 : INFO : EPOCH 20: training on 99524 raw words (62783 effective words) took 0.2s, 403999 effective words/s\n",
      "2023-12-06 14:53:58,382 : INFO : EPOCH 21: training on 99524 raw words (62807 effective words) took 0.2s, 415333 effective words/s\n",
      "2023-12-06 14:53:58,557 : INFO : EPOCH 22: training on 99524 raw words (62716 effective words) took 0.2s, 367080 effective words/s\n",
      "2023-12-06 14:53:58,738 : INFO : EPOCH 23: training on 99524 raw words (62794 effective words) took 0.2s, 358646 effective words/s\n",
      "2023-12-06 14:53:58,893 : INFO : EPOCH 24: training on 99524 raw words (62670 effective words) took 0.1s, 420146 effective words/s\n",
      "2023-12-06 14:53:59,047 : INFO : EPOCH 25: training on 99524 raw words (62715 effective words) took 0.2s, 417242 effective words/s\n",
      "2023-12-06 14:53:59,203 : INFO : EPOCH 26: training on 99524 raw words (62808 effective words) took 0.2s, 416007 effective words/s\n",
      "2023-12-06 14:53:59,357 : INFO : EPOCH 27: training on 99524 raw words (63043 effective words) took 0.1s, 421768 effective words/s\n",
      "2023-12-06 14:53:59,510 : INFO : EPOCH 28: training on 99524 raw words (62724 effective words) took 0.1s, 421851 effective words/s\n",
      "2023-12-06 14:53:59,664 : INFO : EPOCH 29: training on 99524 raw words (62775 effective words) took 0.2s, 417321 effective words/s\n",
      "2023-12-06 14:53:59,666 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881461 effective words) took 4.8s, 394068 effective words/s', 'datetime': '2023-12-06T14:53:59.666192', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:53:59,667 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:53:59.667200', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 53%|    | 257/486 [40:21<26:40,  6.99s/it]2023-12-06 14:54:02,746 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:54:02,747 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:54:02,767 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:54:02,768 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:54:02,774 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:54:02.774272', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:54:02,775 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:54:02.775272', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:54:02,780 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:54:02,781 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:54:02,781 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:54:02.781289', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:54:02,789 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:54:02,790 : INFO : resetting layer weights\n",
      "2023-12-06 14:54:02,794 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:54:02.794804', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:54:02,949 : INFO : EPOCH 0: training on 99524 raw words (62800 effective words) took 0.2s, 416554 effective words/s\n",
      "2023-12-06 14:54:03,116 : INFO : EPOCH 1: training on 99524 raw words (62753 effective words) took 0.2s, 389567 effective words/s\n",
      "2023-12-06 14:54:03,270 : INFO : EPOCH 2: training on 99524 raw words (62719 effective words) took 0.1s, 418648 effective words/s\n",
      "2023-12-06 14:54:03,420 : INFO : EPOCH 3: training on 99524 raw words (62642 effective words) took 0.1s, 432129 effective words/s\n",
      "2023-12-06 14:54:03,571 : INFO : EPOCH 4: training on 99524 raw words (62796 effective words) took 0.1s, 426975 effective words/s\n",
      "2023-12-06 14:54:03,720 : INFO : EPOCH 5: training on 99524 raw words (62779 effective words) took 0.1s, 431795 effective words/s\n",
      "2023-12-06 14:54:03,875 : INFO : EPOCH 6: training on 99524 raw words (62859 effective words) took 0.1s, 420799 effective words/s\n",
      "2023-12-06 14:54:04,028 : INFO : EPOCH 7: training on 99524 raw words (62843 effective words) took 0.1s, 425598 effective words/s\n",
      "2023-12-06 14:54:04,181 : INFO : EPOCH 8: training on 99524 raw words (62590 effective words) took 0.1s, 418669 effective words/s\n",
      "2023-12-06 14:54:04,332 : INFO : EPOCH 9: training on 99524 raw words (62768 effective words) took 0.1s, 429098 effective words/s\n",
      "2023-12-06 14:54:04,486 : INFO : EPOCH 10: training on 99524 raw words (62676 effective words) took 0.1s, 419848 effective words/s\n",
      "2023-12-06 14:54:04,643 : INFO : EPOCH 11: training on 99524 raw words (62794 effective words) took 0.2s, 410382 effective words/s\n",
      "2023-12-06 14:54:04,792 : INFO : EPOCH 12: training on 99524 raw words (62706 effective words) took 0.1s, 433792 effective words/s\n",
      "2023-12-06 14:54:04,945 : INFO : EPOCH 13: training on 99524 raw words (62673 effective words) took 0.1s, 423188 effective words/s\n",
      "2023-12-06 14:54:05,098 : INFO : EPOCH 14: training on 99524 raw words (62697 effective words) took 0.1s, 419480 effective words/s\n",
      "2023-12-06 14:54:05,253 : INFO : EPOCH 15: training on 99524 raw words (62764 effective words) took 0.1s, 418768 effective words/s\n",
      "2023-12-06 14:54:05,401 : INFO : EPOCH 16: training on 99524 raw words (62819 effective words) took 0.1s, 437922 effective words/s\n",
      "2023-12-06 14:54:05,562 : INFO : EPOCH 17: training on 99524 raw words (62647 effective words) took 0.2s, 403547 effective words/s\n",
      "2023-12-06 14:54:05,715 : INFO : EPOCH 18: training on 99524 raw words (62612 effective words) took 0.1s, 420780 effective words/s\n",
      "2023-12-06 14:54:05,871 : INFO : EPOCH 19: training on 99524 raw words (62922 effective words) took 0.2s, 417164 effective words/s\n",
      "2023-12-06 14:54:06,031 : INFO : EPOCH 20: training on 99524 raw words (62715 effective words) took 0.2s, 403659 effective words/s\n",
      "2023-12-06 14:54:06,183 : INFO : EPOCH 21: training on 99524 raw words (62841 effective words) took 0.1s, 421587 effective words/s\n",
      "2023-12-06 14:54:06,337 : INFO : EPOCH 22: training on 99524 raw words (62742 effective words) took 0.1s, 422315 effective words/s\n",
      "2023-12-06 14:54:06,490 : INFO : EPOCH 23: training on 99524 raw words (62578 effective words) took 0.1s, 419733 effective words/s\n",
      "2023-12-06 14:54:06,642 : INFO : EPOCH 24: training on 99524 raw words (62778 effective words) took 0.1s, 423446 effective words/s\n",
      "2023-12-06 14:54:06,797 : INFO : EPOCH 25: training on 99524 raw words (62742 effective words) took 0.1s, 420757 effective words/s\n",
      "2023-12-06 14:54:06,947 : INFO : EPOCH 26: training on 99524 raw words (62849 effective words) took 0.1s, 429332 effective words/s\n",
      "2023-12-06 14:54:07,105 : INFO : EPOCH 27: training on 99524 raw words (62999 effective words) took 0.2s, 411444 effective words/s\n",
      "2023-12-06 14:54:07,258 : INFO : EPOCH 28: training on 99524 raw words (62649 effective words) took 0.1s, 422682 effective words/s\n",
      "2023-12-06 14:54:07,411 : INFO : EPOCH 29: training on 99524 raw words (62820 effective words) took 0.1s, 419977 effective words/s\n",
      "2023-12-06 14:54:07,413 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1882572 effective words) took 4.6s, 407682 effective words/s', 'datetime': '2023-12-06T14:54:07.412614', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:54:07,413 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:54:07.413614', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 53%|    | 258/486 [40:29<28:00,  7.37s/it]2023-12-06 14:54:11,003 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:54:11,003 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:54:11,024 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:54:11,025 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:54:11,030 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:54:11.030992', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:54:11,031 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:54:11.031992', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:54:11,037 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:54:11,037 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:54:11,038 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:54:11.038502', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:54:11,051 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:54:11,051 : INFO : resetting layer weights\n",
      "2023-12-06 14:54:11,055 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:54:11.055423', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:54:11,204 : INFO : EPOCH 0: training on 99524 raw words (62702 effective words) took 0.1s, 431319 effective words/s\n",
      "2023-12-06 14:54:11,368 : INFO : EPOCH 1: training on 99524 raw words (62747 effective words) took 0.2s, 397587 effective words/s\n",
      "2023-12-06 14:54:11,518 : INFO : EPOCH 2: training on 99524 raw words (62776 effective words) took 0.1s, 430556 effective words/s\n",
      "2023-12-06 14:54:11,662 : INFO : EPOCH 3: training on 99524 raw words (62641 effective words) took 0.1s, 450124 effective words/s\n",
      "2023-12-06 14:54:11,811 : INFO : EPOCH 4: training on 99524 raw words (62823 effective words) took 0.1s, 435330 effective words/s\n",
      "2023-12-06 14:54:11,959 : INFO : EPOCH 5: training on 99524 raw words (62898 effective words) took 0.1s, 437449 effective words/s\n",
      "2023-12-06 14:54:12,107 : INFO : EPOCH 6: training on 99524 raw words (62677 effective words) took 0.1s, 436324 effective words/s\n",
      "2023-12-06 14:54:12,249 : INFO : EPOCH 7: training on 99524 raw words (62658 effective words) took 0.1s, 453507 effective words/s\n",
      "2023-12-06 14:54:12,404 : INFO : EPOCH 8: training on 99524 raw words (62861 effective words) took 0.2s, 418342 effective words/s\n",
      "2023-12-06 14:54:12,551 : INFO : EPOCH 9: training on 99524 raw words (62715 effective words) took 0.1s, 436749 effective words/s\n",
      "2023-12-06 14:54:12,704 : INFO : EPOCH 10: training on 99524 raw words (62763 effective words) took 0.1s, 424340 effective words/s\n",
      "2023-12-06 14:54:12,851 : INFO : EPOCH 11: training on 99524 raw words (62718 effective words) took 0.1s, 439085 effective words/s\n",
      "2023-12-06 14:54:13,000 : INFO : EPOCH 12: training on 99524 raw words (62661 effective words) took 0.1s, 435329 effective words/s\n",
      "2023-12-06 14:54:13,145 : INFO : EPOCH 13: training on 99524 raw words (62584 effective words) took 0.1s, 444356 effective words/s\n",
      "2023-12-06 14:54:13,295 : INFO : EPOCH 14: training on 99524 raw words (62678 effective words) took 0.1s, 432621 effective words/s\n",
      "2023-12-06 14:54:13,444 : INFO : EPOCH 15: training on 99524 raw words (62778 effective words) took 0.1s, 431812 effective words/s\n",
      "2023-12-06 14:54:13,594 : INFO : EPOCH 16: training on 99524 raw words (62779 effective words) took 0.1s, 429593 effective words/s\n",
      "2023-12-06 14:54:13,747 : INFO : EPOCH 17: training on 99524 raw words (62485 effective words) took 0.1s, 422976 effective words/s\n",
      "2023-12-06 14:54:13,896 : INFO : EPOCH 18: training on 99524 raw words (62650 effective words) took 0.1s, 434552 effective words/s\n",
      "2023-12-06 14:54:14,044 : INFO : EPOCH 19: training on 99524 raw words (62902 effective words) took 0.1s, 434732 effective words/s\n",
      "2023-12-06 14:54:14,196 : INFO : EPOCH 20: training on 99524 raw words (62716 effective words) took 0.1s, 426192 effective words/s\n",
      "2023-12-06 14:54:14,340 : INFO : EPOCH 21: training on 99524 raw words (62793 effective words) took 0.1s, 453565 effective words/s\n",
      "2023-12-06 14:54:14,488 : INFO : EPOCH 22: training on 99524 raw words (62823 effective words) took 0.1s, 435765 effective words/s\n",
      "2023-12-06 14:54:14,639 : INFO : EPOCH 23: training on 99524 raw words (62797 effective words) took 0.1s, 430086 effective words/s\n",
      "2023-12-06 14:54:14,787 : INFO : EPOCH 24: training on 99524 raw words (62689 effective words) took 0.1s, 433866 effective words/s\n",
      "2023-12-06 14:54:14,932 : INFO : EPOCH 25: training on 99524 raw words (62757 effective words) took 0.1s, 448687 effective words/s\n",
      "2023-12-06 14:54:15,089 : INFO : EPOCH 26: training on 99524 raw words (62832 effective words) took 0.2s, 410894 effective words/s\n",
      "2023-12-06 14:54:15,237 : INFO : EPOCH 27: training on 99524 raw words (62989 effective words) took 0.1s, 442032 effective words/s\n",
      "2023-12-06 14:54:15,384 : INFO : EPOCH 28: training on 99524 raw words (62630 effective words) took 0.1s, 436669 effective words/s\n",
      "2023-12-06 14:54:15,533 : INFO : EPOCH 29: training on 99524 raw words (62767 effective words) took 0.1s, 434588 effective words/s\n",
      "2023-12-06 14:54:15,685 : INFO : EPOCH 30: training on 99524 raw words (62678 effective words) took 0.1s, 425774 effective words/s\n",
      "2023-12-06 14:54:15,834 : INFO : EPOCH 31: training on 99524 raw words (62749 effective words) took 0.1s, 434043 effective words/s\n",
      "2023-12-06 14:54:15,991 : INFO : EPOCH 32: training on 99524 raw words (62798 effective words) took 0.2s, 413338 effective words/s\n",
      "2023-12-06 14:54:16,158 : INFO : EPOCH 33: training on 99524 raw words (62931 effective words) took 0.2s, 387105 effective words/s\n",
      "2023-12-06 14:54:16,303 : INFO : EPOCH 34: training on 99524 raw words (62823 effective words) took 0.1s, 445942 effective words/s\n",
      "2023-12-06 14:54:16,457 : INFO : EPOCH 35: training on 99524 raw words (62706 effective words) took 0.1s, 420855 effective words/s\n",
      "2023-12-06 14:54:16,608 : INFO : EPOCH 36: training on 99524 raw words (62624 effective words) took 0.1s, 428274 effective words/s\n",
      "2023-12-06 14:54:16,765 : INFO : EPOCH 37: training on 99524 raw words (62612 effective words) took 0.2s, 411886 effective words/s\n",
      "2023-12-06 14:54:16,915 : INFO : EPOCH 38: training on 99524 raw words (62576 effective words) took 0.1s, 428172 effective words/s\n",
      "2023-12-06 14:54:17,068 : INFO : EPOCH 39: training on 99524 raw words (62694 effective words) took 0.1s, 423833 effective words/s\n",
      "2023-12-06 14:54:17,217 : INFO : EPOCH 40: training on 99524 raw words (62574 effective words) took 0.1s, 433223 effective words/s\n",
      "2023-12-06 14:54:17,367 : INFO : EPOCH 41: training on 99524 raw words (62860 effective words) took 0.1s, 431957 effective words/s\n",
      "2023-12-06 14:54:17,510 : INFO : EPOCH 42: training on 99524 raw words (62662 effective words) took 0.1s, 452627 effective words/s\n",
      "2023-12-06 14:54:17,668 : INFO : EPOCH 43: training on 99524 raw words (62792 effective words) took 0.2s, 410080 effective words/s\n",
      "2023-12-06 14:54:17,815 : INFO : EPOCH 44: training on 99524 raw words (62655 effective words) took 0.1s, 438274 effective words/s\n",
      "2023-12-06 14:54:17,964 : INFO : EPOCH 45: training on 99524 raw words (62444 effective words) took 0.1s, 433864 effective words/s\n",
      "2023-12-06 14:54:18,113 : INFO : EPOCH 46: training on 99524 raw words (62780 effective words) took 0.1s, 430776 effective words/s\n",
      "2023-12-06 14:54:18,268 : INFO : EPOCH 47: training on 99524 raw words (62778 effective words) took 0.1s, 418802 effective words/s\n",
      "2023-12-06 14:54:18,417 : INFO : EPOCH 48: training on 99524 raw words (62725 effective words) took 0.1s, 433574 effective words/s\n",
      "2023-12-06 14:54:18,564 : INFO : EPOCH 49: training on 99524 raw words (62733 effective words) took 0.1s, 440929 effective words/s\n",
      "2023-12-06 14:54:18,565 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136483 effective words) took 7.5s, 417666 effective words/s', 'datetime': '2023-12-06T14:54:18.565730', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:54:18,565 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:54:18.565730', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 53%|    | 259/486 [40:40<31:55,  8.44s/it]2023-12-06 14:54:21,943 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:54:21,944 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:54:21,965 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:54:21,966 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:54:21,972 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:54:21.972508', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:54:21,973 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:54:21.973508', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:54:21,981 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:54:21,982 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:54:21,982 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:54:21.982905', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:54:21,989 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:54:21,991 : INFO : resetting layer weights\n",
      "2023-12-06 14:54:21,995 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:54:21.995419', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:54:22,152 : INFO : EPOCH 0: training on 99524 raw words (62803 effective words) took 0.2s, 409953 effective words/s\n",
      "2023-12-06 14:54:22,317 : INFO : EPOCH 1: training on 99524 raw words (62747 effective words) took 0.2s, 402241 effective words/s\n",
      "2023-12-06 14:54:22,471 : INFO : EPOCH 2: training on 99524 raw words (62721 effective words) took 0.1s, 418411 effective words/s\n",
      "2023-12-06 14:54:22,624 : INFO : EPOCH 3: training on 99524 raw words (62673 effective words) took 0.1s, 423435 effective words/s\n",
      "2023-12-06 14:54:22,780 : INFO : EPOCH 4: training on 99524 raw words (62683 effective words) took 0.2s, 413165 effective words/s\n",
      "2023-12-06 14:54:22,937 : INFO : EPOCH 5: training on 99524 raw words (62652 effective words) took 0.2s, 411613 effective words/s\n",
      "2023-12-06 14:54:23,098 : INFO : EPOCH 6: training on 99524 raw words (62704 effective words) took 0.2s, 401559 effective words/s\n",
      "2023-12-06 14:54:23,252 : INFO : EPOCH 7: training on 99524 raw words (62826 effective words) took 0.2s, 416685 effective words/s\n",
      "2023-12-06 14:54:23,411 : INFO : EPOCH 8: training on 99524 raw words (62806 effective words) took 0.2s, 407376 effective words/s\n",
      "2023-12-06 14:54:23,566 : INFO : EPOCH 9: training on 99524 raw words (62685 effective words) took 0.1s, 418028 effective words/s\n",
      "2023-12-06 14:54:23,725 : INFO : EPOCH 10: training on 99524 raw words (62578 effective words) took 0.2s, 406081 effective words/s\n",
      "2023-12-06 14:54:23,879 : INFO : EPOCH 11: training on 99524 raw words (62678 effective words) took 0.2s, 417445 effective words/s\n",
      "2023-12-06 14:54:24,036 : INFO : EPOCH 12: training on 99524 raw words (62712 effective words) took 0.2s, 410770 effective words/s\n",
      "2023-12-06 14:54:24,194 : INFO : EPOCH 13: training on 99524 raw words (62746 effective words) took 0.2s, 410659 effective words/s\n",
      "2023-12-06 14:54:24,345 : INFO : EPOCH 14: training on 99524 raw words (62711 effective words) took 0.1s, 426865 effective words/s\n",
      "2023-12-06 14:54:24,503 : INFO : EPOCH 15: training on 99524 raw words (62754 effective words) took 0.2s, 409867 effective words/s\n",
      "2023-12-06 14:54:24,659 : INFO : EPOCH 16: training on 99524 raw words (62691 effective words) took 0.2s, 415422 effective words/s\n",
      "2023-12-06 14:54:24,812 : INFO : EPOCH 17: training on 99524 raw words (62669 effective words) took 0.1s, 419895 effective words/s\n",
      "2023-12-06 14:54:24,975 : INFO : EPOCH 18: training on 99524 raw words (62662 effective words) took 0.2s, 396566 effective words/s\n",
      "2023-12-06 14:54:25,132 : INFO : EPOCH 19: training on 99524 raw words (62795 effective words) took 0.2s, 414666 effective words/s\n",
      "2023-12-06 14:54:25,288 : INFO : EPOCH 20: training on 99524 raw words (62710 effective words) took 0.2s, 411460 effective words/s\n",
      "2023-12-06 14:54:25,440 : INFO : EPOCH 21: training on 99524 raw words (62758 effective words) took 0.1s, 424170 effective words/s\n",
      "2023-12-06 14:54:25,594 : INFO : EPOCH 22: training on 99524 raw words (62794 effective words) took 0.1s, 420889 effective words/s\n",
      "2023-12-06 14:54:25,750 : INFO : EPOCH 23: training on 99524 raw words (62756 effective words) took 0.2s, 416895 effective words/s\n",
      "2023-12-06 14:54:25,904 : INFO : EPOCH 24: training on 99524 raw words (62804 effective words) took 0.2s, 415061 effective words/s\n",
      "2023-12-06 14:54:26,058 : INFO : EPOCH 25: training on 99524 raw words (62719 effective words) took 0.1s, 420897 effective words/s\n",
      "2023-12-06 14:54:26,221 : INFO : EPOCH 26: training on 99524 raw words (62897 effective words) took 0.2s, 400035 effective words/s\n",
      "2023-12-06 14:54:26,375 : INFO : EPOCH 27: training on 99524 raw words (62881 effective words) took 0.2s, 418468 effective words/s\n",
      "2023-12-06 14:54:26,526 : INFO : EPOCH 28: training on 99524 raw words (62804 effective words) took 0.1s, 427543 effective words/s\n",
      "2023-12-06 14:54:26,683 : INFO : EPOCH 29: training on 99524 raw words (62696 effective words) took 0.2s, 409550 effective words/s\n",
      "2023-12-06 14:54:26,839 : INFO : EPOCH 30: training on 99524 raw words (62729 effective words) took 0.2s, 415450 effective words/s\n",
      "2023-12-06 14:54:26,994 : INFO : EPOCH 31: training on 99524 raw words (62702 effective words) took 0.2s, 416415 effective words/s\n",
      "2023-12-06 14:54:27,149 : INFO : EPOCH 32: training on 99524 raw words (62743 effective words) took 0.2s, 414983 effective words/s\n",
      "2023-12-06 14:54:27,318 : INFO : EPOCH 33: training on 99524 raw words (62670 effective words) took 0.2s, 381095 effective words/s\n",
      "2023-12-06 14:54:27,476 : INFO : EPOCH 34: training on 99524 raw words (62743 effective words) took 0.2s, 407310 effective words/s\n",
      "2023-12-06 14:54:27,629 : INFO : EPOCH 35: training on 99524 raw words (62764 effective words) took 0.1s, 424388 effective words/s\n",
      "2023-12-06 14:54:27,787 : INFO : EPOCH 36: training on 99524 raw words (62760 effective words) took 0.2s, 409766 effective words/s\n",
      "2023-12-06 14:54:27,942 : INFO : EPOCH 37: training on 99524 raw words (62654 effective words) took 0.1s, 417887 effective words/s\n",
      "2023-12-06 14:54:28,095 : INFO : EPOCH 38: training on 99524 raw words (62493 effective words) took 0.1s, 420530 effective words/s\n",
      "2023-12-06 14:54:28,248 : INFO : EPOCH 39: training on 99524 raw words (62529 effective words) took 0.1s, 417962 effective words/s\n",
      "2023-12-06 14:54:28,403 : INFO : EPOCH 40: training on 99524 raw words (62599 effective words) took 0.1s, 419284 effective words/s\n",
      "2023-12-06 14:54:28,561 : INFO : EPOCH 41: training on 99524 raw words (62857 effective words) took 0.2s, 407193 effective words/s\n",
      "2023-12-06 14:54:28,717 : INFO : EPOCH 42: training on 99524 raw words (62767 effective words) took 0.1s, 418994 effective words/s\n",
      "2023-12-06 14:54:28,869 : INFO : EPOCH 43: training on 99524 raw words (62865 effective words) took 0.1s, 422470 effective words/s\n",
      "2023-12-06 14:54:29,024 : INFO : EPOCH 44: training on 99524 raw words (62660 effective words) took 0.2s, 417540 effective words/s\n",
      "2023-12-06 14:54:29,179 : INFO : EPOCH 45: training on 99524 raw words (62666 effective words) took 0.2s, 417558 effective words/s\n",
      "2023-12-06 14:54:29,335 : INFO : EPOCH 46: training on 99524 raw words (62537 effective words) took 0.2s, 410096 effective words/s\n",
      "2023-12-06 14:54:29,493 : INFO : EPOCH 47: training on 99524 raw words (62721 effective words) took 0.2s, 412051 effective words/s\n",
      "2023-12-06 14:54:29,648 : INFO : EPOCH 48: training on 99524 raw words (62705 effective words) took 0.2s, 415603 effective words/s\n",
      "2023-12-06 14:54:29,810 : INFO : EPOCH 49: training on 99524 raw words (62804 effective words) took 0.2s, 399032 effective words/s\n",
      "2023-12-06 14:54:29,811 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136083 effective words) took 7.8s, 401243 effective words/s', 'datetime': '2023-12-06T14:54:29.811899', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:54:29,811 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:54:29.811899', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 53%|    | 260/486 [40:51<35:03,  9.31s/it]2023-12-06 14:54:33,270 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:54:33,270 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:54:33,294 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:54:33,295 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:54:33,302 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:54:33.302828', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:54:33,302 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:54:33.302828', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:54:33,310 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:54:33,311 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:54:33,311 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:54:33.311344', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:54:33,320 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:54:33,320 : INFO : resetting layer weights\n",
      "2023-12-06 14:54:33,323 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:54:33.323402', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:54:33,478 : INFO : EPOCH 0: training on 99524 raw words (62620 effective words) took 0.2s, 413142 effective words/s\n",
      "2023-12-06 14:54:33,649 : INFO : EPOCH 1: training on 99524 raw words (62711 effective words) took 0.2s, 381536 effective words/s\n",
      "2023-12-06 14:54:33,798 : INFO : EPOCH 2: training on 99524 raw words (62748 effective words) took 0.1s, 435329 effective words/s\n",
      "2023-12-06 14:54:33,953 : INFO : EPOCH 3: training on 99524 raw words (62763 effective words) took 0.2s, 415361 effective words/s\n",
      "2023-12-06 14:54:34,108 : INFO : EPOCH 4: training on 99524 raw words (62594 effective words) took 0.2s, 415879 effective words/s\n",
      "2023-12-06 14:54:34,261 : INFO : EPOCH 5: training on 99524 raw words (62756 effective words) took 0.1s, 424117 effective words/s\n",
      "2023-12-06 14:54:34,410 : INFO : EPOCH 6: training on 99524 raw words (62709 effective words) took 0.1s, 431731 effective words/s\n",
      "2023-12-06 14:54:34,566 : INFO : EPOCH 7: training on 99524 raw words (62741 effective words) took 0.1s, 418998 effective words/s\n",
      "2023-12-06 14:54:34,720 : INFO : EPOCH 8: training on 99524 raw words (62759 effective words) took 0.2s, 417228 effective words/s\n",
      "2023-12-06 14:54:34,880 : INFO : EPOCH 9: training on 99524 raw words (62710 effective words) took 0.2s, 402154 effective words/s\n",
      "2023-12-06 14:54:35,031 : INFO : EPOCH 10: training on 99524 raw words (62693 effective words) took 0.1s, 429362 effective words/s\n",
      "2023-12-06 14:54:35,186 : INFO : EPOCH 11: training on 99524 raw words (62753 effective words) took 0.2s, 415856 effective words/s\n",
      "2023-12-06 14:54:35,340 : INFO : EPOCH 12: training on 99524 raw words (62733 effective words) took 0.1s, 422786 effective words/s\n",
      "2023-12-06 14:54:35,495 : INFO : EPOCH 13: training on 99524 raw words (62706 effective words) took 0.1s, 419361 effective words/s\n",
      "2023-12-06 14:54:35,649 : INFO : EPOCH 14: training on 99524 raw words (62656 effective words) took 0.1s, 421177 effective words/s\n",
      "2023-12-06 14:54:35,802 : INFO : EPOCH 15: training on 99524 raw words (62817 effective words) took 0.1s, 420716 effective words/s\n",
      "2023-12-06 14:54:35,956 : INFO : EPOCH 16: training on 99524 raw words (62774 effective words) took 0.1s, 421515 effective words/s\n",
      "2023-12-06 14:54:36,110 : INFO : EPOCH 17: training on 99524 raw words (62707 effective words) took 0.1s, 419019 effective words/s\n",
      "2023-12-06 14:54:36,271 : INFO : EPOCH 18: training on 99524 raw words (62618 effective words) took 0.2s, 400231 effective words/s\n",
      "2023-12-06 14:54:36,425 : INFO : EPOCH 19: training on 99524 raw words (62821 effective words) took 0.1s, 421507 effective words/s\n",
      "2023-12-06 14:54:36,579 : INFO : EPOCH 20: training on 99524 raw words (62691 effective words) took 0.1s, 419077 effective words/s\n",
      "2023-12-06 14:54:36,732 : INFO : EPOCH 21: training on 99524 raw words (62904 effective words) took 0.1s, 426359 effective words/s\n",
      "2023-12-06 14:54:36,891 : INFO : EPOCH 22: training on 99524 raw words (62904 effective words) took 0.2s, 405769 effective words/s\n",
      "2023-12-06 14:54:37,040 : INFO : EPOCH 23: training on 99524 raw words (62911 effective words) took 0.1s, 435623 effective words/s\n",
      "2023-12-06 14:54:37,195 : INFO : EPOCH 24: training on 99524 raw words (62711 effective words) took 0.2s, 417749 effective words/s\n",
      "2023-12-06 14:54:37,343 : INFO : EPOCH 25: training on 99524 raw words (62690 effective words) took 0.1s, 434078 effective words/s\n",
      "2023-12-06 14:54:37,496 : INFO : EPOCH 26: training on 99524 raw words (62923 effective words) took 0.1s, 423712 effective words/s\n",
      "2023-12-06 14:54:37,658 : INFO : EPOCH 27: training on 99524 raw words (62830 effective words) took 0.2s, 404842 effective words/s\n",
      "2023-12-06 14:54:37,814 : INFO : EPOCH 28: training on 99524 raw words (62608 effective words) took 0.2s, 411765 effective words/s\n",
      "2023-12-06 14:54:37,970 : INFO : EPOCH 29: training on 99524 raw words (62956 effective words) took 0.2s, 417138 effective words/s\n",
      "2023-12-06 14:54:38,123 : INFO : EPOCH 30: training on 99524 raw words (62716 effective words) took 0.1s, 422548 effective words/s\n",
      "2023-12-06 14:54:38,273 : INFO : EPOCH 31: training on 99524 raw words (62745 effective words) took 0.1s, 431673 effective words/s\n",
      "2023-12-06 14:54:38,428 : INFO : EPOCH 32: training on 99524 raw words (62705 effective words) took 0.2s, 416093 effective words/s\n",
      "2023-12-06 14:54:38,576 : INFO : EPOCH 33: training on 99524 raw words (62806 effective words) took 0.1s, 436071 effective words/s\n",
      "2023-12-06 14:54:38,735 : INFO : EPOCH 34: training on 99524 raw words (62784 effective words) took 0.2s, 407667 effective words/s\n",
      "2023-12-06 14:54:38,889 : INFO : EPOCH 35: training on 99524 raw words (62913 effective words) took 0.1s, 423106 effective words/s\n",
      "2023-12-06 14:54:39,063 : INFO : EPOCH 36: training on 99524 raw words (62624 effective words) took 0.2s, 368063 effective words/s\n",
      "2023-12-06 14:54:39,236 : INFO : EPOCH 37: training on 99524 raw words (62796 effective words) took 0.2s, 376743 effective words/s\n",
      "2023-12-06 14:54:39,404 : INFO : EPOCH 38: training on 99524 raw words (62579 effective words) took 0.2s, 387211 effective words/s\n",
      "2023-12-06 14:54:39,558 : INFO : EPOCH 39: training on 99524 raw words (62634 effective words) took 0.1s, 418942 effective words/s\n",
      "2023-12-06 14:54:39,710 : INFO : EPOCH 40: training on 99524 raw words (62629 effective words) took 0.1s, 421834 effective words/s\n",
      "2023-12-06 14:54:39,861 : INFO : EPOCH 41: training on 99524 raw words (62814 effective words) took 0.1s, 430808 effective words/s\n",
      "2023-12-06 14:54:40,015 : INFO : EPOCH 42: training on 99524 raw words (62709 effective words) took 0.2s, 417895 effective words/s\n",
      "2023-12-06 14:54:40,168 : INFO : EPOCH 43: training on 99524 raw words (62764 effective words) took 0.1s, 420995 effective words/s\n",
      "2023-12-06 14:54:40,323 : INFO : EPOCH 44: training on 99524 raw words (62864 effective words) took 0.2s, 418790 effective words/s\n",
      "2023-12-06 14:54:40,488 : INFO : EPOCH 45: training on 99524 raw words (62825 effective words) took 0.2s, 393031 effective words/s\n",
      "2023-12-06 14:54:40,639 : INFO : EPOCH 46: training on 99524 raw words (62639 effective words) took 0.1s, 426609 effective words/s\n",
      "2023-12-06 14:54:40,794 : INFO : EPOCH 47: training on 99524 raw words (62704 effective words) took 0.1s, 420291 effective words/s\n",
      "2023-12-06 14:54:40,948 : INFO : EPOCH 48: training on 99524 raw words (62854 effective words) took 0.2s, 416444 effective words/s\n",
      "2023-12-06 14:54:41,103 : INFO : EPOCH 49: training on 99524 raw words (62713 effective words) took 0.1s, 418125 effective words/s\n",
      "2023-12-06 14:54:41,104 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3137334 effective words) took 7.8s, 403218 effective words/s', 'datetime': '2023-12-06T14:54:41.104670', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:54:41,104 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:54:41.104670', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 54%|    | 261/486 [41:03<37:25,  9.98s/it]2023-12-06 14:54:44,827 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:54:44,828 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:54:44,851 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:54:44,852 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:54:44,858 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:54:44.858073', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:54:44,859 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:54:44.859073', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:54:44,863 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:54:44,863 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:54:44,864 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:54:44.864901', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:54:44,871 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:54:44,871 : INFO : resetting layer weights\n",
      "2023-12-06 14:54:44,874 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:54:44.874905', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:54:45,016 : INFO : EPOCH 0: training on 99524 raw words (60446 effective words) took 0.1s, 440070 effective words/s\n",
      "2023-12-06 14:54:45,192 : INFO : EPOCH 1: training on 99524 raw words (60442 effective words) took 0.2s, 355763 effective words/s\n",
      "2023-12-06 14:54:45,339 : INFO : EPOCH 2: training on 99524 raw words (60429 effective words) took 0.1s, 428974 effective words/s\n",
      "2023-12-06 14:54:45,489 : INFO : EPOCH 3: training on 99524 raw words (60256 effective words) took 0.1s, 415507 effective words/s\n",
      "2023-12-06 14:54:45,636 : INFO : EPOCH 4: training on 99524 raw words (60434 effective words) took 0.1s, 423334 effective words/s\n",
      "2023-12-06 14:54:45,783 : INFO : EPOCH 5: training on 99524 raw words (60298 effective words) took 0.1s, 423248 effective words/s\n",
      "2023-12-06 14:54:45,927 : INFO : EPOCH 6: training on 99524 raw words (60398 effective words) took 0.1s, 433108 effective words/s\n",
      "2023-12-06 14:54:46,075 : INFO : EPOCH 7: training on 99524 raw words (60355 effective words) took 0.1s, 418983 effective words/s\n",
      "2023-12-06 14:54:46,215 : INFO : EPOCH 8: training on 99524 raw words (60365 effective words) took 0.1s, 444738 effective words/s\n",
      "2023-12-06 14:54:46,373 : INFO : EPOCH 9: training on 99524 raw words (60361 effective words) took 0.2s, 395161 effective words/s\n",
      "2023-12-06 14:54:46,374 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603784 effective words) took 1.5s, 402770 effective words/s', 'datetime': '2023-12-06T14:54:46.374761', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:54:46,374 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:54:46.374761', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 54%|    | 262/486 [41:07<30:42,  8.23s/it]2023-12-06 14:54:48,958 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:54:48,959 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:54:48,977 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:54:48,978 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:54:48,984 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:54:48.984876', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:54:48,986 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:54:48.986057', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:54:48,992 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:54:48,992 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:54:48,993 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:54:48.993830', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:54:49,003 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:54:49,005 : INFO : resetting layer weights\n",
      "2023-12-06 14:54:49,007 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:54:49.007339', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:54:49,163 : INFO : EPOCH 0: training on 99524 raw words (60460 effective words) took 0.2s, 399848 effective words/s\n",
      "2023-12-06 14:54:49,333 : INFO : EPOCH 1: training on 99524 raw words (60434 effective words) took 0.2s, 368225 effective words/s\n",
      "2023-12-06 14:54:49,484 : INFO : EPOCH 2: training on 99524 raw words (60498 effective words) took 0.1s, 412132 effective words/s\n",
      "2023-12-06 14:54:49,646 : INFO : EPOCH 3: training on 99524 raw words (60382 effective words) took 0.2s, 382775 effective words/s\n",
      "2023-12-06 14:54:49,814 : INFO : EPOCH 4: training on 99524 raw words (60471 effective words) took 0.2s, 373060 effective words/s\n",
      "2023-12-06 14:54:49,967 : INFO : EPOCH 5: training on 99524 raw words (60354 effective words) took 0.1s, 407679 effective words/s\n",
      "2023-12-06 14:54:50,121 : INFO : EPOCH 6: training on 99524 raw words (60175 effective words) took 0.1s, 402255 effective words/s\n",
      "2023-12-06 14:54:50,272 : INFO : EPOCH 7: training on 99524 raw words (60127 effective words) took 0.1s, 410742 effective words/s\n",
      "2023-12-06 14:54:50,432 : INFO : EPOCH 8: training on 99524 raw words (60323 effective words) took 0.2s, 390979 effective words/s\n",
      "2023-12-06 14:54:50,582 : INFO : EPOCH 9: training on 99524 raw words (60352 effective words) took 0.1s, 413994 effective words/s\n",
      "2023-12-06 14:54:50,583 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603576 effective words) took 1.6s, 383102 effective words/s', 'datetime': '2023-12-06T14:54:50.583857', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:54:50,583 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:54:50.583857', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 54%|    | 263/486 [41:12<26:21,  7.09s/it]2023-12-06 14:54:53,405 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:54:53,406 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:54:53,427 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:54:53,428 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:54:53,432 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:54:53.432156', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:54:53,433 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:54:53.433258', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:54:53,438 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:54:53,439 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:54:53,440 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:54:53.440627', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:54:53,450 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:54:53,452 : INFO : resetting layer weights\n",
      "2023-12-06 14:54:53,455 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:54:53.455037', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:54:53,620 : INFO : EPOCH 0: training on 99524 raw words (60277 effective words) took 0.2s, 371918 effective words/s\n",
      "2023-12-06 14:54:53,786 : INFO : EPOCH 1: training on 99524 raw words (60327 effective words) took 0.2s, 379753 effective words/s\n",
      "2023-12-06 14:54:53,944 : INFO : EPOCH 2: training on 99524 raw words (60426 effective words) took 0.2s, 396396 effective words/s\n",
      "2023-12-06 14:54:54,092 : INFO : EPOCH 3: training on 99524 raw words (60402 effective words) took 0.1s, 418863 effective words/s\n",
      "2023-12-06 14:54:54,245 : INFO : EPOCH 4: training on 99524 raw words (60425 effective words) took 0.1s, 407104 effective words/s\n",
      "2023-12-06 14:54:54,400 : INFO : EPOCH 5: training on 99524 raw words (60345 effective words) took 0.2s, 400857 effective words/s\n",
      "2023-12-06 14:54:54,553 : INFO : EPOCH 6: training on 99524 raw words (60368 effective words) took 0.1s, 403631 effective words/s\n",
      "2023-12-06 14:54:54,711 : INFO : EPOCH 7: training on 99524 raw words (60537 effective words) took 0.2s, 396466 effective words/s\n",
      "2023-12-06 14:54:54,865 : INFO : EPOCH 8: training on 99524 raw words (60387 effective words) took 0.1s, 403694 effective words/s\n",
      "2023-12-06 14:54:55,023 : INFO : EPOCH 9: training on 99524 raw words (60385 effective words) took 0.2s, 395075 effective words/s\n",
      "2023-12-06 14:54:55,024 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603879 effective words) took 1.6s, 384925 effective words/s', 'datetime': '2023-12-06T14:54:55.024542', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:54:55,024 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:54:55.024542', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 54%|    | 264/486 [41:16<23:11,  6.27s/it]2023-12-06 14:54:57,749 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:54:57,749 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:54:57,771 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:54:57,771 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:54:57,775 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:54:57.775578', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:54:57,775 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:54:57.775578', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:54:57,780 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:54:57,781 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:54:57,782 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:54:57.782586', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:54:57,792 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:54:57,792 : INFO : resetting layer weights\n",
      "2023-12-06 14:54:57,796 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:54:57.796826', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:54:57,956 : INFO : EPOCH 0: training on 99524 raw words (60460 effective words) took 0.2s, 389778 effective words/s\n",
      "2023-12-06 14:54:58,127 : INFO : EPOCH 1: training on 99524 raw words (60352 effective words) took 0.2s, 363953 effective words/s\n",
      "2023-12-06 14:54:58,277 : INFO : EPOCH 2: training on 99524 raw words (60506 effective words) took 0.1s, 414760 effective words/s\n",
      "2023-12-06 14:54:58,422 : INFO : EPOCH 3: training on 99524 raw words (60221 effective words) took 0.1s, 430773 effective words/s\n",
      "2023-12-06 14:54:58,576 : INFO : EPOCH 4: training on 99524 raw words (60348 effective words) took 0.1s, 402708 effective words/s\n",
      "2023-12-06 14:54:58,723 : INFO : EPOCH 5: training on 99524 raw words (60451 effective words) took 0.1s, 426090 effective words/s\n",
      "2023-12-06 14:54:58,868 : INFO : EPOCH 6: training on 99524 raw words (60385 effective words) took 0.1s, 426310 effective words/s\n",
      "2023-12-06 14:54:59,015 : INFO : EPOCH 7: training on 99524 raw words (60386 effective words) took 0.1s, 425861 effective words/s\n",
      "2023-12-06 14:54:59,162 : INFO : EPOCH 8: training on 99524 raw words (60475 effective words) took 0.1s, 421506 effective words/s\n",
      "2023-12-06 14:54:59,319 : INFO : EPOCH 9: training on 99524 raw words (60435 effective words) took 0.2s, 399566 effective words/s\n",
      "2023-12-06 14:54:59,461 : INFO : EPOCH 10: training on 99524 raw words (60304 effective words) took 0.1s, 435994 effective words/s\n",
      "2023-12-06 14:54:59,608 : INFO : EPOCH 11: training on 99524 raw words (60493 effective words) took 0.1s, 428260 effective words/s\n",
      "2023-12-06 14:54:59,756 : INFO : EPOCH 12: training on 99524 raw words (60469 effective words) took 0.1s, 419502 effective words/s\n",
      "2023-12-06 14:54:59,903 : INFO : EPOCH 13: training on 99524 raw words (60293 effective words) took 0.1s, 423022 effective words/s\n",
      "2023-12-06 14:55:00,047 : INFO : EPOCH 14: training on 99524 raw words (60456 effective words) took 0.1s, 435371 effective words/s\n",
      "2023-12-06 14:55:00,193 : INFO : EPOCH 15: training on 99524 raw words (60330 effective words) took 0.1s, 422084 effective words/s\n",
      "2023-12-06 14:55:00,355 : INFO : EPOCH 16: training on 99524 raw words (60367 effective words) took 0.2s, 390599 effective words/s\n",
      "2023-12-06 14:55:00,517 : INFO : EPOCH 17: training on 99524 raw words (60307 effective words) took 0.2s, 383847 effective words/s\n",
      "2023-12-06 14:55:00,657 : INFO : EPOCH 18: training on 99524 raw words (60168 effective words) took 0.1s, 441440 effective words/s\n",
      "2023-12-06 14:55:00,803 : INFO : EPOCH 19: training on 99524 raw words (60359 effective words) took 0.1s, 427401 effective words/s\n",
      "2023-12-06 14:55:00,949 : INFO : EPOCH 20: training on 99524 raw words (60320 effective words) took 0.1s, 427641 effective words/s\n",
      "2023-12-06 14:55:01,104 : INFO : EPOCH 21: training on 99524 raw words (60402 effective words) took 0.2s, 402671 effective words/s\n",
      "2023-12-06 14:55:01,246 : INFO : EPOCH 22: training on 99524 raw words (60530 effective words) took 0.1s, 439482 effective words/s\n",
      "2023-12-06 14:55:01,393 : INFO : EPOCH 23: training on 99524 raw words (60527 effective words) took 0.1s, 425881 effective words/s\n",
      "2023-12-06 14:55:01,541 : INFO : EPOCH 24: training on 99524 raw words (60466 effective words) took 0.1s, 419419 effective words/s\n",
      "2023-12-06 14:55:01,707 : INFO : EPOCH 25: training on 99524 raw words (60379 effective words) took 0.2s, 375451 effective words/s\n",
      "2023-12-06 14:55:01,854 : INFO : EPOCH 26: training on 99524 raw words (60552 effective words) took 0.1s, 430080 effective words/s\n",
      "2023-12-06 14:55:02,005 : INFO : EPOCH 27: training on 99524 raw words (60644 effective words) took 0.1s, 414264 effective words/s\n",
      "2023-12-06 14:55:02,146 : INFO : EPOCH 28: training on 99524 raw words (60314 effective words) took 0.1s, 439295 effective words/s\n",
      "2023-12-06 14:55:02,294 : INFO : EPOCH 29: training on 99524 raw words (60580 effective words) took 0.1s, 422808 effective words/s\n",
      "2023-12-06 14:55:02,295 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812279 effective words) took 4.5s, 402925 effective words/s', 'datetime': '2023-12-06T14:55:02.295794', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:55:02,295 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:55:02.295794', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 55%|    | 265/486 [41:23<24:19,  6.61s/it]2023-12-06 14:55:05,142 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:55:05,142 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:55:05,165 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:55:05,165 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:55:05,172 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:55:05.172835', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:55:05,173 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:55:05.173834', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:55:05,180 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:55:05,181 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:55:05,182 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:55:05.182522', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:55:05,192 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:55:05,193 : INFO : resetting layer weights\n",
      "2023-12-06 14:55:05,196 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:55:05.196324', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:55:05,361 : INFO : EPOCH 0: training on 99524 raw words (60500 effective words) took 0.2s, 379322 effective words/s\n",
      "2023-12-06 14:55:05,536 : INFO : EPOCH 1: training on 99524 raw words (60301 effective words) took 0.2s, 357787 effective words/s\n",
      "2023-12-06 14:55:05,691 : INFO : EPOCH 2: training on 99524 raw words (60415 effective words) took 0.2s, 401083 effective words/s\n",
      "2023-12-06 14:55:05,847 : INFO : EPOCH 3: training on 99524 raw words (60367 effective words) took 0.2s, 401868 effective words/s\n",
      "2023-12-06 14:55:05,996 : INFO : EPOCH 4: training on 99524 raw words (60393 effective words) took 0.1s, 413293 effective words/s\n",
      "2023-12-06 14:55:06,150 : INFO : EPOCH 5: training on 99524 raw words (60434 effective words) took 0.1s, 407282 effective words/s\n",
      "2023-12-06 14:55:06,300 : INFO : EPOCH 6: training on 99524 raw words (60316 effective words) took 0.1s, 412500 effective words/s\n",
      "2023-12-06 14:55:06,453 : INFO : EPOCH 7: training on 99524 raw words (60487 effective words) took 0.1s, 409362 effective words/s\n",
      "2023-12-06 14:55:06,608 : INFO : EPOCH 8: training on 99524 raw words (60305 effective words) took 0.2s, 400059 effective words/s\n",
      "2023-12-06 14:55:06,762 : INFO : EPOCH 9: training on 99524 raw words (60266 effective words) took 0.1s, 403734 effective words/s\n",
      "2023-12-06 14:55:06,920 : INFO : EPOCH 10: training on 99524 raw words (60437 effective words) took 0.2s, 396313 effective words/s\n",
      "2023-12-06 14:55:07,076 : INFO : EPOCH 11: training on 99524 raw words (60580 effective words) took 0.2s, 398748 effective words/s\n",
      "2023-12-06 14:55:07,225 : INFO : EPOCH 12: training on 99524 raw words (60331 effective words) took 0.1s, 414607 effective words/s\n",
      "2023-12-06 14:55:07,380 : INFO : EPOCH 13: training on 99524 raw words (60332 effective words) took 0.1s, 402311 effective words/s\n",
      "2023-12-06 14:55:07,532 : INFO : EPOCH 14: training on 99524 raw words (60455 effective words) took 0.1s, 408397 effective words/s\n",
      "2023-12-06 14:55:07,687 : INFO : EPOCH 15: training on 99524 raw words (60404 effective words) took 0.2s, 401662 effective words/s\n",
      "2023-12-06 14:55:07,840 : INFO : EPOCH 16: training on 99524 raw words (60358 effective words) took 0.1s, 406579 effective words/s\n",
      "2023-12-06 14:55:07,992 : INFO : EPOCH 17: training on 99524 raw words (60262 effective words) took 0.1s, 406975 effective words/s\n",
      "2023-12-06 14:55:08,148 : INFO : EPOCH 18: training on 99524 raw words (60372 effective words) took 0.2s, 400096 effective words/s\n",
      "2023-12-06 14:55:08,310 : INFO : EPOCH 19: training on 99524 raw words (60484 effective words) took 0.2s, 381108 effective words/s\n",
      "2023-12-06 14:55:08,468 : INFO : EPOCH 20: training on 99524 raw words (60288 effective words) took 0.2s, 392677 effective words/s\n",
      "2023-12-06 14:55:08,619 : INFO : EPOCH 21: training on 99524 raw words (60503 effective words) took 0.1s, 414352 effective words/s\n",
      "2023-12-06 14:55:08,775 : INFO : EPOCH 22: training on 99524 raw words (60483 effective words) took 0.2s, 401693 effective words/s\n",
      "2023-12-06 14:55:08,926 : INFO : EPOCH 23: training on 99524 raw words (60500 effective words) took 0.1s, 413227 effective words/s\n",
      "2023-12-06 14:55:09,081 : INFO : EPOCH 24: training on 99524 raw words (60628 effective words) took 0.2s, 403553 effective words/s\n",
      "2023-12-06 14:55:09,229 : INFO : EPOCH 25: training on 99524 raw words (60354 effective words) took 0.1s, 416798 effective words/s\n",
      "2023-12-06 14:55:09,387 : INFO : EPOCH 26: training on 99524 raw words (60381 effective words) took 0.2s, 399011 effective words/s\n",
      "2023-12-06 14:55:09,544 : INFO : EPOCH 27: training on 99524 raw words (60457 effective words) took 0.2s, 392588 effective words/s\n",
      "2023-12-06 14:55:09,702 : INFO : EPOCH 28: training on 99524 raw words (60411 effective words) took 0.2s, 393702 effective words/s\n",
      "2023-12-06 14:55:09,863 : INFO : EPOCH 29: training on 99524 raw words (60351 effective words) took 0.2s, 388390 effective words/s\n",
      "2023-12-06 14:55:09,864 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812155 effective words) took 4.7s, 388341 effective words/s', 'datetime': '2023-12-06T14:55:09.864308', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:55:09,864 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:55:09.864308', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 55%|    | 266/486 [41:31<25:26,  6.94s/it]2023-12-06 14:55:12,859 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:55:12,860 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:55:12,880 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:55:12,881 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:55:12,888 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:55:12.888046', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:55:12,888 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:55:12.888549', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:55:12,892 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:55:12,893 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:55:12,893 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:55:12.893554', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:55:12,903 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:55:12,903 : INFO : resetting layer weights\n",
      "2023-12-06 14:55:12,906 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:55:12.906705', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:55:13,061 : INFO : EPOCH 0: training on 99524 raw words (60308 effective words) took 0.2s, 399811 effective words/s\n",
      "2023-12-06 14:55:13,235 : INFO : EPOCH 1: training on 99524 raw words (60299 effective words) took 0.2s, 359805 effective words/s\n",
      "2023-12-06 14:55:13,389 : INFO : EPOCH 2: training on 99524 raw words (60492 effective words) took 0.1s, 406670 effective words/s\n",
      "2023-12-06 14:55:13,540 : INFO : EPOCH 3: training on 99524 raw words (60324 effective words) took 0.1s, 416235 effective words/s\n",
      "2023-12-06 14:55:13,693 : INFO : EPOCH 4: training on 99524 raw words (60331 effective words) took 0.1s, 405017 effective words/s\n",
      "2023-12-06 14:55:13,847 : INFO : EPOCH 5: training on 99524 raw words (60354 effective words) took 0.1s, 404162 effective words/s\n",
      "2023-12-06 14:55:14,000 : INFO : EPOCH 6: training on 99524 raw words (60389 effective words) took 0.1s, 407740 effective words/s\n",
      "2023-12-06 14:55:14,155 : INFO : EPOCH 7: training on 99524 raw words (60366 effective words) took 0.2s, 399555 effective words/s\n",
      "2023-12-06 14:55:14,308 : INFO : EPOCH 8: training on 99524 raw words (60454 effective words) took 0.1s, 407847 effective words/s\n",
      "2023-12-06 14:55:14,462 : INFO : EPOCH 9: training on 99524 raw words (60456 effective words) took 0.1s, 404103 effective words/s\n",
      "2023-12-06 14:55:14,618 : INFO : EPOCH 10: training on 99524 raw words (60233 effective words) took 0.2s, 398379 effective words/s\n",
      "2023-12-06 14:55:14,776 : INFO : EPOCH 11: training on 99524 raw words (60483 effective words) took 0.2s, 394341 effective words/s\n",
      "2023-12-06 14:55:14,930 : INFO : EPOCH 12: training on 99524 raw words (60400 effective words) took 0.1s, 403164 effective words/s\n",
      "2023-12-06 14:55:15,080 : INFO : EPOCH 13: training on 99524 raw words (60430 effective words) took 0.1s, 414147 effective words/s\n",
      "2023-12-06 14:55:15,237 : INFO : EPOCH 14: training on 99524 raw words (60246 effective words) took 0.2s, 395652 effective words/s\n",
      "2023-12-06 14:55:15,392 : INFO : EPOCH 15: training on 99524 raw words (60452 effective words) took 0.1s, 403037 effective words/s\n",
      "2023-12-06 14:55:15,545 : INFO : EPOCH 16: training on 99524 raw words (60479 effective words) took 0.1s, 405080 effective words/s\n",
      "2023-12-06 14:55:15,699 : INFO : EPOCH 17: training on 99524 raw words (60269 effective words) took 0.1s, 403000 effective words/s\n",
      "2023-12-06 14:55:15,850 : INFO : EPOCH 18: training on 99524 raw words (60357 effective words) took 0.1s, 410293 effective words/s\n",
      "2023-12-06 14:55:16,014 : INFO : EPOCH 19: training on 99524 raw words (60534 effective words) took 0.2s, 384608 effective words/s\n",
      "2023-12-06 14:55:16,166 : INFO : EPOCH 20: training on 99524 raw words (60475 effective words) took 0.1s, 410432 effective words/s\n",
      "2023-12-06 14:55:16,321 : INFO : EPOCH 21: training on 99524 raw words (60552 effective words) took 0.2s, 398295 effective words/s\n",
      "2023-12-06 14:55:16,475 : INFO : EPOCH 22: training on 99524 raw words (60426 effective words) took 0.1s, 406111 effective words/s\n",
      "2023-12-06 14:55:16,626 : INFO : EPOCH 23: training on 99524 raw words (60562 effective words) took 0.1s, 412974 effective words/s\n",
      "2023-12-06 14:55:16,775 : INFO : EPOCH 24: training on 99524 raw words (60438 effective words) took 0.1s, 417272 effective words/s\n",
      "2023-12-06 14:55:16,930 : INFO : EPOCH 25: training on 99524 raw words (60314 effective words) took 0.1s, 403710 effective words/s\n",
      "2023-12-06 14:55:17,080 : INFO : EPOCH 26: training on 99524 raw words (60435 effective words) took 0.1s, 413830 effective words/s\n",
      "2023-12-06 14:55:17,235 : INFO : EPOCH 27: training on 99524 raw words (60461 effective words) took 0.2s, 402096 effective words/s\n",
      "2023-12-06 14:55:17,393 : INFO : EPOCH 28: training on 99524 raw words (60503 effective words) took 0.2s, 395226 effective words/s\n",
      "2023-12-06 14:55:17,549 : INFO : EPOCH 29: training on 99524 raw words (60322 effective words) took 0.2s, 395632 effective words/s\n",
      "2023-12-06 14:55:17,550 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812144 effective words) took 4.6s, 390271 effective words/s', 'datetime': '2023-12-06T14:55:17.550898', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:55:17,551 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:55:17.551900', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 55%|    | 267/486 [41:39<26:19,  7.21s/it]2023-12-06 14:55:20,710 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:55:20,711 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:55:20,731 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:55:20,732 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:55:20,737 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:55:20.737762', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:55:20,737 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:55:20.737762', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:55:20,742 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:55:20,743 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:55:20,743 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:55:20.743762', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:55:20,754 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:55:20,754 : INFO : resetting layer weights\n",
      "2023-12-06 14:55:20,756 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:55:20.756620', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:55:20,895 : INFO : EPOCH 0: training on 99524 raw words (60525 effective words) took 0.1s, 452392 effective words/s\n",
      "2023-12-06 14:55:21,062 : INFO : EPOCH 1: training on 99524 raw words (60380 effective words) took 0.2s, 372910 effective words/s\n",
      "2023-12-06 14:55:21,211 : INFO : EPOCH 2: training on 99524 raw words (60364 effective words) took 0.1s, 424185 effective words/s\n",
      "2023-12-06 14:55:21,358 : INFO : EPOCH 3: training on 99524 raw words (60513 effective words) took 0.1s, 423021 effective words/s\n",
      "2023-12-06 14:55:21,501 : INFO : EPOCH 4: training on 99524 raw words (60253 effective words) took 0.1s, 436685 effective words/s\n",
      "2023-12-06 14:55:21,647 : INFO : EPOCH 5: training on 99524 raw words (60384 effective words) took 0.1s, 423937 effective words/s\n",
      "2023-12-06 14:55:21,794 : INFO : EPOCH 6: training on 99524 raw words (60364 effective words) took 0.1s, 424702 effective words/s\n",
      "2023-12-06 14:55:21,946 : INFO : EPOCH 7: training on 99524 raw words (60418 effective words) took 0.1s, 411546 effective words/s\n",
      "2023-12-06 14:55:22,090 : INFO : EPOCH 8: training on 99524 raw words (60338 effective words) took 0.1s, 433059 effective words/s\n",
      "2023-12-06 14:55:22,237 : INFO : EPOCH 9: training on 99524 raw words (60472 effective words) took 0.1s, 420921 effective words/s\n",
      "2023-12-06 14:55:22,388 : INFO : EPOCH 10: training on 99524 raw words (60275 effective words) took 0.1s, 411799 effective words/s\n",
      "2023-12-06 14:55:22,538 : INFO : EPOCH 11: training on 99524 raw words (60552 effective words) took 0.1s, 416313 effective words/s\n",
      "2023-12-06 14:55:22,685 : INFO : EPOCH 12: training on 99524 raw words (60281 effective words) took 0.1s, 422457 effective words/s\n",
      "2023-12-06 14:55:22,833 : INFO : EPOCH 13: training on 99524 raw words (60465 effective words) took 0.1s, 420711 effective words/s\n",
      "2023-12-06 14:55:22,981 : INFO : EPOCH 14: training on 99524 raw words (60474 effective words) took 0.1s, 420364 effective words/s\n",
      "2023-12-06 14:55:23,128 : INFO : EPOCH 15: training on 99524 raw words (60250 effective words) took 0.1s, 424202 effective words/s\n",
      "2023-12-06 14:55:23,278 : INFO : EPOCH 16: training on 99524 raw words (60406 effective words) took 0.1s, 417546 effective words/s\n",
      "2023-12-06 14:55:23,421 : INFO : EPOCH 17: training on 99524 raw words (60354 effective words) took 0.1s, 431628 effective words/s\n",
      "2023-12-06 14:55:23,571 : INFO : EPOCH 18: training on 99524 raw words (60345 effective words) took 0.1s, 416769 effective words/s\n",
      "2023-12-06 14:55:23,726 : INFO : EPOCH 19: training on 99524 raw words (60374 effective words) took 0.2s, 400351 effective words/s\n",
      "2023-12-06 14:55:23,875 : INFO : EPOCH 20: training on 99524 raw words (60370 effective words) took 0.1s, 418183 effective words/s\n",
      "2023-12-06 14:55:24,027 : INFO : EPOCH 21: training on 99524 raw words (60556 effective words) took 0.1s, 410122 effective words/s\n",
      "2023-12-06 14:55:24,178 : INFO : EPOCH 22: training on 99524 raw words (60517 effective words) took 0.1s, 414801 effective words/s\n",
      "2023-12-06 14:55:24,327 : INFO : EPOCH 23: training on 99524 raw words (60554 effective words) took 0.1s, 418450 effective words/s\n",
      "2023-12-06 14:55:24,474 : INFO : EPOCH 24: training on 99524 raw words (60490 effective words) took 0.1s, 423036 effective words/s\n",
      "2023-12-06 14:55:24,618 : INFO : EPOCH 25: training on 99524 raw words (60433 effective words) took 0.1s, 436998 effective words/s\n",
      "2023-12-06 14:55:24,765 : INFO : EPOCH 26: training on 99524 raw words (60482 effective words) took 0.1s, 421089 effective words/s\n",
      "2023-12-06 14:55:24,919 : INFO : EPOCH 27: training on 99524 raw words (60675 effective words) took 0.1s, 407879 effective words/s\n",
      "2023-12-06 14:55:25,076 : INFO : EPOCH 28: training on 99524 raw words (60374 effective words) took 0.2s, 396848 effective words/s\n",
      "2023-12-06 14:55:25,224 : INFO : EPOCH 29: training on 99524 raw words (60484 effective words) took 0.1s, 419913 effective words/s\n",
      "2023-12-06 14:55:25,373 : INFO : EPOCH 30: training on 99524 raw words (60321 effective words) took 0.1s, 418119 effective words/s\n",
      "2023-12-06 14:55:25,516 : INFO : EPOCH 31: training on 99524 raw words (60230 effective words) took 0.1s, 435412 effective words/s\n",
      "2023-12-06 14:55:25,665 : INFO : EPOCH 32: training on 99524 raw words (60534 effective words) took 0.1s, 421202 effective words/s\n",
      "2023-12-06 14:55:25,813 : INFO : EPOCH 33: training on 99524 raw words (60530 effective words) took 0.1s, 422496 effective words/s\n",
      "2023-12-06 14:55:25,959 : INFO : EPOCH 34: training on 99524 raw words (60355 effective words) took 0.1s, 424845 effective words/s\n",
      "2023-12-06 14:55:26,106 : INFO : EPOCH 35: training on 99524 raw words (60550 effective words) took 0.1s, 424954 effective words/s\n",
      "2023-12-06 14:55:26,266 : INFO : EPOCH 36: training on 99524 raw words (60379 effective words) took 0.2s, 387651 effective words/s\n",
      "2023-12-06 14:55:26,413 : INFO : EPOCH 37: training on 99524 raw words (60359 effective words) took 0.1s, 422505 effective words/s\n",
      "2023-12-06 14:55:26,563 : INFO : EPOCH 38: training on 99524 raw words (60347 effective words) took 0.1s, 416388 effective words/s\n",
      "2023-12-06 14:55:26,712 : INFO : EPOCH 39: training on 99524 raw words (60283 effective words) took 0.1s, 416809 effective words/s\n",
      "2023-12-06 14:55:26,854 : INFO : EPOCH 40: training on 99524 raw words (60285 effective words) took 0.1s, 434806 effective words/s\n",
      "2023-12-06 14:55:27,004 : INFO : EPOCH 41: training on 99524 raw words (60513 effective words) took 0.1s, 419123 effective words/s\n",
      "2023-12-06 14:55:27,146 : INFO : EPOCH 42: training on 99524 raw words (60396 effective words) took 0.1s, 437180 effective words/s\n",
      "2023-12-06 14:55:27,291 : INFO : EPOCH 43: training on 99524 raw words (60445 effective words) took 0.1s, 428600 effective words/s\n",
      "2023-12-06 14:55:27,435 : INFO : EPOCH 44: training on 99524 raw words (60488 effective words) took 0.1s, 433623 effective words/s\n",
      "2023-12-06 14:55:27,592 : INFO : EPOCH 45: training on 99524 raw words (60263 effective words) took 0.2s, 396267 effective words/s\n",
      "2023-12-06 14:55:27,738 : INFO : EPOCH 46: training on 99524 raw words (60198 effective words) took 0.1s, 423365 effective words/s\n",
      "2023-12-06 14:55:27,886 : INFO : EPOCH 47: training on 99524 raw words (60337 effective words) took 0.1s, 422010 effective words/s\n",
      "2023-12-06 14:55:28,034 : INFO : EPOCH 48: training on 99524 raw words (60397 effective words) took 0.1s, 419644 effective words/s\n",
      "2023-12-06 14:55:28,183 : INFO : EPOCH 49: training on 99524 raw words (60340 effective words) took 0.1s, 418459 effective words/s\n",
      "2023-12-06 14:55:28,184 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3020272 effective words) took 7.4s, 406670 effective words/s', 'datetime': '2023-12-06T14:55:28.184703', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:55:28,185 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:55:28.185207', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 55%|    | 268/486 [41:50<30:09,  8.30s/it]2023-12-06 14:55:31,545 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:55:31,546 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:55:31,566 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:55:31,567 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:55:31,571 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:55:31.571298', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:55:31,572 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:55:31.572300', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:55:31,579 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:55:31,579 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:55:31,580 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:55:31.580300', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:55:31,587 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:55:31,588 : INFO : resetting layer weights\n",
      "2023-12-06 14:55:31,589 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:55:31.589945', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:55:31,731 : INFO : EPOCH 0: training on 99524 raw words (60474 effective words) took 0.1s, 445946 effective words/s\n",
      "2023-12-06 14:55:31,895 : INFO : EPOCH 1: training on 99524 raw words (60474 effective words) took 0.2s, 375013 effective words/s\n",
      "2023-12-06 14:55:32,054 : INFO : EPOCH 2: training on 99524 raw words (60307 effective words) took 0.2s, 396263 effective words/s\n",
      "2023-12-06 14:55:32,208 : INFO : EPOCH 3: training on 99524 raw words (60300 effective words) took 0.1s, 402371 effective words/s\n",
      "2023-12-06 14:55:32,362 : INFO : EPOCH 4: training on 99524 raw words (60326 effective words) took 0.1s, 403153 effective words/s\n",
      "2023-12-06 14:55:32,513 : INFO : EPOCH 5: training on 99524 raw words (60295 effective words) took 0.1s, 415202 effective words/s\n",
      "2023-12-06 14:55:32,669 : INFO : EPOCH 6: training on 99524 raw words (60247 effective words) took 0.2s, 396666 effective words/s\n",
      "2023-12-06 14:55:32,825 : INFO : EPOCH 7: training on 99524 raw words (60481 effective words) took 0.2s, 398777 effective words/s\n",
      "2023-12-06 14:55:32,981 : INFO : EPOCH 8: training on 99524 raw words (60371 effective words) took 0.2s, 399425 effective words/s\n",
      "2023-12-06 14:55:33,140 : INFO : EPOCH 9: training on 99524 raw words (60502 effective words) took 0.2s, 391778 effective words/s\n",
      "2023-12-06 14:55:33,296 : INFO : EPOCH 10: training on 99524 raw words (60371 effective words) took 0.2s, 399942 effective words/s\n",
      "2023-12-06 14:55:33,448 : INFO : EPOCH 11: training on 99524 raw words (60462 effective words) took 0.1s, 408925 effective words/s\n",
      "2023-12-06 14:55:33,602 : INFO : EPOCH 12: training on 99524 raw words (60545 effective words) took 0.1s, 406497 effective words/s\n",
      "2023-12-06 14:55:33,754 : INFO : EPOCH 13: training on 99524 raw words (60344 effective words) took 0.1s, 407248 effective words/s\n",
      "2023-12-06 14:55:33,910 : INFO : EPOCH 14: training on 99524 raw words (60364 effective words) took 0.2s, 397747 effective words/s\n",
      "2023-12-06 14:55:34,065 : INFO : EPOCH 15: training on 99524 raw words (60308 effective words) took 0.2s, 399681 effective words/s\n",
      "2023-12-06 14:55:34,221 : INFO : EPOCH 16: training on 99524 raw words (60406 effective words) took 0.2s, 400844 effective words/s\n",
      "2023-12-06 14:55:34,376 : INFO : EPOCH 17: training on 99524 raw words (60207 effective words) took 0.2s, 399525 effective words/s\n",
      "2023-12-06 14:55:34,537 : INFO : EPOCH 18: training on 99524 raw words (60394 effective words) took 0.2s, 386214 effective words/s\n",
      "2023-12-06 14:55:34,692 : INFO : EPOCH 19: training on 99524 raw words (60434 effective words) took 0.2s, 398134 effective words/s\n",
      "2023-12-06 14:55:34,847 : INFO : EPOCH 20: training on 99524 raw words (60280 effective words) took 0.2s, 401786 effective words/s\n",
      "2023-12-06 14:55:35,004 : INFO : EPOCH 21: training on 99524 raw words (60468 effective words) took 0.2s, 396664 effective words/s\n",
      "2023-12-06 14:55:35,159 : INFO : EPOCH 22: training on 99524 raw words (60396 effective words) took 0.2s, 402303 effective words/s\n",
      "2023-12-06 14:55:35,313 : INFO : EPOCH 23: training on 99524 raw words (60538 effective words) took 0.1s, 404250 effective words/s\n",
      "2023-12-06 14:55:35,466 : INFO : EPOCH 24: training on 99524 raw words (60429 effective words) took 0.1s, 405411 effective words/s\n",
      "2023-12-06 14:55:35,617 : INFO : EPOCH 25: training on 99524 raw words (60283 effective words) took 0.1s, 412490 effective words/s\n",
      "2023-12-06 14:55:35,771 : INFO : EPOCH 26: training on 99524 raw words (60452 effective words) took 0.1s, 406610 effective words/s\n",
      "2023-12-06 14:55:35,930 : INFO : EPOCH 27: training on 99524 raw words (60603 effective words) took 0.2s, 389572 effective words/s\n",
      "2023-12-06 14:55:36,086 : INFO : EPOCH 28: training on 99524 raw words (60392 effective words) took 0.2s, 400810 effective words/s\n",
      "2023-12-06 14:55:36,239 : INFO : EPOCH 29: training on 99524 raw words (60430 effective words) took 0.1s, 406042 effective words/s\n",
      "2023-12-06 14:55:36,392 : INFO : EPOCH 30: training on 99524 raw words (60359 effective words) took 0.1s, 405532 effective words/s\n",
      "2023-12-06 14:55:36,542 : INFO : EPOCH 31: training on 99524 raw words (60440 effective words) took 0.1s, 413548 effective words/s\n",
      "2023-12-06 14:55:36,698 : INFO : EPOCH 32: training on 99524 raw words (60376 effective words) took 0.2s, 397266 effective words/s\n",
      "2023-12-06 14:55:36,853 : INFO : EPOCH 33: training on 99524 raw words (60492 effective words) took 0.2s, 402368 effective words/s\n",
      "2023-12-06 14:55:37,007 : INFO : EPOCH 34: training on 99524 raw words (60487 effective words) took 0.2s, 402766 effective words/s\n",
      "2023-12-06 14:55:37,166 : INFO : EPOCH 35: training on 99524 raw words (60486 effective words) took 0.2s, 395519 effective words/s\n",
      "2023-12-06 14:55:37,325 : INFO : EPOCH 36: training on 99524 raw words (60427 effective words) took 0.2s, 391841 effective words/s\n",
      "2023-12-06 14:55:37,480 : INFO : EPOCH 37: training on 99524 raw words (60275 effective words) took 0.2s, 398920 effective words/s\n",
      "2023-12-06 14:55:37,632 : INFO : EPOCH 38: training on 99524 raw words (60253 effective words) took 0.1s, 407573 effective words/s\n",
      "2023-12-06 14:55:37,783 : INFO : EPOCH 39: training on 99524 raw words (60387 effective words) took 0.1s, 412436 effective words/s\n",
      "2023-12-06 14:55:37,938 : INFO : EPOCH 40: training on 99524 raw words (60216 effective words) took 0.2s, 399988 effective words/s\n",
      "2023-12-06 14:55:38,090 : INFO : EPOCH 41: training on 99524 raw words (60513 effective words) took 0.1s, 409648 effective words/s\n",
      "2023-12-06 14:55:38,244 : INFO : EPOCH 42: training on 99524 raw words (60387 effective words) took 0.1s, 405194 effective words/s\n",
      "2023-12-06 14:55:38,400 : INFO : EPOCH 43: training on 99524 raw words (60375 effective words) took 0.2s, 397881 effective words/s\n",
      "2023-12-06 14:55:38,554 : INFO : EPOCH 44: training on 99524 raw words (60327 effective words) took 0.1s, 404436 effective words/s\n",
      "2023-12-06 14:55:38,714 : INFO : EPOCH 45: training on 99524 raw words (60326 effective words) took 0.2s, 389175 effective words/s\n",
      "2023-12-06 14:55:38,868 : INFO : EPOCH 46: training on 99524 raw words (60304 effective words) took 0.2s, 399918 effective words/s\n",
      "2023-12-06 14:55:39,019 : INFO : EPOCH 47: training on 99524 raw words (60253 effective words) took 0.1s, 412442 effective words/s\n",
      "2023-12-06 14:55:39,174 : INFO : EPOCH 48: training on 99524 raw words (60429 effective words) took 0.2s, 400750 effective words/s\n",
      "2023-12-06 14:55:39,331 : INFO : EPOCH 49: training on 99524 raw words (60467 effective words) took 0.2s, 399333 effective words/s\n",
      "2023-12-06 14:55:39,332 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3019462 effective words) took 7.7s, 390053 effective words/s', 'datetime': '2023-12-06T14:55:39.332239', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:55:39,332 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:55:39.332239', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 55%|    | 269/486 [42:01<33:13,  9.19s/it]2023-12-06 14:55:42,809 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:55:42,809 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:55:42,832 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:55:42,833 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:55:42,838 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:55:42.838821', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:55:42,839 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:55:42.839820', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:55:42,846 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:55:42,846 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:55:42,847 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:55:42.847222', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:55:42,854 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:55:42,854 : INFO : resetting layer weights\n",
      "2023-12-06 14:55:42,857 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T14:55:42.857067', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:55:42,998 : INFO : EPOCH 0: training on 99524 raw words (60330 effective words) took 0.1s, 443901 effective words/s\n",
      "2023-12-06 14:55:43,172 : INFO : EPOCH 1: training on 99524 raw words (60457 effective words) took 0.2s, 356067 effective words/s\n",
      "2023-12-06 14:55:43,328 : INFO : EPOCH 2: training on 99524 raw words (60344 effective words) took 0.1s, 402357 effective words/s\n",
      "2023-12-06 14:55:43,484 : INFO : EPOCH 3: training on 99524 raw words (60379 effective words) took 0.2s, 398607 effective words/s\n",
      "2023-12-06 14:55:43,641 : INFO : EPOCH 4: training on 99524 raw words (60374 effective words) took 0.2s, 396232 effective words/s\n",
      "2023-12-06 14:55:43,798 : INFO : EPOCH 5: training on 99524 raw words (60415 effective words) took 0.2s, 397507 effective words/s\n",
      "2023-12-06 14:55:43,952 : INFO : EPOCH 6: training on 99524 raw words (60305 effective words) took 0.1s, 402377 effective words/s\n",
      "2023-12-06 14:55:44,103 : INFO : EPOCH 7: training on 99524 raw words (60447 effective words) took 0.1s, 413153 effective words/s\n",
      "2023-12-06 14:55:44,263 : INFO : EPOCH 8: training on 99524 raw words (60344 effective words) took 0.2s, 387703 effective words/s\n",
      "2023-12-06 14:55:44,416 : INFO : EPOCH 9: training on 99524 raw words (60433 effective words) took 0.1s, 404663 effective words/s\n",
      "2023-12-06 14:55:44,570 : INFO : EPOCH 10: training on 99524 raw words (60364 effective words) took 0.1s, 405263 effective words/s\n",
      "2023-12-06 14:55:44,726 : INFO : EPOCH 11: training on 99524 raw words (60439 effective words) took 0.2s, 399438 effective words/s\n",
      "2023-12-06 14:55:44,875 : INFO : EPOCH 12: training on 99524 raw words (60392 effective words) took 0.1s, 416260 effective words/s\n",
      "2023-12-06 14:55:45,031 : INFO : EPOCH 13: training on 99524 raw words (60396 effective words) took 0.1s, 403210 effective words/s\n",
      "2023-12-06 14:55:45,188 : INFO : EPOCH 14: training on 99524 raw words (60460 effective words) took 0.2s, 395163 effective words/s\n",
      "2023-12-06 14:55:45,343 : INFO : EPOCH 15: training on 99524 raw words (60252 effective words) took 0.2s, 399828 effective words/s\n",
      "2023-12-06 14:55:45,498 : INFO : EPOCH 16: training on 99524 raw words (60472 effective words) took 0.2s, 402465 effective words/s\n",
      "2023-12-06 14:55:45,660 : INFO : EPOCH 17: training on 99524 raw words (60121 effective words) took 0.2s, 382989 effective words/s\n",
      "2023-12-06 14:55:45,814 : INFO : EPOCH 18: training on 99524 raw words (60303 effective words) took 0.1s, 402484 effective words/s\n",
      "2023-12-06 14:55:45,971 : INFO : EPOCH 19: training on 99524 raw words (60412 effective words) took 0.2s, 397612 effective words/s\n",
      "2023-12-06 14:55:46,128 : INFO : EPOCH 20: training on 99524 raw words (60482 effective words) took 0.2s, 395582 effective words/s\n",
      "2023-12-06 14:55:46,285 : INFO : EPOCH 21: training on 99524 raw words (60528 effective words) took 0.2s, 397373 effective words/s\n",
      "2023-12-06 14:55:46,440 : INFO : EPOCH 22: training on 99524 raw words (60616 effective words) took 0.2s, 402088 effective words/s\n",
      "2023-12-06 14:55:46,595 : INFO : EPOCH 23: training on 99524 raw words (60375 effective words) took 0.2s, 401191 effective words/s\n",
      "2023-12-06 14:55:46,751 : INFO : EPOCH 24: training on 99524 raw words (60515 effective words) took 0.2s, 399400 effective words/s\n",
      "2023-12-06 14:55:46,906 : INFO : EPOCH 25: training on 99524 raw words (60260 effective words) took 0.2s, 400452 effective words/s\n",
      "2023-12-06 14:55:47,067 : INFO : EPOCH 26: training on 99524 raw words (60450 effective words) took 0.2s, 384991 effective words/s\n",
      "2023-12-06 14:55:47,223 : INFO : EPOCH 27: training on 99524 raw words (60452 effective words) took 0.2s, 401050 effective words/s\n",
      "2023-12-06 14:55:47,378 : INFO : EPOCH 28: training on 99524 raw words (60435 effective words) took 0.2s, 398478 effective words/s\n",
      "2023-12-06 14:55:47,534 : INFO : EPOCH 29: training on 99524 raw words (60358 effective words) took 0.2s, 400056 effective words/s\n",
      "2023-12-06 14:55:47,688 : INFO : EPOCH 30: training on 99524 raw words (60367 effective words) took 0.1s, 402786 effective words/s\n",
      "2023-12-06 14:55:47,846 : INFO : EPOCH 31: training on 99524 raw words (60438 effective words) took 0.2s, 394974 effective words/s\n",
      "2023-12-06 14:55:48,002 : INFO : EPOCH 32: training on 99524 raw words (60528 effective words) took 0.2s, 400610 effective words/s\n",
      "2023-12-06 14:55:48,164 : INFO : EPOCH 33: training on 99524 raw words (60442 effective words) took 0.2s, 382706 effective words/s\n",
      "2023-12-06 14:55:48,322 : INFO : EPOCH 34: training on 99524 raw words (60617 effective words) took 0.2s, 395041 effective words/s\n",
      "2023-12-06 14:55:48,479 : INFO : EPOCH 35: training on 99524 raw words (60293 effective words) took 0.2s, 395844 effective words/s\n",
      "2023-12-06 14:55:48,634 : INFO : EPOCH 36: training on 99524 raw words (60300 effective words) took 0.2s, 400342 effective words/s\n",
      "2023-12-06 14:55:48,788 : INFO : EPOCH 37: training on 99524 raw words (60381 effective words) took 0.1s, 404235 effective words/s\n",
      "2023-12-06 14:55:48,944 : INFO : EPOCH 38: training on 99524 raw words (60394 effective words) took 0.2s, 399744 effective words/s\n",
      "2023-12-06 14:55:49,094 : INFO : EPOCH 39: training on 99524 raw words (60333 effective words) took 0.1s, 414605 effective words/s\n",
      "2023-12-06 14:55:49,251 : INFO : EPOCH 40: training on 99524 raw words (60425 effective words) took 0.2s, 397193 effective words/s\n",
      "2023-12-06 14:55:49,405 : INFO : EPOCH 41: training on 99524 raw words (60448 effective words) took 0.2s, 402207 effective words/s\n",
      "2023-12-06 14:55:49,555 : INFO : EPOCH 42: training on 99524 raw words (60469 effective words) took 0.1s, 414985 effective words/s\n",
      "2023-12-06 14:55:49,713 : INFO : EPOCH 43: training on 99524 raw words (60505 effective words) took 0.2s, 392503 effective words/s\n",
      "2023-12-06 14:55:49,872 : INFO : EPOCH 44: training on 99524 raw words (60421 effective words) took 0.2s, 393542 effective words/s\n",
      "2023-12-06 14:55:50,027 : INFO : EPOCH 45: training on 99524 raw words (60269 effective words) took 0.2s, 399349 effective words/s\n",
      "2023-12-06 14:55:50,177 : INFO : EPOCH 46: training on 99524 raw words (60512 effective words) took 0.1s, 415186 effective words/s\n",
      "2023-12-06 14:55:50,331 : INFO : EPOCH 47: training on 99524 raw words (60410 effective words) took 0.1s, 403527 effective words/s\n",
      "2023-12-06 14:55:50,485 : INFO : EPOCH 48: training on 99524 raw words (60622 effective words) took 0.1s, 406107 effective words/s\n",
      "2023-12-06 14:55:50,640 : INFO : EPOCH 49: training on 99524 raw words (60342 effective words) took 0.2s, 401128 effective words/s\n",
      "2023-12-06 14:55:50,641 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3020426 effective words) took 7.8s, 388061 effective words/s', 'datetime': '2023-12-06T14:55:50.641498', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:55:50,641 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:55:50.641498', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 56%|    | 270/486 [42:12<35:33,  9.88s/it]2023-12-06 14:55:54,299 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:55:54,300 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:55:54,321 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:55:54,321 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:55:54,327 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:55:54.327273', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:55:54,328 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:55:54.328274', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:55:54,337 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:55:54,338 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:55:54,339 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:55:54.339034', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:55:54,349 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:55:54,349 : INFO : resetting layer weights\n",
      "2023-12-06 14:55:54,352 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:55:54.352042', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:55:54,489 : INFO : EPOCH 0: training on 99524 raw words (65377 effective words) took 0.1s, 489744 effective words/s\n",
      "2023-12-06 14:55:54,657 : INFO : EPOCH 1: training on 99524 raw words (65571 effective words) took 0.2s, 406452 effective words/s\n",
      "2023-12-06 14:55:54,806 : INFO : EPOCH 2: training on 99524 raw words (65676 effective words) took 0.1s, 453071 effective words/s\n",
      "2023-12-06 14:55:54,955 : INFO : EPOCH 3: training on 99524 raw words (65558 effective words) took 0.1s, 452427 effective words/s\n",
      "2023-12-06 14:55:55,106 : INFO : EPOCH 4: training on 99524 raw words (65604 effective words) took 0.1s, 446536 effective words/s\n",
      "2023-12-06 14:55:55,255 : INFO : EPOCH 5: training on 99524 raw words (65520 effective words) took 0.1s, 451484 effective words/s\n",
      "2023-12-06 14:55:55,405 : INFO : EPOCH 6: training on 99524 raw words (65625 effective words) took 0.1s, 453492 effective words/s\n",
      "2023-12-06 14:55:55,554 : INFO : EPOCH 7: training on 99524 raw words (65497 effective words) took 0.1s, 457209 effective words/s\n",
      "2023-12-06 14:55:55,705 : INFO : EPOCH 8: training on 99524 raw words (65504 effective words) took 0.1s, 443092 effective words/s\n",
      "2023-12-06 14:55:55,858 : INFO : EPOCH 9: training on 99524 raw words (65514 effective words) took 0.1s, 446024 effective words/s\n",
      "2023-12-06 14:55:55,859 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655446 effective words) took 1.5s, 435255 effective words/s', 'datetime': '2023-12-06T14:55:55.859039', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:55:55,859 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:55:55.859039', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 56%|    | 271/486 [42:17<29:15,  8.16s/it]2023-12-06 14:55:58,462 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:55:58,463 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:55:58,483 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:55:58,484 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:55:58,490 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:55:58.490748', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:55:58,491 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:55:58.491747', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:55:58,499 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:55:58,500 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:55:58,501 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:55:58.501258', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:55:58,517 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:55:58,518 : INFO : resetting layer weights\n",
      "2023-12-06 14:55:58,520 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:55:58.520002', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:55:58,676 : INFO : EPOCH 0: training on 99524 raw words (65531 effective words) took 0.2s, 431040 effective words/s\n",
      "2023-12-06 14:55:58,851 : INFO : EPOCH 1: training on 99524 raw words (65714 effective words) took 0.2s, 391064 effective words/s\n",
      "2023-12-06 14:55:59,010 : INFO : EPOCH 2: training on 99524 raw words (65573 effective words) took 0.2s, 423991 effective words/s\n",
      "2023-12-06 14:55:59,167 : INFO : EPOCH 3: training on 99524 raw words (65322 effective words) took 0.2s, 427612 effective words/s\n",
      "2023-12-06 14:55:59,322 : INFO : EPOCH 4: training on 99524 raw words (65550 effective words) took 0.1s, 439955 effective words/s\n",
      "2023-12-06 14:55:59,480 : INFO : EPOCH 5: training on 99524 raw words (65497 effective words) took 0.2s, 427387 effective words/s\n",
      "2023-12-06 14:55:59,633 : INFO : EPOCH 6: training on 99524 raw words (65626 effective words) took 0.1s, 442051 effective words/s\n",
      "2023-12-06 14:55:59,790 : INFO : EPOCH 7: training on 99524 raw words (65581 effective words) took 0.2s, 428236 effective words/s\n",
      "2023-12-06 14:55:59,947 : INFO : EPOCH 8: training on 99524 raw words (65538 effective words) took 0.2s, 430235 effective words/s\n",
      "2023-12-06 14:56:00,105 : INFO : EPOCH 9: training on 99524 raw words (65584 effective words) took 0.2s, 426832 effective words/s\n",
      "2023-12-06 14:56:00,106 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655516 effective words) took 1.6s, 413482 effective words/s', 'datetime': '2023-12-06T14:56:00.106311', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:56:00,107 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:56:00.107311', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 56%|    | 272/486 [42:21<25:05,  7.03s/it]2023-12-06 14:56:02,857 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:56:02,858 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:56:02,882 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:56:02,883 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:56:02,889 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:56:02.889952', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:56:02,890 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:56:02.890953', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:56:02,897 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:56:02,897 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:56:02,898 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:56:02.898832', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:56:02,909 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:56:02,909 : INFO : resetting layer weights\n",
      "2023-12-06 14:56:02,912 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:56:02.912677', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:56:03,062 : INFO : EPOCH 0: training on 99524 raw words (65487 effective words) took 0.1s, 448799 effective words/s\n",
      "2023-12-06 14:56:03,239 : INFO : EPOCH 1: training on 99524 raw words (65561 effective words) took 0.2s, 385940 effective words/s\n",
      "2023-12-06 14:56:03,394 : INFO : EPOCH 2: training on 99524 raw words (65629 effective words) took 0.2s, 434106 effective words/s\n",
      "2023-12-06 14:56:03,555 : INFO : EPOCH 3: training on 99524 raw words (65415 effective words) took 0.2s, 419786 effective words/s\n",
      "2023-12-06 14:56:03,709 : INFO : EPOCH 4: training on 99524 raw words (65581 effective words) took 0.2s, 436667 effective words/s\n",
      "2023-12-06 14:56:03,863 : INFO : EPOCH 5: training on 99524 raw words (65488 effective words) took 0.1s, 438498 effective words/s\n",
      "2023-12-06 14:56:04,016 : INFO : EPOCH 6: training on 99524 raw words (65533 effective words) took 0.1s, 439506 effective words/s\n",
      "2023-12-06 14:56:04,170 : INFO : EPOCH 7: training on 99524 raw words (65480 effective words) took 0.1s, 438527 effective words/s\n",
      "2023-12-06 14:56:04,324 : INFO : EPOCH 8: training on 99524 raw words (65577 effective words) took 0.2s, 437091 effective words/s\n",
      "2023-12-06 14:56:04,479 : INFO : EPOCH 9: training on 99524 raw words (65479 effective words) took 0.2s, 433205 effective words/s\n",
      "2023-12-06 14:56:04,480 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655230 effective words) took 1.6s, 418078 effective words/s', 'datetime': '2023-12-06T14:56:04.480653', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:56:04,481 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:56:04.481656', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 56%|    | 273/486 [42:25<22:06,  6.23s/it]2023-12-06 14:56:07,200 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:56:07,201 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:56:07,223 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:56:07,224 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:56:07,232 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:56:07.232239', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:56:07,232 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:56:07.232239', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:56:07,239 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:56:07,240 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:56:07,240 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:56:07.240724', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:56:07,257 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:56:07,258 : INFO : resetting layer weights\n",
      "2023-12-06 14:56:07,260 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:56:07.260020', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:56:07,402 : INFO : EPOCH 0: training on 99524 raw words (65436 effective words) took 0.1s, 479141 effective words/s\n",
      "2023-12-06 14:56:07,579 : INFO : EPOCH 1: training on 99524 raw words (65619 effective words) took 0.2s, 382622 effective words/s\n",
      "2023-12-06 14:56:07,734 : INFO : EPOCH 2: training on 99524 raw words (65346 effective words) took 0.2s, 433091 effective words/s\n",
      "2023-12-06 14:56:07,887 : INFO : EPOCH 3: training on 99524 raw words (65644 effective words) took 0.1s, 443087 effective words/s\n",
      "2023-12-06 14:56:08,035 : INFO : EPOCH 4: training on 99524 raw words (65656 effective words) took 0.1s, 460656 effective words/s\n",
      "2023-12-06 14:56:08,189 : INFO : EPOCH 5: training on 99524 raw words (65419 effective words) took 0.1s, 437117 effective words/s\n",
      "2023-12-06 14:56:08,333 : INFO : EPOCH 6: training on 99524 raw words (65417 effective words) took 0.1s, 463070 effective words/s\n",
      "2023-12-06 14:56:08,486 : INFO : EPOCH 7: training on 99524 raw words (65578 effective words) took 0.1s, 442124 effective words/s\n",
      "2023-12-06 14:56:08,637 : INFO : EPOCH 8: training on 99524 raw words (65520 effective words) took 0.1s, 447777 effective words/s\n",
      "2023-12-06 14:56:08,794 : INFO : EPOCH 9: training on 99524 raw words (65646 effective words) took 0.2s, 432640 effective words/s\n",
      "2023-12-06 14:56:08,940 : INFO : EPOCH 10: training on 99524 raw words (65406 effective words) took 0.1s, 463054 effective words/s\n",
      "2023-12-06 14:56:09,090 : INFO : EPOCH 11: training on 99524 raw words (65637 effective words) took 0.1s, 449306 effective words/s\n",
      "2023-12-06 14:56:09,247 : INFO : EPOCH 12: training on 99524 raw words (65422 effective words) took 0.2s, 428328 effective words/s\n",
      "2023-12-06 14:56:09,407 : INFO : EPOCH 13: training on 99524 raw words (65478 effective words) took 0.2s, 421835 effective words/s\n",
      "2023-12-06 14:56:09,553 : INFO : EPOCH 14: training on 99524 raw words (65527 effective words) took 0.1s, 465037 effective words/s\n",
      "2023-12-06 14:56:09,703 : INFO : EPOCH 15: training on 99524 raw words (65465 effective words) took 0.1s, 447397 effective words/s\n",
      "2023-12-06 14:56:09,855 : INFO : EPOCH 16: training on 99524 raw words (65375 effective words) took 0.1s, 443105 effective words/s\n",
      "2023-12-06 14:56:10,008 : INFO : EPOCH 17: training on 99524 raw words (65548 effective words) took 0.1s, 441622 effective words/s\n",
      "2023-12-06 14:56:10,166 : INFO : EPOCH 18: training on 99524 raw words (65337 effective words) took 0.2s, 424933 effective words/s\n",
      "2023-12-06 14:56:10,317 : INFO : EPOCH 19: training on 99524 raw words (65661 effective words) took 0.1s, 451021 effective words/s\n",
      "2023-12-06 14:56:10,468 : INFO : EPOCH 20: training on 99524 raw words (65507 effective words) took 0.1s, 445253 effective words/s\n",
      "2023-12-06 14:56:10,614 : INFO : EPOCH 21: training on 99524 raw words (65641 effective words) took 0.1s, 465337 effective words/s\n",
      "2023-12-06 14:56:10,765 : INFO : EPOCH 22: training on 99524 raw words (65581 effective words) took 0.1s, 446950 effective words/s\n",
      "2023-12-06 14:56:10,917 : INFO : EPOCH 23: training on 99524 raw words (65645 effective words) took 0.1s, 447131 effective words/s\n",
      "2023-12-06 14:56:11,066 : INFO : EPOCH 24: training on 99524 raw words (65759 effective words) took 0.1s, 454967 effective words/s\n",
      "2023-12-06 14:56:11,214 : INFO : EPOCH 25: training on 99524 raw words (65587 effective words) took 0.1s, 455836 effective words/s\n",
      "2023-12-06 14:56:11,372 : INFO : EPOCH 26: training on 99524 raw words (65617 effective words) took 0.2s, 428589 effective words/s\n",
      "2023-12-06 14:56:11,529 : INFO : EPOCH 27: training on 99524 raw words (65623 effective words) took 0.2s, 429839 effective words/s\n",
      "2023-12-06 14:56:11,676 : INFO : EPOCH 28: training on 99524 raw words (65521 effective words) took 0.1s, 461111 effective words/s\n",
      "2023-12-06 14:56:11,827 : INFO : EPOCH 29: training on 99524 raw words (65444 effective words) took 0.1s, 446456 effective words/s\n",
      "2023-12-06 14:56:11,828 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1966062 effective words) took 4.6s, 430448 effective words/s', 'datetime': '2023-12-06T14:56:11.828368', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:56:11,829 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:56:11.829388', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 56%|    | 274/486 [42:33<23:21,  6.61s/it]2023-12-06 14:56:14,701 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:56:14,702 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:56:14,721 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:56:14,721 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:56:14,727 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:56:14.727792', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:56:14,727 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:56:14.727792', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:56:14,734 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:56:14,736 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:56:14,737 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:56:14.737795', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:56:14,747 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:56:14,748 : INFO : resetting layer weights\n",
      "2023-12-06 14:56:14,751 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:56:14.751793', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:56:14,912 : INFO : EPOCH 0: training on 99524 raw words (65556 effective words) took 0.2s, 417704 effective words/s\n",
      "2023-12-06 14:56:15,076 : INFO : EPOCH 1: training on 99524 raw words (65592 effective words) took 0.2s, 417060 effective words/s\n",
      "2023-12-06 14:56:15,234 : INFO : EPOCH 2: training on 99524 raw words (65526 effective words) took 0.2s, 427974 effective words/s\n",
      "2023-12-06 14:56:15,388 : INFO : EPOCH 3: training on 99524 raw words (65576 effective words) took 0.2s, 436545 effective words/s\n",
      "2023-12-06 14:56:15,544 : INFO : EPOCH 4: training on 99524 raw words (65577 effective words) took 0.2s, 433732 effective words/s\n",
      "2023-12-06 14:56:15,701 : INFO : EPOCH 5: training on 99524 raw words (65418 effective words) took 0.2s, 429705 effective words/s\n",
      "2023-12-06 14:56:15,858 : INFO : EPOCH 6: training on 99524 raw words (65447 effective words) took 0.2s, 427182 effective words/s\n",
      "2023-12-06 14:56:16,020 : INFO : EPOCH 7: training on 99524 raw words (65551 effective words) took 0.2s, 415452 effective words/s\n",
      "2023-12-06 14:56:16,180 : INFO : EPOCH 8: training on 99524 raw words (65359 effective words) took 0.2s, 422948 effective words/s\n",
      "2023-12-06 14:56:16,336 : INFO : EPOCH 9: training on 99524 raw words (65558 effective words) took 0.2s, 430227 effective words/s\n",
      "2023-12-06 14:56:16,492 : INFO : EPOCH 10: training on 99524 raw words (65360 effective words) took 0.2s, 431765 effective words/s\n",
      "2023-12-06 14:56:16,647 : INFO : EPOCH 11: training on 99524 raw words (65531 effective words) took 0.2s, 434121 effective words/s\n",
      "2023-12-06 14:56:16,804 : INFO : EPOCH 12: training on 99524 raw words (65580 effective words) took 0.2s, 431644 effective words/s\n",
      "2023-12-06 14:56:16,958 : INFO : EPOCH 13: training on 99524 raw words (65623 effective words) took 0.2s, 437411 effective words/s\n",
      "2023-12-06 14:56:17,116 : INFO : EPOCH 14: training on 99524 raw words (65642 effective words) took 0.2s, 426221 effective words/s\n",
      "2023-12-06 14:56:17,277 : INFO : EPOCH 15: training on 99524 raw words (65514 effective words) took 0.2s, 420486 effective words/s\n",
      "2023-12-06 14:56:17,447 : INFO : EPOCH 16: training on 99524 raw words (65622 effective words) took 0.2s, 397076 effective words/s\n",
      "2023-12-06 14:56:17,607 : INFO : EPOCH 17: training on 99524 raw words (65473 effective words) took 0.2s, 422142 effective words/s\n",
      "2023-12-06 14:56:17,767 : INFO : EPOCH 18: training on 99524 raw words (65437 effective words) took 0.2s, 419518 effective words/s\n",
      "2023-12-06 14:56:17,919 : INFO : EPOCH 19: training on 99524 raw words (65716 effective words) took 0.1s, 445340 effective words/s\n",
      "2023-12-06 14:56:18,076 : INFO : EPOCH 20: training on 99524 raw words (65605 effective words) took 0.2s, 430354 effective words/s\n",
      "2023-12-06 14:56:18,233 : INFO : EPOCH 21: training on 99524 raw words (65526 effective words) took 0.2s, 429413 effective words/s\n",
      "2023-12-06 14:56:18,391 : INFO : EPOCH 22: training on 99524 raw words (65628 effective words) took 0.2s, 426975 effective words/s\n",
      "2023-12-06 14:56:18,547 : INFO : EPOCH 23: training on 99524 raw words (65571 effective words) took 0.2s, 431597 effective words/s\n",
      "2023-12-06 14:56:18,703 : INFO : EPOCH 24: training on 99524 raw words (65640 effective words) took 0.2s, 436086 effective words/s\n",
      "2023-12-06 14:56:18,866 : INFO : EPOCH 25: training on 99524 raw words (65534 effective words) took 0.2s, 412201 effective words/s\n",
      "2023-12-06 14:56:19,020 : INFO : EPOCH 26: training on 99524 raw words (65694 effective words) took 0.1s, 440603 effective words/s\n",
      "2023-12-06 14:56:19,181 : INFO : EPOCH 27: training on 99524 raw words (65657 effective words) took 0.2s, 420661 effective words/s\n",
      "2023-12-06 14:56:19,336 : INFO : EPOCH 28: training on 99524 raw words (65555 effective words) took 0.1s, 437407 effective words/s\n",
      "2023-12-06 14:56:19,495 : INFO : EPOCH 29: training on 99524 raw words (65408 effective words) took 0.2s, 424005 effective words/s\n",
      "2023-12-06 14:56:19,496 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1966476 effective words) took 4.7s, 414524 effective words/s', 'datetime': '2023-12-06T14:56:19.496821', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:56:19,496 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:56:19.496821', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 57%|    | 275/486 [42:41<24:34,  6.99s/it]2023-12-06 14:56:22,583 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:56:22,583 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:56:22,607 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:56:22,608 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:56:22,616 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:56:22.616189', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:56:22,616 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:56:22.616189', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:56:22,623 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:56:22,624 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:56:22,624 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:56:22.624700', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:56:22,636 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:56:22,636 : INFO : resetting layer weights\n",
      "2023-12-06 14:56:22,639 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:56:22.639823', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:56:22,785 : INFO : EPOCH 0: training on 99524 raw words (65516 effective words) took 0.1s, 461151 effective words/s\n",
      "2023-12-06 14:56:22,958 : INFO : EPOCH 1: training on 99524 raw words (65622 effective words) took 0.2s, 390525 effective words/s\n",
      "2023-12-06 14:56:23,117 : INFO : EPOCH 2: training on 99524 raw words (65649 effective words) took 0.2s, 426236 effective words/s\n",
      "2023-12-06 14:56:23,274 : INFO : EPOCH 3: training on 99524 raw words (65417 effective words) took 0.2s, 429029 effective words/s\n",
      "2023-12-06 14:56:23,430 : INFO : EPOCH 4: training on 99524 raw words (65571 effective words) took 0.2s, 433536 effective words/s\n",
      "2023-12-06 14:56:23,586 : INFO : EPOCH 5: training on 99524 raw words (65497 effective words) took 0.2s, 432566 effective words/s\n",
      "2023-12-06 14:56:23,738 : INFO : EPOCH 6: training on 99524 raw words (65508 effective words) took 0.1s, 442323 effective words/s\n",
      "2023-12-06 14:56:23,892 : INFO : EPOCH 7: training on 99524 raw words (65613 effective words) took 0.1s, 438117 effective words/s\n",
      "2023-12-06 14:56:24,046 : INFO : EPOCH 8: training on 99524 raw words (65535 effective words) took 0.1s, 441732 effective words/s\n",
      "2023-12-06 14:56:24,208 : INFO : EPOCH 9: training on 99524 raw words (65500 effective words) took 0.2s, 416506 effective words/s\n",
      "2023-12-06 14:56:24,359 : INFO : EPOCH 10: training on 99524 raw words (65408 effective words) took 0.1s, 444476 effective words/s\n",
      "2023-12-06 14:56:24,514 : INFO : EPOCH 11: training on 99524 raw words (65681 effective words) took 0.2s, 436937 effective words/s\n",
      "2023-12-06 14:56:24,665 : INFO : EPOCH 12: training on 99524 raw words (65620 effective words) took 0.1s, 449613 effective words/s\n",
      "2023-12-06 14:56:24,821 : INFO : EPOCH 13: training on 99524 raw words (65476 effective words) took 0.2s, 430703 effective words/s\n",
      "2023-12-06 14:56:24,973 : INFO : EPOCH 14: training on 99524 raw words (65497 effective words) took 0.1s, 441618 effective words/s\n",
      "2023-12-06 14:56:25,129 : INFO : EPOCH 15: training on 99524 raw words (65544 effective words) took 0.2s, 432939 effective words/s\n",
      "2023-12-06 14:56:25,293 : INFO : EPOCH 16: training on 99524 raw words (65519 effective words) took 0.2s, 410450 effective words/s\n",
      "2023-12-06 14:56:25,453 : INFO : EPOCH 17: training on 99524 raw words (65440 effective words) took 0.2s, 424926 effective words/s\n",
      "2023-12-06 14:56:25,615 : INFO : EPOCH 18: training on 99524 raw words (65349 effective words) took 0.2s, 411183 effective words/s\n",
      "2023-12-06 14:56:25,772 : INFO : EPOCH 19: training on 99524 raw words (65560 effective words) took 0.2s, 434002 effective words/s\n",
      "2023-12-06 14:56:25,930 : INFO : EPOCH 20: training on 99524 raw words (65411 effective words) took 0.2s, 425454 effective words/s\n",
      "2023-12-06 14:56:26,086 : INFO : EPOCH 21: training on 99524 raw words (65572 effective words) took 0.2s, 433238 effective words/s\n",
      "2023-12-06 14:56:26,236 : INFO : EPOCH 22: training on 99524 raw words (65536 effective words) took 0.1s, 449114 effective words/s\n",
      "2023-12-06 14:56:26,391 : INFO : EPOCH 23: training on 99524 raw words (65582 effective words) took 0.2s, 434356 effective words/s\n",
      "2023-12-06 14:56:26,544 : INFO : EPOCH 24: training on 99524 raw words (65557 effective words) took 0.1s, 442283 effective words/s\n",
      "2023-12-06 14:56:26,700 : INFO : EPOCH 25: training on 99524 raw words (65645 effective words) took 0.2s, 430719 effective words/s\n",
      "2023-12-06 14:56:26,851 : INFO : EPOCH 26: training on 99524 raw words (65656 effective words) took 0.1s, 449845 effective words/s\n",
      "2023-12-06 14:56:27,015 : INFO : EPOCH 27: training on 99524 raw words (65638 effective words) took 0.2s, 410995 effective words/s\n",
      "2023-12-06 14:56:27,167 : INFO : EPOCH 28: training on 99524 raw words (65429 effective words) took 0.1s, 445805 effective words/s\n",
      "2023-12-06 14:56:27,322 : INFO : EPOCH 29: training on 99524 raw words (65592 effective words) took 0.2s, 434224 effective words/s\n",
      "2023-12-06 14:56:27,323 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1966140 effective words) took 4.7s, 419826 effective words/s', 'datetime': '2023-12-06T14:56:27.323149', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:56:27,324 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:56:27.324149', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 57%|    | 276/486 [42:49<25:31,  7.29s/it]2023-12-06 14:56:30,574 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:56:30,575 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:56:30,595 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:56:30,596 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:56:30,603 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:56:30.603976', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:56:30,604 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:56:30.604977', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:56:30,611 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:56:30,612 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:56:30,612 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:56:30.612649', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:56:30,623 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:56:30,624 : INFO : resetting layer weights\n",
      "2023-12-06 14:56:30,628 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:56:30.628333', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:56:30,780 : INFO : EPOCH 0: training on 99524 raw words (65489 effective words) took 0.1s, 442819 effective words/s\n",
      "2023-12-06 14:56:30,947 : INFO : EPOCH 1: training on 99524 raw words (65518 effective words) took 0.2s, 407400 effective words/s\n",
      "2023-12-06 14:56:31,093 : INFO : EPOCH 2: training on 99524 raw words (65391 effective words) took 0.1s, 459872 effective words/s\n",
      "2023-12-06 14:56:31,242 : INFO : EPOCH 3: training on 99524 raw words (65573 effective words) took 0.1s, 455133 effective words/s\n",
      "2023-12-06 14:56:31,394 : INFO : EPOCH 4: training on 99524 raw words (65451 effective words) took 0.1s, 442726 effective words/s\n",
      "2023-12-06 14:56:31,545 : INFO : EPOCH 5: training on 99524 raw words (65522 effective words) took 0.1s, 447264 effective words/s\n",
      "2023-12-06 14:56:31,696 : INFO : EPOCH 6: training on 99524 raw words (65592 effective words) took 0.1s, 447281 effective words/s\n",
      "2023-12-06 14:56:31,845 : INFO : EPOCH 7: training on 99524 raw words (65522 effective words) took 0.1s, 451634 effective words/s\n",
      "2023-12-06 14:56:31,993 : INFO : EPOCH 8: training on 99524 raw words (65450 effective words) took 0.1s, 458949 effective words/s\n",
      "2023-12-06 14:56:32,152 : INFO : EPOCH 9: training on 99524 raw words (65510 effective words) took 0.2s, 422023 effective words/s\n",
      "2023-12-06 14:56:32,296 : INFO : EPOCH 10: training on 99524 raw words (65441 effective words) took 0.1s, 468937 effective words/s\n",
      "2023-12-06 14:56:32,447 : INFO : EPOCH 11: training on 99524 raw words (65612 effective words) took 0.1s, 448951 effective words/s\n",
      "2023-12-06 14:56:32,593 : INFO : EPOCH 12: training on 99524 raw words (65452 effective words) took 0.1s, 465568 effective words/s\n",
      "2023-12-06 14:56:32,743 : INFO : EPOCH 13: training on 99524 raw words (65454 effective words) took 0.1s, 450327 effective words/s\n",
      "2023-12-06 14:56:32,890 : INFO : EPOCH 14: training on 99524 raw words (65505 effective words) took 0.1s, 456912 effective words/s\n",
      "2023-12-06 14:56:33,042 : INFO : EPOCH 15: training on 99524 raw words (65574 effective words) took 0.1s, 444076 effective words/s\n",
      "2023-12-06 14:56:33,189 : INFO : EPOCH 16: training on 99524 raw words (65616 effective words) took 0.1s, 461115 effective words/s\n",
      "2023-12-06 14:56:33,339 : INFO : EPOCH 17: training on 99524 raw words (65374 effective words) took 0.1s, 446630 effective words/s\n",
      "2023-12-06 14:56:33,494 : INFO : EPOCH 18: training on 99524 raw words (65419 effective words) took 0.2s, 435395 effective words/s\n",
      "2023-12-06 14:56:33,646 : INFO : EPOCH 19: training on 99524 raw words (65760 effective words) took 0.1s, 446340 effective words/s\n",
      "2023-12-06 14:56:33,795 : INFO : EPOCH 20: training on 99524 raw words (65502 effective words) took 0.1s, 450873 effective words/s\n",
      "2023-12-06 14:56:33,947 : INFO : EPOCH 21: training on 99524 raw words (65659 effective words) took 0.1s, 448423 effective words/s\n",
      "2023-12-06 14:56:34,097 : INFO : EPOCH 22: training on 99524 raw words (65392 effective words) took 0.1s, 448452 effective words/s\n",
      "2023-12-06 14:56:34,244 : INFO : EPOCH 23: training on 99524 raw words (65706 effective words) took 0.1s, 462511 effective words/s\n",
      "2023-12-06 14:56:34,396 : INFO : EPOCH 24: training on 99524 raw words (65530 effective words) took 0.1s, 442158 effective words/s\n",
      "2023-12-06 14:56:34,546 : INFO : EPOCH 25: training on 99524 raw words (65331 effective words) took 0.1s, 451178 effective words/s\n",
      "2023-12-06 14:56:34,698 : INFO : EPOCH 26: training on 99524 raw words (65716 effective words) took 0.1s, 441849 effective words/s\n",
      "2023-12-06 14:56:34,854 : INFO : EPOCH 27: training on 99524 raw words (65680 effective words) took 0.2s, 435360 effective words/s\n",
      "2023-12-06 14:56:35,007 : INFO : EPOCH 28: training on 99524 raw words (65446 effective words) took 0.1s, 438441 effective words/s\n",
      "2023-12-06 14:56:35,154 : INFO : EPOCH 29: training on 99524 raw words (65586 effective words) took 0.1s, 459172 effective words/s\n",
      "2023-12-06 14:56:35,305 : INFO : EPOCH 30: training on 99524 raw words (65497 effective words) took 0.1s, 448979 effective words/s\n",
      "2023-12-06 14:56:35,453 : INFO : EPOCH 31: training on 99524 raw words (65421 effective words) took 0.1s, 457282 effective words/s\n",
      "2023-12-06 14:56:35,604 : INFO : EPOCH 32: training on 99524 raw words (65743 effective words) took 0.1s, 447015 effective words/s\n",
      "2023-12-06 14:56:35,753 : INFO : EPOCH 33: training on 99524 raw words (65599 effective words) took 0.1s, 457013 effective words/s\n",
      "2023-12-06 14:56:35,903 : INFO : EPOCH 34: training on 99524 raw words (65707 effective words) took 0.1s, 449638 effective words/s\n",
      "2023-12-06 14:56:36,052 : INFO : EPOCH 35: training on 99524 raw words (65656 effective words) took 0.1s, 456375 effective words/s\n",
      "2023-12-06 14:56:36,212 : INFO : EPOCH 36: training on 99524 raw words (65496 effective words) took 0.2s, 422664 effective words/s\n",
      "2023-12-06 14:56:36,358 : INFO : EPOCH 37: training on 99524 raw words (65452 effective words) took 0.1s, 461451 effective words/s\n",
      "2023-12-06 14:56:36,508 : INFO : EPOCH 38: training on 99524 raw words (65364 effective words) took 0.1s, 450805 effective words/s\n",
      "2023-12-06 14:56:36,652 : INFO : EPOCH 39: training on 99524 raw words (65626 effective words) took 0.1s, 467640 effective words/s\n",
      "2023-12-06 14:56:36,803 : INFO : EPOCH 40: training on 99524 raw words (65498 effective words) took 0.1s, 445977 effective words/s\n",
      "2023-12-06 14:56:36,949 : INFO : EPOCH 41: training on 99524 raw words (65674 effective words) took 0.1s, 464690 effective words/s\n",
      "2023-12-06 14:56:37,099 : INFO : EPOCH 42: training on 99524 raw words (65621 effective words) took 0.1s, 452569 effective words/s\n",
      "2023-12-06 14:56:37,251 : INFO : EPOCH 43: training on 99524 raw words (65627 effective words) took 0.1s, 444260 effective words/s\n",
      "2023-12-06 14:56:37,408 : INFO : EPOCH 44: training on 99524 raw words (65416 effective words) took 0.2s, 428159 effective words/s\n",
      "2023-12-06 14:56:37,566 : INFO : EPOCH 45: training on 99524 raw words (65369 effective words) took 0.2s, 426266 effective words/s\n",
      "2023-12-06 14:56:37,719 : INFO : EPOCH 46: training on 99524 raw words (65581 effective words) took 0.1s, 443680 effective words/s\n",
      "2023-12-06 14:56:37,879 : INFO : EPOCH 47: training on 99524 raw words (65526 effective words) took 0.2s, 423273 effective words/s\n",
      "2023-12-06 14:56:38,031 : INFO : EPOCH 48: training on 99524 raw words (65616 effective words) took 0.1s, 445831 effective words/s\n",
      "2023-12-06 14:56:38,184 : INFO : EPOCH 49: training on 99524 raw words (65586 effective words) took 0.1s, 441338 effective words/s\n",
      "2023-12-06 14:56:38,185 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276848 effective words) took 7.6s, 433637 effective words/s', 'datetime': '2023-12-06T14:56:38.185791', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:56:38,186 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:56:38.186295', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 57%|    | 277/486 [43:00<29:11,  8.38s/it]2023-12-06 14:56:41,501 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:56:41,501 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:56:41,523 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:56:41,524 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:56:41,531 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:56:41.531643', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:56:41,532 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:56:41.532643', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:56:41,542 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:56:41,543 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:56:41,544 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:56:41.543506', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:56:41,555 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:56:41,555 : INFO : resetting layer weights\n",
      "2023-12-06 14:56:41,557 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:56:41.557699', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:56:41,721 : INFO : EPOCH 0: training on 99524 raw words (65481 effective words) took 0.2s, 409629 effective words/s\n",
      "2023-12-06 14:56:41,888 : INFO : EPOCH 1: training on 99524 raw words (65672 effective words) took 0.2s, 406709 effective words/s\n",
      "2023-12-06 14:56:42,041 : INFO : EPOCH 2: training on 99524 raw words (65477 effective words) took 0.1s, 442472 effective words/s\n",
      "2023-12-06 14:56:42,198 : INFO : EPOCH 3: training on 99524 raw words (65517 effective words) took 0.2s, 429839 effective words/s\n",
      "2023-12-06 14:56:42,350 : INFO : EPOCH 4: training on 99524 raw words (65483 effective words) took 0.1s, 443026 effective words/s\n",
      "2023-12-06 14:56:42,504 : INFO : EPOCH 5: training on 99524 raw words (65504 effective words) took 0.1s, 436800 effective words/s\n",
      "2023-12-06 14:56:42,658 : INFO : EPOCH 6: training on 99524 raw words (65433 effective words) took 0.1s, 437321 effective words/s\n",
      "2023-12-06 14:56:42,815 : INFO : EPOCH 7: training on 99524 raw words (65640 effective words) took 0.2s, 430205 effective words/s\n",
      "2023-12-06 14:56:42,967 : INFO : EPOCH 8: training on 99524 raw words (65427 effective words) took 0.1s, 444964 effective words/s\n",
      "2023-12-06 14:56:43,131 : INFO : EPOCH 9: training on 99524 raw words (65440 effective words) took 0.2s, 408952 effective words/s\n",
      "2023-12-06 14:56:43,283 : INFO : EPOCH 10: training on 99524 raw words (65413 effective words) took 0.1s, 443069 effective words/s\n",
      "2023-12-06 14:56:43,439 : INFO : EPOCH 11: training on 99524 raw words (65691 effective words) took 0.2s, 434749 effective words/s\n",
      "2023-12-06 14:56:43,596 : INFO : EPOCH 12: training on 99524 raw words (65659 effective words) took 0.2s, 429643 effective words/s\n",
      "2023-12-06 14:56:43,753 : INFO : EPOCH 13: training on 99524 raw words (65450 effective words) took 0.2s, 429291 effective words/s\n",
      "2023-12-06 14:56:43,912 : INFO : EPOCH 14: training on 99524 raw words (65732 effective words) took 0.2s, 425744 effective words/s\n",
      "2023-12-06 14:56:44,065 : INFO : EPOCH 15: training on 99524 raw words (65377 effective words) took 0.1s, 439228 effective words/s\n",
      "2023-12-06 14:56:44,222 : INFO : EPOCH 16: training on 99524 raw words (65649 effective words) took 0.2s, 431288 effective words/s\n",
      "2023-12-06 14:56:44,377 : INFO : EPOCH 17: training on 99524 raw words (65549 effective words) took 0.2s, 432940 effective words/s\n",
      "2023-12-06 14:56:44,541 : INFO : EPOCH 18: training on 99524 raw words (65480 effective words) took 0.2s, 409632 effective words/s\n",
      "2023-12-06 14:56:44,701 : INFO : EPOCH 19: training on 99524 raw words (65592 effective words) took 0.2s, 423727 effective words/s\n",
      "2023-12-06 14:56:44,858 : INFO : EPOCH 20: training on 99524 raw words (65413 effective words) took 0.2s, 430172 effective words/s\n",
      "2023-12-06 14:56:45,012 : INFO : EPOCH 21: training on 99524 raw words (65561 effective words) took 0.2s, 436883 effective words/s\n",
      "2023-12-06 14:56:45,173 : INFO : EPOCH 22: training on 99524 raw words (65618 effective words) took 0.2s, 423434 effective words/s\n",
      "2023-12-06 14:56:45,330 : INFO : EPOCH 23: training on 99524 raw words (65480 effective words) took 0.2s, 429294 effective words/s\n",
      "2023-12-06 14:56:45,486 : INFO : EPOCH 24: training on 99524 raw words (65445 effective words) took 0.2s, 430047 effective words/s\n",
      "2023-12-06 14:56:45,642 : INFO : EPOCH 25: training on 99524 raw words (65364 effective words) took 0.2s, 433007 effective words/s\n",
      "2023-12-06 14:56:45,796 : INFO : EPOCH 26: training on 99524 raw words (65700 effective words) took 0.1s, 439386 effective words/s\n",
      "2023-12-06 14:56:45,958 : INFO : EPOCH 27: training on 99524 raw words (65699 effective words) took 0.2s, 418776 effective words/s\n",
      "2023-12-06 14:56:46,115 : INFO : EPOCH 28: training on 99524 raw words (65457 effective words) took 0.2s, 430213 effective words/s\n",
      "2023-12-06 14:56:46,274 : INFO : EPOCH 29: training on 99524 raw words (65708 effective words) took 0.2s, 426085 effective words/s\n",
      "2023-12-06 14:56:46,430 : INFO : EPOCH 30: training on 99524 raw words (65638 effective words) took 0.2s, 432639 effective words/s\n",
      "2023-12-06 14:56:46,590 : INFO : EPOCH 31: training on 99524 raw words (65442 effective words) took 0.2s, 420418 effective words/s\n",
      "2023-12-06 14:56:46,746 : INFO : EPOCH 32: training on 99524 raw words (65463 effective words) took 0.2s, 433981 effective words/s\n",
      "2023-12-06 14:56:46,905 : INFO : EPOCH 33: training on 99524 raw words (65647 effective words) took 0.2s, 427389 effective words/s\n",
      "2023-12-06 14:56:47,059 : INFO : EPOCH 34: training on 99524 raw words (65552 effective words) took 0.1s, 437370 effective words/s\n",
      "2023-12-06 14:56:47,215 : INFO : EPOCH 35: training on 99524 raw words (65552 effective words) took 0.2s, 431526 effective words/s\n",
      "2023-12-06 14:56:47,379 : INFO : EPOCH 36: training on 99524 raw words (65470 effective words) took 0.2s, 408880 effective words/s\n",
      "2023-12-06 14:56:47,537 : INFO : EPOCH 37: training on 99524 raw words (65528 effective words) took 0.2s, 426881 effective words/s\n",
      "2023-12-06 14:56:47,690 : INFO : EPOCH 38: training on 99524 raw words (65432 effective words) took 0.1s, 441131 effective words/s\n",
      "2023-12-06 14:56:47,849 : INFO : EPOCH 39: training on 99524 raw words (65525 effective words) took 0.2s, 424645 effective words/s\n",
      "2023-12-06 14:56:48,007 : INFO : EPOCH 40: training on 99524 raw words (65570 effective words) took 0.2s, 428737 effective words/s\n",
      "2023-12-06 14:56:48,165 : INFO : EPOCH 41: training on 99524 raw words (65678 effective words) took 0.2s, 427252 effective words/s\n",
      "2023-12-06 14:56:48,324 : INFO : EPOCH 42: training on 99524 raw words (65541 effective words) took 0.2s, 424493 effective words/s\n",
      "2023-12-06 14:56:48,482 : INFO : EPOCH 43: training on 99524 raw words (65594 effective words) took 0.2s, 427208 effective words/s\n",
      "2023-12-06 14:56:48,639 : INFO : EPOCH 44: training on 99524 raw words (65670 effective words) took 0.2s, 429637 effective words/s\n",
      "2023-12-06 14:56:48,799 : INFO : EPOCH 45: training on 99524 raw words (65547 effective words) took 0.2s, 420433 effective words/s\n",
      "2023-12-06 14:56:48,955 : INFO : EPOCH 46: training on 99524 raw words (65369 effective words) took 0.2s, 433048 effective words/s\n",
      "2023-12-06 14:56:49,110 : INFO : EPOCH 47: training on 99524 raw words (65438 effective words) took 0.2s, 431679 effective words/s\n",
      "2023-12-06 14:56:49,276 : INFO : EPOCH 48: training on 99524 raw words (65540 effective words) took 0.2s, 405194 effective words/s\n",
      "2023-12-06 14:56:49,429 : INFO : EPOCH 49: training on 99524 raw words (65509 effective words) took 0.1s, 441920 effective words/s\n",
      "2023-12-06 14:56:49,431 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276816 effective words) took 7.9s, 416233 effective words/s', 'datetime': '2023-12-06T14:56:49.431290', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:56:49,431 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:56:49.431290', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 57%|    | 278/486 [43:11<32:15,  9.31s/it]2023-12-06 14:56:52,966 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:56:52,967 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:56:52,987 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:56:52,988 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:56:52,995 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:56:52.995675', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:56:52,996 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:56:52.996683', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:56:53,004 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:56:53,005 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:56:53,005 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:56:53.005262', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:56:53,017 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:56:53,018 : INFO : resetting layer weights\n",
      "2023-12-06 14:56:53,022 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:56:53.022408', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:56:53,179 : INFO : EPOCH 0: training on 99524 raw words (65468 effective words) took 0.2s, 427795 effective words/s\n",
      "2023-12-06 14:56:53,352 : INFO : EPOCH 1: training on 99524 raw words (65676 effective words) took 0.2s, 390888 effective words/s\n",
      "2023-12-06 14:56:53,504 : INFO : EPOCH 2: training on 99524 raw words (65631 effective words) took 0.1s, 445048 effective words/s\n",
      "2023-12-06 14:56:53,661 : INFO : EPOCH 3: training on 99524 raw words (65414 effective words) took 0.2s, 430847 effective words/s\n",
      "2023-12-06 14:56:53,815 : INFO : EPOCH 4: training on 99524 raw words (65527 effective words) took 0.1s, 437940 effective words/s\n",
      "2023-12-06 14:56:53,971 : INFO : EPOCH 5: training on 99524 raw words (65662 effective words) took 0.2s, 431340 effective words/s\n",
      "2023-12-06 14:56:54,122 : INFO : EPOCH 6: training on 99524 raw words (65437 effective words) took 0.1s, 447594 effective words/s\n",
      "2023-12-06 14:56:54,279 : INFO : EPOCH 7: training on 99524 raw words (65581 effective words) took 0.2s, 430228 effective words/s\n",
      "2023-12-06 14:56:54,428 : INFO : EPOCH 8: training on 99524 raw words (65518 effective words) took 0.1s, 450988 effective words/s\n",
      "2023-12-06 14:56:54,582 : INFO : EPOCH 9: training on 99524 raw words (65608 effective words) took 0.1s, 440660 effective words/s\n",
      "2023-12-06 14:56:54,740 : INFO : EPOCH 10: training on 99524 raw words (65535 effective words) took 0.2s, 429177 effective words/s\n",
      "2023-12-06 14:56:54,895 : INFO : EPOCH 11: training on 99524 raw words (65508 effective words) took 0.2s, 436565 effective words/s\n",
      "2023-12-06 14:56:55,048 : INFO : EPOCH 12: training on 99524 raw words (65588 effective words) took 0.1s, 441107 effective words/s\n",
      "2023-12-06 14:56:55,205 : INFO : EPOCH 13: training on 99524 raw words (65552 effective words) took 0.2s, 428005 effective words/s\n",
      "2023-12-06 14:56:55,359 : INFO : EPOCH 14: training on 99524 raw words (65453 effective words) took 0.1s, 438221 effective words/s\n",
      "2023-12-06 14:56:55,513 : INFO : EPOCH 15: training on 99524 raw words (65530 effective words) took 0.1s, 437491 effective words/s\n",
      "2023-12-06 14:56:55,668 : INFO : EPOCH 16: training on 99524 raw words (65482 effective words) took 0.2s, 434537 effective words/s\n",
      "2023-12-06 14:56:55,823 : INFO : EPOCH 17: training on 99524 raw words (65412 effective words) took 0.1s, 436332 effective words/s\n",
      "2023-12-06 14:56:55,980 : INFO : EPOCH 18: training on 99524 raw words (65563 effective words) took 0.2s, 426847 effective words/s\n",
      "2023-12-06 14:56:56,142 : INFO : EPOCH 19: training on 99524 raw words (65621 effective words) took 0.2s, 416869 effective words/s\n",
      "2023-12-06 14:56:56,300 : INFO : EPOCH 20: training on 99524 raw words (65623 effective words) took 0.2s, 428467 effective words/s\n",
      "2023-12-06 14:56:56,455 : INFO : EPOCH 21: training on 99524 raw words (65575 effective words) took 0.2s, 432834 effective words/s\n",
      "2023-12-06 14:56:56,612 : INFO : EPOCH 22: training on 99524 raw words (65516 effective words) took 0.2s, 433006 effective words/s\n",
      "2023-12-06 14:56:56,767 : INFO : EPOCH 23: training on 99524 raw words (65545 effective words) took 0.2s, 433100 effective words/s\n",
      "2023-12-06 14:56:56,923 : INFO : EPOCH 24: training on 99524 raw words (65570 effective words) took 0.2s, 433509 effective words/s\n",
      "2023-12-06 14:56:57,077 : INFO : EPOCH 25: training on 99524 raw words (65534 effective words) took 0.2s, 435849 effective words/s\n",
      "2023-12-06 14:56:57,228 : INFO : EPOCH 26: training on 99524 raw words (65485 effective words) took 0.1s, 447460 effective words/s\n",
      "2023-12-06 14:56:57,383 : INFO : EPOCH 27: training on 99524 raw words (65702 effective words) took 0.2s, 437716 effective words/s\n",
      "2023-12-06 14:56:57,547 : INFO : EPOCH 28: training on 99524 raw words (65437 effective words) took 0.2s, 408724 effective words/s\n",
      "2023-12-06 14:56:57,703 : INFO : EPOCH 29: training on 99524 raw words (65416 effective words) took 0.2s, 432787 effective words/s\n",
      "2023-12-06 14:56:57,853 : INFO : EPOCH 30: training on 99524 raw words (65503 effective words) took 0.1s, 449877 effective words/s\n",
      "2023-12-06 14:56:58,009 : INFO : EPOCH 31: training on 99524 raw words (65520 effective words) took 0.2s, 433149 effective words/s\n",
      "2023-12-06 14:56:58,163 : INFO : EPOCH 32: training on 99524 raw words (65622 effective words) took 0.1s, 438956 effective words/s\n",
      "2023-12-06 14:56:58,320 : INFO : EPOCH 33: training on 99524 raw words (65623 effective words) took 0.2s, 428746 effective words/s\n",
      "2023-12-06 14:56:58,471 : INFO : EPOCH 34: training on 99524 raw words (65615 effective words) took 0.1s, 448219 effective words/s\n",
      "2023-12-06 14:56:58,634 : INFO : EPOCH 35: training on 99524 raw words (65657 effective words) took 0.2s, 419867 effective words/s\n",
      "2023-12-06 14:56:58,792 : INFO : EPOCH 36: training on 99524 raw words (65406 effective words) took 0.2s, 427675 effective words/s\n",
      "2023-12-06 14:56:58,954 : INFO : EPOCH 37: training on 99524 raw words (65510 effective words) took 0.2s, 414142 effective words/s\n",
      "2023-12-06 14:56:59,110 : INFO : EPOCH 38: training on 99524 raw words (65481 effective words) took 0.2s, 435100 effective words/s\n",
      "2023-12-06 14:56:59,264 : INFO : EPOCH 39: training on 99524 raw words (65516 effective words) took 0.2s, 435548 effective words/s\n",
      "2023-12-06 14:56:59,419 : INFO : EPOCH 40: training on 99524 raw words (65510 effective words) took 0.2s, 435329 effective words/s\n",
      "2023-12-06 14:56:59,573 : INFO : EPOCH 41: training on 99524 raw words (65733 effective words) took 0.1s, 439440 effective words/s\n",
      "2023-12-06 14:56:59,727 : INFO : EPOCH 42: training on 99524 raw words (65609 effective words) took 0.1s, 439223 effective words/s\n",
      "2023-12-06 14:56:59,883 : INFO : EPOCH 43: training on 99524 raw words (65622 effective words) took 0.2s, 432505 effective words/s\n",
      "2023-12-06 14:57:00,036 : INFO : EPOCH 44: training on 99524 raw words (65488 effective words) took 0.1s, 441914 effective words/s\n",
      "2023-12-06 14:57:00,191 : INFO : EPOCH 45: training on 99524 raw words (65462 effective words) took 0.2s, 432797 effective words/s\n",
      "2023-12-06 14:57:00,350 : INFO : EPOCH 46: training on 99524 raw words (65359 effective words) took 0.2s, 424330 effective words/s\n",
      "2023-12-06 14:57:00,506 : INFO : EPOCH 47: training on 99524 raw words (65401 effective words) took 0.2s, 431737 effective words/s\n",
      "2023-12-06 14:57:00,658 : INFO : EPOCH 48: training on 99524 raw words (65481 effective words) took 0.1s, 446365 effective words/s\n",
      "2023-12-06 14:57:00,812 : INFO : EPOCH 49: training on 99524 raw words (65472 effective words) took 0.2s, 435606 effective words/s\n",
      "2023-12-06 14:57:00,813 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276759 effective words) took 7.8s, 420578 effective words/s', 'datetime': '2023-12-06T14:57:00.813963', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:57:00,814 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:57:00.814963', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 57%|    | 279/486 [43:23<34:30, 10.00s/it]2023-12-06 14:57:04,595 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:57:04,596 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:57:04,626 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:57:04,627 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:57:04,632 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:57:04.632237', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:57:04,633 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:57:04.633235', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:57:04,642 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:57:04,642 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:57:04,643 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:57:04.643324', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:57:04,654 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:57:04,655 : INFO : resetting layer weights\n",
      "2023-12-06 14:57:04,658 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:57:04.658834', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:57:04,797 : INFO : EPOCH 0: training on 99524 raw words (62833 effective words) took 0.1s, 469527 effective words/s\n",
      "2023-12-06 14:57:04,967 : INFO : EPOCH 1: training on 99524 raw words (62709 effective words) took 0.2s, 382166 effective words/s\n",
      "2023-12-06 14:57:05,121 : INFO : EPOCH 2: training on 99524 raw words (62703 effective words) took 0.1s, 425539 effective words/s\n",
      "2023-12-06 14:57:05,263 : INFO : EPOCH 3: training on 99524 raw words (62616 effective words) took 0.1s, 450030 effective words/s\n",
      "2023-12-06 14:57:05,414 : INFO : EPOCH 4: training on 99524 raw words (62672 effective words) took 0.1s, 430653 effective words/s\n",
      "2023-12-06 14:57:05,564 : INFO : EPOCH 5: training on 99524 raw words (62690 effective words) took 0.1s, 430047 effective words/s\n",
      "2023-12-06 14:57:05,713 : INFO : EPOCH 6: training on 99524 raw words (62726 effective words) took 0.1s, 434531 effective words/s\n",
      "2023-12-06 14:57:05,855 : INFO : EPOCH 7: training on 99524 raw words (62592 effective words) took 0.1s, 452915 effective words/s\n",
      "2023-12-06 14:57:06,014 : INFO : EPOCH 8: training on 99524 raw words (62605 effective words) took 0.2s, 402968 effective words/s\n",
      "2023-12-06 14:57:06,162 : INFO : EPOCH 9: training on 99524 raw words (62748 effective words) took 0.1s, 439428 effective words/s\n",
      "2023-12-06 14:57:06,163 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (626894 effective words) took 1.5s, 416654 effective words/s', 'datetime': '2023-12-06T14:57:06.163918', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:57:06,163 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:57:06.163918', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 58%|    | 280/486 [43:27<28:18,  8.25s/it]2023-12-06 14:57:08,741 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:57:08,741 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:57:08,762 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:57:08,762 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:57:08,770 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:57:08.770218', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:57:08,771 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:57:08.771218', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:57:08,779 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:57:08,780 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:57:08,780 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:57:08.780220', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:57:08,788 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:57:08,789 : INFO : resetting layer weights\n",
      "2023-12-06 14:57:08,792 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:57:08.792347', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:57:08,945 : INFO : EPOCH 0: training on 99524 raw words (62734 effective words) took 0.1s, 419301 effective words/s\n",
      "2023-12-06 14:57:09,124 : INFO : EPOCH 1: training on 99524 raw words (62758 effective words) took 0.2s, 362199 effective words/s\n",
      "2023-12-06 14:57:09,281 : INFO : EPOCH 2: training on 99524 raw words (62808 effective words) took 0.2s, 415821 effective words/s\n",
      "2023-12-06 14:57:09,431 : INFO : EPOCH 3: training on 99524 raw words (62776 effective words) took 0.1s, 432577 effective words/s\n",
      "2023-12-06 14:57:09,586 : INFO : EPOCH 4: training on 99524 raw words (62732 effective words) took 0.2s, 416563 effective words/s\n",
      "2023-12-06 14:57:09,741 : INFO : EPOCH 5: training on 99524 raw words (62690 effective words) took 0.2s, 415454 effective words/s\n",
      "2023-12-06 14:57:09,896 : INFO : EPOCH 6: training on 99524 raw words (62746 effective words) took 0.2s, 417465 effective words/s\n",
      "2023-12-06 14:57:10,051 : INFO : EPOCH 7: training on 99524 raw words (62630 effective words) took 0.2s, 414900 effective words/s\n",
      "2023-12-06 14:57:10,205 : INFO : EPOCH 8: training on 99524 raw words (62664 effective words) took 0.1s, 419715 effective words/s\n",
      "2023-12-06 14:57:10,364 : INFO : EPOCH 9: training on 99524 raw words (62816 effective words) took 0.2s, 406862 effective words/s\n",
      "2023-12-06 14:57:10,365 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627354 effective words) took 1.6s, 398953 effective words/s', 'datetime': '2023-12-06T14:57:10.365213', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:57:10,365 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:57:10.365213', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 58%|    | 281/486 [43:31<24:06,  7.06s/it]2023-12-06 14:57:13,027 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:57:13,028 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:57:13,060 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:57:13,060 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:57:13,067 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:57:13.067233', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:57:13,068 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:57:13.068233', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:57:13,073 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:57:13,074 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:57:13,075 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:57:13.075235', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:57:13,082 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:57:13,083 : INFO : resetting layer weights\n",
      "2023-12-06 14:57:13,087 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:57:13.087224', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:57:13,239 : INFO : EPOCH 0: training on 99524 raw words (62837 effective words) took 0.1s, 423904 effective words/s\n",
      "2023-12-06 14:57:13,421 : INFO : EPOCH 1: training on 99524 raw words (62628 effective words) took 0.2s, 356091 effective words/s\n",
      "2023-12-06 14:57:13,585 : INFO : EPOCH 2: training on 99524 raw words (62701 effective words) took 0.2s, 395511 effective words/s\n",
      "2023-12-06 14:57:13,740 : INFO : EPOCH 3: training on 99524 raw words (62576 effective words) took 0.2s, 416459 effective words/s\n",
      "2023-12-06 14:57:13,888 : INFO : EPOCH 4: training on 99524 raw words (62840 effective words) took 0.1s, 435340 effective words/s\n",
      "2023-12-06 14:57:14,042 : INFO : EPOCH 5: training on 99524 raw words (62662 effective words) took 0.1s, 420944 effective words/s\n",
      "2023-12-06 14:57:14,193 : INFO : EPOCH 6: training on 99524 raw words (62739 effective words) took 0.1s, 425903 effective words/s\n",
      "2023-12-06 14:57:14,347 : INFO : EPOCH 7: training on 99524 raw words (62806 effective words) took 0.1s, 419633 effective words/s\n",
      "2023-12-06 14:57:14,519 : INFO : EPOCH 8: training on 99524 raw words (62739 effective words) took 0.2s, 375923 effective words/s\n",
      "2023-12-06 14:57:14,681 : INFO : EPOCH 9: training on 99524 raw words (62653 effective words) took 0.2s, 398704 effective words/s\n",
      "2023-12-06 14:57:14,682 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627181 effective words) took 1.6s, 393211 effective words/s', 'datetime': '2023-12-06T14:57:14.682884', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:57:14,683 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:57:14.683884', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 58%|    | 282/486 [43:36<21:14,  6.25s/it]2023-12-06 14:57:17,737 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:57:17,738 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:57:17,761 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:57:17,762 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:57:17,767 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:57:17.767620', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:57:17,768 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:57:17.768620', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:57:17,778 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:57:17,779 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:57:17,779 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:57:17.779171', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:57:17,792 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:57:17,794 : INFO : resetting layer weights\n",
      "2023-12-06 14:57:17,797 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:57:17.797759', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:57:17,955 : INFO : EPOCH 0: training on 99524 raw words (62638 effective words) took 0.2s, 412938 effective words/s\n",
      "2023-12-06 14:57:18,097 : INFO : EPOCH 1: training on 99524 raw words (62692 effective words) took 0.1s, 451472 effective words/s\n",
      "2023-12-06 14:57:18,247 : INFO : EPOCH 2: training on 99524 raw words (62538 effective words) took 0.1s, 433083 effective words/s\n",
      "2023-12-06 14:57:18,396 : INFO : EPOCH 3: training on 99524 raw words (62529 effective words) took 0.1s, 433233 effective words/s\n",
      "2023-12-06 14:57:18,545 : INFO : EPOCH 4: training on 99524 raw words (62888 effective words) took 0.1s, 436996 effective words/s\n",
      "2023-12-06 14:57:18,695 : INFO : EPOCH 5: training on 99524 raw words (62728 effective words) took 0.1s, 427774 effective words/s\n",
      "2023-12-06 14:57:18,844 : INFO : EPOCH 6: training on 99524 raw words (62797 effective words) took 0.1s, 433983 effective words/s\n",
      "2023-12-06 14:57:18,995 : INFO : EPOCH 7: training on 99524 raw words (62712 effective words) took 0.1s, 431320 effective words/s\n",
      "2023-12-06 14:57:19,138 : INFO : EPOCH 8: training on 99524 raw words (62727 effective words) took 0.1s, 451087 effective words/s\n",
      "2023-12-06 14:57:19,296 : INFO : EPOCH 9: training on 99524 raw words (62737 effective words) took 0.2s, 409178 effective words/s\n",
      "2023-12-06 14:57:19,443 : INFO : EPOCH 10: training on 99524 raw words (62706 effective words) took 0.1s, 439199 effective words/s\n",
      "2023-12-06 14:57:19,591 : INFO : EPOCH 11: training on 99524 raw words (62713 effective words) took 0.1s, 436225 effective words/s\n",
      "2023-12-06 14:57:19,736 : INFO : EPOCH 12: training on 99524 raw words (62849 effective words) took 0.1s, 450346 effective words/s\n",
      "2023-12-06 14:57:19,887 : INFO : EPOCH 13: training on 99524 raw words (62694 effective words) took 0.1s, 428283 effective words/s\n",
      "2023-12-06 14:57:20,035 : INFO : EPOCH 14: training on 99524 raw words (62744 effective words) took 0.1s, 438220 effective words/s\n",
      "2023-12-06 14:57:20,184 : INFO : EPOCH 15: training on 99524 raw words (62614 effective words) took 0.1s, 430583 effective words/s\n",
      "2023-12-06 14:57:20,328 : INFO : EPOCH 16: training on 99524 raw words (62670 effective words) took 0.1s, 448492 effective words/s\n",
      "2023-12-06 14:57:20,479 : INFO : EPOCH 17: training on 99524 raw words (62544 effective words) took 0.1s, 429332 effective words/s\n",
      "2023-12-06 14:57:20,634 : INFO : EPOCH 18: training on 99524 raw words (62482 effective words) took 0.2s, 415714 effective words/s\n",
      "2023-12-06 14:57:20,777 : INFO : EPOCH 19: training on 99524 raw words (62819 effective words) took 0.1s, 451566 effective words/s\n",
      "2023-12-06 14:57:20,925 : INFO : EPOCH 20: training on 99524 raw words (62732 effective words) took 0.1s, 436581 effective words/s\n",
      "2023-12-06 14:57:21,073 : INFO : EPOCH 21: training on 99524 raw words (62829 effective words) took 0.1s, 437586 effective words/s\n",
      "2023-12-06 14:57:21,216 : INFO : EPOCH 22: training on 99524 raw words (62794 effective words) took 0.1s, 452601 effective words/s\n",
      "2023-12-06 14:57:21,365 : INFO : EPOCH 23: training on 99524 raw words (62854 effective words) took 0.1s, 437694 effective words/s\n",
      "2023-12-06 14:57:21,512 : INFO : EPOCH 24: training on 99524 raw words (62940 effective words) took 0.1s, 440880 effective words/s\n",
      "2023-12-06 14:57:21,662 : INFO : EPOCH 25: training on 99524 raw words (62730 effective words) took 0.1s, 429537 effective words/s\n",
      "2023-12-06 14:57:21,822 : INFO : EPOCH 26: training on 99524 raw words (62874 effective words) took 0.2s, 404313 effective words/s\n",
      "2023-12-06 14:57:21,964 : INFO : EPOCH 27: training on 99524 raw words (62929 effective words) took 0.1s, 459981 effective words/s\n",
      "2023-12-06 14:57:22,113 : INFO : EPOCH 28: training on 99524 raw words (62570 effective words) took 0.1s, 433855 effective words/s\n",
      "2023-12-06 14:57:22,268 : INFO : EPOCH 29: training on 99524 raw words (62678 effective words) took 0.2s, 416327 effective words/s\n",
      "2023-12-06 14:57:22,269 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881751 effective words) took 4.5s, 420936 effective words/s', 'datetime': '2023-12-06T14:57:22.269484', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:57:22,270 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:57:22.270484', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 58%|    | 283/486 [43:43<22:41,  6.71s/it]2023-12-06 14:57:25,165 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:57:25,166 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:57:25,187 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:57:25,188 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:57:25,192 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:57:25.192435', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:57:25,193 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:57:25.193439', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:57:25,201 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:57:25,201 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:57:25,202 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:57:25.202057', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:57:25,209 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:57:25,210 : INFO : resetting layer weights\n",
      "2023-12-06 14:57:25,213 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:57:25.213586', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:57:25,356 : INFO : EPOCH 0: training on 99524 raw words (62794 effective words) took 0.1s, 453635 effective words/s\n",
      "2023-12-06 14:57:25,527 : INFO : EPOCH 1: training on 99524 raw words (62721 effective words) took 0.2s, 381211 effective words/s\n",
      "2023-12-06 14:57:25,686 : INFO : EPOCH 2: training on 99524 raw words (62769 effective words) took 0.2s, 406257 effective words/s\n",
      "2023-12-06 14:57:25,843 : INFO : EPOCH 3: training on 99524 raw words (62744 effective words) took 0.2s, 413769 effective words/s\n",
      "2023-12-06 14:57:25,994 : INFO : EPOCH 4: training on 99524 raw words (62661 effective words) took 0.1s, 426964 effective words/s\n",
      "2023-12-06 14:57:26,151 : INFO : EPOCH 5: training on 99524 raw words (62763 effective words) took 0.2s, 411415 effective words/s\n",
      "2023-12-06 14:57:26,305 : INFO : EPOCH 6: training on 99524 raw words (62754 effective words) took 0.1s, 418494 effective words/s\n",
      "2023-12-06 14:57:26,462 : INFO : EPOCH 7: training on 99524 raw words (62720 effective words) took 0.2s, 411015 effective words/s\n",
      "2023-12-06 14:57:26,614 : INFO : EPOCH 8: training on 99524 raw words (62828 effective words) took 0.1s, 426982 effective words/s\n",
      "2023-12-06 14:57:26,768 : INFO : EPOCH 9: training on 99524 raw words (62667 effective words) took 0.1s, 419296 effective words/s\n",
      "2023-12-06 14:57:26,930 : INFO : EPOCH 10: training on 99524 raw words (62675 effective words) took 0.2s, 398375 effective words/s\n",
      "2023-12-06 14:57:27,085 : INFO : EPOCH 11: training on 99524 raw words (62770 effective words) took 0.2s, 415555 effective words/s\n",
      "2023-12-06 14:57:27,237 : INFO : EPOCH 12: training on 99524 raw words (62743 effective words) took 0.1s, 427702 effective words/s\n",
      "2023-12-06 14:57:27,392 : INFO : EPOCH 13: training on 99524 raw words (62731 effective words) took 0.2s, 416277 effective words/s\n",
      "2023-12-06 14:57:27,549 : INFO : EPOCH 14: training on 99524 raw words (62842 effective words) took 0.2s, 410766 effective words/s\n",
      "2023-12-06 14:57:27,709 : INFO : EPOCH 15: training on 99524 raw words (62885 effective words) took 0.2s, 407612 effective words/s\n",
      "2023-12-06 14:57:27,860 : INFO : EPOCH 16: training on 99524 raw words (62739 effective words) took 0.1s, 429703 effective words/s\n",
      "2023-12-06 14:57:28,014 : INFO : EPOCH 17: training on 99524 raw words (62588 effective words) took 0.2s, 415854 effective words/s\n",
      "2023-12-06 14:57:28,169 : INFO : EPOCH 18: training on 99524 raw words (62754 effective words) took 0.2s, 416203 effective words/s\n",
      "2023-12-06 14:57:28,328 : INFO : EPOCH 19: training on 99524 raw words (62829 effective words) took 0.2s, 405395 effective words/s\n",
      "2023-12-06 14:57:28,481 : INFO : EPOCH 20: training on 99524 raw words (62758 effective words) took 0.1s, 423012 effective words/s\n",
      "2023-12-06 14:57:28,638 : INFO : EPOCH 21: training on 99524 raw words (62836 effective words) took 0.2s, 416696 effective words/s\n",
      "2023-12-06 14:57:28,790 : INFO : EPOCH 22: training on 99524 raw words (62845 effective words) took 0.1s, 425665 effective words/s\n",
      "2023-12-06 14:57:28,949 : INFO : EPOCH 23: training on 99524 raw words (62772 effective words) took 0.2s, 406285 effective words/s\n",
      "2023-12-06 14:57:29,102 : INFO : EPOCH 24: training on 99524 raw words (62678 effective words) took 0.1s, 421664 effective words/s\n",
      "2023-12-06 14:57:29,266 : INFO : EPOCH 25: training on 99524 raw words (62614 effective words) took 0.2s, 391257 effective words/s\n",
      "2023-12-06 14:57:29,422 : INFO : EPOCH 26: training on 99524 raw words (62941 effective words) took 0.2s, 418611 effective words/s\n",
      "2023-12-06 14:57:29,579 : INFO : EPOCH 27: training on 99524 raw words (62946 effective words) took 0.2s, 412803 effective words/s\n",
      "2023-12-06 14:57:29,735 : INFO : EPOCH 28: training on 99524 raw words (62664 effective words) took 0.2s, 413898 effective words/s\n",
      "2023-12-06 14:57:29,892 : INFO : EPOCH 29: training on 99524 raw words (62744 effective words) took 0.2s, 412383 effective words/s\n",
      "2023-12-06 14:57:29,893 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1882775 effective words) took 4.7s, 402484 effective words/s', 'datetime': '2023-12-06T14:57:29.893168', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:57:29,894 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:57:29.894168', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 58%|    | 284/486 [43:51<23:41,  7.04s/it]2023-12-06 14:57:32,969 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:57:32,970 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:57:32,990 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:57:32,990 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:57:32,995 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:57:32.995266', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:57:32,995 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:57:32.995266', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:57:33,001 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:57:33,001 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:57:33,002 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:57:33.002613', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:57:33,011 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:57:33,012 : INFO : resetting layer weights\n",
      "2023-12-06 14:57:33,015 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:57:33.015120', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:57:33,164 : INFO : EPOCH 0: training on 99524 raw words (62724 effective words) took 0.1s, 432012 effective words/s\n",
      "2023-12-06 14:57:33,340 : INFO : EPOCH 1: training on 99524 raw words (62770 effective words) took 0.2s, 369012 effective words/s\n",
      "2023-12-06 14:57:33,495 : INFO : EPOCH 2: training on 99524 raw words (62888 effective words) took 0.1s, 420717 effective words/s\n",
      "2023-12-06 14:57:33,650 : INFO : EPOCH 3: training on 99524 raw words (62626 effective words) took 0.2s, 415400 effective words/s\n",
      "2023-12-06 14:57:33,805 : INFO : EPOCH 4: training on 99524 raw words (62803 effective words) took 0.1s, 420887 effective words/s\n",
      "2023-12-06 14:57:33,955 : INFO : EPOCH 5: training on 99524 raw words (62778 effective words) took 0.1s, 429243 effective words/s\n",
      "2023-12-06 14:57:34,109 : INFO : EPOCH 6: training on 99524 raw words (62814 effective words) took 0.1s, 422651 effective words/s\n",
      "2023-12-06 14:57:34,259 : INFO : EPOCH 7: training on 99524 raw words (62770 effective words) took 0.1s, 430817 effective words/s\n",
      "2023-12-06 14:57:34,414 : INFO : EPOCH 8: training on 99524 raw words (62599 effective words) took 0.2s, 415880 effective words/s\n",
      "2023-12-06 14:57:34,571 : INFO : EPOCH 9: training on 99524 raw words (62671 effective words) took 0.2s, 410857 effective words/s\n",
      "2023-12-06 14:57:34,729 : INFO : EPOCH 10: training on 99524 raw words (62754 effective words) took 0.2s, 409017 effective words/s\n",
      "2023-12-06 14:57:34,881 : INFO : EPOCH 11: training on 99524 raw words (62774 effective words) took 0.1s, 427108 effective words/s\n",
      "2023-12-06 14:57:35,036 : INFO : EPOCH 12: training on 99524 raw words (62725 effective words) took 0.2s, 415847 effective words/s\n",
      "2023-12-06 14:57:35,191 : INFO : EPOCH 13: training on 99524 raw words (62685 effective words) took 0.2s, 416860 effective words/s\n",
      "2023-12-06 14:57:35,341 : INFO : EPOCH 14: training on 99524 raw words (62860 effective words) took 0.1s, 430330 effective words/s\n",
      "2023-12-06 14:57:35,504 : INFO : EPOCH 15: training on 99524 raw words (62619 effective words) took 0.2s, 396427 effective words/s\n",
      "2023-12-06 14:57:35,658 : INFO : EPOCH 16: training on 99524 raw words (62724 effective words) took 0.2s, 417990 effective words/s\n",
      "2023-12-06 14:57:35,809 : INFO : EPOCH 17: training on 99524 raw words (62610 effective words) took 0.1s, 428657 effective words/s\n",
      "2023-12-06 14:57:35,964 : INFO : EPOCH 18: training on 99524 raw words (62706 effective words) took 0.2s, 416082 effective words/s\n",
      "2023-12-06 14:57:36,116 : INFO : EPOCH 19: training on 99524 raw words (62934 effective words) took 0.1s, 428419 effective words/s\n",
      "2023-12-06 14:57:36,273 : INFO : EPOCH 20: training on 99524 raw words (62773 effective words) took 0.2s, 409103 effective words/s\n",
      "2023-12-06 14:57:36,429 : INFO : EPOCH 21: training on 99524 raw words (62842 effective words) took 0.2s, 414730 effective words/s\n",
      "2023-12-06 14:57:36,591 : INFO : EPOCH 22: training on 99524 raw words (62934 effective words) took 0.2s, 405011 effective words/s\n",
      "2023-12-06 14:57:36,744 : INFO : EPOCH 23: training on 99524 raw words (62627 effective words) took 0.1s, 420723 effective words/s\n",
      "2023-12-06 14:57:36,899 : INFO : EPOCH 24: training on 99524 raw words (62819 effective words) took 0.2s, 416876 effective words/s\n",
      "2023-12-06 14:57:37,050 : INFO : EPOCH 25: training on 99524 raw words (62663 effective words) took 0.1s, 429493 effective words/s\n",
      "2023-12-06 14:57:37,204 : INFO : EPOCH 26: training on 99524 raw words (62767 effective words) took 0.1s, 419968 effective words/s\n",
      "2023-12-06 14:57:37,364 : INFO : EPOCH 27: training on 99524 raw words (62832 effective words) took 0.2s, 402450 effective words/s\n",
      "2023-12-06 14:57:37,522 : INFO : EPOCH 28: training on 99524 raw words (62557 effective words) took 0.2s, 407841 effective words/s\n",
      "2023-12-06 14:57:37,675 : INFO : EPOCH 29: training on 99524 raw words (62654 effective words) took 0.1s, 420776 effective words/s\n",
      "2023-12-06 14:57:37,676 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1882302 effective words) took 4.7s, 403839 effective words/s', 'datetime': '2023-12-06T14:57:37.676692', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:57:37,677 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:57:37.677693', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 59%|    | 285/486 [43:59<24:28,  7.30s/it]2023-12-06 14:57:40,897 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:57:40,898 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:57:40,917 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:57:40,918 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:57:40,923 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:57:40.923738', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:57:40,923 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:57:40.923738', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:57:40,929 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:57:40,930 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:57:40,931 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:57:40.931424', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:57:40,942 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:57:40,943 : INFO : resetting layer weights\n",
      "2023-12-06 14:57:40,946 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:57:40.946177', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:57:41,094 : INFO : EPOCH 0: training on 99524 raw words (62616 effective words) took 0.1s, 436560 effective words/s\n",
      "2023-12-06 14:57:41,260 : INFO : EPOCH 1: training on 99524 raw words (62736 effective words) took 0.2s, 390932 effective words/s\n",
      "2023-12-06 14:57:41,410 : INFO : EPOCH 2: training on 99524 raw words (62824 effective words) took 0.1s, 433027 effective words/s\n",
      "2023-12-06 14:57:41,559 : INFO : EPOCH 3: training on 99524 raw words (62698 effective words) took 0.1s, 435013 effective words/s\n",
      "2023-12-06 14:57:41,703 : INFO : EPOCH 4: training on 99524 raw words (62696 effective words) took 0.1s, 446534 effective words/s\n",
      "2023-12-06 14:57:41,853 : INFO : EPOCH 5: training on 99524 raw words (62658 effective words) took 0.1s, 434191 effective words/s\n",
      "2023-12-06 14:57:42,003 : INFO : EPOCH 6: training on 99524 raw words (62636 effective words) took 0.1s, 425942 effective words/s\n",
      "2023-12-06 14:57:42,152 : INFO : EPOCH 7: training on 99524 raw words (62708 effective words) took 0.1s, 434303 effective words/s\n",
      "2023-12-06 14:57:42,309 : INFO : EPOCH 8: training on 99524 raw words (62745 effective words) took 0.2s, 412796 effective words/s\n",
      "2023-12-06 14:57:42,450 : INFO : EPOCH 9: training on 99524 raw words (62732 effective words) took 0.1s, 457727 effective words/s\n",
      "2023-12-06 14:57:42,598 : INFO : EPOCH 10: training on 99524 raw words (62656 effective words) took 0.1s, 439500 effective words/s\n",
      "2023-12-06 14:57:42,741 : INFO : EPOCH 11: training on 99524 raw words (62755 effective words) took 0.1s, 453989 effective words/s\n",
      "2023-12-06 14:57:42,892 : INFO : EPOCH 12: training on 99524 raw words (62740 effective words) took 0.1s, 428899 effective words/s\n",
      "2023-12-06 14:57:43,032 : INFO : EPOCH 13: training on 99524 raw words (62590 effective words) took 0.1s, 459408 effective words/s\n",
      "2023-12-06 14:57:43,182 : INFO : EPOCH 14: training on 99524 raw words (62794 effective words) took 0.1s, 430959 effective words/s\n",
      "2023-12-06 14:57:43,338 : INFO : EPOCH 15: training on 99524 raw words (62649 effective words) took 0.2s, 415573 effective words/s\n",
      "2023-12-06 14:57:43,487 : INFO : EPOCH 16: training on 99524 raw words (62734 effective words) took 0.1s, 435398 effective words/s\n",
      "2023-12-06 14:57:43,636 : INFO : EPOCH 17: training on 99524 raw words (62654 effective words) took 0.1s, 432729 effective words/s\n",
      "2023-12-06 14:57:43,783 : INFO : EPOCH 18: training on 99524 raw words (62644 effective words) took 0.1s, 436357 effective words/s\n",
      "2023-12-06 14:57:43,932 : INFO : EPOCH 19: training on 99524 raw words (62774 effective words) took 0.1s, 437148 effective words/s\n",
      "2023-12-06 14:57:44,083 : INFO : EPOCH 20: training on 99524 raw words (62712 effective words) took 0.1s, 428721 effective words/s\n",
      "2023-12-06 14:57:44,239 : INFO : EPOCH 21: training on 99524 raw words (62846 effective words) took 0.2s, 414773 effective words/s\n",
      "2023-12-06 14:57:44,389 : INFO : EPOCH 22: training on 99524 raw words (62867 effective words) took 0.1s, 434263 effective words/s\n",
      "2023-12-06 14:57:44,546 : INFO : EPOCH 23: training on 99524 raw words (62687 effective words) took 0.2s, 408805 effective words/s\n",
      "2023-12-06 14:57:44,693 : INFO : EPOCH 24: training on 99524 raw words (62840 effective words) took 0.1s, 440551 effective words/s\n",
      "2023-12-06 14:57:44,842 : INFO : EPOCH 25: training on 99524 raw words (62776 effective words) took 0.1s, 436276 effective words/s\n",
      "2023-12-06 14:57:44,991 : INFO : EPOCH 26: training on 99524 raw words (62812 effective words) took 0.1s, 436770 effective words/s\n",
      "2023-12-06 14:57:45,141 : INFO : EPOCH 27: training on 99524 raw words (62865 effective words) took 0.1s, 430822 effective words/s\n",
      "2023-12-06 14:57:45,288 : INFO : EPOCH 28: training on 99524 raw words (62724 effective words) took 0.1s, 441940 effective words/s\n",
      "2023-12-06 14:57:45,443 : INFO : EPOCH 29: training on 99524 raw words (62761 effective words) took 0.1s, 418535 effective words/s\n",
      "2023-12-06 14:57:45,594 : INFO : EPOCH 30: training on 99524 raw words (62626 effective words) took 0.1s, 428001 effective words/s\n",
      "2023-12-06 14:57:45,740 : INFO : EPOCH 31: training on 99524 raw words (62869 effective words) took 0.1s, 445031 effective words/s\n",
      "2023-12-06 14:57:45,892 : INFO : EPOCH 32: training on 99524 raw words (62731 effective words) took 0.1s, 423107 effective words/s\n",
      "2023-12-06 14:57:46,036 : INFO : EPOCH 33: training on 99524 raw words (62935 effective words) took 0.1s, 452791 effective words/s\n",
      "2023-12-06 14:57:46,184 : INFO : EPOCH 34: training on 99524 raw words (62857 effective words) took 0.1s, 438262 effective words/s\n",
      "2023-12-06 14:57:46,331 : INFO : EPOCH 35: training on 99524 raw words (62858 effective words) took 0.1s, 438220 effective words/s\n",
      "2023-12-06 14:57:46,476 : INFO : EPOCH 36: training on 99524 raw words (62714 effective words) took 0.1s, 448532 effective words/s\n",
      "2023-12-06 14:57:46,635 : INFO : EPOCH 37: training on 99524 raw words (62568 effective words) took 0.2s, 408214 effective words/s\n",
      "2023-12-06 14:57:46,783 : INFO : EPOCH 38: training on 99524 raw words (62613 effective words) took 0.1s, 434913 effective words/s\n",
      "2023-12-06 14:57:46,930 : INFO : EPOCH 39: training on 99524 raw words (62662 effective words) took 0.1s, 438806 effective words/s\n",
      "2023-12-06 14:57:47,079 : INFO : EPOCH 40: training on 99524 raw words (62652 effective words) took 0.1s, 436448 effective words/s\n",
      "2023-12-06 14:57:47,228 : INFO : EPOCH 41: training on 99524 raw words (62900 effective words) took 0.1s, 435677 effective words/s\n",
      "2023-12-06 14:57:47,375 : INFO : EPOCH 42: training on 99524 raw words (62765 effective words) took 0.1s, 436155 effective words/s\n",
      "2023-12-06 14:57:47,525 : INFO : EPOCH 43: training on 99524 raw words (62882 effective words) took 0.1s, 433479 effective words/s\n",
      "2023-12-06 14:57:47,677 : INFO : EPOCH 44: training on 99524 raw words (62722 effective words) took 0.1s, 426121 effective words/s\n",
      "2023-12-06 14:57:47,827 : INFO : EPOCH 45: training on 99524 raw words (62766 effective words) took 0.1s, 432529 effective words/s\n",
      "2023-12-06 14:57:47,976 : INFO : EPOCH 46: training on 99524 raw words (62632 effective words) took 0.1s, 431775 effective words/s\n",
      "2023-12-06 14:57:48,129 : INFO : EPOCH 47: training on 99524 raw words (62574 effective words) took 0.1s, 419121 effective words/s\n",
      "2023-12-06 14:57:48,273 : INFO : EPOCH 48: training on 99524 raw words (62935 effective words) took 0.1s, 452844 effective words/s\n",
      "2023-12-06 14:57:48,423 : INFO : EPOCH 49: training on 99524 raw words (62814 effective words) took 0.1s, 430578 effective words/s\n",
      "2023-12-06 14:57:48,424 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3137004 effective words) took 7.5s, 419538 effective words/s', 'datetime': '2023-12-06T14:57:48.424861', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:57:48,425 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:57:48.425861', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 59%|    | 286/486 [44:10<27:48,  8.34s/it]2023-12-06 14:57:51,655 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:57:51,655 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:57:51,675 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:57:51,676 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:57:51,683 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:57:51.683696', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:57:51,685 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:57:51.685696', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:57:51,691 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:57:51,692 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:57:51,692 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:57:51.692301', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:57:51,704 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:57:51,704 : INFO : resetting layer weights\n",
      "2023-12-06 14:57:51,708 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:57:51.708831', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:57:51,853 : INFO : EPOCH 0: training on 99524 raw words (62659 effective words) took 0.1s, 444097 effective words/s\n",
      "2023-12-06 14:57:52,024 : INFO : EPOCH 1: training on 99524 raw words (62749 effective words) took 0.2s, 380136 effective words/s\n",
      "2023-12-06 14:57:52,176 : INFO : EPOCH 2: training on 99524 raw words (62785 effective words) took 0.1s, 423523 effective words/s\n",
      "2023-12-06 14:57:52,335 : INFO : EPOCH 3: training on 99524 raw words (62576 effective words) took 0.2s, 405669 effective words/s\n",
      "2023-12-06 14:57:52,493 : INFO : EPOCH 4: training on 99524 raw words (62727 effective words) took 0.2s, 409345 effective words/s\n",
      "2023-12-06 14:57:52,651 : INFO : EPOCH 5: training on 99524 raw words (62695 effective words) took 0.2s, 412895 effective words/s\n",
      "2023-12-06 14:57:52,808 : INFO : EPOCH 6: training on 99524 raw words (62845 effective words) took 0.2s, 411678 effective words/s\n",
      "2023-12-06 14:57:52,964 : INFO : EPOCH 7: training on 99524 raw words (62573 effective words) took 0.2s, 414057 effective words/s\n",
      "2023-12-06 14:57:53,121 : INFO : EPOCH 8: training on 99524 raw words (62761 effective words) took 0.2s, 410806 effective words/s\n",
      "2023-12-06 14:57:53,282 : INFO : EPOCH 9: training on 99524 raw words (62702 effective words) took 0.2s, 402837 effective words/s\n",
      "2023-12-06 14:57:53,441 : INFO : EPOCH 10: training on 99524 raw words (62526 effective words) took 0.2s, 404638 effective words/s\n",
      "2023-12-06 14:57:53,597 : INFO : EPOCH 11: training on 99524 raw words (62883 effective words) took 0.2s, 415065 effective words/s\n",
      "2023-12-06 14:57:53,756 : INFO : EPOCH 12: training on 99524 raw words (62790 effective words) took 0.2s, 413954 effective words/s\n",
      "2023-12-06 14:57:53,911 : INFO : EPOCH 13: training on 99524 raw words (62663 effective words) took 0.2s, 415884 effective words/s\n",
      "2023-12-06 14:57:54,071 : INFO : EPOCH 14: training on 99524 raw words (62664 effective words) took 0.2s, 400335 effective words/s\n",
      "2023-12-06 14:57:54,227 : INFO : EPOCH 15: training on 99524 raw words (62707 effective words) took 0.2s, 415440 effective words/s\n",
      "2023-12-06 14:57:54,386 : INFO : EPOCH 16: training on 99524 raw words (62727 effective words) took 0.2s, 404147 effective words/s\n",
      "2023-12-06 14:57:54,542 : INFO : EPOCH 17: training on 99524 raw words (62628 effective words) took 0.2s, 414638 effective words/s\n",
      "2023-12-06 14:57:54,698 : INFO : EPOCH 18: training on 99524 raw words (62685 effective words) took 0.2s, 415804 effective words/s\n",
      "2023-12-06 14:57:54,854 : INFO : EPOCH 19: training on 99524 raw words (62751 effective words) took 0.2s, 413136 effective words/s\n",
      "2023-12-06 14:57:55,021 : INFO : EPOCH 20: training on 99524 raw words (62697 effective words) took 0.2s, 385025 effective words/s\n",
      "2023-12-06 14:57:55,191 : INFO : EPOCH 21: training on 99524 raw words (62792 effective words) took 0.2s, 383778 effective words/s\n",
      "2023-12-06 14:57:55,350 : INFO : EPOCH 22: training on 99524 raw words (62841 effective words) took 0.2s, 407970 effective words/s\n",
      "2023-12-06 14:57:55,522 : INFO : EPOCH 23: training on 99524 raw words (62986 effective words) took 0.2s, 377469 effective words/s\n",
      "2023-12-06 14:57:55,696 : INFO : EPOCH 24: training on 99524 raw words (62850 effective words) took 0.2s, 377272 effective words/s\n",
      "2023-12-06 14:57:55,857 : INFO : EPOCH 25: training on 99524 raw words (62644 effective words) took 0.2s, 398521 effective words/s\n",
      "2023-12-06 14:57:56,035 : INFO : EPOCH 26: training on 99524 raw words (62758 effective words) took 0.2s, 366250 effective words/s\n",
      "2023-12-06 14:57:56,208 : INFO : EPOCH 27: training on 99524 raw words (62997 effective words) took 0.2s, 377757 effective words/s\n",
      "2023-12-06 14:57:56,377 : INFO : EPOCH 28: training on 99524 raw words (62670 effective words) took 0.2s, 383367 effective words/s\n",
      "2023-12-06 14:57:56,532 : INFO : EPOCH 29: training on 99524 raw words (62892 effective words) took 0.1s, 420657 effective words/s\n",
      "2023-12-06 14:57:56,702 : INFO : EPOCH 30: training on 99524 raw words (62728 effective words) took 0.2s, 380997 effective words/s\n",
      "2023-12-06 14:57:56,878 : INFO : EPOCH 31: training on 99524 raw words (62787 effective words) took 0.2s, 370245 effective words/s\n",
      "2023-12-06 14:57:57,045 : INFO : EPOCH 32: training on 99524 raw words (62722 effective words) took 0.2s, 385697 effective words/s\n",
      "2023-12-06 14:57:57,200 : INFO : EPOCH 33: training on 99524 raw words (62966 effective words) took 0.2s, 418000 effective words/s\n",
      "2023-12-06 14:57:57,363 : INFO : EPOCH 34: training on 99524 raw words (62918 effective words) took 0.2s, 396518 effective words/s\n",
      "2023-12-06 14:57:57,533 : INFO : EPOCH 35: training on 99524 raw words (62923 effective words) took 0.2s, 382495 effective words/s\n",
      "2023-12-06 14:57:57,709 : INFO : EPOCH 36: training on 99524 raw words (62611 effective words) took 0.2s, 366831 effective words/s\n",
      "2023-12-06 14:57:57,875 : INFO : EPOCH 37: training on 99524 raw words (62721 effective words) took 0.2s, 390961 effective words/s\n",
      "2023-12-06 14:57:58,065 : INFO : EPOCH 38: training on 99524 raw words (62619 effective words) took 0.2s, 342079 effective words/s\n",
      "2023-12-06 14:57:58,223 : INFO : EPOCH 39: training on 99524 raw words (62777 effective words) took 0.2s, 409422 effective words/s\n",
      "2023-12-06 14:57:58,380 : INFO : EPOCH 40: training on 99524 raw words (62714 effective words) took 0.2s, 410605 effective words/s\n",
      "2023-12-06 14:57:58,551 : INFO : EPOCH 41: training on 99524 raw words (62902 effective words) took 0.2s, 378800 effective words/s\n",
      "2023-12-06 14:57:58,727 : INFO : EPOCH 42: training on 99524 raw words (62612 effective words) took 0.2s, 367404 effective words/s\n",
      "2023-12-06 14:57:58,895 : INFO : EPOCH 43: training on 99524 raw words (62824 effective words) took 0.2s, 385862 effective words/s\n",
      "2023-12-06 14:57:59,058 : INFO : EPOCH 44: training on 99524 raw words (62844 effective words) took 0.2s, 398418 effective words/s\n",
      "2023-12-06 14:57:59,210 : INFO : EPOCH 45: training on 99524 raw words (62686 effective words) took 0.1s, 424115 effective words/s\n",
      "2023-12-06 14:57:59,365 : INFO : EPOCH 46: training on 99524 raw words (62753 effective words) took 0.2s, 414181 effective words/s\n",
      "2023-12-06 14:57:59,524 : INFO : EPOCH 47: training on 99524 raw words (62642 effective words) took 0.2s, 407241 effective words/s\n",
      "2023-12-06 14:57:59,682 : INFO : EPOCH 48: training on 99524 raw words (62925 effective words) took 0.2s, 411658 effective words/s\n",
      "2023-12-06 14:57:59,839 : INFO : EPOCH 49: training on 99524 raw words (62671 effective words) took 0.2s, 409736 effective words/s\n",
      "2023-12-06 14:57:59,840 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3137568 effective words) took 8.1s, 385858 effective words/s', 'datetime': '2023-12-06T14:57:59.840501', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:57:59,841 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:57:59.841545', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 59%|    | 287/486 [44:22<31:05,  9.38s/it]2023-12-06 14:58:03,446 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:58:03,447 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:58:03,469 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:58:03,470 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:58:03,474 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T14:58:03.474507', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:58:03,475 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T14:58:03.475512', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:58:03,480 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:58:03,480 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:58:03,481 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T14:58:03.481511', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:58:03,489 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 14:58:03,490 : INFO : resetting layer weights\n",
      "2023-12-06 14:58:03,493 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:58:03.493508', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:58:03,642 : INFO : EPOCH 0: training on 99524 raw words (62638 effective words) took 0.1s, 433418 effective words/s\n",
      "2023-12-06 14:58:03,824 : INFO : EPOCH 1: training on 99524 raw words (62759 effective words) took 0.2s, 355112 effective words/s\n",
      "2023-12-06 14:58:03,980 : INFO : EPOCH 2: training on 99524 raw words (62875 effective words) took 0.2s, 415660 effective words/s\n",
      "2023-12-06 14:58:04,140 : INFO : EPOCH 3: training on 99524 raw words (62542 effective words) took 0.2s, 404922 effective words/s\n",
      "2023-12-06 14:58:04,291 : INFO : EPOCH 4: training on 99524 raw words (62694 effective words) took 0.1s, 428636 effective words/s\n",
      "2023-12-06 14:58:04,445 : INFO : EPOCH 5: training on 99524 raw words (62799 effective words) took 0.2s, 417320 effective words/s\n",
      "2023-12-06 14:58:04,601 : INFO : EPOCH 6: training on 99524 raw words (62763 effective words) took 0.2s, 413854 effective words/s\n",
      "2023-12-06 14:58:04,761 : INFO : EPOCH 7: training on 99524 raw words (62549 effective words) took 0.2s, 405398 effective words/s\n",
      "2023-12-06 14:58:04,920 : INFO : EPOCH 8: training on 99524 raw words (62806 effective words) took 0.2s, 406040 effective words/s\n",
      "2023-12-06 14:58:05,075 : INFO : EPOCH 9: training on 99524 raw words (62649 effective words) took 0.2s, 415874 effective words/s\n",
      "2023-12-06 14:58:05,234 : INFO : EPOCH 10: training on 99524 raw words (62709 effective words) took 0.2s, 408188 effective words/s\n",
      "2023-12-06 14:58:05,386 : INFO : EPOCH 11: training on 99524 raw words (62804 effective words) took 0.1s, 426097 effective words/s\n",
      "2023-12-06 14:58:05,541 : INFO : EPOCH 12: training on 99524 raw words (62633 effective words) took 0.2s, 415743 effective words/s\n",
      "2023-12-06 14:58:05,695 : INFO : EPOCH 13: training on 99524 raw words (62599 effective words) took 0.1s, 418832 effective words/s\n",
      "2023-12-06 14:58:05,859 : INFO : EPOCH 14: training on 99524 raw words (62779 effective words) took 0.2s, 396467 effective words/s\n",
      "2023-12-06 14:58:06,016 : INFO : EPOCH 15: training on 99524 raw words (62630 effective words) took 0.2s, 413005 effective words/s\n",
      "2023-12-06 14:58:06,174 : INFO : EPOCH 16: training on 99524 raw words (62720 effective words) took 0.2s, 407901 effective words/s\n",
      "2023-12-06 14:58:06,331 : INFO : EPOCH 17: training on 99524 raw words (62716 effective words) took 0.2s, 410532 effective words/s\n",
      "2023-12-06 14:58:06,487 : INFO : EPOCH 18: training on 99524 raw words (62617 effective words) took 0.2s, 413321 effective words/s\n",
      "2023-12-06 14:58:06,647 : INFO : EPOCH 19: training on 99524 raw words (62763 effective words) took 0.2s, 408791 effective words/s\n",
      "2023-12-06 14:58:06,806 : INFO : EPOCH 20: training on 99524 raw words (62704 effective words) took 0.2s, 404744 effective words/s\n",
      "2023-12-06 14:58:06,960 : INFO : EPOCH 21: training on 99524 raw words (62890 effective words) took 0.1s, 423529 effective words/s\n",
      "2023-12-06 14:58:07,112 : INFO : EPOCH 22: training on 99524 raw words (62773 effective words) took 0.1s, 424819 effective words/s\n",
      "2023-12-06 14:58:07,269 : INFO : EPOCH 23: training on 99524 raw words (62738 effective words) took 0.2s, 409749 effective words/s\n",
      "2023-12-06 14:58:07,426 : INFO : EPOCH 24: training on 99524 raw words (62923 effective words) took 0.2s, 414020 effective words/s\n",
      "2023-12-06 14:58:07,586 : INFO : EPOCH 25: training on 99524 raw words (62746 effective words) took 0.2s, 405377 effective words/s\n",
      "2023-12-06 14:58:07,741 : INFO : EPOCH 26: training on 99524 raw words (62834 effective words) took 0.2s, 415372 effective words/s\n",
      "2023-12-06 14:58:07,908 : INFO : EPOCH 27: training on 99524 raw words (62788 effective words) took 0.2s, 391556 effective words/s\n",
      "2023-12-06 14:58:08,067 : INFO : EPOCH 28: training on 99524 raw words (62647 effective words) took 0.2s, 405330 effective words/s\n",
      "2023-12-06 14:58:08,226 : INFO : EPOCH 29: training on 99524 raw words (62833 effective words) took 0.2s, 406714 effective words/s\n",
      "2023-12-06 14:58:08,377 : INFO : EPOCH 30: training on 99524 raw words (62703 effective words) took 0.1s, 430551 effective words/s\n",
      "2023-12-06 14:58:08,535 : INFO : EPOCH 31: training on 99524 raw words (62897 effective words) took 0.2s, 408981 effective words/s\n",
      "2023-12-06 14:58:08,691 : INFO : EPOCH 32: training on 99524 raw words (62716 effective words) took 0.2s, 412282 effective words/s\n",
      "2023-12-06 14:58:08,847 : INFO : EPOCH 33: training on 99524 raw words (62728 effective words) took 0.2s, 415353 effective words/s\n",
      "2023-12-06 14:58:08,997 : INFO : EPOCH 34: training on 99524 raw words (62807 effective words) took 0.1s, 433690 effective words/s\n",
      "2023-12-06 14:58:09,158 : INFO : EPOCH 35: training on 99524 raw words (63005 effective words) took 0.2s, 402244 effective words/s\n",
      "2023-12-06 14:58:09,328 : INFO : EPOCH 36: training on 99524 raw words (62722 effective words) took 0.2s, 377987 effective words/s\n",
      "2023-12-06 14:58:09,492 : INFO : EPOCH 37: training on 99524 raw words (62548 effective words) took 0.2s, 398073 effective words/s\n",
      "2023-12-06 14:58:09,656 : INFO : EPOCH 38: training on 99524 raw words (62755 effective words) took 0.2s, 394518 effective words/s\n",
      "2023-12-06 14:58:09,813 : INFO : EPOCH 39: training on 99524 raw words (62594 effective words) took 0.2s, 410522 effective words/s\n",
      "2023-12-06 14:58:09,975 : INFO : EPOCH 40: training on 99524 raw words (62732 effective words) took 0.2s, 399420 effective words/s\n",
      "2023-12-06 14:58:10,137 : INFO : EPOCH 41: training on 99524 raw words (62853 effective words) took 0.2s, 398869 effective words/s\n",
      "2023-12-06 14:58:10,294 : INFO : EPOCH 42: training on 99524 raw words (62822 effective words) took 0.2s, 412623 effective words/s\n",
      "2023-12-06 14:58:10,456 : INFO : EPOCH 43: training on 99524 raw words (62667 effective words) took 0.2s, 398399 effective words/s\n",
      "2023-12-06 14:58:10,615 : INFO : EPOCH 44: training on 99524 raw words (62763 effective words) took 0.2s, 406030 effective words/s\n",
      "2023-12-06 14:58:10,773 : INFO : EPOCH 45: training on 99524 raw words (62753 effective words) took 0.2s, 411316 effective words/s\n",
      "2023-12-06 14:58:10,930 : INFO : EPOCH 46: training on 99524 raw words (62804 effective words) took 0.2s, 410686 effective words/s\n",
      "2023-12-06 14:58:11,094 : INFO : EPOCH 47: training on 99524 raw words (62645 effective words) took 0.2s, 393135 effective words/s\n",
      "2023-12-06 14:58:11,251 : INFO : EPOCH 48: training on 99524 raw words (62781 effective words) took 0.2s, 412363 effective words/s\n",
      "2023-12-06 14:58:11,405 : INFO : EPOCH 49: training on 99524 raw words (62767 effective words) took 0.1s, 419148 effective words/s\n",
      "2023-12-06 14:58:11,406 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136982 effective words) took 7.9s, 396439 effective words/s', 'datetime': '2023-12-06T14:58:11.406916', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:58:11,406 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T14:58:11.406916', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 59%|    | 288/486 [44:33<33:18, 10.09s/it]2023-12-06 14:58:15,216 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:58:15,216 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:58:15,243 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:58:15,243 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:58:15,249 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:58:15.249623', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:58:15,250 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:58:15.250623', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:58:15,257 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:58:15,257 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:58:15,258 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:58:15.257153', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:58:15,265 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:58:15,266 : INFO : resetting layer weights\n",
      "2023-12-06 14:58:15,268 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:58:15.268666', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:58:15,406 : INFO : EPOCH 0: training on 99524 raw words (60361 effective words) took 0.1s, 451112 effective words/s\n",
      "2023-12-06 14:58:15,575 : INFO : EPOCH 1: training on 99524 raw words (60540 effective words) took 0.2s, 367644 effective words/s\n",
      "2023-12-06 14:58:15,734 : INFO : EPOCH 2: training on 99524 raw words (60424 effective words) took 0.2s, 396456 effective words/s\n",
      "2023-12-06 14:58:15,880 : INFO : EPOCH 3: training on 99524 raw words (60356 effective words) took 0.1s, 425210 effective words/s\n",
      "2023-12-06 14:58:16,038 : INFO : EPOCH 4: training on 99524 raw words (60466 effective words) took 0.2s, 396856 effective words/s\n",
      "2023-12-06 14:58:16,189 : INFO : EPOCH 5: training on 99524 raw words (60371 effective words) took 0.1s, 412775 effective words/s\n",
      "2023-12-06 14:58:16,334 : INFO : EPOCH 6: training on 99524 raw words (60454 effective words) took 0.1s, 428364 effective words/s\n",
      "2023-12-06 14:58:16,481 : INFO : EPOCH 7: training on 99524 raw words (60352 effective words) took 0.1s, 424565 effective words/s\n",
      "2023-12-06 14:58:16,635 : INFO : EPOCH 8: training on 99524 raw words (60409 effective words) took 0.1s, 406931 effective words/s\n",
      "2023-12-06 14:58:16,784 : INFO : EPOCH 9: training on 99524 raw words (60464 effective words) took 0.1s, 416669 effective words/s\n",
      "2023-12-06 14:58:16,785 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604197 effective words) took 1.5s, 398239 effective words/s', 'datetime': '2023-12-06T14:58:16.785864', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:58:16,787 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:58:16.787128', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 59%|    | 289/486 [44:38<27:27,  8.36s/it]2023-12-06 14:58:19,547 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:58:19,548 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:58:19,574 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:58:19,575 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:58:19,581 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:58:19.581074', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:58:19,582 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:58:19.582080', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:58:19,589 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:58:19,590 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:58:19,590 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:58:19.590601', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:58:19,598 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:58:19,599 : INFO : resetting layer weights\n",
      "2023-12-06 14:58:19,602 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:58:19.602582', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:58:19,745 : INFO : EPOCH 0: training on 99524 raw words (60286 effective words) took 0.1s, 434873 effective words/s\n",
      "2023-12-06 14:58:19,923 : INFO : EPOCH 1: training on 99524 raw words (60459 effective words) took 0.2s, 353532 effective words/s\n",
      "2023-12-06 14:58:20,082 : INFO : EPOCH 2: training on 99524 raw words (60475 effective words) took 0.2s, 397386 effective words/s\n",
      "2023-12-06 14:58:20,241 : INFO : EPOCH 3: training on 99524 raw words (60211 effective words) took 0.2s, 390773 effective words/s\n",
      "2023-12-06 14:58:20,396 : INFO : EPOCH 4: training on 99524 raw words (60508 effective words) took 0.2s, 401592 effective words/s\n",
      "2023-12-06 14:58:20,553 : INFO : EPOCH 5: training on 99524 raw words (60449 effective words) took 0.2s, 397945 effective words/s\n",
      "2023-12-06 14:58:20,709 : INFO : EPOCH 6: training on 99524 raw words (60437 effective words) took 0.2s, 400939 effective words/s\n",
      "2023-12-06 14:58:20,866 : INFO : EPOCH 7: training on 99524 raw words (60448 effective words) took 0.2s, 394348 effective words/s\n",
      "2023-12-06 14:58:21,023 : INFO : EPOCH 8: training on 99524 raw words (60405 effective words) took 0.2s, 399141 effective words/s\n",
      "2023-12-06 14:58:21,179 : INFO : EPOCH 9: training on 99524 raw words (60394 effective words) took 0.2s, 397317 effective words/s\n",
      "2023-12-06 14:58:21,181 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604072 effective words) took 1.6s, 382902 effective words/s', 'datetime': '2023-12-06T14:58:21.181332', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:58:21,181 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:58:21.181332', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 60%|    | 290/486 [44:42<23:20,  7.15s/it]2023-12-06 14:58:23,846 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:58:23,847 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:58:23,869 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:58:23,870 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:58:23,876 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:58:23.876488', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:58:23,877 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:58:23.877488', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:58:23,881 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:58:23,882 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:58:23,882 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:58:23.882488', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:58:23,889 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:58:23,890 : INFO : resetting layer weights\n",
      "2023-12-06 14:58:23,895 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:58:23.893936', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:58:24,038 : INFO : EPOCH 0: training on 99524 raw words (60343 effective words) took 0.1s, 432757 effective words/s\n",
      "2023-12-06 14:58:24,209 : INFO : EPOCH 1: training on 99524 raw words (60334 effective words) took 0.2s, 364394 effective words/s\n",
      "2023-12-06 14:58:24,361 : INFO : EPOCH 2: training on 99524 raw words (60618 effective words) took 0.1s, 409579 effective words/s\n",
      "2023-12-06 14:58:24,512 : INFO : EPOCH 3: training on 99524 raw words (60362 effective words) took 0.1s, 414002 effective words/s\n",
      "2023-12-06 14:58:24,666 : INFO : EPOCH 4: training on 99524 raw words (60467 effective words) took 0.1s, 404434 effective words/s\n",
      "2023-12-06 14:58:24,819 : INFO : EPOCH 5: training on 99524 raw words (60524 effective words) took 0.1s, 406941 effective words/s\n",
      "2023-12-06 14:58:24,974 : INFO : EPOCH 6: training on 99524 raw words (60281 effective words) took 0.2s, 400928 effective words/s\n",
      "2023-12-06 14:58:25,124 : INFO : EPOCH 7: training on 99524 raw words (60392 effective words) took 0.1s, 415500 effective words/s\n",
      "2023-12-06 14:58:25,276 : INFO : EPOCH 8: training on 99524 raw words (60368 effective words) took 0.1s, 408448 effective words/s\n",
      "2023-12-06 14:58:25,425 : INFO : EPOCH 9: training on 99524 raw words (60433 effective words) took 0.1s, 417797 effective words/s\n",
      "2023-12-06 14:58:25,426 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604122 effective words) took 1.5s, 394443 effective words/s', 'datetime': '2023-12-06T14:58:25.426872', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:58:25,427 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:58:25.427872', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 60%|    | 291/486 [44:46<20:24,  6.28s/it]2023-12-06 14:58:28,099 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:58:28,100 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:58:28,120 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:58:28,121 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:58:28,125 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:58:28.125684', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:58:28,127 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:58:28.127192', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:58:28,133 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:58:28,134 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:58:28,135 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:58:28.135363', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:58:28,142 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:58:28,143 : INFO : resetting layer weights\n",
      "2023-12-06 14:58:28,146 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:58:28.146331', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:58:28,288 : INFO : EPOCH 0: training on 99524 raw words (60412 effective words) took 0.1s, 434719 effective words/s\n",
      "2023-12-06 14:58:28,455 : INFO : EPOCH 1: training on 99524 raw words (60440 effective words) took 0.2s, 377512 effective words/s\n",
      "2023-12-06 14:58:28,603 : INFO : EPOCH 2: training on 99524 raw words (60428 effective words) took 0.1s, 424268 effective words/s\n",
      "2023-12-06 14:58:28,747 : INFO : EPOCH 3: training on 99524 raw words (60356 effective words) took 0.1s, 427788 effective words/s\n",
      "2023-12-06 14:58:28,898 : INFO : EPOCH 4: training on 99524 raw words (60256 effective words) took 0.1s, 414704 effective words/s\n",
      "2023-12-06 14:58:29,041 : INFO : EPOCH 5: training on 99524 raw words (60473 effective words) took 0.1s, 433844 effective words/s\n",
      "2023-12-06 14:58:29,189 : INFO : EPOCH 6: training on 99524 raw words (60274 effective words) took 0.1s, 421577 effective words/s\n",
      "2023-12-06 14:58:29,338 : INFO : EPOCH 7: training on 99524 raw words (60496 effective words) took 0.1s, 419641 effective words/s\n",
      "2023-12-06 14:58:29,495 : INFO : EPOCH 8: training on 99524 raw words (60505 effective words) took 0.2s, 397640 effective words/s\n",
      "2023-12-06 14:58:29,645 : INFO : EPOCH 9: training on 99524 raw words (60493 effective words) took 0.1s, 414912 effective words/s\n",
      "2023-12-06 14:58:29,807 : INFO : EPOCH 10: training on 99524 raw words (60283 effective words) took 0.2s, 383665 effective words/s\n",
      "2023-12-06 14:58:29,968 : INFO : EPOCH 11: training on 99524 raw words (60578 effective words) took 0.2s, 385106 effective words/s\n",
      "2023-12-06 14:58:30,120 : INFO : EPOCH 12: training on 99524 raw words (60412 effective words) took 0.1s, 410372 effective words/s\n",
      "2023-12-06 14:58:30,276 : INFO : EPOCH 13: training on 99524 raw words (60436 effective words) took 0.2s, 401484 effective words/s\n",
      "2023-12-06 14:58:30,423 : INFO : EPOCH 14: training on 99524 raw words (60519 effective words) took 0.1s, 423073 effective words/s\n",
      "2023-12-06 14:58:30,574 : INFO : EPOCH 15: training on 99524 raw words (60286 effective words) took 0.1s, 414684 effective words/s\n",
      "2023-12-06 14:58:30,725 : INFO : EPOCH 16: training on 99524 raw words (60322 effective words) took 0.1s, 410271 effective words/s\n",
      "2023-12-06 14:58:30,884 : INFO : EPOCH 17: training on 99524 raw words (60364 effective words) took 0.2s, 390128 effective words/s\n",
      "2023-12-06 14:58:31,031 : INFO : EPOCH 18: training on 99524 raw words (60343 effective words) took 0.1s, 423067 effective words/s\n",
      "2023-12-06 14:58:31,176 : INFO : EPOCH 19: training on 99524 raw words (60499 effective words) took 0.1s, 433813 effective words/s\n",
      "2023-12-06 14:58:31,325 : INFO : EPOCH 20: training on 99524 raw words (60198 effective words) took 0.1s, 415433 effective words/s\n",
      "2023-12-06 14:58:31,467 : INFO : EPOCH 21: training on 99524 raw words (60402 effective words) took 0.1s, 440700 effective words/s\n",
      "2023-12-06 14:58:31,612 : INFO : EPOCH 22: training on 99524 raw words (60575 effective words) took 0.1s, 428759 effective words/s\n",
      "2023-12-06 14:58:31,761 : INFO : EPOCH 23: training on 99524 raw words (60509 effective words) took 0.1s, 419689 effective words/s\n",
      "2023-12-06 14:58:31,909 : INFO : EPOCH 24: training on 99524 raw words (60433 effective words) took 0.1s, 421919 effective words/s\n",
      "2023-12-06 14:58:32,059 : INFO : EPOCH 25: training on 99524 raw words (60292 effective words) took 0.1s, 414670 effective words/s\n",
      "2023-12-06 14:58:32,218 : INFO : EPOCH 26: training on 99524 raw words (60453 effective words) took 0.2s, 391931 effective words/s\n",
      "2023-12-06 14:58:32,366 : INFO : EPOCH 27: training on 99524 raw words (60535 effective words) took 0.1s, 422800 effective words/s\n",
      "2023-12-06 14:58:32,514 : INFO : EPOCH 28: training on 99524 raw words (60391 effective words) took 0.1s, 418573 effective words/s\n",
      "2023-12-06 14:58:32,663 : INFO : EPOCH 29: training on 99524 raw words (60550 effective words) took 0.1s, 420665 effective words/s\n",
      "2023-12-06 14:58:32,664 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812513 effective words) took 4.5s, 401195 effective words/s', 'datetime': '2023-12-06T14:58:32.664270', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:58:32,665 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:58:32.665271', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 60%|    | 292/486 [44:54<21:27,  6.64s/it]2023-12-06 14:58:35,572 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:58:35,573 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:58:35,593 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:58:35,594 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:58:35,601 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:58:35.601500', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:58:35,602 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:58:35.602500', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:58:35,606 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:58:35,607 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:58:35,607 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:58:35.607500', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:58:35,615 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:58:35,615 : INFO : resetting layer weights\n",
      "2023-12-06 14:58:35,618 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:58:35.618188', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:58:35,769 : INFO : EPOCH 0: training on 99524 raw words (60497 effective words) took 0.1s, 412047 effective words/s\n",
      "2023-12-06 14:58:35,946 : INFO : EPOCH 1: training on 99524 raw words (60332 effective words) took 0.2s, 354499 effective words/s\n",
      "2023-12-06 14:58:36,103 : INFO : EPOCH 2: training on 99524 raw words (60409 effective words) took 0.2s, 396177 effective words/s\n",
      "2023-12-06 14:58:36,253 : INFO : EPOCH 3: training on 99524 raw words (60392 effective words) took 0.1s, 414803 effective words/s\n",
      "2023-12-06 14:58:36,405 : INFO : EPOCH 4: training on 99524 raw words (60438 effective words) took 0.1s, 409087 effective words/s\n",
      "2023-12-06 14:58:36,558 : INFO : EPOCH 5: training on 99524 raw words (60315 effective words) took 0.1s, 406741 effective words/s\n",
      "2023-12-06 14:58:36,711 : INFO : EPOCH 6: training on 99524 raw words (60369 effective words) took 0.1s, 406528 effective words/s\n",
      "2023-12-06 14:58:36,860 : INFO : EPOCH 7: training on 99524 raw words (60355 effective words) took 0.1s, 414348 effective words/s\n",
      "2023-12-06 14:58:37,016 : INFO : EPOCH 8: training on 99524 raw words (60661 effective words) took 0.1s, 404903 effective words/s\n",
      "2023-12-06 14:58:37,170 : INFO : EPOCH 9: training on 99524 raw words (60400 effective words) took 0.2s, 401330 effective words/s\n",
      "2023-12-06 14:58:37,333 : INFO : EPOCH 10: training on 99524 raw words (60353 effective words) took 0.2s, 380906 effective words/s\n",
      "2023-12-06 14:58:37,489 : INFO : EPOCH 11: training on 99524 raw words (60574 effective words) took 0.2s, 400314 effective words/s\n",
      "2023-12-06 14:58:37,644 : INFO : EPOCH 12: training on 99524 raw words (60424 effective words) took 0.2s, 398645 effective words/s\n",
      "2023-12-06 14:58:37,799 : INFO : EPOCH 13: training on 99524 raw words (60435 effective words) took 0.2s, 401985 effective words/s\n",
      "2023-12-06 14:58:37,950 : INFO : EPOCH 14: training on 99524 raw words (60386 effective words) took 0.1s, 412586 effective words/s\n",
      "2023-12-06 14:58:38,105 : INFO : EPOCH 15: training on 99524 raw words (60494 effective words) took 0.1s, 403639 effective words/s\n",
      "2023-12-06 14:58:38,256 : INFO : EPOCH 16: training on 99524 raw words (60463 effective words) took 0.1s, 413895 effective words/s\n",
      "2023-12-06 14:58:38,411 : INFO : EPOCH 17: training on 99524 raw words (60281 effective words) took 0.2s, 400932 effective words/s\n",
      "2023-12-06 14:58:38,565 : INFO : EPOCH 18: training on 99524 raw words (60345 effective words) took 0.1s, 402737 effective words/s\n",
      "2023-12-06 14:58:38,729 : INFO : EPOCH 19: training on 99524 raw words (60454 effective words) took 0.2s, 379528 effective words/s\n",
      "2023-12-06 14:58:38,884 : INFO : EPOCH 20: training on 99524 raw words (60453 effective words) took 0.1s, 403959 effective words/s\n",
      "2023-12-06 14:58:39,041 : INFO : EPOCH 21: training on 99524 raw words (60365 effective words) took 0.2s, 397941 effective words/s\n",
      "2023-12-06 14:58:39,196 : INFO : EPOCH 22: training on 99524 raw words (60464 effective words) took 0.2s, 400497 effective words/s\n",
      "2023-12-06 14:58:39,351 : INFO : EPOCH 23: training on 99524 raw words (60344 effective words) took 0.2s, 399220 effective words/s\n",
      "2023-12-06 14:58:39,507 : INFO : EPOCH 24: training on 99524 raw words (60369 effective words) took 0.2s, 396974 effective words/s\n",
      "2023-12-06 14:58:39,661 : INFO : EPOCH 25: training on 99524 raw words (60343 effective words) took 0.1s, 406266 effective words/s\n",
      "2023-12-06 14:58:39,814 : INFO : EPOCH 26: training on 99524 raw words (60594 effective words) took 0.1s, 406828 effective words/s\n",
      "2023-12-06 14:58:39,973 : INFO : EPOCH 27: training on 99524 raw words (60556 effective words) took 0.2s, 390873 effective words/s\n",
      "2023-12-06 14:58:40,136 : INFO : EPOCH 28: training on 99524 raw words (60472 effective words) took 0.2s, 385354 effective words/s\n",
      "2023-12-06 14:58:40,292 : INFO : EPOCH 29: training on 99524 raw words (60415 effective words) took 0.2s, 394479 effective words/s\n",
      "2023-12-06 14:58:40,293 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812752 effective words) took 4.7s, 387689 effective words/s', 'datetime': '2023-12-06T14:58:40.293960', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:58:40,294 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:58:40.294960', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 60%|    | 293/486 [45:02<22:30,  7.00s/it]2023-12-06 14:58:43,408 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:58:43,409 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:58:43,430 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:58:43,431 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:58:43,435 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:58:43.435791', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:58:43,436 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:58:43.436791', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:58:43,441 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:58:43,442 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:58:43,442 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:58:43.442430', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:58:43,450 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:58:43,450 : INFO : resetting layer weights\n",
      "2023-12-06 14:58:43,452 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:58:43.452959', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:58:43,605 : INFO : EPOCH 0: training on 99524 raw words (60315 effective words) took 0.1s, 407352 effective words/s\n",
      "2023-12-06 14:58:43,774 : INFO : EPOCH 1: training on 99524 raw words (60384 effective words) took 0.2s, 368512 effective words/s\n",
      "2023-12-06 14:58:43,930 : INFO : EPOCH 2: training on 99524 raw words (60490 effective words) took 0.2s, 400985 effective words/s\n",
      "2023-12-06 14:58:44,113 : INFO : EPOCH 3: training on 99524 raw words (60248 effective words) took 0.2s, 337196 effective words/s\n",
      "2023-12-06 14:58:44,275 : INFO : EPOCH 4: training on 99524 raw words (60622 effective words) took 0.2s, 387637 effective words/s\n",
      "2023-12-06 14:58:44,431 : INFO : EPOCH 5: training on 99524 raw words (60327 effective words) took 0.2s, 397932 effective words/s\n",
      "2023-12-06 14:58:44,587 : INFO : EPOCH 6: training on 99524 raw words (60277 effective words) took 0.2s, 398729 effective words/s\n",
      "2023-12-06 14:58:44,741 : INFO : EPOCH 7: training on 99524 raw words (60505 effective words) took 0.1s, 405621 effective words/s\n",
      "2023-12-06 14:58:44,894 : INFO : EPOCH 8: training on 99524 raw words (60555 effective words) took 0.1s, 407633 effective words/s\n",
      "2023-12-06 14:58:45,050 : INFO : EPOCH 9: training on 99524 raw words (60302 effective words) took 0.2s, 394544 effective words/s\n",
      "2023-12-06 14:58:45,206 : INFO : EPOCH 10: training on 99524 raw words (60261 effective words) took 0.2s, 400468 effective words/s\n",
      "2023-12-06 14:58:45,356 : INFO : EPOCH 11: training on 99524 raw words (60627 effective words) took 0.1s, 417771 effective words/s\n",
      "2023-12-06 14:58:45,509 : INFO : EPOCH 12: training on 99524 raw words (60506 effective words) took 0.1s, 405195 effective words/s\n",
      "2023-12-06 14:58:45,658 : INFO : EPOCH 13: training on 99524 raw words (60460 effective words) took 0.1s, 418631 effective words/s\n",
      "2023-12-06 14:58:45,813 : INFO : EPOCH 14: training on 99524 raw words (60567 effective words) took 0.1s, 404544 effective words/s\n",
      "2023-12-06 14:58:45,965 : INFO : EPOCH 15: training on 99524 raw words (60285 effective words) took 0.1s, 408796 effective words/s\n",
      "2023-12-06 14:58:46,117 : INFO : EPOCH 16: training on 99524 raw words (60333 effective words) took 0.1s, 407302 effective words/s\n",
      "2023-12-06 14:58:46,283 : INFO : EPOCH 17: training on 99524 raw words (60382 effective words) took 0.2s, 375305 effective words/s\n",
      "2023-12-06 14:58:46,438 : INFO : EPOCH 18: training on 99524 raw words (60370 effective words) took 0.2s, 402344 effective words/s\n",
      "2023-12-06 14:58:46,594 : INFO : EPOCH 19: training on 99524 raw words (60513 effective words) took 0.2s, 397910 effective words/s\n",
      "2023-12-06 14:58:46,749 : INFO : EPOCH 20: training on 99524 raw words (60343 effective words) took 0.1s, 403904 effective words/s\n",
      "2023-12-06 14:58:46,903 : INFO : EPOCH 21: training on 99524 raw words (60364 effective words) took 0.1s, 403602 effective words/s\n",
      "2023-12-06 14:58:47,056 : INFO : EPOCH 22: training on 99524 raw words (60575 effective words) took 0.1s, 408619 effective words/s\n",
      "2023-12-06 14:58:47,211 : INFO : EPOCH 23: training on 99524 raw words (60314 effective words) took 0.2s, 401130 effective words/s\n",
      "2023-12-06 14:58:47,363 : INFO : EPOCH 24: training on 99524 raw words (60544 effective words) took 0.1s, 411188 effective words/s\n",
      "2023-12-06 14:58:47,516 : INFO : EPOCH 25: training on 99524 raw words (60278 effective words) took 0.1s, 403899 effective words/s\n",
      "2023-12-06 14:58:47,677 : INFO : EPOCH 26: training on 99524 raw words (60410 effective words) took 0.2s, 386837 effective words/s\n",
      "2023-12-06 14:58:47,826 : INFO : EPOCH 27: training on 99524 raw words (60477 effective words) took 0.1s, 419192 effective words/s\n",
      "2023-12-06 14:58:47,983 : INFO : EPOCH 28: training on 99524 raw words (60606 effective words) took 0.2s, 397212 effective words/s\n",
      "2023-12-06 14:58:48,134 : INFO : EPOCH 29: training on 99524 raw words (60366 effective words) took 0.1s, 412741 effective words/s\n",
      "2023-12-06 14:58:48,135 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812606 effective words) took 4.7s, 387135 effective words/s', 'datetime': '2023-12-06T14:58:48.135329', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:58:48,136 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:58:48.136350', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 60%|    | 294/486 [45:09<23:15,  7.27s/it]2023-12-06 14:58:51,316 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:58:51,316 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:58:51,338 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:58:51,339 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:58:51,344 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:58:51.344185', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:58:51,345 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:58:51.345185', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:58:51,351 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:58:51,352 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:58:51,353 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:58:51.353185', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:58:51,360 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:58:51,360 : INFO : resetting layer weights\n",
      "2023-12-06 14:58:51,362 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:58:51.362185', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:58:51,507 : INFO : EPOCH 0: training on 99524 raw words (60373 effective words) took 0.1s, 425013 effective words/s\n",
      "2023-12-06 14:58:51,671 : INFO : EPOCH 1: training on 99524 raw words (60543 effective words) took 0.2s, 383225 effective words/s\n",
      "2023-12-06 14:58:51,823 : INFO : EPOCH 2: training on 99524 raw words (60375 effective words) took 0.1s, 412027 effective words/s\n",
      "2023-12-06 14:58:51,966 : INFO : EPOCH 3: training on 99524 raw words (60330 effective words) took 0.1s, 434730 effective words/s\n",
      "2023-12-06 14:58:52,113 : INFO : EPOCH 4: training on 99524 raw words (60274 effective words) took 0.1s, 424189 effective words/s\n",
      "2023-12-06 14:58:52,262 : INFO : EPOCH 5: training on 99524 raw words (60354 effective words) took 0.1s, 416850 effective words/s\n",
      "2023-12-06 14:58:52,411 : INFO : EPOCH 6: training on 99524 raw words (60241 effective words) took 0.1s, 420587 effective words/s\n",
      "2023-12-06 14:58:52,558 : INFO : EPOCH 7: training on 99524 raw words (60524 effective words) took 0.1s, 422285 effective words/s\n",
      "2023-12-06 14:58:52,707 : INFO : EPOCH 8: training on 99524 raw words (60426 effective words) took 0.1s, 417687 effective words/s\n",
      "2023-12-06 14:58:52,865 : INFO : EPOCH 9: training on 99524 raw words (60338 effective words) took 0.2s, 391679 effective words/s\n",
      "2023-12-06 14:58:53,009 : INFO : EPOCH 10: training on 99524 raw words (60443 effective words) took 0.1s, 434612 effective words/s\n",
      "2023-12-06 14:58:53,156 : INFO : EPOCH 11: training on 99524 raw words (60464 effective words) took 0.1s, 424022 effective words/s\n",
      "2023-12-06 14:58:53,299 : INFO : EPOCH 12: training on 99524 raw words (60356 effective words) took 0.1s, 435979 effective words/s\n",
      "2023-12-06 14:58:53,448 : INFO : EPOCH 13: training on 99524 raw words (60358 effective words) took 0.1s, 417484 effective words/s\n",
      "2023-12-06 14:58:53,592 : INFO : EPOCH 14: training on 99524 raw words (60398 effective words) took 0.1s, 435301 effective words/s\n",
      "2023-12-06 14:58:53,739 : INFO : EPOCH 15: training on 99524 raw words (60377 effective words) took 0.1s, 422945 effective words/s\n",
      "2023-12-06 14:58:53,881 : INFO : EPOCH 16: training on 99524 raw words (60486 effective words) took 0.1s, 439690 effective words/s\n",
      "2023-12-06 14:58:54,028 : INFO : EPOCH 17: training on 99524 raw words (60412 effective words) took 0.1s, 425846 effective words/s\n",
      "2023-12-06 14:58:54,187 : INFO : EPOCH 18: training on 99524 raw words (60339 effective words) took 0.2s, 389475 effective words/s\n",
      "2023-12-06 14:58:54,334 : INFO : EPOCH 19: training on 99524 raw words (60458 effective words) took 0.1s, 426532 effective words/s\n",
      "2023-12-06 14:58:54,481 : INFO : EPOCH 20: training on 99524 raw words (60343 effective words) took 0.1s, 422181 effective words/s\n",
      "2023-12-06 14:58:54,624 : INFO : EPOCH 21: training on 99524 raw words (60652 effective words) took 0.1s, 436598 effective words/s\n",
      "2023-12-06 14:58:54,772 : INFO : EPOCH 22: training on 99524 raw words (60463 effective words) took 0.1s, 422358 effective words/s\n",
      "2023-12-06 14:58:54,921 : INFO : EPOCH 23: training on 99524 raw words (60469 effective words) took 0.1s, 419727 effective words/s\n",
      "2023-12-06 14:58:55,064 : INFO : EPOCH 24: training on 99524 raw words (60468 effective words) took 0.1s, 436479 effective words/s\n",
      "2023-12-06 14:58:55,212 : INFO : EPOCH 25: training on 99524 raw words (60424 effective words) took 0.1s, 418831 effective words/s\n",
      "2023-12-06 14:58:55,356 : INFO : EPOCH 26: training on 99524 raw words (60492 effective words) took 0.1s, 434190 effective words/s\n",
      "2023-12-06 14:58:55,515 : INFO : EPOCH 27: training on 99524 raw words (60539 effective words) took 0.2s, 392704 effective words/s\n",
      "2023-12-06 14:58:55,658 : INFO : EPOCH 28: training on 99524 raw words (60326 effective words) took 0.1s, 434631 effective words/s\n",
      "2023-12-06 14:58:55,808 : INFO : EPOCH 29: training on 99524 raw words (60481 effective words) took 0.1s, 416879 effective words/s\n",
      "2023-12-06 14:58:55,952 : INFO : EPOCH 30: training on 99524 raw words (60477 effective words) took 0.1s, 437865 effective words/s\n",
      "2023-12-06 14:58:56,101 : INFO : EPOCH 31: training on 99524 raw words (60391 effective words) took 0.1s, 416691 effective words/s\n",
      "2023-12-06 14:58:56,248 : INFO : EPOCH 32: training on 99524 raw words (60346 effective words) took 0.1s, 421678 effective words/s\n",
      "2023-12-06 14:58:56,404 : INFO : EPOCH 33: training on 99524 raw words (60491 effective words) took 0.2s, 400889 effective words/s\n",
      "2023-12-06 14:58:56,557 : INFO : EPOCH 34: training on 99524 raw words (60374 effective words) took 0.1s, 406999 effective words/s\n",
      "2023-12-06 14:58:56,706 : INFO : EPOCH 35: training on 99524 raw words (60614 effective words) took 0.1s, 420630 effective words/s\n",
      "2023-12-06 14:58:56,856 : INFO : EPOCH 36: training on 99524 raw words (60357 effective words) took 0.1s, 414269 effective words/s\n",
      "2023-12-06 14:58:57,000 : INFO : EPOCH 37: training on 99524 raw words (60309 effective words) took 0.1s, 432349 effective words/s\n",
      "2023-12-06 14:58:57,147 : INFO : EPOCH 38: training on 99524 raw words (60334 effective words) took 0.1s, 423176 effective words/s\n",
      "2023-12-06 14:58:57,295 : INFO : EPOCH 39: training on 99524 raw words (60346 effective words) took 0.1s, 421173 effective words/s\n",
      "2023-12-06 14:58:57,440 : INFO : EPOCH 40: training on 99524 raw words (60409 effective words) took 0.1s, 429583 effective words/s\n",
      "2023-12-06 14:58:57,602 : INFO : EPOCH 41: training on 99524 raw words (60599 effective words) took 0.2s, 387042 effective words/s\n",
      "2023-12-06 14:58:57,750 : INFO : EPOCH 42: training on 99524 raw words (60471 effective words) took 0.1s, 418192 effective words/s\n",
      "2023-12-06 14:58:57,902 : INFO : EPOCH 43: training on 99524 raw words (60455 effective words) took 0.1s, 410986 effective words/s\n",
      "2023-12-06 14:58:58,045 : INFO : EPOCH 44: training on 99524 raw words (60336 effective words) took 0.1s, 436078 effective words/s\n",
      "2023-12-06 14:58:58,195 : INFO : EPOCH 45: training on 99524 raw words (60398 effective words) took 0.1s, 415046 effective words/s\n",
      "2023-12-06 14:58:58,344 : INFO : EPOCH 46: training on 99524 raw words (60509 effective words) took 0.1s, 417994 effective words/s\n",
      "2023-12-06 14:58:58,490 : INFO : EPOCH 47: training on 99524 raw words (60384 effective words) took 0.1s, 427199 effective words/s\n",
      "2023-12-06 14:58:58,644 : INFO : EPOCH 48: training on 99524 raw words (60476 effective words) took 0.1s, 404587 effective words/s\n",
      "2023-12-06 14:58:58,798 : INFO : EPOCH 49: training on 99524 raw words (60443 effective words) took 0.1s, 406347 effective words/s\n",
      "2023-12-06 14:58:58,799 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3021045 effective words) took 7.4s, 406270 effective words/s', 'datetime': '2023-12-06T14:58:58.799262', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:58:58,799 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:58:58.799262', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 61%|    | 295/486 [45:20<26:32,  8.34s/it]2023-12-06 14:59:02,146 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:59:02,147 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:59:02,169 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:59:02,170 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:59:02,175 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:59:02.175664', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:59:02,176 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:59:02.176668', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:59:02,182 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:59:02,183 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:59:02,184 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:59:02.184671', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:59:02,191 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:59:02,192 : INFO : resetting layer weights\n",
      "2023-12-06 14:59:02,194 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:59:02.194669', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:59:02,331 : INFO : EPOCH 0: training on 99524 raw words (60359 effective words) took 0.1s, 450769 effective words/s\n",
      "2023-12-06 14:59:02,509 : INFO : EPOCH 1: training on 99524 raw words (60458 effective words) took 0.2s, 349395 effective words/s\n",
      "2023-12-06 14:59:02,673 : INFO : EPOCH 2: training on 99524 raw words (60439 effective words) took 0.2s, 386270 effective words/s\n",
      "2023-12-06 14:59:02,826 : INFO : EPOCH 3: training on 99524 raw words (60314 effective words) took 0.1s, 407710 effective words/s\n",
      "2023-12-06 14:59:02,979 : INFO : EPOCH 4: training on 99524 raw words (60476 effective words) took 0.1s, 406068 effective words/s\n",
      "2023-12-06 14:59:03,134 : INFO : EPOCH 5: training on 99524 raw words (60431 effective words) took 0.2s, 400809 effective words/s\n",
      "2023-12-06 14:59:03,288 : INFO : EPOCH 6: training on 99524 raw words (60410 effective words) took 0.1s, 406458 effective words/s\n",
      "2023-12-06 14:59:03,440 : INFO : EPOCH 7: training on 99524 raw words (60460 effective words) took 0.1s, 408158 effective words/s\n",
      "2023-12-06 14:59:03,601 : INFO : EPOCH 8: training on 99524 raw words (60396 effective words) took 0.2s, 388196 effective words/s\n",
      "2023-12-06 14:59:03,753 : INFO : EPOCH 9: training on 99524 raw words (60274 effective words) took 0.1s, 408512 effective words/s\n",
      "2023-12-06 14:59:03,914 : INFO : EPOCH 10: training on 99524 raw words (60422 effective words) took 0.2s, 387785 effective words/s\n",
      "2023-12-06 14:59:04,063 : INFO : EPOCH 11: training on 99524 raw words (60515 effective words) took 0.1s, 415496 effective words/s\n",
      "2023-12-06 14:59:04,218 : INFO : EPOCH 12: training on 99524 raw words (60444 effective words) took 0.2s, 401506 effective words/s\n",
      "2023-12-06 14:59:04,373 : INFO : EPOCH 13: training on 99524 raw words (60367 effective words) took 0.1s, 403153 effective words/s\n",
      "2023-12-06 14:59:04,528 : INFO : EPOCH 14: training on 99524 raw words (60428 effective words) took 0.2s, 400391 effective words/s\n",
      "2023-12-06 14:59:04,683 : INFO : EPOCH 15: training on 99524 raw words (60271 effective words) took 0.2s, 401218 effective words/s\n",
      "2023-12-06 14:59:04,842 : INFO : EPOCH 16: training on 99524 raw words (60413 effective words) took 0.2s, 390121 effective words/s\n",
      "2023-12-06 14:59:04,998 : INFO : EPOCH 17: training on 99524 raw words (60245 effective words) took 0.2s, 398305 effective words/s\n",
      "2023-12-06 14:59:05,152 : INFO : EPOCH 18: training on 99524 raw words (60313 effective words) took 0.1s, 402541 effective words/s\n",
      "2023-12-06 14:59:05,308 : INFO : EPOCH 19: training on 99524 raw words (60489 effective words) took 0.2s, 398340 effective words/s\n",
      "2023-12-06 14:59:05,460 : INFO : EPOCH 20: training on 99524 raw words (60291 effective words) took 0.1s, 409809 effective words/s\n",
      "2023-12-06 14:59:05,616 : INFO : EPOCH 21: training on 99524 raw words (60482 effective words) took 0.2s, 399926 effective words/s\n",
      "2023-12-06 14:59:05,771 : INFO : EPOCH 22: training on 99524 raw words (60546 effective words) took 0.1s, 403994 effective words/s\n",
      "2023-12-06 14:59:05,926 : INFO : EPOCH 23: training on 99524 raw words (60367 effective words) took 0.2s, 400421 effective words/s\n",
      "2023-12-06 14:59:06,089 : INFO : EPOCH 24: training on 99524 raw words (60324 effective words) took 0.2s, 380043 effective words/s\n",
      "2023-12-06 14:59:06,245 : INFO : EPOCH 25: training on 99524 raw words (60307 effective words) took 0.2s, 400040 effective words/s\n",
      "2023-12-06 14:59:06,396 : INFO : EPOCH 26: training on 99524 raw words (60425 effective words) took 0.1s, 409272 effective words/s\n",
      "2023-12-06 14:59:06,555 : INFO : EPOCH 27: training on 99524 raw words (60459 effective words) took 0.2s, 393534 effective words/s\n",
      "2023-12-06 14:59:06,711 : INFO : EPOCH 28: training on 99524 raw words (60345 effective words) took 0.2s, 396103 effective words/s\n",
      "2023-12-06 14:59:06,864 : INFO : EPOCH 29: training on 99524 raw words (60383 effective words) took 0.1s, 408384 effective words/s\n",
      "2023-12-06 14:59:07,018 : INFO : EPOCH 30: training on 99524 raw words (60272 effective words) took 0.1s, 402833 effective words/s\n",
      "2023-12-06 14:59:07,170 : INFO : EPOCH 31: training on 99524 raw words (60434 effective words) took 0.1s, 408646 effective words/s\n",
      "2023-12-06 14:59:07,329 : INFO : EPOCH 32: training on 99524 raw words (60467 effective words) took 0.2s, 389318 effective words/s\n",
      "2023-12-06 14:59:07,485 : INFO : EPOCH 33: training on 99524 raw words (60539 effective words) took 0.2s, 401321 effective words/s\n",
      "2023-12-06 14:59:07,638 : INFO : EPOCH 34: training on 99524 raw words (60430 effective words) took 0.1s, 405840 effective words/s\n",
      "2023-12-06 14:59:07,793 : INFO : EPOCH 35: training on 99524 raw words (60494 effective words) took 0.1s, 404177 effective words/s\n",
      "2023-12-06 14:59:07,949 : INFO : EPOCH 36: training on 99524 raw words (60357 effective words) took 0.2s, 399839 effective words/s\n",
      "2023-12-06 14:59:08,100 : INFO : EPOCH 37: training on 99524 raw words (60599 effective words) took 0.1s, 410766 effective words/s\n",
      "2023-12-06 14:59:08,253 : INFO : EPOCH 38: training on 99524 raw words (60445 effective words) took 0.1s, 407577 effective words/s\n",
      "2023-12-06 14:59:08,409 : INFO : EPOCH 39: training on 99524 raw words (60319 effective words) took 0.2s, 397241 effective words/s\n",
      "2023-12-06 14:59:08,569 : INFO : EPOCH 40: training on 99524 raw words (60421 effective words) took 0.2s, 389027 effective words/s\n",
      "2023-12-06 14:59:08,726 : INFO : EPOCH 41: training on 99524 raw words (60598 effective words) took 0.2s, 396408 effective words/s\n",
      "2023-12-06 14:59:08,880 : INFO : EPOCH 42: training on 99524 raw words (60456 effective words) took 0.1s, 404137 effective words/s\n",
      "2023-12-06 14:59:09,036 : INFO : EPOCH 43: training on 99524 raw words (60513 effective words) took 0.2s, 399890 effective words/s\n",
      "2023-12-06 14:59:09,191 : INFO : EPOCH 44: training on 99524 raw words (60352 effective words) took 0.2s, 401121 effective words/s\n",
      "2023-12-06 14:59:09,346 : INFO : EPOCH 45: training on 99524 raw words (60318 effective words) took 0.1s, 403007 effective words/s\n",
      "2023-12-06 14:59:09,501 : INFO : EPOCH 46: training on 99524 raw words (60495 effective words) took 0.2s, 400539 effective words/s\n",
      "2023-12-06 14:59:09,643 : INFO : EPOCH 47: training on 99524 raw words (60326 effective words) took 0.1s, 437198 effective words/s\n",
      "2023-12-06 14:59:09,805 : INFO : EPOCH 48: training on 99524 raw words (60381 effective words) took 0.2s, 385654 effective words/s\n",
      "2023-12-06 14:59:09,956 : INFO : EPOCH 49: training on 99524 raw words (60450 effective words) took 0.1s, 415174 effective words/s\n",
      "2023-12-06 14:59:09,957 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3020519 effective words) took 7.8s, 389139 effective words/s', 'datetime': '2023-12-06T14:59:09.957101', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:59:09,958 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:59:09.958105', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 61%|    | 296/486 [45:32<29:20,  9.27s/it]2023-12-06 14:59:13,582 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:59:13,582 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:59:13,602 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:59:13,603 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:59:13,607 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T14:59:13.607738', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:59:13,607 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T14:59:13.607738', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:59:13,614 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:59:13,614 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:59:13,615 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T14:59:13.615506', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:59:13,622 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 14:59:13,623 : INFO : resetting layer weights\n",
      "2023-12-06 14:59:13,625 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T14:59:13.625072', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:59:13,768 : INFO : EPOCH 0: training on 99524 raw words (60314 effective words) took 0.1s, 436080 effective words/s\n",
      "2023-12-06 14:59:13,942 : INFO : EPOCH 1: training on 99524 raw words (60450 effective words) took 0.2s, 355848 effective words/s\n",
      "2023-12-06 14:59:14,101 : INFO : EPOCH 2: training on 99524 raw words (60411 effective words) took 0.2s, 395401 effective words/s\n",
      "2023-12-06 14:59:14,251 : INFO : EPOCH 3: training on 99524 raw words (60401 effective words) took 0.1s, 416487 effective words/s\n",
      "2023-12-06 14:59:14,405 : INFO : EPOCH 4: training on 99524 raw words (60414 effective words) took 0.2s, 402375 effective words/s\n",
      "2023-12-06 14:59:14,560 : INFO : EPOCH 5: training on 99524 raw words (60349 effective words) took 0.2s, 402007 effective words/s\n",
      "2023-12-06 14:59:14,714 : INFO : EPOCH 6: training on 99524 raw words (60318 effective words) took 0.1s, 403236 effective words/s\n",
      "2023-12-06 14:59:14,869 : INFO : EPOCH 7: training on 99524 raw words (60443 effective words) took 0.1s, 403349 effective words/s\n",
      "2023-12-06 14:59:15,026 : INFO : EPOCH 8: training on 99524 raw words (60498 effective words) took 0.2s, 398576 effective words/s\n",
      "2023-12-06 14:59:15,185 : INFO : EPOCH 9: training on 99524 raw words (60480 effective words) took 0.2s, 388590 effective words/s\n",
      "2023-12-06 14:59:15,337 : INFO : EPOCH 10: training on 99524 raw words (60437 effective words) took 0.1s, 409980 effective words/s\n",
      "2023-12-06 14:59:15,492 : INFO : EPOCH 11: training on 99524 raw words (60511 effective words) took 0.1s, 403963 effective words/s\n",
      "2023-12-06 14:59:15,646 : INFO : EPOCH 12: training on 99524 raw words (60440 effective words) took 0.1s, 404040 effective words/s\n",
      "2023-12-06 14:59:15,801 : INFO : EPOCH 13: training on 99524 raw words (60403 effective words) took 0.2s, 400542 effective words/s\n",
      "2023-12-06 14:59:15,956 : INFO : EPOCH 14: training on 99524 raw words (60269 effective words) took 0.2s, 401487 effective words/s\n",
      "2023-12-06 14:59:16,111 : INFO : EPOCH 15: training on 99524 raw words (60298 effective words) took 0.1s, 403133 effective words/s\n",
      "2023-12-06 14:59:16,278 : INFO : EPOCH 16: training on 99524 raw words (60366 effective words) took 0.2s, 371101 effective words/s\n",
      "2023-12-06 14:59:16,434 : INFO : EPOCH 17: training on 99524 raw words (60284 effective words) took 0.2s, 395062 effective words/s\n",
      "2023-12-06 14:59:16,591 : INFO : EPOCH 18: training on 99524 raw words (60296 effective words) took 0.2s, 397330 effective words/s\n",
      "2023-12-06 14:59:16,748 : INFO : EPOCH 19: training on 99524 raw words (60400 effective words) took 0.2s, 394115 effective words/s\n",
      "2023-12-06 14:59:16,916 : INFO : EPOCH 20: training on 99524 raw words (60425 effective words) took 0.2s, 375917 effective words/s\n",
      "2023-12-06 14:59:17,077 : INFO : EPOCH 21: training on 99524 raw words (60433 effective words) took 0.2s, 386807 effective words/s\n",
      "2023-12-06 14:59:17,233 : INFO : EPOCH 22: training on 99524 raw words (60464 effective words) took 0.2s, 400223 effective words/s\n",
      "2023-12-06 14:59:17,385 : INFO : EPOCH 23: training on 99524 raw words (60519 effective words) took 0.1s, 409314 effective words/s\n",
      "2023-12-06 14:59:17,545 : INFO : EPOCH 24: training on 99524 raw words (60508 effective words) took 0.2s, 388775 effective words/s\n",
      "2023-12-06 14:59:17,704 : INFO : EPOCH 25: training on 99524 raw words (60461 effective words) took 0.2s, 393529 effective words/s\n",
      "2023-12-06 14:59:17,860 : INFO : EPOCH 26: training on 99524 raw words (60546 effective words) took 0.2s, 401661 effective words/s\n",
      "2023-12-06 14:59:18,015 : INFO : EPOCH 27: training on 99524 raw words (60602 effective words) took 0.2s, 402378 effective words/s\n",
      "2023-12-06 14:59:18,166 : INFO : EPOCH 28: training on 99524 raw words (60357 effective words) took 0.1s, 411168 effective words/s\n",
      "2023-12-06 14:59:18,322 : INFO : EPOCH 29: training on 99524 raw words (60409 effective words) took 0.2s, 399361 effective words/s\n",
      "2023-12-06 14:59:18,481 : INFO : EPOCH 30: training on 99524 raw words (60409 effective words) took 0.2s, 390815 effective words/s\n",
      "2023-12-06 14:59:18,633 : INFO : EPOCH 31: training on 99524 raw words (60424 effective words) took 0.1s, 409809 effective words/s\n",
      "2023-12-06 14:59:18,788 : INFO : EPOCH 32: training on 99524 raw words (60387 effective words) took 0.2s, 400516 effective words/s\n",
      "2023-12-06 14:59:18,937 : INFO : EPOCH 33: training on 99524 raw words (60417 effective words) took 0.1s, 417412 effective words/s\n",
      "2023-12-06 14:59:19,097 : INFO : EPOCH 34: training on 99524 raw words (60441 effective words) took 0.2s, 389079 effective words/s\n",
      "2023-12-06 14:59:19,250 : INFO : EPOCH 35: training on 99524 raw words (60485 effective words) took 0.1s, 408519 effective words/s\n",
      "2023-12-06 14:59:19,410 : INFO : EPOCH 36: training on 99524 raw words (60340 effective words) took 0.2s, 388367 effective words/s\n",
      "2023-12-06 14:59:19,562 : INFO : EPOCH 37: training on 99524 raw words (60264 effective words) took 0.1s, 410811 effective words/s\n",
      "2023-12-06 14:59:19,719 : INFO : EPOCH 38: training on 99524 raw words (60331 effective words) took 0.2s, 396762 effective words/s\n",
      "2023-12-06 14:59:19,870 : INFO : EPOCH 39: training on 99524 raw words (60319 effective words) took 0.1s, 410669 effective words/s\n",
      "2023-12-06 14:59:20,026 : INFO : EPOCH 40: training on 99524 raw words (60248 effective words) took 0.2s, 397310 effective words/s\n",
      "2023-12-06 14:59:20,178 : INFO : EPOCH 41: training on 99524 raw words (60501 effective words) took 0.1s, 408722 effective words/s\n",
      "2023-12-06 14:59:20,337 : INFO : EPOCH 42: training on 99524 raw words (60640 effective words) took 0.2s, 392733 effective words/s\n",
      "2023-12-06 14:59:20,491 : INFO : EPOCH 43: training on 99524 raw words (60422 effective words) took 0.1s, 404159 effective words/s\n",
      "2023-12-06 14:59:20,646 : INFO : EPOCH 44: training on 99524 raw words (60395 effective words) took 0.2s, 402258 effective words/s\n",
      "2023-12-06 14:59:20,796 : INFO : EPOCH 45: training on 99524 raw words (60262 effective words) took 0.1s, 411874 effective words/s\n",
      "2023-12-06 14:59:20,953 : INFO : EPOCH 46: training on 99524 raw words (60308 effective words) took 0.2s, 398347 effective words/s\n",
      "2023-12-06 14:59:21,109 : INFO : EPOCH 47: training on 99524 raw words (60510 effective words) took 0.2s, 398523 effective words/s\n",
      "2023-12-06 14:59:21,275 : INFO : EPOCH 48: training on 99524 raw words (60354 effective words) took 0.2s, 376117 effective words/s\n",
      "2023-12-06 14:59:21,426 : INFO : EPOCH 49: training on 99524 raw words (60336 effective words) took 0.1s, 408540 effective words/s\n",
      "2023-12-06 14:59:21,427 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3020299 effective words) took 7.8s, 387113 effective words/s', 'datetime': '2023-12-06T14:59:21.427930', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:59:21,428 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T14:59:21.428927', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 61%|    | 297/486 [45:43<31:20,  9.95s/it]2023-12-06 14:59:25,127 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:59:25,127 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:59:25,152 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:59:25,153 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:59:25,158 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:59:25.158567', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:59:25,159 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:59:25.159567', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:59:25,166 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:59:25,167 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:59:25,167 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:59:25.167567', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:59:25,178 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:59:25,179 : INFO : resetting layer weights\n",
      "2023-12-06 14:59:25,181 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:59:25.181702', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:59:25,329 : INFO : EPOCH 0: training on 99524 raw words (65642 effective words) took 0.1s, 463030 effective words/s\n",
      "2023-12-06 14:59:25,506 : INFO : EPOCH 1: training on 99524 raw words (65573 effective words) took 0.2s, 381560 effective words/s\n",
      "2023-12-06 14:59:25,657 : INFO : EPOCH 2: training on 99524 raw words (65588 effective words) took 0.1s, 448248 effective words/s\n",
      "2023-12-06 14:59:25,808 : INFO : EPOCH 3: training on 99524 raw words (65341 effective words) took 0.1s, 445133 effective words/s\n",
      "2023-12-06 14:59:25,957 : INFO : EPOCH 4: training on 99524 raw words (65667 effective words) took 0.1s, 454938 effective words/s\n",
      "2023-12-06 14:59:26,105 : INFO : EPOCH 5: training on 99524 raw words (65289 effective words) took 0.1s, 454925 effective words/s\n",
      "2023-12-06 14:59:26,257 : INFO : EPOCH 6: training on 99524 raw words (65719 effective words) took 0.1s, 445995 effective words/s\n",
      "2023-12-06 14:59:26,407 : INFO : EPOCH 7: training on 99524 raw words (65592 effective words) took 0.1s, 450110 effective words/s\n",
      "2023-12-06 14:59:26,558 : INFO : EPOCH 8: training on 99524 raw words (65402 effective words) took 0.1s, 447937 effective words/s\n",
      "2023-12-06 14:59:26,710 : INFO : EPOCH 9: training on 99524 raw words (65498 effective words) took 0.1s, 440810 effective words/s\n",
      "2023-12-06 14:59:26,712 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655311 effective words) took 1.5s, 428487 effective words/s', 'datetime': '2023-12-06T14:59:26.712579', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:59:26,712 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:59:26.712579', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 61%|   | 298/486 [45:47<25:45,  8.22s/it]2023-12-06 14:59:29,308 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:59:29,308 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:59:29,330 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:59:29,330 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:59:29,339 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:59:29.339306', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:59:29,340 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:59:29.340306', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:59:29,350 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:59:29,351 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:59:29,351 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:59:29.351476', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:59:29,362 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:59:29,363 : INFO : resetting layer weights\n",
      "2023-12-06 14:59:29,365 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:59:29.365798', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:59:29,518 : INFO : EPOCH 0: training on 99524 raw words (65405 effective words) took 0.1s, 443110 effective words/s\n",
      "2023-12-06 14:59:29,698 : INFO : EPOCH 1: training on 99524 raw words (65424 effective words) took 0.2s, 375289 effective words/s\n",
      "2023-12-06 14:59:29,856 : INFO : EPOCH 2: training on 99524 raw words (65715 effective words) took 0.2s, 426805 effective words/s\n",
      "2023-12-06 14:59:30,011 : INFO : EPOCH 3: training on 99524 raw words (65375 effective words) took 0.1s, 436045 effective words/s\n",
      "2023-12-06 14:59:30,168 : INFO : EPOCH 4: training on 99524 raw words (65436 effective words) took 0.2s, 429598 effective words/s\n",
      "2023-12-06 14:59:30,328 : INFO : EPOCH 5: training on 99524 raw words (65448 effective words) took 0.2s, 421230 effective words/s\n",
      "2023-12-06 14:59:30,491 : INFO : EPOCH 6: training on 99524 raw words (65492 effective words) took 0.2s, 414146 effective words/s\n",
      "2023-12-06 14:59:30,661 : INFO : EPOCH 7: training on 99524 raw words (65586 effective words) took 0.2s, 395997 effective words/s\n",
      "2023-12-06 14:59:30,817 : INFO : EPOCH 8: training on 99524 raw words (65629 effective words) took 0.2s, 435642 effective words/s\n",
      "2023-12-06 14:59:30,974 : INFO : EPOCH 9: training on 99524 raw words (65516 effective words) took 0.2s, 428387 effective words/s\n",
      "2023-12-06 14:59:30,975 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655026 effective words) took 1.6s, 407282 effective words/s', 'datetime': '2023-12-06T14:59:30.975677', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:59:30,976 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:59:30.976679', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 62%|   | 299/486 [45:52<21:59,  7.06s/it]2023-12-06 14:59:33,654 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:59:33,655 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:59:33,675 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:59:33,676 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:59:33,682 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:59:33.682433', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:59:33,683 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:59:33.683440', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:59:33,690 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:59:33,691 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:59:33,691 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:59:33.691058', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:59:33,701 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:59:33,702 : INFO : resetting layer weights\n",
      "2023-12-06 14:59:33,707 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:59:33.707043', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:59:33,852 : INFO : EPOCH 0: training on 99524 raw words (65530 effective words) took 0.1s, 460312 effective words/s\n",
      "2023-12-06 14:59:34,027 : INFO : EPOCH 1: training on 99524 raw words (65733 effective words) took 0.2s, 388898 effective words/s\n",
      "2023-12-06 14:59:34,188 : INFO : EPOCH 2: training on 99524 raw words (65625 effective words) took 0.2s, 423693 effective words/s\n",
      "2023-12-06 14:59:34,341 : INFO : EPOCH 3: training on 99524 raw words (65412 effective words) took 0.1s, 440183 effective words/s\n",
      "2023-12-06 14:59:34,497 : INFO : EPOCH 4: training on 99524 raw words (65479 effective words) took 0.2s, 433309 effective words/s\n",
      "2023-12-06 14:59:34,651 : INFO : EPOCH 5: training on 99524 raw words (65626 effective words) took 0.2s, 437440 effective words/s\n",
      "2023-12-06 14:59:34,802 : INFO : EPOCH 6: training on 99524 raw words (65394 effective words) took 0.1s, 445557 effective words/s\n",
      "2023-12-06 14:59:34,965 : INFO : EPOCH 7: training on 99524 raw words (65541 effective words) took 0.2s, 415296 effective words/s\n",
      "2023-12-06 14:59:35,120 : INFO : EPOCH 8: training on 99524 raw words (65503 effective words) took 0.2s, 433554 effective words/s\n",
      "2023-12-06 14:59:35,279 : INFO : EPOCH 9: training on 99524 raw words (65594 effective words) took 0.2s, 427567 effective words/s\n",
      "2023-12-06 14:59:35,279 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655437 effective words) took 1.6s, 416836 effective words/s', 'datetime': '2023-12-06T14:59:35.279321', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:59:35,280 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:59:35.280321', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 62%|   | 300/486 [45:56<19:22,  6.25s/it]2023-12-06 14:59:38,014 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:59:38,015 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:59:38,035 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:59:38,036 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:59:38,043 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:59:38.043734', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:59:38,044 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:59:38.044734', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:59:38,054 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:59:38,055 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:59:38,056 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:59:38.056349', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:59:38,071 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:59:38,072 : INFO : resetting layer weights\n",
      "2023-12-06 14:59:38,075 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:59:38.075103', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:59:38,226 : INFO : EPOCH 0: training on 99524 raw words (65490 effective words) took 0.1s, 445463 effective words/s\n",
      "2023-12-06 14:59:38,402 : INFO : EPOCH 1: training on 99524 raw words (65615 effective words) took 0.2s, 384559 effective words/s\n",
      "2023-12-06 14:59:38,547 : INFO : EPOCH 2: training on 99524 raw words (65398 effective words) took 0.1s, 463009 effective words/s\n",
      "2023-12-06 14:59:38,700 : INFO : EPOCH 3: training on 99524 raw words (65482 effective words) took 0.1s, 441633 effective words/s\n",
      "2023-12-06 14:59:38,853 : INFO : EPOCH 4: training on 99524 raw words (65562 effective words) took 0.1s, 439367 effective words/s\n",
      "2023-12-06 14:59:39,004 : INFO : EPOCH 5: training on 99524 raw words (65348 effective words) took 0.1s, 446036 effective words/s\n",
      "2023-12-06 14:59:39,156 : INFO : EPOCH 6: training on 99524 raw words (65596 effective words) took 0.1s, 447189 effective words/s\n",
      "2023-12-06 14:59:39,310 : INFO : EPOCH 7: training on 99524 raw words (65393 effective words) took 0.1s, 438440 effective words/s\n",
      "2023-12-06 14:59:39,459 : INFO : EPOCH 8: training on 99524 raw words (65454 effective words) took 0.1s, 452352 effective words/s\n",
      "2023-12-06 14:59:39,615 : INFO : EPOCH 9: training on 99524 raw words (65604 effective words) took 0.2s, 432733 effective words/s\n",
      "2023-12-06 14:59:39,766 : INFO : EPOCH 10: training on 99524 raw words (65352 effective words) took 0.1s, 444691 effective words/s\n",
      "2023-12-06 14:59:39,911 : INFO : EPOCH 11: training on 99524 raw words (65554 effective words) took 0.1s, 466330 effective words/s\n",
      "2023-12-06 14:59:40,061 : INFO : EPOCH 12: training on 99524 raw words (65514 effective words) took 0.1s, 447350 effective words/s\n",
      "2023-12-06 14:59:40,213 : INFO : EPOCH 13: training on 99524 raw words (65437 effective words) took 0.1s, 446183 effective words/s\n",
      "2023-12-06 14:59:40,365 : INFO : EPOCH 14: training on 99524 raw words (65522 effective words) took 0.1s, 443776 effective words/s\n",
      "2023-12-06 14:59:40,515 : INFO : EPOCH 15: training on 99524 raw words (65592 effective words) took 0.1s, 452188 effective words/s\n",
      "2023-12-06 14:59:40,668 : INFO : EPOCH 16: training on 99524 raw words (65590 effective words) took 0.1s, 442265 effective words/s\n",
      "2023-12-06 14:59:40,816 : INFO : EPOCH 17: training on 99524 raw words (65586 effective words) took 0.1s, 455545 effective words/s\n",
      "2023-12-06 14:59:40,966 : INFO : EPOCH 18: training on 99524 raw words (65382 effective words) took 0.1s, 447405 effective words/s\n",
      "2023-12-06 14:59:41,116 : INFO : EPOCH 19: training on 99524 raw words (65538 effective words) took 0.1s, 451198 effective words/s\n",
      "2023-12-06 14:59:41,260 : INFO : EPOCH 20: training on 99524 raw words (65481 effective words) took 0.1s, 468466 effective words/s\n",
      "2023-12-06 14:59:41,409 : INFO : EPOCH 21: training on 99524 raw words (65500 effective words) took 0.1s, 450831 effective words/s\n",
      "2023-12-06 14:59:41,560 : INFO : EPOCH 22: training on 99524 raw words (65629 effective words) took 0.1s, 451869 effective words/s\n",
      "2023-12-06 14:59:41,713 : INFO : EPOCH 23: training on 99524 raw words (65448 effective words) took 0.1s, 441944 effective words/s\n",
      "2023-12-06 14:59:41,880 : INFO : EPOCH 24: training on 99524 raw words (65569 effective words) took 0.2s, 402005 effective words/s\n",
      "2023-12-06 14:59:42,034 : INFO : EPOCH 25: training on 99524 raw words (65471 effective words) took 0.1s, 438669 effective words/s\n",
      "2023-12-06 14:59:42,190 : INFO : EPOCH 26: training on 99524 raw words (65616 effective words) took 0.2s, 436696 effective words/s\n",
      "2023-12-06 14:59:42,334 : INFO : EPOCH 27: training on 99524 raw words (65568 effective words) took 0.1s, 466171 effective words/s\n",
      "2023-12-06 14:59:42,487 : INFO : EPOCH 28: training on 99524 raw words (65376 effective words) took 0.1s, 441624 effective words/s\n",
      "2023-12-06 14:59:42,638 : INFO : EPOCH 29: training on 99524 raw words (65591 effective words) took 0.1s, 448141 effective words/s\n",
      "2023-12-06 14:59:42,640 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965258 effective words) took 4.6s, 430587 effective words/s', 'datetime': '2023-12-06T14:59:42.640146', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:59:42,640 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:59:42.640146', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 62%|   | 301/486 [46:04<20:26,  6.63s/it]2023-12-06 14:59:45,536 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:59:45,536 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:59:45,557 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:59:45,558 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:59:45,567 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:59:45.567802', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:59:45,568 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:59:45.568805', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:59:45,578 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:59:45,579 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:59:45,579 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:59:45.579801', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:59:45,589 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:59:45,590 : INFO : resetting layer weights\n",
      "2023-12-06 14:59:45,592 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:59:45.592802', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:59:45,747 : INFO : EPOCH 0: training on 99524 raw words (65517 effective words) took 0.2s, 436405 effective words/s\n",
      "2023-12-06 14:59:45,923 : INFO : EPOCH 1: training on 99524 raw words (65698 effective words) took 0.2s, 386017 effective words/s\n",
      "2023-12-06 14:59:46,082 : INFO : EPOCH 2: training on 99524 raw words (65656 effective words) took 0.2s, 428980 effective words/s\n",
      "2023-12-06 14:59:46,237 : INFO : EPOCH 3: training on 99524 raw words (65416 effective words) took 0.2s, 432625 effective words/s\n",
      "2023-12-06 14:59:46,394 : INFO : EPOCH 4: training on 99524 raw words (65426 effective words) took 0.2s, 428954 effective words/s\n",
      "2023-12-06 14:59:46,554 : INFO : EPOCH 5: training on 99524 raw words (65492 effective words) took 0.2s, 421034 effective words/s\n",
      "2023-12-06 14:59:46,712 : INFO : EPOCH 6: training on 99524 raw words (65299 effective words) took 0.2s, 426553 effective words/s\n",
      "2023-12-06 14:59:46,866 : INFO : EPOCH 7: training on 99524 raw words (65568 effective words) took 0.1s, 438247 effective words/s\n",
      "2023-12-06 14:59:47,031 : INFO : EPOCH 8: training on 99524 raw words (65498 effective words) took 0.2s, 408108 effective words/s\n",
      "2023-12-06 14:59:47,195 : INFO : EPOCH 9: training on 99524 raw words (65547 effective words) took 0.2s, 411629 effective words/s\n",
      "2023-12-06 14:59:47,352 : INFO : EPOCH 10: training on 99524 raw words (65427 effective words) took 0.2s, 429552 effective words/s\n",
      "2023-12-06 14:59:47,510 : INFO : EPOCH 11: training on 99524 raw words (65597 effective words) took 0.2s, 427762 effective words/s\n",
      "2023-12-06 14:59:47,669 : INFO : EPOCH 12: training on 99524 raw words (65542 effective words) took 0.2s, 424558 effective words/s\n",
      "2023-12-06 14:59:47,825 : INFO : EPOCH 13: training on 99524 raw words (65582 effective words) took 0.2s, 433269 effective words/s\n",
      "2023-12-06 14:59:47,984 : INFO : EPOCH 14: training on 99524 raw words (65466 effective words) took 0.2s, 423928 effective words/s\n",
      "2023-12-06 14:59:48,142 : INFO : EPOCH 15: training on 99524 raw words (65494 effective words) took 0.2s, 424970 effective words/s\n",
      "2023-12-06 14:59:48,305 : INFO : EPOCH 16: training on 99524 raw words (65456 effective words) took 0.2s, 412787 effective words/s\n",
      "2023-12-06 14:59:48,461 : INFO : EPOCH 17: training on 99524 raw words (65542 effective words) took 0.2s, 433249 effective words/s\n",
      "2023-12-06 14:59:48,620 : INFO : EPOCH 18: training on 99524 raw words (65352 effective words) took 0.2s, 424519 effective words/s\n",
      "2023-12-06 14:59:48,777 : INFO : EPOCH 19: training on 99524 raw words (65645 effective words) took 0.2s, 428650 effective words/s\n",
      "2023-12-06 14:59:48,935 : INFO : EPOCH 20: training on 99524 raw words (65541 effective words) took 0.2s, 425934 effective words/s\n",
      "2023-12-06 14:59:49,093 : INFO : EPOCH 21: training on 99524 raw words (65496 effective words) took 0.2s, 426317 effective words/s\n",
      "2023-12-06 14:59:49,257 : INFO : EPOCH 22: training on 99524 raw words (65535 effective words) took 0.2s, 412955 effective words/s\n",
      "2023-12-06 14:59:49,426 : INFO : EPOCH 23: training on 99524 raw words (65482 effective words) took 0.2s, 397736 effective words/s\n",
      "2023-12-06 14:59:49,583 : INFO : EPOCH 24: training on 99524 raw words (65447 effective words) took 0.2s, 427627 effective words/s\n",
      "2023-12-06 14:59:49,737 : INFO : EPOCH 25: training on 99524 raw words (65522 effective words) took 0.1s, 439548 effective words/s\n",
      "2023-12-06 14:59:49,892 : INFO : EPOCH 26: training on 99524 raw words (65655 effective words) took 0.2s, 435754 effective words/s\n",
      "2023-12-06 14:59:50,045 : INFO : EPOCH 27: training on 99524 raw words (65688 effective words) took 0.1s, 442947 effective words/s\n",
      "2023-12-06 14:59:50,204 : INFO : EPOCH 28: training on 99524 raw words (65652 effective words) took 0.2s, 423863 effective words/s\n",
      "2023-12-06 14:59:50,359 : INFO : EPOCH 29: training on 99524 raw words (65726 effective words) took 0.2s, 436000 effective words/s\n",
      "2023-12-06 14:59:50,360 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965964 effective words) took 4.8s, 412439 effective words/s', 'datetime': '2023-12-06T14:59:50.360347', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:59:50,361 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:59:50.361348', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 62%|   | 302/486 [46:12<21:31,  7.02s/it]2023-12-06 14:59:53,457 : INFO : collecting all words and their counts\n",
      "2023-12-06 14:59:53,457 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 14:59:53,479 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 14:59:53,480 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 14:59:53,486 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T14:59:53.486456', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:59:53,487 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T14:59:53.487456', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:59:53,495 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 14:59:53,496 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 14:59:53,496 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T14:59:53.496962', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 14:59:53,511 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 14:59:53,512 : INFO : resetting layer weights\n",
      "2023-12-06 14:59:53,515 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T14:59:53.515071', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:59:53,661 : INFO : EPOCH 0: training on 99524 raw words (65433 effective words) took 0.1s, 460547 effective words/s\n",
      "2023-12-06 14:59:53,836 : INFO : EPOCH 1: training on 99524 raw words (65487 effective words) took 0.2s, 386241 effective words/s\n",
      "2023-12-06 14:59:53,999 : INFO : EPOCH 2: training on 99524 raw words (65479 effective words) took 0.2s, 416422 effective words/s\n",
      "2023-12-06 14:59:54,150 : INFO : EPOCH 3: training on 99524 raw words (65400 effective words) took 0.1s, 443729 effective words/s\n",
      "2023-12-06 14:59:54,307 : INFO : EPOCH 4: training on 99524 raw words (65436 effective words) took 0.2s, 433115 effective words/s\n",
      "2023-12-06 14:59:54,463 : INFO : EPOCH 5: training on 99524 raw words (65396 effective words) took 0.2s, 429865 effective words/s\n",
      "2023-12-06 14:59:54,620 : INFO : EPOCH 6: training on 99524 raw words (65529 effective words) took 0.2s, 427447 effective words/s\n",
      "2023-12-06 14:59:54,776 : INFO : EPOCH 7: training on 99524 raw words (65381 effective words) took 0.1s, 435934 effective words/s\n",
      "2023-12-06 14:59:54,932 : INFO : EPOCH 8: training on 99524 raw words (65495 effective words) took 0.2s, 428949 effective words/s\n",
      "2023-12-06 14:59:55,094 : INFO : EPOCH 9: training on 99524 raw words (65460 effective words) took 0.2s, 418163 effective words/s\n",
      "2023-12-06 14:59:55,245 : INFO : EPOCH 10: training on 99524 raw words (65455 effective words) took 0.1s, 447779 effective words/s\n",
      "2023-12-06 14:59:55,401 : INFO : EPOCH 11: training on 99524 raw words (65731 effective words) took 0.2s, 432450 effective words/s\n",
      "2023-12-06 14:59:55,558 : INFO : EPOCH 12: training on 99524 raw words (65385 effective words) took 0.2s, 428919 effective words/s\n",
      "2023-12-06 14:59:55,708 : INFO : EPOCH 13: training on 99524 raw words (65469 effective words) took 0.1s, 447791 effective words/s\n",
      "2023-12-06 14:59:55,863 : INFO : EPOCH 14: training on 99524 raw words (65494 effective words) took 0.2s, 435509 effective words/s\n",
      "2023-12-06 14:59:56,020 : INFO : EPOCH 15: training on 99524 raw words (65574 effective words) took 0.2s, 429774 effective words/s\n",
      "2023-12-06 14:59:56,176 : INFO : EPOCH 16: training on 99524 raw words (65406 effective words) took 0.2s, 433567 effective words/s\n",
      "2023-12-06 14:59:56,341 : INFO : EPOCH 17: training on 99524 raw words (65487 effective words) took 0.2s, 408283 effective words/s\n",
      "2023-12-06 14:59:56,500 : INFO : EPOCH 18: training on 99524 raw words (65511 effective words) took 0.2s, 424820 effective words/s\n",
      "2023-12-06 14:59:56,653 : INFO : EPOCH 19: training on 99524 raw words (65676 effective words) took 0.1s, 438438 effective words/s\n",
      "2023-12-06 14:59:56,810 : INFO : EPOCH 20: training on 99524 raw words (65557 effective words) took 0.2s, 430685 effective words/s\n",
      "2023-12-06 14:59:56,965 : INFO : EPOCH 21: training on 99524 raw words (65539 effective words) took 0.2s, 435996 effective words/s\n",
      "2023-12-06 14:59:57,116 : INFO : EPOCH 22: training on 99524 raw words (65662 effective words) took 0.1s, 449377 effective words/s\n",
      "2023-12-06 14:59:57,272 : INFO : EPOCH 23: training on 99524 raw words (65577 effective words) took 0.2s, 433202 effective words/s\n",
      "2023-12-06 14:59:57,425 : INFO : EPOCH 24: training on 99524 raw words (65629 effective words) took 0.1s, 442180 effective words/s\n",
      "2023-12-06 14:59:57,585 : INFO : EPOCH 25: training on 99524 raw words (65369 effective words) took 0.2s, 420444 effective words/s\n",
      "2023-12-06 14:59:57,741 : INFO : EPOCH 26: training on 99524 raw words (65655 effective words) took 0.2s, 433424 effective words/s\n",
      "2023-12-06 14:59:57,898 : INFO : EPOCH 27: training on 99524 raw words (65547 effective words) took 0.2s, 434081 effective words/s\n",
      "2023-12-06 14:59:58,052 : INFO : EPOCH 28: training on 99524 raw words (65508 effective words) took 0.2s, 436417 effective words/s\n",
      "2023-12-06 14:59:58,213 : INFO : EPOCH 29: training on 99524 raw words (65601 effective words) took 0.2s, 421668 effective words/s\n",
      "2023-12-06 14:59:58,214 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965328 effective words) took 4.7s, 418345 effective words/s', 'datetime': '2023-12-06T14:59:58.214039', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 14:59:58,214 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T14:59:58.214039', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 62%|   | 303/486 [46:20<22:18,  7.31s/it]2023-12-06 15:00:01,461 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:00:01,462 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:00:01,486 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:00:01,487 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:00:01,496 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:00:01.496193', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:00:01,497 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:00:01.497200', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:00:01,505 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:00:01,506 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:00:01,506 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:00:01.506665', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:00:01,525 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 15:00:01,526 : INFO : resetting layer weights\n",
      "2023-12-06 15:00:01,529 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:00:01.529304', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:00:01,680 : INFO : EPOCH 0: training on 99524 raw words (65491 effective words) took 0.1s, 445831 effective words/s\n",
      "2023-12-06 15:00:01,846 : INFO : EPOCH 1: training on 99524 raw words (65701 effective words) took 0.2s, 412831 effective words/s\n",
      "2023-12-06 15:00:01,994 : INFO : EPOCH 2: training on 99524 raw words (65660 effective words) took 0.1s, 456504 effective words/s\n",
      "2023-12-06 15:00:02,148 : INFO : EPOCH 3: training on 99524 raw words (65347 effective words) took 0.1s, 437483 effective words/s\n",
      "2023-12-06 15:00:02,298 : INFO : EPOCH 4: training on 99524 raw words (65578 effective words) took 0.1s, 451959 effective words/s\n",
      "2023-12-06 15:00:02,452 : INFO : EPOCH 5: training on 99524 raw words (65426 effective words) took 0.2s, 435956 effective words/s\n",
      "2023-12-06 15:00:02,602 : INFO : EPOCH 6: training on 99524 raw words (65527 effective words) took 0.1s, 450781 effective words/s\n",
      "2023-12-06 15:00:02,751 : INFO : EPOCH 7: training on 99524 raw words (65637 effective words) took 0.1s, 452850 effective words/s\n",
      "2023-12-06 15:00:02,904 : INFO : EPOCH 8: training on 99524 raw words (65301 effective words) took 0.1s, 438549 effective words/s\n",
      "2023-12-06 15:00:03,062 : INFO : EPOCH 9: training on 99524 raw words (65507 effective words) took 0.2s, 427051 effective words/s\n",
      "2023-12-06 15:00:03,218 : INFO : EPOCH 10: training on 99524 raw words (65468 effective words) took 0.2s, 433256 effective words/s\n",
      "2023-12-06 15:00:03,371 : INFO : EPOCH 11: training on 99524 raw words (65569 effective words) took 0.1s, 438800 effective words/s\n",
      "2023-12-06 15:00:03,525 : INFO : EPOCH 12: training on 99524 raw words (65492 effective words) took 0.1s, 441139 effective words/s\n",
      "2023-12-06 15:00:03,672 : INFO : EPOCH 13: training on 99524 raw words (65543 effective words) took 0.1s, 461842 effective words/s\n",
      "2023-12-06 15:00:03,821 : INFO : EPOCH 14: training on 99524 raw words (65620 effective words) took 0.1s, 451149 effective words/s\n",
      "2023-12-06 15:00:03,975 : INFO : EPOCH 15: training on 99524 raw words (65519 effective words) took 0.1s, 439416 effective words/s\n",
      "2023-12-06 15:00:04,125 : INFO : EPOCH 16: training on 99524 raw words (65535 effective words) took 0.1s, 449932 effective words/s\n",
      "2023-12-06 15:00:04,282 : INFO : EPOCH 17: training on 99524 raw words (65487 effective words) took 0.2s, 429251 effective words/s\n",
      "2023-12-06 15:00:04,439 : INFO : EPOCH 18: training on 99524 raw words (65502 effective words) took 0.2s, 434639 effective words/s\n",
      "2023-12-06 15:00:04,593 : INFO : EPOCH 19: training on 99524 raw words (65659 effective words) took 0.2s, 436271 effective words/s\n",
      "2023-12-06 15:00:04,747 : INFO : EPOCH 20: training on 99524 raw words (65579 effective words) took 0.1s, 441556 effective words/s\n",
      "2023-12-06 15:00:04,900 : INFO : EPOCH 21: training on 99524 raw words (65626 effective words) took 0.1s, 441766 effective words/s\n",
      "2023-12-06 15:00:05,052 : INFO : EPOCH 22: training on 99524 raw words (65445 effective words) took 0.1s, 443393 effective words/s\n",
      "2023-12-06 15:00:05,213 : INFO : EPOCH 23: training on 99524 raw words (65676 effective words) took 0.2s, 419795 effective words/s\n",
      "2023-12-06 15:00:05,375 : INFO : EPOCH 24: training on 99524 raw words (65745 effective words) took 0.2s, 419265 effective words/s\n",
      "2023-12-06 15:00:05,540 : INFO : EPOCH 25: training on 99524 raw words (65513 effective words) took 0.2s, 410360 effective words/s\n",
      "2023-12-06 15:00:05,696 : INFO : EPOCH 26: training on 99524 raw words (65897 effective words) took 0.2s, 435384 effective words/s\n",
      "2023-12-06 15:00:05,847 : INFO : EPOCH 27: training on 99524 raw words (65778 effective words) took 0.1s, 448907 effective words/s\n",
      "2023-12-06 15:00:05,997 : INFO : EPOCH 28: training on 99524 raw words (65556 effective words) took 0.1s, 448657 effective words/s\n",
      "2023-12-06 15:00:06,155 : INFO : EPOCH 29: training on 99524 raw words (65619 effective words) took 0.2s, 428294 effective words/s\n",
      "2023-12-06 15:00:06,307 : INFO : EPOCH 30: training on 99524 raw words (65440 effective words) took 0.1s, 442636 effective words/s\n",
      "2023-12-06 15:00:06,461 : INFO : EPOCH 31: training on 99524 raw words (65452 effective words) took 0.1s, 440190 effective words/s\n",
      "2023-12-06 15:00:06,616 : INFO : EPOCH 32: training on 99524 raw words (65625 effective words) took 0.2s, 436311 effective words/s\n",
      "2023-12-06 15:00:06,773 : INFO : EPOCH 33: training on 99524 raw words (65673 effective words) took 0.2s, 428308 effective words/s\n",
      "2023-12-06 15:00:06,927 : INFO : EPOCH 34: training on 99524 raw words (65685 effective words) took 0.1s, 441606 effective words/s\n",
      "2023-12-06 15:00:07,082 : INFO : EPOCH 35: training on 99524 raw words (65522 effective words) took 0.2s, 436356 effective words/s\n",
      "2023-12-06 15:00:07,233 : INFO : EPOCH 36: training on 99524 raw words (65488 effective words) took 0.1s, 445334 effective words/s\n",
      "2023-12-06 15:00:07,380 : INFO : EPOCH 37: training on 99524 raw words (65529 effective words) took 0.1s, 458535 effective words/s\n",
      "2023-12-06 15:00:07,532 : INFO : EPOCH 38: training on 99524 raw words (65456 effective words) took 0.1s, 444156 effective words/s\n",
      "2023-12-06 15:00:07,684 : INFO : EPOCH 39: training on 99524 raw words (65622 effective words) took 0.1s, 444046 effective words/s\n",
      "2023-12-06 15:00:07,834 : INFO : EPOCH 40: training on 99524 raw words (65539 effective words) took 0.1s, 449926 effective words/s\n",
      "2023-12-06 15:00:08,001 : INFO : EPOCH 41: training on 99524 raw words (65605 effective words) took 0.2s, 404035 effective words/s\n",
      "2023-12-06 15:00:08,155 : INFO : EPOCH 42: training on 99524 raw words (65466 effective words) took 0.1s, 439042 effective words/s\n",
      "2023-12-06 15:00:08,310 : INFO : EPOCH 43: training on 99524 raw words (65610 effective words) took 0.2s, 436150 effective words/s\n",
      "2023-12-06 15:00:08,463 : INFO : EPOCH 44: training on 99524 raw words (65350 effective words) took 0.1s, 440129 effective words/s\n",
      "2023-12-06 15:00:08,614 : INFO : EPOCH 45: training on 99524 raw words (65430 effective words) took 0.1s, 446794 effective words/s\n",
      "2023-12-06 15:00:08,768 : INFO : EPOCH 46: training on 99524 raw words (65452 effective words) took 0.1s, 439451 effective words/s\n",
      "2023-12-06 15:00:08,929 : INFO : EPOCH 47: training on 99524 raw words (65441 effective words) took 0.2s, 418046 effective words/s\n",
      "2023-12-06 15:00:09,084 : INFO : EPOCH 48: training on 99524 raw words (65623 effective words) took 0.2s, 436171 effective words/s\n",
      "2023-12-06 15:00:09,238 : INFO : EPOCH 49: training on 99524 raw words (65634 effective words) took 0.1s, 438843 effective words/s\n",
      "2023-12-06 15:00:09,239 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3277645 effective words) took 7.7s, 425171 effective words/s', 'datetime': '2023-12-06T15:00:09.239497', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:00:09,239 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:00:09.239497', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 63%|   | 304/486 [46:31<25:32,  8.42s/it]2023-12-06 15:00:12,464 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:00:12,465 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:00:12,489 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:00:12,489 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:00:12,497 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:00:12.497202', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:00:12,497 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:00:12.497202', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:00:12,507 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:00:12,507 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:00:12,508 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:00:12.508201', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:00:12,519 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 15:00:12,519 : INFO : resetting layer weights\n",
      "2023-12-06 15:00:12,522 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:00:12.522942', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:00:12,679 : INFO : EPOCH 0: training on 99524 raw words (65584 effective words) took 0.2s, 429159 effective words/s\n",
      "2023-12-06 15:00:12,849 : INFO : EPOCH 1: training on 99524 raw words (65658 effective words) took 0.2s, 397987 effective words/s\n",
      "2023-12-06 15:00:13,008 : INFO : EPOCH 2: training on 99524 raw words (65551 effective words) took 0.2s, 427255 effective words/s\n",
      "2023-12-06 15:00:13,165 : INFO : EPOCH 3: training on 99524 raw words (65609 effective words) took 0.2s, 430285 effective words/s\n",
      "2023-12-06 15:00:13,330 : INFO : EPOCH 4: training on 99524 raw words (65566 effective words) took 0.2s, 407896 effective words/s\n",
      "2023-12-06 15:00:13,493 : INFO : EPOCH 5: training on 99524 raw words (65561 effective words) took 0.2s, 413912 effective words/s\n",
      "2023-12-06 15:00:13,648 : INFO : EPOCH 6: training on 99524 raw words (65512 effective words) took 0.2s, 434428 effective words/s\n",
      "2023-12-06 15:00:13,805 : INFO : EPOCH 7: training on 99524 raw words (65585 effective words) took 0.2s, 433018 effective words/s\n",
      "2023-12-06 15:00:13,970 : INFO : EPOCH 8: training on 99524 raw words (65575 effective words) took 0.2s, 409660 effective words/s\n",
      "2023-12-06 15:00:14,127 : INFO : EPOCH 9: training on 99524 raw words (65497 effective words) took 0.2s, 427636 effective words/s\n",
      "2023-12-06 15:00:14,283 : INFO : EPOCH 10: training on 99524 raw words (65333 effective words) took 0.2s, 431932 effective words/s\n",
      "2023-12-06 15:00:14,439 : INFO : EPOCH 11: training on 99524 raw words (65611 effective words) took 0.2s, 432144 effective words/s\n",
      "2023-12-06 15:00:14,598 : INFO : EPOCH 12: training on 99524 raw words (65592 effective words) took 0.2s, 425876 effective words/s\n",
      "2023-12-06 15:00:14,755 : INFO : EPOCH 13: training on 99524 raw words (65524 effective words) took 0.2s, 428324 effective words/s\n",
      "2023-12-06 15:00:14,913 : INFO : EPOCH 14: training on 99524 raw words (65628 effective words) took 0.2s, 430081 effective words/s\n",
      "2023-12-06 15:00:15,071 : INFO : EPOCH 15: training on 99524 raw words (65498 effective words) took 0.2s, 426043 effective words/s\n",
      "2023-12-06 15:00:15,231 : INFO : EPOCH 16: training on 99524 raw words (65624 effective words) took 0.2s, 421038 effective words/s\n",
      "2023-12-06 15:00:15,387 : INFO : EPOCH 17: training on 99524 raw words (65542 effective words) took 0.2s, 432107 effective words/s\n",
      "2023-12-06 15:00:15,545 : INFO : EPOCH 18: training on 99524 raw words (65436 effective words) took 0.2s, 429114 effective words/s\n",
      "2023-12-06 15:00:15,701 : INFO : EPOCH 19: training on 99524 raw words (65693 effective words) took 0.2s, 429029 effective words/s\n",
      "2023-12-06 15:00:15,856 : INFO : EPOCH 20: training on 99524 raw words (65502 effective words) took 0.2s, 435432 effective words/s\n",
      "2023-12-06 15:00:16,013 : INFO : EPOCH 21: training on 99524 raw words (65641 effective words) took 0.2s, 430472 effective words/s\n",
      "2023-12-06 15:00:16,181 : INFO : EPOCH 22: training on 99524 raw words (65617 effective words) took 0.2s, 402869 effective words/s\n",
      "2023-12-06 15:00:16,343 : INFO : EPOCH 23: training on 99524 raw words (65585 effective words) took 0.2s, 415422 effective words/s\n",
      "2023-12-06 15:00:16,502 : INFO : EPOCH 24: training on 99524 raw words (65597 effective words) took 0.2s, 426097 effective words/s\n",
      "2023-12-06 15:00:16,658 : INFO : EPOCH 25: training on 99524 raw words (65511 effective words) took 0.2s, 429916 effective words/s\n",
      "2023-12-06 15:00:16,812 : INFO : EPOCH 26: training on 99524 raw words (65602 effective words) took 0.1s, 438756 effective words/s\n",
      "2023-12-06 15:00:16,976 : INFO : EPOCH 27: training on 99524 raw words (65519 effective words) took 0.2s, 415263 effective words/s\n",
      "2023-12-06 15:00:17,138 : INFO : EPOCH 28: training on 99524 raw words (65561 effective words) took 0.2s, 414751 effective words/s\n",
      "2023-12-06 15:00:17,301 : INFO : EPOCH 29: training on 99524 raw words (65446 effective words) took 0.2s, 415275 effective words/s\n",
      "2023-12-06 15:00:17,458 : INFO : EPOCH 30: training on 99524 raw words (65626 effective words) took 0.2s, 428283 effective words/s\n",
      "2023-12-06 15:00:17,616 : INFO : EPOCH 31: training on 99524 raw words (65563 effective words) took 0.2s, 428389 effective words/s\n",
      "2023-12-06 15:00:17,771 : INFO : EPOCH 32: training on 99524 raw words (65471 effective words) took 0.2s, 433238 effective words/s\n",
      "2023-12-06 15:00:17,928 : INFO : EPOCH 33: training on 99524 raw words (65576 effective words) took 0.2s, 431396 effective words/s\n",
      "2023-12-06 15:00:18,086 : INFO : EPOCH 34: training on 99524 raw words (65619 effective words) took 0.2s, 426982 effective words/s\n",
      "2023-12-06 15:00:18,244 : INFO : EPOCH 35: training on 99524 raw words (65590 effective words) took 0.2s, 426251 effective words/s\n",
      "2023-12-06 15:00:18,408 : INFO : EPOCH 36: training on 99524 raw words (65493 effective words) took 0.2s, 409632 effective words/s\n",
      "2023-12-06 15:00:18,565 : INFO : EPOCH 37: training on 99524 raw words (65474 effective words) took 0.2s, 429003 effective words/s\n",
      "2023-12-06 15:00:18,718 : INFO : EPOCH 38: training on 99524 raw words (65532 effective words) took 0.1s, 443108 effective words/s\n",
      "2023-12-06 15:00:18,874 : INFO : EPOCH 39: training on 99524 raw words (65492 effective words) took 0.2s, 433209 effective words/s\n",
      "2023-12-06 15:00:19,027 : INFO : EPOCH 40: training on 99524 raw words (65519 effective words) took 0.1s, 439690 effective words/s\n",
      "2023-12-06 15:00:19,182 : INFO : EPOCH 41: training on 99524 raw words (65585 effective words) took 0.2s, 436725 effective words/s\n",
      "2023-12-06 15:00:19,335 : INFO : EPOCH 42: training on 99524 raw words (65717 effective words) took 0.1s, 442174 effective words/s\n",
      "2023-12-06 15:00:19,490 : INFO : EPOCH 43: training on 99524 raw words (65747 effective words) took 0.2s, 435526 effective words/s\n",
      "2023-12-06 15:00:19,656 : INFO : EPOCH 44: training on 99524 raw words (65613 effective words) took 0.2s, 407621 effective words/s\n",
      "2023-12-06 15:00:19,813 : INFO : EPOCH 45: training on 99524 raw words (65483 effective words) took 0.2s, 426887 effective words/s\n",
      "2023-12-06 15:00:19,971 : INFO : EPOCH 46: training on 99524 raw words (65495 effective words) took 0.2s, 428632 effective words/s\n",
      "2023-12-06 15:00:20,130 : INFO : EPOCH 47: training on 99524 raw words (65516 effective words) took 0.2s, 425477 effective words/s\n",
      "2023-12-06 15:00:20,286 : INFO : EPOCH 48: training on 99524 raw words (65729 effective words) took 0.2s, 432304 effective words/s\n",
      "2023-12-06 15:00:20,444 : INFO : EPOCH 49: training on 99524 raw words (65558 effective words) took 0.2s, 427646 effective words/s\n",
      "2023-12-06 15:00:20,445 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3278158 effective words) took 7.9s, 413832 effective words/s', 'datetime': '2023-12-06T15:00:20.445275', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:00:20,445 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:00:20.445275', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 63%|   | 305/486 [46:42<28:08,  9.33s/it]2023-12-06 15:00:23,916 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:00:23,917 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:00:23,940 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:00:23,941 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:00:23,947 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:00:23.947879', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:00:23,948 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:00:23.948885', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:00:23,957 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:00:23,957 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:00:23,958 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:00:23.958719', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:00:23,968 : INFO : estimated required memory for 1966 words and 100 dimensions: 5143600 bytes\n",
      "2023-12-06 15:00:23,969 : INFO : resetting layer weights\n",
      "2023-12-06 15:00:23,972 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:00:23.972288', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:00:24,125 : INFO : EPOCH 0: training on 99524 raw words (65689 effective words) took 0.1s, 442163 effective words/s\n",
      "2023-12-06 15:00:24,299 : INFO : EPOCH 1: training on 99524 raw words (65631 effective words) took 0.2s, 386189 effective words/s\n",
      "2023-12-06 15:00:24,464 : INFO : EPOCH 2: training on 99524 raw words (65515 effective words) took 0.2s, 413880 effective words/s\n",
      "2023-12-06 15:00:24,616 : INFO : EPOCH 3: training on 99524 raw words (65355 effective words) took 0.1s, 440188 effective words/s\n",
      "2023-12-06 15:00:24,773 : INFO : EPOCH 4: training on 99524 raw words (65379 effective words) took 0.2s, 432341 effective words/s\n",
      "2023-12-06 15:00:24,932 : INFO : EPOCH 5: training on 99524 raw words (65469 effective words) took 0.2s, 424389 effective words/s\n",
      "2023-12-06 15:00:25,086 : INFO : EPOCH 6: training on 99524 raw words (65612 effective words) took 0.1s, 438465 effective words/s\n",
      "2023-12-06 15:00:25,242 : INFO : EPOCH 7: training on 99524 raw words (65453 effective words) took 0.2s, 432845 effective words/s\n",
      "2023-12-06 15:00:25,396 : INFO : EPOCH 8: training on 99524 raw words (65510 effective words) took 0.1s, 438373 effective words/s\n",
      "2023-12-06 15:00:25,562 : INFO : EPOCH 9: training on 99524 raw words (65583 effective words) took 0.2s, 407494 effective words/s\n",
      "2023-12-06 15:00:25,725 : INFO : EPOCH 10: training on 99524 raw words (65583 effective words) took 0.2s, 418931 effective words/s\n",
      "2023-12-06 15:00:25,884 : INFO : EPOCH 11: training on 99524 raw words (65523 effective words) took 0.2s, 423787 effective words/s\n",
      "2023-12-06 15:00:26,041 : INFO : EPOCH 12: training on 99524 raw words (65445 effective words) took 0.2s, 430924 effective words/s\n",
      "2023-12-06 15:00:26,197 : INFO : EPOCH 13: training on 99524 raw words (65576 effective words) took 0.2s, 429012 effective words/s\n",
      "2023-12-06 15:00:26,351 : INFO : EPOCH 14: training on 99524 raw words (65518 effective words) took 0.1s, 438269 effective words/s\n",
      "2023-12-06 15:00:26,505 : INFO : EPOCH 15: training on 99524 raw words (65744 effective words) took 0.1s, 440559 effective words/s\n",
      "2023-12-06 15:00:26,660 : INFO : EPOCH 16: training on 99524 raw words (65538 effective words) took 0.2s, 436512 effective words/s\n",
      "2023-12-06 15:00:26,821 : INFO : EPOCH 17: training on 99524 raw words (65438 effective words) took 0.2s, 417230 effective words/s\n",
      "2023-12-06 15:00:26,976 : INFO : EPOCH 18: training on 99524 raw words (65522 effective words) took 0.2s, 435105 effective words/s\n",
      "2023-12-06 15:00:27,135 : INFO : EPOCH 19: training on 99524 raw words (65533 effective words) took 0.2s, 424348 effective words/s\n",
      "2023-12-06 15:00:27,292 : INFO : EPOCH 20: training on 99524 raw words (65559 effective words) took 0.2s, 431645 effective words/s\n",
      "2023-12-06 15:00:27,445 : INFO : EPOCH 21: training on 99524 raw words (65538 effective words) took 0.1s, 441187 effective words/s\n",
      "2023-12-06 15:00:27,600 : INFO : EPOCH 22: training on 99524 raw words (65715 effective words) took 0.2s, 435689 effective words/s\n",
      "2023-12-06 15:00:27,753 : INFO : EPOCH 23: training on 99524 raw words (65618 effective words) took 0.1s, 439878 effective words/s\n",
      "2023-12-06 15:00:27,906 : INFO : EPOCH 24: training on 99524 raw words (65513 effective words) took 0.1s, 441388 effective words/s\n",
      "2023-12-06 15:00:28,066 : INFO : EPOCH 25: training on 99524 raw words (65557 effective words) took 0.2s, 421834 effective words/s\n",
      "2023-12-06 15:00:28,226 : INFO : EPOCH 26: training on 99524 raw words (65607 effective words) took 0.2s, 422732 effective words/s\n",
      "2023-12-06 15:00:28,381 : INFO : EPOCH 27: training on 99524 raw words (65776 effective words) took 0.2s, 437561 effective words/s\n",
      "2023-12-06 15:00:28,534 : INFO : EPOCH 28: training on 99524 raw words (65407 effective words) took 0.1s, 439405 effective words/s\n",
      "2023-12-06 15:00:28,689 : INFO : EPOCH 29: training on 99524 raw words (65530 effective words) took 0.2s, 436513 effective words/s\n",
      "2023-12-06 15:00:28,842 : INFO : EPOCH 30: training on 99524 raw words (65322 effective words) took 0.1s, 439567 effective words/s\n",
      "2023-12-06 15:00:28,997 : INFO : EPOCH 31: training on 99524 raw words (65489 effective words) took 0.2s, 435910 effective words/s\n",
      "2023-12-06 15:00:29,151 : INFO : EPOCH 32: training on 99524 raw words (65449 effective words) took 0.2s, 436096 effective words/s\n",
      "2023-12-06 15:00:29,314 : INFO : EPOCH 33: training on 99524 raw words (65551 effective words) took 0.2s, 412323 effective words/s\n",
      "2023-12-06 15:00:29,466 : INFO : EPOCH 34: training on 99524 raw words (65633 effective words) took 0.1s, 447143 effective words/s\n",
      "2023-12-06 15:00:29,620 : INFO : EPOCH 35: training on 99524 raw words (65632 effective words) took 0.2s, 437475 effective words/s\n",
      "2023-12-06 15:00:29,775 : INFO : EPOCH 36: training on 99524 raw words (65509 effective words) took 0.2s, 435563 effective words/s\n",
      "2023-12-06 15:00:29,930 : INFO : EPOCH 37: training on 99524 raw words (65474 effective words) took 0.2s, 433293 effective words/s\n",
      "2023-12-06 15:00:30,086 : INFO : EPOCH 38: training on 99524 raw words (65431 effective words) took 0.2s, 432142 effective words/s\n",
      "2023-12-06 15:00:30,242 : INFO : EPOCH 39: training on 99524 raw words (65515 effective words) took 0.2s, 433042 effective words/s\n",
      "2023-12-06 15:00:30,398 : INFO : EPOCH 40: training on 99524 raw words (65518 effective words) took 0.2s, 432817 effective words/s\n",
      "2023-12-06 15:00:30,559 : INFO : EPOCH 41: training on 99524 raw words (65679 effective words) took 0.2s, 416988 effective words/s\n",
      "2023-12-06 15:00:30,714 : INFO : EPOCH 42: training on 99524 raw words (65504 effective words) took 0.1s, 436870 effective words/s\n",
      "2023-12-06 15:00:30,871 : INFO : EPOCH 43: training on 99524 raw words (65524 effective words) took 0.2s, 430256 effective words/s\n",
      "2023-12-06 15:00:31,027 : INFO : EPOCH 44: training on 99524 raw words (65496 effective words) took 0.2s, 432649 effective words/s\n",
      "2023-12-06 15:00:31,181 : INFO : EPOCH 45: training on 99524 raw words (65382 effective words) took 0.1s, 436876 effective words/s\n",
      "2023-12-06 15:00:31,339 : INFO : EPOCH 46: training on 99524 raw words (65454 effective words) took 0.2s, 425130 effective words/s\n",
      "2023-12-06 15:00:31,500 : INFO : EPOCH 47: training on 99524 raw words (65506 effective words) took 0.2s, 420200 effective words/s\n",
      "2023-12-06 15:00:31,655 : INFO : EPOCH 48: training on 99524 raw words (65457 effective words) took 0.2s, 432530 effective words/s\n",
      "2023-12-06 15:00:31,810 : INFO : EPOCH 49: training on 99524 raw words (65625 effective words) took 0.1s, 437930 effective words/s\n",
      "2023-12-06 15:00:31,811 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276586 effective words) took 7.8s, 418035 effective words/s', 'datetime': '2023-12-06T15:00:31.811559', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:00:31,812 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:00:31.811559', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 63%|   | 306/486 [46:54<30:06, 10.03s/it]2023-12-06 15:00:35,593 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:00:35,594 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:00:35,616 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:00:35,617 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:00:35,624 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:00:35.624493', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:00:35,625 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:00:35.625493', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:00:35,633 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:00:35,634 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:00:35,634 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:00:35.634216', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:00:35,646 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 15:00:35,647 : INFO : resetting layer weights\n",
      "2023-12-06 15:00:35,649 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:00:35.649820', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:00:35,796 : INFO : EPOCH 0: training on 99524 raw words (62812 effective words) took 0.1s, 440298 effective words/s\n",
      "2023-12-06 15:00:35,966 : INFO : EPOCH 1: training on 99524 raw words (62850 effective words) took 0.2s, 384438 effective words/s\n",
      "2023-12-06 15:00:36,116 : INFO : EPOCH 2: training on 99524 raw words (62866 effective words) took 0.1s, 430308 effective words/s\n",
      "2023-12-06 15:00:36,263 : INFO : EPOCH 3: training on 99524 raw words (62481 effective words) took 0.1s, 439644 effective words/s\n",
      "2023-12-06 15:00:36,407 : INFO : EPOCH 4: training on 99524 raw words (62632 effective words) took 0.1s, 449105 effective words/s\n",
      "2023-12-06 15:00:36,555 : INFO : EPOCH 5: training on 99524 raw words (62734 effective words) took 0.1s, 438307 effective words/s\n",
      "2023-12-06 15:00:36,705 : INFO : EPOCH 6: training on 99524 raw words (62869 effective words) took 0.1s, 432061 effective words/s\n",
      "2023-12-06 15:00:36,852 : INFO : EPOCH 7: training on 99524 raw words (62750 effective words) took 0.1s, 437721 effective words/s\n",
      "2023-12-06 15:00:37,008 : INFO : EPOCH 8: training on 99524 raw words (62729 effective words) took 0.1s, 418195 effective words/s\n",
      "2023-12-06 15:00:37,153 : INFO : EPOCH 9: training on 99524 raw words (62707 effective words) took 0.1s, 443731 effective words/s\n",
      "2023-12-06 15:00:37,154 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627430 effective words) took 1.5s, 417190 effective words/s', 'datetime': '2023-12-06T15:00:37.154730', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:00:37,154 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:00:37.154730', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 63%|   | 307/486 [46:58<24:40,  8.27s/it]2023-12-06 15:00:39,742 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:00:39,742 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:00:39,763 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:00:39,764 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:00:39,770 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:00:39.770082', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:00:39,771 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:00:39.771084', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:00:39,778 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:00:39,779 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:00:39,780 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:00:39.780590', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:00:39,788 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 15:00:39,789 : INFO : resetting layer weights\n",
      "2023-12-06 15:00:39,791 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:00:39.791108', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:00:39,943 : INFO : EPOCH 0: training on 99524 raw words (62762 effective words) took 0.1s, 422366 effective words/s\n",
      "2023-12-06 15:00:40,114 : INFO : EPOCH 1: training on 99524 raw words (62734 effective words) took 0.2s, 378729 effective words/s\n",
      "2023-12-06 15:00:40,271 : INFO : EPOCH 2: training on 99524 raw words (62848 effective words) took 0.2s, 412847 effective words/s\n",
      "2023-12-06 15:00:40,431 : INFO : EPOCH 3: training on 99524 raw words (62626 effective words) took 0.2s, 403662 effective words/s\n",
      "2023-12-06 15:00:40,585 : INFO : EPOCH 4: training on 99524 raw words (62786 effective words) took 0.1s, 419672 effective words/s\n",
      "2023-12-06 15:00:40,741 : INFO : EPOCH 5: training on 99524 raw words (62639 effective words) took 0.2s, 413558 effective words/s\n",
      "2023-12-06 15:00:40,897 : INFO : EPOCH 6: training on 99524 raw words (62721 effective words) took 0.2s, 415703 effective words/s\n",
      "2023-12-06 15:00:41,057 : INFO : EPOCH 7: training on 99524 raw words (62581 effective words) took 0.2s, 400677 effective words/s\n",
      "2023-12-06 15:00:41,215 : INFO : EPOCH 8: training on 99524 raw words (62719 effective words) took 0.2s, 409349 effective words/s\n",
      "2023-12-06 15:00:41,370 : INFO : EPOCH 9: training on 99524 raw words (62691 effective words) took 0.2s, 415067 effective words/s\n",
      "2023-12-06 15:00:41,371 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627107 effective words) took 1.6s, 397054 effective words/s', 'datetime': '2023-12-06T15:00:41.371691', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:00:41,371 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:00:41.371691', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 63%|   | 308/486 [47:02<20:56,  7.06s/it]2023-12-06 15:00:43,989 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:00:43,990 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:00:44,009 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:00:44,010 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:00:44,017 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:00:44.017655', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:00:44,018 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:00:44.018656', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:00:44,024 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:00:44,025 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:00:44,025 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:00:44.025225', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:00:44,037 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 15:00:44,037 : INFO : resetting layer weights\n",
      "2023-12-06 15:00:44,040 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:00:44.040225', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:00:44,183 : INFO : EPOCH 0: training on 99524 raw words (62684 effective words) took 0.1s, 452808 effective words/s\n",
      "2023-12-06 15:00:44,347 : INFO : EPOCH 1: training on 99524 raw words (62692 effective words) took 0.2s, 391462 effective words/s\n",
      "2023-12-06 15:00:44,506 : INFO : EPOCH 2: training on 99524 raw words (62749 effective words) took 0.2s, 415609 effective words/s\n",
      "2023-12-06 15:00:44,661 : INFO : EPOCH 3: training on 99524 raw words (62656 effective words) took 0.1s, 417750 effective words/s\n",
      "2023-12-06 15:00:44,812 : INFO : EPOCH 4: training on 99524 raw words (62708 effective words) took 0.1s, 429310 effective words/s\n",
      "2023-12-06 15:00:44,959 : INFO : EPOCH 5: training on 99524 raw words (62734 effective words) took 0.1s, 437838 effective words/s\n",
      "2023-12-06 15:00:45,112 : INFO : EPOCH 6: training on 99524 raw words (62883 effective words) took 0.1s, 423066 effective words/s\n",
      "2023-12-06 15:00:45,261 : INFO : EPOCH 7: training on 99524 raw words (62777 effective words) took 0.1s, 434369 effective words/s\n",
      "2023-12-06 15:00:45,414 : INFO : EPOCH 8: training on 99524 raw words (62831 effective words) took 0.1s, 422795 effective words/s\n",
      "2023-12-06 15:00:45,573 : INFO : EPOCH 9: training on 99524 raw words (62655 effective words) took 0.2s, 406942 effective words/s\n",
      "2023-12-06 15:00:45,574 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627369 effective words) took 1.5s, 409065 effective words/s', 'datetime': '2023-12-06T15:00:45.574343', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:00:45,574 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:00:45.574343', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 64%|   | 309/486 [47:06<18:22,  6.23s/it]2023-12-06 15:00:48,266 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:00:48,267 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:00:48,288 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:00:48,289 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:00:48,294 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:00:48.293995', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:00:48,294 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:00:48.294995', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:00:48,300 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:00:48,300 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:00:48,301 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:00:48.301508', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:00:48,309 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 15:00:48,310 : INFO : resetting layer weights\n",
      "2023-12-06 15:00:48,312 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:00:48.312017', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:00:48,447 : INFO : EPOCH 0: training on 99524 raw words (62754 effective words) took 0.1s, 483226 effective words/s\n",
      "2023-12-06 15:00:48,614 : INFO : EPOCH 1: training on 99524 raw words (62860 effective words) took 0.2s, 387463 effective words/s\n",
      "2023-12-06 15:00:48,767 : INFO : EPOCH 2: training on 99524 raw words (62671 effective words) took 0.1s, 424261 effective words/s\n",
      "2023-12-06 15:00:48,913 : INFO : EPOCH 3: training on 99524 raw words (62684 effective words) took 0.1s, 445522 effective words/s\n",
      "2023-12-06 15:00:49,062 : INFO : EPOCH 4: training on 99524 raw words (62878 effective words) took 0.1s, 435051 effective words/s\n",
      "2023-12-06 15:00:49,211 : INFO : EPOCH 5: training on 99524 raw words (62725 effective words) took 0.1s, 436188 effective words/s\n",
      "2023-12-06 15:00:49,360 : INFO : EPOCH 6: training on 99524 raw words (62656 effective words) took 0.1s, 432561 effective words/s\n",
      "2023-12-06 15:00:49,510 : INFO : EPOCH 7: training on 99524 raw words (62617 effective words) took 0.1s, 432169 effective words/s\n",
      "2023-12-06 15:00:49,659 : INFO : EPOCH 8: training on 99524 raw words (62664 effective words) took 0.1s, 430175 effective words/s\n",
      "2023-12-06 15:00:49,814 : INFO : EPOCH 9: training on 99524 raw words (62864 effective words) took 0.2s, 417779 effective words/s\n",
      "2023-12-06 15:00:49,963 : INFO : EPOCH 10: training on 99524 raw words (62705 effective words) took 0.1s, 433492 effective words/s\n",
      "2023-12-06 15:00:50,112 : INFO : EPOCH 11: training on 99524 raw words (62752 effective words) took 0.1s, 435146 effective words/s\n",
      "2023-12-06 15:00:50,260 : INFO : EPOCH 12: training on 99524 raw words (62696 effective words) took 0.1s, 440114 effective words/s\n",
      "2023-12-06 15:00:50,405 : INFO : EPOCH 13: training on 99524 raw words (62633 effective words) took 0.1s, 441838 effective words/s\n",
      "2023-12-06 15:00:50,551 : INFO : EPOCH 14: training on 99524 raw words (62832 effective words) took 0.1s, 445549 effective words/s\n",
      "2023-12-06 15:00:50,700 : INFO : EPOCH 15: training on 99524 raw words (62770 effective words) took 0.1s, 437671 effective words/s\n",
      "2023-12-06 15:00:50,849 : INFO : EPOCH 16: training on 99524 raw words (62782 effective words) took 0.1s, 431804 effective words/s\n",
      "2023-12-06 15:00:51,006 : INFO : EPOCH 17: training on 99524 raw words (62716 effective words) took 0.2s, 412369 effective words/s\n",
      "2023-12-06 15:00:51,157 : INFO : EPOCH 18: training on 99524 raw words (62537 effective words) took 0.1s, 427941 effective words/s\n",
      "2023-12-06 15:00:51,309 : INFO : EPOCH 19: training on 99524 raw words (62775 effective words) took 0.1s, 422967 effective words/s\n",
      "2023-12-06 15:00:51,458 : INFO : EPOCH 20: training on 99524 raw words (62721 effective words) took 0.1s, 433454 effective words/s\n",
      "2023-12-06 15:00:51,610 : INFO : EPOCH 21: training on 99524 raw words (62747 effective words) took 0.1s, 427831 effective words/s\n",
      "2023-12-06 15:00:51,761 : INFO : EPOCH 22: training on 99524 raw words (62800 effective words) took 0.1s, 430797 effective words/s\n",
      "2023-12-06 15:00:51,909 : INFO : EPOCH 23: training on 99524 raw words (62819 effective words) took 0.1s, 434600 effective words/s\n",
      "2023-12-06 15:00:52,060 : INFO : EPOCH 24: training on 99524 raw words (62750 effective words) took 0.1s, 429392 effective words/s\n",
      "2023-12-06 15:00:52,215 : INFO : EPOCH 25: training on 99524 raw words (62827 effective words) took 0.2s, 416281 effective words/s\n",
      "2023-12-06 15:00:52,364 : INFO : EPOCH 26: training on 99524 raw words (62844 effective words) took 0.1s, 435088 effective words/s\n",
      "2023-12-06 15:00:52,509 : INFO : EPOCH 27: training on 99524 raw words (62848 effective words) took 0.1s, 449408 effective words/s\n",
      "2023-12-06 15:00:52,658 : INFO : EPOCH 28: training on 99524 raw words (62686 effective words) took 0.1s, 433277 effective words/s\n",
      "2023-12-06 15:00:52,808 : INFO : EPOCH 29: training on 99524 raw words (62964 effective words) took 0.1s, 434172 effective words/s\n",
      "2023-12-06 15:00:52,808 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1882577 effective words) took 4.5s, 418688 effective words/s', 'datetime': '2023-12-06T15:00:52.808874', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:00:52,809 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:00:52.809937', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 64%|   | 310/486 [47:14<19:22,  6.60s/it]2023-12-06 15:00:55,747 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:00:55,747 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:00:55,780 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:00:55,780 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:00:55,787 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:00:55.787427', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:00:55,788 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:00:55.788427', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:00:55,798 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:00:55,799 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:00:55,800 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:00:55.800480', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:00:55,814 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 15:00:55,815 : INFO : resetting layer weights\n",
      "2023-12-06 15:00:55,819 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:00:55.819181', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:00:55,981 : INFO : EPOCH 0: training on 99524 raw words (62832 effective words) took 0.2s, 397221 effective words/s\n",
      "2023-12-06 15:00:56,158 : INFO : EPOCH 1: training on 99524 raw words (62769 effective words) took 0.2s, 366696 effective words/s\n",
      "2023-12-06 15:00:56,318 : INFO : EPOCH 2: training on 99524 raw words (62660 effective words) took 0.2s, 411381 effective words/s\n",
      "2023-12-06 15:00:56,473 : INFO : EPOCH 3: training on 99524 raw words (62483 effective words) took 0.2s, 411104 effective words/s\n",
      "2023-12-06 15:00:56,629 : INFO : EPOCH 4: training on 99524 raw words (62716 effective words) took 0.2s, 416856 effective words/s\n",
      "2023-12-06 15:00:56,782 : INFO : EPOCH 5: training on 99524 raw words (62708 effective words) took 0.1s, 422162 effective words/s\n",
      "2023-12-06 15:00:56,936 : INFO : EPOCH 6: training on 99524 raw words (62633 effective words) took 0.2s, 415399 effective words/s\n",
      "2023-12-06 15:00:57,091 : INFO : EPOCH 7: training on 99524 raw words (62675 effective words) took 0.2s, 415269 effective words/s\n",
      "2023-12-06 15:00:57,247 : INFO : EPOCH 8: training on 99524 raw words (62627 effective words) took 0.2s, 414936 effective words/s\n",
      "2023-12-06 15:00:57,408 : INFO : EPOCH 9: training on 99524 raw words (62822 effective words) took 0.2s, 401146 effective words/s\n",
      "2023-12-06 15:00:57,563 : INFO : EPOCH 10: training on 99524 raw words (62758 effective words) took 0.2s, 416753 effective words/s\n",
      "2023-12-06 15:00:57,719 : INFO : EPOCH 11: training on 99524 raw words (62841 effective words) took 0.2s, 416207 effective words/s\n",
      "2023-12-06 15:00:57,874 : INFO : EPOCH 12: training on 99524 raw words (62740 effective words) took 0.2s, 415744 effective words/s\n",
      "2023-12-06 15:00:58,029 : INFO : EPOCH 13: training on 99524 raw words (62840 effective words) took 0.2s, 416896 effective words/s\n",
      "2023-12-06 15:00:58,187 : INFO : EPOCH 14: training on 99524 raw words (62730 effective words) took 0.2s, 409986 effective words/s\n",
      "2023-12-06 15:00:58,341 : INFO : EPOCH 15: training on 99524 raw words (62581 effective words) took 0.2s, 417165 effective words/s\n",
      "2023-12-06 15:00:58,503 : INFO : EPOCH 16: training on 99524 raw words (62689 effective words) took 0.2s, 402249 effective words/s\n",
      "2023-12-06 15:00:58,669 : INFO : EPOCH 17: training on 99524 raw words (62602 effective words) took 0.2s, 385275 effective words/s\n",
      "2023-12-06 15:00:58,824 : INFO : EPOCH 18: training on 99524 raw words (62630 effective words) took 0.2s, 416742 effective words/s\n",
      "2023-12-06 15:00:58,982 : INFO : EPOCH 19: training on 99524 raw words (62791 effective words) took 0.2s, 408668 effective words/s\n",
      "2023-12-06 15:00:59,140 : INFO : EPOCH 20: training on 99524 raw words (62870 effective words) took 0.2s, 412230 effective words/s\n",
      "2023-12-06 15:00:59,293 : INFO : EPOCH 21: training on 99524 raw words (62868 effective words) took 0.1s, 419573 effective words/s\n",
      "2023-12-06 15:00:59,448 : INFO : EPOCH 22: training on 99524 raw words (62686 effective words) took 0.1s, 419673 effective words/s\n",
      "2023-12-06 15:00:59,603 : INFO : EPOCH 23: training on 99524 raw words (62829 effective words) took 0.2s, 414262 effective words/s\n",
      "2023-12-06 15:00:59,759 : INFO : EPOCH 24: training on 99524 raw words (62684 effective words) took 0.2s, 414285 effective words/s\n",
      "2023-12-06 15:00:59,924 : INFO : EPOCH 25: training on 99524 raw words (62685 effective words) took 0.2s, 391211 effective words/s\n",
      "2023-12-06 15:01:00,082 : INFO : EPOCH 26: training on 99524 raw words (62817 effective words) took 0.2s, 408778 effective words/s\n",
      "2023-12-06 15:01:00,239 : INFO : EPOCH 27: training on 99524 raw words (62976 effective words) took 0.2s, 411963 effective words/s\n",
      "2023-12-06 15:01:00,398 : INFO : EPOCH 28: training on 99524 raw words (62735 effective words) took 0.2s, 407648 effective words/s\n",
      "2023-12-06 15:01:00,555 : INFO : EPOCH 29: training on 99524 raw words (62838 effective words) took 0.2s, 412701 effective words/s\n",
      "2023-12-06 15:01:00,556 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1882115 effective words) took 4.7s, 397370 effective words/s', 'datetime': '2023-12-06T15:01:00.556531', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:01:00,556 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:01:00.556531', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 64%|   | 311/486 [47:22<20:27,  7.01s/it]2023-12-06 15:01:04,015 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:01:04,016 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:01:04,038 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:01:04,038 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:01:04,045 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:01:04.045470', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:01:04,045 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:01:04.045470', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:01:04,053 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:01:04,054 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:01:04,055 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:01:04.055472', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:01:04,063 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 15:01:04,064 : INFO : resetting layer weights\n",
      "2023-12-06 15:01:04,067 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:01:04.067686', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:01:04,209 : INFO : EPOCH 0: training on 99524 raw words (62686 effective words) took 0.1s, 456263 effective words/s\n",
      "2023-12-06 15:01:04,383 : INFO : EPOCH 1: training on 99524 raw words (62639 effective words) took 0.2s, 368623 effective words/s\n",
      "2023-12-06 15:01:04,544 : INFO : EPOCH 2: training on 99524 raw words (62683 effective words) took 0.2s, 409653 effective words/s\n",
      "2023-12-06 15:01:04,693 : INFO : EPOCH 3: training on 99524 raw words (62617 effective words) took 0.1s, 431634 effective words/s\n",
      "2023-12-06 15:01:04,853 : INFO : EPOCH 4: training on 99524 raw words (62818 effective words) took 0.2s, 407969 effective words/s\n",
      "2023-12-06 15:01:05,007 : INFO : EPOCH 5: training on 99524 raw words (62657 effective words) took 0.2s, 416047 effective words/s\n",
      "2023-12-06 15:01:05,156 : INFO : EPOCH 6: training on 99524 raw words (62645 effective words) took 0.1s, 435146 effective words/s\n",
      "2023-12-06 15:01:05,309 : INFO : EPOCH 7: training on 99524 raw words (62726 effective words) took 0.1s, 424232 effective words/s\n",
      "2023-12-06 15:01:05,462 : INFO : EPOCH 8: training on 99524 raw words (62796 effective words) took 0.1s, 421097 effective words/s\n",
      "2023-12-06 15:01:05,627 : INFO : EPOCH 9: training on 99524 raw words (62765 effective words) took 0.2s, 392370 effective words/s\n",
      "2023-12-06 15:01:05,783 : INFO : EPOCH 10: training on 99524 raw words (62736 effective words) took 0.2s, 414498 effective words/s\n",
      "2023-12-06 15:01:05,938 : INFO : EPOCH 11: training on 99524 raw words (62788 effective words) took 0.2s, 417799 effective words/s\n",
      "2023-12-06 15:01:06,091 : INFO : EPOCH 12: training on 99524 raw words (62743 effective words) took 0.1s, 421649 effective words/s\n",
      "2023-12-06 15:01:06,244 : INFO : EPOCH 13: training on 99524 raw words (62762 effective words) took 0.1s, 420390 effective words/s\n",
      "2023-12-06 15:01:06,397 : INFO : EPOCH 14: training on 99524 raw words (62847 effective words) took 0.1s, 423491 effective words/s\n",
      "2023-12-06 15:01:06,561 : INFO : EPOCH 15: training on 99524 raw words (62734 effective words) took 0.2s, 395704 effective words/s\n",
      "2023-12-06 15:01:06,715 : INFO : EPOCH 16: training on 99524 raw words (62728 effective words) took 0.1s, 420046 effective words/s\n",
      "2023-12-06 15:01:06,885 : INFO : EPOCH 17: training on 99524 raw words (62724 effective words) took 0.2s, 378969 effective words/s\n",
      "2023-12-06 15:01:07,038 : INFO : EPOCH 18: training on 99524 raw words (62684 effective words) took 0.1s, 418929 effective words/s\n",
      "2023-12-06 15:01:07,192 : INFO : EPOCH 19: training on 99524 raw words (62869 effective words) took 0.1s, 422888 effective words/s\n",
      "2023-12-06 15:01:07,347 : INFO : EPOCH 20: training on 99524 raw words (62580 effective words) took 0.2s, 413313 effective words/s\n",
      "2023-12-06 15:01:07,502 : INFO : EPOCH 21: training on 99524 raw words (62827 effective words) took 0.1s, 420344 effective words/s\n",
      "2023-12-06 15:01:07,657 : INFO : EPOCH 22: training on 99524 raw words (62850 effective words) took 0.2s, 415845 effective words/s\n",
      "2023-12-06 15:01:07,813 : INFO : EPOCH 23: training on 99524 raw words (62639 effective words) took 0.2s, 414132 effective words/s\n",
      "2023-12-06 15:01:07,970 : INFO : EPOCH 24: training on 99524 raw words (62800 effective words) took 0.2s, 411797 effective words/s\n",
      "2023-12-06 15:01:08,133 : INFO : EPOCH 25: training on 99524 raw words (62582 effective words) took 0.2s, 393437 effective words/s\n",
      "2023-12-06 15:01:08,291 : INFO : EPOCH 26: training on 99524 raw words (62891 effective words) took 0.2s, 412932 effective words/s\n",
      "2023-12-06 15:01:08,446 : INFO : EPOCH 27: training on 99524 raw words (62805 effective words) took 0.2s, 415948 effective words/s\n",
      "2023-12-06 15:01:08,598 : INFO : EPOCH 28: training on 99524 raw words (62754 effective words) took 0.1s, 423552 effective words/s\n",
      "2023-12-06 15:01:08,752 : INFO : EPOCH 29: training on 99524 raw words (62815 effective words) took 0.2s, 418102 effective words/s\n",
      "2023-12-06 15:01:08,753 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1882190 effective words) took 4.7s, 401626 effective words/s', 'datetime': '2023-12-06T15:01:08.753886', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:01:08,754 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:01:08.754896', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 64%|   | 312/486 [47:30<21:29,  7.41s/it]2023-12-06 15:01:12,050 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:01:12,050 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:01:12,072 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:01:12,073 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:01:12,079 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:01:12.079256', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:01:12,080 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:01:12.080258', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:01:12,085 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:01:12,085 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:01:12,086 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:01:12.086906', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:01:12,098 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 15:01:12,099 : INFO : resetting layer weights\n",
      "2023-12-06 15:01:12,104 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:01:12.104134', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:01:12,249 : INFO : EPOCH 0: training on 99524 raw words (62633 effective words) took 0.1s, 443089 effective words/s\n",
      "2023-12-06 15:01:12,424 : INFO : EPOCH 1: training on 99524 raw words (62806 effective words) took 0.2s, 369084 effective words/s\n",
      "2023-12-06 15:01:12,578 : INFO : EPOCH 2: training on 99524 raw words (62811 effective words) took 0.1s, 425795 effective words/s\n",
      "2023-12-06 15:01:12,729 : INFO : EPOCH 3: training on 99524 raw words (62588 effective words) took 0.1s, 424416 effective words/s\n",
      "2023-12-06 15:01:12,881 : INFO : EPOCH 4: training on 99524 raw words (62765 effective words) took 0.1s, 424138 effective words/s\n",
      "2023-12-06 15:01:13,031 : INFO : EPOCH 5: training on 99524 raw words (62557 effective words) took 0.1s, 431571 effective words/s\n",
      "2023-12-06 15:01:13,180 : INFO : EPOCH 6: training on 99524 raw words (62767 effective words) took 0.1s, 433694 effective words/s\n",
      "2023-12-06 15:01:13,327 : INFO : EPOCH 7: training on 99524 raw words (62937 effective words) took 0.1s, 441183 effective words/s\n",
      "2023-12-06 15:01:13,475 : INFO : EPOCH 8: training on 99524 raw words (62725 effective words) took 0.1s, 437197 effective words/s\n",
      "2023-12-06 15:01:13,636 : INFO : EPOCH 9: training on 99524 raw words (62751 effective words) took 0.2s, 402080 effective words/s\n",
      "2023-12-06 15:01:13,788 : INFO : EPOCH 10: training on 99524 raw words (62776 effective words) took 0.1s, 425216 effective words/s\n",
      "2023-12-06 15:01:13,940 : INFO : EPOCH 11: training on 99524 raw words (62762 effective words) took 0.1s, 427208 effective words/s\n",
      "2023-12-06 15:01:14,088 : INFO : EPOCH 12: training on 99524 raw words (62670 effective words) took 0.1s, 434976 effective words/s\n",
      "2023-12-06 15:01:14,238 : INFO : EPOCH 13: training on 99524 raw words (62708 effective words) took 0.1s, 429810 effective words/s\n",
      "2023-12-06 15:01:14,388 : INFO : EPOCH 14: training on 99524 raw words (62729 effective words) took 0.1s, 431930 effective words/s\n",
      "2023-12-06 15:01:14,536 : INFO : EPOCH 15: training on 99524 raw words (62670 effective words) took 0.1s, 435598 effective words/s\n",
      "2023-12-06 15:01:14,685 : INFO : EPOCH 16: training on 99524 raw words (62757 effective words) took 0.1s, 433211 effective words/s\n",
      "2023-12-06 15:01:14,844 : INFO : EPOCH 17: training on 99524 raw words (62636 effective words) took 0.2s, 407411 effective words/s\n",
      "2023-12-06 15:01:14,996 : INFO : EPOCH 18: training on 99524 raw words (62821 effective words) took 0.1s, 424346 effective words/s\n",
      "2023-12-06 15:01:15,146 : INFO : EPOCH 19: training on 99524 raw words (62895 effective words) took 0.1s, 431494 effective words/s\n",
      "2023-12-06 15:01:15,294 : INFO : EPOCH 20: training on 99524 raw words (62697 effective words) took 0.1s, 437704 effective words/s\n",
      "2023-12-06 15:01:15,445 : INFO : EPOCH 21: training on 99524 raw words (62614 effective words) took 0.1s, 424427 effective words/s\n",
      "2023-12-06 15:01:15,595 : INFO : EPOCH 22: training on 99524 raw words (62762 effective words) took 0.1s, 433695 effective words/s\n",
      "2023-12-06 15:01:15,740 : INFO : EPOCH 23: training on 99524 raw words (62914 effective words) took 0.1s, 446126 effective words/s\n",
      "2023-12-06 15:01:15,892 : INFO : EPOCH 24: training on 99524 raw words (62879 effective words) took 0.1s, 424631 effective words/s\n",
      "2023-12-06 15:01:16,050 : INFO : EPOCH 25: training on 99524 raw words (62756 effective words) took 0.2s, 409125 effective words/s\n",
      "2023-12-06 15:01:16,204 : INFO : EPOCH 26: training on 99524 raw words (62878 effective words) took 0.1s, 422606 effective words/s\n",
      "2023-12-06 15:01:16,358 : INFO : EPOCH 27: training on 99524 raw words (62777 effective words) took 0.1s, 421119 effective words/s\n",
      "2023-12-06 15:01:16,509 : INFO : EPOCH 28: training on 99524 raw words (62793 effective words) took 0.1s, 428483 effective words/s\n",
      "2023-12-06 15:01:16,659 : INFO : EPOCH 29: training on 99524 raw words (62757 effective words) took 0.1s, 425689 effective words/s\n",
      "2023-12-06 15:01:16,808 : INFO : EPOCH 30: training on 99524 raw words (62777 effective words) took 0.1s, 436953 effective words/s\n",
      "2023-12-06 15:01:16,959 : INFO : EPOCH 31: training on 99524 raw words (62745 effective words) took 0.1s, 428333 effective words/s\n",
      "2023-12-06 15:01:17,109 : INFO : EPOCH 32: training on 99524 raw words (62755 effective words) took 0.1s, 431236 effective words/s\n",
      "2023-12-06 15:01:17,266 : INFO : EPOCH 33: training on 99524 raw words (62897 effective words) took 0.2s, 412345 effective words/s\n",
      "2023-12-06 15:01:17,414 : INFO : EPOCH 34: training on 99524 raw words (62680 effective words) took 0.1s, 437113 effective words/s\n",
      "2023-12-06 15:01:17,565 : INFO : EPOCH 35: training on 99524 raw words (62864 effective words) took 0.1s, 431658 effective words/s\n",
      "2023-12-06 15:01:17,715 : INFO : EPOCH 36: training on 99524 raw words (62752 effective words) took 0.1s, 432807 effective words/s\n",
      "2023-12-06 15:01:17,862 : INFO : EPOCH 37: training on 99524 raw words (62613 effective words) took 0.1s, 436142 effective words/s\n",
      "2023-12-06 15:01:18,013 : INFO : EPOCH 38: training on 99524 raw words (62465 effective words) took 0.1s, 426743 effective words/s\n",
      "2023-12-06 15:01:18,164 : INFO : EPOCH 39: training on 99524 raw words (62700 effective words) took 0.1s, 426821 effective words/s\n",
      "2023-12-06 15:01:18,317 : INFO : EPOCH 40: training on 99524 raw words (62583 effective words) took 0.1s, 422640 effective words/s\n",
      "2023-12-06 15:01:18,474 : INFO : EPOCH 41: training on 99524 raw words (62797 effective words) took 0.2s, 411344 effective words/s\n",
      "2023-12-06 15:01:18,622 : INFO : EPOCH 42: training on 99524 raw words (62893 effective words) took 0.1s, 439449 effective words/s\n",
      "2023-12-06 15:01:18,770 : INFO : EPOCH 43: training on 99524 raw words (62760 effective words) took 0.1s, 432946 effective words/s\n",
      "2023-12-06 15:01:18,922 : INFO : EPOCH 44: training on 99524 raw words (62679 effective words) took 0.1s, 425005 effective words/s\n",
      "2023-12-06 15:01:19,075 : INFO : EPOCH 45: training on 99524 raw words (62686 effective words) took 0.1s, 423724 effective words/s\n",
      "2023-12-06 15:01:19,226 : INFO : EPOCH 46: training on 99524 raw words (62695 effective words) took 0.1s, 427306 effective words/s\n",
      "2023-12-06 15:01:19,378 : INFO : EPOCH 47: training on 99524 raw words (62539 effective words) took 0.1s, 425500 effective words/s\n",
      "2023-12-06 15:01:19,527 : INFO : EPOCH 48: training on 99524 raw words (62750 effective words) took 0.1s, 432338 effective words/s\n",
      "2023-12-06 15:01:19,684 : INFO : EPOCH 49: training on 99524 raw words (62744 effective words) took 0.2s, 412099 effective words/s\n",
      "2023-12-06 15:01:19,685 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136965 effective words) took 7.6s, 413802 effective words/s', 'datetime': '2023-12-06T15:01:19.685362', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:01:19,686 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:01:19.686363', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 64%|   | 313/486 [47:41<24:21,  8.45s/it]2023-12-06 15:01:22,923 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:01:22,923 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:01:22,943 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:01:22,944 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:01:22,951 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:01:22.951660', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:01:22,952 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:01:22.952660', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:01:22,960 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:01:22,961 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:01:22,961 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:01:22.961660', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:01:22,970 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 15:01:22,970 : INFO : resetting layer weights\n",
      "2023-12-06 15:01:22,973 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:01:22.973659', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:01:23,112 : INFO : EPOCH 0: training on 99524 raw words (62628 effective words) took 0.1s, 466995 effective words/s\n",
      "2023-12-06 15:01:23,276 : INFO : EPOCH 1: training on 99524 raw words (62777 effective words) took 0.2s, 393484 effective words/s\n",
      "2023-12-06 15:01:23,443 : INFO : EPOCH 2: training on 99524 raw words (62775 effective words) took 0.2s, 390268 effective words/s\n",
      "2023-12-06 15:01:23,599 : INFO : EPOCH 3: training on 99524 raw words (62585 effective words) took 0.2s, 416556 effective words/s\n",
      "2023-12-06 15:01:23,752 : INFO : EPOCH 4: training on 99524 raw words (62776 effective words) took 0.1s, 421361 effective words/s\n",
      "2023-12-06 15:01:23,906 : INFO : EPOCH 5: training on 99524 raw words (62801 effective words) took 0.1s, 420105 effective words/s\n",
      "2023-12-06 15:01:24,060 : INFO : EPOCH 6: training on 99524 raw words (62891 effective words) took 0.1s, 419709 effective words/s\n",
      "2023-12-06 15:01:24,216 : INFO : EPOCH 7: training on 99524 raw words (62735 effective words) took 0.2s, 415199 effective words/s\n",
      "2023-12-06 15:01:24,369 : INFO : EPOCH 8: training on 99524 raw words (62738 effective words) took 0.1s, 422946 effective words/s\n",
      "2023-12-06 15:01:24,530 : INFO : EPOCH 9: training on 99524 raw words (62640 effective words) took 0.2s, 400373 effective words/s\n",
      "2023-12-06 15:01:24,680 : INFO : EPOCH 10: training on 99524 raw words (62680 effective words) took 0.1s, 431008 effective words/s\n",
      "2023-12-06 15:01:24,835 : INFO : EPOCH 11: training on 99524 raw words (62811 effective words) took 0.1s, 418790 effective words/s\n",
      "2023-12-06 15:01:24,992 : INFO : EPOCH 12: training on 99524 raw words (62739 effective words) took 0.2s, 411508 effective words/s\n",
      "2023-12-06 15:01:25,146 : INFO : EPOCH 13: training on 99524 raw words (62677 effective words) took 0.1s, 418843 effective words/s\n",
      "2023-12-06 15:01:25,298 : INFO : EPOCH 14: training on 99524 raw words (62804 effective words) took 0.1s, 425351 effective words/s\n",
      "2023-12-06 15:01:25,451 : INFO : EPOCH 15: training on 99524 raw words (62727 effective words) took 0.1s, 420463 effective words/s\n",
      "2023-12-06 15:01:25,606 : INFO : EPOCH 16: training on 99524 raw words (62718 effective words) took 0.1s, 419666 effective words/s\n",
      "2023-12-06 15:01:25,767 : INFO : EPOCH 17: training on 99524 raw words (62689 effective words) took 0.2s, 397114 effective words/s\n",
      "2023-12-06 15:01:25,919 : INFO : EPOCH 18: training on 99524 raw words (62645 effective words) took 0.1s, 427937 effective words/s\n",
      "2023-12-06 15:01:26,075 : INFO : EPOCH 19: training on 99524 raw words (62852 effective words) took 0.2s, 413961 effective words/s\n",
      "2023-12-06 15:01:26,230 : INFO : EPOCH 20: training on 99524 raw words (62816 effective words) took 0.2s, 415902 effective words/s\n",
      "2023-12-06 15:01:26,386 : INFO : EPOCH 21: training on 99524 raw words (62903 effective words) took 0.2s, 416752 effective words/s\n",
      "2023-12-06 15:01:26,543 : INFO : EPOCH 22: training on 99524 raw words (62724 effective words) took 0.2s, 412359 effective words/s\n",
      "2023-12-06 15:01:26,697 : INFO : EPOCH 23: training on 99524 raw words (62714 effective words) took 0.1s, 419489 effective words/s\n",
      "2023-12-06 15:01:26,856 : INFO : EPOCH 24: training on 99524 raw words (62696 effective words) took 0.2s, 405405 effective words/s\n",
      "2023-12-06 15:01:27,016 : INFO : EPOCH 25: training on 99524 raw words (62674 effective words) took 0.2s, 402131 effective words/s\n",
      "2023-12-06 15:01:27,172 : INFO : EPOCH 26: training on 99524 raw words (62800 effective words) took 0.2s, 414918 effective words/s\n",
      "2023-12-06 15:01:27,327 : INFO : EPOCH 27: training on 99524 raw words (62897 effective words) took 0.2s, 417818 effective words/s\n",
      "2023-12-06 15:01:27,481 : INFO : EPOCH 28: training on 99524 raw words (62748 effective words) took 0.1s, 419504 effective words/s\n",
      "2023-12-06 15:01:27,636 : INFO : EPOCH 29: training on 99524 raw words (62738 effective words) took 0.2s, 415958 effective words/s\n",
      "2023-12-06 15:01:27,794 : INFO : EPOCH 30: training on 99524 raw words (62780 effective words) took 0.2s, 409959 effective words/s\n",
      "2023-12-06 15:01:27,947 : INFO : EPOCH 31: training on 99524 raw words (62676 effective words) took 0.1s, 421762 effective words/s\n",
      "2023-12-06 15:01:28,101 : INFO : EPOCH 32: training on 99524 raw words (62669 effective words) took 0.1s, 419994 effective words/s\n",
      "2023-12-06 15:01:28,265 : INFO : EPOCH 33: training on 99524 raw words (62746 effective words) took 0.2s, 391336 effective words/s\n",
      "2023-12-06 15:01:28,417 : INFO : EPOCH 34: training on 99524 raw words (62891 effective words) took 0.1s, 425839 effective words/s\n",
      "2023-12-06 15:01:28,575 : INFO : EPOCH 35: training on 99524 raw words (62665 effective words) took 0.2s, 409418 effective words/s\n",
      "2023-12-06 15:01:28,727 : INFO : EPOCH 36: training on 99524 raw words (62758 effective words) took 0.1s, 427293 effective words/s\n",
      "2023-12-06 15:01:28,880 : INFO : EPOCH 37: training on 99524 raw words (62791 effective words) took 0.1s, 422582 effective words/s\n",
      "2023-12-06 15:01:29,034 : INFO : EPOCH 38: training on 99524 raw words (62743 effective words) took 0.1s, 420577 effective words/s\n",
      "2023-12-06 15:01:29,188 : INFO : EPOCH 39: training on 99524 raw words (62752 effective words) took 0.1s, 418842 effective words/s\n",
      "2023-12-06 15:01:29,347 : INFO : EPOCH 40: training on 99524 raw words (62734 effective words) took 0.2s, 405086 effective words/s\n",
      "2023-12-06 15:01:29,502 : INFO : EPOCH 41: training on 99524 raw words (62745 effective words) took 0.2s, 418137 effective words/s\n",
      "2023-12-06 15:01:29,659 : INFO : EPOCH 42: training on 99524 raw words (62683 effective words) took 0.2s, 410993 effective words/s\n",
      "2023-12-06 15:01:29,814 : INFO : EPOCH 43: training on 99524 raw words (62716 effective words) took 0.2s, 417594 effective words/s\n",
      "2023-12-06 15:01:29,968 : INFO : EPOCH 44: training on 99524 raw words (62771 effective words) took 0.1s, 419779 effective words/s\n",
      "2023-12-06 15:01:30,123 : INFO : EPOCH 45: training on 99524 raw words (62685 effective words) took 0.2s, 414655 effective words/s\n",
      "2023-12-06 15:01:30,277 : INFO : EPOCH 46: training on 99524 raw words (62732 effective words) took 0.1s, 420529 effective words/s\n",
      "2023-12-06 15:01:30,433 : INFO : EPOCH 47: training on 99524 raw words (62710 effective words) took 0.2s, 413917 effective words/s\n",
      "2023-12-06 15:01:30,594 : INFO : EPOCH 48: training on 99524 raw words (62724 effective words) took 0.2s, 399642 effective words/s\n",
      "2023-12-06 15:01:30,749 : INFO : EPOCH 49: training on 99524 raw words (62718 effective words) took 0.1s, 418398 effective words/s\n",
      "2023-12-06 15:01:30,750 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3137087 effective words) took 7.8s, 403448 effective words/s', 'datetime': '2023-12-06T15:01:30.750405', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:01:30,750 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:01:30.750405', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 65%|   | 314/486 [47:52<26:45,  9.34s/it]2023-12-06 15:01:34,332 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:01:34,333 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:01:34,352 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:01:34,353 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:01:34,358 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:01:34.358727', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:01:34,359 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:01:34.359727', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:01:34,365 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:01:34,365 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:01:34,366 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:01:34.366693', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:01:34,375 : INFO : estimated required memory for 1509 words and 100 dimensions: 4549500 bytes\n",
      "2023-12-06 15:01:34,375 : INFO : resetting layer weights\n",
      "2023-12-06 15:01:34,377 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:01:34.377914', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:01:34,517 : INFO : EPOCH 0: training on 99524 raw words (62761 effective words) took 0.1s, 461558 effective words/s\n",
      "2023-12-06 15:01:34,690 : INFO : EPOCH 1: training on 99524 raw words (62785 effective words) took 0.2s, 377063 effective words/s\n",
      "2023-12-06 15:01:34,858 : INFO : EPOCH 2: training on 99524 raw words (62752 effective words) took 0.2s, 384418 effective words/s\n",
      "2023-12-06 15:01:35,013 : INFO : EPOCH 3: training on 99524 raw words (62614 effective words) took 0.1s, 418482 effective words/s\n",
      "2023-12-06 15:01:35,207 : INFO : EPOCH 4: training on 99524 raw words (62817 effective words) took 0.2s, 331818 effective words/s\n",
      "2023-12-06 15:01:35,386 : INFO : EPOCH 5: training on 99524 raw words (62625 effective words) took 0.2s, 359324 effective words/s\n",
      "2023-12-06 15:01:35,549 : INFO : EPOCH 6: training on 99524 raw words (62789 effective words) took 0.2s, 398709 effective words/s\n",
      "2023-12-06 15:01:35,713 : INFO : EPOCH 7: training on 99524 raw words (62754 effective words) took 0.2s, 393636 effective words/s\n",
      "2023-12-06 15:01:35,893 : INFO : EPOCH 8: training on 99524 raw words (62747 effective words) took 0.2s, 357137 effective words/s\n",
      "2023-12-06 15:01:36,057 : INFO : EPOCH 9: training on 99524 raw words (62648 effective words) took 0.2s, 394940 effective words/s\n",
      "2023-12-06 15:01:36,210 : INFO : EPOCH 10: training on 99524 raw words (62592 effective words) took 0.1s, 419836 effective words/s\n",
      "2023-12-06 15:01:36,364 : INFO : EPOCH 11: training on 99524 raw words (62842 effective words) took 0.1s, 420791 effective words/s\n",
      "2023-12-06 15:01:36,526 : INFO : EPOCH 12: training on 99524 raw words (62736 effective words) took 0.2s, 397103 effective words/s\n",
      "2023-12-06 15:01:36,684 : INFO : EPOCH 13: training on 99524 raw words (62693 effective words) took 0.2s, 407983 effective words/s\n",
      "2023-12-06 15:01:36,852 : INFO : EPOCH 14: training on 99524 raw words (62874 effective words) took 0.2s, 387252 effective words/s\n",
      "2023-12-06 15:01:37,032 : INFO : EPOCH 15: training on 99524 raw words (62708 effective words) took 0.2s, 357911 effective words/s\n",
      "2023-12-06 15:01:37,196 : INFO : EPOCH 16: training on 99524 raw words (62700 effective words) took 0.2s, 394668 effective words/s\n",
      "2023-12-06 15:01:37,365 : INFO : EPOCH 17: training on 99524 raw words (62677 effective words) took 0.2s, 380036 effective words/s\n",
      "2023-12-06 15:01:37,531 : INFO : EPOCH 18: training on 99524 raw words (62665 effective words) took 0.2s, 389630 effective words/s\n",
      "2023-12-06 15:01:37,701 : INFO : EPOCH 19: training on 99524 raw words (62998 effective words) took 0.2s, 378475 effective words/s\n",
      "2023-12-06 15:01:37,875 : INFO : EPOCH 20: training on 99524 raw words (62766 effective words) took 0.2s, 375756 effective words/s\n",
      "2023-12-06 15:01:38,040 : INFO : EPOCH 21: training on 99524 raw words (62857 effective words) took 0.2s, 391588 effective words/s\n",
      "2023-12-06 15:01:38,195 : INFO : EPOCH 22: training on 99524 raw words (62843 effective words) took 0.2s, 416079 effective words/s\n",
      "2023-12-06 15:01:38,389 : INFO : EPOCH 23: training on 99524 raw words (62815 effective words) took 0.2s, 333319 effective words/s\n",
      "2023-12-06 15:01:38,554 : INFO : EPOCH 24: training on 99524 raw words (62754 effective words) took 0.2s, 388091 effective words/s\n",
      "2023-12-06 15:01:38,717 : INFO : EPOCH 25: training on 99524 raw words (62756 effective words) took 0.2s, 400275 effective words/s\n",
      "2023-12-06 15:01:38,877 : INFO : EPOCH 26: training on 99524 raw words (62625 effective words) took 0.2s, 401378 effective words/s\n",
      "2023-12-06 15:01:39,040 : INFO : EPOCH 27: training on 99524 raw words (62861 effective words) took 0.2s, 396651 effective words/s\n",
      "2023-12-06 15:01:39,216 : INFO : EPOCH 28: training on 99524 raw words (62635 effective words) took 0.2s, 365750 effective words/s\n",
      "2023-12-06 15:01:39,382 : INFO : EPOCH 29: training on 99524 raw words (62806 effective words) took 0.2s, 391155 effective words/s\n",
      "2023-12-06 15:01:39,558 : INFO : EPOCH 30: training on 99524 raw words (62667 effective words) took 0.2s, 368044 effective words/s\n",
      "2023-12-06 15:01:39,728 : INFO : EPOCH 31: training on 99524 raw words (62638 effective words) took 0.2s, 378207 effective words/s\n",
      "2023-12-06 15:01:39,890 : INFO : EPOCH 32: training on 99524 raw words (62743 effective words) took 0.2s, 400099 effective words/s\n",
      "2023-12-06 15:01:40,050 : INFO : EPOCH 33: training on 99524 raw words (62729 effective words) took 0.2s, 402810 effective words/s\n",
      "2023-12-06 15:01:40,185 : INFO : EPOCH 34: training on 99524 raw words (62825 effective words) took 0.1s, 482555 effective words/s\n",
      "2023-12-06 15:01:40,319 : INFO : EPOCH 35: training on 99524 raw words (62763 effective words) took 0.1s, 483838 effective words/s\n",
      "2023-12-06 15:01:40,454 : INFO : EPOCH 36: training on 99524 raw words (62621 effective words) took 0.1s, 478121 effective words/s\n",
      "2023-12-06 15:01:40,609 : INFO : EPOCH 37: training on 99524 raw words (62583 effective words) took 0.1s, 417555 effective words/s\n",
      "2023-12-06 15:01:40,734 : INFO : EPOCH 38: training on 99524 raw words (62599 effective words) took 0.1s, 514670 effective words/s\n",
      "2023-12-06 15:01:40,880 : INFO : EPOCH 39: training on 99524 raw words (62710 effective words) took 0.1s, 476165 effective words/s\n",
      "2023-12-06 15:01:41,015 : INFO : EPOCH 40: training on 99524 raw words (62714 effective words) took 0.1s, 477444 effective words/s\n",
      "2023-12-06 15:01:41,151 : INFO : EPOCH 41: training on 99524 raw words (62680 effective words) took 0.1s, 480176 effective words/s\n",
      "2023-12-06 15:01:41,287 : INFO : EPOCH 42: training on 99524 raw words (62941 effective words) took 0.1s, 475993 effective words/s\n",
      "2023-12-06 15:01:41,422 : INFO : EPOCH 43: training on 99524 raw words (62828 effective words) took 0.1s, 480739 effective words/s\n",
      "2023-12-06 15:01:41,565 : INFO : EPOCH 44: training on 99524 raw words (62694 effective words) took 0.1s, 453545 effective words/s\n",
      "2023-12-06 15:01:41,697 : INFO : EPOCH 45: training on 99524 raw words (62726 effective words) took 0.1s, 491712 effective words/s\n",
      "2023-12-06 15:01:41,836 : INFO : EPOCH 46: training on 99524 raw words (62668 effective words) took 0.1s, 465965 effective words/s\n",
      "2023-12-06 15:01:41,971 : INFO : EPOCH 47: training on 99524 raw words (62708 effective words) took 0.1s, 480312 effective words/s\n",
      "2023-12-06 15:01:42,107 : INFO : EPOCH 48: training on 99524 raw words (62761 effective words) took 0.1s, 476250 effective words/s\n",
      "2023-12-06 15:01:42,244 : INFO : EPOCH 49: training on 99524 raw words (62710 effective words) took 0.1s, 471874 effective words/s\n",
      "2023-12-06 15:01:42,245 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136803 effective words) took 7.9s, 398694 effective words/s', 'datetime': '2023-12-06T15:01:42.245758', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:01:42,246 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:01:42.246760', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 65%|   | 315/486 [48:04<28:35, 10.03s/it]2023-12-06 15:01:45,985 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:01:45,986 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:01:46,007 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:01:46,007 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:01:46,011 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:01:46.011837', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:01:46,011 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:01:46.011837', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:01:46,017 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:01:46,017 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:01:46,018 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:01:46.018024', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:01:46,024 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 15:01:46,025 : INFO : resetting layer weights\n",
      "2023-12-06 15:01:46,027 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:01:46.027029', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:01:46,153 : INFO : EPOCH 0: training on 99524 raw words (60354 effective words) took 0.1s, 497421 effective words/s\n",
      "2023-12-06 15:01:46,347 : INFO : EPOCH 1: training on 99524 raw words (60300 effective words) took 0.2s, 352753 effective words/s\n",
      "2023-12-06 15:01:46,480 : INFO : EPOCH 2: training on 99524 raw words (60518 effective words) took 0.1s, 470247 effective words/s\n",
      "2023-12-06 15:01:46,613 : INFO : EPOCH 3: training on 99524 raw words (60170 effective words) took 0.1s, 470471 effective words/s\n",
      "2023-12-06 15:01:46,745 : INFO : EPOCH 4: training on 99524 raw words (60386 effective words) took 0.1s, 472432 effective words/s\n",
      "2023-12-06 15:01:46,878 : INFO : EPOCH 5: training on 99524 raw words (60336 effective words) took 0.1s, 469722 effective words/s\n",
      "2023-12-06 15:01:47,004 : INFO : EPOCH 6: training on 99524 raw words (60438 effective words) took 0.1s, 499369 effective words/s\n",
      "2023-12-06 15:01:47,160 : INFO : EPOCH 7: training on 99524 raw words (60273 effective words) took 0.2s, 397718 effective words/s\n",
      "2023-12-06 15:01:47,307 : INFO : EPOCH 8: training on 99524 raw words (60444 effective words) took 0.1s, 422876 effective words/s\n",
      "2023-12-06 15:01:47,455 : INFO : EPOCH 9: training on 99524 raw words (60300 effective words) took 0.1s, 419250 effective words/s\n",
      "2023-12-06 15:01:47,456 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603519 effective words) took 1.4s, 422307 effective words/s', 'datetime': '2023-12-06T15:01:47.456582', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:01:47,457 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:01:47.457583', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 65%|   | 316/486 [48:08<23:23,  8.25s/it]2023-12-06 15:01:50,089 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:01:50,090 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:01:50,113 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:01:50,113 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:01:50,118 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:01:50.117732', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:01:50,118 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:01:50.118732', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:01:50,123 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:01:50,123 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:01:50,124 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:01:50.124733', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:01:50,131 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 15:01:50,131 : INFO : resetting layer weights\n",
      "2023-12-06 15:01:50,134 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:01:50.134417', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:01:50,263 : INFO : EPOCH 0: training on 99524 raw words (60346 effective words) took 0.1s, 485362 effective words/s\n",
      "2023-12-06 15:01:50,426 : INFO : EPOCH 1: training on 99524 raw words (60369 effective words) took 0.2s, 383677 effective words/s\n",
      "2023-12-06 15:01:50,558 : INFO : EPOCH 2: training on 99524 raw words (60433 effective words) took 0.1s, 474466 effective words/s\n",
      "2023-12-06 15:01:50,690 : INFO : EPOCH 3: training on 99524 raw words (60248 effective words) took 0.1s, 473834 effective words/s\n",
      "2023-12-06 15:01:50,822 : INFO : EPOCH 4: training on 99524 raw words (60424 effective words) took 0.1s, 471963 effective words/s\n",
      "2023-12-06 15:01:50,952 : INFO : EPOCH 5: training on 99524 raw words (60472 effective words) took 0.1s, 480653 effective words/s\n",
      "2023-12-06 15:01:51,082 : INFO : EPOCH 6: training on 99524 raw words (60332 effective words) took 0.1s, 477631 effective words/s\n",
      "2023-12-06 15:01:51,230 : INFO : EPOCH 7: training on 99524 raw words (60458 effective words) took 0.1s, 421799 effective words/s\n",
      "2023-12-06 15:01:51,362 : INFO : EPOCH 8: training on 99524 raw words (60521 effective words) took 0.1s, 473602 effective words/s\n",
      "2023-12-06 15:01:51,492 : INFO : EPOCH 9: training on 99524 raw words (60430 effective words) took 0.1s, 478666 effective words/s\n",
      "2023-12-06 15:01:51,493 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604033 effective words) took 1.4s, 444669 effective words/s', 'datetime': '2023-12-06T15:01:51.493629', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:01:51,494 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:01:51.494629', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 65%|   | 317/486 [48:12<19:35,  6.96s/it]2023-12-06 15:01:54,021 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:01:54,021 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:01:54,042 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:01:54,043 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:01:54,047 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:01:54.047146', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:01:54,048 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:01:54.048149', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:01:54,053 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:01:54,053 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:01:54,054 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:01:54.054326', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:01:54,060 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 15:01:54,061 : INFO : resetting layer weights\n",
      "2023-12-06 15:01:54,063 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:01:54.063348', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:01:54,187 : INFO : EPOCH 0: training on 99524 raw words (60462 effective words) took 0.1s, 501347 effective words/s\n",
      "2023-12-06 15:01:54,351 : INFO : EPOCH 1: training on 99524 raw words (60512 effective words) took 0.2s, 386821 effective words/s\n",
      "2023-12-06 15:01:54,486 : INFO : EPOCH 2: training on 99524 raw words (60386 effective words) took 0.1s, 465669 effective words/s\n",
      "2023-12-06 15:01:54,617 : INFO : EPOCH 3: training on 99524 raw words (60263 effective words) took 0.1s, 474643 effective words/s\n",
      "2023-12-06 15:01:54,746 : INFO : EPOCH 4: training on 99524 raw words (60273 effective words) took 0.1s, 481269 effective words/s\n",
      "2023-12-06 15:01:54,869 : INFO : EPOCH 5: training on 99524 raw words (60262 effective words) took 0.1s, 508280 effective words/s\n",
      "2023-12-06 15:01:54,999 : INFO : EPOCH 6: training on 99524 raw words (60435 effective words) took 0.1s, 479955 effective words/s\n",
      "2023-12-06 15:01:55,129 : INFO : EPOCH 7: training on 99524 raw words (60315 effective words) took 0.1s, 478535 effective words/s\n",
      "2023-12-06 15:01:55,252 : INFO : EPOCH 8: training on 99524 raw words (60429 effective words) took 0.1s, 508341 effective words/s\n",
      "2023-12-06 15:01:55,400 : INFO : EPOCH 9: training on 99524 raw words (60497 effective words) took 0.1s, 423833 effective words/s\n",
      "2023-12-06 15:01:55,401 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603834 effective words) took 1.3s, 451529 effective words/s', 'datetime': '2023-12-06T15:01:55.401259', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:01:55,401 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:01:55.401259', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 65%|   | 318/486 [48:16<16:57,  6.06s/it]2023-12-06 15:01:57,985 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:01:57,985 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:01:58,003 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:01:58,004 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:01:58,008 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:01:58.008696', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:01:58,009 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:01:58.009696', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:01:58,013 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:01:58,014 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:01:58,014 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:01:58.014695', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:01:58,021 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 15:01:58,021 : INFO : resetting layer weights\n",
      "2023-12-06 15:01:58,024 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:01:58.024694', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:01:58,149 : INFO : EPOCH 0: training on 99524 raw words (60451 effective words) took 0.1s, 500357 effective words/s\n",
      "2023-12-06 15:01:58,316 : INFO : EPOCH 1: training on 99524 raw words (60397 effective words) took 0.2s, 376666 effective words/s\n",
      "2023-12-06 15:01:58,450 : INFO : EPOCH 2: training on 99524 raw words (60530 effective words) took 0.1s, 474980 effective words/s\n",
      "2023-12-06 15:01:58,577 : INFO : EPOCH 3: training on 99524 raw words (60306 effective words) took 0.1s, 488701 effective words/s\n",
      "2023-12-06 15:01:58,708 : INFO : EPOCH 4: training on 99524 raw words (60385 effective words) took 0.1s, 475785 effective words/s\n",
      "2023-12-06 15:01:58,857 : INFO : EPOCH 5: training on 99524 raw words (60264 effective words) took 0.1s, 417789 effective words/s\n",
      "2023-12-06 15:01:59,005 : INFO : EPOCH 6: training on 99524 raw words (60226 effective words) took 0.1s, 417115 effective words/s\n",
      "2023-12-06 15:01:59,155 : INFO : EPOCH 7: training on 99524 raw words (60396 effective words) took 0.1s, 416278 effective words/s\n",
      "2023-12-06 15:01:59,304 : INFO : EPOCH 8: training on 99524 raw words (60315 effective words) took 0.1s, 416453 effective words/s\n",
      "2023-12-06 15:01:59,458 : INFO : EPOCH 9: training on 99524 raw words (60372 effective words) took 0.1s, 405234 effective words/s\n",
      "2023-12-06 15:01:59,606 : INFO : EPOCH 10: training on 99524 raw words (60379 effective words) took 0.1s, 420604 effective words/s\n",
      "2023-12-06 15:01:59,754 : INFO : EPOCH 11: training on 99524 raw words (60455 effective words) took 0.1s, 418768 effective words/s\n",
      "2023-12-06 15:01:59,898 : INFO : EPOCH 12: training on 99524 raw words (60451 effective words) took 0.1s, 433626 effective words/s\n",
      "2023-12-06 15:02:00,048 : INFO : EPOCH 13: training on 99524 raw words (60353 effective words) took 0.1s, 415316 effective words/s\n",
      "2023-12-06 15:02:00,197 : INFO : EPOCH 14: training on 99524 raw words (60455 effective words) took 0.1s, 415634 effective words/s\n",
      "2023-12-06 15:02:00,342 : INFO : EPOCH 15: training on 99524 raw words (60288 effective words) took 0.1s, 429264 effective words/s\n",
      "2023-12-06 15:02:00,492 : INFO : EPOCH 16: training on 99524 raw words (60431 effective words) took 0.1s, 419372 effective words/s\n",
      "2023-12-06 15:02:00,646 : INFO : EPOCH 17: training on 99524 raw words (60520 effective words) took 0.1s, 404208 effective words/s\n",
      "2023-12-06 15:02:00,794 : INFO : EPOCH 18: training on 99524 raw words (60401 effective words) took 0.1s, 419768 effective words/s\n",
      "2023-12-06 15:02:00,942 : INFO : EPOCH 19: training on 99524 raw words (60404 effective words) took 0.1s, 421447 effective words/s\n",
      "2023-12-06 15:02:01,089 : INFO : EPOCH 20: training on 99524 raw words (60377 effective words) took 0.1s, 423853 effective words/s\n",
      "2023-12-06 15:02:01,234 : INFO : EPOCH 21: training on 99524 raw words (60325 effective words) took 0.1s, 427202 effective words/s\n",
      "2023-12-06 15:02:01,384 : INFO : EPOCH 22: training on 99524 raw words (60516 effective words) took 0.1s, 422307 effective words/s\n",
      "2023-12-06 15:02:01,532 : INFO : EPOCH 23: training on 99524 raw words (60578 effective words) took 0.1s, 418119 effective words/s\n",
      "2023-12-06 15:02:01,681 : INFO : EPOCH 24: training on 99524 raw words (60605 effective words) took 0.1s, 420410 effective words/s\n",
      "2023-12-06 15:02:01,834 : INFO : EPOCH 25: training on 99524 raw words (60396 effective words) took 0.1s, 407634 effective words/s\n",
      "2023-12-06 15:02:01,982 : INFO : EPOCH 26: training on 99524 raw words (60457 effective words) took 0.1s, 420600 effective words/s\n",
      "2023-12-06 15:02:02,130 : INFO : EPOCH 27: training on 99524 raw words (60576 effective words) took 0.1s, 419881 effective words/s\n",
      "2023-12-06 15:02:02,287 : INFO : EPOCH 28: training on 99524 raw words (60348 effective words) took 0.2s, 397871 effective words/s\n",
      "2023-12-06 15:02:02,444 : INFO : EPOCH 29: training on 99524 raw words (60530 effective words) took 0.2s, 396929 effective words/s\n",
      "2023-12-06 15:02:02,446 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812487 effective words) took 4.4s, 410034 effective words/s', 'datetime': '2023-12-06T15:02:02.446446', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:02:02,446 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:02:02.446446', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 66%|   | 319/486 [48:23<17:54,  6.43s/it]2023-12-06 15:02:05,292 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:02:05,292 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:02:05,312 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:02:05,314 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:02:05,319 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:02:05.319402', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:02:05,319 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:02:05.319402', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:02:05,324 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:02:05,325 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:02:05,325 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:02:05.325835', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:02:05,336 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 15:02:05,337 : INFO : resetting layer weights\n",
      "2023-12-06 15:02:05,340 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:02:05.340623', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:02:05,482 : INFO : EPOCH 0: training on 99524 raw words (60407 effective words) took 0.1s, 442811 effective words/s\n",
      "2023-12-06 15:02:05,646 : INFO : EPOCH 1: training on 99524 raw words (60466 effective words) took 0.2s, 376510 effective words/s\n",
      "2023-12-06 15:02:05,810 : INFO : EPOCH 2: training on 99524 raw words (60558 effective words) took 0.2s, 383607 effective words/s\n",
      "2023-12-06 15:02:05,969 : INFO : EPOCH 3: training on 99524 raw words (60205 effective words) took 0.2s, 391874 effective words/s\n",
      "2023-12-06 15:02:06,123 : INFO : EPOCH 4: training on 99524 raw words (60235 effective words) took 0.1s, 403754 effective words/s\n",
      "2023-12-06 15:02:06,280 : INFO : EPOCH 5: training on 99524 raw words (60351 effective words) took 0.2s, 393199 effective words/s\n",
      "2023-12-06 15:02:06,436 : INFO : EPOCH 6: training on 99524 raw words (60343 effective words) took 0.2s, 398732 effective words/s\n",
      "2023-12-06 15:02:06,596 : INFO : EPOCH 7: training on 99524 raw words (60416 effective words) took 0.2s, 389521 effective words/s\n",
      "2023-12-06 15:02:06,752 : INFO : EPOCH 8: training on 99524 raw words (60323 effective words) took 0.2s, 397287 effective words/s\n",
      "2023-12-06 15:02:06,907 : INFO : EPOCH 9: training on 99524 raw words (60510 effective words) took 0.2s, 403123 effective words/s\n",
      "2023-12-06 15:02:07,064 : INFO : EPOCH 10: training on 99524 raw words (60213 effective words) took 0.2s, 396136 effective words/s\n",
      "2023-12-06 15:02:07,219 : INFO : EPOCH 11: training on 99524 raw words (60594 effective words) took 0.2s, 402615 effective words/s\n",
      "2023-12-06 15:02:07,377 : INFO : EPOCH 12: training on 99524 raw words (60386 effective words) took 0.2s, 396415 effective words/s\n",
      "2023-12-06 15:02:07,532 : INFO : EPOCH 13: training on 99524 raw words (60328 effective words) took 0.1s, 403453 effective words/s\n",
      "2023-12-06 15:02:07,689 : INFO : EPOCH 14: training on 99524 raw words (60437 effective words) took 0.2s, 398225 effective words/s\n",
      "2023-12-06 15:02:07,849 : INFO : EPOCH 15: training on 99524 raw words (60424 effective words) took 0.2s, 389844 effective words/s\n",
      "2023-12-06 15:02:08,004 : INFO : EPOCH 16: training on 99524 raw words (60445 effective words) took 0.2s, 400829 effective words/s\n",
      "2023-12-06 15:02:08,164 : INFO : EPOCH 17: training on 99524 raw words (60236 effective words) took 0.2s, 387068 effective words/s\n",
      "2023-12-06 15:02:08,320 : INFO : EPOCH 18: training on 99524 raw words (60373 effective words) took 0.2s, 397278 effective words/s\n",
      "2023-12-06 15:02:08,476 : INFO : EPOCH 19: training on 99524 raw words (60361 effective words) took 0.2s, 399397 effective words/s\n",
      "2023-12-06 15:02:08,633 : INFO : EPOCH 20: training on 99524 raw words (60290 effective words) took 0.2s, 395192 effective words/s\n",
      "2023-12-06 15:02:08,789 : INFO : EPOCH 21: training on 99524 raw words (60457 effective words) took 0.2s, 398564 effective words/s\n",
      "2023-12-06 15:02:08,945 : INFO : EPOCH 22: training on 99524 raw words (60349 effective words) took 0.2s, 395842 effective words/s\n",
      "2023-12-06 15:02:09,103 : INFO : EPOCH 23: training on 99524 raw words (60442 effective words) took 0.2s, 397134 effective words/s\n",
      "2023-12-06 15:02:09,256 : INFO : EPOCH 24: training on 99524 raw words (60425 effective words) took 0.1s, 404202 effective words/s\n",
      "2023-12-06 15:02:09,414 : INFO : EPOCH 25: training on 99524 raw words (60451 effective words) took 0.2s, 395192 effective words/s\n",
      "2023-12-06 15:02:09,570 : INFO : EPOCH 26: training on 99524 raw words (60503 effective words) took 0.2s, 398601 effective words/s\n",
      "2023-12-06 15:02:09,728 : INFO : EPOCH 27: training on 99524 raw words (60469 effective words) took 0.2s, 394725 effective words/s\n",
      "2023-12-06 15:02:09,884 : INFO : EPOCH 28: training on 99524 raw words (60464 effective words) took 0.1s, 404219 effective words/s\n",
      "2023-12-06 15:02:10,041 : INFO : EPOCH 29: training on 99524 raw words (60385 effective words) took 0.2s, 395852 effective words/s\n",
      "2023-12-06 15:02:10,042 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811846 effective words) took 4.7s, 385440 effective words/s', 'datetime': '2023-12-06T15:02:10.042116', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:02:10,042 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:02:10.042116', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 66%|   | 320/486 [48:31<19:00,  6.87s/it]2023-12-06 15:02:13,186 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:02:13,186 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:02:13,207 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:02:13,209 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:02:13,213 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:02:13.213090', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:02:13,214 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:02:13.214100', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:02:13,220 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:02:13,220 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:02:13,221 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:02:13.221712', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:02:13,231 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 15:02:13,231 : INFO : resetting layer weights\n",
      "2023-12-06 15:02:13,235 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:02:13.235337', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:02:13,375 : INFO : EPOCH 0: training on 99524 raw words (60422 effective words) took 0.1s, 443861 effective words/s\n",
      "2023-12-06 15:02:13,540 : INFO : EPOCH 1: training on 99524 raw words (60412 effective words) took 0.2s, 378984 effective words/s\n",
      "2023-12-06 15:02:13,704 : INFO : EPOCH 2: training on 99524 raw words (60428 effective words) took 0.2s, 381709 effective words/s\n",
      "2023-12-06 15:02:13,859 : INFO : EPOCH 3: training on 99524 raw words (60162 effective words) took 0.2s, 401016 effective words/s\n",
      "2023-12-06 15:02:14,008 : INFO : EPOCH 4: training on 99524 raw words (60391 effective words) took 0.1s, 415991 effective words/s\n",
      "2023-12-06 15:02:14,160 : INFO : EPOCH 5: training on 99524 raw words (60180 effective words) took 0.1s, 406403 effective words/s\n",
      "2023-12-06 15:02:14,314 : INFO : EPOCH 6: training on 99524 raw words (60338 effective words) took 0.1s, 403514 effective words/s\n",
      "2023-12-06 15:02:14,467 : INFO : EPOCH 7: training on 99524 raw words (60654 effective words) took 0.1s, 408795 effective words/s\n",
      "2023-12-06 15:02:14,620 : INFO : EPOCH 8: training on 99524 raw words (60468 effective words) took 0.1s, 407016 effective words/s\n",
      "2023-12-06 15:02:14,771 : INFO : EPOCH 9: training on 99524 raw words (60368 effective words) took 0.1s, 408591 effective words/s\n",
      "2023-12-06 15:02:14,934 : INFO : EPOCH 10: training on 99524 raw words (60396 effective words) took 0.2s, 385445 effective words/s\n",
      "2023-12-06 15:02:15,087 : INFO : EPOCH 11: training on 99524 raw words (60517 effective words) took 0.1s, 407733 effective words/s\n",
      "2023-12-06 15:02:15,240 : INFO : EPOCH 12: training on 99524 raw words (60284 effective words) took 0.1s, 402533 effective words/s\n",
      "2023-12-06 15:02:15,393 : INFO : EPOCH 13: training on 99524 raw words (60342 effective words) took 0.1s, 410174 effective words/s\n",
      "2023-12-06 15:02:15,547 : INFO : EPOCH 14: training on 99524 raw words (60353 effective words) took 0.1s, 402723 effective words/s\n",
      "2023-12-06 15:02:15,701 : INFO : EPOCH 15: training on 99524 raw words (60403 effective words) took 0.1s, 406182 effective words/s\n",
      "2023-12-06 15:02:15,851 : INFO : EPOCH 16: training on 99524 raw words (60401 effective words) took 0.1s, 414022 effective words/s\n",
      "2023-12-06 15:02:16,002 : INFO : EPOCH 17: training on 99524 raw words (60089 effective words) took 0.1s, 406234 effective words/s\n",
      "2023-12-06 15:02:16,162 : INFO : EPOCH 18: training on 99524 raw words (60278 effective words) took 0.2s, 388398 effective words/s\n",
      "2023-12-06 15:02:16,314 : INFO : EPOCH 19: training on 99524 raw words (60545 effective words) took 0.1s, 412422 effective words/s\n",
      "2023-12-06 15:02:16,466 : INFO : EPOCH 20: training on 99524 raw words (60555 effective words) took 0.1s, 409299 effective words/s\n",
      "2023-12-06 15:02:16,617 : INFO : EPOCH 21: training on 99524 raw words (60501 effective words) took 0.1s, 412460 effective words/s\n",
      "2023-12-06 15:02:16,770 : INFO : EPOCH 22: training on 99524 raw words (60499 effective words) took 0.1s, 408019 effective words/s\n",
      "2023-12-06 15:02:16,923 : INFO : EPOCH 23: training on 99524 raw words (60394 effective words) took 0.1s, 406901 effective words/s\n",
      "2023-12-06 15:02:17,074 : INFO : EPOCH 24: training on 99524 raw words (60425 effective words) took 0.1s, 411119 effective words/s\n",
      "2023-12-06 15:02:17,224 : INFO : EPOCH 25: training on 99524 raw words (60457 effective words) took 0.1s, 415346 effective words/s\n",
      "2023-12-06 15:02:17,390 : INFO : EPOCH 26: training on 99524 raw words (60459 effective words) took 0.2s, 374323 effective words/s\n",
      "2023-12-06 15:02:17,544 : INFO : EPOCH 27: training on 99524 raw words (60593 effective words) took 0.1s, 406564 effective words/s\n",
      "2023-12-06 15:02:17,697 : INFO : EPOCH 28: training on 99524 raw words (60437 effective words) took 0.1s, 406091 effective words/s\n",
      "2023-12-06 15:02:17,851 : INFO : EPOCH 29: training on 99524 raw words (60436 effective words) took 0.1s, 403165 effective words/s\n",
      "2023-12-06 15:02:17,852 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812187 effective words) took 4.6s, 392484 effective words/s', 'datetime': '2023-12-06T15:02:17.852769', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:02:17,853 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:02:17.853768', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 66%|   | 321/486 [48:39<19:40,  7.16s/it]2023-12-06 15:02:21,006 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:02:21,006 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:02:21,029 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:02:21,029 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:02:21,035 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:02:21.035715', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:02:21,035 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:02:21.035715', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:02:21,042 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:02:21,043 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:02:21,043 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:02:21.043139', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:02:21,050 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 15:02:21,050 : INFO : resetting layer weights\n",
      "2023-12-06 15:02:21,053 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:02:21.053653', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:02:21,195 : INFO : EPOCH 0: training on 99524 raw words (60351 effective words) took 0.1s, 439086 effective words/s\n",
      "2023-12-06 15:02:21,364 : INFO : EPOCH 1: training on 99524 raw words (60454 effective words) took 0.2s, 369046 effective words/s\n",
      "2023-12-06 15:02:21,517 : INFO : EPOCH 2: training on 99524 raw words (60349 effective words) took 0.1s, 407000 effective words/s\n",
      "2023-12-06 15:02:21,666 : INFO : EPOCH 3: training on 99524 raw words (60357 effective words) took 0.1s, 417112 effective words/s\n",
      "2023-12-06 15:02:21,814 : INFO : EPOCH 4: training on 99524 raw words (60443 effective words) took 0.1s, 421086 effective words/s\n",
      "2023-12-06 15:02:21,961 : INFO : EPOCH 5: training on 99524 raw words (60296 effective words) took 0.1s, 424065 effective words/s\n",
      "2023-12-06 15:02:22,110 : INFO : EPOCH 6: training on 99524 raw words (60489 effective words) took 0.1s, 418596 effective words/s\n",
      "2023-12-06 15:02:22,255 : INFO : EPOCH 7: training on 99524 raw words (60245 effective words) took 0.1s, 426429 effective words/s\n",
      "2023-12-06 15:02:22,413 : INFO : EPOCH 8: training on 99524 raw words (60395 effective words) took 0.2s, 396525 effective words/s\n",
      "2023-12-06 15:02:22,561 : INFO : EPOCH 9: training on 99524 raw words (60359 effective words) took 0.1s, 418265 effective words/s\n",
      "2023-12-06 15:02:22,711 : INFO : EPOCH 10: training on 99524 raw words (60468 effective words) took 0.1s, 413711 effective words/s\n",
      "2023-12-06 15:02:22,857 : INFO : EPOCH 11: training on 99524 raw words (60407 effective words) took 0.1s, 425543 effective words/s\n",
      "2023-12-06 15:02:23,008 : INFO : EPOCH 12: training on 99524 raw words (60325 effective words) took 0.1s, 416725 effective words/s\n",
      "2023-12-06 15:02:23,158 : INFO : EPOCH 13: training on 99524 raw words (60304 effective words) took 0.1s, 411855 effective words/s\n",
      "2023-12-06 15:02:23,305 : INFO : EPOCH 14: training on 99524 raw words (60439 effective words) took 0.1s, 423589 effective words/s\n",
      "2023-12-06 15:02:23,455 : INFO : EPOCH 15: training on 99524 raw words (60293 effective words) took 0.1s, 417789 effective words/s\n",
      "2023-12-06 15:02:23,609 : INFO : EPOCH 16: training on 99524 raw words (60467 effective words) took 0.1s, 403938 effective words/s\n",
      "2023-12-06 15:02:23,759 : INFO : EPOCH 17: training on 99524 raw words (60314 effective words) took 0.1s, 412936 effective words/s\n",
      "2023-12-06 15:02:23,907 : INFO : EPOCH 18: training on 99524 raw words (60255 effective words) took 0.1s, 420545 effective words/s\n",
      "2023-12-06 15:02:24,054 : INFO : EPOCH 19: training on 99524 raw words (60416 effective words) took 0.1s, 422883 effective words/s\n",
      "2023-12-06 15:02:24,202 : INFO : EPOCH 20: training on 99524 raw words (60463 effective words) took 0.1s, 419911 effective words/s\n",
      "2023-12-06 15:02:24,354 : INFO : EPOCH 21: training on 99524 raw words (60466 effective words) took 0.1s, 413162 effective words/s\n",
      "2023-12-06 15:02:24,504 : INFO : EPOCH 22: training on 99524 raw words (60562 effective words) took 0.1s, 416001 effective words/s\n",
      "2023-12-06 15:02:24,669 : INFO : EPOCH 23: training on 99524 raw words (60478 effective words) took 0.2s, 377668 effective words/s\n",
      "2023-12-06 15:02:24,840 : INFO : EPOCH 24: training on 99524 raw words (60381 effective words) took 0.2s, 367056 effective words/s\n",
      "2023-12-06 15:02:24,995 : INFO : EPOCH 25: training on 99524 raw words (60326 effective words) took 0.1s, 402416 effective words/s\n",
      "2023-12-06 15:02:25,144 : INFO : EPOCH 26: training on 99524 raw words (60575 effective words) took 0.1s, 418223 effective words/s\n",
      "2023-12-06 15:02:25,290 : INFO : EPOCH 27: training on 99524 raw words (60434 effective words) took 0.1s, 424948 effective words/s\n",
      "2023-12-06 15:02:25,437 : INFO : EPOCH 28: training on 99524 raw words (60362 effective words) took 0.1s, 426937 effective words/s\n",
      "2023-12-06 15:02:25,584 : INFO : EPOCH 29: training on 99524 raw words (60447 effective words) took 0.1s, 421987 effective words/s\n",
      "2023-12-06 15:02:25,730 : INFO : EPOCH 30: training on 99524 raw words (60291 effective words) took 0.1s, 425399 effective words/s\n",
      "2023-12-06 15:02:25,878 : INFO : EPOCH 31: training on 99524 raw words (60449 effective words) took 0.1s, 421840 effective words/s\n",
      "2023-12-06 15:02:26,032 : INFO : EPOCH 32: training on 99524 raw words (60456 effective words) took 0.2s, 403030 effective words/s\n",
      "2023-12-06 15:02:26,182 : INFO : EPOCH 33: training on 99524 raw words (60466 effective words) took 0.1s, 416568 effective words/s\n",
      "2023-12-06 15:02:26,330 : INFO : EPOCH 34: training on 99524 raw words (60329 effective words) took 0.1s, 417036 effective words/s\n",
      "2023-12-06 15:02:26,476 : INFO : EPOCH 35: training on 99524 raw words (60428 effective words) took 0.1s, 427922 effective words/s\n",
      "2023-12-06 15:02:26,623 : INFO : EPOCH 36: training on 99524 raw words (60261 effective words) took 0.1s, 422589 effective words/s\n",
      "2023-12-06 15:02:26,773 : INFO : EPOCH 37: training on 99524 raw words (60515 effective words) took 0.1s, 416469 effective words/s\n",
      "2023-12-06 15:02:26,920 : INFO : EPOCH 38: training on 99524 raw words (60290 effective words) took 0.1s, 421692 effective words/s\n",
      "2023-12-06 15:02:27,064 : INFO : EPOCH 39: training on 99524 raw words (60327 effective words) took 0.1s, 434206 effective words/s\n",
      "2023-12-06 15:02:27,219 : INFO : EPOCH 40: training on 99524 raw words (60408 effective words) took 0.2s, 402572 effective words/s\n",
      "2023-12-06 15:02:27,367 : INFO : EPOCH 41: training on 99524 raw words (60487 effective words) took 0.1s, 422797 effective words/s\n",
      "2023-12-06 15:02:27,512 : INFO : EPOCH 42: training on 99524 raw words (60336 effective words) took 0.1s, 429635 effective words/s\n",
      "2023-12-06 15:02:27,662 : INFO : EPOCH 43: training on 99524 raw words (60451 effective words) took 0.1s, 415694 effective words/s\n",
      "2023-12-06 15:02:27,811 : INFO : EPOCH 44: training on 99524 raw words (60436 effective words) took 0.1s, 417551 effective words/s\n",
      "2023-12-06 15:02:27,960 : INFO : EPOCH 45: training on 99524 raw words (60470 effective words) took 0.1s, 420304 effective words/s\n",
      "2023-12-06 15:02:28,118 : INFO : EPOCH 46: training on 99524 raw words (60340 effective words) took 0.2s, 390199 effective words/s\n",
      "2023-12-06 15:02:28,273 : INFO : EPOCH 47: training on 99524 raw words (60452 effective words) took 0.1s, 405655 effective words/s\n",
      "2023-12-06 15:02:28,418 : INFO : EPOCH 48: training on 99524 raw words (60460 effective words) took 0.1s, 431917 effective words/s\n",
      "2023-12-06 15:02:28,569 : INFO : EPOCH 49: training on 99524 raw words (60471 effective words) took 0.1s, 414350 effective words/s\n",
      "2023-12-06 15:02:28,570 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3020043 effective words) took 7.5s, 401826 effective words/s', 'datetime': '2023-12-06T15:02:28.570281', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:02:28,571 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:02:28.571673', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 66%|   | 322/486 [48:50<22:27,  8.22s/it]2023-12-06 15:02:31,707 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:02:31,708 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:02:31,728 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:02:31,729 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:02:31,733 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:02:31.733003', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:02:31,734 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:02:31.734003', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:02:31,738 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:02:31,739 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:02:31,739 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:02:31.739195', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:02:31,746 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 15:02:31,748 : INFO : resetting layer weights\n",
      "2023-12-06 15:02:31,751 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:02:31.751247', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:02:31,895 : INFO : EPOCH 0: training on 99524 raw words (60350 effective words) took 0.1s, 428794 effective words/s\n",
      "2023-12-06 15:02:32,063 : INFO : EPOCH 1: training on 99524 raw words (60524 effective words) took 0.2s, 373682 effective words/s\n",
      "2023-12-06 15:02:32,219 : INFO : EPOCH 2: training on 99524 raw words (60468 effective words) took 0.2s, 398859 effective words/s\n",
      "2023-12-06 15:02:32,372 : INFO : EPOCH 3: training on 99524 raw words (60421 effective words) took 0.1s, 407784 effective words/s\n",
      "2023-12-06 15:02:32,525 : INFO : EPOCH 4: training on 99524 raw words (60475 effective words) took 0.1s, 406510 effective words/s\n",
      "2023-12-06 15:02:32,684 : INFO : EPOCH 5: training on 99524 raw words (60457 effective words) took 0.2s, 393573 effective words/s\n",
      "2023-12-06 15:02:32,851 : INFO : EPOCH 6: training on 99524 raw words (60277 effective words) took 0.2s, 370061 effective words/s\n",
      "2023-12-06 15:02:33,005 : INFO : EPOCH 7: training on 99524 raw words (60459 effective words) took 0.1s, 410580 effective words/s\n",
      "2023-12-06 15:02:33,162 : INFO : EPOCH 8: training on 99524 raw words (60252 effective words) took 0.2s, 396950 effective words/s\n",
      "2023-12-06 15:02:33,325 : INFO : EPOCH 9: training on 99524 raw words (60497 effective words) took 0.2s, 381719 effective words/s\n",
      "2023-12-06 15:02:33,483 : INFO : EPOCH 10: training on 99524 raw words (60446 effective words) took 0.2s, 393649 effective words/s\n",
      "2023-12-06 15:02:33,646 : INFO : EPOCH 11: training on 99524 raw words (60548 effective words) took 0.2s, 385109 effective words/s\n",
      "2023-12-06 15:02:33,804 : INFO : EPOCH 12: training on 99524 raw words (60367 effective words) took 0.2s, 393826 effective words/s\n",
      "2023-12-06 15:02:33,960 : INFO : EPOCH 13: training on 99524 raw words (60388 effective words) took 0.2s, 400629 effective words/s\n",
      "2023-12-06 15:02:34,112 : INFO : EPOCH 14: training on 99524 raw words (60393 effective words) took 0.1s, 408443 effective words/s\n",
      "2023-12-06 15:02:34,285 : INFO : EPOCH 15: training on 99524 raw words (60386 effective words) took 0.2s, 357413 effective words/s\n",
      "2023-12-06 15:02:34,454 : INFO : EPOCH 16: training on 99524 raw words (60458 effective words) took 0.2s, 368873 effective words/s\n",
      "2023-12-06 15:02:34,618 : INFO : EPOCH 17: training on 99524 raw words (60294 effective words) took 0.2s, 382009 effective words/s\n",
      "2023-12-06 15:02:34,774 : INFO : EPOCH 18: training on 99524 raw words (60362 effective words) took 0.2s, 396556 effective words/s\n",
      "2023-12-06 15:02:34,929 : INFO : EPOCH 19: training on 99524 raw words (60402 effective words) took 0.1s, 402781 effective words/s\n",
      "2023-12-06 15:02:35,084 : INFO : EPOCH 20: training on 99524 raw words (60370 effective words) took 0.2s, 401233 effective words/s\n",
      "2023-12-06 15:02:35,236 : INFO : EPOCH 21: training on 99524 raw words (60414 effective words) took 0.1s, 406257 effective words/s\n",
      "2023-12-06 15:02:35,392 : INFO : EPOCH 22: training on 99524 raw words (60414 effective words) took 0.2s, 398964 effective words/s\n",
      "2023-12-06 15:02:35,547 : INFO : EPOCH 23: training on 99524 raw words (60587 effective words) took 0.2s, 402971 effective words/s\n",
      "2023-12-06 15:02:35,708 : INFO : EPOCH 24: training on 99524 raw words (60559 effective words) took 0.2s, 389871 effective words/s\n",
      "2023-12-06 15:02:35,864 : INFO : EPOCH 25: training on 99524 raw words (60473 effective words) took 0.2s, 397597 effective words/s\n",
      "2023-12-06 15:02:36,019 : INFO : EPOCH 26: training on 99524 raw words (60580 effective words) took 0.2s, 400765 effective words/s\n",
      "2023-12-06 15:02:36,173 : INFO : EPOCH 27: training on 99524 raw words (60637 effective words) took 0.1s, 406196 effective words/s\n",
      "2023-12-06 15:02:36,329 : INFO : EPOCH 28: training on 99524 raw words (60405 effective words) took 0.2s, 399507 effective words/s\n",
      "2023-12-06 15:02:36,485 : INFO : EPOCH 29: training on 99524 raw words (60425 effective words) took 0.2s, 400744 effective words/s\n",
      "2023-12-06 15:02:36,639 : INFO : EPOCH 30: training on 99524 raw words (60287 effective words) took 0.1s, 402678 effective words/s\n",
      "2023-12-06 15:02:36,797 : INFO : EPOCH 31: training on 99524 raw words (60388 effective words) took 0.2s, 391075 effective words/s\n",
      "2023-12-06 15:02:36,959 : INFO : EPOCH 32: training on 99524 raw words (60394 effective words) took 0.2s, 385970 effective words/s\n",
      "2023-12-06 15:02:37,117 : INFO : EPOCH 33: training on 99524 raw words (60619 effective words) took 0.2s, 395661 effective words/s\n",
      "2023-12-06 15:02:37,267 : INFO : EPOCH 34: training on 99524 raw words (60438 effective words) took 0.1s, 413906 effective words/s\n",
      "2023-12-06 15:02:37,422 : INFO : EPOCH 35: training on 99524 raw words (60550 effective words) took 0.2s, 401964 effective words/s\n",
      "2023-12-06 15:02:37,581 : INFO : EPOCH 36: training on 99524 raw words (60376 effective words) took 0.2s, 391875 effective words/s\n",
      "2023-12-06 15:02:37,736 : INFO : EPOCH 37: training on 99524 raw words (60348 effective words) took 0.2s, 400079 effective words/s\n",
      "2023-12-06 15:02:37,893 : INFO : EPOCH 38: training on 99524 raw words (60469 effective words) took 0.2s, 398257 effective words/s\n",
      "2023-12-06 15:02:38,046 : INFO : EPOCH 39: training on 99524 raw words (60397 effective words) took 0.1s, 404217 effective words/s\n",
      "2023-12-06 15:02:38,202 : INFO : EPOCH 40: training on 99524 raw words (60323 effective words) took 0.2s, 398301 effective words/s\n",
      "2023-12-06 15:02:38,358 : INFO : EPOCH 41: training on 99524 raw words (60580 effective words) took 0.2s, 402690 effective words/s\n",
      "2023-12-06 15:02:38,511 : INFO : EPOCH 42: training on 99524 raw words (60370 effective words) took 0.1s, 404094 effective words/s\n",
      "2023-12-06 15:02:38,667 : INFO : EPOCH 43: training on 99524 raw words (60458 effective words) took 0.2s, 399620 effective words/s\n",
      "2023-12-06 15:02:38,824 : INFO : EPOCH 44: training on 99524 raw words (60373 effective words) took 0.2s, 395256 effective words/s\n",
      "2023-12-06 15:02:38,981 : INFO : EPOCH 45: training on 99524 raw words (60369 effective words) took 0.2s, 397941 effective words/s\n",
      "2023-12-06 15:02:39,137 : INFO : EPOCH 46: training on 99524 raw words (60429 effective words) took 0.2s, 398180 effective words/s\n",
      "2023-12-06 15:02:39,290 : INFO : EPOCH 47: training on 99524 raw words (60364 effective words) took 0.1s, 405503 effective words/s\n",
      "2023-12-06 15:02:39,463 : INFO : EPOCH 48: training on 99524 raw words (60425 effective words) took 0.2s, 358234 effective words/s\n",
      "2023-12-06 15:02:39,622 : INFO : EPOCH 49: training on 99524 raw words (60408 effective words) took 0.2s, 392175 effective words/s\n",
      "2023-12-06 15:02:39,622 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3021453 effective words) took 7.9s, 383839 effective words/s', 'datetime': '2023-12-06T15:02:39.622948', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:02:39,623 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:02:39.623949', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 66%|   | 323/486 [49:01<25:00,  9.21s/it]2023-12-06 15:02:43,222 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:02:43,223 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:02:43,248 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:02:43,249 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:02:43,255 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:02:43.255108', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:02:43,256 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:02:43.256108', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:02:43,262 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:02:43,263 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:02:43,263 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:02:43.263408', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:02:43,273 : INFO : estimated required memory for 1231 words and 100 dimensions: 4188100 bytes\n",
      "2023-12-06 15:02:43,274 : INFO : resetting layer weights\n",
      "2023-12-06 15:02:43,277 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:02:43.277876', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:02:43,432 : INFO : EPOCH 0: training on 99524 raw words (60273 effective words) took 0.2s, 401188 effective words/s\n",
      "2023-12-06 15:02:43,623 : INFO : EPOCH 1: training on 99524 raw words (60340 effective words) took 0.2s, 322219 effective words/s\n",
      "2023-12-06 15:02:43,785 : INFO : EPOCH 2: training on 99524 raw words (60552 effective words) took 0.2s, 392797 effective words/s\n",
      "2023-12-06 15:02:43,946 : INFO : EPOCH 3: training on 99524 raw words (60286 effective words) took 0.2s, 384696 effective words/s\n",
      "2023-12-06 15:02:44,106 : INFO : EPOCH 4: training on 99524 raw words (60321 effective words) took 0.2s, 386654 effective words/s\n",
      "2023-12-06 15:02:44,268 : INFO : EPOCH 5: training on 99524 raw words (60321 effective words) took 0.2s, 381416 effective words/s\n",
      "2023-12-06 15:02:44,442 : INFO : EPOCH 6: training on 99524 raw words (60287 effective words) took 0.2s, 358419 effective words/s\n",
      "2023-12-06 15:02:44,597 : INFO : EPOCH 7: training on 99524 raw words (60451 effective words) took 0.2s, 400737 effective words/s\n",
      "2023-12-06 15:02:44,758 : INFO : EPOCH 8: training on 99524 raw words (60399 effective words) took 0.2s, 386438 effective words/s\n",
      "2023-12-06 15:02:44,913 : INFO : EPOCH 9: training on 99524 raw words (60481 effective words) took 0.2s, 401303 effective words/s\n",
      "2023-12-06 15:02:45,068 : INFO : EPOCH 10: training on 99524 raw words (60474 effective words) took 0.2s, 402481 effective words/s\n",
      "2023-12-06 15:02:45,229 : INFO : EPOCH 11: training on 99524 raw words (60414 effective words) took 0.2s, 383409 effective words/s\n",
      "2023-12-06 15:02:45,384 : INFO : EPOCH 12: training on 99524 raw words (60360 effective words) took 0.1s, 403044 effective words/s\n",
      "2023-12-06 15:02:45,549 : INFO : EPOCH 13: training on 99524 raw words (60471 effective words) took 0.2s, 378900 effective words/s\n",
      "2023-12-06 15:02:45,708 : INFO : EPOCH 14: training on 99524 raw words (60455 effective words) took 0.2s, 391304 effective words/s\n",
      "2023-12-06 15:02:45,870 : INFO : EPOCH 15: training on 99524 raw words (60407 effective words) took 0.2s, 383231 effective words/s\n",
      "2023-12-06 15:02:46,026 : INFO : EPOCH 16: training on 99524 raw words (60378 effective words) took 0.2s, 399674 effective words/s\n",
      "2023-12-06 15:02:46,189 : INFO : EPOCH 17: training on 99524 raw words (60215 effective words) took 0.2s, 380444 effective words/s\n",
      "2023-12-06 15:02:46,352 : INFO : EPOCH 18: training on 99524 raw words (60263 effective words) took 0.2s, 381007 effective words/s\n",
      "2023-12-06 15:02:46,521 : INFO : EPOCH 19: training on 99524 raw words (60504 effective words) took 0.2s, 368098 effective words/s\n",
      "2023-12-06 15:02:46,682 : INFO : EPOCH 20: training on 99524 raw words (60516 effective words) took 0.2s, 386587 effective words/s\n",
      "2023-12-06 15:02:46,838 : INFO : EPOCH 21: training on 99524 raw words (60725 effective words) took 0.2s, 402637 effective words/s\n",
      "2023-12-06 15:02:46,994 : INFO : EPOCH 22: training on 99524 raw words (60488 effective words) took 0.2s, 396661 effective words/s\n",
      "2023-12-06 15:02:47,140 : INFO : EPOCH 23: training on 99524 raw words (60455 effective words) took 0.1s, 425592 effective words/s\n",
      "2023-12-06 15:02:47,266 : INFO : EPOCH 24: training on 99524 raw words (60356 effective words) took 0.1s, 497666 effective words/s\n",
      "2023-12-06 15:02:47,408 : INFO : EPOCH 25: training on 99524 raw words (60257 effective words) took 0.1s, 439316 effective words/s\n",
      "2023-12-06 15:02:47,542 : INFO : EPOCH 26: training on 99524 raw words (60496 effective words) took 0.1s, 464839 effective words/s\n",
      "2023-12-06 15:02:47,675 : INFO : EPOCH 27: training on 99524 raw words (60510 effective words) took 0.1s, 469299 effective words/s\n",
      "2023-12-06 15:02:47,807 : INFO : EPOCH 28: training on 99524 raw words (60384 effective words) took 0.1s, 474966 effective words/s\n",
      "2023-12-06 15:02:47,931 : INFO : EPOCH 29: training on 99524 raw words (60543 effective words) took 0.1s, 503820 effective words/s\n",
      "2023-12-06 15:02:48,065 : INFO : EPOCH 30: training on 99524 raw words (60282 effective words) took 0.1s, 463608 effective words/s\n",
      "2023-12-06 15:02:48,192 : INFO : EPOCH 31: training on 99524 raw words (60375 effective words) took 0.1s, 495407 effective words/s\n",
      "2023-12-06 15:02:48,336 : INFO : EPOCH 32: training on 99524 raw words (60305 effective words) took 0.1s, 432920 effective words/s\n",
      "2023-12-06 15:02:48,474 : INFO : EPOCH 33: training on 99524 raw words (60514 effective words) took 0.1s, 451578 effective words/s\n",
      "2023-12-06 15:02:48,609 : INFO : EPOCH 34: training on 99524 raw words (60400 effective words) took 0.1s, 462656 effective words/s\n",
      "2023-12-06 15:02:48,734 : INFO : EPOCH 35: training on 99524 raw words (60542 effective words) took 0.1s, 503574 effective words/s\n",
      "2023-12-06 15:02:48,869 : INFO : EPOCH 36: training on 99524 raw words (60285 effective words) took 0.1s, 459408 effective words/s\n",
      "2023-12-06 15:02:49,004 : INFO : EPOCH 37: training on 99524 raw words (60489 effective words) took 0.1s, 462521 effective words/s\n",
      "2023-12-06 15:02:49,129 : INFO : EPOCH 38: training on 99524 raw words (60275 effective words) took 0.1s, 498686 effective words/s\n",
      "2023-12-06 15:02:49,280 : INFO : EPOCH 39: training on 99524 raw words (60439 effective words) took 0.1s, 414154 effective words/s\n",
      "2023-12-06 15:02:49,404 : INFO : EPOCH 40: training on 99524 raw words (60249 effective words) took 0.1s, 498834 effective words/s\n",
      "2023-12-06 15:02:49,536 : INFO : EPOCH 41: training on 99524 raw words (60545 effective words) took 0.1s, 472202 effective words/s\n",
      "2023-12-06 15:02:49,672 : INFO : EPOCH 42: training on 99524 raw words (60601 effective words) took 0.1s, 459812 effective words/s\n",
      "2023-12-06 15:02:49,806 : INFO : EPOCH 43: training on 99524 raw words (60435 effective words) took 0.1s, 466686 effective words/s\n",
      "2023-12-06 15:02:49,939 : INFO : EPOCH 44: training on 99524 raw words (60376 effective words) took 0.1s, 469274 effective words/s\n",
      "2023-12-06 15:02:50,074 : INFO : EPOCH 45: training on 99524 raw words (60399 effective words) took 0.1s, 464887 effective words/s\n",
      "2023-12-06 15:02:50,233 : INFO : EPOCH 46: training on 99524 raw words (60373 effective words) took 0.2s, 389856 effective words/s\n",
      "2023-12-06 15:02:50,391 : INFO : EPOCH 47: training on 99524 raw words (60458 effective words) took 0.2s, 395112 effective words/s\n",
      "2023-12-06 15:02:50,525 : INFO : EPOCH 48: training on 99524 raw words (60593 effective words) took 0.1s, 467918 effective words/s\n",
      "2023-12-06 15:02:50,655 : INFO : EPOCH 49: training on 99524 raw words (60563 effective words) took 0.1s, 483558 effective words/s\n",
      "2023-12-06 15:02:50,656 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3020880 effective words) took 7.4s, 409404 effective words/s', 'datetime': '2023-12-06T15:02:50.656926', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:02:50,657 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d100,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:02:50.657928', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 67%|   | 324/486 [49:13<26:27,  9.80s/it]2023-12-06 15:02:54,410 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:02:54,411 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:02:54,432 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:02:54,433 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:02:54,438 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:02:54.438442', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:02:54,438 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:02:54.438442', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:02:54,446 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:02:54,446 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:02:54,447 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:02:54.447159', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:02:54,457 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:02:54,457 : INFO : resetting layer weights\n",
      "2023-12-06 15:02:54,462 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:02:54.462556', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:02:54,712 : INFO : EPOCH 0: training on 99524 raw words (65635 effective words) took 0.2s, 265848 effective words/s\n",
      "2023-12-06 15:02:54,937 : INFO : EPOCH 1: training on 99524 raw words (65502 effective words) took 0.2s, 328687 effective words/s\n",
      "2023-12-06 15:02:55,171 : INFO : EPOCH 2: training on 99524 raw words (65627 effective words) took 0.2s, 285978 effective words/s\n",
      "2023-12-06 15:02:55,391 : INFO : EPOCH 3: training on 99524 raw words (65729 effective words) took 0.2s, 306602 effective words/s\n",
      "2023-12-06 15:02:55,605 : INFO : EPOCH 4: training on 99524 raw words (65234 effective words) took 0.2s, 310387 effective words/s\n",
      "2023-12-06 15:02:55,814 : INFO : EPOCH 5: training on 99524 raw words (65611 effective words) took 0.2s, 320844 effective words/s\n",
      "2023-12-06 15:02:56,035 : INFO : EPOCH 6: training on 99524 raw words (65623 effective words) took 0.2s, 303418 effective words/s\n",
      "2023-12-06 15:02:56,256 : INFO : EPOCH 7: training on 99524 raw words (65532 effective words) took 0.2s, 302136 effective words/s\n",
      "2023-12-06 15:02:56,468 : INFO : EPOCH 8: training on 99524 raw words (65484 effective words) took 0.2s, 315536 effective words/s\n",
      "2023-12-06 15:02:56,678 : INFO : EPOCH 9: training on 99524 raw words (65575 effective words) took 0.2s, 320930 effective words/s\n",
      "2023-12-06 15:02:56,679 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655552 effective words) took 2.2s, 295718 effective words/s', 'datetime': '2023-12-06T15:02:56.679867', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:02:56,680 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:02:56.680867', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 67%|   | 325/486 [49:18<22:33,  8.40s/it]2023-12-06 15:02:59,550 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:02:59,551 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:02:59,574 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:02:59,576 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:02:59,581 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:02:59.581833', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:02:59,581 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:02:59.581833', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:02:59,591 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:02:59,592 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:02:59,592 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:02:59.592458', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:02:59,603 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:02:59,604 : INFO : resetting layer weights\n",
      "2023-12-06 15:02:59,608 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:02:59.608466', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:02:59,850 : INFO : EPOCH 0: training on 99524 raw words (65505 effective words) took 0.2s, 276217 effective words/s\n",
      "2023-12-06 15:03:00,054 : INFO : EPOCH 1: training on 99524 raw words (65463 effective words) took 0.2s, 328994 effective words/s\n",
      "2023-12-06 15:03:00,280 : INFO : EPOCH 2: training on 99524 raw words (65585 effective words) took 0.2s, 296103 effective words/s\n",
      "2023-12-06 15:03:00,483 : INFO : EPOCH 3: training on 99524 raw words (65365 effective words) took 0.2s, 329253 effective words/s\n",
      "2023-12-06 15:03:00,694 : INFO : EPOCH 4: training on 99524 raw words (65523 effective words) took 0.2s, 317189 effective words/s\n",
      "2023-12-06 15:03:00,892 : INFO : EPOCH 5: training on 99524 raw words (65586 effective words) took 0.2s, 338902 effective words/s\n",
      "2023-12-06 15:03:01,089 : INFO : EPOCH 6: training on 99524 raw words (65531 effective words) took 0.2s, 338935 effective words/s\n",
      "2023-12-06 15:03:01,288 : INFO : EPOCH 7: training on 99524 raw words (65492 effective words) took 0.2s, 337428 effective words/s\n",
      "2023-12-06 15:03:01,514 : INFO : EPOCH 8: training on 99524 raw words (65359 effective words) took 0.2s, 300645 effective words/s\n",
      "2023-12-06 15:03:01,714 : INFO : EPOCH 9: training on 99524 raw words (65496 effective words) took 0.2s, 335345 effective words/s\n",
      "2023-12-06 15:03:01,715 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (654905 effective words) took 2.1s, 310933 effective words/s', 'datetime': '2023-12-06T15:03:01.715939', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:03:01,716 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:03:01.716941', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 67%|   | 326/486 [49:23<19:43,  7.40s/it]2023-12-06 15:03:04,593 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:03:04,593 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:03:04,615 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:03:04,617 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:03:04,622 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:03:04.622654', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:03:04,622 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:03:04.622654', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:03:04,629 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:03:04,630 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:03:04,630 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:03:04.630658', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:03:04,641 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:03:04,642 : INFO : resetting layer weights\n",
      "2023-12-06 15:03:04,646 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:03:04.646166', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:03:04,923 : INFO : EPOCH 0: training on 99524 raw words (65644 effective words) took 0.3s, 239977 effective words/s\n",
      "2023-12-06 15:03:05,138 : INFO : EPOCH 1: training on 99524 raw words (65455 effective words) took 0.2s, 310918 effective words/s\n",
      "2023-12-06 15:03:05,362 : INFO : EPOCH 2: training on 99524 raw words (65471 effective words) took 0.2s, 297457 effective words/s\n",
      "2023-12-06 15:03:05,590 : INFO : EPOCH 3: training on 99524 raw words (65457 effective words) took 0.2s, 293876 effective words/s\n",
      "2023-12-06 15:03:05,808 : INFO : EPOCH 4: training on 99524 raw words (65628 effective words) took 0.2s, 307116 effective words/s\n",
      "2023-12-06 15:03:06,032 : INFO : EPOCH 5: training on 99524 raw words (65532 effective words) took 0.2s, 298249 effective words/s\n",
      "2023-12-06 15:03:06,279 : INFO : EPOCH 6: training on 99524 raw words (65479 effective words) took 0.2s, 269880 effective words/s\n",
      "2023-12-06 15:03:06,501 : INFO : EPOCH 7: training on 99524 raw words (65480 effective words) took 0.2s, 302139 effective words/s\n",
      "2023-12-06 15:03:06,721 : INFO : EPOCH 8: training on 99524 raw words (65681 effective words) took 0.2s, 304381 effective words/s\n",
      "2023-12-06 15:03:06,942 : INFO : EPOCH 9: training on 99524 raw words (65306 effective words) took 0.2s, 300423 effective words/s\n",
      "2023-12-06 15:03:06,943 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655133 effective words) took 2.3s, 285137 effective words/s', 'datetime': '2023-12-06T15:03:06.943941', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:03:06,944 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:03:06.944946', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 67%|   | 327/486 [49:28<17:56,  6.77s/it]2023-12-06 15:03:09,898 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:03:09,898 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:03:09,919 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:03:09,920 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:03:09,925 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:03:09.925369', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:03:09,926 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:03:09.926369', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:03:09,933 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:03:09,934 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:03:09,935 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:03:09.935880', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:03:09,945 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:03:09,946 : INFO : resetting layer weights\n",
      "2023-12-06 15:03:09,950 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:03:09.950715', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:03:10,209 : INFO : EPOCH 0: training on 99524 raw words (65423 effective words) took 0.3s, 256685 effective words/s\n",
      "2023-12-06 15:03:10,423 : INFO : EPOCH 1: training on 99524 raw words (65563 effective words) took 0.2s, 318198 effective words/s\n",
      "2023-12-06 15:03:10,618 : INFO : EPOCH 2: training on 99524 raw words (65499 effective words) took 0.2s, 342088 effective words/s\n",
      "2023-12-06 15:03:10,822 : INFO : EPOCH 3: training on 99524 raw words (65494 effective words) took 0.2s, 328136 effective words/s\n",
      "2023-12-06 15:03:11,027 : INFO : EPOCH 4: training on 99524 raw words (65491 effective words) took 0.2s, 327193 effective words/s\n",
      "2023-12-06 15:03:11,253 : INFO : EPOCH 5: training on 99524 raw words (65541 effective words) took 0.2s, 295244 effective words/s\n",
      "2023-12-06 15:03:11,458 : INFO : EPOCH 6: training on 99524 raw words (65441 effective words) took 0.2s, 325468 effective words/s\n",
      "2023-12-06 15:03:11,653 : INFO : EPOCH 7: training on 99524 raw words (65677 effective words) took 0.2s, 345635 effective words/s\n",
      "2023-12-06 15:03:11,872 : INFO : EPOCH 8: training on 99524 raw words (65588 effective words) took 0.2s, 305264 effective words/s\n",
      "2023-12-06 15:03:12,081 : INFO : EPOCH 9: training on 99524 raw words (65558 effective words) took 0.2s, 319737 effective words/s\n",
      "2023-12-06 15:03:12,287 : INFO : EPOCH 10: training on 99524 raw words (65636 effective words) took 0.2s, 325972 effective words/s\n",
      "2023-12-06 15:03:12,499 : INFO : EPOCH 11: training on 99524 raw words (65417 effective words) took 0.2s, 314896 effective words/s\n",
      "2023-12-06 15:03:12,704 : INFO : EPOCH 12: training on 99524 raw words (65491 effective words) took 0.2s, 325204 effective words/s\n",
      "2023-12-06 15:03:12,908 : INFO : EPOCH 13: training on 99524 raw words (65541 effective words) took 0.2s, 328769 effective words/s\n",
      "2023-12-06 15:03:13,116 : INFO : EPOCH 14: training on 99524 raw words (65487 effective words) took 0.2s, 322264 effective words/s\n",
      "2023-12-06 15:03:13,352 : INFO : EPOCH 15: training on 99524 raw words (65491 effective words) took 0.2s, 282336 effective words/s\n",
      "2023-12-06 15:03:13,606 : INFO : EPOCH 16: training on 99524 raw words (65734 effective words) took 0.2s, 263467 effective words/s\n",
      "2023-12-06 15:03:13,863 : INFO : EPOCH 17: training on 99524 raw words (65754 effective words) took 0.3s, 260250 effective words/s\n",
      "2023-12-06 15:03:14,131 : INFO : EPOCH 18: training on 99524 raw words (65552 effective words) took 0.3s, 248424 effective words/s\n",
      "2023-12-06 15:03:14,389 : INFO : EPOCH 19: training on 99524 raw words (65653 effective words) took 0.3s, 259009 effective words/s\n",
      "2023-12-06 15:03:14,654 : INFO : EPOCH 20: training on 99524 raw words (65525 effective words) took 0.3s, 251738 effective words/s\n",
      "2023-12-06 15:03:14,910 : INFO : EPOCH 21: training on 99524 raw words (65731 effective words) took 0.3s, 262309 effective words/s\n",
      "2023-12-06 15:03:15,171 : INFO : EPOCH 22: training on 99524 raw words (65450 effective words) took 0.3s, 254410 effective words/s\n",
      "2023-12-06 15:03:15,424 : INFO : EPOCH 23: training on 99524 raw words (65530 effective words) took 0.2s, 264929 effective words/s\n",
      "2023-12-06 15:03:15,672 : INFO : EPOCH 24: training on 99524 raw words (65652 effective words) took 0.2s, 269630 effective words/s\n",
      "2023-12-06 15:03:15,929 : INFO : EPOCH 25: training on 99524 raw words (65360 effective words) took 0.3s, 259941 effective words/s\n",
      "2023-12-06 15:03:16,195 : INFO : EPOCH 26: training on 99524 raw words (65491 effective words) took 0.3s, 252121 effective words/s\n",
      "2023-12-06 15:03:16,443 : INFO : EPOCH 27: training on 99524 raw words (65577 effective words) took 0.2s, 268100 effective words/s\n",
      "2023-12-06 15:03:16,701 : INFO : EPOCH 28: training on 99524 raw words (65667 effective words) took 0.3s, 258624 effective words/s\n",
      "2023-12-06 15:03:16,960 : INFO : EPOCH 29: training on 99524 raw words (65448 effective words) took 0.3s, 257476 effective words/s\n",
      "2023-12-06 15:03:16,961 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1966462 effective words) took 7.0s, 280529 effective words/s', 'datetime': '2023-12-06T15:03:16.960641', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:03:16,961 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:03:16.961642', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 67%|   | 328/486 [49:39<20:49,  7.91s/it]2023-12-06 15:03:20,461 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:03:20,461 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:03:20,486 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:03:20,487 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:03:20,492 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:03:20.492906', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:03:20,494 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:03:20.494069', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:03:20,503 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:03:20,504 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:03:20,505 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:03:20.505577', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:03:20,515 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:03:20,516 : INFO : resetting layer weights\n",
      "2023-12-06 15:03:20,523 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:03:20.523966', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:03:20,803 : INFO : EPOCH 0: training on 99524 raw words (65386 effective words) took 0.3s, 237364 effective words/s\n",
      "2023-12-06 15:03:21,084 : INFO : EPOCH 1: training on 99524 raw words (65540 effective words) took 0.3s, 239402 effective words/s\n",
      "2023-12-06 15:03:21,351 : INFO : EPOCH 2: training on 99524 raw words (65360 effective words) took 0.3s, 249112 effective words/s\n",
      "2023-12-06 15:03:21,621 : INFO : EPOCH 3: training on 99524 raw words (65470 effective words) took 0.3s, 247308 effective words/s\n",
      "2023-12-06 15:03:21,888 : INFO : EPOCH 4: training on 99524 raw words (65384 effective words) took 0.3s, 248462 effective words/s\n",
      "2023-12-06 15:03:22,162 : INFO : EPOCH 5: training on 99524 raw words (65637 effective words) took 0.3s, 244943 effective words/s\n",
      "2023-12-06 15:03:22,430 : INFO : EPOCH 6: training on 99524 raw words (65301 effective words) took 0.3s, 247913 effective words/s\n",
      "2023-12-06 15:03:22,699 : INFO : EPOCH 7: training on 99524 raw words (65631 effective words) took 0.3s, 248528 effective words/s\n",
      "2023-12-06 15:03:22,965 : INFO : EPOCH 8: training on 99524 raw words (65654 effective words) took 0.3s, 250763 effective words/s\n",
      "2023-12-06 15:03:23,235 : INFO : EPOCH 9: training on 99524 raw words (65618 effective words) took 0.3s, 246883 effective words/s\n",
      "2023-12-06 15:03:23,499 : INFO : EPOCH 10: training on 99524 raw words (65466 effective words) took 0.3s, 252692 effective words/s\n",
      "2023-12-06 15:03:23,769 : INFO : EPOCH 11: training on 99524 raw words (65622 effective words) took 0.3s, 247466 effective words/s\n",
      "2023-12-06 15:03:24,046 : INFO : EPOCH 12: training on 99524 raw words (65635 effective words) took 0.3s, 241229 effective words/s\n",
      "2023-12-06 15:03:24,321 : INFO : EPOCH 13: training on 99524 raw words (65415 effective words) took 0.3s, 241390 effective words/s\n",
      "2023-12-06 15:03:24,586 : INFO : EPOCH 14: training on 99524 raw words (65520 effective words) took 0.3s, 251725 effective words/s\n",
      "2023-12-06 15:03:24,853 : INFO : EPOCH 15: training on 99524 raw words (65569 effective words) took 0.3s, 250543 effective words/s\n",
      "2023-12-06 15:03:25,122 : INFO : EPOCH 16: training on 99524 raw words (65637 effective words) took 0.3s, 249167 effective words/s\n",
      "2023-12-06 15:03:25,404 : INFO : EPOCH 17: training on 99524 raw words (65470 effective words) took 0.3s, 235244 effective words/s\n",
      "2023-12-06 15:03:25,675 : INFO : EPOCH 18: training on 99524 raw words (65418 effective words) took 0.3s, 245801 effective words/s\n",
      "2023-12-06 15:03:25,943 : INFO : EPOCH 19: training on 99524 raw words (65413 effective words) took 0.3s, 248407 effective words/s\n",
      "2023-12-06 15:03:26,214 : INFO : EPOCH 20: training on 99524 raw words (65519 effective words) took 0.3s, 245428 effective words/s\n",
      "2023-12-06 15:03:26,487 : INFO : EPOCH 21: training on 99524 raw words (65565 effective words) took 0.3s, 244893 effective words/s\n",
      "2023-12-06 15:03:26,757 : INFO : EPOCH 22: training on 99524 raw words (65484 effective words) took 0.3s, 246583 effective words/s\n",
      "2023-12-06 15:03:27,030 : INFO : EPOCH 23: training on 99524 raw words (65445 effective words) took 0.3s, 243756 effective words/s\n",
      "2023-12-06 15:03:27,301 : INFO : EPOCH 24: training on 99524 raw words (65575 effective words) took 0.3s, 246560 effective words/s\n",
      "2023-12-06 15:03:27,575 : INFO : EPOCH 25: training on 99524 raw words (65598 effective words) took 0.3s, 243328 effective words/s\n",
      "2023-12-06 15:03:27,842 : INFO : EPOCH 26: training on 99524 raw words (65485 effective words) took 0.3s, 248731 effective words/s\n",
      "2023-12-06 15:03:28,120 : INFO : EPOCH 27: training on 99524 raw words (65615 effective words) took 0.3s, 240132 effective words/s\n",
      "2023-12-06 15:03:28,405 : INFO : EPOCH 28: training on 99524 raw words (65588 effective words) took 0.3s, 233971 effective words/s\n",
      "2023-12-06 15:03:28,689 : INFO : EPOCH 29: training on 99524 raw words (65416 effective words) took 0.3s, 233422 effective words/s\n",
      "2023-12-06 15:03:28,691 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965436 effective words) took 8.2s, 240681 effective words/s', 'datetime': '2023-12-06T15:03:28.691207', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:03:28,691 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:03:28.691207', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 68%|   | 329/486 [49:51<23:53,  9.13s/it]2023-12-06 15:03:32,454 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:03:32,454 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:03:32,479 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:03:32,480 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:03:32,486 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:03:32.486708', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:03:32,486 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:03:32.486708', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:03:32,497 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:03:32,497 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:03:32,498 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:03:32.498712', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:03:32,514 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:03:32,515 : INFO : resetting layer weights\n",
      "2023-12-06 15:03:32,520 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:03:32.520461', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:03:32,804 : INFO : EPOCH 0: training on 99524 raw words (65396 effective words) took 0.3s, 232973 effective words/s\n",
      "2023-12-06 15:03:33,103 : INFO : EPOCH 1: training on 99524 raw words (65447 effective words) took 0.3s, 224881 effective words/s\n",
      "2023-12-06 15:03:33,383 : INFO : EPOCH 2: training on 99524 raw words (65447 effective words) took 0.3s, 238309 effective words/s\n",
      "2023-12-06 15:03:33,662 : INFO : EPOCH 3: training on 99524 raw words (65475 effective words) took 0.3s, 238535 effective words/s\n",
      "2023-12-06 15:03:33,942 : INFO : EPOCH 4: training on 99524 raw words (65569 effective words) took 0.3s, 239438 effective words/s\n",
      "2023-12-06 15:03:34,223 : INFO : EPOCH 5: training on 99524 raw words (65521 effective words) took 0.3s, 236778 effective words/s\n",
      "2023-12-06 15:03:34,523 : INFO : EPOCH 6: training on 99524 raw words (65522 effective words) took 0.3s, 221495 effective words/s\n",
      "2023-12-06 15:03:34,804 : INFO : EPOCH 7: training on 99524 raw words (65533 effective words) took 0.3s, 237401 effective words/s\n",
      "2023-12-06 15:03:35,086 : INFO : EPOCH 8: training on 99524 raw words (65427 effective words) took 0.3s, 235976 effective words/s\n",
      "2023-12-06 15:03:35,373 : INFO : EPOCH 9: training on 99524 raw words (65431 effective words) took 0.3s, 231237 effective words/s\n",
      "2023-12-06 15:03:35,652 : INFO : EPOCH 10: training on 99524 raw words (65480 effective words) took 0.3s, 238477 effective words/s\n",
      "2023-12-06 15:03:35,927 : INFO : EPOCH 11: training on 99524 raw words (65543 effective words) took 0.3s, 242589 effective words/s\n",
      "2023-12-06 15:03:36,206 : INFO : EPOCH 12: training on 99524 raw words (65450 effective words) took 0.3s, 238253 effective words/s\n",
      "2023-12-06 15:03:36,501 : INFO : EPOCH 13: training on 99524 raw words (65435 effective words) took 0.3s, 227528 effective words/s\n",
      "2023-12-06 15:03:36,782 : INFO : EPOCH 14: training on 99524 raw words (65505 effective words) took 0.3s, 236724 effective words/s\n",
      "2023-12-06 15:03:37,062 : INFO : EPOCH 15: training on 99524 raw words (65361 effective words) took 0.3s, 237479 effective words/s\n",
      "2023-12-06 15:03:37,339 : INFO : EPOCH 16: training on 99524 raw words (65439 effective words) took 0.3s, 240791 effective words/s\n",
      "2023-12-06 15:03:37,614 : INFO : EPOCH 17: training on 99524 raw words (65505 effective words) took 0.3s, 241147 effective words/s\n",
      "2023-12-06 15:03:37,898 : INFO : EPOCH 18: training on 99524 raw words (65584 effective words) took 0.3s, 235345 effective words/s\n",
      "2023-12-06 15:03:38,181 : INFO : EPOCH 19: training on 99524 raw words (65502 effective words) took 0.3s, 235023 effective words/s\n",
      "2023-12-06 15:03:38,482 : INFO : EPOCH 20: training on 99524 raw words (65396 effective words) took 0.3s, 220899 effective words/s\n",
      "2023-12-06 15:03:38,761 : INFO : EPOCH 21: training on 99524 raw words (65573 effective words) took 0.3s, 238447 effective words/s\n",
      "2023-12-06 15:03:39,038 : INFO : EPOCH 22: training on 99524 raw words (65526 effective words) took 0.3s, 240507 effective words/s\n",
      "2023-12-06 15:03:39,328 : INFO : EPOCH 23: training on 99524 raw words (65660 effective words) took 0.3s, 230666 effective words/s\n",
      "2023-12-06 15:03:39,604 : INFO : EPOCH 24: training on 99524 raw words (65595 effective words) took 0.3s, 242393 effective words/s\n",
      "2023-12-06 15:03:39,876 : INFO : EPOCH 25: training on 99524 raw words (65445 effective words) took 0.3s, 244839 effective words/s\n",
      "2023-12-06 15:03:40,163 : INFO : EPOCH 26: training on 99524 raw words (65716 effective words) took 0.3s, 232617 effective words/s\n",
      "2023-12-06 15:03:40,458 : INFO : EPOCH 27: training on 99524 raw words (65489 effective words) took 0.3s, 225508 effective words/s\n",
      "2023-12-06 15:03:40,743 : INFO : EPOCH 28: training on 99524 raw words (65446 effective words) took 0.3s, 236121 effective words/s\n",
      "2023-12-06 15:03:41,022 : INFO : EPOCH 29: training on 99524 raw words (65537 effective words) took 0.3s, 239063 effective words/s\n",
      "2023-12-06 15:03:41,023 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1964955 effective words) took 8.5s, 231098 effective words/s', 'datetime': '2023-12-06T15:03:41.023117', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:03:41,024 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:03:41.024117', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 68%|   | 330/486 [50:03<26:25, 10.16s/it]2023-12-06 15:03:45,021 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:03:45,022 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:03:45,045 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:03:45,045 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:03:45,052 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:03:45.052647', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:03:45,052 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:03:45.052647', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:03:45,062 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:03:45,063 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:03:45,064 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:03:45.064627', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:03:45,074 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:03:45,075 : INFO : resetting layer weights\n",
      "2023-12-06 15:03:45,082 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:03:45.081627', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:03:45,366 : INFO : EPOCH 0: training on 99524 raw words (65518 effective words) took 0.3s, 234278 effective words/s\n",
      "2023-12-06 15:03:45,636 : INFO : EPOCH 1: training on 99524 raw words (65462 effective words) took 0.3s, 249890 effective words/s\n",
      "2023-12-06 15:03:45,894 : INFO : EPOCH 2: training on 99524 raw words (65556 effective words) took 0.3s, 259499 effective words/s\n",
      "2023-12-06 15:03:46,141 : INFO : EPOCH 3: training on 99524 raw words (65584 effective words) took 0.2s, 270391 effective words/s\n",
      "2023-12-06 15:03:46,432 : INFO : EPOCH 4: training on 99524 raw words (65612 effective words) took 0.3s, 229786 effective words/s\n",
      "2023-12-06 15:03:46,716 : INFO : EPOCH 5: training on 99524 raw words (65723 effective words) took 0.3s, 235148 effective words/s\n",
      "2023-12-06 15:03:47,017 : INFO : EPOCH 6: training on 99524 raw words (65503 effective words) took 0.3s, 221140 effective words/s\n",
      "2023-12-06 15:03:47,284 : INFO : EPOCH 7: training on 99524 raw words (65433 effective words) took 0.3s, 250136 effective words/s\n",
      "2023-12-06 15:03:47,552 : INFO : EPOCH 8: training on 99524 raw words (65680 effective words) took 0.3s, 249283 effective words/s\n",
      "2023-12-06 15:03:47,820 : INFO : EPOCH 9: training on 99524 raw words (65470 effective words) took 0.3s, 249372 effective words/s\n",
      "2023-12-06 15:03:48,076 : INFO : EPOCH 10: training on 99524 raw words (65554 effective words) took 0.3s, 260470 effective words/s\n",
      "2023-12-06 15:03:48,329 : INFO : EPOCH 11: training on 99524 raw words (65576 effective words) took 0.2s, 264049 effective words/s\n",
      "2023-12-06 15:03:48,600 : INFO : EPOCH 12: training on 99524 raw words (65367 effective words) took 0.3s, 245901 effective words/s\n",
      "2023-12-06 15:03:48,859 : INFO : EPOCH 13: training on 99524 raw words (65491 effective words) took 0.3s, 257222 effective words/s\n",
      "2023-12-06 15:03:49,120 : INFO : EPOCH 14: training on 99524 raw words (65557 effective words) took 0.3s, 256288 effective words/s\n",
      "2023-12-06 15:03:49,377 : INFO : EPOCH 15: training on 99524 raw words (65505 effective words) took 0.3s, 260033 effective words/s\n",
      "2023-12-06 15:03:49,632 : INFO : EPOCH 16: training on 99524 raw words (65577 effective words) took 0.3s, 261108 effective words/s\n",
      "2023-12-06 15:03:49,887 : INFO : EPOCH 17: training on 99524 raw words (65562 effective words) took 0.3s, 260996 effective words/s\n",
      "2023-12-06 15:03:50,141 : INFO : EPOCH 18: training on 99524 raw words (65459 effective words) took 0.2s, 263868 effective words/s\n",
      "2023-12-06 15:03:50,398 : INFO : EPOCH 19: training on 99524 raw words (65462 effective words) took 0.3s, 258560 effective words/s\n",
      "2023-12-06 15:03:50,649 : INFO : EPOCH 20: training on 99524 raw words (65447 effective words) took 0.2s, 264847 effective words/s\n",
      "2023-12-06 15:03:50,905 : INFO : EPOCH 21: training on 99524 raw words (65441 effective words) took 0.2s, 261958 effective words/s\n",
      "2023-12-06 15:03:51,159 : INFO : EPOCH 22: training on 99524 raw words (65532 effective words) took 0.2s, 262177 effective words/s\n",
      "2023-12-06 15:03:51,426 : INFO : EPOCH 23: training on 99524 raw words (65575 effective words) took 0.3s, 250043 effective words/s\n",
      "2023-12-06 15:03:51,679 : INFO : EPOCH 24: training on 99524 raw words (65486 effective words) took 0.2s, 263396 effective words/s\n",
      "2023-12-06 15:03:51,929 : INFO : EPOCH 25: training on 99524 raw words (65602 effective words) took 0.2s, 266966 effective words/s\n",
      "2023-12-06 15:03:52,185 : INFO : EPOCH 26: training on 99524 raw words (65727 effective words) took 0.3s, 261755 effective words/s\n",
      "2023-12-06 15:03:52,440 : INFO : EPOCH 27: training on 99524 raw words (65576 effective words) took 0.3s, 261591 effective words/s\n",
      "2023-12-06 15:03:52,693 : INFO : EPOCH 28: training on 99524 raw words (65379 effective words) took 0.2s, 263336 effective words/s\n",
      "2023-12-06 15:03:52,946 : INFO : EPOCH 29: training on 99524 raw words (65691 effective words) took 0.2s, 265146 effective words/s\n",
      "2023-12-06 15:03:53,198 : INFO : EPOCH 30: training on 99524 raw words (65248 effective words) took 0.2s, 263117 effective words/s\n",
      "2023-12-06 15:03:53,471 : INFO : EPOCH 31: training on 99524 raw words (65505 effective words) took 0.3s, 244146 effective words/s\n",
      "2023-12-06 15:03:53,749 : INFO : EPOCH 32: training on 99524 raw words (65563 effective words) took 0.3s, 240423 effective words/s\n",
      "2023-12-06 15:03:54,012 : INFO : EPOCH 33: training on 99524 raw words (65474 effective words) took 0.3s, 253550 effective words/s\n",
      "2023-12-06 15:03:54,258 : INFO : EPOCH 34: training on 99524 raw words (65398 effective words) took 0.2s, 270207 effective words/s\n",
      "2023-12-06 15:03:54,509 : INFO : EPOCH 35: training on 99524 raw words (65460 effective words) took 0.2s, 264862 effective words/s\n",
      "2023-12-06 15:03:54,759 : INFO : EPOCH 36: training on 99524 raw words (65596 effective words) took 0.2s, 267594 effective words/s\n",
      "2023-12-06 15:03:55,008 : INFO : EPOCH 37: training on 99524 raw words (65445 effective words) took 0.2s, 267413 effective words/s\n",
      "2023-12-06 15:03:55,269 : INFO : EPOCH 38: training on 99524 raw words (65641 effective words) took 0.3s, 255532 effective words/s\n",
      "2023-12-06 15:03:55,526 : INFO : EPOCH 39: training on 99524 raw words (65456 effective words) took 0.3s, 259446 effective words/s\n",
      "2023-12-06 15:03:55,775 : INFO : EPOCH 40: training on 99524 raw words (65608 effective words) took 0.2s, 268261 effective words/s\n",
      "2023-12-06 15:03:56,023 : INFO : EPOCH 41: training on 99524 raw words (65588 effective words) took 0.2s, 268840 effective words/s\n",
      "2023-12-06 15:03:56,278 : INFO : EPOCH 42: training on 99524 raw words (65640 effective words) took 0.3s, 262248 effective words/s\n",
      "2023-12-06 15:03:56,528 : INFO : EPOCH 43: training on 99524 raw words (65591 effective words) took 0.2s, 266269 effective words/s\n",
      "2023-12-06 15:03:56,785 : INFO : EPOCH 44: training on 99524 raw words (65661 effective words) took 0.3s, 260556 effective words/s\n",
      "2023-12-06 15:03:57,042 : INFO : EPOCH 45: training on 99524 raw words (65436 effective words) took 0.3s, 259186 effective words/s\n",
      "2023-12-06 15:03:57,292 : INFO : EPOCH 46: training on 99524 raw words (65377 effective words) took 0.2s, 265905 effective words/s\n",
      "2023-12-06 15:03:57,543 : INFO : EPOCH 47: training on 99524 raw words (65487 effective words) took 0.2s, 264752 effective words/s\n",
      "2023-12-06 15:03:57,806 : INFO : EPOCH 48: training on 99524 raw words (65636 effective words) took 0.3s, 256068 effective words/s\n",
      "2023-12-06 15:03:58,074 : INFO : EPOCH 49: training on 99524 raw words (65499 effective words) took 0.3s, 248422 effective words/s\n",
      "2023-12-06 15:03:58,076 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276416 effective words) took 13.0s, 252167 effective words/s', 'datetime': '2023-12-06T15:03:58.076243', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:03:58,076 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:03:58.076243', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 68%|   | 331/486 [50:21<31:51, 12.33s/it]2023-12-06 15:04:02,414 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:04:02,415 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:04:02,435 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:04:02,436 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:04:02,442 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:04:02.442674', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:04:02,443 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:04:02.443679', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:04:02,450 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:04:02,451 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:04:02,451 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:04:02.451872', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:04:02,468 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:04:02,468 : INFO : resetting layer weights\n",
      "2023-12-06 15:04:02,475 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:04:02.475059', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:04:02,771 : INFO : EPOCH 0: training on 99524 raw words (65319 effective words) took 0.3s, 223171 effective words/s\n",
      "2023-12-06 15:04:03,217 : INFO : EPOCH 1: training on 99524 raw words (65506 effective words) took 0.4s, 162262 effective words/s\n",
      "2023-12-06 15:04:03,683 : INFO : EPOCH 2: training on 99524 raw words (65587 effective words) took 0.4s, 150742 effective words/s\n",
      "2023-12-06 15:04:04,115 : INFO : EPOCH 3: training on 99524 raw words (65542 effective words) took 0.4s, 153984 effective words/s\n",
      "2023-12-06 15:04:04,485 : INFO : EPOCH 4: training on 99524 raw words (65576 effective words) took 0.4s, 184204 effective words/s\n",
      "2023-12-06 15:04:04,785 : INFO : EPOCH 5: training on 99524 raw words (65642 effective words) took 0.3s, 222793 effective words/s\n",
      "2023-12-06 15:04:05,078 : INFO : EPOCH 6: training on 99524 raw words (65626 effective words) took 0.3s, 227856 effective words/s\n",
      "2023-12-06 15:04:05,373 : INFO : EPOCH 7: training on 99524 raw words (65505 effective words) took 0.3s, 225953 effective words/s\n",
      "2023-12-06 15:04:05,657 : INFO : EPOCH 8: training on 99524 raw words (65608 effective words) took 0.3s, 234886 effective words/s\n",
      "2023-12-06 15:04:05,938 : INFO : EPOCH 9: training on 99524 raw words (65322 effective words) took 0.3s, 236765 effective words/s\n",
      "2023-12-06 15:04:06,207 : INFO : EPOCH 10: training on 99524 raw words (65542 effective words) took 0.3s, 247736 effective words/s\n",
      "2023-12-06 15:04:06,483 : INFO : EPOCH 11: training on 99524 raw words (65595 effective words) took 0.3s, 242530 effective words/s\n",
      "2023-12-06 15:04:06,753 : INFO : EPOCH 12: training on 99524 raw words (65593 effective words) took 0.3s, 246486 effective words/s\n",
      "2023-12-06 15:04:07,042 : INFO : EPOCH 13: training on 99524 raw words (65553 effective words) took 0.3s, 230983 effective words/s\n",
      "2023-12-06 15:04:07,319 : INFO : EPOCH 14: training on 99524 raw words (65542 effective words) took 0.3s, 240834 effective words/s\n",
      "2023-12-06 15:04:07,604 : INFO : EPOCH 15: training on 99524 raw words (65659 effective words) took 0.3s, 234128 effective words/s\n",
      "2023-12-06 15:04:07,884 : INFO : EPOCH 16: training on 99524 raw words (65699 effective words) took 0.3s, 238715 effective words/s\n",
      "2023-12-06 15:04:08,154 : INFO : EPOCH 17: training on 99524 raw words (65395 effective words) took 0.3s, 245932 effective words/s\n",
      "2023-12-06 15:04:08,437 : INFO : EPOCH 18: training on 99524 raw words (65460 effective words) took 0.3s, 235411 effective words/s\n",
      "2023-12-06 15:04:08,709 : INFO : EPOCH 19: training on 99524 raw words (65865 effective words) took 0.3s, 246038 effective words/s\n",
      "2023-12-06 15:04:08,978 : INFO : EPOCH 20: training on 99524 raw words (65485 effective words) took 0.3s, 248471 effective words/s\n",
      "2023-12-06 15:04:09,247 : INFO : EPOCH 21: training on 99524 raw words (65592 effective words) took 0.3s, 248275 effective words/s\n",
      "2023-12-06 15:04:09,519 : INFO : EPOCH 22: training on 99524 raw words (65516 effective words) took 0.3s, 245008 effective words/s\n",
      "2023-12-06 15:04:09,788 : INFO : EPOCH 23: training on 99524 raw words (65462 effective words) took 0.3s, 247450 effective words/s\n",
      "2023-12-06 15:04:10,054 : INFO : EPOCH 24: training on 99524 raw words (65534 effective words) took 0.3s, 251587 effective words/s\n",
      "2023-12-06 15:04:10,318 : INFO : EPOCH 25: training on 99524 raw words (65482 effective words) took 0.3s, 252002 effective words/s\n",
      "2023-12-06 15:04:10,607 : INFO : EPOCH 26: training on 99524 raw words (65494 effective words) took 0.3s, 230803 effective words/s\n",
      "2023-12-06 15:04:10,876 : INFO : EPOCH 27: training on 99524 raw words (65453 effective words) took 0.3s, 248050 effective words/s\n",
      "2023-12-06 15:04:11,161 : INFO : EPOCH 28: training on 99524 raw words (65484 effective words) took 0.3s, 234041 effective words/s\n",
      "2023-12-06 15:04:11,455 : INFO : EPOCH 29: training on 99524 raw words (65569 effective words) took 0.3s, 226155 effective words/s\n",
      "2023-12-06 15:04:11,736 : INFO : EPOCH 30: training on 99524 raw words (65523 effective words) took 0.3s, 237943 effective words/s\n",
      "2023-12-06 15:04:12,014 : INFO : EPOCH 31: training on 99524 raw words (65507 effective words) took 0.3s, 241063 effective words/s\n",
      "2023-12-06 15:04:12,297 : INFO : EPOCH 32: training on 99524 raw words (65534 effective words) took 0.3s, 235728 effective words/s\n",
      "2023-12-06 15:04:12,604 : INFO : EPOCH 33: training on 99524 raw words (65679 effective words) took 0.3s, 218336 effective words/s\n",
      "2023-12-06 15:04:12,896 : INFO : EPOCH 34: training on 99524 raw words (65483 effective words) took 0.3s, 228115 effective words/s\n",
      "2023-12-06 15:04:13,163 : INFO : EPOCH 35: training on 99524 raw words (65448 effective words) took 0.3s, 249964 effective words/s\n",
      "2023-12-06 15:04:13,446 : INFO : EPOCH 36: training on 99524 raw words (65752 effective words) took 0.3s, 235915 effective words/s\n",
      "2023-12-06 15:04:13,719 : INFO : EPOCH 37: training on 99524 raw words (65587 effective words) took 0.3s, 245068 effective words/s\n",
      "2023-12-06 15:04:14,013 : INFO : EPOCH 38: training on 99524 raw words (65589 effective words) took 0.3s, 226718 effective words/s\n",
      "2023-12-06 15:04:14,298 : INFO : EPOCH 39: training on 99524 raw words (65578 effective words) took 0.3s, 234265 effective words/s\n",
      "2023-12-06 15:04:14,574 : INFO : EPOCH 40: training on 99524 raw words (65594 effective words) took 0.3s, 242298 effective words/s\n",
      "2023-12-06 15:04:14,856 : INFO : EPOCH 41: training on 99524 raw words (65699 effective words) took 0.3s, 237226 effective words/s\n",
      "2023-12-06 15:04:15,126 : INFO : EPOCH 42: training on 99524 raw words (65490 effective words) took 0.3s, 246794 effective words/s\n",
      "2023-12-06 15:04:15,396 : INFO : EPOCH 43: training on 99524 raw words (65374 effective words) took 0.3s, 246189 effective words/s\n",
      "2023-12-06 15:04:15,664 : INFO : EPOCH 44: training on 99524 raw words (65486 effective words) took 0.3s, 248641 effective words/s\n",
      "2023-12-06 15:04:15,951 : INFO : EPOCH 45: training on 99524 raw words (65615 effective words) took 0.3s, 231428 effective words/s\n",
      "2023-12-06 15:04:16,217 : INFO : EPOCH 46: training on 99524 raw words (65450 effective words) took 0.3s, 251633 effective words/s\n",
      "2023-12-06 15:04:16,500 : INFO : EPOCH 47: training on 99524 raw words (65497 effective words) took 0.3s, 235223 effective words/s\n",
      "2023-12-06 15:04:16,771 : INFO : EPOCH 48: training on 99524 raw words (65483 effective words) took 0.3s, 247123 effective words/s\n",
      "2023-12-06 15:04:17,050 : INFO : EPOCH 49: training on 99524 raw words (65489 effective words) took 0.3s, 239089 effective words/s\n",
      "2023-12-06 15:04:17,051 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3277064 effective words) took 14.6s, 224843 effective words/s', 'datetime': '2023-12-06T15:04:17.051059', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:04:17,052 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:04:17.052059', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 68%|   | 332/486 [50:40<36:46, 14.33s/it]2023-12-06 15:04:21,401 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:04:21,401 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:04:21,424 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:04:21,425 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:04:21,430 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:04:21.430977', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:04:21,431 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:04:21.431977', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:04:21,438 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:04:21,439 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:04:21,440 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:04:21.440489', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:04:21,451 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:04:21,452 : INFO : resetting layer weights\n",
      "2023-12-06 15:04:21,456 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:04:21.456488', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:04:21,750 : INFO : EPOCH 0: training on 99524 raw words (65619 effective words) took 0.3s, 226692 effective words/s\n",
      "2023-12-06 15:04:21,973 : INFO : EPOCH 1: training on 99524 raw words (65445 effective words) took 0.2s, 301013 effective words/s\n",
      "2023-12-06 15:04:22,186 : INFO : EPOCH 2: training on 99524 raw words (65650 effective words) took 0.2s, 312744 effective words/s\n",
      "2023-12-06 15:04:22,424 : INFO : EPOCH 3: training on 99524 raw words (65615 effective words) took 0.2s, 280712 effective words/s\n",
      "2023-12-06 15:04:22,650 : INFO : EPOCH 4: training on 99524 raw words (65606 effective words) took 0.2s, 296760 effective words/s\n",
      "2023-12-06 15:04:22,896 : INFO : EPOCH 5: training on 99524 raw words (65397 effective words) took 0.2s, 272485 effective words/s\n",
      "2023-12-06 15:04:23,115 : INFO : EPOCH 6: training on 99524 raw words (65570 effective words) took 0.2s, 303285 effective words/s\n",
      "2023-12-06 15:04:23,325 : INFO : EPOCH 7: training on 99524 raw words (65430 effective words) took 0.2s, 317981 effective words/s\n",
      "2023-12-06 15:04:23,582 : INFO : EPOCH 8: training on 99524 raw words (65460 effective words) took 0.3s, 259521 effective words/s\n",
      "2023-12-06 15:04:23,861 : INFO : EPOCH 9: training on 99524 raw words (65725 effective words) took 0.3s, 239749 effective words/s\n",
      "2023-12-06 15:04:24,147 : INFO : EPOCH 10: training on 99524 raw words (65594 effective words) took 0.3s, 233099 effective words/s\n",
      "2023-12-06 15:04:24,434 : INFO : EPOCH 11: training on 99524 raw words (65441 effective words) took 0.3s, 232008 effective words/s\n",
      "2023-12-06 15:04:24,726 : INFO : EPOCH 12: training on 99524 raw words (65533 effective words) took 0.3s, 228244 effective words/s\n",
      "2023-12-06 15:04:25,009 : INFO : EPOCH 13: training on 99524 raw words (65513 effective words) took 0.3s, 235837 effective words/s\n",
      "2023-12-06 15:04:25,298 : INFO : EPOCH 14: training on 99524 raw words (65551 effective words) took 0.3s, 230418 effective words/s\n",
      "2023-12-06 15:04:25,587 : INFO : EPOCH 15: training on 99524 raw words (65609 effective words) took 0.3s, 230531 effective words/s\n",
      "2023-12-06 15:04:25,874 : INFO : EPOCH 16: training on 99524 raw words (65564 effective words) took 0.3s, 233065 effective words/s\n",
      "2023-12-06 15:04:26,161 : INFO : EPOCH 17: training on 99524 raw words (65594 effective words) took 0.3s, 232652 effective words/s\n",
      "2023-12-06 15:04:26,448 : INFO : EPOCH 18: training on 99524 raw words (65448 effective words) took 0.3s, 231531 effective words/s\n",
      "2023-12-06 15:04:26,731 : INFO : EPOCH 19: training on 99524 raw words (65530 effective words) took 0.3s, 235841 effective words/s\n",
      "2023-12-06 15:04:27,011 : INFO : EPOCH 20: training on 99524 raw words (65404 effective words) took 0.3s, 237640 effective words/s\n",
      "2023-12-06 15:04:27,286 : INFO : EPOCH 21: training on 99524 raw words (65464 effective words) took 0.3s, 242164 effective words/s\n",
      "2023-12-06 15:04:27,559 : INFO : EPOCH 22: training on 99524 raw words (65332 effective words) took 0.3s, 242679 effective words/s\n",
      "2023-12-06 15:04:27,852 : INFO : EPOCH 23: training on 99524 raw words (65611 effective words) took 0.3s, 226970 effective words/s\n",
      "2023-12-06 15:04:28,130 : INFO : EPOCH 24: training on 99524 raw words (65449 effective words) took 0.3s, 239950 effective words/s\n",
      "2023-12-06 15:04:28,409 : INFO : EPOCH 25: training on 99524 raw words (65486 effective words) took 0.3s, 238886 effective words/s\n",
      "2023-12-06 15:04:28,697 : INFO : EPOCH 26: training on 99524 raw words (65460 effective words) took 0.3s, 231304 effective words/s\n",
      "2023-12-06 15:04:28,968 : INFO : EPOCH 27: training on 99524 raw words (65571 effective words) took 0.3s, 246076 effective words/s\n",
      "2023-12-06 15:04:29,250 : INFO : EPOCH 28: training on 99524 raw words (65629 effective words) took 0.3s, 236713 effective words/s\n",
      "2023-12-06 15:04:29,542 : INFO : EPOCH 29: training on 99524 raw words (65685 effective words) took 0.3s, 228312 effective words/s\n",
      "2023-12-06 15:04:29,834 : INFO : EPOCH 30: training on 99524 raw words (65578 effective words) took 0.3s, 229631 effective words/s\n",
      "2023-12-06 15:04:30,129 : INFO : EPOCH 31: training on 99524 raw words (65599 effective words) took 0.3s, 226132 effective words/s\n",
      "2023-12-06 15:04:30,428 : INFO : EPOCH 32: training on 99524 raw words (65486 effective words) took 0.3s, 223599 effective words/s\n",
      "2023-12-06 15:04:30,713 : INFO : EPOCH 33: training on 99524 raw words (65563 effective words) took 0.3s, 234853 effective words/s\n",
      "2023-12-06 15:04:30,990 : INFO : EPOCH 34: training on 99524 raw words (65565 effective words) took 0.3s, 240218 effective words/s\n",
      "2023-12-06 15:04:31,272 : INFO : EPOCH 35: training on 99524 raw words (65536 effective words) took 0.3s, 236570 effective words/s\n",
      "2023-12-06 15:04:31,568 : INFO : EPOCH 36: training on 99524 raw words (65586 effective words) took 0.3s, 224978 effective words/s\n",
      "2023-12-06 15:04:31,852 : INFO : EPOCH 37: training on 99524 raw words (65515 effective words) took 0.3s, 234590 effective words/s\n",
      "2023-12-06 15:04:32,148 : INFO : EPOCH 38: training on 99524 raw words (65435 effective words) took 0.3s, 225659 effective words/s\n",
      "2023-12-06 15:04:32,422 : INFO : EPOCH 39: training on 99524 raw words (65563 effective words) took 0.3s, 242813 effective words/s\n",
      "2023-12-06 15:04:32,713 : INFO : EPOCH 40: training on 99524 raw words (65421 effective words) took 0.3s, 228441 effective words/s\n",
      "2023-12-06 15:04:33,006 : INFO : EPOCH 41: training on 99524 raw words (65344 effective words) took 0.3s, 226820 effective words/s\n",
      "2023-12-06 15:04:33,287 : INFO : EPOCH 42: training on 99524 raw words (65566 effective words) took 0.3s, 237506 effective words/s\n",
      "2023-12-06 15:04:33,565 : INFO : EPOCH 43: training on 99524 raw words (65564 effective words) took 0.3s, 238734 effective words/s\n",
      "2023-12-06 15:04:33,843 : INFO : EPOCH 44: training on 99524 raw words (65628 effective words) took 0.3s, 240431 effective words/s\n",
      "2023-12-06 15:04:34,123 : INFO : EPOCH 45: training on 99524 raw words (65608 effective words) took 0.3s, 238456 effective words/s\n",
      "2023-12-06 15:04:34,405 : INFO : EPOCH 46: training on 99524 raw words (65550 effective words) took 0.3s, 236087 effective words/s\n",
      "2023-12-06 15:04:34,679 : INFO : EPOCH 47: training on 99524 raw words (65482 effective words) took 0.3s, 242423 effective words/s\n",
      "2023-12-06 15:04:34,960 : INFO : EPOCH 48: training on 99524 raw words (65379 effective words) took 0.3s, 237734 effective words/s\n",
      "2023-12-06 15:04:35,269 : INFO : EPOCH 49: training on 99524 raw words (65323 effective words) took 0.3s, 215127 effective words/s\n",
      "2023-12-06 15:04:35,270 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276276 effective words) took 13.8s, 237196 effective words/s', 'datetime': '2023-12-06T15:04:35.270282', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:04:35,271 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w5,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:04:35.271281', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 69%|   | 333/486 [50:58<39:54, 15.65s/it]2023-12-06 15:04:40,138 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:04:40,139 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:04:40,163 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:04:40,164 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:04:40,171 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:04:40.170983', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:04:40,171 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:04:40.171488', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:04:40,177 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:04:40,178 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:04:40,179 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:04:40.179009', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:04:40,190 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:04:40,191 : INFO : resetting layer weights\n",
      "2023-12-06 15:04:40,197 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:04:40.197578', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:04:40,481 : INFO : EPOCH 0: training on 99524 raw words (62772 effective words) took 0.3s, 222908 effective words/s\n",
      "2023-12-06 15:04:40,735 : INFO : EPOCH 1: training on 99524 raw words (62598 effective words) took 0.2s, 255081 effective words/s\n",
      "2023-12-06 15:04:40,987 : INFO : EPOCH 2: training on 99524 raw words (62721 effective words) took 0.2s, 253597 effective words/s\n",
      "2023-12-06 15:04:41,238 : INFO : EPOCH 3: training on 99524 raw words (62569 effective words) took 0.2s, 253911 effective words/s\n",
      "2023-12-06 15:04:41,492 : INFO : EPOCH 4: training on 99524 raw words (62642 effective words) took 0.2s, 251628 effective words/s\n",
      "2023-12-06 15:04:41,736 : INFO : EPOCH 5: training on 99524 raw words (62930 effective words) took 0.2s, 263310 effective words/s\n",
      "2023-12-06 15:04:41,991 : INFO : EPOCH 6: training on 99524 raw words (62581 effective words) took 0.3s, 250136 effective words/s\n",
      "2023-12-06 15:04:42,235 : INFO : EPOCH 7: training on 99524 raw words (62611 effective words) took 0.2s, 259781 effective words/s\n",
      "2023-12-06 15:04:42,485 : INFO : EPOCH 8: training on 99524 raw words (62813 effective words) took 0.2s, 256627 effective words/s\n",
      "2023-12-06 15:04:42,736 : INFO : EPOCH 9: training on 99524 raw words (62690 effective words) took 0.2s, 256215 effective words/s\n",
      "2023-12-06 15:04:42,737 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (626927 effective words) took 2.5s, 246946 effective words/s', 'datetime': '2023-12-06T15:04:42.737028', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:04:42,737 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:04:42.737028', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 69%|   | 334/486 [51:04<31:58, 12.62s/it]2023-12-06 15:04:45,695 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:04:45,696 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:04:45,717 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:04:45,718 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:04:45,725 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:04:45.725561', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:04:45,726 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:04:45.726561', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:04:45,732 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:04:45,733 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:04:45,734 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:04:45.734069', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:04:45,742 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:04:45,743 : INFO : resetting layer weights\n",
      "2023-12-06 15:04:45,749 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:04:45.749413', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:04:46,001 : INFO : EPOCH 0: training on 99524 raw words (62505 effective words) took 0.2s, 252088 effective words/s\n",
      "2023-12-06 15:04:46,289 : INFO : EPOCH 1: training on 99524 raw words (62779 effective words) took 0.3s, 224726 effective words/s\n",
      "2023-12-06 15:04:46,557 : INFO : EPOCH 2: training on 99524 raw words (62612 effective words) took 0.3s, 236948 effective words/s\n",
      "2023-12-06 15:04:46,826 : INFO : EPOCH 3: training on 99524 raw words (62717 effective words) took 0.3s, 237990 effective words/s\n",
      "2023-12-06 15:04:47,094 : INFO : EPOCH 4: training on 99524 raw words (62728 effective words) took 0.3s, 236694 effective words/s\n",
      "2023-12-06 15:04:47,361 : INFO : EPOCH 5: training on 99524 raw words (62653 effective words) took 0.3s, 238539 effective words/s\n",
      "2023-12-06 15:04:47,627 : INFO : EPOCH 6: training on 99524 raw words (62686 effective words) took 0.3s, 240162 effective words/s\n",
      "2023-12-06 15:04:47,895 : INFO : EPOCH 7: training on 99524 raw words (62849 effective words) took 0.3s, 238134 effective words/s\n",
      "2023-12-06 15:04:48,158 : INFO : EPOCH 8: training on 99524 raw words (62779 effective words) took 0.3s, 242495 effective words/s\n",
      "2023-12-06 15:04:48,429 : INFO : EPOCH 9: training on 99524 raw words (62863 effective words) took 0.3s, 235344 effective words/s\n",
      "2023-12-06 15:04:48,430 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627171 effective words) took 2.7s, 233998 effective words/s', 'datetime': '2023-12-06T15:04:48.430566', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:04:48,431 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:04:48.431566', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 69%|   | 335/486 [51:10<26:36, 10.57s/it]2023-12-06 15:04:51,491 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:04:51,492 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:04:51,514 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:04:51,514 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:04:51,521 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:04:51.521516', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:04:51,522 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:04:51.522520', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:04:51,528 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:04:51,529 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:04:51,529 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:04:51.529452', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:04:51,541 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:04:51,542 : INFO : resetting layer weights\n",
      "2023-12-06 15:04:51,546 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:04:51.546775', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:04:51,854 : INFO : EPOCH 0: training on 99524 raw words (62721 effective words) took 0.3s, 206997 effective words/s\n",
      "2023-12-06 15:04:52,128 : INFO : EPOCH 1: training on 99524 raw words (62744 effective words) took 0.3s, 234252 effective words/s\n",
      "2023-12-06 15:04:52,402 : INFO : EPOCH 2: training on 99524 raw words (62601 effective words) took 0.3s, 232529 effective words/s\n",
      "2023-12-06 15:04:52,680 : INFO : EPOCH 3: training on 99524 raw words (62785 effective words) took 0.3s, 229675 effective words/s\n",
      "2023-12-06 15:04:52,968 : INFO : EPOCH 4: training on 99524 raw words (62819 effective words) took 0.3s, 221721 effective words/s\n",
      "2023-12-06 15:04:53,251 : INFO : EPOCH 5: training on 99524 raw words (62695 effective words) took 0.3s, 226204 effective words/s\n",
      "2023-12-06 15:04:53,578 : INFO : EPOCH 6: training on 99524 raw words (62894 effective words) took 0.3s, 194918 effective words/s\n",
      "2023-12-06 15:04:53,851 : INFO : EPOCH 7: training on 99524 raw words (62788 effective words) took 0.3s, 235745 effective words/s\n",
      "2023-12-06 15:04:54,127 : INFO : EPOCH 8: training on 99524 raw words (62571 effective words) took 0.3s, 229574 effective words/s\n",
      "2023-12-06 15:04:54,408 : INFO : EPOCH 9: training on 99524 raw words (62780 effective words) took 0.3s, 228184 effective words/s\n",
      "2023-12-06 15:04:54,409 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627398 effective words) took 2.9s, 219239 effective words/s', 'datetime': '2023-12-06T15:04:54.409497', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:04:54,410 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:04:54.410496', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 69%|   | 336/486 [51:16<23:06,  9.24s/it]2023-12-06 15:04:57,620 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:04:57,621 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:04:57,647 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:04:57,648 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:04:57,652 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:04:57.652507', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:04:57,653 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:04:57.653517', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:04:57,658 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:04:57,659 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:04:57,659 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:04:57.659788', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:04:57,669 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:04:57,669 : INFO : resetting layer weights\n",
      "2023-12-06 15:04:57,674 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:04:57.674262', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:04:57,927 : INFO : EPOCH 0: training on 99524 raw words (62877 effective words) took 0.2s, 252497 effective words/s\n",
      "2023-12-06 15:04:58,248 : INFO : EPOCH 1: training on 99524 raw words (62715 effective words) took 0.3s, 226103 effective words/s\n",
      "2023-12-06 15:04:58,542 : INFO : EPOCH 2: training on 99524 raw words (62606 effective words) took 0.3s, 216252 effective words/s\n",
      "2023-12-06 15:04:58,807 : INFO : EPOCH 3: training on 99524 raw words (62715 effective words) took 0.3s, 244213 effective words/s\n",
      "2023-12-06 15:04:59,058 : INFO : EPOCH 4: training on 99524 raw words (62509 effective words) took 0.2s, 253946 effective words/s\n",
      "2023-12-06 15:04:59,319 : INFO : EPOCH 5: training on 99524 raw words (62728 effective words) took 0.3s, 244629 effective words/s\n",
      "2023-12-06 15:04:59,584 : INFO : EPOCH 6: training on 99524 raw words (62533 effective words) took 0.3s, 239736 effective words/s\n",
      "2023-12-06 15:04:59,837 : INFO : EPOCH 7: training on 99524 raw words (62735 effective words) took 0.2s, 253599 effective words/s\n",
      "2023-12-06 15:05:00,102 : INFO : EPOCH 8: training on 99524 raw words (62624 effective words) took 0.3s, 240489 effective words/s\n",
      "2023-12-06 15:05:00,389 : INFO : EPOCH 9: training on 99524 raw words (62758 effective words) took 0.3s, 221242 effective words/s\n",
      "2023-12-06 15:05:00,649 : INFO : EPOCH 10: training on 99524 raw words (62749 effective words) took 0.3s, 245605 effective words/s\n",
      "2023-12-06 15:05:00,907 : INFO : EPOCH 11: training on 99524 raw words (62807 effective words) took 0.3s, 247601 effective words/s\n",
      "2023-12-06 15:05:01,184 : INFO : EPOCH 12: training on 99524 raw words (62763 effective words) took 0.3s, 230909 effective words/s\n",
      "2023-12-06 15:05:01,459 : INFO : EPOCH 13: training on 99524 raw words (62830 effective words) took 0.3s, 232846 effective words/s\n",
      "2023-12-06 15:05:01,727 : INFO : EPOCH 14: training on 99524 raw words (62580 effective words) took 0.3s, 237437 effective words/s\n",
      "2023-12-06 15:05:01,989 : INFO : EPOCH 15: training on 99524 raw words (62668 effective words) took 0.3s, 244196 effective words/s\n",
      "2023-12-06 15:05:02,276 : INFO : EPOCH 16: training on 99524 raw words (62599 effective words) took 0.3s, 221942 effective words/s\n",
      "2023-12-06 15:05:02,541 : INFO : EPOCH 17: training on 99524 raw words (62760 effective words) took 0.3s, 241168 effective words/s\n",
      "2023-12-06 15:05:02,800 : INFO : EPOCH 18: training on 99524 raw words (62744 effective words) took 0.3s, 246544 effective words/s\n",
      "2023-12-06 15:05:03,063 : INFO : EPOCH 19: training on 99524 raw words (62953 effective words) took 0.3s, 243888 effective words/s\n",
      "2023-12-06 15:05:03,327 : INFO : EPOCH 20: training on 99524 raw words (62794 effective words) took 0.3s, 242169 effective words/s\n",
      "2023-12-06 15:05:03,594 : INFO : EPOCH 21: training on 99524 raw words (62579 effective words) took 0.3s, 238581 effective words/s\n",
      "2023-12-06 15:05:03,857 : INFO : EPOCH 22: training on 99524 raw words (62797 effective words) took 0.3s, 242700 effective words/s\n",
      "2023-12-06 15:05:04,116 : INFO : EPOCH 23: training on 99524 raw words (62738 effective words) took 0.3s, 247172 effective words/s\n",
      "2023-12-06 15:05:04,366 : INFO : EPOCH 24: training on 99524 raw words (62766 effective words) took 0.2s, 255572 effective words/s\n",
      "2023-12-06 15:05:04,630 : INFO : EPOCH 25: training on 99524 raw words (62569 effective words) took 0.3s, 240039 effective words/s\n",
      "2023-12-06 15:05:04,895 : INFO : EPOCH 26: training on 99524 raw words (62777 effective words) took 0.3s, 241769 effective words/s\n",
      "2023-12-06 15:05:05,156 : INFO : EPOCH 27: training on 99524 raw words (62797 effective words) took 0.3s, 246032 effective words/s\n",
      "2023-12-06 15:05:05,416 : INFO : EPOCH 28: training on 99524 raw words (62714 effective words) took 0.3s, 244752 effective words/s\n",
      "2023-12-06 15:05:05,686 : INFO : EPOCH 29: training on 99524 raw words (62715 effective words) took 0.3s, 236179 effective words/s\n",
      "2023-12-06 15:05:05,687 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881499 effective words) took 8.0s, 234811 effective words/s', 'datetime': '2023-12-06T15:05:05.687925', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:05:05,687 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:05:05.687925', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 69%|   | 337/486 [51:27<24:48,  9.99s/it]2023-12-06 15:05:09,348 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:05:09,348 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:05:09,371 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:05:09,372 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:05:09,378 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:05:09.378151', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:05:09,379 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:05:09.379152', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:05:09,386 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:05:09,387 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:05:09,387 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:05:09.387346', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:05:09,400 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:05:09,400 : INFO : resetting layer weights\n",
      "2023-12-06 15:05:09,405 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:05:09.405231', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:05:09,683 : INFO : EPOCH 0: training on 99524 raw words (62729 effective words) took 0.3s, 229817 effective words/s\n",
      "2023-12-06 15:05:09,971 : INFO : EPOCH 1: training on 99524 raw words (62739 effective words) took 0.3s, 225230 effective words/s\n",
      "2023-12-06 15:05:10,245 : INFO : EPOCH 2: training on 99524 raw words (62759 effective words) took 0.3s, 233572 effective words/s\n",
      "2023-12-06 15:05:10,504 : INFO : EPOCH 3: training on 99524 raw words (62704 effective words) took 0.3s, 246087 effective words/s\n",
      "2023-12-06 15:05:10,766 : INFO : EPOCH 4: training on 99524 raw words (62636 effective words) took 0.3s, 244447 effective words/s\n",
      "2023-12-06 15:05:11,030 : INFO : EPOCH 5: training on 99524 raw words (62771 effective words) took 0.3s, 241683 effective words/s\n",
      "2023-12-06 15:05:11,302 : INFO : EPOCH 6: training on 99524 raw words (62720 effective words) took 0.3s, 234214 effective words/s\n",
      "2023-12-06 15:05:11,573 : INFO : EPOCH 7: training on 99524 raw words (62854 effective words) took 0.3s, 234918 effective words/s\n",
      "2023-12-06 15:05:11,845 : INFO : EPOCH 8: training on 99524 raw words (62706 effective words) took 0.3s, 235091 effective words/s\n",
      "2023-12-06 15:05:12,113 : INFO : EPOCH 9: training on 99524 raw words (62822 effective words) took 0.3s, 238416 effective words/s\n",
      "2023-12-06 15:05:12,379 : INFO : EPOCH 10: training on 99524 raw words (62666 effective words) took 0.3s, 239589 effective words/s\n",
      "2023-12-06 15:05:12,648 : INFO : EPOCH 11: training on 99524 raw words (62852 effective words) took 0.3s, 237132 effective words/s\n",
      "2023-12-06 15:05:12,916 : INFO : EPOCH 12: training on 99524 raw words (62804 effective words) took 0.3s, 239375 effective words/s\n",
      "2023-12-06 15:05:13,183 : INFO : EPOCH 13: training on 99524 raw words (62672 effective words) took 0.3s, 238946 effective words/s\n",
      "2023-12-06 15:05:13,456 : INFO : EPOCH 14: training on 99524 raw words (62857 effective words) took 0.3s, 233775 effective words/s\n",
      "2023-12-06 15:05:13,722 : INFO : EPOCH 15: training on 99524 raw words (62525 effective words) took 0.3s, 240100 effective words/s\n",
      "2023-12-06 15:05:13,997 : INFO : EPOCH 16: training on 99524 raw words (62575 effective words) took 0.3s, 230849 effective words/s\n",
      "2023-12-06 15:05:14,305 : INFO : EPOCH 17: training on 99524 raw words (62903 effective words) took 0.3s, 207443 effective words/s\n",
      "2023-12-06 15:05:14,570 : INFO : EPOCH 18: training on 99524 raw words (62842 effective words) took 0.3s, 241493 effective words/s\n",
      "2023-12-06 15:05:14,834 : INFO : EPOCH 19: training on 99524 raw words (62849 effective words) took 0.3s, 241892 effective words/s\n",
      "2023-12-06 15:05:15,114 : INFO : EPOCH 20: training on 99524 raw words (62892 effective words) took 0.3s, 229277 effective words/s\n",
      "2023-12-06 15:05:15,395 : INFO : EPOCH 21: training on 99524 raw words (62696 effective words) took 0.3s, 226810 effective words/s\n",
      "2023-12-06 15:05:15,665 : INFO : EPOCH 22: training on 99524 raw words (62819 effective words) took 0.3s, 235875 effective words/s\n",
      "2023-12-06 15:05:15,985 : INFO : EPOCH 23: training on 99524 raw words (62848 effective words) took 0.3s, 202349 effective words/s\n",
      "2023-12-06 15:05:16,253 : INFO : EPOCH 24: training on 99524 raw words (62722 effective words) took 0.3s, 238674 effective words/s\n",
      "2023-12-06 15:05:16,532 : INFO : EPOCH 25: training on 99524 raw words (62924 effective words) took 0.3s, 230355 effective words/s\n",
      "2023-12-06 15:05:16,804 : INFO : EPOCH 26: training on 99524 raw words (62629 effective words) took 0.3s, 235513 effective words/s\n",
      "2023-12-06 15:05:17,066 : INFO : EPOCH 27: training on 99524 raw words (62746 effective words) took 0.3s, 243529 effective words/s\n",
      "2023-12-06 15:05:17,369 : INFO : EPOCH 28: training on 99524 raw words (62600 effective words) took 0.3s, 210507 effective words/s\n",
      "2023-12-06 15:05:17,661 : INFO : EPOCH 29: training on 99524 raw words (62621 effective words) took 0.3s, 219300 effective words/s\n",
      "2023-12-06 15:05:17,662 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1882482 effective words) took 8.3s, 227994 effective words/s', 'datetime': '2023-12-06T15:05:17.662937', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:05:17,663 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:05:17.663938', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 70%|   | 338/486 [51:40<26:11, 10.62s/it]2023-12-06 15:05:21,438 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:05:21,439 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:05:21,462 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:05:21,463 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:05:21,470 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:05:21.470461', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:05:21,470 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:05:21.470461', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:05:21,476 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:05:21,477 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:05:21,478 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:05:21.478467', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:05:21,490 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:05:21,491 : INFO : resetting layer weights\n",
      "2023-12-06 15:05:21,495 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:05:21.495278', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:05:21,803 : INFO : EPOCH 0: training on 99524 raw words (62697 effective words) took 0.3s, 206124 effective words/s\n",
      "2023-12-06 15:05:22,080 : INFO : EPOCH 1: training on 99524 raw words (62689 effective words) took 0.3s, 231708 effective words/s\n",
      "2023-12-06 15:05:22,360 : INFO : EPOCH 2: training on 99524 raw words (62719 effective words) took 0.3s, 227848 effective words/s\n",
      "2023-12-06 15:05:22,637 : INFO : EPOCH 3: training on 99524 raw words (62823 effective words) took 0.3s, 230824 effective words/s\n",
      "2023-12-06 15:05:22,916 : INFO : EPOCH 4: training on 99524 raw words (62854 effective words) took 0.3s, 229594 effective words/s\n",
      "2023-12-06 15:05:23,194 : INFO : EPOCH 5: training on 99524 raw words (62778 effective words) took 0.3s, 228947 effective words/s\n",
      "2023-12-06 15:05:23,473 : INFO : EPOCH 6: training on 99524 raw words (62723 effective words) took 0.3s, 229610 effective words/s\n",
      "2023-12-06 15:05:23,749 : INFO : EPOCH 7: training on 99524 raw words (62642 effective words) took 0.3s, 230626 effective words/s\n",
      "2023-12-06 15:05:24,037 : INFO : EPOCH 8: training on 99524 raw words (62603 effective words) took 0.3s, 220373 effective words/s\n",
      "2023-12-06 15:05:24,309 : INFO : EPOCH 9: training on 99524 raw words (62630 effective words) took 0.3s, 233914 effective words/s\n",
      "2023-12-06 15:05:24,578 : INFO : EPOCH 10: training on 99524 raw words (62709 effective words) took 0.3s, 237654 effective words/s\n",
      "2023-12-06 15:05:24,855 : INFO : EPOCH 11: training on 99524 raw words (62710 effective words) took 0.3s, 231922 effective words/s\n",
      "2023-12-06 15:05:25,131 : INFO : EPOCH 12: training on 99524 raw words (62819 effective words) took 0.3s, 230423 effective words/s\n",
      "2023-12-06 15:05:25,408 : INFO : EPOCH 13: training on 99524 raw words (62754 effective words) took 0.3s, 231334 effective words/s\n",
      "2023-12-06 15:05:25,688 : INFO : EPOCH 14: training on 99524 raw words (62671 effective words) took 0.3s, 226399 effective words/s\n",
      "2023-12-06 15:05:25,971 : INFO : EPOCH 15: training on 99524 raw words (62770 effective words) took 0.3s, 225624 effective words/s\n",
      "2023-12-06 15:05:26,266 : INFO : EPOCH 16: training on 99524 raw words (62782 effective words) took 0.3s, 216605 effective words/s\n",
      "2023-12-06 15:05:26,538 : INFO : EPOCH 17: training on 99524 raw words (62749 effective words) took 0.3s, 234335 effective words/s\n",
      "2023-12-06 15:05:26,810 : INFO : EPOCH 18: training on 99524 raw words (62725 effective words) took 0.3s, 233940 effective words/s\n",
      "2023-12-06 15:05:27,084 : INFO : EPOCH 19: training on 99524 raw words (62503 effective words) took 0.3s, 233407 effective words/s\n",
      "2023-12-06 15:05:27,357 : INFO : EPOCH 20: training on 99524 raw words (62845 effective words) took 0.3s, 233581 effective words/s\n",
      "2023-12-06 15:05:27,634 : INFO : EPOCH 21: training on 99524 raw words (62830 effective words) took 0.3s, 231194 effective words/s\n",
      "2023-12-06 15:05:27,909 : INFO : EPOCH 22: training on 99524 raw words (62743 effective words) took 0.3s, 230884 effective words/s\n",
      "2023-12-06 15:05:28,204 : INFO : EPOCH 23: training on 99524 raw words (62703 effective words) took 0.3s, 216483 effective words/s\n",
      "2023-12-06 15:05:28,484 : INFO : EPOCH 24: training on 99524 raw words (62628 effective words) took 0.3s, 227737 effective words/s\n",
      "2023-12-06 15:05:28,763 : INFO : EPOCH 25: training on 99524 raw words (62862 effective words) took 0.3s, 229570 effective words/s\n",
      "2023-12-06 15:05:29,036 : INFO : EPOCH 26: training on 99524 raw words (62769 effective words) took 0.3s, 234210 effective words/s\n",
      "2023-12-06 15:05:29,313 : INFO : EPOCH 27: training on 99524 raw words (62721 effective words) took 0.3s, 229458 effective words/s\n",
      "2023-12-06 15:05:29,588 : INFO : EPOCH 28: training on 99524 raw words (62771 effective words) took 0.3s, 232377 effective words/s\n",
      "2023-12-06 15:05:29,865 : INFO : EPOCH 29: training on 99524 raw words (62723 effective words) took 0.3s, 230111 effective words/s\n",
      "2023-12-06 15:05:29,866 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881945 effective words) took 8.4s, 224834 effective words/s', 'datetime': '2023-12-06T15:05:29.866236', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:05:29,866 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:05:29.866236', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 70%|   | 339/486 [51:52<27:17, 11.14s/it]2023-12-06 15:05:33,789 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:05:33,789 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:05:33,815 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:05:33,816 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:05:33,821 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:05:33.821119', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:05:33,822 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:05:33.822120', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:05:33,828 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:05:33,829 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:05:33,830 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:05:33.830308', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:05:33,838 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:05:33,839 : INFO : resetting layer weights\n",
      "2023-12-06 15:05:33,843 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:05:33.843705', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:05:34,107 : INFO : EPOCH 0: training on 99524 raw words (62770 effective words) took 0.3s, 243370 effective words/s\n",
      "2023-12-06 15:05:34,396 : INFO : EPOCH 1: training on 99524 raw words (62737 effective words) took 0.3s, 249892 effective words/s\n",
      "2023-12-06 15:05:34,645 : INFO : EPOCH 2: training on 99524 raw words (62621 effective words) took 0.2s, 257675 effective words/s\n",
      "2023-12-06 15:05:34,901 : INFO : EPOCH 3: training on 99524 raw words (62710 effective words) took 0.3s, 248274 effective words/s\n",
      "2023-12-06 15:05:35,151 : INFO : EPOCH 4: training on 99524 raw words (62660 effective words) took 0.2s, 255770 effective words/s\n",
      "2023-12-06 15:05:35,402 : INFO : EPOCH 5: training on 99524 raw words (62590 effective words) took 0.2s, 253981 effective words/s\n",
      "2023-12-06 15:05:35,662 : INFO : EPOCH 6: training on 99524 raw words (62661 effective words) took 0.3s, 245175 effective words/s\n",
      "2023-12-06 15:05:35,915 : INFO : EPOCH 7: training on 99524 raw words (62890 effective words) took 0.2s, 251870 effective words/s\n",
      "2023-12-06 15:05:36,163 : INFO : EPOCH 8: training on 99524 raw words (62677 effective words) took 0.2s, 257312 effective words/s\n",
      "2023-12-06 15:05:36,416 : INFO : EPOCH 9: training on 99524 raw words (62762 effective words) took 0.2s, 253576 effective words/s\n",
      "2023-12-06 15:05:36,665 : INFO : EPOCH 10: training on 99524 raw words (62808 effective words) took 0.2s, 255961 effective words/s\n",
      "2023-12-06 15:05:36,915 : INFO : EPOCH 11: training on 99524 raw words (62511 effective words) took 0.2s, 254603 effective words/s\n",
      "2023-12-06 15:05:37,176 : INFO : EPOCH 12: training on 99524 raw words (62690 effective words) took 0.3s, 243827 effective words/s\n",
      "2023-12-06 15:05:37,428 : INFO : EPOCH 13: training on 99524 raw words (62793 effective words) took 0.2s, 253535 effective words/s\n",
      "2023-12-06 15:05:37,680 : INFO : EPOCH 14: training on 99524 raw words (62709 effective words) took 0.2s, 254000 effective words/s\n",
      "2023-12-06 15:05:37,932 : INFO : EPOCH 15: training on 99524 raw words (62624 effective words) took 0.2s, 252860 effective words/s\n",
      "2023-12-06 15:05:38,190 : INFO : EPOCH 16: training on 99524 raw words (62577 effective words) took 0.3s, 247414 effective words/s\n",
      "2023-12-06 15:05:38,442 : INFO : EPOCH 17: training on 99524 raw words (62667 effective words) took 0.2s, 253484 effective words/s\n",
      "2023-12-06 15:05:38,695 : INFO : EPOCH 18: training on 99524 raw words (62570 effective words) took 0.2s, 250542 effective words/s\n",
      "2023-12-06 15:05:38,941 : INFO : EPOCH 19: training on 99524 raw words (62848 effective words) took 0.2s, 260218 effective words/s\n",
      "2023-12-06 15:05:39,198 : INFO : EPOCH 20: training on 99524 raw words (62627 effective words) took 0.3s, 248334 effective words/s\n",
      "2023-12-06 15:05:39,452 : INFO : EPOCH 21: training on 99524 raw words (62708 effective words) took 0.2s, 251772 effective words/s\n",
      "2023-12-06 15:05:39,701 : INFO : EPOCH 22: training on 99524 raw words (62668 effective words) took 0.2s, 256255 effective words/s\n",
      "2023-12-06 15:05:39,954 : INFO : EPOCH 23: training on 99524 raw words (62743 effective words) took 0.2s, 252984 effective words/s\n",
      "2023-12-06 15:05:40,208 : INFO : EPOCH 24: training on 99524 raw words (62805 effective words) took 0.2s, 252844 effective words/s\n",
      "2023-12-06 15:05:40,467 : INFO : EPOCH 25: training on 99524 raw words (62749 effective words) took 0.3s, 246243 effective words/s\n",
      "2023-12-06 15:05:40,717 : INFO : EPOCH 26: training on 99524 raw words (62674 effective words) took 0.2s, 255142 effective words/s\n",
      "2023-12-06 15:05:40,968 : INFO : EPOCH 27: training on 99524 raw words (62622 effective words) took 0.2s, 254536 effective words/s\n",
      "2023-12-06 15:05:41,222 : INFO : EPOCH 28: training on 99524 raw words (62761 effective words) took 0.2s, 251727 effective words/s\n",
      "2023-12-06 15:05:41,477 : INFO : EPOCH 29: training on 99524 raw words (62901 effective words) took 0.3s, 251269 effective words/s\n",
      "2023-12-06 15:05:41,730 : INFO : EPOCH 30: training on 99524 raw words (62739 effective words) took 0.2s, 252293 effective words/s\n",
      "2023-12-06 15:05:41,987 : INFO : EPOCH 31: training on 99524 raw words (62644 effective words) took 0.3s, 248169 effective words/s\n",
      "2023-12-06 15:05:42,245 : INFO : EPOCH 32: training on 99524 raw words (62808 effective words) took 0.3s, 247846 effective words/s\n",
      "2023-12-06 15:05:42,497 : INFO : EPOCH 33: training on 99524 raw words (62791 effective words) took 0.2s, 254188 effective words/s\n",
      "2023-12-06 15:05:42,744 : INFO : EPOCH 34: training on 99524 raw words (62723 effective words) took 0.2s, 259113 effective words/s\n",
      "2023-12-06 15:05:42,996 : INFO : EPOCH 35: training on 99524 raw words (62832 effective words) took 0.2s, 253464 effective words/s\n",
      "2023-12-06 15:05:43,249 : INFO : EPOCH 36: training on 99524 raw words (62789 effective words) took 0.2s, 253421 effective words/s\n",
      "2023-12-06 15:05:43,495 : INFO : EPOCH 37: training on 99524 raw words (62850 effective words) took 0.2s, 260226 effective words/s\n",
      "2023-12-06 15:05:43,761 : INFO : EPOCH 38: training on 99524 raw words (62599 effective words) took 0.3s, 241361 effective words/s\n",
      "2023-12-06 15:05:44,014 : INFO : EPOCH 39: training on 99524 raw words (62715 effective words) took 0.2s, 253398 effective words/s\n",
      "2023-12-06 15:05:44,269 : INFO : EPOCH 40: training on 99524 raw words (62788 effective words) took 0.2s, 251947 effective words/s\n",
      "2023-12-06 15:05:44,513 : INFO : EPOCH 41: training on 99524 raw words (62826 effective words) took 0.2s, 263141 effective words/s\n",
      "2023-12-06 15:05:44,755 : INFO : EPOCH 42: training on 99524 raw words (62769 effective words) took 0.2s, 263708 effective words/s\n",
      "2023-12-06 15:05:45,008 : INFO : EPOCH 43: training on 99524 raw words (62864 effective words) took 0.2s, 254071 effective words/s\n",
      "2023-12-06 15:05:45,269 : INFO : EPOCH 44: training on 99524 raw words (62789 effective words) took 0.3s, 243835 effective words/s\n",
      "2023-12-06 15:05:45,518 : INFO : EPOCH 45: training on 99524 raw words (62573 effective words) took 0.2s, 257196 effective words/s\n",
      "2023-12-06 15:05:45,773 : INFO : EPOCH 46: training on 99524 raw words (62752 effective words) took 0.2s, 251183 effective words/s\n",
      "2023-12-06 15:05:46,026 : INFO : EPOCH 47: training on 99524 raw words (62863 effective words) took 0.2s, 253809 effective words/s\n",
      "2023-12-06 15:05:46,289 : INFO : EPOCH 48: training on 99524 raw words (62795 effective words) took 0.3s, 242431 effective words/s\n",
      "2023-12-06 15:05:46,552 : INFO : EPOCH 49: training on 99524 raw words (62713 effective words) took 0.3s, 243063 effective words/s\n",
      "2023-12-06 15:05:46,552 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136355 effective words) took 12.7s, 246784 effective words/s', 'datetime': '2023-12-06T15:05:46.552663', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:05:46,554 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:05:46.554092', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 70%|   | 340/486 [52:09<31:20, 12.88s/it]2023-12-06 15:05:50,733 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:05:50,733 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:05:50,759 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:05:50,760 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:05:50,765 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:05:50.765055', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:05:50,765 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:05:50.765055', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:05:50,770 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:05:50,771 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:05:50,772 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:05:50.771261', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:05:50,780 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:05:50,780 : INFO : resetting layer weights\n",
      "2023-12-06 15:05:50,784 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:05:50.784249', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:05:51,061 : INFO : EPOCH 0: training on 99524 raw words (62653 effective words) took 0.3s, 230120 effective words/s\n",
      "2023-12-06 15:05:51,356 : INFO : EPOCH 1: training on 99524 raw words (62878 effective words) took 0.3s, 222651 effective words/s\n",
      "2023-12-06 15:05:51,625 : INFO : EPOCH 2: training on 99524 raw words (62784 effective words) took 0.3s, 237506 effective words/s\n",
      "2023-12-06 15:05:51,891 : INFO : EPOCH 3: training on 99524 raw words (62733 effective words) took 0.3s, 240714 effective words/s\n",
      "2023-12-06 15:05:52,155 : INFO : EPOCH 4: training on 99524 raw words (62579 effective words) took 0.3s, 240168 effective words/s\n",
      "2023-12-06 15:05:52,425 : INFO : EPOCH 5: training on 99524 raw words (62834 effective words) took 0.3s, 237339 effective words/s\n",
      "2023-12-06 15:05:52,690 : INFO : EPOCH 6: training on 99524 raw words (62614 effective words) took 0.3s, 240000 effective words/s\n",
      "2023-12-06 15:05:52,957 : INFO : EPOCH 7: training on 99524 raw words (62716 effective words) took 0.3s, 238121 effective words/s\n",
      "2023-12-06 15:05:53,225 : INFO : EPOCH 8: training on 99524 raw words (62612 effective words) took 0.3s, 238879 effective words/s\n",
      "2023-12-06 15:05:53,497 : INFO : EPOCH 9: training on 99524 raw words (62704 effective words) took 0.3s, 233898 effective words/s\n",
      "2023-12-06 15:05:53,767 : INFO : EPOCH 10: training on 99524 raw words (62731 effective words) took 0.3s, 236760 effective words/s\n",
      "2023-12-06 15:05:54,036 : INFO : EPOCH 11: training on 99524 raw words (62729 effective words) took 0.3s, 237284 effective words/s\n",
      "2023-12-06 15:05:54,304 : INFO : EPOCH 12: training on 99524 raw words (62832 effective words) took 0.3s, 238322 effective words/s\n",
      "2023-12-06 15:05:54,588 : INFO : EPOCH 13: training on 99524 raw words (62839 effective words) took 0.3s, 224667 effective words/s\n",
      "2023-12-06 15:05:54,854 : INFO : EPOCH 14: training on 99524 raw words (62808 effective words) took 0.3s, 240394 effective words/s\n",
      "2023-12-06 15:05:55,118 : INFO : EPOCH 15: training on 99524 raw words (62676 effective words) took 0.3s, 241958 effective words/s\n",
      "2023-12-06 15:05:55,390 : INFO : EPOCH 16: training on 99524 raw words (62642 effective words) took 0.3s, 233626 effective words/s\n",
      "2023-12-06 15:05:55,657 : INFO : EPOCH 17: training on 99524 raw words (62721 effective words) took 0.3s, 239212 effective words/s\n",
      "2023-12-06 15:05:55,922 : INFO : EPOCH 18: training on 99524 raw words (62804 effective words) took 0.3s, 241101 effective words/s\n",
      "2023-12-06 15:05:56,190 : INFO : EPOCH 19: training on 99524 raw words (62759 effective words) took 0.3s, 237984 effective words/s\n",
      "2023-12-06 15:05:56,475 : INFO : EPOCH 20: training on 99524 raw words (62516 effective words) took 0.3s, 227615 effective words/s\n",
      "2023-12-06 15:05:56,745 : INFO : EPOCH 21: training on 99524 raw words (62586 effective words) took 0.3s, 235989 effective words/s\n",
      "2023-12-06 15:05:57,014 : INFO : EPOCH 22: training on 99524 raw words (62678 effective words) took 0.3s, 237606 effective words/s\n",
      "2023-12-06 15:05:57,284 : INFO : EPOCH 23: training on 99524 raw words (62505 effective words) took 0.3s, 235118 effective words/s\n",
      "2023-12-06 15:05:57,561 : INFO : EPOCH 24: training on 99524 raw words (62717 effective words) took 0.3s, 230199 effective words/s\n",
      "2023-12-06 15:05:57,829 : INFO : EPOCH 25: training on 99524 raw words (62639 effective words) took 0.3s, 238465 effective words/s\n",
      "2023-12-06 15:05:58,104 : INFO : EPOCH 26: training on 99524 raw words (62735 effective words) took 0.3s, 231162 effective words/s\n",
      "2023-12-06 15:05:58,378 : INFO : EPOCH 27: training on 99524 raw words (62752 effective words) took 0.3s, 232778 effective words/s\n",
      "2023-12-06 15:05:58,647 : INFO : EPOCH 28: training on 99524 raw words (62699 effective words) took 0.3s, 237388 effective words/s\n",
      "2023-12-06 15:05:58,914 : INFO : EPOCH 29: training on 99524 raw words (62573 effective words) took 0.3s, 237174 effective words/s\n",
      "2023-12-06 15:05:59,188 : INFO : EPOCH 30: training on 99524 raw words (62617 effective words) took 0.3s, 232461 effective words/s\n",
      "2023-12-06 15:05:59,456 : INFO : EPOCH 31: training on 99524 raw words (62821 effective words) took 0.3s, 238675 effective words/s\n",
      "2023-12-06 15:05:59,730 : INFO : EPOCH 32: training on 99524 raw words (62923 effective words) took 0.3s, 233388 effective words/s\n",
      "2023-12-06 15:05:59,998 : INFO : EPOCH 33: training on 99524 raw words (62773 effective words) took 0.3s, 238542 effective words/s\n",
      "2023-12-06 15:06:00,265 : INFO : EPOCH 34: training on 99524 raw words (62554 effective words) took 0.3s, 238895 effective words/s\n",
      "2023-12-06 15:06:00,537 : INFO : EPOCH 35: training on 99524 raw words (62807 effective words) took 0.3s, 233891 effective words/s\n",
      "2023-12-06 15:06:00,815 : INFO : EPOCH 36: training on 99524 raw words (62709 effective words) took 0.3s, 229934 effective words/s\n",
      "2023-12-06 15:06:01,089 : INFO : EPOCH 37: training on 99524 raw words (62728 effective words) took 0.3s, 231261 effective words/s\n",
      "2023-12-06 15:06:01,373 : INFO : EPOCH 38: training on 99524 raw words (62909 effective words) took 0.3s, 225926 effective words/s\n",
      "2023-12-06 15:06:01,640 : INFO : EPOCH 39: training on 99524 raw words (62880 effective words) took 0.3s, 240004 effective words/s\n",
      "2023-12-06 15:06:01,911 : INFO : EPOCH 40: training on 99524 raw words (62874 effective words) took 0.3s, 236607 effective words/s\n",
      "2023-12-06 15:06:02,176 : INFO : EPOCH 41: training on 99524 raw words (62821 effective words) took 0.3s, 241391 effective words/s\n",
      "2023-12-06 15:06:02,450 : INFO : EPOCH 42: training on 99524 raw words (62773 effective words) took 0.3s, 232722 effective words/s\n",
      "2023-12-06 15:06:02,725 : INFO : EPOCH 43: training on 99524 raw words (62523 effective words) took 0.3s, 230520 effective words/s\n",
      "2023-12-06 15:06:03,018 : INFO : EPOCH 44: training on 99524 raw words (62554 effective words) took 0.3s, 217581 effective words/s\n",
      "2023-12-06 15:06:03,299 : INFO : EPOCH 45: training on 99524 raw words (62732 effective words) took 0.3s, 227147 effective words/s\n",
      "2023-12-06 15:06:03,580 : INFO : EPOCH 46: training on 99524 raw words (62672 effective words) took 0.3s, 226326 effective words/s\n",
      "2023-12-06 15:06:03,853 : INFO : EPOCH 47: training on 99524 raw words (62921 effective words) took 0.3s, 234345 effective words/s\n",
      "2023-12-06 15:06:04,136 : INFO : EPOCH 48: training on 99524 raw words (62574 effective words) took 0.3s, 224193 effective words/s\n",
      "2023-12-06 15:06:04,419 : INFO : EPOCH 49: training on 99524 raw words (62409 effective words) took 0.3s, 224335 effective words/s\n",
      "2023-12-06 15:06:04,421 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3135622 effective words) took 13.6s, 229960 effective words/s', 'datetime': '2023-12-06T15:06:04.421508', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:06:04,421 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:06:04.421508', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 70%|   | 341/486 [52:27<35:02, 14.50s/it]2023-12-06 15:06:09,018 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:06:09,018 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:06:09,041 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:06:09,041 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:06:09,048 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:06:09.048467', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:06:09,048 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:06:09.048467', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:06:09,056 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:06:09,057 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:06:09,057 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:06:09.057446', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:06:09,066 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:06:09,067 : INFO : resetting layer weights\n",
      "2023-12-06 15:06:09,072 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:06:09.072975', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:06:09,378 : INFO : EPOCH 0: training on 99524 raw words (62757 effective words) took 0.3s, 208282 effective words/s\n",
      "2023-12-06 15:06:09,685 : INFO : EPOCH 1: training on 99524 raw words (62739 effective words) took 0.3s, 214784 effective words/s\n",
      "2023-12-06 15:06:09,960 : INFO : EPOCH 2: training on 99524 raw words (62894 effective words) took 0.3s, 233267 effective words/s\n",
      "2023-12-06 15:06:10,241 : INFO : EPOCH 3: training on 99524 raw words (62643 effective words) took 0.3s, 225810 effective words/s\n",
      "2023-12-06 15:06:10,515 : INFO : EPOCH 4: training on 99524 raw words (62722 effective words) took 0.3s, 233114 effective words/s\n",
      "2023-12-06 15:06:10,794 : INFO : EPOCH 5: training on 99524 raw words (62650 effective words) took 0.3s, 228303 effective words/s\n",
      "2023-12-06 15:06:11,082 : INFO : EPOCH 6: training on 99524 raw words (62777 effective words) took 0.3s, 221041 effective words/s\n",
      "2023-12-06 15:06:11,364 : INFO : EPOCH 7: training on 99524 raw words (62758 effective words) took 0.3s, 226491 effective words/s\n",
      "2023-12-06 15:06:11,643 : INFO : EPOCH 8: training on 99524 raw words (62652 effective words) took 0.3s, 229109 effective words/s\n",
      "2023-12-06 15:06:11,928 : INFO : EPOCH 9: training on 99524 raw words (62801 effective words) took 0.3s, 222983 effective words/s\n",
      "2023-12-06 15:06:12,206 : INFO : EPOCH 10: training on 99524 raw words (62653 effective words) took 0.3s, 229576 effective words/s\n",
      "2023-12-06 15:06:12,482 : INFO : EPOCH 11: training on 99524 raw words (62748 effective words) took 0.3s, 230452 effective words/s\n",
      "2023-12-06 15:06:12,779 : INFO : EPOCH 12: training on 99524 raw words (62748 effective words) took 0.3s, 215199 effective words/s\n",
      "2023-12-06 15:06:13,057 : INFO : EPOCH 13: training on 99524 raw words (62816 effective words) took 0.3s, 229818 effective words/s\n",
      "2023-12-06 15:06:13,328 : INFO : EPOCH 14: training on 99524 raw words (62692 effective words) took 0.3s, 234748 effective words/s\n",
      "2023-12-06 15:06:13,598 : INFO : EPOCH 15: training on 99524 raw words (62571 effective words) took 0.3s, 236856 effective words/s\n",
      "2023-12-06 15:06:13,880 : INFO : EPOCH 16: training on 99524 raw words (62889 effective words) took 0.3s, 227357 effective words/s\n",
      "2023-12-06 15:06:14,156 : INFO : EPOCH 17: training on 99524 raw words (62674 effective words) took 0.3s, 230618 effective words/s\n",
      "2023-12-06 15:06:14,440 : INFO : EPOCH 18: training on 99524 raw words (62726 effective words) took 0.3s, 224193 effective words/s\n",
      "2023-12-06 15:06:14,719 : INFO : EPOCH 19: training on 99524 raw words (62698 effective words) took 0.3s, 228380 effective words/s\n",
      "2023-12-06 15:06:14,998 : INFO : EPOCH 20: training on 99524 raw words (62784 effective words) took 0.3s, 229250 effective words/s\n",
      "2023-12-06 15:06:15,268 : INFO : EPOCH 21: training on 99524 raw words (62581 effective words) took 0.3s, 236389 effective words/s\n",
      "2023-12-06 15:06:15,544 : INFO : EPOCH 22: training on 99524 raw words (62693 effective words) took 0.3s, 231868 effective words/s\n",
      "2023-12-06 15:06:15,824 : INFO : EPOCH 23: training on 99524 raw words (62681 effective words) took 0.3s, 227428 effective words/s\n",
      "2023-12-06 15:06:16,140 : INFO : EPOCH 24: training on 99524 raw words (62769 effective words) took 0.3s, 201709 effective words/s\n",
      "2023-12-06 15:06:16,416 : INFO : EPOCH 25: training on 99524 raw words (62637 effective words) took 0.3s, 230100 effective words/s\n",
      "2023-12-06 15:06:16,693 : INFO : EPOCH 26: training on 99524 raw words (62599 effective words) took 0.3s, 230074 effective words/s\n",
      "2023-12-06 15:06:16,971 : INFO : EPOCH 27: training on 99524 raw words (62878 effective words) took 0.3s, 230356 effective words/s\n",
      "2023-12-06 15:06:17,246 : INFO : EPOCH 28: training on 99524 raw words (62810 effective words) took 0.3s, 231992 effective words/s\n",
      "2023-12-06 15:06:17,535 : INFO : EPOCH 29: training on 99524 raw words (62699 effective words) took 0.3s, 220462 effective words/s\n",
      "2023-12-06 15:06:17,857 : INFO : EPOCH 30: training on 99524 raw words (62644 effective words) took 0.3s, 197839 effective words/s\n",
      "2023-12-06 15:06:18,138 : INFO : EPOCH 31: training on 99524 raw words (62896 effective words) took 0.3s, 227780 effective words/s\n",
      "2023-12-06 15:06:18,411 : INFO : EPOCH 32: training on 99524 raw words (62716 effective words) took 0.3s, 232841 effective words/s\n",
      "2023-12-06 15:06:18,688 : INFO : EPOCH 33: training on 99524 raw words (62885 effective words) took 0.3s, 230762 effective words/s\n",
      "2023-12-06 15:06:18,969 : INFO : EPOCH 34: training on 99524 raw words (62576 effective words) took 0.3s, 226493 effective words/s\n",
      "2023-12-06 15:06:19,241 : INFO : EPOCH 35: training on 99524 raw words (62512 effective words) took 0.3s, 233152 effective words/s\n",
      "2023-12-06 15:06:19,515 : INFO : EPOCH 36: training on 99524 raw words (62807 effective words) took 0.3s, 233215 effective words/s\n",
      "2023-12-06 15:06:19,793 : INFO : EPOCH 37: training on 99524 raw words (62671 effective words) took 0.3s, 229261 effective words/s\n",
      "2023-12-06 15:06:20,074 : INFO : EPOCH 38: training on 99524 raw words (62807 effective words) took 0.3s, 227976 effective words/s\n",
      "2023-12-06 15:06:20,348 : INFO : EPOCH 39: training on 99524 raw words (62852 effective words) took 0.3s, 233177 effective words/s\n",
      "2023-12-06 15:06:20,619 : INFO : EPOCH 40: training on 99524 raw words (62839 effective words) took 0.3s, 235417 effective words/s\n",
      "2023-12-06 15:06:20,893 : INFO : EPOCH 41: training on 99524 raw words (62601 effective words) took 0.3s, 232630 effective words/s\n",
      "2023-12-06 15:06:21,181 : INFO : EPOCH 42: training on 99524 raw words (62618 effective words) took 0.3s, 225145 effective words/s\n",
      "2023-12-06 15:06:21,468 : INFO : EPOCH 43: training on 99524 raw words (62774 effective words) took 0.3s, 221822 effective words/s\n",
      "2023-12-06 15:06:21,742 : INFO : EPOCH 44: training on 99524 raw words (62525 effective words) took 0.3s, 232781 effective words/s\n",
      "2023-12-06 15:06:22,020 : INFO : EPOCH 45: training on 99524 raw words (62706 effective words) took 0.3s, 229052 effective words/s\n",
      "2023-12-06 15:06:22,292 : INFO : EPOCH 46: training on 99524 raw words (62622 effective words) took 0.3s, 234915 effective words/s\n",
      "2023-12-06 15:06:22,574 : INFO : EPOCH 47: training on 99524 raw words (62592 effective words) took 0.3s, 225519 effective words/s\n",
      "2023-12-06 15:06:22,858 : INFO : EPOCH 48: training on 99524 raw words (62803 effective words) took 0.3s, 225422 effective words/s\n",
      "2023-12-06 15:06:23,131 : INFO : EPOCH 49: training on 99524 raw words (62651 effective words) took 0.3s, 233433 effective words/s\n",
      "2023-12-06 15:06:23,132 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3135836 effective words) took 14.1s, 223044 effective words/s', 'datetime': '2023-12-06T15:06:23.132824', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:06:23,133 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w5,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:06:23.133821', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 70%|   | 342/486 [52:46<37:58, 15.82s/it]2023-12-06 15:06:27,922 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:06:27,923 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:06:27,945 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:06:27,946 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:06:27,950 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:06:27.950592', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:06:27,950 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:06:27.950592', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:06:27,955 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:06:27,957 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:06:27,957 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:06:27.957639', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:06:27,968 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:06:27,968 : INFO : resetting layer weights\n",
      "2023-12-06 15:06:27,973 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:06:27.973893', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:06:28,207 : INFO : EPOCH 0: training on 99524 raw words (60323 effective words) took 0.2s, 263515 effective words/s\n",
      "2023-12-06 15:06:28,485 : INFO : EPOCH 1: training on 99524 raw words (60353 effective words) took 0.3s, 222175 effective words/s\n",
      "2023-12-06 15:06:28,745 : INFO : EPOCH 2: training on 99524 raw words (60487 effective words) took 0.3s, 236690 effective words/s\n",
      "2023-12-06 15:06:28,998 : INFO : EPOCH 3: training on 99524 raw words (60231 effective words) took 0.2s, 242798 effective words/s\n",
      "2023-12-06 15:06:29,241 : INFO : EPOCH 4: training on 99524 raw words (60379 effective words) took 0.2s, 252505 effective words/s\n",
      "2023-12-06 15:06:29,486 : INFO : EPOCH 5: training on 99524 raw words (60491 effective words) took 0.2s, 251689 effective words/s\n",
      "2023-12-06 15:06:29,743 : INFO : EPOCH 6: training on 99524 raw words (60503 effective words) took 0.3s, 240528 effective words/s\n",
      "2023-12-06 15:06:29,994 : INFO : EPOCH 7: training on 99524 raw words (60487 effective words) took 0.2s, 244868 effective words/s\n",
      "2023-12-06 15:06:30,247 : INFO : EPOCH 8: training on 99524 raw words (60487 effective words) took 0.2s, 243729 effective words/s\n",
      "2023-12-06 15:06:30,498 : INFO : EPOCH 9: training on 99524 raw words (60352 effective words) took 0.2s, 245083 effective words/s\n",
      "2023-12-06 15:06:30,499 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604093 effective words) took 2.5s, 239263 effective words/s', 'datetime': '2023-12-06T15:06:30.499661', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:06:30,499 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:06:30.499661', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 71%|   | 343/486 [52:52<30:21, 12.74s/it]2023-12-06 15:06:33,464 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:06:33,464 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:06:33,489 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:06:33,490 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:06:33,493 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:06:33.493787', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:06:33,494 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:06:33.494792', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:06:33,498 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:06:33,500 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:06:33,500 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:06:33.500796', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:06:33,508 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:06:33,508 : INFO : resetting layer weights\n",
      "2023-12-06 15:06:33,512 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:06:33.512873', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:06:33,786 : INFO : EPOCH 0: training on 99524 raw words (60326 effective words) took 0.3s, 223598 effective words/s\n",
      "2023-12-06 15:06:34,064 : INFO : EPOCH 1: training on 99524 raw words (60231 effective words) took 0.3s, 222604 effective words/s\n",
      "2023-12-06 15:06:34,329 : INFO : EPOCH 2: training on 99524 raw words (60571 effective words) took 0.3s, 233594 effective words/s\n",
      "2023-12-06 15:06:34,592 : INFO : EPOCH 3: training on 99524 raw words (60483 effective words) took 0.3s, 234192 effective words/s\n",
      "2023-12-06 15:06:34,857 : INFO : EPOCH 4: training on 99524 raw words (60215 effective words) took 0.3s, 230299 effective words/s\n",
      "2023-12-06 15:06:35,125 : INFO : EPOCH 5: training on 99524 raw words (60388 effective words) took 0.3s, 229349 effective words/s\n",
      "2023-12-06 15:06:35,394 : INFO : EPOCH 6: training on 99524 raw words (60440 effective words) took 0.3s, 228527 effective words/s\n",
      "2023-12-06 15:06:35,661 : INFO : EPOCH 7: training on 99524 raw words (60224 effective words) took 0.3s, 229664 effective words/s\n",
      "2023-12-06 15:06:35,924 : INFO : EPOCH 8: training on 99524 raw words (60191 effective words) took 0.3s, 233015 effective words/s\n",
      "2023-12-06 15:06:36,192 : INFO : EPOCH 9: training on 99524 raw words (60238 effective words) took 0.3s, 227956 effective words/s\n",
      "2023-12-06 15:06:36,192 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603307 effective words) took 2.7s, 225089 effective words/s', 'datetime': '2023-12-06T15:06:36.192877', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:06:36,194 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:06:36.194380', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 71%|   | 344/486 [52:57<25:09, 10.63s/it]2023-12-06 15:06:39,186 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:06:39,187 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:06:39,208 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:06:39,209 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:06:39,212 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:06:39.212622', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:06:39,213 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:06:39.213622', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:06:39,218 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:06:39,220 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:06:39,220 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:06:39.220731', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:06:39,227 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:06:39,227 : INFO : resetting layer weights\n",
      "2023-12-06 15:06:39,232 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:06:39.232482', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:06:39,494 : INFO : EPOCH 0: training on 99524 raw words (60412 effective words) took 0.3s, 234830 effective words/s\n",
      "2023-12-06 15:06:39,803 : INFO : EPOCH 1: training on 99524 raw words (60298 effective words) took 0.3s, 198701 effective words/s\n",
      "2023-12-06 15:06:40,078 : INFO : EPOCH 2: training on 99524 raw words (60380 effective words) took 0.3s, 223079 effective words/s\n",
      "2023-12-06 15:06:40,351 : INFO : EPOCH 3: training on 99524 raw words (60407 effective words) took 0.3s, 224905 effective words/s\n",
      "2023-12-06 15:06:40,621 : INFO : EPOCH 4: training on 99524 raw words (60308 effective words) took 0.3s, 227630 effective words/s\n",
      "2023-12-06 15:06:40,890 : INFO : EPOCH 5: training on 99524 raw words (60315 effective words) took 0.3s, 226888 effective words/s\n",
      "2023-12-06 15:06:41,161 : INFO : EPOCH 6: training on 99524 raw words (60421 effective words) took 0.3s, 226676 effective words/s\n",
      "2023-12-06 15:06:41,441 : INFO : EPOCH 7: training on 99524 raw words (60304 effective words) took 0.3s, 219068 effective words/s\n",
      "2023-12-06 15:06:41,710 : INFO : EPOCH 8: training on 99524 raw words (60299 effective words) took 0.3s, 228728 effective words/s\n",
      "2023-12-06 15:06:41,989 : INFO : EPOCH 9: training on 99524 raw words (60372 effective words) took 0.3s, 219433 effective words/s\n",
      "2023-12-06 15:06:41,990 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603516 effective words) took 2.8s, 218826 effective words/s', 'datetime': '2023-12-06T15:06:41.990440', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:06:41,991 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:06:41.991439', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 71%|   | 345/486 [53:03<21:41,  9.23s/it]2023-12-06 15:06:45,143 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:06:45,144 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:06:45,166 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:06:45,167 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:06:45,173 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:06:45.173957', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:06:45,174 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:06:45.174962', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:06:45,178 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:06:45,179 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:06:45,179 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:06:45.179962', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:06:45,188 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:06:45,189 : INFO : resetting layer weights\n",
      "2023-12-06 15:06:45,195 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:06:45.195421', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:06:45,481 : INFO : EPOCH 0: training on 99524 raw words (60328 effective words) took 0.3s, 214789 effective words/s\n",
      "2023-12-06 15:06:45,742 : INFO : EPOCH 1: training on 99524 raw words (60386 effective words) took 0.3s, 238376 effective words/s\n",
      "2023-12-06 15:06:45,989 : INFO : EPOCH 2: training on 99524 raw words (60331 effective words) took 0.2s, 248760 effective words/s\n",
      "2023-12-06 15:06:46,237 : INFO : EPOCH 3: training on 99524 raw words (60439 effective words) took 0.2s, 247650 effective words/s\n",
      "2023-12-06 15:06:46,493 : INFO : EPOCH 4: training on 99524 raw words (60320 effective words) took 0.3s, 240029 effective words/s\n",
      "2023-12-06 15:06:46,752 : INFO : EPOCH 5: training on 99524 raw words (60397 effective words) took 0.3s, 237601 effective words/s\n",
      "2023-12-06 15:06:47,008 : INFO : EPOCH 6: training on 99524 raw words (60422 effective words) took 0.3s, 239800 effective words/s\n",
      "2023-12-06 15:06:47,257 : INFO : EPOCH 7: training on 99524 raw words (60394 effective words) took 0.2s, 247694 effective words/s\n",
      "2023-12-06 15:06:47,519 : INFO : EPOCH 8: training on 99524 raw words (60235 effective words) took 0.3s, 234677 effective words/s\n",
      "2023-12-06 15:06:47,770 : INFO : EPOCH 9: training on 99524 raw words (60496 effective words) took 0.2s, 244841 effective words/s\n",
      "2023-12-06 15:06:48,020 : INFO : EPOCH 10: training on 99524 raw words (60413 effective words) took 0.2s, 246753 effective words/s\n",
      "2023-12-06 15:06:48,273 : INFO : EPOCH 11: training on 99524 raw words (60476 effective words) took 0.2s, 243366 effective words/s\n",
      "2023-12-06 15:06:48,519 : INFO : EPOCH 12: training on 99524 raw words (60580 effective words) took 0.2s, 250144 effective words/s\n",
      "2023-12-06 15:06:48,767 : INFO : EPOCH 13: training on 99524 raw words (60381 effective words) took 0.2s, 247846 effective words/s\n",
      "2023-12-06 15:06:49,017 : INFO : EPOCH 14: training on 99524 raw words (60577 effective words) took 0.2s, 246787 effective words/s\n",
      "2023-12-06 15:06:49,269 : INFO : EPOCH 15: training on 99524 raw words (60393 effective words) took 0.2s, 244836 effective words/s\n",
      "2023-12-06 15:06:49,516 : INFO : EPOCH 16: training on 99524 raw words (60346 effective words) took 0.2s, 248129 effective words/s\n",
      "2023-12-06 15:06:49,770 : INFO : EPOCH 17: training on 99524 raw words (60230 effective words) took 0.2s, 245185 effective words/s\n",
      "2023-12-06 15:06:50,019 : INFO : EPOCH 18: training on 99524 raw words (60468 effective words) took 0.2s, 248118 effective words/s\n",
      "2023-12-06 15:06:50,275 : INFO : EPOCH 19: training on 99524 raw words (60087 effective words) took 0.3s, 238574 effective words/s\n",
      "2023-12-06 15:06:50,526 : INFO : EPOCH 20: training on 99524 raw words (60369 effective words) took 0.2s, 245722 effective words/s\n",
      "2023-12-06 15:06:50,777 : INFO : EPOCH 21: training on 99524 raw words (60404 effective words) took 0.2s, 244948 effective words/s\n",
      "2023-12-06 15:06:51,026 : INFO : EPOCH 22: training on 99524 raw words (60461 effective words) took 0.2s, 247977 effective words/s\n",
      "2023-12-06 15:06:51,288 : INFO : EPOCH 23: training on 99524 raw words (60312 effective words) took 0.3s, 236120 effective words/s\n",
      "2023-12-06 15:06:51,537 : INFO : EPOCH 24: training on 99524 raw words (60359 effective words) took 0.2s, 246800 effective words/s\n",
      "2023-12-06 15:06:51,786 : INFO : EPOCH 25: training on 99524 raw words (60466 effective words) took 0.2s, 246289 effective words/s\n",
      "2023-12-06 15:06:52,036 : INFO : EPOCH 26: training on 99524 raw words (60192 effective words) took 0.2s, 246013 effective words/s\n",
      "2023-12-06 15:06:52,283 : INFO : EPOCH 27: training on 99524 raw words (60618 effective words) took 0.2s, 250088 effective words/s\n",
      "2023-12-06 15:06:52,533 : INFO : EPOCH 28: training on 99524 raw words (60359 effective words) took 0.2s, 245830 effective words/s\n",
      "2023-12-06 15:06:52,787 : INFO : EPOCH 29: training on 99524 raw words (60193 effective words) took 0.2s, 240895 effective words/s\n",
      "2023-12-06 15:06:52,789 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811432 effective words) took 7.6s, 238581 effective words/s', 'datetime': '2023-12-06T15:06:52.789339', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:06:52,789 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:06:52.789339', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 71%|   | 346/486 [53:15<22:58,  9.85s/it]2023-12-06 15:06:56,423 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:06:56,423 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:06:56,446 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:06:56,447 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:06:56,451 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:06:56.451300', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:06:56,452 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:06:56.452310', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:06:56,457 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:06:56,457 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:06:56,458 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:06:56.458877', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:06:56,465 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:06:56,466 : INFO : resetting layer weights\n",
      "2023-12-06 15:06:56,470 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:06:56.470498', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:06:56,739 : INFO : EPOCH 0: training on 99524 raw words (60511 effective words) took 0.3s, 229006 effective words/s\n",
      "2023-12-06 15:06:57,027 : INFO : EPOCH 1: training on 99524 raw words (60285 effective words) took 0.3s, 216916 effective words/s\n",
      "2023-12-06 15:06:57,297 : INFO : EPOCH 2: training on 99524 raw words (60330 effective words) took 0.3s, 227030 effective words/s\n",
      "2023-12-06 15:06:57,563 : INFO : EPOCH 3: training on 99524 raw words (60458 effective words) took 0.3s, 230763 effective words/s\n",
      "2023-12-06 15:06:57,824 : INFO : EPOCH 4: training on 99524 raw words (60503 effective words) took 0.3s, 235626 effective words/s\n",
      "2023-12-06 15:06:58,089 : INFO : EPOCH 5: training on 99524 raw words (60418 effective words) took 0.3s, 231781 effective words/s\n",
      "2023-12-06 15:06:58,354 : INFO : EPOCH 6: training on 99524 raw words (60357 effective words) took 0.3s, 231769 effective words/s\n",
      "2023-12-06 15:06:58,617 : INFO : EPOCH 7: training on 99524 raw words (60368 effective words) took 0.3s, 233613 effective words/s\n",
      "2023-12-06 15:06:58,883 : INFO : EPOCH 8: training on 99524 raw words (60383 effective words) took 0.3s, 231249 effective words/s\n",
      "2023-12-06 15:06:59,159 : INFO : EPOCH 9: training on 99524 raw words (60610 effective words) took 0.3s, 222733 effective words/s\n",
      "2023-12-06 15:06:59,426 : INFO : EPOCH 10: training on 99524 raw words (60376 effective words) took 0.3s, 230918 effective words/s\n",
      "2023-12-06 15:06:59,689 : INFO : EPOCH 11: training on 99524 raw words (60418 effective words) took 0.3s, 232832 effective words/s\n",
      "2023-12-06 15:06:59,958 : INFO : EPOCH 12: training on 99524 raw words (60434 effective words) took 0.3s, 228692 effective words/s\n",
      "2023-12-06 15:07:00,221 : INFO : EPOCH 13: training on 99524 raw words (60523 effective words) took 0.3s, 235111 effective words/s\n",
      "2023-12-06 15:07:00,494 : INFO : EPOCH 14: training on 99524 raw words (60333 effective words) took 0.3s, 224907 effective words/s\n",
      "2023-12-06 15:07:00,758 : INFO : EPOCH 15: training on 99524 raw words (60348 effective words) took 0.3s, 232810 effective words/s\n",
      "2023-12-06 15:07:01,027 : INFO : EPOCH 16: training on 99524 raw words (60404 effective words) took 0.3s, 229131 effective words/s\n",
      "2023-12-06 15:07:01,289 : INFO : EPOCH 17: training on 99524 raw words (60414 effective words) took 0.3s, 232777 effective words/s\n",
      "2023-12-06 15:07:01,557 : INFO : EPOCH 18: training on 99524 raw words (60470 effective words) took 0.3s, 230312 effective words/s\n",
      "2023-12-06 15:07:01,826 : INFO : EPOCH 19: training on 99524 raw words (60301 effective words) took 0.3s, 227806 effective words/s\n",
      "2023-12-06 15:07:02,096 : INFO : EPOCH 20: training on 99524 raw words (60313 effective words) took 0.3s, 226591 effective words/s\n",
      "2023-12-06 15:07:02,365 : INFO : EPOCH 21: training on 99524 raw words (60205 effective words) took 0.3s, 227299 effective words/s\n",
      "2023-12-06 15:07:02,633 : INFO : EPOCH 22: training on 99524 raw words (60370 effective words) took 0.3s, 228959 effective words/s\n",
      "2023-12-06 15:07:02,900 : INFO : EPOCH 23: training on 99524 raw words (60447 effective words) took 0.3s, 231204 effective words/s\n",
      "2023-12-06 15:07:03,159 : INFO : EPOCH 24: training on 99524 raw words (60452 effective words) took 0.3s, 236888 effective words/s\n",
      "2023-12-06 15:07:03,434 : INFO : EPOCH 25: training on 99524 raw words (60411 effective words) took 0.3s, 223511 effective words/s\n",
      "2023-12-06 15:07:03,700 : INFO : EPOCH 26: training on 99524 raw words (60244 effective words) took 0.3s, 230720 effective words/s\n",
      "2023-12-06 15:07:03,980 : INFO : EPOCH 27: training on 99524 raw words (60367 effective words) took 0.3s, 219788 effective words/s\n",
      "2023-12-06 15:07:04,250 : INFO : EPOCH 28: training on 99524 raw words (60522 effective words) took 0.3s, 227538 effective words/s\n",
      "2023-12-06 15:07:04,542 : INFO : EPOCH 29: training on 99524 raw words (60397 effective words) took 0.3s, 210622 effective words/s\n",
      "2023-12-06 15:07:04,543 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811972 effective words) took 8.1s, 224451 effective words/s', 'datetime': '2023-12-06T15:07:04.543608', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:07:04,544 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:07:04.544615', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 71%|  | 347/486 [53:26<24:12, 10.45s/it]2023-12-06 15:07:08,287 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:07:08,288 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:07:08,312 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:07:08,313 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:07:08,318 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:07:08.318931', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:07:08,318 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:07:08.318931', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:07:08,326 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:07:08,326 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:07:08,327 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:07:08.327546', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:07:08,334 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:07:08,335 : INFO : resetting layer weights\n",
      "2023-12-06 15:07:08,339 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:07:08.339165', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:07:08,612 : INFO : EPOCH 0: training on 99524 raw words (60355 effective words) took 0.3s, 224749 effective words/s\n",
      "2023-12-06 15:07:08,917 : INFO : EPOCH 1: training on 99524 raw words (60566 effective words) took 0.3s, 204981 effective words/s\n",
      "2023-12-06 15:07:09,185 : INFO : EPOCH 2: training on 99524 raw words (60401 effective words) took 0.3s, 228760 effective words/s\n",
      "2023-12-06 15:07:09,458 : INFO : EPOCH 3: training on 99524 raw words (60452 effective words) took 0.3s, 225554 effective words/s\n",
      "2023-12-06 15:07:09,732 : INFO : EPOCH 4: training on 99524 raw words (60197 effective words) took 0.3s, 223192 effective words/s\n",
      "2023-12-06 15:07:10,003 : INFO : EPOCH 5: training on 99524 raw words (60454 effective words) took 0.3s, 226153 effective words/s\n",
      "2023-12-06 15:07:10,275 : INFO : EPOCH 6: training on 99524 raw words (60577 effective words) took 0.3s, 226847 effective words/s\n",
      "2023-12-06 15:07:10,554 : INFO : EPOCH 7: training on 99524 raw words (60434 effective words) took 0.3s, 221915 effective words/s\n",
      "2023-12-06 15:07:10,828 : INFO : EPOCH 8: training on 99524 raw words (60340 effective words) took 0.3s, 224132 effective words/s\n",
      "2023-12-06 15:07:11,101 : INFO : EPOCH 9: training on 99524 raw words (60262 effective words) took 0.3s, 224266 effective words/s\n",
      "2023-12-06 15:07:11,373 : INFO : EPOCH 10: training on 99524 raw words (60169 effective words) took 0.3s, 224308 effective words/s\n",
      "2023-12-06 15:07:11,650 : INFO : EPOCH 11: training on 99524 raw words (60401 effective words) took 0.3s, 222080 effective words/s\n",
      "2023-12-06 15:07:11,928 : INFO : EPOCH 12: training on 99524 raw words (60307 effective words) took 0.3s, 219765 effective words/s\n",
      "2023-12-06 15:07:12,205 : INFO : EPOCH 13: training on 99524 raw words (60502 effective words) took 0.3s, 222598 effective words/s\n",
      "2023-12-06 15:07:12,488 : INFO : EPOCH 14: training on 99524 raw words (60536 effective words) took 0.3s, 217770 effective words/s\n",
      "2023-12-06 15:07:12,758 : INFO : EPOCH 15: training on 99524 raw words (60198 effective words) took 0.3s, 227079 effective words/s\n",
      "2023-12-06 15:07:13,033 : INFO : EPOCH 16: training on 99524 raw words (60392 effective words) took 0.3s, 222444 effective words/s\n",
      "2023-12-06 15:07:13,319 : INFO : EPOCH 17: training on 99524 raw words (60394 effective words) took 0.3s, 214736 effective words/s\n",
      "2023-12-06 15:07:13,598 : INFO : EPOCH 18: training on 99524 raw words (60171 effective words) took 0.3s, 219167 effective words/s\n",
      "2023-12-06 15:07:13,875 : INFO : EPOCH 19: training on 99524 raw words (60496 effective words) took 0.3s, 221374 effective words/s\n",
      "2023-12-06 15:07:14,145 : INFO : EPOCH 20: training on 99524 raw words (60326 effective words) took 0.3s, 227698 effective words/s\n",
      "2023-12-06 15:07:14,424 : INFO : EPOCH 21: training on 99524 raw words (60227 effective words) took 0.3s, 220603 effective words/s\n",
      "2023-12-06 15:07:14,695 : INFO : EPOCH 22: training on 99524 raw words (60357 effective words) took 0.3s, 226974 effective words/s\n",
      "2023-12-06 15:07:14,963 : INFO : EPOCH 23: training on 99524 raw words (60515 effective words) took 0.3s, 229726 effective words/s\n",
      "2023-12-06 15:07:15,238 : INFO : EPOCH 24: training on 99524 raw words (60525 effective words) took 0.3s, 223761 effective words/s\n",
      "2023-12-06 15:07:15,509 : INFO : EPOCH 25: training on 99524 raw words (60314 effective words) took 0.3s, 226344 effective words/s\n",
      "2023-12-06 15:07:15,783 : INFO : EPOCH 26: training on 99524 raw words (60337 effective words) took 0.3s, 223852 effective words/s\n",
      "2023-12-06 15:07:16,056 : INFO : EPOCH 27: training on 99524 raw words (60409 effective words) took 0.3s, 225551 effective words/s\n",
      "2023-12-06 15:07:16,342 : INFO : EPOCH 28: training on 99524 raw words (60364 effective words) took 0.3s, 213429 effective words/s\n",
      "2023-12-06 15:07:16,652 : INFO : EPOCH 29: training on 99524 raw words (60377 effective words) took 0.3s, 198560 effective words/s\n",
      "2023-12-06 15:07:16,653 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811355 effective words) took 8.3s, 217877 effective words/s', 'datetime': '2023-12-06T15:07:16.653835', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:07:16,653 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:07:16.653835', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 72%|  | 348/486 [53:39<25:17, 10.99s/it]2023-12-06 15:07:20,550 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:07:20,550 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:07:20,572 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:07:20,573 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:07:20,578 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:07:20.578463', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:07:20,579 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:07:20.579472', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:07:20,586 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:07:20,586 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:07:20,587 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:07:20.587039', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:07:20,594 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:07:20,595 : INFO : resetting layer weights\n",
      "2023-12-06 15:07:20,598 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:07:20.598023', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:07:20,844 : INFO : EPOCH 0: training on 99524 raw words (60430 effective words) took 0.2s, 249572 effective words/s\n",
      "2023-12-06 15:07:21,119 : INFO : EPOCH 1: training on 99524 raw words (60427 effective words) took 0.3s, 226234 effective words/s\n",
      "2023-12-06 15:07:21,369 : INFO : EPOCH 2: training on 99524 raw words (60428 effective words) took 0.2s, 246559 effective words/s\n",
      "2023-12-06 15:07:21,617 : INFO : EPOCH 3: training on 99524 raw words (60522 effective words) took 0.2s, 247681 effective words/s\n",
      "2023-12-06 15:07:21,868 : INFO : EPOCH 4: training on 99524 raw words (60404 effective words) took 0.2s, 244657 effective words/s\n",
      "2023-12-06 15:07:22,118 : INFO : EPOCH 5: training on 99524 raw words (60569 effective words) took 0.2s, 247201 effective words/s\n",
      "2023-12-06 15:07:22,367 : INFO : EPOCH 6: training on 99524 raw words (60371 effective words) took 0.2s, 246956 effective words/s\n",
      "2023-12-06 15:07:22,623 : INFO : EPOCH 7: training on 99524 raw words (60474 effective words) took 0.3s, 240416 effective words/s\n",
      "2023-12-06 15:07:22,876 : INFO : EPOCH 8: training on 99524 raw words (60358 effective words) took 0.2s, 244412 effective words/s\n",
      "2023-12-06 15:07:23,126 : INFO : EPOCH 9: training on 99524 raw words (60374 effective words) took 0.2s, 244964 effective words/s\n",
      "2023-12-06 15:07:23,376 : INFO : EPOCH 10: training on 99524 raw words (60415 effective words) took 0.2s, 247064 effective words/s\n",
      "2023-12-06 15:07:23,626 : INFO : EPOCH 11: training on 99524 raw words (60533 effective words) took 0.2s, 246261 effective words/s\n",
      "2023-12-06 15:07:23,873 : INFO : EPOCH 12: training on 99524 raw words (60547 effective words) took 0.2s, 249298 effective words/s\n",
      "2023-12-06 15:07:24,129 : INFO : EPOCH 13: training on 99524 raw words (60345 effective words) took 0.3s, 239695 effective words/s\n",
      "2023-12-06 15:07:24,394 : INFO : EPOCH 14: training on 99524 raw words (60458 effective words) took 0.3s, 231969 effective words/s\n",
      "2023-12-06 15:07:24,639 : INFO : EPOCH 15: training on 99524 raw words (60518 effective words) took 0.2s, 252031 effective words/s\n",
      "2023-12-06 15:07:24,879 : INFO : EPOCH 16: training on 99524 raw words (60488 effective words) took 0.2s, 257832 effective words/s\n",
      "2023-12-06 15:07:25,127 : INFO : EPOCH 17: training on 99524 raw words (60359 effective words) took 0.2s, 247398 effective words/s\n",
      "2023-12-06 15:07:25,379 : INFO : EPOCH 18: training on 99524 raw words (60371 effective words) took 0.2s, 244039 effective words/s\n",
      "2023-12-06 15:07:25,638 : INFO : EPOCH 19: training on 99524 raw words (60454 effective words) took 0.3s, 237683 effective words/s\n",
      "2023-12-06 15:07:25,891 : INFO : EPOCH 20: training on 99524 raw words (60205 effective words) took 0.2s, 244046 effective words/s\n",
      "2023-12-06 15:07:26,137 : INFO : EPOCH 21: training on 99524 raw words (60282 effective words) took 0.2s, 250283 effective words/s\n",
      "2023-12-06 15:07:26,384 : INFO : EPOCH 22: training on 99524 raw words (60380 effective words) took 0.2s, 248747 effective words/s\n",
      "2023-12-06 15:07:26,630 : INFO : EPOCH 23: training on 99524 raw words (60548 effective words) took 0.2s, 250814 effective words/s\n",
      "2023-12-06 15:07:26,880 : INFO : EPOCH 24: training on 99524 raw words (60466 effective words) took 0.2s, 247382 effective words/s\n",
      "2023-12-06 15:07:27,129 : INFO : EPOCH 25: training on 99524 raw words (60524 effective words) took 0.2s, 246001 effective words/s\n",
      "2023-12-06 15:07:27,403 : INFO : EPOCH 26: training on 99524 raw words (60467 effective words) took 0.3s, 225046 effective words/s\n",
      "2023-12-06 15:07:27,651 : INFO : EPOCH 27: training on 99524 raw words (60436 effective words) took 0.2s, 248154 effective words/s\n",
      "2023-12-06 15:07:27,900 : INFO : EPOCH 28: training on 99524 raw words (60392 effective words) took 0.2s, 246732 effective words/s\n",
      "2023-12-06 15:07:28,147 : INFO : EPOCH 29: training on 99524 raw words (60495 effective words) took 0.2s, 249765 effective words/s\n",
      "2023-12-06 15:07:28,409 : INFO : EPOCH 30: training on 99524 raw words (60363 effective words) took 0.3s, 234136 effective words/s\n",
      "2023-12-06 15:07:28,670 : INFO : EPOCH 31: training on 99524 raw words (60424 effective words) took 0.3s, 235730 effective words/s\n",
      "2023-12-06 15:07:28,937 : INFO : EPOCH 32: training on 99524 raw words (60454 effective words) took 0.3s, 231690 effective words/s\n",
      "2023-12-06 15:07:29,186 : INFO : EPOCH 33: training on 99524 raw words (60457 effective words) took 0.2s, 247880 effective words/s\n",
      "2023-12-06 15:07:29,435 : INFO : EPOCH 34: training on 99524 raw words (60388 effective words) took 0.2s, 246617 effective words/s\n",
      "2023-12-06 15:07:29,685 : INFO : EPOCH 35: training on 99524 raw words (60247 effective words) took 0.2s, 246426 effective words/s\n",
      "2023-12-06 15:07:29,939 : INFO : EPOCH 36: training on 99524 raw words (60223 effective words) took 0.2s, 241776 effective words/s\n",
      "2023-12-06 15:07:30,196 : INFO : EPOCH 37: training on 99524 raw words (60379 effective words) took 0.3s, 239683 effective words/s\n",
      "2023-12-06 15:07:30,470 : INFO : EPOCH 38: training on 99524 raw words (60371 effective words) took 0.3s, 224609 effective words/s\n",
      "2023-12-06 15:07:30,723 : INFO : EPOCH 39: training on 99524 raw words (60333 effective words) took 0.2s, 242469 effective words/s\n",
      "2023-12-06 15:07:30,968 : INFO : EPOCH 40: training on 99524 raw words (60445 effective words) took 0.2s, 251520 effective words/s\n",
      "2023-12-06 15:07:31,218 : INFO : EPOCH 41: training on 99524 raw words (60237 effective words) took 0.2s, 246961 effective words/s\n",
      "2023-12-06 15:07:31,464 : INFO : EPOCH 42: training on 99524 raw words (60613 effective words) took 0.2s, 250346 effective words/s\n",
      "2023-12-06 15:07:31,718 : INFO : EPOCH 43: training on 99524 raw words (60394 effective words) took 0.2s, 242761 effective words/s\n",
      "2023-12-06 15:07:31,982 : INFO : EPOCH 44: training on 99524 raw words (60428 effective words) took 0.3s, 233122 effective words/s\n",
      "2023-12-06 15:07:32,228 : INFO : EPOCH 45: training on 99524 raw words (60451 effective words) took 0.2s, 249464 effective words/s\n",
      "2023-12-06 15:07:32,473 : INFO : EPOCH 46: training on 99524 raw words (60554 effective words) took 0.2s, 252113 effective words/s\n",
      "2023-12-06 15:07:32,720 : INFO : EPOCH 47: training on 99524 raw words (60463 effective words) took 0.2s, 249993 effective words/s\n",
      "2023-12-06 15:07:32,971 : INFO : EPOCH 48: training on 99524 raw words (60216 effective words) took 0.2s, 244556 effective words/s\n",
      "2023-12-06 15:07:33,248 : INFO : EPOCH 49: training on 99524 raw words (60349 effective words) took 0.3s, 220635 effective words/s\n",
      "2023-12-06 15:07:33,249 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3020829 effective words) took 12.7s, 238783 effective words/s', 'datetime': '2023-12-06T15:07:33.249604', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:07:33,250 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:07:33.250609', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 72%|  | 349/486 [53:55<29:05, 12.74s/it]2023-12-06 15:07:37,360 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:07:37,360 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:07:37,382 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:07:37,383 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:07:37,387 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:07:37.387692', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:07:37,388 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:07:37.388697', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:07:37,393 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:07:37,393 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:07:37,394 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:07:37.394699', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:07:37,401 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:07:37,402 : INFO : resetting layer weights\n",
      "2023-12-06 15:07:37,406 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:07:37.406350', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:07:37,686 : INFO : EPOCH 0: training on 99524 raw words (60470 effective words) took 0.3s, 218727 effective words/s\n",
      "2023-12-06 15:07:38,019 : INFO : EPOCH 1: training on 99524 raw words (60367 effective words) took 0.3s, 193490 effective words/s\n",
      "2023-12-06 15:07:38,281 : INFO : EPOCH 2: training on 99524 raw words (60354 effective words) took 0.3s, 235077 effective words/s\n",
      "2023-12-06 15:07:38,538 : INFO : EPOCH 3: training on 99524 raw words (60610 effective words) took 0.3s, 239217 effective words/s\n",
      "2023-12-06 15:07:38,803 : INFO : EPOCH 4: training on 99524 raw words (60360 effective words) took 0.3s, 231889 effective words/s\n",
      "2023-12-06 15:07:39,068 : INFO : EPOCH 5: training on 99524 raw words (60373 effective words) took 0.3s, 231924 effective words/s\n",
      "2023-12-06 15:07:39,336 : INFO : EPOCH 6: training on 99524 raw words (60297 effective words) took 0.3s, 228555 effective words/s\n",
      "2023-12-06 15:07:39,596 : INFO : EPOCH 7: training on 99524 raw words (60414 effective words) took 0.3s, 235799 effective words/s\n",
      "2023-12-06 15:07:39,860 : INFO : EPOCH 8: training on 99524 raw words (60530 effective words) took 0.3s, 233923 effective words/s\n",
      "2023-12-06 15:07:40,125 : INFO : EPOCH 9: training on 99524 raw words (60496 effective words) took 0.3s, 232537 effective words/s\n",
      "2023-12-06 15:07:40,387 : INFO : EPOCH 10: training on 99524 raw words (60267 effective words) took 0.3s, 233816 effective words/s\n",
      "2023-12-06 15:07:40,650 : INFO : EPOCH 11: training on 99524 raw words (60440 effective words) took 0.3s, 233258 effective words/s\n",
      "2023-12-06 15:07:40,926 : INFO : EPOCH 12: training on 99524 raw words (60404 effective words) took 0.3s, 227838 effective words/s\n",
      "2023-12-06 15:07:41,198 : INFO : EPOCH 13: training on 99524 raw words (60285 effective words) took 0.3s, 225948 effective words/s\n",
      "2023-12-06 15:07:41,457 : INFO : EPOCH 14: training on 99524 raw words (60434 effective words) took 0.3s, 237251 effective words/s\n",
      "2023-12-06 15:07:41,723 : INFO : EPOCH 15: training on 99524 raw words (60494 effective words) took 0.3s, 231262 effective words/s\n",
      "2023-12-06 15:07:41,986 : INFO : EPOCH 16: training on 99524 raw words (60475 effective words) took 0.3s, 233282 effective words/s\n",
      "2023-12-06 15:07:42,264 : INFO : EPOCH 17: training on 99524 raw words (60386 effective words) took 0.3s, 221011 effective words/s\n",
      "2023-12-06 15:07:42,539 : INFO : EPOCH 18: training on 99524 raw words (60503 effective words) took 0.3s, 224723 effective words/s\n",
      "2023-12-06 15:07:42,811 : INFO : EPOCH 19: training on 99524 raw words (60444 effective words) took 0.3s, 226196 effective words/s\n",
      "2023-12-06 15:07:43,074 : INFO : EPOCH 20: training on 99524 raw words (60480 effective words) took 0.3s, 234821 effective words/s\n",
      "2023-12-06 15:07:43,340 : INFO : EPOCH 21: training on 99524 raw words (60522 effective words) took 0.3s, 231534 effective words/s\n",
      "2023-12-06 15:07:43,608 : INFO : EPOCH 22: training on 99524 raw words (60441 effective words) took 0.3s, 229761 effective words/s\n",
      "2023-12-06 15:07:43,876 : INFO : EPOCH 23: training on 99524 raw words (60454 effective words) took 0.3s, 229616 effective words/s\n",
      "2023-12-06 15:07:44,158 : INFO : EPOCH 24: training on 99524 raw words (60440 effective words) took 0.3s, 217660 effective words/s\n",
      "2023-12-06 15:07:44,422 : INFO : EPOCH 25: training on 99524 raw words (60405 effective words) took 0.3s, 232747 effective words/s\n",
      "2023-12-06 15:07:44,687 : INFO : EPOCH 26: training on 99524 raw words (60475 effective words) took 0.3s, 232894 effective words/s\n",
      "2023-12-06 15:07:44,950 : INFO : EPOCH 27: training on 99524 raw words (60306 effective words) took 0.3s, 232804 effective words/s\n",
      "2023-12-06 15:07:45,217 : INFO : EPOCH 28: training on 99524 raw words (60274 effective words) took 0.3s, 229057 effective words/s\n",
      "2023-12-06 15:07:45,499 : INFO : EPOCH 29: training on 99524 raw words (60405 effective words) took 0.3s, 218269 effective words/s\n",
      "2023-12-06 15:07:45,770 : INFO : EPOCH 30: training on 99524 raw words (60367 effective words) took 0.3s, 227139 effective words/s\n",
      "2023-12-06 15:07:46,038 : INFO : EPOCH 31: training on 99524 raw words (60359 effective words) took 0.3s, 229606 effective words/s\n",
      "2023-12-06 15:07:46,309 : INFO : EPOCH 32: training on 99524 raw words (60395 effective words) took 0.3s, 226799 effective words/s\n",
      "2023-12-06 15:07:46,578 : INFO : EPOCH 33: training on 99524 raw words (60296 effective words) took 0.3s, 227433 effective words/s\n",
      "2023-12-06 15:07:46,846 : INFO : EPOCH 34: training on 99524 raw words (60446 effective words) took 0.3s, 229227 effective words/s\n",
      "2023-12-06 15:07:47,113 : INFO : EPOCH 35: training on 99524 raw words (60444 effective words) took 0.3s, 232129 effective words/s\n",
      "2023-12-06 15:07:47,381 : INFO : EPOCH 36: training on 99524 raw words (60303 effective words) took 0.3s, 227996 effective words/s\n",
      "2023-12-06 15:07:47,648 : INFO : EPOCH 37: training on 99524 raw words (60291 effective words) took 0.3s, 229656 effective words/s\n",
      "2023-12-06 15:07:47,910 : INFO : EPOCH 38: training on 99524 raw words (60305 effective words) took 0.3s, 234706 effective words/s\n",
      "2023-12-06 15:07:48,183 : INFO : EPOCH 39: training on 99524 raw words (60410 effective words) took 0.3s, 225048 effective words/s\n",
      "2023-12-06 15:07:48,473 : INFO : EPOCH 40: training on 99524 raw words (60338 effective words) took 0.3s, 210933 effective words/s\n",
      "2023-12-06 15:07:48,733 : INFO : EPOCH 41: training on 99524 raw words (60311 effective words) took 0.3s, 236083 effective words/s\n",
      "2023-12-06 15:07:49,005 : INFO : EPOCH 42: training on 99524 raw words (60502 effective words) took 0.3s, 226028 effective words/s\n",
      "2023-12-06 15:07:49,272 : INFO : EPOCH 43: training on 99524 raw words (60288 effective words) took 0.3s, 230097 effective words/s\n",
      "2023-12-06 15:07:49,538 : INFO : EPOCH 44: training on 99524 raw words (60238 effective words) took 0.3s, 230117 effective words/s\n",
      "2023-12-06 15:07:49,801 : INFO : EPOCH 45: training on 99524 raw words (60425 effective words) took 0.3s, 234324 effective words/s\n",
      "2023-12-06 15:07:50,072 : INFO : EPOCH 46: training on 99524 raw words (60278 effective words) took 0.3s, 226221 effective words/s\n",
      "2023-12-06 15:07:50,343 : INFO : EPOCH 47: training on 99524 raw words (60480 effective words) took 0.3s, 226517 effective words/s\n",
      "2023-12-06 15:07:50,611 : INFO : EPOCH 48: training on 99524 raw words (60384 effective words) took 0.3s, 229815 effective words/s\n",
      "2023-12-06 15:07:50,878 : INFO : EPOCH 49: training on 99524 raw words (60402 effective words) took 0.3s, 229927 effective words/s\n",
      "2023-12-06 15:07:50,880 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3019867 effective words) took 13.5s, 224139 effective words/s', 'datetime': '2023-12-06T15:07:50.880007', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:07:50,880 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:07:50.880511', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 72%|  | 350/486 [54:13<32:26, 14.31s/it]2023-12-06 15:07:55,344 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:07:55,344 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:07:55,367 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:07:55,368 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:07:55,374 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:07:55.374240', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:07:55,375 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:07:55.375240', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:07:55,379 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:07:55,380 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:07:55,380 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:07:55.380255', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:07:55,390 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:07:55,391 : INFO : resetting layer weights\n",
      "2023-12-06 15:07:55,396 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:07:55.396969', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:07:55,736 : INFO : EPOCH 0: training on 99524 raw words (60310 effective words) took 0.3s, 179311 effective words/s\n",
      "2023-12-06 15:07:56,028 : INFO : EPOCH 1: training on 99524 raw words (60354 effective words) took 0.3s, 218564 effective words/s\n",
      "2023-12-06 15:07:56,302 : INFO : EPOCH 2: training on 99524 raw words (60392 effective words) took 0.3s, 223738 effective words/s\n",
      "2023-12-06 15:07:56,579 : INFO : EPOCH 3: training on 99524 raw words (60371 effective words) took 0.3s, 221918 effective words/s\n",
      "2023-12-06 15:07:56,850 : INFO : EPOCH 4: training on 99524 raw words (60501 effective words) took 0.3s, 227172 effective words/s\n",
      "2023-12-06 15:07:57,124 : INFO : EPOCH 5: training on 99524 raw words (60322 effective words) took 0.3s, 223608 effective words/s\n",
      "2023-12-06 15:07:57,396 : INFO : EPOCH 6: training on 99524 raw words (60250 effective words) took 0.3s, 226382 effective words/s\n",
      "2023-12-06 15:07:57,665 : INFO : EPOCH 7: training on 99524 raw words (60381 effective words) took 0.3s, 227664 effective words/s\n",
      "2023-12-06 15:07:57,938 : INFO : EPOCH 8: training on 99524 raw words (60339 effective words) took 0.3s, 224975 effective words/s\n",
      "2023-12-06 15:07:58,218 : INFO : EPOCH 9: training on 99524 raw words (60390 effective words) took 0.3s, 219228 effective words/s\n",
      "2023-12-06 15:07:58,502 : INFO : EPOCH 10: training on 99524 raw words (60502 effective words) took 0.3s, 216261 effective words/s\n",
      "2023-12-06 15:07:58,781 : INFO : EPOCH 11: training on 99524 raw words (60694 effective words) took 0.3s, 222750 effective words/s\n",
      "2023-12-06 15:07:59,057 : INFO : EPOCH 12: training on 99524 raw words (60498 effective words) took 0.3s, 222985 effective words/s\n",
      "2023-12-06 15:07:59,342 : INFO : EPOCH 13: training on 99524 raw words (60405 effective words) took 0.3s, 215219 effective words/s\n",
      "2023-12-06 15:07:59,613 : INFO : EPOCH 14: training on 99524 raw words (60456 effective words) took 0.3s, 226511 effective words/s\n",
      "2023-12-06 15:07:59,889 : INFO : EPOCH 15: training on 99524 raw words (60638 effective words) took 0.3s, 224392 effective words/s\n",
      "2023-12-06 15:08:00,176 : INFO : EPOCH 16: training on 99524 raw words (60339 effective words) took 0.3s, 212860 effective words/s\n",
      "2023-12-06 15:08:00,451 : INFO : EPOCH 17: training on 99524 raw words (60309 effective words) took 0.3s, 223752 effective words/s\n",
      "2023-12-06 15:08:00,727 : INFO : EPOCH 18: training on 99524 raw words (60591 effective words) took 0.3s, 223651 effective words/s\n",
      "2023-12-06 15:08:00,995 : INFO : EPOCH 19: training on 99524 raw words (60356 effective words) took 0.3s, 229032 effective words/s\n",
      "2023-12-06 15:08:01,269 : INFO : EPOCH 20: training on 99524 raw words (60362 effective words) took 0.3s, 223882 effective words/s\n",
      "2023-12-06 15:08:01,542 : INFO : EPOCH 21: training on 99524 raw words (60275 effective words) took 0.3s, 223688 effective words/s\n",
      "2023-12-06 15:08:01,819 : INFO : EPOCH 22: training on 99524 raw words (60537 effective words) took 0.3s, 222140 effective words/s\n",
      "2023-12-06 15:08:02,110 : INFO : EPOCH 23: training on 99524 raw words (60448 effective words) took 0.3s, 210776 effective words/s\n",
      "2023-12-06 15:08:02,384 : INFO : EPOCH 24: training on 99524 raw words (60369 effective words) took 0.3s, 223850 effective words/s\n",
      "2023-12-06 15:08:02,657 : INFO : EPOCH 25: training on 99524 raw words (60398 effective words) took 0.3s, 224935 effective words/s\n",
      "2023-12-06 15:08:02,939 : INFO : EPOCH 26: training on 99524 raw words (60296 effective words) took 0.3s, 217883 effective words/s\n",
      "2023-12-06 15:08:03,205 : INFO : EPOCH 27: training on 99524 raw words (60494 effective words) took 0.3s, 231119 effective words/s\n",
      "2023-12-06 15:08:03,501 : INFO : EPOCH 28: training on 99524 raw words (60388 effective words) took 0.3s, 207142 effective words/s\n",
      "2023-12-06 15:08:03,782 : INFO : EPOCH 29: training on 99524 raw words (60342 effective words) took 0.3s, 218709 effective words/s\n",
      "2023-12-06 15:08:04,067 : INFO : EPOCH 30: training on 99524 raw words (60554 effective words) took 0.3s, 216064 effective words/s\n",
      "2023-12-06 15:08:04,342 : INFO : EPOCH 31: training on 99524 raw words (60385 effective words) took 0.3s, 222406 effective words/s\n",
      "2023-12-06 15:08:04,615 : INFO : EPOCH 32: training on 99524 raw words (60472 effective words) took 0.3s, 225823 effective words/s\n",
      "2023-12-06 15:08:04,900 : INFO : EPOCH 33: training on 99524 raw words (60395 effective words) took 0.3s, 215972 effective words/s\n",
      "2023-12-06 15:08:05,185 : INFO : EPOCH 34: training on 99524 raw words (60386 effective words) took 0.3s, 214241 effective words/s\n",
      "2023-12-06 15:08:05,454 : INFO : EPOCH 35: training on 99524 raw words (60450 effective words) took 0.3s, 229224 effective words/s\n",
      "2023-12-06 15:08:05,729 : INFO : EPOCH 36: training on 99524 raw words (60393 effective words) took 0.3s, 223437 effective words/s\n",
      "2023-12-06 15:08:05,999 : INFO : EPOCH 37: training on 99524 raw words (60351 effective words) took 0.3s, 227786 effective words/s\n",
      "2023-12-06 15:08:06,278 : INFO : EPOCH 38: training on 99524 raw words (60375 effective words) took 0.3s, 221226 effective words/s\n",
      "2023-12-06 15:08:06,557 : INFO : EPOCH 39: training on 99524 raw words (60367 effective words) took 0.3s, 219636 effective words/s\n",
      "2023-12-06 15:08:06,833 : INFO : EPOCH 40: training on 99524 raw words (60425 effective words) took 0.3s, 223402 effective words/s\n",
      "2023-12-06 15:08:07,107 : INFO : EPOCH 41: training on 99524 raw words (60628 effective words) took 0.3s, 225596 effective words/s\n",
      "2023-12-06 15:08:07,382 : INFO : EPOCH 42: training on 99524 raw words (60500 effective words) took 0.3s, 223243 effective words/s\n",
      "2023-12-06 15:08:07,658 : INFO : EPOCH 43: training on 99524 raw words (60262 effective words) took 0.3s, 223077 effective words/s\n",
      "2023-12-06 15:08:07,952 : INFO : EPOCH 44: training on 99524 raw words (60299 effective words) took 0.3s, 207740 effective words/s\n",
      "2023-12-06 15:08:08,228 : INFO : EPOCH 45: training on 99524 raw words (60616 effective words) took 0.3s, 223212 effective words/s\n",
      "2023-12-06 15:08:08,507 : INFO : EPOCH 46: training on 99524 raw words (60276 effective words) took 0.3s, 219937 effective words/s\n",
      "2023-12-06 15:08:08,783 : INFO : EPOCH 47: training on 99524 raw words (60328 effective words) took 0.3s, 221712 effective words/s\n",
      "2023-12-06 15:08:09,054 : INFO : EPOCH 48: training on 99524 raw words (60316 effective words) took 0.3s, 226274 effective words/s\n",
      "2023-12-06 15:08:09,328 : INFO : EPOCH 49: training on 99524 raw words (60287 effective words) took 0.3s, 223993 effective words/s\n",
      "2023-12-06 15:08:09,330 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3020372 effective words) took 13.9s, 216787 effective words/s', 'datetime': '2023-12-06T15:08:09.330102', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:08:09,330 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w5,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:08:09.330102', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 72%|  | 351/486 [54:32<35:13, 15.65s/it]2023-12-06 15:08:14,127 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:08:14,127 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:08:14,149 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:08:14,149 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:08:14,155 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:08:14.155979', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:08:14,156 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:08:14.156979', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:08:14,166 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:08:14,167 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:08:14,167 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:08:14.167979', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:08:14,180 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:08:14,181 : INFO : resetting layer weights\n",
      "2023-12-06 15:08:14,185 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:08:14.185956', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:08:14,434 : INFO : EPOCH 0: training on 99524 raw words (65372 effective words) took 0.2s, 267458 effective words/s\n",
      "2023-12-06 15:08:14,770 : INFO : EPOCH 1: training on 99524 raw words (65315 effective words) took 0.3s, 213313 effective words/s\n",
      "2023-12-06 15:08:15,029 : INFO : EPOCH 2: training on 99524 raw words (65546 effective words) took 0.3s, 257788 effective words/s\n",
      "2023-12-06 15:08:15,281 : INFO : EPOCH 3: training on 99524 raw words (65423 effective words) took 0.2s, 264197 effective words/s\n",
      "2023-12-06 15:08:15,538 : INFO : EPOCH 4: training on 99524 raw words (65499 effective words) took 0.3s, 259765 effective words/s\n",
      "2023-12-06 15:08:15,794 : INFO : EPOCH 5: training on 99524 raw words (65475 effective words) took 0.3s, 260825 effective words/s\n",
      "2023-12-06 15:08:16,058 : INFO : EPOCH 6: training on 99524 raw words (65535 effective words) took 0.3s, 252483 effective words/s\n",
      "2023-12-06 15:08:16,308 : INFO : EPOCH 7: training on 99524 raw words (65490 effective words) took 0.2s, 266315 effective words/s\n",
      "2023-12-06 15:08:16,570 : INFO : EPOCH 8: training on 99524 raw words (65673 effective words) took 0.3s, 255667 effective words/s\n",
      "2023-12-06 15:08:16,815 : INFO : EPOCH 9: training on 99524 raw words (65540 effective words) took 0.2s, 271471 effective words/s\n",
      "2023-12-06 15:08:16,816 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (654868 effective words) took 2.6s, 248978 effective words/s', 'datetime': '2023-12-06T15:08:16.816873', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:08:16,817 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:08:16.817872', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 72%|  | 352/486 [54:38<28:16, 12.66s/it]2023-12-06 15:08:19,799 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:08:19,800 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:08:19,821 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:08:19,822 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:08:19,828 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:08:19.828002', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:08:19,829 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:08:19.829002', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:08:19,840 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:08:19,840 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:08:19,841 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:08:19.841287', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:08:19,852 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:08:19,852 : INFO : resetting layer weights\n",
      "2023-12-06 15:08:19,858 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:08:19.858852', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:08:20,155 : INFO : EPOCH 0: training on 99524 raw words (65434 effective words) took 0.3s, 224472 effective words/s\n",
      "2023-12-06 15:08:20,434 : INFO : EPOCH 1: training on 99524 raw words (65654 effective words) took 0.3s, 241255 effective words/s\n",
      "2023-12-06 15:08:20,708 : INFO : EPOCH 2: training on 99524 raw words (65617 effective words) took 0.3s, 244101 effective words/s\n",
      "2023-12-06 15:08:20,981 : INFO : EPOCH 3: training on 99524 raw words (65622 effective words) took 0.3s, 244024 effective words/s\n",
      "2023-12-06 15:08:21,252 : INFO : EPOCH 4: training on 99524 raw words (65634 effective words) took 0.3s, 246473 effective words/s\n",
      "2023-12-06 15:08:21,522 : INFO : EPOCH 5: training on 99524 raw words (65515 effective words) took 0.3s, 247386 effective words/s\n",
      "2023-12-06 15:08:21,786 : INFO : EPOCH 6: training on 99524 raw words (65329 effective words) took 0.3s, 250850 effective words/s\n",
      "2023-12-06 15:08:22,054 : INFO : EPOCH 7: training on 99524 raw words (65577 effective words) took 0.3s, 250023 effective words/s\n",
      "2023-12-06 15:08:22,325 : INFO : EPOCH 8: training on 99524 raw words (65491 effective words) took 0.3s, 245999 effective words/s\n",
      "2023-12-06 15:08:22,591 : INFO : EPOCH 9: training on 99524 raw words (65595 effective words) took 0.3s, 249912 effective words/s\n",
      "2023-12-06 15:08:22,592 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655468 effective words) took 2.7s, 239836 effective words/s', 'datetime': '2023-12-06T15:08:22.592823', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:08:22,593 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:08:22.593825', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 73%|  | 353/486 [54:44<23:30, 10.61s/it]2023-12-06 15:08:25,619 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:08:25,619 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:08:25,644 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:08:25,645 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:08:25,651 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:08:25.651367', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:08:25,651 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:08:25.651367', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:08:25,658 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:08:25,659 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:08:25,659 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:08:25.659877', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:08:25,672 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:08:25,672 : INFO : resetting layer weights\n",
      "2023-12-06 15:08:25,678 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:08:25.678577', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:08:25,991 : INFO : EPOCH 0: training on 99524 raw words (65490 effective words) took 0.3s, 212137 effective words/s\n",
      "2023-12-06 15:08:26,286 : INFO : EPOCH 1: training on 99524 raw words (65497 effective words) took 0.3s, 240518 effective words/s\n",
      "2023-12-06 15:08:26,556 : INFO : EPOCH 2: training on 99524 raw words (65422 effective words) took 0.3s, 247147 effective words/s\n",
      "2023-12-06 15:08:26,830 : INFO : EPOCH 3: training on 99524 raw words (65480 effective words) took 0.3s, 242998 effective words/s\n",
      "2023-12-06 15:08:27,108 : INFO : EPOCH 4: training on 99524 raw words (65551 effective words) took 0.3s, 239890 effective words/s\n",
      "2023-12-06 15:08:27,391 : INFO : EPOCH 5: training on 99524 raw words (65644 effective words) took 0.3s, 235708 effective words/s\n",
      "2023-12-06 15:08:27,666 : INFO : EPOCH 6: training on 99524 raw words (65535 effective words) took 0.3s, 242375 effective words/s\n",
      "2023-12-06 15:08:27,950 : INFO : EPOCH 7: training on 99524 raw words (65563 effective words) took 0.3s, 234423 effective words/s\n",
      "2023-12-06 15:08:28,226 : INFO : EPOCH 8: training on 99524 raw words (65463 effective words) took 0.3s, 240838 effective words/s\n",
      "2023-12-06 15:08:28,504 : INFO : EPOCH 9: training on 99524 raw words (65455 effective words) took 0.3s, 239111 effective words/s\n",
      "2023-12-06 15:08:28,505 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655100 effective words) took 2.8s, 231761 effective words/s', 'datetime': '2023-12-06T15:08:28.505501', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:08:28,505 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:08:28.505501', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 73%|  | 354/486 [54:50<20:17,  9.22s/it]2023-12-06 15:08:31,610 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:08:31,611 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:08:31,633 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:08:31,634 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:08:31,642 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:08:31.642215', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:08:31,643 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:08:31.643215', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:08:31,653 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:08:31,654 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:08:31,654 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:08:31.654216', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:08:31,665 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:08:31,666 : INFO : resetting layer weights\n",
      "2023-12-06 15:08:31,672 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:08:31.672813', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:08:31,946 : INFO : EPOCH 0: training on 99524 raw words (65591 effective words) took 0.3s, 242901 effective words/s\n",
      "2023-12-06 15:08:32,206 : INFO : EPOCH 1: training on 99524 raw words (65339 effective words) took 0.3s, 257455 effective words/s\n",
      "2023-12-06 15:08:32,455 : INFO : EPOCH 2: training on 99524 raw words (65637 effective words) took 0.2s, 268144 effective words/s\n",
      "2023-12-06 15:08:32,710 : INFO : EPOCH 3: training on 99524 raw words (65643 effective words) took 0.3s, 262438 effective words/s\n",
      "2023-12-06 15:08:32,964 : INFO : EPOCH 4: training on 99524 raw words (65443 effective words) took 0.2s, 262699 effective words/s\n",
      "2023-12-06 15:08:33,217 : INFO : EPOCH 5: training on 99524 raw words (65770 effective words) took 0.2s, 264710 effective words/s\n",
      "2023-12-06 15:08:33,499 : INFO : EPOCH 6: training on 99524 raw words (65572 effective words) took 0.3s, 235858 effective words/s\n",
      "2023-12-06 15:08:33,758 : INFO : EPOCH 7: training on 99524 raw words (65502 effective words) took 0.3s, 258035 effective words/s\n",
      "2023-12-06 15:08:34,006 : INFO : EPOCH 8: training on 99524 raw words (65568 effective words) took 0.2s, 268028 effective words/s\n",
      "2023-12-06 15:08:34,254 : INFO : EPOCH 9: training on 99524 raw words (65412 effective words) took 0.2s, 269354 effective words/s\n",
      "2023-12-06 15:08:34,500 : INFO : EPOCH 10: training on 99524 raw words (65393 effective words) took 0.2s, 270428 effective words/s\n",
      "2023-12-06 15:08:34,754 : INFO : EPOCH 11: training on 99524 raw words (65464 effective words) took 0.2s, 262368 effective words/s\n",
      "2023-12-06 15:08:35,012 : INFO : EPOCH 12: training on 99524 raw words (65560 effective words) took 0.3s, 257355 effective words/s\n",
      "2023-12-06 15:08:35,261 : INFO : EPOCH 13: training on 99524 raw words (65503 effective words) took 0.2s, 269900 effective words/s\n",
      "2023-12-06 15:08:35,519 : INFO : EPOCH 14: training on 99524 raw words (65474 effective words) took 0.3s, 257829 effective words/s\n",
      "2023-12-06 15:08:35,774 : INFO : EPOCH 15: training on 99524 raw words (65527 effective words) took 0.3s, 261268 effective words/s\n",
      "2023-12-06 15:08:36,033 : INFO : EPOCH 16: training on 99524 raw words (65296 effective words) took 0.3s, 256955 effective words/s\n",
      "2023-12-06 15:08:36,284 : INFO : EPOCH 17: training on 99524 raw words (65473 effective words) took 0.2s, 264702 effective words/s\n",
      "2023-12-06 15:08:36,539 : INFO : EPOCH 18: training on 99524 raw words (65556 effective words) took 0.2s, 262507 effective words/s\n",
      "2023-12-06 15:08:36,789 : INFO : EPOCH 19: training on 99524 raw words (65426 effective words) took 0.2s, 266580 effective words/s\n",
      "2023-12-06 15:08:37,041 : INFO : EPOCH 20: training on 99524 raw words (65608 effective words) took 0.2s, 263760 effective words/s\n",
      "2023-12-06 15:08:37,291 : INFO : EPOCH 21: training on 99524 raw words (65350 effective words) took 0.2s, 267683 effective words/s\n",
      "2023-12-06 15:08:37,549 : INFO : EPOCH 22: training on 99524 raw words (65575 effective words) took 0.3s, 259927 effective words/s\n",
      "2023-12-06 15:08:37,805 : INFO : EPOCH 23: training on 99524 raw words (65523 effective words) took 0.3s, 259678 effective words/s\n",
      "2023-12-06 15:08:38,072 : INFO : EPOCH 24: training on 99524 raw words (65623 effective words) took 0.3s, 250416 effective words/s\n",
      "2023-12-06 15:08:38,327 : INFO : EPOCH 25: training on 99524 raw words (65546 effective words) took 0.3s, 260720 effective words/s\n",
      "2023-12-06 15:08:38,583 : INFO : EPOCH 26: training on 99524 raw words (65605 effective words) took 0.3s, 261408 effective words/s\n",
      "2023-12-06 15:08:38,840 : INFO : EPOCH 27: training on 99524 raw words (65487 effective words) took 0.3s, 258736 effective words/s\n",
      "2023-12-06 15:08:39,092 : INFO : EPOCH 28: training on 99524 raw words (65555 effective words) took 0.2s, 265481 effective words/s\n",
      "2023-12-06 15:08:39,351 : INFO : EPOCH 29: training on 99524 raw words (65508 effective words) took 0.3s, 258560 effective words/s\n",
      "2023-12-06 15:08:39,352 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965529 effective words) took 7.7s, 255985 effective words/s', 'datetime': '2023-12-06T15:08:39.352036', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:08:39,352 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:08:39.352036', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 73%|  | 355/486 [55:01<21:30,  9.85s/it]2023-12-06 15:08:42,938 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:08:42,939 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:08:42,960 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:08:42,960 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:08:42,969 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:08:42.969144', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:08:42,969 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:08:42.969144', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:08:42,976 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:08:42,976 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:08:42,977 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:08:42.977939', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:08:42,991 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:08:42,992 : INFO : resetting layer weights\n",
      "2023-12-06 15:08:42,997 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:08:42.997348', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:08:43,263 : INFO : EPOCH 0: training on 99524 raw words (65528 effective words) took 0.3s, 249754 effective words/s\n",
      "2023-12-06 15:08:43,559 : INFO : EPOCH 1: training on 99524 raw words (65636 effective words) took 0.3s, 226218 effective words/s\n",
      "2023-12-06 15:08:43,833 : INFO : EPOCH 2: training on 99524 raw words (65492 effective words) took 0.3s, 243376 effective words/s\n",
      "2023-12-06 15:08:44,105 : INFO : EPOCH 3: training on 99524 raw words (65597 effective words) took 0.3s, 246254 effective words/s\n",
      "2023-12-06 15:08:44,376 : INFO : EPOCH 4: training on 99524 raw words (65629 effective words) took 0.3s, 246109 effective words/s\n",
      "2023-12-06 15:08:44,646 : INFO : EPOCH 5: training on 99524 raw words (65387 effective words) took 0.3s, 244812 effective words/s\n",
      "2023-12-06 15:08:44,911 : INFO : EPOCH 6: training on 99524 raw words (65495 effective words) took 0.3s, 252010 effective words/s\n",
      "2023-12-06 15:08:45,198 : INFO : EPOCH 7: training on 99524 raw words (65451 effective words) took 0.3s, 231229 effective words/s\n",
      "2023-12-06 15:08:45,466 : INFO : EPOCH 8: training on 99524 raw words (65490 effective words) took 0.3s, 248919 effective words/s\n",
      "2023-12-06 15:08:45,739 : INFO : EPOCH 9: training on 99524 raw words (65647 effective words) took 0.3s, 243221 effective words/s\n",
      "2023-12-06 15:08:46,009 : INFO : EPOCH 10: training on 99524 raw words (65614 effective words) took 0.3s, 248453 effective words/s\n",
      "2023-12-06 15:08:46,278 : INFO : EPOCH 11: training on 99524 raw words (65496 effective words) took 0.3s, 247693 effective words/s\n",
      "2023-12-06 15:08:46,544 : INFO : EPOCH 12: training on 99524 raw words (65641 effective words) took 0.3s, 250908 effective words/s\n",
      "2023-12-06 15:08:46,843 : INFO : EPOCH 13: training on 99524 raw words (65597 effective words) took 0.3s, 222544 effective words/s\n",
      "2023-12-06 15:08:47,125 : INFO : EPOCH 14: training on 99524 raw words (65598 effective words) took 0.3s, 236154 effective words/s\n",
      "2023-12-06 15:08:47,395 : INFO : EPOCH 15: training on 99524 raw words (65495 effective words) took 0.3s, 246854 effective words/s\n",
      "2023-12-06 15:08:47,666 : INFO : EPOCH 16: training on 99524 raw words (65570 effective words) took 0.3s, 246162 effective words/s\n",
      "2023-12-06 15:08:47,937 : INFO : EPOCH 17: training on 99524 raw words (65355 effective words) took 0.3s, 245667 effective words/s\n",
      "2023-12-06 15:08:48,218 : INFO : EPOCH 18: training on 99524 raw words (65661 effective words) took 0.3s, 237825 effective words/s\n",
      "2023-12-06 15:08:48,495 : INFO : EPOCH 19: training on 99524 raw words (65358 effective words) took 0.3s, 241568 effective words/s\n",
      "2023-12-06 15:08:48,770 : INFO : EPOCH 20: training on 99524 raw words (65486 effective words) took 0.3s, 243396 effective words/s\n",
      "2023-12-06 15:08:49,037 : INFO : EPOCH 21: training on 99524 raw words (65497 effective words) took 0.3s, 249588 effective words/s\n",
      "2023-12-06 15:08:49,311 : INFO : EPOCH 22: training on 99524 raw words (65646 effective words) took 0.3s, 244342 effective words/s\n",
      "2023-12-06 15:08:49,580 : INFO : EPOCH 23: training on 99524 raw words (65474 effective words) took 0.3s, 247173 effective words/s\n",
      "2023-12-06 15:08:49,859 : INFO : EPOCH 24: training on 99524 raw words (65660 effective words) took 0.3s, 239651 effective words/s\n",
      "2023-12-06 15:08:50,129 : INFO : EPOCH 25: training on 99524 raw words (65463 effective words) took 0.3s, 246584 effective words/s\n",
      "2023-12-06 15:08:50,397 : INFO : EPOCH 26: training on 99524 raw words (65550 effective words) took 0.3s, 248082 effective words/s\n",
      "2023-12-06 15:08:50,670 : INFO : EPOCH 27: training on 99524 raw words (65459 effective words) took 0.3s, 244256 effective words/s\n",
      "2023-12-06 15:08:50,942 : INFO : EPOCH 28: training on 99524 raw words (65552 effective words) took 0.3s, 245297 effective words/s\n",
      "2023-12-06 15:08:51,206 : INFO : EPOCH 29: training on 99524 raw words (65440 effective words) took 0.3s, 250994 effective words/s\n",
      "2023-12-06 15:08:51,207 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965964 effective words) took 8.2s, 239447 effective words/s', 'datetime': '2023-12-06T15:08:51.207767', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:08:51,208 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:08:51.208768', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 73%|  | 356/486 [55:13<22:51, 10.55s/it]2023-12-06 15:08:55,106 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:08:55,107 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:08:55,129 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:08:55,130 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:08:55,136 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:08:55.136141', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:08:55,136 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:08:55.136141', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:08:55,143 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:08:55,144 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:08:55,145 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:08:55.145141', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:08:55,160 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:08:55,161 : INFO : resetting layer weights\n",
      "2023-12-06 15:08:55,166 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:08:55.166682', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:08:55,479 : INFO : EPOCH 0: training on 99524 raw words (65580 effective words) took 0.3s, 212758 effective words/s\n",
      "2023-12-06 15:08:55,761 : INFO : EPOCH 1: training on 99524 raw words (65478 effective words) took 0.3s, 237067 effective words/s\n",
      "2023-12-06 15:08:56,039 : INFO : EPOCH 2: training on 99524 raw words (65593 effective words) took 0.3s, 241154 effective words/s\n",
      "2023-12-06 15:08:56,316 : INFO : EPOCH 3: training on 99524 raw words (65552 effective words) took 0.3s, 241054 effective words/s\n",
      "2023-12-06 15:08:56,584 : INFO : EPOCH 4: training on 99524 raw words (65540 effective words) took 0.3s, 249274 effective words/s\n",
      "2023-12-06 15:08:56,864 : INFO : EPOCH 5: training on 99524 raw words (65434 effective words) took 0.3s, 238570 effective words/s\n",
      "2023-12-06 15:08:57,133 : INFO : EPOCH 6: training on 99524 raw words (65577 effective words) took 0.3s, 248258 effective words/s\n",
      "2023-12-06 15:08:57,413 : INFO : EPOCH 7: training on 99524 raw words (65461 effective words) took 0.3s, 237812 effective words/s\n",
      "2023-12-06 15:08:57,697 : INFO : EPOCH 8: training on 99524 raw words (65635 effective words) took 0.3s, 235525 effective words/s\n",
      "2023-12-06 15:08:57,975 : INFO : EPOCH 9: training on 99524 raw words (65467 effective words) took 0.3s, 238439 effective words/s\n",
      "2023-12-06 15:08:58,255 : INFO : EPOCH 10: training on 99524 raw words (65651 effective words) took 0.3s, 238759 effective words/s\n",
      "2023-12-06 15:08:58,551 : INFO : EPOCH 11: training on 99524 raw words (65564 effective words) took 0.3s, 225048 effective words/s\n",
      "2023-12-06 15:08:58,826 : INFO : EPOCH 12: training on 99524 raw words (65477 effective words) took 0.3s, 241993 effective words/s\n",
      "2023-12-06 15:08:59,096 : INFO : EPOCH 13: training on 99524 raw words (65484 effective words) took 0.3s, 246813 effective words/s\n",
      "2023-12-06 15:08:59,368 : INFO : EPOCH 14: training on 99524 raw words (65629 effective words) took 0.3s, 245419 effective words/s\n",
      "2023-12-06 15:08:59,646 : INFO : EPOCH 15: training on 99524 raw words (65487 effective words) took 0.3s, 239890 effective words/s\n",
      "2023-12-06 15:08:59,931 : INFO : EPOCH 16: training on 99524 raw words (65418 effective words) took 0.3s, 233099 effective words/s\n",
      "2023-12-06 15:09:00,229 : INFO : EPOCH 17: training on 99524 raw words (65384 effective words) took 0.3s, 223175 effective words/s\n",
      "2023-12-06 15:09:00,509 : INFO : EPOCH 18: training on 99524 raw words (65446 effective words) took 0.3s, 237343 effective words/s\n",
      "2023-12-06 15:09:00,787 : INFO : EPOCH 19: training on 99524 raw words (65439 effective words) took 0.3s, 238656 effective words/s\n",
      "2023-12-06 15:09:01,060 : INFO : EPOCH 20: training on 99524 raw words (65515 effective words) took 0.3s, 245691 effective words/s\n",
      "2023-12-06 15:09:01,328 : INFO : EPOCH 21: training on 99524 raw words (65687 effective words) took 0.3s, 248295 effective words/s\n",
      "2023-12-06 15:09:01,601 : INFO : EPOCH 22: training on 99524 raw words (65516 effective words) took 0.3s, 245419 effective words/s\n",
      "2023-12-06 15:09:01,889 : INFO : EPOCH 23: training on 99524 raw words (65352 effective words) took 0.3s, 229247 effective words/s\n",
      "2023-12-06 15:09:02,165 : INFO : EPOCH 24: training on 99524 raw words (65503 effective words) took 0.3s, 241373 effective words/s\n",
      "2023-12-06 15:09:02,445 : INFO : EPOCH 25: training on 99524 raw words (65488 effective words) took 0.3s, 238160 effective words/s\n",
      "2023-12-06 15:09:02,720 : INFO : EPOCH 26: training on 99524 raw words (65423 effective words) took 0.3s, 243301 effective words/s\n",
      "2023-12-06 15:09:03,000 : INFO : EPOCH 27: training on 99524 raw words (65618 effective words) took 0.3s, 237952 effective words/s\n",
      "2023-12-06 15:09:03,278 : INFO : EPOCH 28: training on 99524 raw words (65708 effective words) took 0.3s, 239642 effective words/s\n",
      "2023-12-06 15:09:03,581 : INFO : EPOCH 29: training on 99524 raw words (65514 effective words) took 0.3s, 220376 effective words/s\n",
      "2023-12-06 15:09:03,582 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965620 effective words) took 8.4s, 233573 effective words/s', 'datetime': '2023-12-06T15:09:03.582606', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:09:03,583 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:09:03.583606', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 73%|  | 357/486 [55:26<23:53, 11.12s/it]2023-12-06 15:09:07,548 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:09:07,549 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:09:07,573 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:09:07,574 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:09:07,582 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:09:07.582296', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:09:07,583 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:09:07.583298', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:09:07,589 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:09:07,590 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:09:07,590 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:09:07.590678', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:09:07,607 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:09:07,607 : INFO : resetting layer weights\n",
      "2023-12-06 15:09:07,614 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:09:07.614717', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:09:07,874 : INFO : EPOCH 0: training on 99524 raw words (65461 effective words) took 0.3s, 257125 effective words/s\n",
      "2023-12-06 15:09:08,152 : INFO : EPOCH 1: training on 99524 raw words (65448 effective words) took 0.3s, 243923 effective words/s\n",
      "2023-12-06 15:09:08,406 : INFO : EPOCH 2: training on 99524 raw words (65507 effective words) took 0.2s, 262287 effective words/s\n",
      "2023-12-06 15:09:08,663 : INFO : EPOCH 3: training on 99524 raw words (65529 effective words) took 0.3s, 259646 effective words/s\n",
      "2023-12-06 15:09:08,919 : INFO : EPOCH 4: training on 99524 raw words (65547 effective words) took 0.3s, 261379 effective words/s\n",
      "2023-12-06 15:09:09,177 : INFO : EPOCH 5: training on 99524 raw words (65588 effective words) took 0.3s, 257105 effective words/s\n",
      "2023-12-06 15:09:09,438 : INFO : EPOCH 6: training on 99524 raw words (65484 effective words) took 0.3s, 256033 effective words/s\n",
      "2023-12-06 15:09:09,703 : INFO : EPOCH 7: training on 99524 raw words (65454 effective words) took 0.3s, 251288 effective words/s\n",
      "2023-12-06 15:09:09,966 : INFO : EPOCH 8: training on 99524 raw words (65573 effective words) took 0.3s, 253512 effective words/s\n",
      "2023-12-06 15:09:10,221 : INFO : EPOCH 9: training on 99524 raw words (65461 effective words) took 0.3s, 261821 effective words/s\n",
      "2023-12-06 15:09:10,478 : INFO : EPOCH 10: training on 99524 raw words (65512 effective words) took 0.3s, 258983 effective words/s\n",
      "2023-12-06 15:09:10,735 : INFO : EPOCH 11: training on 99524 raw words (65473 effective words) took 0.3s, 258909 effective words/s\n",
      "2023-12-06 15:09:10,990 : INFO : EPOCH 12: training on 99524 raw words (65518 effective words) took 0.3s, 262028 effective words/s\n",
      "2023-12-06 15:09:11,239 : INFO : EPOCH 13: training on 99524 raw words (65688 effective words) took 0.2s, 268624 effective words/s\n",
      "2023-12-06 15:09:11,484 : INFO : EPOCH 14: training on 99524 raw words (65452 effective words) took 0.2s, 272099 effective words/s\n",
      "2023-12-06 15:09:11,744 : INFO : EPOCH 15: training on 99524 raw words (65540 effective words) took 0.3s, 257716 effective words/s\n",
      "2023-12-06 15:09:12,003 : INFO : EPOCH 16: training on 99524 raw words (65496 effective words) took 0.3s, 256213 effective words/s\n",
      "2023-12-06 15:09:12,265 : INFO : EPOCH 17: training on 99524 raw words (65643 effective words) took 0.3s, 255864 effective words/s\n",
      "2023-12-06 15:09:12,561 : INFO : EPOCH 18: training on 99524 raw words (65492 effective words) took 0.3s, 224228 effective words/s\n",
      "2023-12-06 15:09:12,860 : INFO : EPOCH 19: training on 99524 raw words (65544 effective words) took 0.3s, 223702 effective words/s\n",
      "2023-12-06 15:09:13,114 : INFO : EPOCH 20: training on 99524 raw words (65379 effective words) took 0.2s, 262822 effective words/s\n",
      "2023-12-06 15:09:13,367 : INFO : EPOCH 21: training on 99524 raw words (65450 effective words) took 0.3s, 261104 effective words/s\n",
      "2023-12-06 15:09:13,626 : INFO : EPOCH 22: training on 99524 raw words (65491 effective words) took 0.3s, 257585 effective words/s\n",
      "2023-12-06 15:09:13,901 : INFO : EPOCH 23: training on 99524 raw words (65458 effective words) took 0.3s, 242542 effective words/s\n",
      "2023-12-06 15:09:14,159 : INFO : EPOCH 24: training on 99524 raw words (65462 effective words) took 0.3s, 258215 effective words/s\n",
      "2023-12-06 15:09:14,418 : INFO : EPOCH 25: training on 99524 raw words (65706 effective words) took 0.3s, 258252 effective words/s\n",
      "2023-12-06 15:09:14,671 : INFO : EPOCH 26: training on 99524 raw words (65436 effective words) took 0.2s, 263159 effective words/s\n",
      "2023-12-06 15:09:14,924 : INFO : EPOCH 27: training on 99524 raw words (65545 effective words) took 0.2s, 264916 effective words/s\n",
      "2023-12-06 15:09:15,176 : INFO : EPOCH 28: training on 99524 raw words (65478 effective words) took 0.2s, 263809 effective words/s\n",
      "2023-12-06 15:09:15,436 : INFO : EPOCH 29: training on 99524 raw words (65680 effective words) took 0.3s, 257138 effective words/s\n",
      "2023-12-06 15:09:15,695 : INFO : EPOCH 30: training on 99524 raw words (65484 effective words) took 0.3s, 257495 effective words/s\n",
      "2023-12-06 15:09:15,947 : INFO : EPOCH 31: training on 99524 raw words (65500 effective words) took 0.2s, 264176 effective words/s\n",
      "2023-12-06 15:09:16,210 : INFO : EPOCH 32: training on 99524 raw words (65434 effective words) took 0.3s, 254667 effective words/s\n",
      "2023-12-06 15:09:16,463 : INFO : EPOCH 33: training on 99524 raw words (65375 effective words) took 0.2s, 262226 effective words/s\n",
      "2023-12-06 15:09:16,725 : INFO : EPOCH 34: training on 99524 raw words (65313 effective words) took 0.3s, 253621 effective words/s\n",
      "2023-12-06 15:09:16,979 : INFO : EPOCH 35: training on 99524 raw words (65485 effective words) took 0.2s, 262236 effective words/s\n",
      "2023-12-06 15:09:17,234 : INFO : EPOCH 36: training on 99524 raw words (65470 effective words) took 0.3s, 261481 effective words/s\n",
      "2023-12-06 15:09:17,496 : INFO : EPOCH 37: training on 99524 raw words (65517 effective words) took 0.3s, 254271 effective words/s\n",
      "2023-12-06 15:09:17,749 : INFO : EPOCH 38: training on 99524 raw words (65637 effective words) took 0.2s, 264722 effective words/s\n",
      "2023-12-06 15:09:18,002 : INFO : EPOCH 39: training on 99524 raw words (65444 effective words) took 0.2s, 263123 effective words/s\n",
      "2023-12-06 15:09:18,264 : INFO : EPOCH 40: training on 99524 raw words (65539 effective words) took 0.3s, 254712 effective words/s\n",
      "2023-12-06 15:09:18,517 : INFO : EPOCH 41: training on 99524 raw words (65589 effective words) took 0.2s, 262861 effective words/s\n",
      "2023-12-06 15:09:18,769 : INFO : EPOCH 42: training on 99524 raw words (65508 effective words) took 0.2s, 264799 effective words/s\n",
      "2023-12-06 15:09:19,026 : INFO : EPOCH 43: training on 99524 raw words (65514 effective words) took 0.3s, 260812 effective words/s\n",
      "2023-12-06 15:09:19,282 : INFO : EPOCH 44: training on 99524 raw words (65637 effective words) took 0.3s, 260760 effective words/s\n",
      "2023-12-06 15:09:19,547 : INFO : EPOCH 45: training on 99524 raw words (65559 effective words) took 0.3s, 251842 effective words/s\n",
      "2023-12-06 15:09:19,799 : INFO : EPOCH 46: training on 99524 raw words (65399 effective words) took 0.2s, 264574 effective words/s\n",
      "2023-12-06 15:09:20,060 : INFO : EPOCH 47: training on 99524 raw words (65504 effective words) took 0.3s, 256032 effective words/s\n",
      "2023-12-06 15:09:20,316 : INFO : EPOCH 48: training on 99524 raw words (65448 effective words) took 0.3s, 259826 effective words/s\n",
      "2023-12-06 15:09:20,569 : INFO : EPOCH 49: training on 99524 raw words (65455 effective words) took 0.2s, 264436 effective words/s\n",
      "2023-12-06 15:09:20,570 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3275306 effective words) took 13.0s, 252830 effective words/s', 'datetime': '2023-12-06T15:09:20.570385', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:09:20,570 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:09:20.570896', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 74%|  | 358/486 [55:43<27:36, 12.94s/it]2023-12-06 15:09:24,745 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:09:24,745 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:09:24,766 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:09:24,767 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:09:24,773 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:09:24.773281', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:09:24,774 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:09:24.774282', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:09:24,785 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:09:24,785 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:09:24,786 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:09:24.786415', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:09:24,802 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:09:24,803 : INFO : resetting layer weights\n",
      "2023-12-06 15:09:24,807 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:09:24.807603', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:09:25,086 : INFO : EPOCH 0: training on 99524 raw words (65263 effective words) took 0.3s, 238102 effective words/s\n",
      "2023-12-06 15:09:25,380 : INFO : EPOCH 1: training on 99524 raw words (65547 effective words) took 0.3s, 227529 effective words/s\n",
      "2023-12-06 15:09:25,654 : INFO : EPOCH 2: training on 99524 raw words (65479 effective words) took 0.3s, 243564 effective words/s\n",
      "2023-12-06 15:09:25,922 : INFO : EPOCH 3: training on 99524 raw words (65568 effective words) took 0.3s, 248587 effective words/s\n",
      "2023-12-06 15:09:26,191 : INFO : EPOCH 4: training on 99524 raw words (65548 effective words) took 0.3s, 247395 effective words/s\n",
      "2023-12-06 15:09:26,466 : INFO : EPOCH 5: training on 99524 raw words (65434 effective words) took 0.3s, 241898 effective words/s\n",
      "2023-12-06 15:09:26,729 : INFO : EPOCH 6: training on 99524 raw words (65495 effective words) took 0.3s, 253760 effective words/s\n",
      "2023-12-06 15:09:27,001 : INFO : EPOCH 7: training on 99524 raw words (65634 effective words) took 0.3s, 246513 effective words/s\n",
      "2023-12-06 15:09:27,275 : INFO : EPOCH 8: training on 99524 raw words (65499 effective words) took 0.3s, 243036 effective words/s\n",
      "2023-12-06 15:09:27,551 : INFO : EPOCH 9: training on 99524 raw words (65477 effective words) took 0.3s, 241572 effective words/s\n",
      "2023-12-06 15:09:27,853 : INFO : EPOCH 10: training on 99524 raw words (65631 effective words) took 0.3s, 219737 effective words/s\n",
      "2023-12-06 15:09:28,128 : INFO : EPOCH 11: training on 99524 raw words (65506 effective words) took 0.3s, 242455 effective words/s\n",
      "2023-12-06 15:09:28,398 : INFO : EPOCH 12: training on 99524 raw words (65547 effective words) took 0.3s, 246770 effective words/s\n",
      "2023-12-06 15:09:28,669 : INFO : EPOCH 13: training on 99524 raw words (65465 effective words) took 0.3s, 246352 effective words/s\n",
      "2023-12-06 15:09:28,941 : INFO : EPOCH 14: training on 99524 raw words (65426 effective words) took 0.3s, 244710 effective words/s\n",
      "2023-12-06 15:09:29,214 : INFO : EPOCH 15: training on 99524 raw words (65488 effective words) took 0.3s, 243694 effective words/s\n",
      "2023-12-06 15:09:29,505 : INFO : EPOCH 16: training on 99524 raw words (65651 effective words) took 0.3s, 229369 effective words/s\n",
      "2023-12-06 15:09:29,776 : INFO : EPOCH 17: training on 99524 raw words (65530 effective words) took 0.3s, 245957 effective words/s\n",
      "2023-12-06 15:09:30,052 : INFO : EPOCH 18: training on 99524 raw words (65397 effective words) took 0.3s, 240172 effective words/s\n",
      "2023-12-06 15:09:30,326 : INFO : EPOCH 19: training on 99524 raw words (65505 effective words) took 0.3s, 243860 effective words/s\n",
      "2023-12-06 15:09:30,601 : INFO : EPOCH 20: training on 99524 raw words (65682 effective words) took 0.3s, 243032 effective words/s\n",
      "2023-12-06 15:09:30,870 : INFO : EPOCH 21: training on 99524 raw words (65676 effective words) took 0.3s, 248185 effective words/s\n",
      "2023-12-06 15:09:31,138 : INFO : EPOCH 22: training on 99524 raw words (65537 effective words) took 0.3s, 249478 effective words/s\n",
      "2023-12-06 15:09:31,425 : INFO : EPOCH 23: training on 99524 raw words (65566 effective words) took 0.3s, 231090 effective words/s\n",
      "2023-12-06 15:09:31,699 : INFO : EPOCH 24: training on 99524 raw words (65755 effective words) took 0.3s, 244415 effective words/s\n",
      "2023-12-06 15:09:31,969 : INFO : EPOCH 25: training on 99524 raw words (65363 effective words) took 0.3s, 247232 effective words/s\n",
      "2023-12-06 15:09:32,239 : INFO : EPOCH 26: training on 99524 raw words (65737 effective words) took 0.3s, 246339 effective words/s\n",
      "2023-12-06 15:09:32,522 : INFO : EPOCH 27: training on 99524 raw words (65545 effective words) took 0.3s, 235507 effective words/s\n",
      "2023-12-06 15:09:32,818 : INFO : EPOCH 28: training on 99524 raw words (65596 effective words) took 0.3s, 225069 effective words/s\n",
      "2023-12-06 15:09:33,090 : INFO : EPOCH 29: training on 99524 raw words (65522 effective words) took 0.3s, 244883 effective words/s\n",
      "2023-12-06 15:09:33,364 : INFO : EPOCH 30: training on 99524 raw words (65534 effective words) took 0.3s, 243029 effective words/s\n",
      "2023-12-06 15:09:33,632 : INFO : EPOCH 31: training on 99524 raw words (65642 effective words) took 0.3s, 249133 effective words/s\n",
      "2023-12-06 15:09:33,901 : INFO : EPOCH 32: training on 99524 raw words (65482 effective words) took 0.3s, 246387 effective words/s\n",
      "2023-12-06 15:09:34,171 : INFO : EPOCH 33: training on 99524 raw words (65411 effective words) took 0.3s, 246718 effective words/s\n",
      "2023-12-06 15:09:34,440 : INFO : EPOCH 34: training on 99524 raw words (65466 effective words) took 0.3s, 248004 effective words/s\n",
      "2023-12-06 15:09:34,706 : INFO : EPOCH 35: training on 99524 raw words (65477 effective words) took 0.3s, 251719 effective words/s\n",
      "2023-12-06 15:09:34,983 : INFO : EPOCH 36: training on 99524 raw words (65371 effective words) took 0.3s, 239116 effective words/s\n",
      "2023-12-06 15:09:35,255 : INFO : EPOCH 37: training on 99524 raw words (65452 effective words) took 0.3s, 244433 effective words/s\n",
      "2023-12-06 15:09:35,524 : INFO : EPOCH 38: training on 99524 raw words (65617 effective words) took 0.3s, 247999 effective words/s\n",
      "2023-12-06 15:09:35,796 : INFO : EPOCH 39: training on 99524 raw words (65580 effective words) took 0.3s, 245949 effective words/s\n",
      "2023-12-06 15:09:36,067 : INFO : EPOCH 40: training on 99524 raw words (65615 effective words) took 0.3s, 245096 effective words/s\n",
      "2023-12-06 15:09:36,334 : INFO : EPOCH 41: training on 99524 raw words (65565 effective words) took 0.3s, 250488 effective words/s\n",
      "2023-12-06 15:09:36,616 : INFO : EPOCH 42: training on 99524 raw words (65716 effective words) took 0.3s, 237518 effective words/s\n",
      "2023-12-06 15:09:36,886 : INFO : EPOCH 43: training on 99524 raw words (65480 effective words) took 0.3s, 245582 effective words/s\n",
      "2023-12-06 15:09:37,157 : INFO : EPOCH 44: training on 99524 raw words (65534 effective words) took 0.3s, 246442 effective words/s\n",
      "2023-12-06 15:09:37,433 : INFO : EPOCH 45: training on 99524 raw words (65411 effective words) took 0.3s, 240949 effective words/s\n",
      "2023-12-06 15:09:37,703 : INFO : EPOCH 46: training on 99524 raw words (65475 effective words) took 0.3s, 247769 effective words/s\n",
      "2023-12-06 15:09:37,980 : INFO : EPOCH 47: training on 99524 raw words (65444 effective words) took 0.3s, 239597 effective words/s\n",
      "2023-12-06 15:09:38,250 : INFO : EPOCH 48: training on 99524 raw words (65449 effective words) took 0.3s, 245780 effective words/s\n",
      "2023-12-06 15:09:38,521 : INFO : EPOCH 49: training on 99524 raw words (65539 effective words) took 0.3s, 246046 effective words/s\n",
      "2023-12-06 15:09:38,522 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276329 effective words) took 13.7s, 238896 effective words/s', 'datetime': '2023-12-06T15:09:38.522893', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:09:38,522 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:09:38.522893', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 74%|  | 359/486 [56:01<30:48, 14.56s/it]2023-12-06 15:09:43,075 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:09:43,076 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:09:43,098 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:09:43,099 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:09:43,104 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:09:43.104409', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:09:43,105 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:09:43.105410', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:09:43,116 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:09:43,116 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:09:43,117 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:09:43.117612', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:09:43,129 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:09:43,129 : INFO : resetting layer weights\n",
      "2023-12-06 15:09:43,133 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:09:43.133960', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:09:43,415 : INFO : EPOCH 0: training on 99524 raw words (65652 effective words) took 0.3s, 236971 effective words/s\n",
      "2023-12-06 15:09:43,714 : INFO : EPOCH 1: training on 99524 raw words (65425 effective words) took 0.3s, 223509 effective words/s\n",
      "2023-12-06 15:09:43,986 : INFO : EPOCH 2: training on 99524 raw words (65549 effective words) took 0.3s, 245943 effective words/s\n",
      "2023-12-06 15:09:44,262 : INFO : EPOCH 3: training on 99524 raw words (65714 effective words) took 0.3s, 241254 effective words/s\n",
      "2023-12-06 15:09:44,543 : INFO : EPOCH 4: training on 99524 raw words (65631 effective words) took 0.3s, 237247 effective words/s\n",
      "2023-12-06 15:09:44,816 : INFO : EPOCH 5: training on 99524 raw words (65643 effective words) took 0.3s, 244713 effective words/s\n",
      "2023-12-06 15:09:45,093 : INFO : EPOCH 6: training on 99524 raw words (65451 effective words) took 0.3s, 240006 effective words/s\n",
      "2023-12-06 15:09:45,381 : INFO : EPOCH 7: training on 99524 raw words (65458 effective words) took 0.3s, 231742 effective words/s\n",
      "2023-12-06 15:09:45,656 : INFO : EPOCH 8: training on 99524 raw words (65719 effective words) took 0.3s, 242026 effective words/s\n",
      "2023-12-06 15:09:45,931 : INFO : EPOCH 9: training on 99524 raw words (65530 effective words) took 0.3s, 242727 effective words/s\n",
      "2023-12-06 15:09:46,209 : INFO : EPOCH 10: training on 99524 raw words (65347 effective words) took 0.3s, 238328 effective words/s\n",
      "2023-12-06 15:09:46,495 : INFO : EPOCH 11: training on 99524 raw words (65465 effective words) took 0.3s, 232898 effective words/s\n",
      "2023-12-06 15:09:46,777 : INFO : EPOCH 12: training on 99524 raw words (65571 effective words) took 0.3s, 237634 effective words/s\n",
      "2023-12-06 15:09:47,053 : INFO : EPOCH 13: training on 99524 raw words (65463 effective words) took 0.3s, 241113 effective words/s\n",
      "2023-12-06 15:09:47,333 : INFO : EPOCH 14: training on 99524 raw words (65637 effective words) took 0.3s, 238286 effective words/s\n",
      "2023-12-06 15:09:47,610 : INFO : EPOCH 15: training on 99524 raw words (65548 effective words) took 0.3s, 240920 effective words/s\n",
      "2023-12-06 15:09:47,888 : INFO : EPOCH 16: training on 99524 raw words (65421 effective words) took 0.3s, 239778 effective words/s\n",
      "2023-12-06 15:09:48,170 : INFO : EPOCH 17: training on 99524 raw words (65603 effective words) took 0.3s, 235410 effective words/s\n",
      "2023-12-06 15:09:48,448 : INFO : EPOCH 18: training on 99524 raw words (65491 effective words) took 0.3s, 239802 effective words/s\n",
      "2023-12-06 15:09:48,739 : INFO : EPOCH 19: training on 99524 raw words (65548 effective words) took 0.3s, 229299 effective words/s\n",
      "2023-12-06 15:09:49,014 : INFO : EPOCH 20: training on 99524 raw words (65638 effective words) took 0.3s, 242898 effective words/s\n",
      "2023-12-06 15:09:49,292 : INFO : EPOCH 21: training on 99524 raw words (65597 effective words) took 0.3s, 239679 effective words/s\n",
      "2023-12-06 15:09:49,575 : INFO : EPOCH 22: training on 99524 raw words (65483 effective words) took 0.3s, 235740 effective words/s\n",
      "2023-12-06 15:09:49,880 : INFO : EPOCH 23: training on 99524 raw words (65570 effective words) took 0.3s, 217679 effective words/s\n",
      "2023-12-06 15:09:50,160 : INFO : EPOCH 24: training on 99524 raw words (65527 effective words) took 0.3s, 238466 effective words/s\n",
      "2023-12-06 15:09:50,435 : INFO : EPOCH 25: training on 99524 raw words (65354 effective words) took 0.3s, 241468 effective words/s\n",
      "2023-12-06 15:09:50,707 : INFO : EPOCH 26: training on 99524 raw words (65565 effective words) took 0.3s, 244992 effective words/s\n",
      "2023-12-06 15:09:50,979 : INFO : EPOCH 27: training on 99524 raw words (65668 effective words) took 0.3s, 245840 effective words/s\n",
      "2023-12-06 15:09:51,257 : INFO : EPOCH 28: training on 99524 raw words (65615 effective words) took 0.3s, 239621 effective words/s\n",
      "2023-12-06 15:09:51,566 : INFO : EPOCH 29: training on 99524 raw words (65553 effective words) took 0.3s, 215090 effective words/s\n",
      "2023-12-06 15:09:51,901 : INFO : EPOCH 30: training on 99524 raw words (65582 effective words) took 0.3s, 199759 effective words/s\n",
      "2023-12-06 15:09:52,182 : INFO : EPOCH 31: training on 99524 raw words (65657 effective words) took 0.3s, 237751 effective words/s\n",
      "2023-12-06 15:09:52,459 : INFO : EPOCH 32: training on 99524 raw words (65501 effective words) took 0.3s, 240271 effective words/s\n",
      "2023-12-06 15:09:52,730 : INFO : EPOCH 33: training on 99524 raw words (65608 effective words) took 0.3s, 246509 effective words/s\n",
      "2023-12-06 15:09:53,016 : INFO : EPOCH 34: training on 99524 raw words (65489 effective words) took 0.3s, 233784 effective words/s\n",
      "2023-12-06 15:09:53,289 : INFO : EPOCH 35: training on 99524 raw words (65563 effective words) took 0.3s, 245177 effective words/s\n",
      "2023-12-06 15:09:53,567 : INFO : EPOCH 36: training on 99524 raw words (65733 effective words) took 0.3s, 240842 effective words/s\n",
      "2023-12-06 15:09:53,838 : INFO : EPOCH 37: training on 99524 raw words (65449 effective words) took 0.3s, 244823 effective words/s\n",
      "2023-12-06 15:09:54,120 : INFO : EPOCH 38: training on 99524 raw words (65614 effective words) took 0.3s, 236227 effective words/s\n",
      "2023-12-06 15:09:54,402 : INFO : EPOCH 39: training on 99524 raw words (65594 effective words) took 0.3s, 237144 effective words/s\n",
      "2023-12-06 15:09:54,680 : INFO : EPOCH 40: training on 99524 raw words (65473 effective words) took 0.3s, 239277 effective words/s\n",
      "2023-12-06 15:09:54,958 : INFO : EPOCH 41: training on 99524 raw words (65473 effective words) took 0.3s, 239902 effective words/s\n",
      "2023-12-06 15:09:55,236 : INFO : EPOCH 42: training on 99524 raw words (65546 effective words) took 0.3s, 239811 effective words/s\n",
      "2023-12-06 15:09:55,512 : INFO : EPOCH 43: training on 99524 raw words (65563 effective words) took 0.3s, 241506 effective words/s\n",
      "2023-12-06 15:09:55,790 : INFO : EPOCH 44: training on 99524 raw words (65581 effective words) took 0.3s, 241054 effective words/s\n",
      "2023-12-06 15:09:56,069 : INFO : EPOCH 45: training on 99524 raw words (65492 effective words) took 0.3s, 238221 effective words/s\n",
      "2023-12-06 15:09:56,354 : INFO : EPOCH 46: training on 99524 raw words (65652 effective words) took 0.3s, 233983 effective words/s\n",
      "2023-12-06 15:09:56,630 : INFO : EPOCH 47: training on 99524 raw words (65575 effective words) took 0.3s, 241631 effective words/s\n",
      "2023-12-06 15:09:56,906 : INFO : EPOCH 48: training on 99524 raw words (65419 effective words) took 0.3s, 240317 effective words/s\n",
      "2023-12-06 15:09:57,184 : INFO : EPOCH 49: training on 99524 raw words (65499 effective words) took 0.3s, 239903 effective words/s\n",
      "2023-12-06 15:09:57,185 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3277499 effective words) took 14.1s, 233267 effective words/s', 'datetime': '2023-12-06T15:09:57.185520', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:09:57,185 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w7,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:09:57.185520', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 74%|  | 360/486 [56:20<33:23, 15.90s/it]2023-12-06 15:10:02,109 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:10:02,109 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:10:02,129 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:10:02,129 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:10:02,134 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:10:02.134643', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:10:02,134 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:10:02.134643', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:10:02,140 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:10:02,140 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:10:02,141 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:10:02.141643', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:10:02,149 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:10:02,150 : INFO : resetting layer weights\n",
      "2023-12-06 15:10:02,154 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:10:02.154510', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:10:02,433 : INFO : EPOCH 0: training on 99524 raw words (62688 effective words) took 0.3s, 228597 effective words/s\n",
      "2023-12-06 15:10:02,735 : INFO : EPOCH 1: training on 99524 raw words (62739 effective words) took 0.3s, 218448 effective words/s\n",
      "2023-12-06 15:10:02,981 : INFO : EPOCH 2: training on 99524 raw words (62756 effective words) took 0.2s, 259518 effective words/s\n",
      "2023-12-06 15:10:03,235 : INFO : EPOCH 3: training on 99524 raw words (62915 effective words) took 0.2s, 252093 effective words/s\n",
      "2023-12-06 15:10:03,492 : INFO : EPOCH 4: training on 99524 raw words (62679 effective words) took 0.3s, 247439 effective words/s\n",
      "2023-12-06 15:10:03,741 : INFO : EPOCH 5: training on 99524 raw words (62645 effective words) took 0.2s, 257533 effective words/s\n",
      "2023-12-06 15:10:03,993 : INFO : EPOCH 6: training on 99524 raw words (62560 effective words) took 0.2s, 253674 effective words/s\n",
      "2023-12-06 15:10:04,252 : INFO : EPOCH 7: training on 99524 raw words (62693 effective words) took 0.3s, 246625 effective words/s\n",
      "2023-12-06 15:10:04,504 : INFO : EPOCH 8: training on 99524 raw words (62734 effective words) took 0.2s, 252749 effective words/s\n",
      "2023-12-06 15:10:04,756 : INFO : EPOCH 9: training on 99524 raw words (62755 effective words) took 0.2s, 253757 effective words/s\n",
      "2023-12-06 15:10:04,757 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627164 effective words) took 2.6s, 241024 effective words/s', 'datetime': '2023-12-06T15:10:04.757825', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:10:04,757 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:10:04.757825', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 74%|  | 361/486 [56:26<26:40, 12.81s/it]2023-12-06 15:10:07,698 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:10:07,698 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:10:07,720 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:10:07,721 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:10:07,726 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:10:07.726293', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:10:07,727 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:10:07.727287', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:10:07,733 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:10:07,733 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:10:07,734 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:10:07.734287', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:10:07,742 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:10:07,742 : INFO : resetting layer weights\n",
      "2023-12-06 15:10:07,747 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:10:07.747438', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:10:08,003 : INFO : EPOCH 0: training on 99524 raw words (62674 effective words) took 0.3s, 248175 effective words/s\n",
      "2023-12-06 15:10:08,291 : INFO : EPOCH 1: training on 99524 raw words (62671 effective words) took 0.3s, 224322 effective words/s\n",
      "2023-12-06 15:10:08,555 : INFO : EPOCH 2: training on 99524 raw words (62636 effective words) took 0.3s, 241442 effective words/s\n",
      "2023-12-06 15:10:08,820 : INFO : EPOCH 3: training on 99524 raw words (62919 effective words) took 0.3s, 241628 effective words/s\n",
      "2023-12-06 15:10:09,086 : INFO : EPOCH 4: training on 99524 raw words (62818 effective words) took 0.3s, 240469 effective words/s\n",
      "2023-12-06 15:10:09,362 : INFO : EPOCH 5: training on 99524 raw words (62779 effective words) took 0.3s, 230790 effective words/s\n",
      "2023-12-06 15:10:09,630 : INFO : EPOCH 6: training on 99524 raw words (62832 effective words) took 0.3s, 239385 effective words/s\n",
      "2023-12-06 15:10:09,893 : INFO : EPOCH 7: training on 99524 raw words (62744 effective words) took 0.3s, 241811 effective words/s\n",
      "2023-12-06 15:10:10,153 : INFO : EPOCH 8: training on 99524 raw words (62585 effective words) took 0.3s, 245469 effective words/s\n",
      "2023-12-06 15:10:10,419 : INFO : EPOCH 9: training on 99524 raw words (62848 effective words) took 0.3s, 240487 effective words/s\n",
      "2023-12-06 15:10:10,420 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627506 effective words) took 2.7s, 234803 effective words/s', 'datetime': '2023-12-06T15:10:10.420360', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:10:10,421 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:10:10.421358', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 74%|  | 362/486 [56:32<22:06, 10.70s/it]2023-12-06 15:10:13,469 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:10:13,469 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:10:13,493 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:10:13,494 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:10:13,501 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:10:13.501222', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:10:13,502 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:10:13.502222', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:10:13,509 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:10:13,510 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:10:13,511 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:10:13.511442', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:10:13,519 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:10:13,520 : INFO : resetting layer weights\n",
      "2023-12-06 15:10:13,523 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:10:13.523851', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:10:13,825 : INFO : EPOCH 0: training on 99524 raw words (62839 effective words) took 0.3s, 211717 effective words/s\n",
      "2023-12-06 15:10:14,110 : INFO : EPOCH 1: training on 99524 raw words (62814 effective words) took 0.3s, 230447 effective words/s\n",
      "2023-12-06 15:10:14,378 : INFO : EPOCH 2: training on 99524 raw words (62739 effective words) took 0.3s, 237606 effective words/s\n",
      "2023-12-06 15:10:14,652 : INFO : EPOCH 3: training on 99524 raw words (62663 effective words) took 0.3s, 232973 effective words/s\n",
      "2023-12-06 15:10:14,928 : INFO : EPOCH 4: training on 99524 raw words (62599 effective words) took 0.3s, 231241 effective words/s\n",
      "2023-12-06 15:10:15,200 : INFO : EPOCH 5: training on 99524 raw words (62750 effective words) took 0.3s, 233589 effective words/s\n",
      "2023-12-06 15:10:15,487 : INFO : EPOCH 6: training on 99524 raw words (62649 effective words) took 0.3s, 223388 effective words/s\n",
      "2023-12-06 15:10:15,753 : INFO : EPOCH 7: training on 99524 raw words (62715 effective words) took 0.3s, 238646 effective words/s\n",
      "2023-12-06 15:10:16,036 : INFO : EPOCH 8: training on 99524 raw words (63036 effective words) took 0.3s, 227037 effective words/s\n",
      "2023-12-06 15:10:16,313 : INFO : EPOCH 9: training on 99524 raw words (62484 effective words) took 0.3s, 229004 effective words/s\n",
      "2023-12-06 15:10:16,314 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627288 effective words) took 2.8s, 224868 effective words/s', 'datetime': '2023-12-06T15:10:16.314499', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:10:16,314 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:10:16.314499', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 75%|  | 363/486 [56:38<19:00,  9.27s/it]2023-12-06 15:10:19,425 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:10:19,425 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:10:19,446 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:10:19,447 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:10:19,453 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:10:19.453986', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:10:19,454 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:10:19.454989', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:10:19,462 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:10:19,463 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:10:19,464 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:10:19.464735', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:10:19,473 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:10:19,473 : INFO : resetting layer weights\n",
      "2023-12-06 15:10:19,477 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:10:19.477489', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:10:19,743 : INFO : EPOCH 0: training on 99524 raw words (62864 effective words) took 0.3s, 241108 effective words/s\n",
      "2023-12-06 15:10:20,006 : INFO : EPOCH 1: training on 99524 raw words (62821 effective words) took 0.3s, 244876 effective words/s\n",
      "2023-12-06 15:10:20,256 : INFO : EPOCH 2: training on 99524 raw words (62810 effective words) took 0.2s, 255233 effective words/s\n",
      "2023-12-06 15:10:20,510 : INFO : EPOCH 3: training on 99524 raw words (62737 effective words) took 0.2s, 251837 effective words/s\n",
      "2023-12-06 15:10:20,759 : INFO : EPOCH 4: training on 99524 raw words (62600 effective words) took 0.2s, 255878 effective words/s\n",
      "2023-12-06 15:10:21,011 : INFO : EPOCH 5: training on 99524 raw words (62551 effective words) took 0.2s, 253018 effective words/s\n",
      "2023-12-06 15:10:21,267 : INFO : EPOCH 6: training on 99524 raw words (62664 effective words) took 0.3s, 249320 effective words/s\n",
      "2023-12-06 15:10:21,516 : INFO : EPOCH 7: training on 99524 raw words (62775 effective words) took 0.2s, 256097 effective words/s\n",
      "2023-12-06 15:10:21,770 : INFO : EPOCH 8: training on 99524 raw words (62844 effective words) took 0.2s, 252318 effective words/s\n",
      "2023-12-06 15:10:22,028 : INFO : EPOCH 9: training on 99524 raw words (62589 effective words) took 0.3s, 247684 effective words/s\n",
      "2023-12-06 15:10:22,279 : INFO : EPOCH 10: training on 99524 raw words (62673 effective words) took 0.2s, 254300 effective words/s\n",
      "2023-12-06 15:10:22,539 : INFO : EPOCH 11: training on 99524 raw words (62665 effective words) took 0.3s, 245745 effective words/s\n",
      "2023-12-06 15:10:22,815 : INFO : EPOCH 12: training on 99524 raw words (62696 effective words) took 0.3s, 230450 effective words/s\n",
      "2023-12-06 15:10:23,070 : INFO : EPOCH 13: training on 99524 raw words (62688 effective words) took 0.3s, 250460 effective words/s\n",
      "2023-12-06 15:10:23,323 : INFO : EPOCH 14: training on 99524 raw words (62722 effective words) took 0.2s, 252496 effective words/s\n",
      "2023-12-06 15:10:23,579 : INFO : EPOCH 15: training on 99524 raw words (62552 effective words) took 0.3s, 247827 effective words/s\n",
      "2023-12-06 15:10:23,836 : INFO : EPOCH 16: training on 99524 raw words (62837 effective words) took 0.3s, 249042 effective words/s\n",
      "2023-12-06 15:10:24,090 : INFO : EPOCH 17: training on 99524 raw words (62794 effective words) took 0.2s, 252974 effective words/s\n",
      "2023-12-06 15:10:24,342 : INFO : EPOCH 18: training on 99524 raw words (62806 effective words) took 0.2s, 252845 effective words/s\n",
      "2023-12-06 15:10:24,592 : INFO : EPOCH 19: training on 99524 raw words (62748 effective words) took 0.2s, 256086 effective words/s\n",
      "2023-12-06 15:10:24,851 : INFO : EPOCH 20: training on 99524 raw words (62586 effective words) took 0.3s, 246111 effective words/s\n",
      "2023-12-06 15:10:25,106 : INFO : EPOCH 21: training on 99524 raw words (62824 effective words) took 0.2s, 251772 effective words/s\n",
      "2023-12-06 15:10:25,358 : INFO : EPOCH 22: training on 99524 raw words (62672 effective words) took 0.2s, 252916 effective words/s\n",
      "2023-12-06 15:10:25,613 : INFO : EPOCH 23: training on 99524 raw words (62691 effective words) took 0.2s, 251216 effective words/s\n",
      "2023-12-06 15:10:25,865 : INFO : EPOCH 24: training on 99524 raw words (62826 effective words) took 0.2s, 252767 effective words/s\n",
      "2023-12-06 15:10:26,115 : INFO : EPOCH 25: training on 99524 raw words (62725 effective words) took 0.2s, 255987 effective words/s\n",
      "2023-12-06 15:10:26,369 : INFO : EPOCH 26: training on 99524 raw words (62858 effective words) took 0.2s, 253578 effective words/s\n",
      "2023-12-06 15:10:26,620 : INFO : EPOCH 27: training on 99524 raw words (62598 effective words) took 0.2s, 253980 effective words/s\n",
      "2023-12-06 15:10:26,863 : INFO : EPOCH 28: training on 99524 raw words (62702 effective words) took 0.2s, 263547 effective words/s\n",
      "2023-12-06 15:10:27,114 : INFO : EPOCH 29: training on 99524 raw words (62665 effective words) took 0.2s, 254429 effective words/s\n",
      "2023-12-06 15:10:27,115 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881583 effective words) took 7.6s, 246396 effective words/s', 'datetime': '2023-12-06T15:10:27.115017', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:10:27,115 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:10:27.115017', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 75%|  | 364/486 [56:49<20:03,  9.86s/it]2023-12-06 15:10:30,665 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:10:30,666 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:10:30,687 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:10:30,688 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:10:30,693 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:10:30.693162', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:10:30,694 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:10:30.694161', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:10:30,702 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:10:30,702 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:10:30,703 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:10:30.703163', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:10:30,711 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:10:30,712 : INFO : resetting layer weights\n",
      "2023-12-06 15:10:30,716 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:10:30.716686', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:10:30,987 : INFO : EPOCH 0: training on 99524 raw words (62819 effective words) took 0.3s, 235305 effective words/s\n",
      "2023-12-06 15:10:31,278 : INFO : EPOCH 1: training on 99524 raw words (62701 effective words) took 0.3s, 219238 effective words/s\n",
      "2023-12-06 15:10:31,549 : INFO : EPOCH 2: training on 99524 raw words (62823 effective words) took 0.3s, 235698 effective words/s\n",
      "2023-12-06 15:10:31,815 : INFO : EPOCH 3: training on 99524 raw words (62767 effective words) took 0.3s, 239222 effective words/s\n",
      "2023-12-06 15:10:32,080 : INFO : EPOCH 4: training on 99524 raw words (62686 effective words) took 0.3s, 239846 effective words/s\n",
      "2023-12-06 15:10:32,350 : INFO : EPOCH 5: training on 99524 raw words (62705 effective words) took 0.3s, 236354 effective words/s\n",
      "2023-12-06 15:10:32,622 : INFO : EPOCH 6: training on 99524 raw words (62746 effective words) took 0.3s, 234466 effective words/s\n",
      "2023-12-06 15:10:32,886 : INFO : EPOCH 7: training on 99524 raw words (62727 effective words) took 0.3s, 241763 effective words/s\n",
      "2023-12-06 15:10:33,153 : INFO : EPOCH 8: training on 99524 raw words (62586 effective words) took 0.3s, 238116 effective words/s\n",
      "2023-12-06 15:10:33,421 : INFO : EPOCH 9: training on 99524 raw words (62661 effective words) took 0.3s, 238495 effective words/s\n",
      "2023-12-06 15:10:33,686 : INFO : EPOCH 10: training on 99524 raw words (62796 effective words) took 0.3s, 240822 effective words/s\n",
      "2023-12-06 15:10:33,948 : INFO : EPOCH 11: training on 99524 raw words (62699 effective words) took 0.3s, 243052 effective words/s\n",
      "2023-12-06 15:10:34,221 : INFO : EPOCH 12: training on 99524 raw words (62746 effective words) took 0.3s, 233501 effective words/s\n",
      "2023-12-06 15:10:34,498 : INFO : EPOCH 13: training on 99524 raw words (62766 effective words) took 0.3s, 231095 effective words/s\n",
      "2023-12-06 15:10:34,754 : INFO : EPOCH 14: training on 99524 raw words (62757 effective words) took 0.3s, 248908 effective words/s\n",
      "2023-12-06 15:10:35,021 : INFO : EPOCH 15: training on 99524 raw words (62850 effective words) took 0.3s, 240180 effective words/s\n",
      "2023-12-06 15:10:35,284 : INFO : EPOCH 16: training on 99524 raw words (62630 effective words) took 0.3s, 242756 effective words/s\n",
      "2023-12-06 15:10:35,550 : INFO : EPOCH 17: training on 99524 raw words (62818 effective words) took 0.3s, 239102 effective words/s\n",
      "2023-12-06 15:10:35,826 : INFO : EPOCH 18: training on 99524 raw words (62754 effective words) took 0.3s, 232083 effective words/s\n",
      "2023-12-06 15:10:36,089 : INFO : EPOCH 19: training on 99524 raw words (62658 effective words) took 0.3s, 241643 effective words/s\n",
      "2023-12-06 15:10:36,353 : INFO : EPOCH 20: training on 99524 raw words (62825 effective words) took 0.3s, 241798 effective words/s\n",
      "2023-12-06 15:10:36,622 : INFO : EPOCH 21: training on 99524 raw words (62662 effective words) took 0.3s, 237658 effective words/s\n",
      "2023-12-06 15:10:36,896 : INFO : EPOCH 22: training on 99524 raw words (62661 effective words) took 0.3s, 232585 effective words/s\n",
      "2023-12-06 15:10:37,168 : INFO : EPOCH 23: training on 99524 raw words (62687 effective words) took 0.3s, 234807 effective words/s\n",
      "2023-12-06 15:10:37,444 : INFO : EPOCH 24: training on 99524 raw words (62722 effective words) took 0.3s, 231725 effective words/s\n",
      "2023-12-06 15:10:37,707 : INFO : EPOCH 25: training on 99524 raw words (62633 effective words) took 0.3s, 241995 effective words/s\n",
      "2023-12-06 15:10:37,969 : INFO : EPOCH 26: training on 99524 raw words (62528 effective words) took 0.3s, 242177 effective words/s\n",
      "2023-12-06 15:10:38,233 : INFO : EPOCH 27: training on 99524 raw words (62684 effective words) took 0.3s, 242526 effective words/s\n",
      "2023-12-06 15:10:38,501 : INFO : EPOCH 28: training on 99524 raw words (62689 effective words) took 0.3s, 238143 effective words/s\n",
      "2023-12-06 15:10:38,768 : INFO : EPOCH 29: training on 99524 raw words (62535 effective words) took 0.3s, 238277 effective words/s\n",
      "2023-12-06 15:10:38,769 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881321 effective words) took 8.1s, 233633 effective words/s', 'datetime': '2023-12-06T15:10:38.769413', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:10:38,770 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:10:38.770411', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 75%|  | 365/486 [57:01<21:07, 10.48s/it]2023-12-06 15:10:42,572 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:10:42,573 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:10:42,593 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:10:42,594 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:10:42,602 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:10:42.602544', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:10:42,602 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:10:42.602544', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:10:42,610 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:10:42,611 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:10:42,612 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:10:42.612951', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:10:42,625 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:10:42,625 : INFO : resetting layer weights\n",
      "2023-12-06 15:10:42,631 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:10:42.631192', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:10:42,937 : INFO : EPOCH 0: training on 99524 raw words (62667 effective words) took 0.3s, 207309 effective words/s\n",
      "2023-12-06 15:10:43,219 : INFO : EPOCH 1: training on 99524 raw words (62813 effective words) took 0.3s, 227687 effective words/s\n",
      "2023-12-06 15:10:43,491 : INFO : EPOCH 2: training on 99524 raw words (62737 effective words) took 0.3s, 235430 effective words/s\n",
      "2023-12-06 15:10:43,760 : INFO : EPOCH 3: training on 99524 raw words (62840 effective words) took 0.3s, 236665 effective words/s\n",
      "2023-12-06 15:10:44,034 : INFO : EPOCH 4: training on 99524 raw words (62660 effective words) took 0.3s, 232778 effective words/s\n",
      "2023-12-06 15:10:44,307 : INFO : EPOCH 5: training on 99524 raw words (62688 effective words) took 0.3s, 233423 effective words/s\n",
      "2023-12-06 15:10:44,588 : INFO : EPOCH 6: training on 99524 raw words (62628 effective words) took 0.3s, 227408 effective words/s\n",
      "2023-12-06 15:10:44,856 : INFO : EPOCH 7: training on 99524 raw words (62930 effective words) took 0.3s, 238010 effective words/s\n",
      "2023-12-06 15:10:45,126 : INFO : EPOCH 8: training on 99524 raw words (62729 effective words) took 0.3s, 236167 effective words/s\n",
      "2023-12-06 15:10:45,402 : INFO : EPOCH 9: training on 99524 raw words (62700 effective words) took 0.3s, 230804 effective words/s\n",
      "2023-12-06 15:10:45,674 : INFO : EPOCH 10: training on 99524 raw words (62673 effective words) took 0.3s, 234632 effective words/s\n",
      "2023-12-06 15:10:45,952 : INFO : EPOCH 11: training on 99524 raw words (62666 effective words) took 0.3s, 229146 effective words/s\n",
      "2023-12-06 15:10:46,224 : INFO : EPOCH 12: training on 99524 raw words (62615 effective words) took 0.3s, 234759 effective words/s\n",
      "2023-12-06 15:10:46,509 : INFO : EPOCH 13: training on 99524 raw words (62880 effective words) took 0.3s, 224174 effective words/s\n",
      "2023-12-06 15:10:46,784 : INFO : EPOCH 14: training on 99524 raw words (62842 effective words) took 0.3s, 232096 effective words/s\n",
      "2023-12-06 15:10:47,059 : INFO : EPOCH 15: training on 99524 raw words (62571 effective words) took 0.3s, 231028 effective words/s\n",
      "2023-12-06 15:10:47,341 : INFO : EPOCH 16: training on 99524 raw words (62585 effective words) took 0.3s, 224986 effective words/s\n",
      "2023-12-06 15:10:47,657 : INFO : EPOCH 17: training on 99524 raw words (62780 effective words) took 0.3s, 202100 effective words/s\n",
      "2023-12-06 15:10:47,967 : INFO : EPOCH 18: training on 99524 raw words (62709 effective words) took 0.3s, 205306 effective words/s\n",
      "2023-12-06 15:10:48,260 : INFO : EPOCH 19: training on 99524 raw words (62832 effective words) took 0.3s, 218233 effective words/s\n",
      "2023-12-06 15:10:48,537 : INFO : EPOCH 20: training on 99524 raw words (62782 effective words) took 0.3s, 230871 effective words/s\n",
      "2023-12-06 15:10:48,822 : INFO : EPOCH 21: training on 99524 raw words (62740 effective words) took 0.3s, 223993 effective words/s\n",
      "2023-12-06 15:10:49,100 : INFO : EPOCH 22: training on 99524 raw words (62688 effective words) took 0.3s, 228457 effective words/s\n",
      "2023-12-06 15:10:49,386 : INFO : EPOCH 23: training on 99524 raw words (62844 effective words) took 0.3s, 223219 effective words/s\n",
      "2023-12-06 15:10:49,665 : INFO : EPOCH 24: training on 99524 raw words (62596 effective words) took 0.3s, 228596 effective words/s\n",
      "2023-12-06 15:10:49,942 : INFO : EPOCH 25: training on 99524 raw words (62693 effective words) took 0.3s, 230011 effective words/s\n",
      "2023-12-06 15:10:50,218 : INFO : EPOCH 26: training on 99524 raw words (62706 effective words) took 0.3s, 231400 effective words/s\n",
      "2023-12-06 15:10:50,494 : INFO : EPOCH 27: training on 99524 raw words (62671 effective words) took 0.3s, 230996 effective words/s\n",
      "2023-12-06 15:10:50,792 : INFO : EPOCH 28: training on 99524 raw words (62729 effective words) took 0.3s, 213945 effective words/s\n",
      "2023-12-06 15:10:51,071 : INFO : EPOCH 29: training on 99524 raw words (62640 effective words) took 0.3s, 227591 effective words/s\n",
      "2023-12-06 15:10:51,072 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881634 effective words) took 8.4s, 222927 effective words/s', 'datetime': '2023-12-06T15:10:51.072300', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:10:51,073 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:10:51.073308', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 75%|  | 366/486 [57:13<22:08, 11.07s/it]2023-12-06 15:10:55,023 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:10:55,023 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:10:55,046 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:10:55,046 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:10:55,053 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:10:55.053681', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:10:55,054 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:10:55.054681', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:10:55,062 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:10:55,063 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:10:55,063 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:10:55.063084', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:10:55,074 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:10:55,074 : INFO : resetting layer weights\n",
      "2023-12-06 15:10:55,081 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:10:55.081744', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:10:55,358 : INFO : EPOCH 0: training on 99524 raw words (62706 effective words) took 0.3s, 229811 effective words/s\n",
      "2023-12-06 15:10:55,646 : INFO : EPOCH 1: training on 99524 raw words (62638 effective words) took 0.3s, 226137 effective words/s\n",
      "2023-12-06 15:10:55,899 : INFO : EPOCH 2: training on 99524 raw words (62801 effective words) took 0.2s, 253621 effective words/s\n",
      "2023-12-06 15:10:56,152 : INFO : EPOCH 3: training on 99524 raw words (62833 effective words) took 0.2s, 253016 effective words/s\n",
      "2023-12-06 15:10:56,402 : INFO : EPOCH 4: training on 99524 raw words (62844 effective words) took 0.2s, 255588 effective words/s\n",
      "2023-12-06 15:10:56,656 : INFO : EPOCH 5: training on 99524 raw words (62797 effective words) took 0.2s, 252827 effective words/s\n",
      "2023-12-06 15:10:56,911 : INFO : EPOCH 6: training on 99524 raw words (62796 effective words) took 0.3s, 249564 effective words/s\n",
      "2023-12-06 15:10:57,170 : INFO : EPOCH 7: training on 99524 raw words (62722 effective words) took 0.3s, 246288 effective words/s\n",
      "2023-12-06 15:10:57,420 : INFO : EPOCH 8: training on 99524 raw words (62685 effective words) took 0.2s, 255543 effective words/s\n",
      "2023-12-06 15:10:57,673 : INFO : EPOCH 9: training on 99524 raw words (62679 effective words) took 0.2s, 253139 effective words/s\n",
      "2023-12-06 15:10:57,922 : INFO : EPOCH 10: training on 99524 raw words (62788 effective words) took 0.2s, 256859 effective words/s\n",
      "2023-12-06 15:10:58,178 : INFO : EPOCH 11: training on 99524 raw words (62578 effective words) took 0.3s, 249474 effective words/s\n",
      "2023-12-06 15:10:58,438 : INFO : EPOCH 12: training on 99524 raw words (62728 effective words) took 0.3s, 244779 effective words/s\n",
      "2023-12-06 15:10:58,733 : INFO : EPOCH 13: training on 99524 raw words (62682 effective words) took 0.3s, 216399 effective words/s\n",
      "2023-12-06 15:10:58,947 : INFO : EPOCH 14: training on 99524 raw words (62694 effective words) took 0.2s, 298899 effective words/s\n",
      "2023-12-06 15:10:59,195 : INFO : EPOCH 15: training on 99524 raw words (62647 effective words) took 0.2s, 257312 effective words/s\n",
      "2023-12-06 15:10:59,452 : INFO : EPOCH 16: training on 99524 raw words (62739 effective words) took 0.3s, 248762 effective words/s\n",
      "2023-12-06 15:10:59,708 : INFO : EPOCH 17: training on 99524 raw words (62771 effective words) took 0.3s, 248583 effective words/s\n",
      "2023-12-06 15:10:59,967 : INFO : EPOCH 18: training on 99524 raw words (62808 effective words) took 0.3s, 247262 effective words/s\n",
      "2023-12-06 15:11:00,233 : INFO : EPOCH 19: training on 99524 raw words (62607 effective words) took 0.3s, 240524 effective words/s\n",
      "2023-12-06 15:11:00,493 : INFO : EPOCH 20: training on 99524 raw words (62728 effective words) took 0.3s, 245291 effective words/s\n",
      "2023-12-06 15:11:00,747 : INFO : EPOCH 21: training on 99524 raw words (62829 effective words) took 0.2s, 252038 effective words/s\n",
      "2023-12-06 15:11:01,001 : INFO : EPOCH 22: training on 99524 raw words (62821 effective words) took 0.2s, 251615 effective words/s\n",
      "2023-12-06 15:11:01,252 : INFO : EPOCH 23: training on 99524 raw words (62721 effective words) took 0.2s, 254854 effective words/s\n",
      "2023-12-06 15:11:01,506 : INFO : EPOCH 24: training on 99524 raw words (62659 effective words) took 0.3s, 250413 effective words/s\n",
      "2023-12-06 15:11:01,772 : INFO : EPOCH 25: training on 99524 raw words (62653 effective words) took 0.3s, 240246 effective words/s\n",
      "2023-12-06 15:11:02,035 : INFO : EPOCH 26: training on 99524 raw words (62754 effective words) took 0.3s, 243354 effective words/s\n",
      "2023-12-06 15:11:02,285 : INFO : EPOCH 27: training on 99524 raw words (62772 effective words) took 0.2s, 254881 effective words/s\n",
      "2023-12-06 15:11:02,533 : INFO : EPOCH 28: training on 99524 raw words (62576 effective words) took 0.2s, 256716 effective words/s\n",
      "2023-12-06 15:11:02,785 : INFO : EPOCH 29: training on 99524 raw words (62707 effective words) took 0.2s, 252748 effective words/s\n",
      "2023-12-06 15:11:03,040 : INFO : EPOCH 30: training on 99524 raw words (62901 effective words) took 0.2s, 251978 effective words/s\n",
      "2023-12-06 15:11:03,305 : INFO : EPOCH 31: training on 99524 raw words (62765 effective words) took 0.3s, 242139 effective words/s\n",
      "2023-12-06 15:11:03,607 : INFO : EPOCH 32: training on 99524 raw words (62898 effective words) took 0.3s, 211462 effective words/s\n",
      "2023-12-06 15:11:03,881 : INFO : EPOCH 33: training on 99524 raw words (62814 effective words) took 0.3s, 235087 effective words/s\n",
      "2023-12-06 15:11:04,132 : INFO : EPOCH 34: training on 99524 raw words (62756 effective words) took 0.2s, 253812 effective words/s\n",
      "2023-12-06 15:11:04,392 : INFO : EPOCH 35: training on 99524 raw words (62901 effective words) took 0.3s, 245926 effective words/s\n",
      "2023-12-06 15:11:04,655 : INFO : EPOCH 36: training on 99524 raw words (62745 effective words) took 0.3s, 243726 effective words/s\n",
      "2023-12-06 15:11:04,932 : INFO : EPOCH 37: training on 99524 raw words (62772 effective words) took 0.3s, 230172 effective words/s\n",
      "2023-12-06 15:11:05,191 : INFO : EPOCH 38: training on 99524 raw words (62662 effective words) took 0.3s, 246642 effective words/s\n",
      "2023-12-06 15:11:05,452 : INFO : EPOCH 39: training on 99524 raw words (62742 effective words) took 0.3s, 245354 effective words/s\n",
      "2023-12-06 15:11:05,702 : INFO : EPOCH 40: training on 99524 raw words (62721 effective words) took 0.2s, 255420 effective words/s\n",
      "2023-12-06 15:11:05,951 : INFO : EPOCH 41: training on 99524 raw words (62757 effective words) took 0.2s, 256548 effective words/s\n",
      "2023-12-06 15:11:06,229 : INFO : EPOCH 42: training on 99524 raw words (62814 effective words) took 0.3s, 229891 effective words/s\n",
      "2023-12-06 15:11:06,477 : INFO : EPOCH 43: training on 99524 raw words (62706 effective words) took 0.2s, 258023 effective words/s\n",
      "2023-12-06 15:11:06,723 : INFO : EPOCH 44: training on 99524 raw words (62665 effective words) took 0.2s, 259082 effective words/s\n",
      "2023-12-06 15:11:06,972 : INFO : EPOCH 45: training on 99524 raw words (62835 effective words) took 0.2s, 256726 effective words/s\n",
      "2023-12-06 15:11:07,220 : INFO : EPOCH 46: training on 99524 raw words (62644 effective words) took 0.2s, 258151 effective words/s\n",
      "2023-12-06 15:11:07,468 : INFO : EPOCH 47: training on 99524 raw words (63009 effective words) took 0.2s, 260702 effective words/s\n",
      "2023-12-06 15:11:07,728 : INFO : EPOCH 48: training on 99524 raw words (62943 effective words) took 0.3s, 246209 effective words/s\n",
      "2023-12-06 15:11:07,982 : INFO : EPOCH 49: training on 99524 raw words (62632 effective words) took 0.2s, 251912 effective words/s\n",
      "2023-12-06 15:11:07,983 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3137445 effective words) took 12.9s, 243179 effective words/s', 'datetime': '2023-12-06T15:11:07.983892', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:11:07,984 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:11:07.984892', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 76%|  | 367/486 [57:30<25:32, 12.88s/it]2023-12-06 15:11:12,128 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:11:12,129 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:11:12,151 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:11:12,152 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:11:12,160 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:11:12.160285', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:11:12,160 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:11:12.160285', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:11:12,166 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:11:12,167 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:11:12,167 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:11:12.167285', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:11:12,176 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:11:12,177 : INFO : resetting layer weights\n",
      "2023-12-06 15:11:12,180 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:11:12.180912', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:11:12,430 : INFO : EPOCH 0: training on 99524 raw words (62817 effective words) took 0.2s, 256926 effective words/s\n",
      "2023-12-06 15:11:12,765 : INFO : EPOCH 1: training on 99524 raw words (62754 effective words) took 0.3s, 209847 effective words/s\n",
      "2023-12-06 15:11:13,031 : INFO : EPOCH 2: training on 99524 raw words (62752 effective words) took 0.3s, 240745 effective words/s\n",
      "2023-12-06 15:11:13,294 : INFO : EPOCH 3: training on 99524 raw words (62733 effective words) took 0.3s, 242272 effective words/s\n",
      "2023-12-06 15:11:13,559 : INFO : EPOCH 4: training on 99524 raw words (62703 effective words) took 0.3s, 240971 effective words/s\n",
      "2023-12-06 15:11:13,827 : INFO : EPOCH 5: training on 99524 raw words (62644 effective words) took 0.3s, 236911 effective words/s\n",
      "2023-12-06 15:11:14,102 : INFO : EPOCH 6: training on 99524 raw words (62709 effective words) took 0.3s, 231912 effective words/s\n",
      "2023-12-06 15:11:14,370 : INFO : EPOCH 7: training on 99524 raw words (62539 effective words) took 0.3s, 237871 effective words/s\n",
      "2023-12-06 15:11:14,643 : INFO : EPOCH 8: training on 99524 raw words (62738 effective words) took 0.3s, 233989 effective words/s\n",
      "2023-12-06 15:11:14,903 : INFO : EPOCH 9: training on 99524 raw words (62715 effective words) took 0.3s, 245704 effective words/s\n",
      "2023-12-06 15:11:15,166 : INFO : EPOCH 10: training on 99524 raw words (62668 effective words) took 0.3s, 242446 effective words/s\n",
      "2023-12-06 15:11:15,439 : INFO : EPOCH 11: training on 99524 raw words (62830 effective words) took 0.3s, 234193 effective words/s\n",
      "2023-12-06 15:11:15,711 : INFO : EPOCH 12: training on 99524 raw words (62700 effective words) took 0.3s, 234650 effective words/s\n",
      "2023-12-06 15:11:15,985 : INFO : EPOCH 13: training on 99524 raw words (63017 effective words) took 0.3s, 234187 effective words/s\n",
      "2023-12-06 15:11:16,250 : INFO : EPOCH 14: training on 99524 raw words (62718 effective words) took 0.3s, 239903 effective words/s\n",
      "2023-12-06 15:11:16,517 : INFO : EPOCH 15: training on 99524 raw words (62783 effective words) took 0.3s, 239602 effective words/s\n",
      "2023-12-06 15:11:16,786 : INFO : EPOCH 16: training on 99524 raw words (62715 effective words) took 0.3s, 236288 effective words/s\n",
      "2023-12-06 15:11:17,074 : INFO : EPOCH 17: training on 99524 raw words (62688 effective words) took 0.3s, 221615 effective words/s\n",
      "2023-12-06 15:11:17,360 : INFO : EPOCH 18: training on 99524 raw words (62709 effective words) took 0.3s, 223713 effective words/s\n",
      "2023-12-06 15:11:17,628 : INFO : EPOCH 19: training on 99524 raw words (62625 effective words) took 0.3s, 236974 effective words/s\n",
      "2023-12-06 15:11:17,901 : INFO : EPOCH 20: training on 99524 raw words (62801 effective words) took 0.3s, 234943 effective words/s\n",
      "2023-12-06 15:11:18,169 : INFO : EPOCH 21: training on 99524 raw words (62662 effective words) took 0.3s, 237187 effective words/s\n",
      "2023-12-06 15:11:18,439 : INFO : EPOCH 22: training on 99524 raw words (62775 effective words) took 0.3s, 236604 effective words/s\n",
      "2023-12-06 15:11:18,715 : INFO : EPOCH 23: training on 99524 raw words (62676 effective words) took 0.3s, 230699 effective words/s\n",
      "2023-12-06 15:11:18,993 : INFO : EPOCH 24: training on 99524 raw words (62551 effective words) took 0.3s, 228743 effective words/s\n",
      "2023-12-06 15:11:19,262 : INFO : EPOCH 25: training on 99524 raw words (62564 effective words) took 0.3s, 236836 effective words/s\n",
      "2023-12-06 15:11:19,526 : INFO : EPOCH 26: training on 99524 raw words (62700 effective words) took 0.3s, 241249 effective words/s\n",
      "2023-12-06 15:11:19,801 : INFO : EPOCH 27: training on 99524 raw words (62607 effective words) took 0.3s, 231859 effective words/s\n",
      "2023-12-06 15:11:20,063 : INFO : EPOCH 28: training on 99524 raw words (62677 effective words) took 0.3s, 242797 effective words/s\n",
      "2023-12-06 15:11:20,344 : INFO : EPOCH 29: training on 99524 raw words (62573 effective words) took 0.3s, 225861 effective words/s\n",
      "2023-12-06 15:11:20,643 : INFO : EPOCH 30: training on 99524 raw words (62728 effective words) took 0.3s, 214323 effective words/s\n",
      "2023-12-06 15:11:20,908 : INFO : EPOCH 31: training on 99524 raw words (62588 effective words) took 0.3s, 241342 effective words/s\n",
      "2023-12-06 15:11:21,184 : INFO : EPOCH 32: training on 99524 raw words (62708 effective words) took 0.3s, 230942 effective words/s\n",
      "2023-12-06 15:11:21,460 : INFO : EPOCH 33: training on 99524 raw words (62815 effective words) took 0.3s, 231733 effective words/s\n",
      "2023-12-06 15:11:21,743 : INFO : EPOCH 34: training on 99524 raw words (62929 effective words) took 0.3s, 226570 effective words/s\n",
      "2023-12-06 15:11:22,026 : INFO : EPOCH 35: training on 99524 raw words (62696 effective words) took 0.3s, 225349 effective words/s\n",
      "2023-12-06 15:11:22,308 : INFO : EPOCH 36: training on 99524 raw words (62595 effective words) took 0.3s, 225487 effective words/s\n",
      "2023-12-06 15:11:22,633 : INFO : EPOCH 37: training on 99524 raw words (62764 effective words) took 0.3s, 196331 effective words/s\n",
      "2023-12-06 15:11:22,923 : INFO : EPOCH 38: training on 99524 raw words (62779 effective words) took 0.3s, 219323 effective words/s\n",
      "2023-12-06 15:11:23,204 : INFO : EPOCH 39: training on 99524 raw words (62851 effective words) took 0.3s, 227612 effective words/s\n",
      "2023-12-06 15:11:23,482 : INFO : EPOCH 40: training on 99524 raw words (62549 effective words) took 0.3s, 230058 effective words/s\n",
      "2023-12-06 15:11:23,750 : INFO : EPOCH 41: training on 99524 raw words (62711 effective words) took 0.3s, 237621 effective words/s\n",
      "2023-12-06 15:11:24,017 : INFO : EPOCH 42: training on 99524 raw words (62793 effective words) took 0.3s, 239841 effective words/s\n",
      "2023-12-06 15:11:24,278 : INFO : EPOCH 43: training on 99524 raw words (62693 effective words) took 0.3s, 245061 effective words/s\n",
      "2023-12-06 15:11:24,563 : INFO : EPOCH 44: training on 99524 raw words (62782 effective words) took 0.3s, 223197 effective words/s\n",
      "2023-12-06 15:11:24,882 : INFO : EPOCH 45: training on 99524 raw words (62822 effective words) took 0.3s, 200715 effective words/s\n",
      "2023-12-06 15:11:25,195 : INFO : EPOCH 46: training on 99524 raw words (62763 effective words) took 0.3s, 203048 effective words/s\n",
      "2023-12-06 15:11:25,508 : INFO : EPOCH 47: training on 99524 raw words (62693 effective words) took 0.3s, 204488 effective words/s\n",
      "2023-12-06 15:11:25,814 : INFO : EPOCH 48: training on 99524 raw words (62671 effective words) took 0.3s, 207801 effective words/s\n",
      "2023-12-06 15:11:26,124 : INFO : EPOCH 49: training on 99524 raw words (62521 effective words) took 0.3s, 204463 effective words/s\n",
      "2023-12-06 15:11:26,125 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3135594 effective words) took 13.9s, 224872 effective words/s', 'datetime': '2023-12-06T15:11:26.125658', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:11:26,127 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:11:26.127047', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 76%|  | 368/486 [57:49<28:43, 14.61s/it]2023-12-06 15:11:30,759 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:11:30,760 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:11:30,782 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:11:30,782 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:11:30,787 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:11:30.787825', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:11:30,788 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:11:30.788826', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:11:30,795 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:11:30,795 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:11:30,796 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:11:30.796030', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:11:30,803 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:11:30,805 : INFO : resetting layer weights\n",
      "2023-12-06 15:11:30,811 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:11:30.811867', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:11:31,099 : INFO : EPOCH 0: training on 99524 raw words (62713 effective words) took 0.3s, 221726 effective words/s\n",
      "2023-12-06 15:11:31,383 : INFO : EPOCH 1: training on 99524 raw words (62760 effective words) took 0.3s, 226480 effective words/s\n",
      "2023-12-06 15:11:31,654 : INFO : EPOCH 2: training on 99524 raw words (62838 effective words) took 0.3s, 235855 effective words/s\n",
      "2023-12-06 15:11:31,925 : INFO : EPOCH 3: training on 99524 raw words (62686 effective words) took 0.3s, 234766 effective words/s\n",
      "2023-12-06 15:11:32,196 : INFO : EPOCH 4: training on 99524 raw words (62802 effective words) took 0.3s, 236406 effective words/s\n",
      "2023-12-06 15:11:32,464 : INFO : EPOCH 5: training on 99524 raw words (62667 effective words) took 0.3s, 236965 effective words/s\n",
      "2023-12-06 15:11:32,734 : INFO : EPOCH 6: training on 99524 raw words (62643 effective words) took 0.3s, 236068 effective words/s\n",
      "2023-12-06 15:11:33,010 : INFO : EPOCH 7: training on 99524 raw words (62691 effective words) took 0.3s, 230740 effective words/s\n",
      "2023-12-06 15:11:33,281 : INFO : EPOCH 8: training on 99524 raw words (62645 effective words) took 0.3s, 234733 effective words/s\n",
      "2023-12-06 15:11:33,553 : INFO : EPOCH 9: training on 99524 raw words (62745 effective words) took 0.3s, 234289 effective words/s\n",
      "2023-12-06 15:11:33,829 : INFO : EPOCH 10: training on 99524 raw words (62638 effective words) took 0.3s, 231149 effective words/s\n",
      "2023-12-06 15:11:34,098 : INFO : EPOCH 11: training on 99524 raw words (62679 effective words) took 0.3s, 235967 effective words/s\n",
      "2023-12-06 15:11:34,397 : INFO : EPOCH 12: training on 99524 raw words (62580 effective words) took 0.3s, 212683 effective words/s\n",
      "2023-12-06 15:11:34,699 : INFO : EPOCH 13: training on 99524 raw words (62817 effective words) took 0.3s, 211996 effective words/s\n",
      "2023-12-06 15:11:35,038 : INFO : EPOCH 14: training on 99524 raw words (62792 effective words) took 0.3s, 188005 effective words/s\n",
      "2023-12-06 15:11:35,318 : INFO : EPOCH 15: training on 99524 raw words (62763 effective words) took 0.3s, 227589 effective words/s\n",
      "2023-12-06 15:11:35,598 : INFO : EPOCH 16: training on 99524 raw words (62806 effective words) took 0.3s, 228601 effective words/s\n",
      "2023-12-06 15:11:35,891 : INFO : EPOCH 17: training on 99524 raw words (62651 effective words) took 0.3s, 217326 effective words/s\n",
      "2023-12-06 15:11:36,161 : INFO : EPOCH 18: training on 99524 raw words (62635 effective words) took 0.3s, 235899 effective words/s\n",
      "2023-12-06 15:11:36,435 : INFO : EPOCH 19: training on 99524 raw words (62874 effective words) took 0.3s, 232567 effective words/s\n",
      "2023-12-06 15:11:36,716 : INFO : EPOCH 20: training on 99524 raw words (62881 effective words) took 0.3s, 233827 effective words/s\n",
      "2023-12-06 15:11:36,987 : INFO : EPOCH 21: training on 99524 raw words (62730 effective words) took 0.3s, 235085 effective words/s\n",
      "2023-12-06 15:11:37,280 : INFO : EPOCH 22: training on 99524 raw words (62827 effective words) took 0.3s, 217517 effective words/s\n",
      "2023-12-06 15:11:37,555 : INFO : EPOCH 23: training on 99524 raw words (62777 effective words) took 0.3s, 231806 effective words/s\n",
      "2023-12-06 15:11:37,830 : INFO : EPOCH 24: training on 99524 raw words (62769 effective words) took 0.3s, 232163 effective words/s\n",
      "2023-12-06 15:11:38,112 : INFO : EPOCH 25: training on 99524 raw words (62843 effective words) took 0.3s, 227145 effective words/s\n",
      "2023-12-06 15:11:38,387 : INFO : EPOCH 26: training on 99524 raw words (62575 effective words) took 0.3s, 230430 effective words/s\n",
      "2023-12-06 15:11:38,660 : INFO : EPOCH 27: training on 99524 raw words (62797 effective words) took 0.3s, 233537 effective words/s\n",
      "2023-12-06 15:11:38,926 : INFO : EPOCH 28: training on 99524 raw words (62727 effective words) took 0.3s, 239781 effective words/s\n",
      "2023-12-06 15:11:39,214 : INFO : EPOCH 29: training on 99524 raw words (62747 effective words) took 0.3s, 221654 effective words/s\n",
      "2023-12-06 15:11:39,489 : INFO : EPOCH 30: training on 99524 raw words (62820 effective words) took 0.3s, 231723 effective words/s\n",
      "2023-12-06 15:11:39,770 : INFO : EPOCH 31: training on 99524 raw words (62769 effective words) took 0.3s, 227659 effective words/s\n",
      "2023-12-06 15:11:40,038 : INFO : EPOCH 32: training on 99524 raw words (62645 effective words) took 0.3s, 237485 effective words/s\n",
      "2023-12-06 15:11:40,305 : INFO : EPOCH 33: training on 99524 raw words (62440 effective words) took 0.3s, 236891 effective words/s\n",
      "2023-12-06 15:11:40,584 : INFO : EPOCH 34: training on 99524 raw words (62825 effective words) took 0.3s, 229359 effective words/s\n",
      "2023-12-06 15:11:40,854 : INFO : EPOCH 35: training on 99524 raw words (62608 effective words) took 0.3s, 235563 effective words/s\n",
      "2023-12-06 15:11:41,126 : INFO : EPOCH 36: training on 99524 raw words (62538 effective words) took 0.3s, 234183 effective words/s\n",
      "2023-12-06 15:11:41,430 : INFO : EPOCH 37: training on 99524 raw words (62862 effective words) took 0.3s, 209289 effective words/s\n",
      "2023-12-06 15:11:41,702 : INFO : EPOCH 38: training on 99524 raw words (62634 effective words) took 0.3s, 233648 effective words/s\n",
      "2023-12-06 15:11:41,971 : INFO : EPOCH 39: training on 99524 raw words (62783 effective words) took 0.3s, 238010 effective words/s\n",
      "2023-12-06 15:11:42,242 : INFO : EPOCH 40: training on 99524 raw words (62791 effective words) took 0.3s, 235672 effective words/s\n",
      "2023-12-06 15:11:42,518 : INFO : EPOCH 41: training on 99524 raw words (62827 effective words) took 0.3s, 231400 effective words/s\n",
      "2023-12-06 15:11:42,789 : INFO : EPOCH 42: training on 99524 raw words (62688 effective words) took 0.3s, 234343 effective words/s\n",
      "2023-12-06 15:11:43,080 : INFO : EPOCH 43: training on 99524 raw words (62709 effective words) took 0.3s, 218365 effective words/s\n",
      "2023-12-06 15:11:43,353 : INFO : EPOCH 44: training on 99524 raw words (62637 effective words) took 0.3s, 234158 effective words/s\n",
      "2023-12-06 15:11:43,627 : INFO : EPOCH 45: training on 99524 raw words (62708 effective words) took 0.3s, 231903 effective words/s\n",
      "2023-12-06 15:11:43,910 : INFO : EPOCH 46: training on 99524 raw words (62721 effective words) took 0.3s, 224480 effective words/s\n",
      "2023-12-06 15:11:44,183 : INFO : EPOCH 47: training on 99524 raw words (62887 effective words) took 0.3s, 234676 effective words/s\n",
      "2023-12-06 15:11:44,458 : INFO : EPOCH 48: training on 99524 raw words (62632 effective words) took 0.3s, 231195 effective words/s\n",
      "2023-12-06 15:11:44,760 : INFO : EPOCH 49: training on 99524 raw words (62622 effective words) took 0.3s, 210889 effective words/s\n",
      "2023-12-06 15:11:44,761 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136244 effective words) took 13.9s, 224848 effective words/s', 'datetime': '2023-12-06T15:11:44.761330', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:11:44,761 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w7,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:11:44.761330', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 76%|  | 369/486 [58:08<30:56, 15.87s/it]2023-12-06 15:11:49,570 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:11:49,570 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:11:49,591 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:11:49,592 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:11:49,599 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:11:49.599506', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:11:49,600 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:11:49.600505', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:11:49,605 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:11:49,605 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:11:49,606 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:11:49.606507', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:11:49,613 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:11:49,614 : INFO : resetting layer weights\n",
      "2023-12-06 15:11:49,620 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:11:49.620334', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:11:49,909 : INFO : EPOCH 0: training on 99524 raw words (60490 effective words) took 0.3s, 212223 effective words/s\n",
      "2023-12-06 15:11:50,209 : INFO : EPOCH 1: training on 99524 raw words (60417 effective words) took 0.3s, 222313 effective words/s\n",
      "2023-12-06 15:11:50,463 : INFO : EPOCH 2: training on 99524 raw words (60423 effective words) took 0.2s, 242861 effective words/s\n",
      "2023-12-06 15:11:50,707 : INFO : EPOCH 3: training on 99524 raw words (60291 effective words) took 0.2s, 251916 effective words/s\n",
      "2023-12-06 15:11:50,959 : INFO : EPOCH 4: training on 99524 raw words (60455 effective words) took 0.2s, 244724 effective words/s\n",
      "2023-12-06 15:11:51,203 : INFO : EPOCH 5: training on 99524 raw words (60430 effective words) took 0.2s, 252587 effective words/s\n",
      "2023-12-06 15:11:51,458 : INFO : EPOCH 6: training on 99524 raw words (60424 effective words) took 0.3s, 240617 effective words/s\n",
      "2023-12-06 15:11:51,723 : INFO : EPOCH 7: training on 99524 raw words (60382 effective words) took 0.3s, 231525 effective words/s\n",
      "2023-12-06 15:11:51,972 : INFO : EPOCH 8: training on 99524 raw words (60231 effective words) took 0.2s, 246627 effective words/s\n",
      "2023-12-06 15:11:52,226 : INFO : EPOCH 9: training on 99524 raw words (60530 effective words) took 0.2s, 243636 effective words/s\n",
      "2023-12-06 15:11:52,227 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604073 effective words) took 2.6s, 231783 effective words/s', 'datetime': '2023-12-06T15:11:52.227798', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:11:52,227 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:11:52.227798', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 76%|  | 370/486 [58:13<24:43, 12.79s/it]2023-12-06 15:11:55,172 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:11:55,174 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:11:55,199 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:11:55,200 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:11:55,205 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:11:55.205925', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:11:55,207 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:11:55.207430', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:11:55,213 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:11:55,214 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:11:55,214 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:11:55.214611', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:11:55,222 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:11:55,223 : INFO : resetting layer weights\n",
      "2023-12-06 15:11:55,228 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:11:55.228682', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:11:55,502 : INFO : EPOCH 0: training on 99524 raw words (60417 effective words) took 0.3s, 223906 effective words/s\n",
      "2023-12-06 15:11:55,804 : INFO : EPOCH 1: training on 99524 raw words (60372 effective words) took 0.3s, 209462 effective words/s\n",
      "2023-12-06 15:11:56,071 : INFO : EPOCH 2: training on 99524 raw words (60389 effective words) took 0.3s, 230197 effective words/s\n",
      "2023-12-06 15:11:56,346 : INFO : EPOCH 3: training on 99524 raw words (60402 effective words) took 0.3s, 223572 effective words/s\n",
      "2023-12-06 15:11:56,615 : INFO : EPOCH 4: training on 99524 raw words (60379 effective words) took 0.3s, 228235 effective words/s\n",
      "2023-12-06 15:11:56,882 : INFO : EPOCH 5: training on 99524 raw words (60274 effective words) took 0.3s, 229075 effective words/s\n",
      "2023-12-06 15:11:57,150 : INFO : EPOCH 6: training on 99524 raw words (60275 effective words) took 0.3s, 228551 effective words/s\n",
      "2023-12-06 15:11:57,419 : INFO : EPOCH 7: training on 99524 raw words (60417 effective words) took 0.3s, 229440 effective words/s\n",
      "2023-12-06 15:11:57,691 : INFO : EPOCH 8: training on 99524 raw words (60331 effective words) took 0.3s, 226069 effective words/s\n",
      "2023-12-06 15:11:57,953 : INFO : EPOCH 9: training on 99524 raw words (60331 effective words) took 0.3s, 234493 effective words/s\n",
      "2023-12-06 15:11:57,954 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603587 effective words) took 2.7s, 221502 effective words/s', 'datetime': '2023-12-06T15:11:57.954267', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:11:57,955 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:11:57.955266', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 76%|  | 371/486 [58:19<20:30, 10.70s/it]2023-12-06 15:12:01,010 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:12:01,010 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:12:01,032 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:12:01,034 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:12:01,040 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:12:01.040384', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:12:01,041 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:12:01.041386', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:12:01,045 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:12:01,046 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:12:01,047 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:12:01.047833', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:12:01,054 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:12:01,055 : INFO : resetting layer weights\n",
      "2023-12-06 15:12:01,061 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:12:01.061014', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:12:01,319 : INFO : EPOCH 0: training on 99524 raw words (60471 effective words) took 0.3s, 239084 effective words/s\n",
      "2023-12-06 15:12:01,626 : INFO : EPOCH 1: training on 99524 raw words (60214 effective words) took 0.3s, 203463 effective words/s\n",
      "2023-12-06 15:12:01,902 : INFO : EPOCH 2: training on 99524 raw words (60415 effective words) took 0.3s, 222095 effective words/s\n",
      "2023-12-06 15:12:02,179 : INFO : EPOCH 3: training on 99524 raw words (60230 effective words) took 0.3s, 221614 effective words/s\n",
      "2023-12-06 15:12:02,453 : INFO : EPOCH 4: training on 99524 raw words (60372 effective words) took 0.3s, 223945 effective words/s\n",
      "2023-12-06 15:12:02,728 : INFO : EPOCH 5: training on 99524 raw words (60519 effective words) took 0.3s, 223801 effective words/s\n",
      "2023-12-06 15:12:03,006 : INFO : EPOCH 6: training on 99524 raw words (60371 effective words) took 0.3s, 221433 effective words/s\n",
      "2023-12-06 15:12:03,281 : INFO : EPOCH 7: training on 99524 raw words (60446 effective words) took 0.3s, 222995 effective words/s\n",
      "2023-12-06 15:12:03,551 : INFO : EPOCH 8: training on 99524 raw words (60488 effective words) took 0.3s, 227094 effective words/s\n",
      "2023-12-06 15:12:03,826 : INFO : EPOCH 9: training on 99524 raw words (60304 effective words) took 0.3s, 224013 effective words/s\n",
      "2023-12-06 15:12:03,827 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603830 effective words) took 2.8s, 218395 effective words/s', 'datetime': '2023-12-06T15:12:03.827504', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:12:03,827 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:12:03.827504', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 77%|  | 372/486 [58:25<17:35,  9.26s/it]2023-12-06 15:12:06,910 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:12:06,911 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:12:06,931 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:12:06,932 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:12:06,939 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:12:06.939360', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:12:06,940 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:12:06.940360', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:12:06,946 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:12:06,947 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:12:06,947 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:12:06.947362', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:12:06,954 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:12:06,956 : INFO : resetting layer weights\n",
      "2023-12-06 15:12:06,961 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:12:06.961983', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:12:07,249 : INFO : EPOCH 0: training on 99524 raw words (60305 effective words) took 0.3s, 213238 effective words/s\n",
      "2023-12-06 15:12:07,516 : INFO : EPOCH 1: training on 99524 raw words (60520 effective words) took 0.3s, 235813 effective words/s\n",
      "2023-12-06 15:12:07,766 : INFO : EPOCH 2: training on 99524 raw words (60283 effective words) took 0.2s, 245038 effective words/s\n",
      "2023-12-06 15:12:08,026 : INFO : EPOCH 3: training on 99524 raw words (60209 effective words) took 0.3s, 235923 effective words/s\n",
      "2023-12-06 15:12:08,274 : INFO : EPOCH 4: training on 99524 raw words (60315 effective words) took 0.2s, 248206 effective words/s\n",
      "2023-12-06 15:12:08,526 : INFO : EPOCH 5: training on 99524 raw words (60423 effective words) took 0.2s, 243820 effective words/s\n",
      "2023-12-06 15:12:08,778 : INFO : EPOCH 6: training on 99524 raw words (60409 effective words) took 0.2s, 244309 effective words/s\n",
      "2023-12-06 15:12:09,042 : INFO : EPOCH 7: training on 99524 raw words (60401 effective words) took 0.3s, 238648 effective words/s\n",
      "2023-12-06 15:12:09,293 : INFO : EPOCH 8: training on 99524 raw words (60449 effective words) took 0.2s, 245612 effective words/s\n",
      "2023-12-06 15:12:09,543 : INFO : EPOCH 9: training on 99524 raw words (60376 effective words) took 0.2s, 245922 effective words/s\n",
      "2023-12-06 15:12:09,788 : INFO : EPOCH 10: training on 99524 raw words (60472 effective words) took 0.2s, 250974 effective words/s\n",
      "2023-12-06 15:12:10,040 : INFO : EPOCH 11: training on 99524 raw words (60508 effective words) took 0.2s, 244838 effective words/s\n",
      "2023-12-06 15:12:10,302 : INFO : EPOCH 12: training on 99524 raw words (60384 effective words) took 0.3s, 233819 effective words/s\n",
      "2023-12-06 15:12:10,551 : INFO : EPOCH 13: training on 99524 raw words (60443 effective words) took 0.2s, 247750 effective words/s\n",
      "2023-12-06 15:12:10,815 : INFO : EPOCH 14: training on 99524 raw words (60477 effective words) took 0.3s, 232554 effective words/s\n",
      "2023-12-06 15:12:11,067 : INFO : EPOCH 15: training on 99524 raw words (60497 effective words) took 0.2s, 246002 effective words/s\n",
      "2023-12-06 15:12:11,315 : INFO : EPOCH 16: training on 99524 raw words (60464 effective words) took 0.2s, 248242 effective words/s\n",
      "2023-12-06 15:12:11,567 : INFO : EPOCH 17: training on 99524 raw words (60288 effective words) took 0.2s, 244231 effective words/s\n",
      "2023-12-06 15:12:11,827 : INFO : EPOCH 18: training on 99524 raw words (60268 effective words) took 0.3s, 235712 effective words/s\n",
      "2023-12-06 15:12:12,077 : INFO : EPOCH 19: training on 99524 raw words (60433 effective words) took 0.2s, 246396 effective words/s\n",
      "2023-12-06 15:12:12,325 : INFO : EPOCH 20: training on 99524 raw words (60489 effective words) took 0.2s, 248999 effective words/s\n",
      "2023-12-06 15:12:12,575 : INFO : EPOCH 21: training on 99524 raw words (60360 effective words) took 0.2s, 246146 effective words/s\n",
      "2023-12-06 15:12:12,824 : INFO : EPOCH 22: training on 99524 raw words (60448 effective words) took 0.2s, 247232 effective words/s\n",
      "2023-12-06 15:12:13,073 : INFO : EPOCH 23: training on 99524 raw words (60216 effective words) took 0.2s, 246102 effective words/s\n",
      "2023-12-06 15:12:13,322 : INFO : EPOCH 24: training on 99524 raw words (60615 effective words) took 0.2s, 247315 effective words/s\n",
      "2023-12-06 15:12:13,574 : INFO : EPOCH 25: training on 99524 raw words (60316 effective words) took 0.2s, 244172 effective words/s\n",
      "2023-12-06 15:12:13,821 : INFO : EPOCH 26: training on 99524 raw words (60334 effective words) took 0.2s, 249003 effective words/s\n",
      "2023-12-06 15:12:14,073 : INFO : EPOCH 27: training on 99524 raw words (60521 effective words) took 0.2s, 244723 effective words/s\n",
      "2023-12-06 15:12:14,321 : INFO : EPOCH 28: training on 99524 raw words (60520 effective words) took 0.2s, 248970 effective words/s\n",
      "2023-12-06 15:12:14,571 : INFO : EPOCH 29: training on 99524 raw words (60242 effective words) took 0.2s, 244947 effective words/s\n",
      "2023-12-06 15:12:14,573 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811985 effective words) took 7.6s, 238112 effective words/s', 'datetime': '2023-12-06T15:12:14.572326', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:12:14,573 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:12:14.573330', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 77%|  | 373/486 [58:36<18:31,  9.84s/it]2023-12-06 15:12:18,090 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:12:18,092 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:12:18,118 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:12:18,119 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:12:18,125 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:12:18.125897', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:12:18,126 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:12:18.125897', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:12:18,131 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:12:18,132 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:12:18,132 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:12:18.132913', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:12:18,139 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:12:18,140 : INFO : resetting layer weights\n",
      "2023-12-06 15:12:18,144 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:12:18.144914', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:12:18,390 : INFO : EPOCH 0: training on 99524 raw words (60425 effective words) took 0.2s, 251153 effective words/s\n",
      "2023-12-06 15:12:18,721 : INFO : EPOCH 1: training on 99524 raw words (60352 effective words) took 0.3s, 206393 effective words/s\n",
      "2023-12-06 15:12:18,984 : INFO : EPOCH 2: training on 99524 raw words (60282 effective words) took 0.3s, 233565 effective words/s\n",
      "2023-12-06 15:12:19,248 : INFO : EPOCH 3: training on 99524 raw words (60508 effective words) took 0.3s, 232692 effective words/s\n",
      "2023-12-06 15:12:19,512 : INFO : EPOCH 4: training on 99524 raw words (60451 effective words) took 0.3s, 233985 effective words/s\n",
      "2023-12-06 15:12:19,774 : INFO : EPOCH 5: training on 99524 raw words (60295 effective words) took 0.3s, 233662 effective words/s\n",
      "2023-12-06 15:12:20,039 : INFO : EPOCH 6: training on 99524 raw words (60466 effective words) took 0.3s, 232854 effective words/s\n",
      "2023-12-06 15:12:20,313 : INFO : EPOCH 7: training on 99524 raw words (60415 effective words) took 0.3s, 226225 effective words/s\n",
      "2023-12-06 15:12:20,578 : INFO : EPOCH 8: training on 99524 raw words (60278 effective words) took 0.3s, 230951 effective words/s\n",
      "2023-12-06 15:12:20,846 : INFO : EPOCH 9: training on 99524 raw words (60290 effective words) took 0.3s, 228842 effective words/s\n",
      "2023-12-06 15:12:21,114 : INFO : EPOCH 10: training on 99524 raw words (60364 effective words) took 0.3s, 228881 effective words/s\n",
      "2023-12-06 15:12:21,380 : INFO : EPOCH 11: training on 99524 raw words (60574 effective words) took 0.3s, 231501 effective words/s\n",
      "2023-12-06 15:12:21,651 : INFO : EPOCH 12: training on 99524 raw words (60239 effective words) took 0.3s, 226106 effective words/s\n",
      "2023-12-06 15:12:21,934 : INFO : EPOCH 13: training on 99524 raw words (60375 effective words) took 0.3s, 217816 effective words/s\n",
      "2023-12-06 15:12:22,203 : INFO : EPOCH 14: training on 99524 raw words (60573 effective words) took 0.3s, 228943 effective words/s\n",
      "2023-12-06 15:12:22,468 : INFO : EPOCH 15: training on 99524 raw words (60388 effective words) took 0.3s, 231849 effective words/s\n",
      "2023-12-06 15:12:22,735 : INFO : EPOCH 16: training on 99524 raw words (60436 effective words) took 0.3s, 229884 effective words/s\n",
      "2023-12-06 15:12:23,007 : INFO : EPOCH 17: training on 99524 raw words (60232 effective words) took 0.3s, 225674 effective words/s\n",
      "2023-12-06 15:12:23,284 : INFO : EPOCH 18: training on 99524 raw words (60410 effective words) took 0.3s, 221742 effective words/s\n",
      "2023-12-06 15:12:23,560 : INFO : EPOCH 19: training on 99524 raw words (60327 effective words) took 0.3s, 222868 effective words/s\n",
      "2023-12-06 15:12:23,829 : INFO : EPOCH 20: training on 99524 raw words (60414 effective words) took 0.3s, 228721 effective words/s\n",
      "2023-12-06 15:12:24,098 : INFO : EPOCH 21: training on 99524 raw words (60369 effective words) took 0.3s, 227814 effective words/s\n",
      "2023-12-06 15:12:24,364 : INFO : EPOCH 22: training on 99524 raw words (60352 effective words) took 0.3s, 231200 effective words/s\n",
      "2023-12-06 15:12:24,629 : INFO : EPOCH 23: training on 99524 raw words (60414 effective words) took 0.3s, 232150 effective words/s\n",
      "2023-12-06 15:12:24,913 : INFO : EPOCH 24: training on 99524 raw words (60234 effective words) took 0.3s, 215968 effective words/s\n",
      "2023-12-06 15:12:25,177 : INFO : EPOCH 25: training on 99524 raw words (60308 effective words) took 0.3s, 232003 effective words/s\n",
      "2023-12-06 15:12:25,444 : INFO : EPOCH 26: training on 99524 raw words (60546 effective words) took 0.3s, 230732 effective words/s\n",
      "2023-12-06 15:12:25,712 : INFO : EPOCH 27: training on 99524 raw words (60259 effective words) took 0.3s, 229002 effective words/s\n",
      "2023-12-06 15:12:25,978 : INFO : EPOCH 28: training on 99524 raw words (60395 effective words) took 0.3s, 230867 effective words/s\n",
      "2023-12-06 15:12:26,246 : INFO : EPOCH 29: training on 99524 raw words (60423 effective words) took 0.3s, 229381 effective words/s\n",
      "2023-12-06 15:12:26,247 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811394 effective words) took 8.1s, 223584 effective words/s', 'datetime': '2023-12-06T15:12:26.247425', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:12:26,248 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:12:26.247425', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 77%|  | 374/486 [58:48<19:31, 10.46s/it]2023-12-06 15:12:30,012 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:12:30,013 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:12:30,035 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:12:30,035 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:12:30,039 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:12:30.039853', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:12:30,041 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:12:30.041172', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:12:30,048 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:12:30,048 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:12:30,048 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:12:30.048525', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:12:30,056 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:12:30,057 : INFO : resetting layer weights\n",
      "2023-12-06 15:12:30,061 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:12:30.061382', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:12:30,345 : INFO : EPOCH 0: training on 99524 raw words (60501 effective words) took 0.3s, 216832 effective words/s\n",
      "2023-12-06 15:12:30,645 : INFO : EPOCH 1: training on 99524 raw words (60432 effective words) took 0.3s, 205467 effective words/s\n",
      "2023-12-06 15:12:30,919 : INFO : EPOCH 2: training on 99524 raw words (60373 effective words) took 0.3s, 224094 effective words/s\n",
      "2023-12-06 15:12:31,196 : INFO : EPOCH 3: training on 99524 raw words (60392 effective words) took 0.3s, 221249 effective words/s\n",
      "2023-12-06 15:12:31,466 : INFO : EPOCH 4: training on 99524 raw words (60383 effective words) took 0.3s, 228397 effective words/s\n",
      "2023-12-06 15:12:31,733 : INFO : EPOCH 5: training on 99524 raw words (60408 effective words) took 0.3s, 229171 effective words/s\n",
      "2023-12-06 15:12:32,008 : INFO : EPOCH 6: training on 99524 raw words (60352 effective words) took 0.3s, 223861 effective words/s\n",
      "2023-12-06 15:12:32,278 : INFO : EPOCH 7: training on 99524 raw words (60339 effective words) took 0.3s, 227185 effective words/s\n",
      "2023-12-06 15:12:32,546 : INFO : EPOCH 8: training on 99524 raw words (60264 effective words) took 0.3s, 228765 effective words/s\n",
      "2023-12-06 15:12:32,814 : INFO : EPOCH 9: training on 99524 raw words (60331 effective words) took 0.3s, 229227 effective words/s\n",
      "2023-12-06 15:12:33,085 : INFO : EPOCH 10: training on 99524 raw words (60295 effective words) took 0.3s, 226043 effective words/s\n",
      "2023-12-06 15:12:33,353 : INFO : EPOCH 11: training on 99524 raw words (60487 effective words) took 0.3s, 229437 effective words/s\n",
      "2023-12-06 15:12:33,630 : INFO : EPOCH 12: training on 99524 raw words (60539 effective words) took 0.3s, 222741 effective words/s\n",
      "2023-12-06 15:12:33,903 : INFO : EPOCH 13: training on 99524 raw words (60342 effective words) took 0.3s, 225103 effective words/s\n",
      "2023-12-06 15:12:34,171 : INFO : EPOCH 14: training on 99524 raw words (60399 effective words) took 0.3s, 229524 effective words/s\n",
      "2023-12-06 15:12:34,443 : INFO : EPOCH 15: training on 99524 raw words (60447 effective words) took 0.3s, 224887 effective words/s\n",
      "2023-12-06 15:12:34,715 : INFO : EPOCH 16: training on 99524 raw words (60446 effective words) took 0.3s, 226373 effective words/s\n",
      "2023-12-06 15:12:34,986 : INFO : EPOCH 17: training on 99524 raw words (60483 effective words) took 0.3s, 226804 effective words/s\n",
      "2023-12-06 15:12:35,264 : INFO : EPOCH 18: training on 99524 raw words (60424 effective words) took 0.3s, 221448 effective words/s\n",
      "2023-12-06 15:12:35,542 : INFO : EPOCH 19: training on 99524 raw words (60336 effective words) took 0.3s, 220533 effective words/s\n",
      "2023-12-06 15:12:35,814 : INFO : EPOCH 20: training on 99524 raw words (60435 effective words) took 0.3s, 226392 effective words/s\n",
      "2023-12-06 15:12:36,087 : INFO : EPOCH 21: training on 99524 raw words (60412 effective words) took 0.3s, 224758 effective words/s\n",
      "2023-12-06 15:12:36,363 : INFO : EPOCH 22: training on 99524 raw words (60520 effective words) took 0.3s, 223018 effective words/s\n",
      "2023-12-06 15:12:36,635 : INFO : EPOCH 23: training on 99524 raw words (60439 effective words) took 0.3s, 226970 effective words/s\n",
      "2023-12-06 15:12:36,919 : INFO : EPOCH 24: training on 99524 raw words (60367 effective words) took 0.3s, 215488 effective words/s\n",
      "2023-12-06 15:12:37,198 : INFO : EPOCH 25: training on 99524 raw words (60398 effective words) took 0.3s, 219962 effective words/s\n",
      "2023-12-06 15:12:37,465 : INFO : EPOCH 26: training on 99524 raw words (60459 effective words) took 0.3s, 230583 effective words/s\n",
      "2023-12-06 15:12:37,731 : INFO : EPOCH 27: training on 99524 raw words (60403 effective words) took 0.3s, 231531 effective words/s\n",
      "2023-12-06 15:12:38,003 : INFO : EPOCH 28: training on 99524 raw words (60451 effective words) took 0.3s, 227047 effective words/s\n",
      "2023-12-06 15:12:38,275 : INFO : EPOCH 29: training on 99524 raw words (60440 effective words) took 0.3s, 225337 effective words/s\n",
      "2023-12-06 15:12:38,276 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812297 effective words) took 8.2s, 220629 effective words/s', 'datetime': '2023-12-06T15:12:38.276401', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:12:38,277 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:12:38.277399', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 77%|  | 375/486 [59:00<20:21, 11.00s/it]2023-12-06 15:12:42,282 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:12:42,283 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:12:42,305 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:12:42,306 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:12:42,311 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:12:42.310939', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:12:42,311 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:12:42.311939', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:12:42,317 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:12:42,318 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:12:42,318 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:12:42.318479', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:12:42,329 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:12:42,329 : INFO : resetting layer weights\n",
      "2023-12-06 15:12:42,334 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:12:42.334769', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:12:42,566 : INFO : EPOCH 0: training on 99524 raw words (60327 effective words) took 0.2s, 266123 effective words/s\n",
      "2023-12-06 15:12:42,869 : INFO : EPOCH 1: training on 99524 raw words (60555 effective words) took 0.3s, 225153 effective words/s\n",
      "2023-12-06 15:12:43,119 : INFO : EPOCH 2: training on 99524 raw words (60296 effective words) took 0.2s, 245798 effective words/s\n",
      "2023-12-06 15:12:43,371 : INFO : EPOCH 3: training on 99524 raw words (60390 effective words) took 0.2s, 245055 effective words/s\n",
      "2023-12-06 15:12:43,618 : INFO : EPOCH 4: training on 99524 raw words (60528 effective words) took 0.2s, 248432 effective words/s\n",
      "2023-12-06 15:12:43,874 : INFO : EPOCH 5: training on 99524 raw words (60457 effective words) took 0.3s, 241799 effective words/s\n",
      "2023-12-06 15:12:44,129 : INFO : EPOCH 6: training on 99524 raw words (60406 effective words) took 0.3s, 240643 effective words/s\n",
      "2023-12-06 15:12:44,376 : INFO : EPOCH 7: training on 99524 raw words (60566 effective words) took 0.2s, 250744 effective words/s\n",
      "2023-12-06 15:12:44,623 : INFO : EPOCH 8: training on 99524 raw words (60417 effective words) took 0.2s, 249200 effective words/s\n",
      "2023-12-06 15:12:44,874 : INFO : EPOCH 9: training on 99524 raw words (60231 effective words) took 0.2s, 244163 effective words/s\n",
      "2023-12-06 15:12:45,123 : INFO : EPOCH 10: training on 99524 raw words (60269 effective words) took 0.2s, 246972 effective words/s\n",
      "2023-12-06 15:12:45,392 : INFO : EPOCH 11: training on 99524 raw words (60306 effective words) took 0.3s, 227998 effective words/s\n",
      "2023-12-06 15:12:45,652 : INFO : EPOCH 12: training on 99524 raw words (60282 effective words) took 0.3s, 235783 effective words/s\n",
      "2023-12-06 15:12:45,907 : INFO : EPOCH 13: training on 99524 raw words (60496 effective words) took 0.2s, 242040 effective words/s\n",
      "2023-12-06 15:12:46,158 : INFO : EPOCH 14: training on 99524 raw words (60401 effective words) took 0.2s, 244480 effective words/s\n",
      "2023-12-06 15:12:46,411 : INFO : EPOCH 15: training on 99524 raw words (60519 effective words) took 0.2s, 244985 effective words/s\n",
      "2023-12-06 15:12:46,660 : INFO : EPOCH 16: training on 99524 raw words (60390 effective words) took 0.2s, 247908 effective words/s\n",
      "2023-12-06 15:12:46,915 : INFO : EPOCH 17: training on 99524 raw words (60272 effective words) took 0.3s, 240117 effective words/s\n",
      "2023-12-06 15:12:47,169 : INFO : EPOCH 18: training on 99524 raw words (60289 effective words) took 0.2s, 241800 effective words/s\n",
      "2023-12-06 15:12:47,433 : INFO : EPOCH 19: training on 99524 raw words (60241 effective words) took 0.3s, 232001 effective words/s\n",
      "2023-12-06 15:12:47,678 : INFO : EPOCH 20: training on 99524 raw words (60529 effective words) took 0.2s, 251000 effective words/s\n",
      "2023-12-06 15:12:47,927 : INFO : EPOCH 21: training on 99524 raw words (60233 effective words) took 0.2s, 246891 effective words/s\n",
      "2023-12-06 15:12:48,174 : INFO : EPOCH 22: training on 99524 raw words (60475 effective words) took 0.2s, 248872 effective words/s\n",
      "2023-12-06 15:12:48,431 : INFO : EPOCH 23: training on 99524 raw words (60345 effective words) took 0.3s, 239356 effective words/s\n",
      "2023-12-06 15:12:48,676 : INFO : EPOCH 24: training on 99524 raw words (60257 effective words) took 0.2s, 251713 effective words/s\n",
      "2023-12-06 15:12:48,928 : INFO : EPOCH 25: training on 99524 raw words (60352 effective words) took 0.2s, 242620 effective words/s\n",
      "2023-12-06 15:12:49,185 : INFO : EPOCH 26: training on 99524 raw words (60368 effective words) took 0.3s, 239710 effective words/s\n",
      "2023-12-06 15:12:49,439 : INFO : EPOCH 27: training on 99524 raw words (60426 effective words) took 0.2s, 242239 effective words/s\n",
      "2023-12-06 15:12:49,687 : INFO : EPOCH 28: training on 99524 raw words (60524 effective words) took 0.2s, 247814 effective words/s\n",
      "2023-12-06 15:12:49,938 : INFO : EPOCH 29: training on 99524 raw words (60487 effective words) took 0.2s, 246384 effective words/s\n",
      "2023-12-06 15:12:50,185 : INFO : EPOCH 30: training on 99524 raw words (60433 effective words) took 0.2s, 249811 effective words/s\n",
      "2023-12-06 15:12:50,431 : INFO : EPOCH 31: training on 99524 raw words (60406 effective words) took 0.2s, 249123 effective words/s\n",
      "2023-12-06 15:12:50,681 : INFO : EPOCH 32: training on 99524 raw words (60558 effective words) took 0.2s, 246691 effective words/s\n",
      "2023-12-06 15:12:50,927 : INFO : EPOCH 33: training on 99524 raw words (60416 effective words) took 0.2s, 249901 effective words/s\n",
      "2023-12-06 15:12:51,180 : INFO : EPOCH 34: training on 99524 raw words (60395 effective words) took 0.2s, 242578 effective words/s\n",
      "2023-12-06 15:12:51,431 : INFO : EPOCH 35: training on 99524 raw words (60424 effective words) took 0.2s, 246233 effective words/s\n",
      "2023-12-06 15:12:51,683 : INFO : EPOCH 36: training on 99524 raw words (60569 effective words) took 0.2s, 245087 effective words/s\n",
      "2023-12-06 15:12:51,929 : INFO : EPOCH 37: training on 99524 raw words (60331 effective words) took 0.2s, 249620 effective words/s\n",
      "2023-12-06 15:12:52,183 : INFO : EPOCH 38: training on 99524 raw words (60562 effective words) took 0.2s, 243767 effective words/s\n",
      "2023-12-06 15:12:52,428 : INFO : EPOCH 39: training on 99524 raw words (60432 effective words) took 0.2s, 250991 effective words/s\n",
      "2023-12-06 15:12:52,681 : INFO : EPOCH 40: training on 99524 raw words (60531 effective words) took 0.2s, 243464 effective words/s\n",
      "2023-12-06 15:12:52,925 : INFO : EPOCH 41: training on 99524 raw words (60367 effective words) took 0.2s, 252372 effective words/s\n",
      "2023-12-06 15:12:53,182 : INFO : EPOCH 42: training on 99524 raw words (60337 effective words) took 0.3s, 239248 effective words/s\n",
      "2023-12-06 15:12:53,441 : INFO : EPOCH 43: training on 99524 raw words (60384 effective words) took 0.3s, 236702 effective words/s\n",
      "2023-12-06 15:12:53,691 : INFO : EPOCH 44: training on 99524 raw words (60374 effective words) took 0.2s, 245060 effective words/s\n",
      "2023-12-06 15:12:53,938 : INFO : EPOCH 45: training on 99524 raw words (60562 effective words) took 0.2s, 250555 effective words/s\n",
      "2023-12-06 15:12:54,193 : INFO : EPOCH 46: training on 99524 raw words (60628 effective words) took 0.3s, 241893 effective words/s\n",
      "2023-12-06 15:12:54,443 : INFO : EPOCH 47: training on 99524 raw words (60476 effective words) took 0.2s, 246322 effective words/s\n",
      "2023-12-06 15:12:54,694 : INFO : EPOCH 48: training on 99524 raw words (60277 effective words) took 0.2s, 245050 effective words/s\n",
      "2023-12-06 15:12:54,936 : INFO : EPOCH 49: training on 99524 raw words (60529 effective words) took 0.2s, 254226 effective words/s\n",
      "2023-12-06 15:12:54,937 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3020625 effective words) took 12.6s, 239681 effective words/s', 'datetime': '2023-12-06T15:12:54.937665', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:12:54,938 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:12:54.938865', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 77%|  | 376/486 [59:17<23:22, 12.75s/it]2023-12-06 15:12:59,106 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:12:59,106 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:12:59,129 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:12:59,129 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:12:59,133 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:12:59.133516', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:12:59,133 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:12:59.133516', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:12:59,139 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:12:59,141 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:12:59,141 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:12:59.141692', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:12:59,148 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:12:59,149 : INFO : resetting layer weights\n",
      "2023-12-06 15:12:59,155 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:12:59.155285', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:12:59,446 : INFO : EPOCH 0: training on 99524 raw words (60355 effective words) took 0.3s, 210558 effective words/s\n",
      "2023-12-06 15:12:59,737 : INFO : EPOCH 1: training on 99524 raw words (60107 effective words) took 0.3s, 217025 effective words/s\n",
      "2023-12-06 15:13:00,003 : INFO : EPOCH 2: training on 99524 raw words (60486 effective words) took 0.3s, 230624 effective words/s\n",
      "2023-12-06 15:13:00,267 : INFO : EPOCH 3: training on 99524 raw words (60546 effective words) took 0.3s, 233763 effective words/s\n",
      "2023-12-06 15:13:00,533 : INFO : EPOCH 4: training on 99524 raw words (60492 effective words) took 0.3s, 232002 effective words/s\n",
      "2023-12-06 15:13:00,799 : INFO : EPOCH 5: training on 99524 raw words (60401 effective words) took 0.3s, 232226 effective words/s\n",
      "2023-12-06 15:13:01,062 : INFO : EPOCH 6: training on 99524 raw words (60254 effective words) took 0.3s, 233465 effective words/s\n",
      "2023-12-06 15:13:01,333 : INFO : EPOCH 7: training on 99524 raw words (60594 effective words) took 0.3s, 226669 effective words/s\n",
      "2023-12-06 15:13:01,598 : INFO : EPOCH 8: training on 99524 raw words (60401 effective words) took 0.3s, 232759 effective words/s\n",
      "2023-12-06 15:13:01,865 : INFO : EPOCH 9: training on 99524 raw words (60160 effective words) took 0.3s, 228625 effective words/s\n",
      "2023-12-06 15:13:02,128 : INFO : EPOCH 10: training on 99524 raw words (60384 effective words) took 0.3s, 233357 effective words/s\n",
      "2023-12-06 15:13:02,397 : INFO : EPOCH 11: training on 99524 raw words (60420 effective words) took 0.3s, 228949 effective words/s\n",
      "2023-12-06 15:13:02,692 : INFO : EPOCH 12: training on 99524 raw words (60431 effective words) took 0.3s, 208258 effective words/s\n",
      "2023-12-06 15:13:02,958 : INFO : EPOCH 13: training on 99524 raw words (60335 effective words) took 0.3s, 230754 effective words/s\n",
      "2023-12-06 15:13:03,220 : INFO : EPOCH 14: training on 99524 raw words (60355 effective words) took 0.3s, 234899 effective words/s\n",
      "2023-12-06 15:13:03,485 : INFO : EPOCH 15: training on 99524 raw words (60278 effective words) took 0.3s, 231621 effective words/s\n",
      "2023-12-06 15:13:03,747 : INFO : EPOCH 16: training on 99524 raw words (60340 effective words) took 0.3s, 233280 effective words/s\n",
      "2023-12-06 15:13:04,010 : INFO : EPOCH 17: training on 99524 raw words (60294 effective words) took 0.3s, 233879 effective words/s\n",
      "2023-12-06 15:13:04,281 : INFO : EPOCH 18: training on 99524 raw words (60226 effective words) took 0.3s, 225850 effective words/s\n",
      "2023-12-06 15:13:04,552 : INFO : EPOCH 19: training on 99524 raw words (60593 effective words) took 0.3s, 228498 effective words/s\n",
      "2023-12-06 15:13:04,811 : INFO : EPOCH 20: training on 99524 raw words (60431 effective words) took 0.3s, 236784 effective words/s\n",
      "2023-12-06 15:13:05,077 : INFO : EPOCH 21: training on 99524 raw words (60295 effective words) took 0.3s, 230987 effective words/s\n",
      "2023-12-06 15:13:05,340 : INFO : EPOCH 22: training on 99524 raw words (60222 effective words) took 0.3s, 232982 effective words/s\n",
      "2023-12-06 15:13:05,612 : INFO : EPOCH 23: training on 99524 raw words (60235 effective words) took 0.3s, 224893 effective words/s\n",
      "2023-12-06 15:13:05,883 : INFO : EPOCH 24: training on 99524 raw words (60312 effective words) took 0.3s, 227542 effective words/s\n",
      "2023-12-06 15:13:06,152 : INFO : EPOCH 25: training on 99524 raw words (60415 effective words) took 0.3s, 228509 effective words/s\n",
      "2023-12-06 15:13:06,414 : INFO : EPOCH 26: training on 99524 raw words (60398 effective words) took 0.3s, 234403 effective words/s\n",
      "2023-12-06 15:13:06,674 : INFO : EPOCH 27: training on 99524 raw words (60368 effective words) took 0.3s, 235958 effective words/s\n",
      "2023-12-06 15:13:06,936 : INFO : EPOCH 28: training on 99524 raw words (60374 effective words) took 0.3s, 234067 effective words/s\n",
      "2023-12-06 15:13:07,204 : INFO : EPOCH 29: training on 99524 raw words (60270 effective words) took 0.3s, 228934 effective words/s\n",
      "2023-12-06 15:13:07,475 : INFO : EPOCH 30: training on 99524 raw words (60329 effective words) took 0.3s, 225985 effective words/s\n",
      "2023-12-06 15:13:07,741 : INFO : EPOCH 31: training on 99524 raw words (60498 effective words) took 0.3s, 231504 effective words/s\n",
      "2023-12-06 15:13:08,005 : INFO : EPOCH 32: training on 99524 raw words (60577 effective words) took 0.3s, 232801 effective words/s\n",
      "2023-12-06 15:13:08,272 : INFO : EPOCH 33: training on 99524 raw words (60426 effective words) took 0.3s, 231252 effective words/s\n",
      "2023-12-06 15:13:08,545 : INFO : EPOCH 34: training on 99524 raw words (60352 effective words) took 0.3s, 225045 effective words/s\n",
      "2023-12-06 15:13:08,807 : INFO : EPOCH 35: training on 99524 raw words (60496 effective words) took 0.3s, 234074 effective words/s\n",
      "2023-12-06 15:13:09,079 : INFO : EPOCH 36: training on 99524 raw words (60611 effective words) took 0.3s, 226322 effective words/s\n",
      "2023-12-06 15:13:09,345 : INFO : EPOCH 37: training on 99524 raw words (60478 effective words) took 0.3s, 231842 effective words/s\n",
      "2023-12-06 15:13:09,608 : INFO : EPOCH 38: training on 99524 raw words (60427 effective words) took 0.3s, 235167 effective words/s\n",
      "2023-12-06 15:13:09,874 : INFO : EPOCH 39: training on 99524 raw words (60485 effective words) took 0.3s, 232063 effective words/s\n",
      "2023-12-06 15:13:10,135 : INFO : EPOCH 40: training on 99524 raw words (60355 effective words) took 0.3s, 235227 effective words/s\n",
      "2023-12-06 15:13:10,404 : INFO : EPOCH 41: training on 99524 raw words (60449 effective words) took 0.3s, 229842 effective words/s\n",
      "2023-12-06 15:13:10,671 : INFO : EPOCH 42: training on 99524 raw words (60350 effective words) took 0.3s, 229951 effective words/s\n",
      "2023-12-06 15:13:10,929 : INFO : EPOCH 43: training on 99524 raw words (60422 effective words) took 0.3s, 237978 effective words/s\n",
      "2023-12-06 15:13:11,191 : INFO : EPOCH 44: training on 99524 raw words (60341 effective words) took 0.3s, 234282 effective words/s\n",
      "2023-12-06 15:13:11,457 : INFO : EPOCH 45: training on 99524 raw words (60378 effective words) took 0.3s, 232598 effective words/s\n",
      "2023-12-06 15:13:11,720 : INFO : EPOCH 46: training on 99524 raw words (60216 effective words) took 0.3s, 232641 effective words/s\n",
      "2023-12-06 15:13:11,988 : INFO : EPOCH 47: training on 99524 raw words (60533 effective words) took 0.3s, 229841 effective words/s\n",
      "2023-12-06 15:13:12,273 : INFO : EPOCH 48: training on 99524 raw words (60318 effective words) took 0.3s, 215860 effective words/s\n",
      "2023-12-06 15:13:12,532 : INFO : EPOCH 49: training on 99524 raw words (60415 effective words) took 0.3s, 236490 effective words/s\n",
      "2023-12-06 15:13:12,533 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3019228 effective words) took 13.4s, 225686 effective words/s', 'datetime': '2023-12-06T15:13:12.533900', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:13:12,534 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:13:12.534900', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 78%|  | 377/486 [59:35<25:58, 14.30s/it]2023-12-06 15:13:17,005 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:13:17,005 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:13:17,027 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:13:17,028 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:13:17,033 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:13:17.033972', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:13:17,033 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:13:17.033972', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:13:17,038 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:13:17,039 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:13:17,039 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:13:17.039971', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:13:17,047 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:13:17,047 : INFO : resetting layer weights\n",
      "2023-12-06 15:13:17,053 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:13:17.053971', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:13:17,371 : INFO : EPOCH 0: training on 99524 raw words (60315 effective words) took 0.3s, 191789 effective words/s\n",
      "2023-12-06 15:13:17,662 : INFO : EPOCH 1: training on 99524 raw words (60387 effective words) took 0.3s, 212008 effective words/s\n",
      "2023-12-06 15:13:17,931 : INFO : EPOCH 2: training on 99524 raw words (60329 effective words) took 0.3s, 228020 effective words/s\n",
      "2023-12-06 15:13:18,203 : INFO : EPOCH 3: training on 99524 raw words (60350 effective words) took 0.3s, 225498 effective words/s\n",
      "2023-12-06 15:13:18,478 : INFO : EPOCH 4: training on 99524 raw words (60576 effective words) took 0.3s, 224731 effective words/s\n",
      "2023-12-06 15:13:18,746 : INFO : EPOCH 5: training on 99524 raw words (60395 effective words) took 0.3s, 229119 effective words/s\n",
      "2023-12-06 15:13:19,018 : INFO : EPOCH 6: training on 99524 raw words (60403 effective words) took 0.3s, 224759 effective words/s\n",
      "2023-12-06 15:13:19,318 : INFO : EPOCH 7: training on 99524 raw words (60233 effective words) took 0.3s, 204024 effective words/s\n",
      "2023-12-06 15:13:19,605 : INFO : EPOCH 8: training on 99524 raw words (60448 effective words) took 0.3s, 214353 effective words/s\n",
      "2023-12-06 15:13:19,871 : INFO : EPOCH 9: training on 99524 raw words (60453 effective words) took 0.3s, 232272 effective words/s\n",
      "2023-12-06 15:13:20,143 : INFO : EPOCH 10: training on 99524 raw words (60473 effective words) took 0.3s, 226059 effective words/s\n",
      "2023-12-06 15:13:20,418 : INFO : EPOCH 11: training on 99524 raw words (60360 effective words) took 0.3s, 223240 effective words/s\n",
      "2023-12-06 15:13:20,685 : INFO : EPOCH 12: training on 99524 raw words (60366 effective words) took 0.3s, 229831 effective words/s\n",
      "2023-12-06 15:13:20,963 : INFO : EPOCH 13: training on 99524 raw words (60311 effective words) took 0.3s, 223642 effective words/s\n",
      "2023-12-06 15:13:21,242 : INFO : EPOCH 14: training on 99524 raw words (60238 effective words) took 0.3s, 219656 effective words/s\n",
      "2023-12-06 15:13:21,513 : INFO : EPOCH 15: training on 99524 raw words (60451 effective words) took 0.3s, 226977 effective words/s\n",
      "2023-12-06 15:13:21,782 : INFO : EPOCH 16: training on 99524 raw words (60507 effective words) took 0.3s, 228054 effective words/s\n",
      "2023-12-06 15:13:22,054 : INFO : EPOCH 17: training on 99524 raw words (60377 effective words) took 0.3s, 226222 effective words/s\n",
      "2023-12-06 15:13:22,327 : INFO : EPOCH 18: training on 99524 raw words (60368 effective words) took 0.3s, 225246 effective words/s\n",
      "2023-12-06 15:13:22,600 : INFO : EPOCH 19: training on 99524 raw words (60431 effective words) took 0.3s, 225828 effective words/s\n",
      "2023-12-06 15:13:22,870 : INFO : EPOCH 20: training on 99524 raw words (60515 effective words) took 0.3s, 227676 effective words/s\n",
      "2023-12-06 15:13:23,144 : INFO : EPOCH 21: training on 99524 raw words (60423 effective words) took 0.3s, 224557 effective words/s\n",
      "2023-12-06 15:13:23,418 : INFO : EPOCH 22: training on 99524 raw words (60407 effective words) took 0.3s, 224629 effective words/s\n",
      "2023-12-06 15:13:23,689 : INFO : EPOCH 23: training on 99524 raw words (60533 effective words) took 0.3s, 227083 effective words/s\n",
      "2023-12-06 15:13:23,973 : INFO : EPOCH 24: training on 99524 raw words (60446 effective words) took 0.3s, 215965 effective words/s\n",
      "2023-12-06 15:13:24,245 : INFO : EPOCH 25: training on 99524 raw words (60454 effective words) took 0.3s, 226856 effective words/s\n",
      "2023-12-06 15:13:24,527 : INFO : EPOCH 26: training on 99524 raw words (60278 effective words) took 0.3s, 217536 effective words/s\n",
      "2023-12-06 15:13:24,798 : INFO : EPOCH 27: training on 99524 raw words (60388 effective words) took 0.3s, 225976 effective words/s\n",
      "2023-12-06 15:13:25,070 : INFO : EPOCH 28: training on 99524 raw words (60488 effective words) took 0.3s, 227120 effective words/s\n",
      "2023-12-06 15:13:25,343 : INFO : EPOCH 29: training on 99524 raw words (60498 effective words) took 0.3s, 225681 effective words/s\n",
      "2023-12-06 15:13:25,616 : INFO : EPOCH 30: training on 99524 raw words (60416 effective words) took 0.3s, 224709 effective words/s\n",
      "2023-12-06 15:13:25,892 : INFO : EPOCH 31: training on 99524 raw words (60323 effective words) took 0.3s, 222308 effective words/s\n",
      "2023-12-06 15:13:26,164 : INFO : EPOCH 32: training on 99524 raw words (60343 effective words) took 0.3s, 226157 effective words/s\n",
      "2023-12-06 15:13:26,437 : INFO : EPOCH 33: training on 99524 raw words (60400 effective words) took 0.3s, 225310 effective words/s\n",
      "2023-12-06 15:13:26,715 : INFO : EPOCH 34: training on 99524 raw words (60419 effective words) took 0.3s, 220998 effective words/s\n",
      "2023-12-06 15:13:26,990 : INFO : EPOCH 35: training on 99524 raw words (60314 effective words) took 0.3s, 224120 effective words/s\n",
      "2023-12-06 15:13:27,268 : INFO : EPOCH 36: training on 99524 raw words (60529 effective words) took 0.3s, 220576 effective words/s\n",
      "2023-12-06 15:13:27,540 : INFO : EPOCH 37: training on 99524 raw words (60340 effective words) took 0.3s, 226610 effective words/s\n",
      "2023-12-06 15:13:27,813 : INFO : EPOCH 38: training on 99524 raw words (60466 effective words) took 0.3s, 225893 effective words/s\n",
      "2023-12-06 15:13:28,091 : INFO : EPOCH 39: training on 99524 raw words (60289 effective words) took 0.3s, 219610 effective words/s\n",
      "2023-12-06 15:13:28,377 : INFO : EPOCH 40: training on 99524 raw words (60413 effective words) took 0.3s, 215871 effective words/s\n",
      "2023-12-06 15:13:28,664 : INFO : EPOCH 41: training on 99524 raw words (60353 effective words) took 0.3s, 213332 effective words/s\n",
      "2023-12-06 15:13:28,941 : INFO : EPOCH 42: training on 99524 raw words (60433 effective words) took 0.3s, 221847 effective words/s\n",
      "2023-12-06 15:13:29,214 : INFO : EPOCH 43: training on 99524 raw words (60360 effective words) took 0.3s, 224946 effective words/s\n",
      "2023-12-06 15:13:29,488 : INFO : EPOCH 44: training on 99524 raw words (60416 effective words) took 0.3s, 224816 effective words/s\n",
      "2023-12-06 15:13:29,757 : INFO : EPOCH 45: training on 99524 raw words (60564 effective words) took 0.3s, 228794 effective words/s\n",
      "2023-12-06 15:13:30,039 : INFO : EPOCH 46: training on 99524 raw words (60306 effective words) took 0.3s, 216837 effective words/s\n",
      "2023-12-06 15:13:30,310 : INFO : EPOCH 47: training on 99524 raw words (60294 effective words) took 0.3s, 226455 effective words/s\n",
      "2023-12-06 15:13:30,585 : INFO : EPOCH 48: training on 99524 raw words (60355 effective words) took 0.3s, 222875 effective words/s\n",
      "2023-12-06 15:13:30,852 : INFO : EPOCH 49: training on 99524 raw words (60278 effective words) took 0.3s, 230848 effective words/s\n",
      "2023-12-06 15:13:30,853 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3019812 effective words) took 13.8s, 218851 effective words/s', 'datetime': '2023-12-06T15:13:30.853102', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:13:30,854 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w7,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:13:30.854102', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 78%|  | 378/486 [59:54<28:06, 15.62s/it]2023-12-06 15:13:35,700 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:13:35,701 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:13:35,726 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:13:35,726 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:13:35,734 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:13:35.734265', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:13:35,735 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:13:35.735267', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:13:35,745 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:13:35,746 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:13:35,746 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:13:35.746268', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:13:35,762 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:13:35,763 : INFO : resetting layer weights\n",
      "2023-12-06 15:13:35,767 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:13:35.767653', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:13:36,045 : INFO : EPOCH 0: training on 99524 raw words (65449 effective words) took 0.3s, 240075 effective words/s\n",
      "2023-12-06 15:13:36,333 : INFO : EPOCH 1: training on 99524 raw words (65460 effective words) took 0.3s, 237477 effective words/s\n",
      "2023-12-06 15:13:36,594 : INFO : EPOCH 2: training on 99524 raw words (65372 effective words) took 0.3s, 253963 effective words/s\n",
      "2023-12-06 15:13:36,859 : INFO : EPOCH 3: training on 99524 raw words (65604 effective words) took 0.3s, 253381 effective words/s\n",
      "2023-12-06 15:13:37,115 : INFO : EPOCH 4: training on 99524 raw words (65576 effective words) took 0.3s, 260228 effective words/s\n",
      "2023-12-06 15:13:37,372 : INFO : EPOCH 5: training on 99524 raw words (65496 effective words) took 0.3s, 259460 effective words/s\n",
      "2023-12-06 15:13:37,632 : INFO : EPOCH 6: training on 99524 raw words (65616 effective words) took 0.3s, 255866 effective words/s\n",
      "2023-12-06 15:13:37,894 : INFO : EPOCH 7: training on 99524 raw words (65751 effective words) took 0.3s, 256142 effective words/s\n",
      "2023-12-06 15:13:38,156 : INFO : EPOCH 8: training on 99524 raw words (65602 effective words) took 0.3s, 254353 effective words/s\n",
      "2023-12-06 15:13:38,416 : INFO : EPOCH 9: training on 99524 raw words (65320 effective words) took 0.3s, 256018 effective words/s\n",
      "2023-12-06 15:13:38,417 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655246 effective words) took 2.6s, 247358 effective words/s', 'datetime': '2023-12-06T15:13:38.417196', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:13:38,418 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:13:38.418196', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 78%|  | 379/486 [1:00:00<22:33, 12.65s/it]2023-12-06 15:13:41,423 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:13:41,424 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:13:41,445 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:13:41,446 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:13:41,453 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:13:41.453957', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:13:41,454 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:13:41.454959', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:13:41,461 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:13:41,462 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:13:41,462 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:13:41.462976', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:13:41,474 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:13:41,474 : INFO : resetting layer weights\n",
      "2023-12-06 15:13:41,479 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:13:41.479701', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:13:41,764 : INFO : EPOCH 0: training on 99524 raw words (65437 effective words) took 0.3s, 233556 effective words/s\n",
      "2023-12-06 15:13:42,061 : INFO : EPOCH 1: training on 99524 raw words (65479 effective words) took 0.3s, 224362 effective words/s\n",
      "2023-12-06 15:13:42,327 : INFO : EPOCH 2: training on 99524 raw words (65530 effective words) took 0.3s, 249374 effective words/s\n",
      "2023-12-06 15:13:42,601 : INFO : EPOCH 3: training on 99524 raw words (65700 effective words) took 0.3s, 244901 effective words/s\n",
      "2023-12-06 15:13:42,870 : INFO : EPOCH 4: training on 99524 raw words (65603 effective words) took 0.3s, 246742 effective words/s\n",
      "2023-12-06 15:13:43,143 : INFO : EPOCH 5: training on 99524 raw words (65461 effective words) took 0.3s, 244844 effective words/s\n",
      "2023-12-06 15:13:43,422 : INFO : EPOCH 6: training on 99524 raw words (65566 effective words) took 0.3s, 238428 effective words/s\n",
      "2023-12-06 15:13:43,691 : INFO : EPOCH 7: training on 99524 raw words (65479 effective words) took 0.3s, 249262 effective words/s\n",
      "2023-12-06 15:13:43,969 : INFO : EPOCH 8: training on 99524 raw words (65532 effective words) took 0.3s, 239504 effective words/s\n",
      "2023-12-06 15:13:44,269 : INFO : EPOCH 9: training on 99524 raw words (65434 effective words) took 0.3s, 222131 effective words/s\n",
      "2023-12-06 15:13:44,271 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655221 effective words) took 2.8s, 234789 effective words/s', 'datetime': '2023-12-06T15:13:44.271309', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:13:44,272 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:13:44.272326', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 78%|  | 380/486 [1:00:05<18:45, 10.62s/it]2023-12-06 15:13:47,320 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:13:47,321 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:13:47,344 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:13:47,345 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:13:47,351 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:13:47.351431', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:13:47,352 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:13:47.352433', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:13:47,360 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:13:47,361 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:13:47,362 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:13:47.362114', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:13:47,372 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:13:47,373 : INFO : resetting layer weights\n",
      "2023-12-06 15:13:47,378 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:13:47.378675', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:13:47,675 : INFO : EPOCH 0: training on 99524 raw words (65778 effective words) took 0.3s, 224410 effective words/s\n",
      "2023-12-06 15:13:47,972 : INFO : EPOCH 1: training on 99524 raw words (65567 effective words) took 0.3s, 228102 effective words/s\n",
      "2023-12-06 15:13:48,253 : INFO : EPOCH 2: training on 99524 raw words (65590 effective words) took 0.3s, 237938 effective words/s\n",
      "2023-12-06 15:13:48,531 : INFO : EPOCH 3: training on 99524 raw words (65475 effective words) took 0.3s, 239989 effective words/s\n",
      "2023-12-06 15:13:48,805 : INFO : EPOCH 4: training on 99524 raw words (65681 effective words) took 0.3s, 243232 effective words/s\n",
      "2023-12-06 15:13:49,087 : INFO : EPOCH 5: training on 99524 raw words (65521 effective words) took 0.3s, 236585 effective words/s\n",
      "2023-12-06 15:13:49,365 : INFO : EPOCH 6: training on 99524 raw words (65468 effective words) took 0.3s, 239988 effective words/s\n",
      "2023-12-06 15:13:49,637 : INFO : EPOCH 7: training on 99524 raw words (65494 effective words) took 0.3s, 244243 effective words/s\n",
      "2023-12-06 15:13:49,914 : INFO : EPOCH 8: training on 99524 raw words (65685 effective words) took 0.3s, 241165 effective words/s\n",
      "2023-12-06 15:13:50,193 : INFO : EPOCH 9: training on 99524 raw words (65612 effective words) took 0.3s, 240209 effective words/s\n",
      "2023-12-06 15:13:50,193 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655871 effective words) took 2.8s, 233069 effective words/s', 'datetime': '2023-12-06T15:13:50.193517', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:13:50,194 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:13:50.194792', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 78%|  | 381/486 [1:00:11<16:08,  9.23s/it]2023-12-06 15:13:53,288 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:13:53,288 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:13:53,309 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:13:53,310 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:13:53,318 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:13:53.318804', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:13:53,319 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:13:53.319808', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:13:53,329 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:13:53,330 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:13:53,330 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:13:53.330806', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:13:53,343 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:13:53,343 : INFO : resetting layer weights\n",
      "2023-12-06 15:13:53,350 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:13:53.350025', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:13:53,619 : INFO : EPOCH 0: training on 99524 raw words (65584 effective words) took 0.3s, 247198 effective words/s\n",
      "2023-12-06 15:13:53,895 : INFO : EPOCH 1: training on 99524 raw words (65657 effective words) took 0.3s, 244683 effective words/s\n",
      "2023-12-06 15:13:54,148 : INFO : EPOCH 2: training on 99524 raw words (65562 effective words) took 0.2s, 263827 effective words/s\n",
      "2023-12-06 15:13:54,406 : INFO : EPOCH 3: training on 99524 raw words (65527 effective words) took 0.3s, 259332 effective words/s\n",
      "2023-12-06 15:13:54,661 : INFO : EPOCH 4: training on 99524 raw words (65603 effective words) took 0.3s, 261177 effective words/s\n",
      "2023-12-06 15:13:54,920 : INFO : EPOCH 5: training on 99524 raw words (65693 effective words) took 0.3s, 259542 effective words/s\n",
      "2023-12-06 15:13:55,177 : INFO : EPOCH 6: training on 99524 raw words (65569 effective words) took 0.3s, 260084 effective words/s\n",
      "2023-12-06 15:13:55,434 : INFO : EPOCH 7: training on 99524 raw words (65551 effective words) took 0.3s, 258348 effective words/s\n",
      "2023-12-06 15:13:55,688 : INFO : EPOCH 8: training on 99524 raw words (65561 effective words) took 0.2s, 263383 effective words/s\n",
      "2023-12-06 15:13:55,945 : INFO : EPOCH 9: training on 99524 raw words (65454 effective words) took 0.3s, 259374 effective words/s\n",
      "2023-12-06 15:13:56,199 : INFO : EPOCH 10: training on 99524 raw words (65473 effective words) took 0.3s, 261684 effective words/s\n",
      "2023-12-06 15:13:56,454 : INFO : EPOCH 11: training on 99524 raw words (65557 effective words) took 0.3s, 261874 effective words/s\n",
      "2023-12-06 15:13:56,712 : INFO : EPOCH 12: training on 99524 raw words (65588 effective words) took 0.3s, 259080 effective words/s\n",
      "2023-12-06 15:13:56,978 : INFO : EPOCH 13: training on 99524 raw words (65489 effective words) took 0.3s, 253886 effective words/s\n",
      "2023-12-06 15:13:57,247 : INFO : EPOCH 14: training on 99524 raw words (65719 effective words) took 0.3s, 248348 effective words/s\n",
      "2023-12-06 15:13:57,501 : INFO : EPOCH 15: training on 99524 raw words (65692 effective words) took 0.2s, 263479 effective words/s\n",
      "2023-12-06 15:13:57,756 : INFO : EPOCH 16: training on 99524 raw words (65556 effective words) took 0.3s, 261070 effective words/s\n",
      "2023-12-06 15:13:58,003 : INFO : EPOCH 17: training on 99524 raw words (65810 effective words) took 0.2s, 271143 effective words/s\n",
      "2023-12-06 15:13:58,216 : INFO : EPOCH 18: training on 99524 raw words (65429 effective words) took 0.2s, 312566 effective words/s\n",
      "2023-12-06 15:13:58,440 : INFO : EPOCH 19: training on 99524 raw words (65571 effective words) took 0.2s, 298554 effective words/s\n",
      "2023-12-06 15:13:58,692 : INFO : EPOCH 20: training on 99524 raw words (65333 effective words) took 0.2s, 263623 effective words/s\n",
      "2023-12-06 15:13:58,956 : INFO : EPOCH 21: training on 99524 raw words (65579 effective words) took 0.3s, 253964 effective words/s\n",
      "2023-12-06 15:13:59,212 : INFO : EPOCH 22: training on 99524 raw words (65513 effective words) took 0.3s, 259933 effective words/s\n",
      "2023-12-06 15:13:59,473 : INFO : EPOCH 23: training on 99524 raw words (65533 effective words) took 0.3s, 256371 effective words/s\n",
      "2023-12-06 15:13:59,740 : INFO : EPOCH 24: training on 99524 raw words (65523 effective words) took 0.3s, 248927 effective words/s\n",
      "2023-12-06 15:14:00,028 : INFO : EPOCH 25: training on 99524 raw words (65401 effective words) took 0.3s, 230954 effective words/s\n",
      "2023-12-06 15:14:00,294 : INFO : EPOCH 26: training on 99524 raw words (65709 effective words) took 0.3s, 252208 effective words/s\n",
      "2023-12-06 15:14:00,554 : INFO : EPOCH 27: training on 99524 raw words (65410 effective words) took 0.3s, 255297 effective words/s\n",
      "2023-12-06 15:14:00,809 : INFO : EPOCH 28: training on 99524 raw words (65510 effective words) took 0.3s, 261358 effective words/s\n",
      "2023-12-06 15:14:01,066 : INFO : EPOCH 29: training on 99524 raw words (65638 effective words) took 0.3s, 260423 effective words/s\n",
      "2023-12-06 15:14:01,067 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1966794 effective words) took 7.7s, 254885 effective words/s', 'datetime': '2023-12-06T15:14:01.067162', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:14:01,068 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:14:01.068244', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 79%|  | 382/486 [1:00:23<17:06,  9.87s/it]2023-12-06 15:14:04,671 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:14:04,671 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:14:04,694 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:14:04,694 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:14:04,701 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:14:04.701953', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:14:04,701 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:14:04.701953', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:14:04,712 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:14:04,713 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:14:04,713 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:14:04.713954', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:14:04,730 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:14:04,731 : INFO : resetting layer weights\n",
      "2023-12-06 15:14:04,737 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:14:04.737960', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:14:05,016 : INFO : EPOCH 0: training on 99524 raw words (65578 effective words) took 0.3s, 240446 effective words/s\n",
      "2023-12-06 15:14:05,324 : INFO : EPOCH 1: training on 99524 raw words (65516 effective words) took 0.3s, 218124 effective words/s\n",
      "2023-12-06 15:14:05,602 : INFO : EPOCH 2: training on 99524 raw words (65488 effective words) took 0.3s, 239786 effective words/s\n",
      "2023-12-06 15:14:05,874 : INFO : EPOCH 3: training on 99524 raw words (65542 effective words) took 0.3s, 245793 effective words/s\n",
      "2023-12-06 15:14:06,145 : INFO : EPOCH 4: training on 99524 raw words (65416 effective words) took 0.3s, 246270 effective words/s\n",
      "2023-12-06 15:14:06,410 : INFO : EPOCH 5: training on 99524 raw words (65611 effective words) took 0.3s, 251807 effective words/s\n",
      "2023-12-06 15:14:06,715 : INFO : EPOCH 6: training on 99524 raw words (65417 effective words) took 0.3s, 218569 effective words/s\n",
      "2023-12-06 15:14:06,997 : INFO : EPOCH 7: training on 99524 raw words (65514 effective words) took 0.3s, 235885 effective words/s\n",
      "2023-12-06 15:14:07,271 : INFO : EPOCH 8: training on 99524 raw words (65513 effective words) took 0.3s, 243023 effective words/s\n",
      "2023-12-06 15:14:07,539 : INFO : EPOCH 9: training on 99524 raw words (65583 effective words) took 0.3s, 249281 effective words/s\n",
      "2023-12-06 15:14:07,806 : INFO : EPOCH 10: training on 99524 raw words (65583 effective words) took 0.3s, 249645 effective words/s\n",
      "2023-12-06 15:14:08,075 : INFO : EPOCH 11: training on 99524 raw words (65441 effective words) took 0.3s, 247697 effective words/s\n",
      "2023-12-06 15:14:08,357 : INFO : EPOCH 12: training on 99524 raw words (65547 effective words) took 0.3s, 236881 effective words/s\n",
      "2023-12-06 15:14:08,625 : INFO : EPOCH 13: training on 99524 raw words (65618 effective words) took 0.3s, 249547 effective words/s\n",
      "2023-12-06 15:14:08,902 : INFO : EPOCH 14: training on 99524 raw words (65402 effective words) took 0.3s, 240098 effective words/s\n",
      "2023-12-06 15:14:09,173 : INFO : EPOCH 15: training on 99524 raw words (65606 effective words) took 0.3s, 246769 effective words/s\n",
      "2023-12-06 15:14:09,443 : INFO : EPOCH 16: training on 99524 raw words (65602 effective words) took 0.3s, 246819 effective words/s\n",
      "2023-12-06 15:14:09,715 : INFO : EPOCH 17: training on 99524 raw words (65584 effective words) took 0.3s, 244586 effective words/s\n",
      "2023-12-06 15:14:10,005 : INFO : EPOCH 18: training on 99524 raw words (65485 effective words) took 0.3s, 229725 effective words/s\n",
      "2023-12-06 15:14:10,280 : INFO : EPOCH 19: training on 99524 raw words (65585 effective words) took 0.3s, 242552 effective words/s\n",
      "2023-12-06 15:14:10,555 : INFO : EPOCH 20: training on 99524 raw words (65552 effective words) took 0.3s, 241755 effective words/s\n",
      "2023-12-06 15:14:10,826 : INFO : EPOCH 21: training on 99524 raw words (65571 effective words) took 0.3s, 246642 effective words/s\n",
      "2023-12-06 15:14:11,101 : INFO : EPOCH 22: training on 99524 raw words (65563 effective words) took 0.3s, 242851 effective words/s\n",
      "2023-12-06 15:14:11,395 : INFO : EPOCH 23: training on 99524 raw words (65480 effective words) took 0.3s, 225886 effective words/s\n",
      "2023-12-06 15:14:11,666 : INFO : EPOCH 24: training on 99524 raw words (65615 effective words) took 0.3s, 245775 effective words/s\n",
      "2023-12-06 15:14:11,948 : INFO : EPOCH 25: training on 99524 raw words (65555 effective words) took 0.3s, 237013 effective words/s\n",
      "2023-12-06 15:14:12,215 : INFO : EPOCH 26: training on 99524 raw words (65442 effective words) took 0.3s, 249460 effective words/s\n",
      "2023-12-06 15:14:12,485 : INFO : EPOCH 27: training on 99524 raw words (65505 effective words) took 0.3s, 246861 effective words/s\n",
      "2023-12-06 15:14:12,745 : INFO : EPOCH 28: training on 99524 raw words (65505 effective words) took 0.3s, 255693 effective words/s\n",
      "2023-12-06 15:14:13,033 : INFO : EPOCH 29: training on 99524 raw words (65476 effective words) took 0.3s, 230640 effective words/s\n",
      "2023-12-06 15:14:13,034 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965895 effective words) took 8.3s, 236967 effective words/s', 'datetime': '2023-12-06T15:14:13.034977', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:14:13,035 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:14:13.035978', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 79%|  | 383/486 [1:00:35<18:06, 10.55s/it]2023-12-06 15:14:16,796 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:14:16,797 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:14:16,819 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:14:16,820 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:14:16,828 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:14:16.828479', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:14:16,829 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:14:16.829480', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:14:16,839 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:14:16,840 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:14:16,840 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:14:16.840524', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:14:16,852 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:14:16,852 : INFO : resetting layer weights\n",
      "2023-12-06 15:14:16,857 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:14:16.857441', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:14:17,151 : INFO : EPOCH 0: training on 99524 raw words (65494 effective words) took 0.3s, 225501 effective words/s\n",
      "2023-12-06 15:14:17,440 : INFO : EPOCH 1: training on 99524 raw words (65600 effective words) took 0.3s, 231603 effective words/s\n",
      "2023-12-06 15:14:17,722 : INFO : EPOCH 2: training on 99524 raw words (65334 effective words) took 0.3s, 236506 effective words/s\n",
      "2023-12-06 15:14:17,998 : INFO : EPOCH 3: training on 99524 raw words (65481 effective words) took 0.3s, 240818 effective words/s\n",
      "2023-12-06 15:14:18,269 : INFO : EPOCH 4: training on 99524 raw words (65550 effective words) took 0.3s, 246082 effective words/s\n",
      "2023-12-06 15:14:18,552 : INFO : EPOCH 5: training on 99524 raw words (65525 effective words) took 0.3s, 235173 effective words/s\n",
      "2023-12-06 15:14:18,839 : INFO : EPOCH 6: training on 99524 raw words (65547 effective words) took 0.3s, 232443 effective words/s\n",
      "2023-12-06 15:14:19,109 : INFO : EPOCH 7: training on 99524 raw words (65399 effective words) took 0.3s, 246121 effective words/s\n",
      "2023-12-06 15:14:19,387 : INFO : EPOCH 8: training on 99524 raw words (65389 effective words) took 0.3s, 240227 effective words/s\n",
      "2023-12-06 15:14:19,665 : INFO : EPOCH 9: training on 99524 raw words (65582 effective words) took 0.3s, 238926 effective words/s\n",
      "2023-12-06 15:14:19,948 : INFO : EPOCH 10: training on 99524 raw words (65458 effective words) took 0.3s, 235671 effective words/s\n",
      "2023-12-06 15:14:20,234 : INFO : EPOCH 11: training on 99524 raw words (65478 effective words) took 0.3s, 232515 effective words/s\n",
      "2023-12-06 15:14:20,514 : INFO : EPOCH 12: training on 99524 raw words (65697 effective words) took 0.3s, 240854 effective words/s\n",
      "2023-12-06 15:14:20,791 : INFO : EPOCH 13: training on 99524 raw words (65480 effective words) took 0.3s, 239988 effective words/s\n",
      "2023-12-06 15:14:21,065 : INFO : EPOCH 14: training on 99524 raw words (65615 effective words) took 0.3s, 243264 effective words/s\n",
      "2023-12-06 15:14:21,341 : INFO : EPOCH 15: training on 99524 raw words (65512 effective words) took 0.3s, 242771 effective words/s\n",
      "2023-12-06 15:14:21,620 : INFO : EPOCH 16: training on 99524 raw words (65474 effective words) took 0.3s, 237873 effective words/s\n",
      "2023-12-06 15:14:21,907 : INFO : EPOCH 17: training on 99524 raw words (65544 effective words) took 0.3s, 232050 effective words/s\n",
      "2023-12-06 15:14:22,189 : INFO : EPOCH 18: training on 99524 raw words (65650 effective words) took 0.3s, 238237 effective words/s\n",
      "2023-12-06 15:14:22,471 : INFO : EPOCH 19: training on 99524 raw words (65406 effective words) took 0.3s, 235390 effective words/s\n",
      "2023-12-06 15:14:22,744 : INFO : EPOCH 20: training on 99524 raw words (65336 effective words) took 0.3s, 242791 effective words/s\n",
      "2023-12-06 15:14:23,021 : INFO : EPOCH 21: training on 99524 raw words (65490 effective words) took 0.3s, 240664 effective words/s\n",
      "2023-12-06 15:14:23,305 : INFO : EPOCH 22: training on 99524 raw words (65526 effective words) took 0.3s, 235212 effective words/s\n",
      "2023-12-06 15:14:23,591 : INFO : EPOCH 23: training on 99524 raw words (65602 effective words) took 0.3s, 232968 effective words/s\n",
      "2023-12-06 15:14:23,872 : INFO : EPOCH 24: training on 99524 raw words (65463 effective words) took 0.3s, 236271 effective words/s\n",
      "2023-12-06 15:14:24,147 : INFO : EPOCH 25: training on 99524 raw words (65604 effective words) took 0.3s, 242919 effective words/s\n",
      "2023-12-06 15:14:24,419 : INFO : EPOCH 26: training on 99524 raw words (65457 effective words) took 0.3s, 245633 effective words/s\n",
      "2023-12-06 15:14:24,707 : INFO : EPOCH 27: training on 99524 raw words (65564 effective words) took 0.3s, 235923 effective words/s\n",
      "2023-12-06 15:14:25,003 : INFO : EPOCH 28: training on 99524 raw words (65572 effective words) took 0.3s, 225837 effective words/s\n",
      "2023-12-06 15:14:25,282 : INFO : EPOCH 29: training on 99524 raw words (65600 effective words) took 0.3s, 238949 effective words/s\n",
      "2023-12-06 15:14:25,283 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965429 effective words) took 8.4s, 233269 effective words/s', 'datetime': '2023-12-06T15:14:25.283073', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:14:25,284 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:14:25.284209', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 79%|  | 384/486 [1:00:47<18:56, 11.15s/it]2023-12-06 15:14:29,337 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:14:29,337 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:14:29,358 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:14:29,359 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:14:29,364 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:14:29.364267', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:14:29,365 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:14:29.365266', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:14:29,376 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:14:29,377 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:14:29,377 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:14:29.377262', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:14:29,388 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:14:29,389 : INFO : resetting layer weights\n",
      "2023-12-06 15:14:29,393 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:14:29.393772', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:14:29,641 : INFO : EPOCH 0: training on 99524 raw words (65542 effective words) took 0.2s, 268621 effective words/s\n",
      "2023-12-06 15:14:29,933 : INFO : EPOCH 1: training on 99524 raw words (65545 effective words) took 0.3s, 239652 effective words/s\n",
      "2023-12-06 15:14:30,192 : INFO : EPOCH 2: training on 99524 raw words (65738 effective words) took 0.3s, 258512 effective words/s\n",
      "2023-12-06 15:14:30,455 : INFO : EPOCH 3: training on 99524 raw words (65536 effective words) took 0.3s, 254805 effective words/s\n",
      "2023-12-06 15:14:30,710 : INFO : EPOCH 4: training on 99524 raw words (65408 effective words) took 0.3s, 260925 effective words/s\n",
      "2023-12-06 15:14:30,963 : INFO : EPOCH 5: training on 99524 raw words (65582 effective words) took 0.2s, 263433 effective words/s\n",
      "2023-12-06 15:14:31,227 : INFO : EPOCH 6: training on 99524 raw words (65577 effective words) took 0.3s, 251949 effective words/s\n",
      "2023-12-06 15:14:31,483 : INFO : EPOCH 7: training on 99524 raw words (65519 effective words) took 0.3s, 261306 effective words/s\n",
      "2023-12-06 15:14:31,741 : INFO : EPOCH 8: training on 99524 raw words (65601 effective words) took 0.3s, 258619 effective words/s\n",
      "2023-12-06 15:14:32,004 : INFO : EPOCH 9: training on 99524 raw words (65585 effective words) took 0.3s, 253216 effective words/s\n",
      "2023-12-06 15:14:32,259 : INFO : EPOCH 10: training on 99524 raw words (65547 effective words) took 0.3s, 262183 effective words/s\n",
      "2023-12-06 15:14:32,524 : INFO : EPOCH 11: training on 99524 raw words (65592 effective words) took 0.3s, 252656 effective words/s\n",
      "2023-12-06 15:14:32,804 : INFO : EPOCH 12: training on 99524 raw words (65531 effective words) took 0.3s, 243876 effective words/s\n",
      "2023-12-06 15:14:33,064 : INFO : EPOCH 13: training on 99524 raw words (65696 effective words) took 0.3s, 257393 effective words/s\n",
      "2023-12-06 15:14:33,330 : INFO : EPOCH 14: training on 99524 raw words (65416 effective words) took 0.3s, 250386 effective words/s\n",
      "2023-12-06 15:14:33,588 : INFO : EPOCH 15: training on 99524 raw words (65242 effective words) took 0.3s, 257147 effective words/s\n",
      "2023-12-06 15:14:33,846 : INFO : EPOCH 16: training on 99524 raw words (65478 effective words) took 0.3s, 258785 effective words/s\n",
      "2023-12-06 15:14:34,110 : INFO : EPOCH 17: training on 99524 raw words (65645 effective words) took 0.3s, 253285 effective words/s\n",
      "2023-12-06 15:14:34,386 : INFO : EPOCH 18: training on 99524 raw words (65596 effective words) took 0.3s, 241165 effective words/s\n",
      "2023-12-06 15:14:34,638 : INFO : EPOCH 19: training on 99524 raw words (65510 effective words) took 0.2s, 264959 effective words/s\n",
      "2023-12-06 15:14:34,897 : INFO : EPOCH 20: training on 99524 raw words (65450 effective words) took 0.3s, 257618 effective words/s\n",
      "2023-12-06 15:14:35,163 : INFO : EPOCH 21: training on 99524 raw words (65584 effective words) took 0.3s, 250102 effective words/s\n",
      "2023-12-06 15:14:35,431 : INFO : EPOCH 22: training on 99524 raw words (65493 effective words) took 0.3s, 248249 effective words/s\n",
      "2023-12-06 15:14:35,699 : INFO : EPOCH 23: training on 99524 raw words (65615 effective words) took 0.3s, 248908 effective words/s\n",
      "2023-12-06 15:14:35,957 : INFO : EPOCH 24: training on 99524 raw words (65444 effective words) took 0.3s, 258334 effective words/s\n",
      "2023-12-06 15:14:36,211 : INFO : EPOCH 25: training on 99524 raw words (65598 effective words) took 0.2s, 262615 effective words/s\n",
      "2023-12-06 15:14:36,473 : INFO : EPOCH 26: training on 99524 raw words (65376 effective words) took 0.3s, 254317 effective words/s\n",
      "2023-12-06 15:14:36,728 : INFO : EPOCH 27: training on 99524 raw words (65593 effective words) took 0.3s, 261694 effective words/s\n",
      "2023-12-06 15:14:36,990 : INFO : EPOCH 28: training on 99524 raw words (65552 effective words) took 0.3s, 254440 effective words/s\n",
      "2023-12-06 15:14:37,259 : INFO : EPOCH 29: training on 99524 raw words (65654 effective words) took 0.3s, 248631 effective words/s\n",
      "2023-12-06 15:14:37,524 : INFO : EPOCH 30: training on 99524 raw words (65485 effective words) took 0.3s, 252448 effective words/s\n",
      "2023-12-06 15:14:37,781 : INFO : EPOCH 31: training on 99524 raw words (65678 effective words) took 0.3s, 259305 effective words/s\n",
      "2023-12-06 15:14:38,039 : INFO : EPOCH 32: training on 99524 raw words (65588 effective words) took 0.3s, 259001 effective words/s\n",
      "2023-12-06 15:14:38,298 : INFO : EPOCH 33: training on 99524 raw words (65579 effective words) took 0.3s, 258446 effective words/s\n",
      "2023-12-06 15:14:38,561 : INFO : EPOCH 34: training on 99524 raw words (65531 effective words) took 0.3s, 252875 effective words/s\n",
      "2023-12-06 15:14:38,831 : INFO : EPOCH 35: training on 99524 raw words (65396 effective words) took 0.3s, 248017 effective words/s\n",
      "2023-12-06 15:14:39,086 : INFO : EPOCH 36: training on 99524 raw words (65688 effective words) took 0.3s, 262469 effective words/s\n",
      "2023-12-06 15:14:39,340 : INFO : EPOCH 37: training on 99524 raw words (65681 effective words) took 0.2s, 263857 effective words/s\n",
      "2023-12-06 15:14:39,597 : INFO : EPOCH 38: training on 99524 raw words (65502 effective words) took 0.3s, 259667 effective words/s\n",
      "2023-12-06 15:14:39,868 : INFO : EPOCH 39: training on 99524 raw words (65713 effective words) took 0.3s, 246692 effective words/s\n",
      "2023-12-06 15:14:40,123 : INFO : EPOCH 40: training on 99524 raw words (65571 effective words) took 0.3s, 261432 effective words/s\n",
      "2023-12-06 15:14:40,380 : INFO : EPOCH 41: training on 99524 raw words (65320 effective words) took 0.3s, 258954 effective words/s\n",
      "2023-12-06 15:14:40,634 : INFO : EPOCH 42: training on 99524 raw words (65563 effective words) took 0.2s, 263686 effective words/s\n",
      "2023-12-06 15:14:40,889 : INFO : EPOCH 43: training on 99524 raw words (65596 effective words) took 0.3s, 261441 effective words/s\n",
      "2023-12-06 15:14:41,159 : INFO : EPOCH 44: training on 99524 raw words (65465 effective words) took 0.3s, 247176 effective words/s\n",
      "2023-12-06 15:14:41,420 : INFO : EPOCH 45: training on 99524 raw words (65439 effective words) took 0.3s, 255265 effective words/s\n",
      "2023-12-06 15:14:41,680 : INFO : EPOCH 46: training on 99524 raw words (65568 effective words) took 0.3s, 256215 effective words/s\n",
      "2023-12-06 15:14:41,943 : INFO : EPOCH 47: training on 99524 raw words (65494 effective words) took 0.3s, 253910 effective words/s\n",
      "2023-12-06 15:14:42,208 : INFO : EPOCH 48: training on 99524 raw words (65525 effective words) took 0.3s, 252003 effective words/s\n",
      "2023-12-06 15:14:42,467 : INFO : EPOCH 49: training on 99524 raw words (65590 effective words) took 0.3s, 257074 effective words/s\n",
      "2023-12-06 15:14:42,468 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3277217 effective words) took 13.1s, 250658 effective words/s', 'datetime': '2023-12-06T15:14:42.468321', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:14:42,469 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:14:42.469324', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 79%|  | 385/486 [1:01:05<21:54, 13.01s/it]2023-12-06 15:14:46,696 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:14:46,697 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:14:46,717 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:14:46,718 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:14:46,726 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:14:46.726227', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:14:46,727 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:14:46.727227', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:14:46,737 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:14:46,738 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:14:46,738 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:14:46.738069', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:14:46,748 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:14:46,750 : INFO : resetting layer weights\n",
      "2023-12-06 15:14:46,755 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:14:46.755466', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:14:47,063 : INFO : EPOCH 0: training on 99524 raw words (65657 effective words) took 0.3s, 216476 effective words/s\n",
      "2023-12-06 15:14:47,345 : INFO : EPOCH 1: training on 99524 raw words (65648 effective words) took 0.3s, 242308 effective words/s\n",
      "2023-12-06 15:14:47,621 : INFO : EPOCH 2: training on 99524 raw words (65507 effective words) took 0.3s, 240621 effective words/s\n",
      "2023-12-06 15:14:47,897 : INFO : EPOCH 3: training on 99524 raw words (65597 effective words) took 0.3s, 242254 effective words/s\n",
      "2023-12-06 15:14:48,166 : INFO : EPOCH 4: training on 99524 raw words (65810 effective words) took 0.3s, 248043 effective words/s\n",
      "2023-12-06 15:14:48,441 : INFO : EPOCH 5: training on 99524 raw words (65581 effective words) took 0.3s, 242768 effective words/s\n",
      "2023-12-06 15:14:48,725 : INFO : EPOCH 6: training on 99524 raw words (65379 effective words) took 0.3s, 234228 effective words/s\n",
      "2023-12-06 15:14:48,992 : INFO : EPOCH 7: training on 99524 raw words (65522 effective words) took 0.3s, 250059 effective words/s\n",
      "2023-12-06 15:14:49,265 : INFO : EPOCH 8: training on 99524 raw words (65394 effective words) took 0.3s, 244245 effective words/s\n",
      "2023-12-06 15:14:49,530 : INFO : EPOCH 9: training on 99524 raw words (65489 effective words) took 0.3s, 250928 effective words/s\n",
      "2023-12-06 15:14:49,798 : INFO : EPOCH 10: training on 99524 raw words (65555 effective words) took 0.3s, 249007 effective words/s\n",
      "2023-12-06 15:14:50,082 : INFO : EPOCH 11: training on 99524 raw words (65441 effective words) took 0.3s, 235058 effective words/s\n",
      "2023-12-06 15:14:50,348 : INFO : EPOCH 12: training on 99524 raw words (65430 effective words) took 0.3s, 250410 effective words/s\n",
      "2023-12-06 15:14:50,628 : INFO : EPOCH 13: training on 99524 raw words (65586 effective words) took 0.3s, 238402 effective words/s\n",
      "2023-12-06 15:14:50,906 : INFO : EPOCH 14: training on 99524 raw words (65544 effective words) took 0.3s, 239532 effective words/s\n",
      "2023-12-06 15:14:51,178 : INFO : EPOCH 15: training on 99524 raw words (65601 effective words) took 0.3s, 245612 effective words/s\n",
      "2023-12-06 15:14:51,452 : INFO : EPOCH 16: training on 99524 raw words (65473 effective words) took 0.3s, 242367 effective words/s\n",
      "2023-12-06 15:14:51,730 : INFO : EPOCH 17: training on 99524 raw words (65495 effective words) took 0.3s, 244731 effective words/s\n",
      "2023-12-06 15:14:51,996 : INFO : EPOCH 18: training on 99524 raw words (65437 effective words) took 0.3s, 249907 effective words/s\n",
      "2023-12-06 15:14:52,269 : INFO : EPOCH 19: training on 99524 raw words (65470 effective words) took 0.3s, 243529 effective words/s\n",
      "2023-12-06 15:14:52,546 : INFO : EPOCH 20: training on 99524 raw words (65541 effective words) took 0.3s, 241445 effective words/s\n",
      "2023-12-06 15:14:52,817 : INFO : EPOCH 21: training on 99524 raw words (65523 effective words) took 0.3s, 245488 effective words/s\n",
      "2023-12-06 15:14:53,089 : INFO : EPOCH 22: training on 99524 raw words (65485 effective words) took 0.3s, 245642 effective words/s\n",
      "2023-12-06 15:14:53,368 : INFO : EPOCH 23: training on 99524 raw words (65585 effective words) took 0.3s, 238856 effective words/s\n",
      "2023-12-06 15:14:53,635 : INFO : EPOCH 24: training on 99524 raw words (65599 effective words) took 0.3s, 249643 effective words/s\n",
      "2023-12-06 15:14:53,914 : INFO : EPOCH 25: training on 99524 raw words (65555 effective words) took 0.3s, 238523 effective words/s\n",
      "2023-12-06 15:14:54,190 : INFO : EPOCH 26: training on 99524 raw words (65306 effective words) took 0.3s, 241038 effective words/s\n",
      "2023-12-06 15:14:54,466 : INFO : EPOCH 27: training on 99524 raw words (65551 effective words) took 0.3s, 241774 effective words/s\n",
      "2023-12-06 15:14:54,737 : INFO : EPOCH 28: training on 99524 raw words (65514 effective words) took 0.3s, 245523 effective words/s\n",
      "2023-12-06 15:14:55,022 : INFO : EPOCH 29: training on 99524 raw words (65509 effective words) took 0.3s, 234363 effective words/s\n",
      "2023-12-06 15:14:55,294 : INFO : EPOCH 30: training on 99524 raw words (65491 effective words) took 0.3s, 244052 effective words/s\n",
      "2023-12-06 15:14:55,574 : INFO : EPOCH 31: training on 99524 raw words (65583 effective words) took 0.3s, 238782 effective words/s\n",
      "2023-12-06 15:14:55,845 : INFO : EPOCH 32: training on 99524 raw words (65538 effective words) took 0.3s, 245143 effective words/s\n",
      "2023-12-06 15:14:56,118 : INFO : EPOCH 33: training on 99524 raw words (65756 effective words) took 0.3s, 246288 effective words/s\n",
      "2023-12-06 15:14:56,390 : INFO : EPOCH 34: training on 99524 raw words (65466 effective words) took 0.3s, 244353 effective words/s\n",
      "2023-12-06 15:14:56,662 : INFO : EPOCH 35: training on 99524 raw words (65609 effective words) took 0.3s, 244975 effective words/s\n",
      "2023-12-06 15:14:56,937 : INFO : EPOCH 36: training on 99524 raw words (65497 effective words) took 0.3s, 243182 effective words/s\n",
      "2023-12-06 15:14:57,212 : INFO : EPOCH 37: training on 99524 raw words (65466 effective words) took 0.3s, 242304 effective words/s\n",
      "2023-12-06 15:14:57,485 : INFO : EPOCH 38: training on 99524 raw words (65318 effective words) took 0.3s, 243037 effective words/s\n",
      "2023-12-06 15:14:57,760 : INFO : EPOCH 39: training on 99524 raw words (65520 effective words) took 0.3s, 242602 effective words/s\n",
      "2023-12-06 15:14:58,033 : INFO : EPOCH 40: training on 99524 raw words (65540 effective words) took 0.3s, 244105 effective words/s\n",
      "2023-12-06 15:14:58,312 : INFO : EPOCH 41: training on 99524 raw words (65333 effective words) took 0.3s, 237616 effective words/s\n",
      "2023-12-06 15:14:58,587 : INFO : EPOCH 42: training on 99524 raw words (65519 effective words) took 0.3s, 242704 effective words/s\n",
      "2023-12-06 15:14:58,861 : INFO : EPOCH 43: training on 99524 raw words (65492 effective words) took 0.3s, 243619 effective words/s\n",
      "2023-12-06 15:14:59,131 : INFO : EPOCH 44: training on 99524 raw words (65622 effective words) took 0.3s, 246725 effective words/s\n",
      "2023-12-06 15:14:59,410 : INFO : EPOCH 45: training on 99524 raw words (65625 effective words) took 0.3s, 239306 effective words/s\n",
      "2023-12-06 15:14:59,695 : INFO : EPOCH 46: training on 99524 raw words (65675 effective words) took 0.3s, 234493 effective words/s\n",
      "2023-12-06 15:14:59,963 : INFO : EPOCH 47: training on 99524 raw words (65348 effective words) took 0.3s, 248263 effective words/s\n",
      "2023-12-06 15:15:00,241 : INFO : EPOCH 48: training on 99524 raw words (65587 effective words) took 0.3s, 240549 effective words/s\n",
      "2023-12-06 15:15:00,514 : INFO : EPOCH 49: training on 99524 raw words (65492 effective words) took 0.3s, 242014 effective words/s\n",
      "2023-12-06 15:15:00,516 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276261 effective words) took 13.8s, 238107 effective words/s', 'datetime': '2023-12-06T15:15:00.516577', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:15:00,517 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:15:00.517081', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 79%|  | 386/486 [1:01:23<24:22, 14.62s/it]2023-12-06 15:15:05,073 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:15:05,073 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:15:05,097 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:15:05,098 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:15:05,103 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:15:05.103400', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:15:05,104 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:15:05.104399', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:15:05,114 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:15:05,115 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:15:05,115 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:15:05.115405', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:15:05,125 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:15:05,126 : INFO : resetting layer weights\n",
      "2023-12-06 15:15:05,130 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:15:05.130918', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:15:05,402 : INFO : EPOCH 0: training on 99524 raw words (65723 effective words) took 0.3s, 245642 effective words/s\n",
      "2023-12-06 15:15:05,720 : INFO : EPOCH 1: training on 99524 raw words (65455 effective words) took 0.3s, 224697 effective words/s\n",
      "2023-12-06 15:15:06,003 : INFO : EPOCH 2: training on 99524 raw words (65546 effective words) took 0.3s, 236212 effective words/s\n",
      "2023-12-06 15:15:06,272 : INFO : EPOCH 3: training on 99524 raw words (65575 effective words) took 0.3s, 247496 effective words/s\n",
      "2023-12-06 15:15:06,553 : INFO : EPOCH 4: training on 99524 raw words (65556 effective words) took 0.3s, 237213 effective words/s\n",
      "2023-12-06 15:15:06,840 : INFO : EPOCH 5: training on 99524 raw words (65527 effective words) took 0.3s, 232989 effective words/s\n",
      "2023-12-06 15:15:07,132 : INFO : EPOCH 6: training on 99524 raw words (65563 effective words) took 0.3s, 228462 effective words/s\n",
      "2023-12-06 15:15:07,411 : INFO : EPOCH 7: training on 99524 raw words (65478 effective words) took 0.3s, 238248 effective words/s\n",
      "2023-12-06 15:15:07,693 : INFO : EPOCH 8: training on 99524 raw words (65275 effective words) took 0.3s, 235121 effective words/s\n",
      "2023-12-06 15:15:07,975 : INFO : EPOCH 9: training on 99524 raw words (65508 effective words) took 0.3s, 236435 effective words/s\n",
      "2023-12-06 15:15:08,246 : INFO : EPOCH 10: training on 99524 raw words (65686 effective words) took 0.3s, 245773 effective words/s\n",
      "2023-12-06 15:15:08,524 : INFO : EPOCH 11: training on 99524 raw words (65420 effective words) took 0.3s, 239391 effective words/s\n",
      "2023-12-06 15:15:08,821 : INFO : EPOCH 12: training on 99524 raw words (65583 effective words) took 0.3s, 224231 effective words/s\n",
      "2023-12-06 15:15:09,101 : INFO : EPOCH 13: training on 99524 raw words (65519 effective words) took 0.3s, 238149 effective words/s\n",
      "2023-12-06 15:15:09,381 : INFO : EPOCH 14: training on 99524 raw words (65430 effective words) took 0.3s, 237418 effective words/s\n",
      "2023-12-06 15:15:09,668 : INFO : EPOCH 15: training on 99524 raw words (65696 effective words) took 0.3s, 232251 effective words/s\n",
      "2023-12-06 15:15:09,946 : INFO : EPOCH 16: training on 99524 raw words (65557 effective words) took 0.3s, 240886 effective words/s\n",
      "2023-12-06 15:15:10,231 : INFO : EPOCH 17: training on 99524 raw words (65426 effective words) took 0.3s, 233560 effective words/s\n",
      "2023-12-06 15:15:10,512 : INFO : EPOCH 18: training on 99524 raw words (65555 effective words) took 0.3s, 236232 effective words/s\n",
      "2023-12-06 15:15:10,797 : INFO : EPOCH 19: training on 99524 raw words (65459 effective words) took 0.3s, 233361 effective words/s\n",
      "2023-12-06 15:15:11,077 : INFO : EPOCH 20: training on 99524 raw words (65645 effective words) took 0.3s, 237198 effective words/s\n",
      "2023-12-06 15:15:11,351 : INFO : EPOCH 21: training on 99524 raw words (65422 effective words) took 0.3s, 243407 effective words/s\n",
      "2023-12-06 15:15:11,654 : INFO : EPOCH 22: training on 99524 raw words (65451 effective words) took 0.3s, 219724 effective words/s\n",
      "2023-12-06 15:15:11,936 : INFO : EPOCH 23: training on 99524 raw words (65499 effective words) took 0.3s, 236823 effective words/s\n",
      "2023-12-06 15:15:12,211 : INFO : EPOCH 24: training on 99524 raw words (65594 effective words) took 0.3s, 242778 effective words/s\n",
      "2023-12-06 15:15:12,493 : INFO : EPOCH 25: training on 99524 raw words (65496 effective words) took 0.3s, 235939 effective words/s\n",
      "2023-12-06 15:15:12,773 : INFO : EPOCH 26: training on 99524 raw words (65527 effective words) took 0.3s, 237556 effective words/s\n",
      "2023-12-06 15:15:13,050 : INFO : EPOCH 27: training on 99524 raw words (65570 effective words) took 0.3s, 241103 effective words/s\n",
      "2023-12-06 15:15:13,329 : INFO : EPOCH 28: training on 99524 raw words (65402 effective words) took 0.3s, 237385 effective words/s\n",
      "2023-12-06 15:15:13,613 : INFO : EPOCH 29: training on 99524 raw words (65539 effective words) took 0.3s, 235749 effective words/s\n",
      "2023-12-06 15:15:13,889 : INFO : EPOCH 30: training on 99524 raw words (65267 effective words) took 0.3s, 240838 effective words/s\n",
      "2023-12-06 15:15:14,170 : INFO : EPOCH 31: training on 99524 raw words (65456 effective words) took 0.3s, 236785 effective words/s\n",
      "2023-12-06 15:15:14,459 : INFO : EPOCH 32: training on 99524 raw words (65523 effective words) took 0.3s, 231176 effective words/s\n",
      "2023-12-06 15:15:14,735 : INFO : EPOCH 33: training on 99524 raw words (65317 effective words) took 0.3s, 239527 effective words/s\n",
      "2023-12-06 15:15:15,017 : INFO : EPOCH 34: training on 99524 raw words (65602 effective words) took 0.3s, 236344 effective words/s\n",
      "2023-12-06 15:15:15,294 : INFO : EPOCH 35: training on 99524 raw words (65586 effective words) took 0.3s, 241868 effective words/s\n",
      "2023-12-06 15:15:15,573 : INFO : EPOCH 36: training on 99524 raw words (65493 effective words) took 0.3s, 237745 effective words/s\n",
      "2023-12-06 15:15:15,852 : INFO : EPOCH 37: training on 99524 raw words (65592 effective words) took 0.3s, 239018 effective words/s\n",
      "2023-12-06 15:15:16,130 : INFO : EPOCH 38: training on 99524 raw words (65590 effective words) took 0.3s, 239242 effective words/s\n",
      "2023-12-06 15:15:16,412 : INFO : EPOCH 39: training on 99524 raw words (65501 effective words) took 0.3s, 236992 effective words/s\n",
      "2023-12-06 15:15:16,686 : INFO : EPOCH 40: training on 99524 raw words (65595 effective words) took 0.3s, 243313 effective words/s\n",
      "2023-12-06 15:15:16,970 : INFO : EPOCH 41: training on 99524 raw words (65570 effective words) took 0.3s, 235179 effective words/s\n",
      "2023-12-06 15:15:17,249 : INFO : EPOCH 42: training on 99524 raw words (65451 effective words) took 0.3s, 237526 effective words/s\n",
      "2023-12-06 15:15:17,525 : INFO : EPOCH 43: training on 99524 raw words (65518 effective words) took 0.3s, 242362 effective words/s\n",
      "2023-12-06 15:15:17,798 : INFO : EPOCH 44: training on 99524 raw words (65382 effective words) took 0.3s, 242190 effective words/s\n",
      "2023-12-06 15:15:18,096 : INFO : EPOCH 45: training on 99524 raw words (65476 effective words) took 0.3s, 224756 effective words/s\n",
      "2023-12-06 15:15:18,380 : INFO : EPOCH 46: training on 99524 raw words (65341 effective words) took 0.3s, 233995 effective words/s\n",
      "2023-12-06 15:15:18,655 : INFO : EPOCH 47: training on 99524 raw words (65656 effective words) took 0.3s, 241744 effective words/s\n",
      "2023-12-06 15:15:18,941 : INFO : EPOCH 48: training on 99524 raw words (65661 effective words) took 0.3s, 233726 effective words/s\n",
      "2023-12-06 15:15:19,220 : INFO : EPOCH 49: training on 99524 raw words (65622 effective words) took 0.3s, 239050 effective words/s\n",
      "2023-12-06 15:15:19,221 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3275881 effective words) took 14.1s, 232502 effective words/s', 'datetime': '2023-12-06T15:15:19.221111', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:15:19,222 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w10,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:15:19.222109', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 80%|  | 387/486 [1:01:42<26:21, 15.97s/it]2023-12-06 15:15:24,200 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:15:24,200 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:15:24,223 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:15:24,224 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:15:24,229 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:15:24.229071', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:15:24,230 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:15:24.229071', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:15:24,236 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:15:24,236 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:15:24,236 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:15:24.236410', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:15:24,249 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:15:24,250 : INFO : resetting layer weights\n",
      "2023-12-06 15:15:24,256 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:15:24.256202', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:15:24,536 : INFO : EPOCH 0: training on 99524 raw words (62860 effective words) took 0.3s, 227021 effective words/s\n",
      "2023-12-06 15:15:24,811 : INFO : EPOCH 1: training on 99524 raw words (62757 effective words) took 0.3s, 241884 effective words/s\n",
      "2023-12-06 15:15:25,066 : INFO : EPOCH 2: training on 99524 raw words (62793 effective words) took 0.3s, 250937 effective words/s\n",
      "2023-12-06 15:15:25,322 : INFO : EPOCH 3: training on 99524 raw words (62797 effective words) took 0.3s, 250003 effective words/s\n",
      "2023-12-06 15:15:25,581 : INFO : EPOCH 4: training on 99524 raw words (62640 effective words) took 0.3s, 246026 effective words/s\n",
      "2023-12-06 15:15:25,841 : INFO : EPOCH 5: training on 99524 raw words (62894 effective words) took 0.3s, 246130 effective words/s\n",
      "2023-12-06 15:15:26,094 : INFO : EPOCH 6: training on 99524 raw words (62617 effective words) took 0.2s, 251641 effective words/s\n",
      "2023-12-06 15:15:26,348 : INFO : EPOCH 7: training on 99524 raw words (62753 effective words) took 0.2s, 252254 effective words/s\n",
      "2023-12-06 15:15:26,606 : INFO : EPOCH 8: training on 99524 raw words (62709 effective words) took 0.3s, 248249 effective words/s\n",
      "2023-12-06 15:15:26,856 : INFO : EPOCH 9: training on 99524 raw words (62534 effective words) took 0.2s, 254899 effective words/s\n",
      "2023-12-06 15:15:26,857 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627354 effective words) took 2.6s, 241208 effective words/s', 'datetime': '2023-12-06T15:15:26.857629', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:15:26,858 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:15:26.858629', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 80%|  | 388/486 [1:01:48<21:01, 12.87s/it]2023-12-06 15:15:29,830 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:15:29,830 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:15:29,853 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:15:29,853 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:15:29,858 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:15:29.858885', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:15:29,858 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:15:29.858885', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:15:29,864 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:15:29,865 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:15:29,866 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:15:29.866429', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:15:29,879 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:15:29,879 : INFO : resetting layer weights\n",
      "2023-12-06 15:15:29,883 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:15:29.883997', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:15:30,138 : INFO : EPOCH 0: training on 99524 raw words (62750 effective words) took 0.3s, 250019 effective words/s\n",
      "2023-12-06 15:15:30,438 : INFO : EPOCH 1: training on 99524 raw words (62645 effective words) took 0.3s, 212511 effective words/s\n",
      "2023-12-06 15:15:30,706 : INFO : EPOCH 2: training on 99524 raw words (62827 effective words) took 0.3s, 238438 effective words/s\n",
      "2023-12-06 15:15:30,973 : INFO : EPOCH 3: training on 99524 raw words (62716 effective words) took 0.3s, 238537 effective words/s\n",
      "2023-12-06 15:15:31,246 : INFO : EPOCH 4: training on 99524 raw words (62828 effective words) took 0.3s, 235225 effective words/s\n",
      "2023-12-06 15:15:31,515 : INFO : EPOCH 5: training on 99524 raw words (62602 effective words) took 0.3s, 236686 effective words/s\n",
      "2023-12-06 15:15:31,782 : INFO : EPOCH 6: training on 99524 raw words (62727 effective words) took 0.3s, 237969 effective words/s\n",
      "2023-12-06 15:15:32,053 : INFO : EPOCH 7: training on 99524 raw words (62766 effective words) took 0.3s, 236938 effective words/s\n",
      "2023-12-06 15:15:32,317 : INFO : EPOCH 8: training on 99524 raw words (62677 effective words) took 0.3s, 241315 effective words/s\n",
      "2023-12-06 15:15:32,584 : INFO : EPOCH 9: training on 99524 raw words (62630 effective words) took 0.3s, 238295 effective words/s\n",
      "2023-12-06 15:15:32,585 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627168 effective words) took 2.7s, 232240 effective words/s', 'datetime': '2023-12-06T15:15:32.585468', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:15:32,585 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:15:32.585468', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 80%|  | 389/486 [1:01:54<17:22, 10.75s/it]2023-12-06 15:15:35,618 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:15:35,620 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:15:35,643 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:15:35,644 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:15:35,651 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:15:35.651835', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:15:35,652 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:15:35.652834', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:15:35,660 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:15:35,661 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:15:35,661 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:15:35.661793', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:15:35,674 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:15:35,674 : INFO : resetting layer weights\n",
      "2023-12-06 15:15:35,679 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:15:35.679285', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:15:35,980 : INFO : EPOCH 0: training on 99524 raw words (62926 effective words) took 0.3s, 211838 effective words/s\n",
      "2023-12-06 15:15:36,274 : INFO : EPOCH 1: training on 99524 raw words (62689 effective words) took 0.3s, 218513 effective words/s\n",
      "2023-12-06 15:15:36,554 : INFO : EPOCH 2: training on 99524 raw words (62659 effective words) took 0.3s, 227091 effective words/s\n",
      "2023-12-06 15:15:36,828 : INFO : EPOCH 3: training on 99524 raw words (62643 effective words) took 0.3s, 232621 effective words/s\n",
      "2023-12-06 15:15:37,102 : INFO : EPOCH 4: training on 99524 raw words (62571 effective words) took 0.3s, 232582 effective words/s\n",
      "2023-12-06 15:15:37,377 : INFO : EPOCH 5: training on 99524 raw words (62692 effective words) took 0.3s, 232470 effective words/s\n",
      "2023-12-06 15:15:37,653 : INFO : EPOCH 6: training on 99524 raw words (62550 effective words) took 0.3s, 229364 effective words/s\n",
      "2023-12-06 15:15:37,939 : INFO : EPOCH 7: training on 99524 raw words (62715 effective words) took 0.3s, 224278 effective words/s\n",
      "2023-12-06 15:15:38,216 : INFO : EPOCH 8: training on 99524 raw words (62745 effective words) took 0.3s, 230917 effective words/s\n",
      "2023-12-06 15:15:38,494 : INFO : EPOCH 9: training on 99524 raw words (62683 effective words) took 0.3s, 229313 effective words/s\n",
      "2023-12-06 15:15:38,495 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (626873 effective words) took 2.8s, 222635 effective words/s', 'datetime': '2023-12-06T15:15:38.495139', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:15:38,496 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:15:38.496197', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 80%|  | 390/486 [1:02:00<14:55,  9.32s/it]2023-12-06 15:15:41,625 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:15:41,626 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:15:41,652 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:15:41,653 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:15:41,658 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:15:41.658571', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:15:41,659 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:15:41.659578', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:15:41,664 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:15:41,665 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:15:41,665 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:15:41.665243', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:15:41,674 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:15:41,675 : INFO : resetting layer weights\n",
      "2023-12-06 15:15:41,678 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:15:41.678547', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:15:41,917 : INFO : EPOCH 0: training on 99524 raw words (62687 effective words) took 0.2s, 267359 effective words/s\n",
      "2023-12-06 15:15:42,224 : INFO : EPOCH 1: training on 99524 raw words (62665 effective words) took 0.3s, 231920 effective words/s\n",
      "2023-12-06 15:15:42,479 : INFO : EPOCH 2: training on 99524 raw words (62846 effective words) took 0.3s, 249628 effective words/s\n",
      "2023-12-06 15:15:42,731 : INFO : EPOCH 3: training on 99524 raw words (62803 effective words) took 0.2s, 254486 effective words/s\n",
      "2023-12-06 15:15:42,983 : INFO : EPOCH 4: training on 99524 raw words (62693 effective words) took 0.2s, 253514 effective words/s\n",
      "2023-12-06 15:15:43,241 : INFO : EPOCH 5: training on 99524 raw words (62768 effective words) took 0.3s, 247551 effective words/s\n",
      "2023-12-06 15:15:43,498 : INFO : EPOCH 6: training on 99524 raw words (62736 effective words) took 0.3s, 249306 effective words/s\n",
      "2023-12-06 15:15:43,753 : INFO : EPOCH 7: training on 99524 raw words (62758 effective words) took 0.3s, 250462 effective words/s\n",
      "2023-12-06 15:15:44,007 : INFO : EPOCH 8: training on 99524 raw words (62684 effective words) took 0.2s, 251958 effective words/s\n",
      "2023-12-06 15:15:44,259 : INFO : EPOCH 9: training on 99524 raw words (62754 effective words) took 0.2s, 251852 effective words/s\n",
      "2023-12-06 15:15:44,525 : INFO : EPOCH 10: training on 99524 raw words (62622 effective words) took 0.3s, 240232 effective words/s\n",
      "2023-12-06 15:15:44,784 : INFO : EPOCH 11: training on 99524 raw words (62883 effective words) took 0.3s, 246827 effective words/s\n",
      "2023-12-06 15:15:45,039 : INFO : EPOCH 12: training on 99524 raw words (62651 effective words) took 0.3s, 249590 effective words/s\n",
      "2023-12-06 15:15:45,294 : INFO : EPOCH 13: training on 99524 raw words (62814 effective words) took 0.3s, 250911 effective words/s\n",
      "2023-12-06 15:15:45,560 : INFO : EPOCH 14: training on 99524 raw words (62769 effective words) took 0.3s, 240281 effective words/s\n",
      "2023-12-06 15:15:45,825 : INFO : EPOCH 15: training on 99524 raw words (62850 effective words) took 0.3s, 241291 effective words/s\n",
      "2023-12-06 15:15:46,091 : INFO : EPOCH 16: training on 99524 raw words (62732 effective words) took 0.3s, 241595 effective words/s\n",
      "2023-12-06 15:15:46,348 : INFO : EPOCH 17: training on 99524 raw words (62923 effective words) took 0.3s, 248291 effective words/s\n",
      "2023-12-06 15:15:46,604 : INFO : EPOCH 18: training on 99524 raw words (62743 effective words) took 0.3s, 249576 effective words/s\n",
      "2023-12-06 15:15:46,860 : INFO : EPOCH 19: training on 99524 raw words (62734 effective words) took 0.3s, 249660 effective words/s\n",
      "2023-12-06 15:15:47,129 : INFO : EPOCH 20: training on 99524 raw words (62743 effective words) took 0.3s, 237938 effective words/s\n",
      "2023-12-06 15:15:47,382 : INFO : EPOCH 21: training on 99524 raw words (62835 effective words) took 0.2s, 252926 effective words/s\n",
      "2023-12-06 15:15:47,630 : INFO : EPOCH 22: training on 99524 raw words (62727 effective words) took 0.2s, 257548 effective words/s\n",
      "2023-12-06 15:15:47,885 : INFO : EPOCH 23: training on 99524 raw words (62802 effective words) took 0.3s, 250764 effective words/s\n",
      "2023-12-06 15:15:48,143 : INFO : EPOCH 24: training on 99524 raw words (62599 effective words) took 0.3s, 247229 effective words/s\n",
      "2023-12-06 15:15:48,402 : INFO : EPOCH 25: training on 99524 raw words (62710 effective words) took 0.3s, 245986 effective words/s\n",
      "2023-12-06 15:15:48,666 : INFO : EPOCH 26: training on 99524 raw words (62571 effective words) took 0.3s, 240709 effective words/s\n",
      "2023-12-06 15:15:48,925 : INFO : EPOCH 27: training on 99524 raw words (62671 effective words) took 0.3s, 247096 effective words/s\n",
      "2023-12-06 15:15:49,182 : INFO : EPOCH 28: training on 99524 raw words (62800 effective words) took 0.3s, 248145 effective words/s\n",
      "2023-12-06 15:15:49,438 : INFO : EPOCH 29: training on 99524 raw words (62683 effective words) took 0.3s, 250725 effective words/s\n",
      "2023-12-06 15:15:49,439 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1882256 effective words) took 7.8s, 242568 effective words/s', 'datetime': '2023-12-06T15:15:49.439252', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:15:49,439 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:15:49.439252', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 80%|  | 391/486 [1:02:11<15:44,  9.94s/it]2023-12-06 15:15:53,017 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:15:53,018 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:15:53,041 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:15:53,042 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:15:53,048 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:15:53.048501', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:15:53,049 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:15:53.049502', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:15:53,055 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:15:53,056 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:15:53,057 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:15:53.057010', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:15:53,066 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:15:53,067 : INFO : resetting layer weights\n",
      "2023-12-06 15:15:53,073 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:15:53.073342', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:15:53,320 : INFO : EPOCH 0: training on 99524 raw words (62587 effective words) took 0.2s, 257100 effective words/s\n",
      "2023-12-06 15:15:53,611 : INFO : EPOCH 1: training on 99524 raw words (62730 effective words) took 0.3s, 219755 effective words/s\n",
      "2023-12-06 15:15:53,883 : INFO : EPOCH 2: training on 99524 raw words (62882 effective words) took 0.3s, 234962 effective words/s\n",
      "2023-12-06 15:15:54,156 : INFO : EPOCH 3: training on 99524 raw words (62754 effective words) took 0.3s, 234253 effective words/s\n",
      "2023-12-06 15:15:54,422 : INFO : EPOCH 4: training on 99524 raw words (62644 effective words) took 0.3s, 239478 effective words/s\n",
      "2023-12-06 15:15:54,688 : INFO : EPOCH 5: training on 99524 raw words (62674 effective words) took 0.3s, 238968 effective words/s\n",
      "2023-12-06 15:15:54,958 : INFO : EPOCH 6: training on 99524 raw words (62739 effective words) took 0.3s, 236068 effective words/s\n",
      "2023-12-06 15:15:55,240 : INFO : EPOCH 7: training on 99524 raw words (62643 effective words) took 0.3s, 227508 effective words/s\n",
      "2023-12-06 15:15:55,507 : INFO : EPOCH 8: training on 99524 raw words (62865 effective words) took 0.3s, 239627 effective words/s\n",
      "2023-12-06 15:15:55,776 : INFO : EPOCH 9: training on 99524 raw words (62769 effective words) took 0.3s, 236613 effective words/s\n",
      "2023-12-06 15:15:56,045 : INFO : EPOCH 10: training on 99524 raw words (62799 effective words) took 0.3s, 238500 effective words/s\n",
      "2023-12-06 15:15:56,314 : INFO : EPOCH 11: training on 99524 raw words (62819 effective words) took 0.3s, 237777 effective words/s\n",
      "2023-12-06 15:15:56,587 : INFO : EPOCH 12: training on 99524 raw words (62634 effective words) took 0.3s, 232699 effective words/s\n",
      "2023-12-06 15:15:56,863 : INFO : EPOCH 13: training on 99524 raw words (62701 effective words) took 0.3s, 231724 effective words/s\n",
      "2023-12-06 15:15:57,138 : INFO : EPOCH 14: training on 99524 raw words (62841 effective words) took 0.3s, 233001 effective words/s\n",
      "2023-12-06 15:15:57,408 : INFO : EPOCH 15: training on 99524 raw words (62561 effective words) took 0.3s, 235361 effective words/s\n",
      "2023-12-06 15:15:57,679 : INFO : EPOCH 16: training on 99524 raw words (62631 effective words) took 0.3s, 234611 effective words/s\n",
      "2023-12-06 15:15:57,951 : INFO : EPOCH 17: training on 99524 raw words (62702 effective words) took 0.3s, 234429 effective words/s\n",
      "2023-12-06 15:15:58,231 : INFO : EPOCH 18: training on 99524 raw words (62642 effective words) took 0.3s, 228094 effective words/s\n",
      "2023-12-06 15:15:58,508 : INFO : EPOCH 19: training on 99524 raw words (62786 effective words) took 0.3s, 230701 effective words/s\n",
      "2023-12-06 15:15:58,783 : INFO : EPOCH 20: training on 99524 raw words (62816 effective words) took 0.3s, 233364 effective words/s\n",
      "2023-12-06 15:15:59,055 : INFO : EPOCH 21: training on 99524 raw words (62735 effective words) took 0.3s, 234055 effective words/s\n",
      "2023-12-06 15:15:59,329 : INFO : EPOCH 22: training on 99524 raw words (62648 effective words) took 0.3s, 233276 effective words/s\n",
      "2023-12-06 15:15:59,632 : INFO : EPOCH 23: training on 99524 raw words (62679 effective words) took 0.3s, 210210 effective words/s\n",
      "2023-12-06 15:15:59,907 : INFO : EPOCH 24: training on 99524 raw words (62668 effective words) took 0.3s, 232435 effective words/s\n",
      "2023-12-06 15:16:00,171 : INFO : EPOCH 25: training on 99524 raw words (62828 effective words) took 0.3s, 242266 effective words/s\n",
      "2023-12-06 15:16:00,447 : INFO : EPOCH 26: training on 99524 raw words (62762 effective words) took 0.3s, 231412 effective words/s\n",
      "2023-12-06 15:16:00,722 : INFO : EPOCH 27: training on 99524 raw words (62613 effective words) took 0.3s, 231430 effective words/s\n",
      "2023-12-06 15:16:01,001 : INFO : EPOCH 28: training on 99524 raw words (62705 effective words) took 0.3s, 228605 effective words/s\n",
      "2023-12-06 15:16:01,273 : INFO : EPOCH 29: training on 99524 raw words (62614 effective words) took 0.3s, 233920 effective words/s\n",
      "2023-12-06 15:16:01,274 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881471 effective words) took 8.2s, 229406 effective words/s', 'datetime': '2023-12-06T15:16:01.274686', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:16:01,275 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:16:01.275689', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 81%|  | 392/486 [1:02:23<16:32, 10.56s/it]2023-12-06 15:16:05,021 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:16:05,021 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:16:05,043 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:16:05,043 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:16:05,048 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:16:05.048955', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:16:05,048 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:16:05.048955', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:16:05,057 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:16:05,058 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:16:05,058 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:16:05.058481', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:16:05,070 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:16:05,071 : INFO : resetting layer weights\n",
      "2023-12-06 15:16:05,079 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:16:05.078892', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:16:05,363 : INFO : EPOCH 0: training on 99524 raw words (62677 effective words) took 0.3s, 223796 effective words/s\n",
      "2023-12-06 15:16:05,646 : INFO : EPOCH 1: training on 99524 raw words (62876 effective words) took 0.3s, 227506 effective words/s\n",
      "2023-12-06 15:16:05,922 : INFO : EPOCH 2: training on 99524 raw words (62698 effective words) took 0.3s, 231552 effective words/s\n",
      "2023-12-06 15:16:06,196 : INFO : EPOCH 3: training on 99524 raw words (62734 effective words) took 0.3s, 232372 effective words/s\n",
      "2023-12-06 15:16:06,473 : INFO : EPOCH 4: training on 99524 raw words (62712 effective words) took 0.3s, 230534 effective words/s\n",
      "2023-12-06 15:16:06,745 : INFO : EPOCH 5: training on 99524 raw words (62754 effective words) took 0.3s, 234191 effective words/s\n",
      "2023-12-06 15:16:07,044 : INFO : EPOCH 6: training on 99524 raw words (62495 effective words) took 0.3s, 212452 effective words/s\n",
      "2023-12-06 15:16:07,315 : INFO : EPOCH 7: training on 99524 raw words (62804 effective words) took 0.3s, 236713 effective words/s\n",
      "2023-12-06 15:16:07,586 : INFO : EPOCH 8: training on 99524 raw words (62703 effective words) took 0.3s, 234959 effective words/s\n",
      "2023-12-06 15:16:07,861 : INFO : EPOCH 9: training on 99524 raw words (62821 effective words) took 0.3s, 232397 effective words/s\n",
      "2023-12-06 15:16:08,138 : INFO : EPOCH 10: training on 99524 raw words (62547 effective words) took 0.3s, 229545 effective words/s\n",
      "2023-12-06 15:16:08,420 : INFO : EPOCH 11: training on 99524 raw words (62707 effective words) took 0.3s, 227101 effective words/s\n",
      "2023-12-06 15:16:08,693 : INFO : EPOCH 12: training on 99524 raw words (62672 effective words) took 0.3s, 233493 effective words/s\n",
      "2023-12-06 15:16:08,962 : INFO : EPOCH 13: training on 99524 raw words (62619 effective words) took 0.3s, 236264 effective words/s\n",
      "2023-12-06 15:16:09,240 : INFO : EPOCH 14: training on 99524 raw words (62610 effective words) took 0.3s, 229074 effective words/s\n",
      "2023-12-06 15:16:09,516 : INFO : EPOCH 15: training on 99524 raw words (62762 effective words) took 0.3s, 231626 effective words/s\n",
      "2023-12-06 15:16:09,792 : INFO : EPOCH 16: training on 99524 raw words (62758 effective words) took 0.3s, 232051 effective words/s\n",
      "2023-12-06 15:16:10,069 : INFO : EPOCH 17: training on 99524 raw words (62761 effective words) took 0.3s, 230260 effective words/s\n",
      "2023-12-06 15:16:10,347 : INFO : EPOCH 18: training on 99524 raw words (62650 effective words) took 0.3s, 229320 effective words/s\n",
      "2023-12-06 15:16:10,632 : INFO : EPOCH 19: training on 99524 raw words (62928 effective words) took 0.3s, 225360 effective words/s\n",
      "2023-12-06 15:16:10,901 : INFO : EPOCH 20: training on 99524 raw words (62580 effective words) took 0.3s, 236475 effective words/s\n",
      "2023-12-06 15:16:11,173 : INFO : EPOCH 21: training on 99524 raw words (62657 effective words) took 0.3s, 233860 effective words/s\n",
      "2023-12-06 15:16:11,449 : INFO : EPOCH 22: training on 99524 raw words (62943 effective words) took 0.3s, 232073 effective words/s\n",
      "2023-12-06 15:16:11,731 : INFO : EPOCH 23: training on 99524 raw words (62595 effective words) took 0.3s, 227076 effective words/s\n",
      "2023-12-06 15:16:12,004 : INFO : EPOCH 24: training on 99524 raw words (62788 effective words) took 0.3s, 233709 effective words/s\n",
      "2023-12-06 15:16:12,273 : INFO : EPOCH 25: training on 99524 raw words (62620 effective words) took 0.3s, 236756 effective words/s\n",
      "2023-12-06 15:16:12,555 : INFO : EPOCH 26: training on 99524 raw words (62754 effective words) took 0.3s, 226408 effective words/s\n",
      "2023-12-06 15:16:12,830 : INFO : EPOCH 27: training on 99524 raw words (62663 effective words) took 0.3s, 232131 effective words/s\n",
      "2023-12-06 15:16:13,106 : INFO : EPOCH 28: training on 99524 raw words (62572 effective words) took 0.3s, 230769 effective words/s\n",
      "2023-12-06 15:16:13,393 : INFO : EPOCH 29: training on 99524 raw words (62684 effective words) took 0.3s, 221870 effective words/s\n",
      "2023-12-06 15:16:13,394 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881144 effective words) took 8.3s, 226229 effective words/s', 'datetime': '2023-12-06T15:16:13.394889', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:16:13,395 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:16:13.395757', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 81%|  | 393/486 [1:02:35<17:10, 11.08s/it]2023-12-06 15:16:17,324 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:16:17,325 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:16:17,347 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:16:17,348 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:16:17,355 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:16:17.355309', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:16:17,355 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:16:17.355309', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:16:17,363 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:16:17,364 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:16:17,364 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:16:17.364366', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:16:17,374 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:16:17,374 : INFO : resetting layer weights\n",
      "2023-12-06 15:16:17,381 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:16:17.381563', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:16:17,636 : INFO : EPOCH 0: training on 99524 raw words (62677 effective words) took 0.3s, 249508 effective words/s\n",
      "2023-12-06 15:16:17,908 : INFO : EPOCH 1: training on 99524 raw words (62817 effective words) took 0.3s, 236813 effective words/s\n",
      "2023-12-06 15:16:18,159 : INFO : EPOCH 2: training on 99524 raw words (62644 effective words) took 0.2s, 254089 effective words/s\n",
      "2023-12-06 15:16:18,416 : INFO : EPOCH 3: training on 99524 raw words (62722 effective words) took 0.3s, 248327 effective words/s\n",
      "2023-12-06 15:16:18,669 : INFO : EPOCH 4: training on 99524 raw words (62733 effective words) took 0.2s, 253111 effective words/s\n",
      "2023-12-06 15:16:18,922 : INFO : EPOCH 5: training on 99524 raw words (62685 effective words) took 0.3s, 250630 effective words/s\n",
      "2023-12-06 15:16:19,202 : INFO : EPOCH 6: training on 99524 raw words (62862 effective words) took 0.3s, 228334 effective words/s\n",
      "2023-12-06 15:16:19,456 : INFO : EPOCH 7: training on 99524 raw words (62819 effective words) took 0.2s, 251569 effective words/s\n",
      "2023-12-06 15:16:19,707 : INFO : EPOCH 8: training on 99524 raw words (62874 effective words) took 0.2s, 255302 effective words/s\n",
      "2023-12-06 15:16:19,958 : INFO : EPOCH 9: training on 99524 raw words (62750 effective words) took 0.2s, 255890 effective words/s\n",
      "2023-12-06 15:16:20,211 : INFO : EPOCH 10: training on 99524 raw words (62670 effective words) took 0.2s, 251976 effective words/s\n",
      "2023-12-06 15:16:20,466 : INFO : EPOCH 11: training on 99524 raw words (62651 effective words) took 0.3s, 249460 effective words/s\n",
      "2023-12-06 15:16:20,733 : INFO : EPOCH 12: training on 99524 raw words (62701 effective words) took 0.3s, 239366 effective words/s\n",
      "2023-12-06 15:16:20,996 : INFO : EPOCH 13: training on 99524 raw words (62844 effective words) took 0.3s, 242757 effective words/s\n",
      "2023-12-06 15:16:21,251 : INFO : EPOCH 14: training on 99524 raw words (62728 effective words) took 0.3s, 250850 effective words/s\n",
      "2023-12-06 15:16:21,506 : INFO : EPOCH 15: training on 99524 raw words (62727 effective words) took 0.3s, 250667 effective words/s\n",
      "2023-12-06 15:16:21,756 : INFO : EPOCH 16: training on 99524 raw words (62725 effective words) took 0.2s, 255496 effective words/s\n",
      "2023-12-06 15:16:22,009 : INFO : EPOCH 17: training on 99524 raw words (62581 effective words) took 0.2s, 251928 effective words/s\n",
      "2023-12-06 15:16:22,267 : INFO : EPOCH 18: training on 99524 raw words (62875 effective words) took 0.3s, 248069 effective words/s\n",
      "2023-12-06 15:16:22,526 : INFO : EPOCH 19: training on 99524 raw words (62662 effective words) took 0.3s, 246879 effective words/s\n",
      "2023-12-06 15:16:22,776 : INFO : EPOCH 20: training on 99524 raw words (62841 effective words) took 0.2s, 256610 effective words/s\n",
      "2023-12-06 15:16:23,026 : INFO : EPOCH 21: training on 99524 raw words (62836 effective words) took 0.2s, 256055 effective words/s\n",
      "2023-12-06 15:16:23,275 : INFO : EPOCH 22: training on 99524 raw words (62868 effective words) took 0.2s, 258191 effective words/s\n",
      "2023-12-06 15:16:23,532 : INFO : EPOCH 23: training on 99524 raw words (62568 effective words) took 0.3s, 247542 effective words/s\n",
      "2023-12-06 15:16:23,788 : INFO : EPOCH 24: training on 99524 raw words (62802 effective words) took 0.3s, 249986 effective words/s\n",
      "2023-12-06 15:16:24,054 : INFO : EPOCH 25: training on 99524 raw words (62771 effective words) took 0.3s, 240133 effective words/s\n",
      "2023-12-06 15:16:24,313 : INFO : EPOCH 26: training on 99524 raw words (62867 effective words) took 0.3s, 246314 effective words/s\n",
      "2023-12-06 15:16:24,564 : INFO : EPOCH 27: training on 99524 raw words (62771 effective words) took 0.2s, 255703 effective words/s\n",
      "2023-12-06 15:16:24,820 : INFO : EPOCH 28: training on 99524 raw words (62754 effective words) took 0.3s, 249132 effective words/s\n",
      "2023-12-06 15:16:25,086 : INFO : EPOCH 29: training on 99524 raw words (62720 effective words) took 0.3s, 240411 effective words/s\n",
      "2023-12-06 15:16:25,338 : INFO : EPOCH 30: training on 99524 raw words (62763 effective words) took 0.2s, 252784 effective words/s\n",
      "2023-12-06 15:16:25,606 : INFO : EPOCH 31: training on 99524 raw words (62707 effective words) took 0.3s, 244622 effective words/s\n",
      "2023-12-06 15:16:25,857 : INFO : EPOCH 32: training on 99524 raw words (62610 effective words) took 0.2s, 253979 effective words/s\n",
      "2023-12-06 15:16:26,106 : INFO : EPOCH 33: training on 99524 raw words (62719 effective words) took 0.2s, 256485 effective words/s\n",
      "2023-12-06 15:16:26,363 : INFO : EPOCH 34: training on 99524 raw words (62666 effective words) took 0.3s, 248342 effective words/s\n",
      "2023-12-06 15:16:26,629 : INFO : EPOCH 35: training on 99524 raw words (62696 effective words) took 0.3s, 241177 effective words/s\n",
      "2023-12-06 15:16:26,886 : INFO : EPOCH 36: training on 99524 raw words (62796 effective words) took 0.3s, 248584 effective words/s\n",
      "2023-12-06 15:16:27,138 : INFO : EPOCH 37: training on 99524 raw words (62647 effective words) took 0.2s, 252929 effective words/s\n",
      "2023-12-06 15:16:27,396 : INFO : EPOCH 38: training on 99524 raw words (62763 effective words) took 0.3s, 247533 effective words/s\n",
      "2023-12-06 15:16:27,650 : INFO : EPOCH 39: training on 99524 raw words (62543 effective words) took 0.2s, 251002 effective words/s\n",
      "2023-12-06 15:16:27,900 : INFO : EPOCH 40: training on 99524 raw words (62617 effective words) took 0.2s, 254469 effective words/s\n",
      "2023-12-06 15:16:28,159 : INFO : EPOCH 41: training on 99524 raw words (62703 effective words) took 0.3s, 247581 effective words/s\n",
      "2023-12-06 15:16:28,413 : INFO : EPOCH 42: training on 99524 raw words (62647 effective words) took 0.3s, 250454 effective words/s\n",
      "2023-12-06 15:16:28,663 : INFO : EPOCH 43: training on 99524 raw words (62932 effective words) took 0.2s, 256434 effective words/s\n",
      "2023-12-06 15:16:28,921 : INFO : EPOCH 44: training on 99524 raw words (62604 effective words) took 0.3s, 246891 effective words/s\n",
      "2023-12-06 15:16:29,172 : INFO : EPOCH 45: training on 99524 raw words (62683 effective words) took 0.2s, 254645 effective words/s\n",
      "2023-12-06 15:16:29,427 : INFO : EPOCH 46: training on 99524 raw words (62761 effective words) took 0.3s, 250117 effective words/s\n",
      "2023-12-06 15:16:29,690 : INFO : EPOCH 47: training on 99524 raw words (62851 effective words) took 0.3s, 243451 effective words/s\n",
      "2023-12-06 15:16:29,939 : INFO : EPOCH 48: training on 99524 raw words (62792 effective words) took 0.2s, 256815 effective words/s\n",
      "2023-12-06 15:16:30,190 : INFO : EPOCH 49: training on 99524 raw words (62770 effective words) took 0.2s, 254643 effective words/s\n",
      "2023-12-06 15:16:30,191 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136815 effective words) took 12.8s, 244881 effective words/s', 'datetime': '2023-12-06T15:16:30.191563', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:16:30,192 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:16:30.192625', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 81%|  | 394/486 [1:02:53<19:44, 12.88s/it]2023-12-06 15:16:34,381 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:16:34,381 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:16:34,405 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:16:34,405 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:16:34,412 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:16:34.412903', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:16:34,413 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:16:34.413905', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:16:34,421 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:16:34,421 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:16:34,422 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:16:34.422507', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:16:34,430 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:16:34,431 : INFO : resetting layer weights\n",
      "2023-12-06 15:16:34,438 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:16:34.438104', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:16:34,686 : INFO : EPOCH 0: training on 99524 raw words (62659 effective words) took 0.2s, 256466 effective words/s\n",
      "2023-12-06 15:16:34,977 : INFO : EPOCH 1: training on 99524 raw words (62862 effective words) took 0.3s, 221048 effective words/s\n",
      "2023-12-06 15:16:35,244 : INFO : EPOCH 2: training on 99524 raw words (62892 effective words) took 0.3s, 238369 effective words/s\n",
      "2023-12-06 15:16:35,510 : INFO : EPOCH 3: training on 99524 raw words (62884 effective words) took 0.3s, 241712 effective words/s\n",
      "2023-12-06 15:16:35,773 : INFO : EPOCH 4: training on 99524 raw words (62661 effective words) took 0.3s, 242060 effective words/s\n",
      "2023-12-06 15:16:36,046 : INFO : EPOCH 5: training on 99524 raw words (62672 effective words) took 0.3s, 232922 effective words/s\n",
      "2023-12-06 15:16:36,315 : INFO : EPOCH 6: training on 99524 raw words (62789 effective words) took 0.3s, 236928 effective words/s\n",
      "2023-12-06 15:16:36,587 : INFO : EPOCH 7: training on 99524 raw words (62784 effective words) took 0.3s, 235583 effective words/s\n",
      "2023-12-06 15:16:36,857 : INFO : EPOCH 8: training on 99524 raw words (62588 effective words) took 0.3s, 236107 effective words/s\n",
      "2023-12-06 15:16:37,123 : INFO : EPOCH 9: training on 99524 raw words (62750 effective words) took 0.3s, 239361 effective words/s\n",
      "2023-12-06 15:16:37,396 : INFO : EPOCH 10: training on 99524 raw words (62912 effective words) took 0.3s, 234471 effective words/s\n",
      "2023-12-06 15:16:37,675 : INFO : EPOCH 11: training on 99524 raw words (62760 effective words) took 0.3s, 228565 effective words/s\n",
      "2023-12-06 15:16:37,954 : INFO : EPOCH 12: training on 99524 raw words (62797 effective words) took 0.3s, 228732 effective words/s\n",
      "2023-12-06 15:16:38,224 : INFO : EPOCH 13: training on 99524 raw words (62747 effective words) took 0.3s, 236770 effective words/s\n",
      "2023-12-06 15:16:38,492 : INFO : EPOCH 14: training on 99524 raw words (62838 effective words) took 0.3s, 238386 effective words/s\n",
      "2023-12-06 15:16:38,759 : INFO : EPOCH 15: training on 99524 raw words (62883 effective words) took 0.3s, 238988 effective words/s\n",
      "2023-12-06 15:16:39,026 : INFO : EPOCH 16: training on 99524 raw words (62733 effective words) took 0.3s, 239074 effective words/s\n",
      "2023-12-06 15:16:39,298 : INFO : EPOCH 17: training on 99524 raw words (62775 effective words) took 0.3s, 234711 effective words/s\n",
      "2023-12-06 15:16:39,565 : INFO : EPOCH 18: training on 99524 raw words (62699 effective words) took 0.3s, 238342 effective words/s\n",
      "2023-12-06 15:16:39,836 : INFO : EPOCH 19: training on 99524 raw words (62701 effective words) took 0.3s, 236565 effective words/s\n",
      "2023-12-06 15:16:40,096 : INFO : EPOCH 20: training on 99524 raw words (62640 effective words) took 0.3s, 244492 effective words/s\n",
      "2023-12-06 15:16:40,368 : INFO : EPOCH 21: training on 99524 raw words (62527 effective words) took 0.3s, 234274 effective words/s\n",
      "2023-12-06 15:16:40,644 : INFO : EPOCH 22: training on 99524 raw words (62825 effective words) took 0.3s, 231770 effective words/s\n",
      "2023-12-06 15:16:40,916 : INFO : EPOCH 23: training on 99524 raw words (62893 effective words) took 0.3s, 236328 effective words/s\n",
      "2023-12-06 15:16:41,185 : INFO : EPOCH 24: training on 99524 raw words (62616 effective words) took 0.3s, 236300 effective words/s\n",
      "2023-12-06 15:16:41,459 : INFO : EPOCH 25: training on 99524 raw words (62816 effective words) took 0.3s, 233268 effective words/s\n",
      "2023-12-06 15:16:41,723 : INFO : EPOCH 26: training on 99524 raw words (62728 effective words) took 0.3s, 241579 effective words/s\n",
      "2023-12-06 15:16:41,998 : INFO : EPOCH 27: training on 99524 raw words (62522 effective words) took 0.3s, 230470 effective words/s\n",
      "2023-12-06 15:16:42,284 : INFO : EPOCH 28: training on 99524 raw words (62731 effective words) took 0.3s, 223406 effective words/s\n",
      "2023-12-06 15:16:42,551 : INFO : EPOCH 29: training on 99524 raw words (62789 effective words) took 0.3s, 238347 effective words/s\n",
      "2023-12-06 15:16:42,823 : INFO : EPOCH 30: training on 99524 raw words (62586 effective words) took 0.3s, 234225 effective words/s\n",
      "2023-12-06 15:16:43,092 : INFO : EPOCH 31: training on 99524 raw words (62765 effective words) took 0.3s, 237859 effective words/s\n",
      "2023-12-06 15:16:43,362 : INFO : EPOCH 32: training on 99524 raw words (62598 effective words) took 0.3s, 235224 effective words/s\n",
      "2023-12-06 15:16:43,650 : INFO : EPOCH 33: training on 99524 raw words (62731 effective words) took 0.3s, 222066 effective words/s\n",
      "2023-12-06 15:16:43,918 : INFO : EPOCH 34: training on 99524 raw words (62649 effective words) took 0.3s, 238193 effective words/s\n",
      "2023-12-06 15:16:44,187 : INFO : EPOCH 35: training on 99524 raw words (62793 effective words) took 0.3s, 236841 effective words/s\n",
      "2023-12-06 15:16:44,456 : INFO : EPOCH 36: training on 99524 raw words (62673 effective words) took 0.3s, 237382 effective words/s\n",
      "2023-12-06 15:16:44,722 : INFO : EPOCH 37: training on 99524 raw words (62743 effective words) took 0.3s, 240261 effective words/s\n",
      "2023-12-06 15:16:44,991 : INFO : EPOCH 38: training on 99524 raw words (62993 effective words) took 0.3s, 237800 effective words/s\n",
      "2023-12-06 15:16:45,280 : INFO : EPOCH 39: training on 99524 raw words (62879 effective words) took 0.3s, 220705 effective words/s\n",
      "2023-12-06 15:16:45,549 : INFO : EPOCH 40: training on 99524 raw words (62814 effective words) took 0.3s, 237550 effective words/s\n",
      "2023-12-06 15:16:45,814 : INFO : EPOCH 41: training on 99524 raw words (62719 effective words) took 0.3s, 241970 effective words/s\n",
      "2023-12-06 15:16:46,082 : INFO : EPOCH 42: training on 99524 raw words (62651 effective words) took 0.3s, 237561 effective words/s\n",
      "2023-12-06 15:16:46,353 : INFO : EPOCH 43: training on 99524 raw words (62675 effective words) took 0.3s, 235273 effective words/s\n",
      "2023-12-06 15:16:46,621 : INFO : EPOCH 44: training on 99524 raw words (62705 effective words) took 0.3s, 238546 effective words/s\n",
      "2023-12-06 15:16:46,891 : INFO : EPOCH 45: training on 99524 raw words (62958 effective words) took 0.3s, 237244 effective words/s\n",
      "2023-12-06 15:16:47,159 : INFO : EPOCH 46: training on 99524 raw words (62731 effective words) took 0.3s, 238437 effective words/s\n",
      "2023-12-06 15:16:47,428 : INFO : EPOCH 47: training on 99524 raw words (62569 effective words) took 0.3s, 236900 effective words/s\n",
      "2023-12-06 15:16:47,694 : INFO : EPOCH 48: training on 99524 raw words (62792 effective words) took 0.3s, 240380 effective words/s\n",
      "2023-12-06 15:16:47,966 : INFO : EPOCH 49: training on 99524 raw words (62726 effective words) took 0.3s, 234303 effective words/s\n",
      "2023-12-06 15:16:47,967 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3137223 effective words) took 13.5s, 231892 effective words/s', 'datetime': '2023-12-06T15:16:47.967252', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:16:47,968 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:16:47.968250', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 81%| | 395/486 [1:03:11<21:54, 14.44s/it]2023-12-06 15:16:52,485 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:16:52,485 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:16:52,505 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:16:52,507 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:16:52,512 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:16:52.512553', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:16:52,513 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:16:52.513558', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:16:52,521 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:16:52,521 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:16:52,522 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:16:52.522942', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:16:52,531 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:16:52,532 : INFO : resetting layer weights\n",
      "2023-12-06 15:16:52,537 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:16:52.537672', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:16:52,803 : INFO : EPOCH 0: training on 99524 raw words (62940 effective words) took 0.3s, 240806 effective words/s\n",
      "2023-12-06 15:16:53,114 : INFO : EPOCH 1: training on 99524 raw words (62829 effective words) took 0.3s, 206504 effective words/s\n",
      "2023-12-06 15:16:53,385 : INFO : EPOCH 2: training on 99524 raw words (62858 effective words) took 0.3s, 235951 effective words/s\n",
      "2023-12-06 15:16:53,664 : INFO : EPOCH 3: training on 99524 raw words (62854 effective words) took 0.3s, 228965 effective words/s\n",
      "2023-12-06 15:16:53,940 : INFO : EPOCH 4: training on 99524 raw words (62742 effective words) took 0.3s, 231758 effective words/s\n",
      "2023-12-06 15:16:54,214 : INFO : EPOCH 5: training on 99524 raw words (62560 effective words) took 0.3s, 232378 effective words/s\n",
      "2023-12-06 15:16:54,486 : INFO : EPOCH 6: training on 99524 raw words (62776 effective words) took 0.3s, 234461 effective words/s\n",
      "2023-12-06 15:16:54,777 : INFO : EPOCH 7: training on 99524 raw words (62650 effective words) took 0.3s, 218976 effective words/s\n",
      "2023-12-06 15:16:55,048 : INFO : EPOCH 8: training on 99524 raw words (62748 effective words) took 0.3s, 235368 effective words/s\n",
      "2023-12-06 15:16:55,319 : INFO : EPOCH 9: training on 99524 raw words (62776 effective words) took 0.3s, 234976 effective words/s\n",
      "2023-12-06 15:16:55,600 : INFO : EPOCH 10: training on 99524 raw words (62701 effective words) took 0.3s, 227712 effective words/s\n",
      "2023-12-06 15:16:55,873 : INFO : EPOCH 11: training on 99524 raw words (62949 effective words) took 0.3s, 233852 effective words/s\n",
      "2023-12-06 15:16:56,151 : INFO : EPOCH 12: training on 99524 raw words (62838 effective words) took 0.3s, 230239 effective words/s\n",
      "2023-12-06 15:16:56,430 : INFO : EPOCH 13: training on 99524 raw words (62781 effective words) took 0.3s, 228677 effective words/s\n",
      "2023-12-06 15:16:56,707 : INFO : EPOCH 14: training on 99524 raw words (62738 effective words) took 0.3s, 230048 effective words/s\n",
      "2023-12-06 15:16:56,988 : INFO : EPOCH 15: training on 99524 raw words (62537 effective words) took 0.3s, 226306 effective words/s\n",
      "2023-12-06 15:16:57,261 : INFO : EPOCH 16: training on 99524 raw words (62637 effective words) took 0.3s, 233920 effective words/s\n",
      "2023-12-06 15:16:57,537 : INFO : EPOCH 17: training on 99524 raw words (62692 effective words) took 0.3s, 230812 effective words/s\n",
      "2023-12-06 15:16:57,828 : INFO : EPOCH 18: training on 99524 raw words (62738 effective words) took 0.3s, 219067 effective words/s\n",
      "2023-12-06 15:16:58,102 : INFO : EPOCH 19: training on 99524 raw words (62761 effective words) took 0.3s, 232330 effective words/s\n",
      "2023-12-06 15:16:58,391 : INFO : EPOCH 20: training on 99524 raw words (62771 effective words) took 0.3s, 221591 effective words/s\n",
      "2023-12-06 15:16:58,665 : INFO : EPOCH 21: training on 99524 raw words (62712 effective words) took 0.3s, 232540 effective words/s\n",
      "2023-12-06 15:16:58,944 : INFO : EPOCH 22: training on 99524 raw words (62726 effective words) took 0.3s, 229083 effective words/s\n",
      "2023-12-06 15:16:59,223 : INFO : EPOCH 23: training on 99524 raw words (62720 effective words) took 0.3s, 227551 effective words/s\n",
      "2023-12-06 15:16:59,513 : INFO : EPOCH 24: training on 99524 raw words (62962 effective words) took 0.3s, 223655 effective words/s\n",
      "2023-12-06 15:16:59,785 : INFO : EPOCH 25: training on 99524 raw words (62763 effective words) took 0.3s, 234577 effective words/s\n",
      "2023-12-06 15:17:00,065 : INFO : EPOCH 26: training on 99524 raw words (62668 effective words) took 0.3s, 228063 effective words/s\n",
      "2023-12-06 15:17:00,345 : INFO : EPOCH 27: training on 99524 raw words (62674 effective words) took 0.3s, 227071 effective words/s\n",
      "2023-12-06 15:17:00,626 : INFO : EPOCH 28: training on 99524 raw words (62769 effective words) took 0.3s, 228379 effective words/s\n",
      "2023-12-06 15:17:00,904 : INFO : EPOCH 29: training on 99524 raw words (62762 effective words) took 0.3s, 229145 effective words/s\n",
      "2023-12-06 15:17:01,182 : INFO : EPOCH 30: training on 99524 raw words (62750 effective words) took 0.3s, 230298 effective words/s\n",
      "2023-12-06 15:17:01,458 : INFO : EPOCH 31: training on 99524 raw words (62754 effective words) took 0.3s, 231097 effective words/s\n",
      "2023-12-06 15:17:01,734 : INFO : EPOCH 32: training on 99524 raw words (62670 effective words) took 0.3s, 231809 effective words/s\n",
      "2023-12-06 15:17:02,012 : INFO : EPOCH 33: training on 99524 raw words (62650 effective words) took 0.3s, 228282 effective words/s\n",
      "2023-12-06 15:17:02,283 : INFO : EPOCH 34: training on 99524 raw words (62547 effective words) took 0.3s, 235884 effective words/s\n",
      "2023-12-06 15:17:02,565 : INFO : EPOCH 35: training on 99524 raw words (62694 effective words) took 0.3s, 226447 effective words/s\n",
      "2023-12-06 15:17:02,834 : INFO : EPOCH 36: training on 99524 raw words (62878 effective words) took 0.3s, 236734 effective words/s\n",
      "2023-12-06 15:17:03,127 : INFO : EPOCH 37: training on 99524 raw words (62904 effective words) took 0.3s, 218800 effective words/s\n",
      "2023-12-06 15:17:03,402 : INFO : EPOCH 38: training on 99524 raw words (62707 effective words) took 0.3s, 231024 effective words/s\n",
      "2023-12-06 15:17:03,681 : INFO : EPOCH 39: training on 99524 raw words (62526 effective words) took 0.3s, 228961 effective words/s\n",
      "2023-12-06 15:17:03,958 : INFO : EPOCH 40: training on 99524 raw words (62719 effective words) took 0.3s, 230240 effective words/s\n",
      "2023-12-06 15:17:04,267 : INFO : EPOCH 41: training on 99524 raw words (62521 effective words) took 0.3s, 205029 effective words/s\n",
      "2023-12-06 15:17:04,550 : INFO : EPOCH 42: training on 99524 raw words (62726 effective words) took 0.3s, 225264 effective words/s\n",
      "2023-12-06 15:17:04,832 : INFO : EPOCH 43: training on 99524 raw words (62658 effective words) took 0.3s, 226218 effective words/s\n",
      "2023-12-06 15:17:05,106 : INFO : EPOCH 44: training on 99524 raw words (62851 effective words) took 0.3s, 233704 effective words/s\n",
      "2023-12-06 15:17:05,378 : INFO : EPOCH 45: training on 99524 raw words (62673 effective words) took 0.3s, 234387 effective words/s\n",
      "2023-12-06 15:17:05,662 : INFO : EPOCH 46: training on 99524 raw words (62709 effective words) took 0.3s, 223847 effective words/s\n",
      "2023-12-06 15:17:05,938 : INFO : EPOCH 47: training on 99524 raw words (62635 effective words) took 0.3s, 232601 effective words/s\n",
      "2023-12-06 15:17:06,212 : INFO : EPOCH 48: training on 99524 raw words (62637 effective words) took 0.3s, 232668 effective words/s\n",
      "2023-12-06 15:17:06,491 : INFO : EPOCH 49: training on 99524 raw words (62779 effective words) took 0.3s, 228465 effective words/s\n",
      "2023-12-06 15:17:06,492 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136620 effective words) took 14.0s, 224777 effective words/s', 'datetime': '2023-12-06T15:17:06.492621', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:17:06,493 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w10,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:17:06.493621', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 81%| | 396/486 [1:03:29<23:39, 15.77s/it]2023-12-06 15:17:11,355 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:17:11,356 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:17:11,381 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:17:11,382 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:17:11,386 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:17:11.386855', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:17:11,387 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:17:11.387855', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:17:11,391 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:17:11,392 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:17:11,392 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:17:11.392855', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:17:11,403 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:17:11,404 : INFO : resetting layer weights\n",
      "2023-12-06 15:17:11,408 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:17:11.408603', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:17:11,640 : INFO : EPOCH 0: training on 99524 raw words (60380 effective words) took 0.2s, 265163 effective words/s\n",
      "2023-12-06 15:17:11,920 : INFO : EPOCH 1: training on 99524 raw words (60426 effective words) took 0.3s, 222944 effective words/s\n",
      "2023-12-06 15:17:12,178 : INFO : EPOCH 2: training on 99524 raw words (60435 effective words) took 0.3s, 238773 effective words/s\n",
      "2023-12-06 15:17:12,436 : INFO : EPOCH 3: training on 99524 raw words (60250 effective words) took 0.3s, 236951 effective words/s\n",
      "2023-12-06 15:17:12,690 : INFO : EPOCH 4: training on 99524 raw words (60476 effective words) took 0.2s, 242549 effective words/s\n",
      "2023-12-06 15:17:12,948 : INFO : EPOCH 5: training on 99524 raw words (60352 effective words) took 0.3s, 238035 effective words/s\n",
      "2023-12-06 15:17:13,199 : INFO : EPOCH 6: training on 99524 raw words (60453 effective words) took 0.2s, 245716 effective words/s\n",
      "2023-12-06 15:17:13,471 : INFO : EPOCH 7: training on 99524 raw words (60441 effective words) took 0.3s, 226035 effective words/s\n",
      "2023-12-06 15:17:13,732 : INFO : EPOCH 8: training on 99524 raw words (60484 effective words) took 0.3s, 235609 effective words/s\n",
      "2023-12-06 15:17:13,987 : INFO : EPOCH 9: training on 99524 raw words (60313 effective words) took 0.2s, 241310 effective words/s\n",
      "2023-12-06 15:17:13,988 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604010 effective words) took 2.6s, 234212 effective words/s', 'datetime': '2023-12-06T15:17:13.988118', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:17:13,989 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:17:13.988118', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 82%| | 397/486 [1:03:35<18:52, 12.72s/it]2023-12-06 15:17:16,965 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:17:16,965 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:17:16,989 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:17:16,990 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:17:16,995 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:17:16.995654', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:17:16,996 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:17:16.996638', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:17:17,003 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:17:17,004 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:17:17,004 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:17:17.004691', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:17:17,012 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:17:17,012 : INFO : resetting layer weights\n",
      "2023-12-06 15:17:17,018 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:17:17.018618', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:17:17,292 : INFO : EPOCH 0: training on 99524 raw words (60604 effective words) took 0.3s, 225236 effective words/s\n",
      "2023-12-06 15:17:17,584 : INFO : EPOCH 1: training on 99524 raw words (60441 effective words) took 0.3s, 216226 effective words/s\n",
      "2023-12-06 15:17:17,855 : INFO : EPOCH 2: training on 99524 raw words (60344 effective words) took 0.3s, 225533 effective words/s\n",
      "2023-12-06 15:17:18,126 : INFO : EPOCH 3: training on 99524 raw words (60442 effective words) took 0.3s, 227107 effective words/s\n",
      "2023-12-06 15:17:18,400 : INFO : EPOCH 4: training on 99524 raw words (60308 effective words) took 0.3s, 223683 effective words/s\n",
      "2023-12-06 15:17:18,667 : INFO : EPOCH 5: training on 99524 raw words (60626 effective words) took 0.3s, 231353 effective words/s\n",
      "2023-12-06 15:17:18,933 : INFO : EPOCH 6: training on 99524 raw words (60398 effective words) took 0.3s, 231212 effective words/s\n",
      "2023-12-06 15:17:19,204 : INFO : EPOCH 7: training on 99524 raw words (60265 effective words) took 0.3s, 225474 effective words/s\n",
      "2023-12-06 15:17:19,471 : INFO : EPOCH 8: training on 99524 raw words (60413 effective words) took 0.3s, 229854 effective words/s\n",
      "2023-12-06 15:17:19,736 : INFO : EPOCH 9: training on 99524 raw words (60366 effective words) took 0.3s, 231261 effective words/s\n",
      "2023-12-06 15:17:19,737 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604207 effective words) took 2.7s, 222251 effective words/s', 'datetime': '2023-12-06T15:17:19.737935', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:17:19,738 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:17:19.738932', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 82%| | 398/486 [1:03:41<15:36, 10.64s/it]2023-12-06 15:17:22,755 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:17:22,755 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:17:22,776 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:17:22,777 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:17:22,783 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:17:22.783222', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:17:22,784 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:17:22.784222', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:17:22,789 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:17:22,789 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:17:22,790 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:17:22.790223', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:17:22,797 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:17:22,798 : INFO : resetting layer weights\n",
      "2023-12-06 15:17:22,803 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:17:22.803800', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:17:23,097 : INFO : EPOCH 0: training on 99524 raw words (60441 effective words) took 0.3s, 208762 effective words/s\n",
      "2023-12-06 15:17:23,385 : INFO : EPOCH 1: training on 99524 raw words (60298 effective words) took 0.3s, 214839 effective words/s\n",
      "2023-12-06 15:17:23,657 : INFO : EPOCH 2: training on 99524 raw words (60569 effective words) took 0.3s, 226345 effective words/s\n",
      "2023-12-06 15:17:23,932 : INFO : EPOCH 3: training on 99524 raw words (60594 effective words) took 0.3s, 224394 effective words/s\n",
      "2023-12-06 15:17:24,208 : INFO : EPOCH 4: training on 99524 raw words (60350 effective words) took 0.3s, 221859 effective words/s\n",
      "2023-12-06 15:17:24,487 : INFO : EPOCH 5: training on 99524 raw words (60453 effective words) took 0.3s, 219829 effective words/s\n",
      "2023-12-06 15:17:24,767 : INFO : EPOCH 6: training on 99524 raw words (60410 effective words) took 0.3s, 220090 effective words/s\n",
      "2023-12-06 15:17:25,045 : INFO : EPOCH 7: training on 99524 raw words (60382 effective words) took 0.3s, 221517 effective words/s\n",
      "2023-12-06 15:17:25,322 : INFO : EPOCH 8: training on 99524 raw words (60580 effective words) took 0.3s, 222494 effective words/s\n",
      "2023-12-06 15:17:25,589 : INFO : EPOCH 9: training on 99524 raw words (60282 effective words) took 0.3s, 230479 effective words/s\n",
      "2023-12-06 15:17:25,590 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604359 effective words) took 2.8s, 217036 effective words/s', 'datetime': '2023-12-06T15:17:25.590006', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:17:25,590 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:17:25.590006', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 82%| | 399/486 [1:03:47<13:23,  9.23s/it]2023-12-06 15:17:28,695 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:17:28,696 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:17:28,716 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:17:28,717 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:17:28,722 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:17:28.721305', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:17:28,722 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:17:28.722833', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:17:28,729 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:17:28,730 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:17:28,730 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:17:28.730718', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:17:28,738 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:17:28,738 : INFO : resetting layer weights\n",
      "2023-12-06 15:17:28,745 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:17:28.745229', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:17:29,004 : INFO : EPOCH 0: training on 99524 raw words (60182 effective words) took 0.3s, 235541 effective words/s\n",
      "2023-12-06 15:17:29,283 : INFO : EPOCH 1: training on 99524 raw words (60299 effective words) took 0.3s, 223361 effective words/s\n",
      "2023-12-06 15:17:29,537 : INFO : EPOCH 2: training on 99524 raw words (60418 effective words) took 0.2s, 243178 effective words/s\n",
      "2023-12-06 15:17:29,794 : INFO : EPOCH 3: training on 99524 raw words (60413 effective words) took 0.3s, 240150 effective words/s\n",
      "2023-12-06 15:17:30,049 : INFO : EPOCH 4: training on 99524 raw words (60361 effective words) took 0.3s, 241185 effective words/s\n",
      "2023-12-06 15:17:30,304 : INFO : EPOCH 5: training on 99524 raw words (60446 effective words) took 0.3s, 240352 effective words/s\n",
      "2023-12-06 15:17:30,562 : INFO : EPOCH 6: training on 99524 raw words (60365 effective words) took 0.3s, 238760 effective words/s\n",
      "2023-12-06 15:17:30,817 : INFO : EPOCH 7: training on 99524 raw words (60406 effective words) took 0.3s, 241091 effective words/s\n",
      "2023-12-06 15:17:31,078 : INFO : EPOCH 8: training on 99524 raw words (60438 effective words) took 0.3s, 236077 effective words/s\n",
      "2023-12-06 15:17:31,338 : INFO : EPOCH 9: training on 99524 raw words (60317 effective words) took 0.3s, 236156 effective words/s\n",
      "2023-12-06 15:17:31,595 : INFO : EPOCH 10: training on 99524 raw words (60459 effective words) took 0.3s, 239556 effective words/s\n",
      "2023-12-06 15:17:31,851 : INFO : EPOCH 11: training on 99524 raw words (60531 effective words) took 0.3s, 239912 effective words/s\n",
      "2023-12-06 15:17:32,117 : INFO : EPOCH 12: training on 99524 raw words (60373 effective words) took 0.3s, 231673 effective words/s\n",
      "2023-12-06 15:17:32,368 : INFO : EPOCH 13: training on 99524 raw words (60362 effective words) took 0.2s, 244742 effective words/s\n",
      "2023-12-06 15:17:32,623 : INFO : EPOCH 14: training on 99524 raw words (60631 effective words) took 0.2s, 244140 effective words/s\n",
      "2023-12-06 15:17:32,886 : INFO : EPOCH 15: training on 99524 raw words (60311 effective words) took 0.3s, 233472 effective words/s\n",
      "2023-12-06 15:17:33,138 : INFO : EPOCH 16: training on 99524 raw words (60106 effective words) took 0.2s, 242658 effective words/s\n",
      "2023-12-06 15:17:33,393 : INFO : EPOCH 17: training on 99524 raw words (60310 effective words) took 0.3s, 240978 effective words/s\n",
      "2023-12-06 15:17:33,656 : INFO : EPOCH 18: training on 99524 raw words (60490 effective words) took 0.3s, 233426 effective words/s\n",
      "2023-12-06 15:17:33,912 : INFO : EPOCH 19: training on 99524 raw words (60438 effective words) took 0.3s, 239361 effective words/s\n",
      "2023-12-06 15:17:34,162 : INFO : EPOCH 20: training on 99524 raw words (60345 effective words) took 0.2s, 245707 effective words/s\n",
      "2023-12-06 15:17:34,415 : INFO : EPOCH 21: training on 99524 raw words (60389 effective words) took 0.2s, 243592 effective words/s\n",
      "2023-12-06 15:17:34,674 : INFO : EPOCH 22: training on 99524 raw words (60368 effective words) took 0.3s, 237532 effective words/s\n",
      "2023-12-06 15:17:34,927 : INFO : EPOCH 23: training on 99524 raw words (60396 effective words) took 0.2s, 242777 effective words/s\n",
      "2023-12-06 15:17:35,198 : INFO : EPOCH 24: training on 99524 raw words (60461 effective words) took 0.3s, 227213 effective words/s\n",
      "2023-12-06 15:17:35,452 : INFO : EPOCH 25: training on 99524 raw words (60398 effective words) took 0.2s, 241844 effective words/s\n",
      "2023-12-06 15:17:35,697 : INFO : EPOCH 26: training on 99524 raw words (60237 effective words) took 0.2s, 249672 effective words/s\n",
      "2023-12-06 15:17:35,954 : INFO : EPOCH 27: training on 99524 raw words (60465 effective words) took 0.3s, 240311 effective words/s\n",
      "2023-12-06 15:17:36,211 : INFO : EPOCH 28: training on 99524 raw words (60355 effective words) took 0.3s, 239033 effective words/s\n",
      "2023-12-06 15:17:36,462 : INFO : EPOCH 29: training on 99524 raw words (60477 effective words) took 0.2s, 244744 effective words/s\n",
      "2023-12-06 15:17:36,463 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811547 effective words) took 7.7s, 234717 effective words/s', 'datetime': '2023-12-06T15:17:36.463803', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:17:36,463 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:17:36.463803', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 82%| | 400/486 [1:03:58<14:09,  9.88s/it]2023-12-06 15:17:40,099 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:17:40,099 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:17:40,121 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:17:40,121 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:17:40,128 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:17:40.128578', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:17:40,128 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:17:40.128578', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:17:40,134 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:17:40,136 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:17:40,136 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:17:40.136082', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:17:40,143 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:17:40,143 : INFO : resetting layer weights\n",
      "2023-12-06 15:17:40,149 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:17:40.149832', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:17:40,424 : INFO : EPOCH 0: training on 99524 raw words (60353 effective words) took 0.3s, 223501 effective words/s\n",
      "2023-12-06 15:17:40,706 : INFO : EPOCH 1: training on 99524 raw words (60386 effective words) took 0.3s, 218577 effective words/s\n",
      "2023-12-06 15:17:40,975 : INFO : EPOCH 2: training on 99524 raw words (60413 effective words) took 0.3s, 228477 effective words/s\n",
      "2023-12-06 15:17:41,248 : INFO : EPOCH 3: training on 99524 raw words (60455 effective words) took 0.3s, 225455 effective words/s\n",
      "2023-12-06 15:17:41,518 : INFO : EPOCH 4: training on 99524 raw words (60413 effective words) took 0.3s, 227290 effective words/s\n",
      "2023-12-06 15:17:41,796 : INFO : EPOCH 5: training on 99524 raw words (60440 effective words) took 0.3s, 220039 effective words/s\n",
      "2023-12-06 15:17:42,069 : INFO : EPOCH 6: training on 99524 raw words (60487 effective words) took 0.3s, 225777 effective words/s\n",
      "2023-12-06 15:17:42,335 : INFO : EPOCH 7: training on 99524 raw words (60534 effective words) took 0.3s, 231980 effective words/s\n",
      "2023-12-06 15:17:42,606 : INFO : EPOCH 8: training on 99524 raw words (60413 effective words) took 0.3s, 226121 effective words/s\n",
      "2023-12-06 15:17:42,872 : INFO : EPOCH 9: training on 99524 raw words (60188 effective words) took 0.3s, 230438 effective words/s\n",
      "2023-12-06 15:17:43,134 : INFO : EPOCH 10: training on 99524 raw words (60301 effective words) took 0.3s, 234472 effective words/s\n",
      "2023-12-06 15:17:43,400 : INFO : EPOCH 11: training on 99524 raw words (60316 effective words) took 0.3s, 230337 effective words/s\n",
      "2023-12-06 15:17:43,680 : INFO : EPOCH 12: training on 99524 raw words (60415 effective words) took 0.3s, 221439 effective words/s\n",
      "2023-12-06 15:17:43,952 : INFO : EPOCH 13: training on 99524 raw words (60394 effective words) took 0.3s, 225834 effective words/s\n",
      "2023-12-06 15:17:44,222 : INFO : EPOCH 14: training on 99524 raw words (60419 effective words) took 0.3s, 226645 effective words/s\n",
      "2023-12-06 15:17:44,490 : INFO : EPOCH 15: training on 99524 raw words (60365 effective words) took 0.3s, 229843 effective words/s\n",
      "2023-12-06 15:17:44,757 : INFO : EPOCH 16: training on 99524 raw words (60612 effective words) took 0.3s, 230672 effective words/s\n",
      "2023-12-06 15:17:45,035 : INFO : EPOCH 17: training on 99524 raw words (60178 effective words) took 0.3s, 220821 effective words/s\n",
      "2023-12-06 15:17:45,303 : INFO : EPOCH 18: training on 99524 raw words (60403 effective words) took 0.3s, 230753 effective words/s\n",
      "2023-12-06 15:17:45,572 : INFO : EPOCH 19: training on 99524 raw words (60591 effective words) took 0.3s, 229377 effective words/s\n",
      "2023-12-06 15:17:45,848 : INFO : EPOCH 20: training on 99524 raw words (60311 effective words) took 0.3s, 222861 effective words/s\n",
      "2023-12-06 15:17:46,118 : INFO : EPOCH 21: training on 99524 raw words (60565 effective words) took 0.3s, 227076 effective words/s\n",
      "2023-12-06 15:17:46,384 : INFO : EPOCH 22: training on 99524 raw words (60516 effective words) took 0.3s, 232096 effective words/s\n",
      "2023-12-06 15:17:46,656 : INFO : EPOCH 23: training on 99524 raw words (60539 effective words) took 0.3s, 227646 effective words/s\n",
      "2023-12-06 15:17:46,923 : INFO : EPOCH 24: training on 99524 raw words (60287 effective words) took 0.3s, 229332 effective words/s\n",
      "2023-12-06 15:17:47,186 : INFO : EPOCH 25: training on 99524 raw words (60462 effective words) took 0.3s, 233155 effective words/s\n",
      "2023-12-06 15:17:47,452 : INFO : EPOCH 26: training on 99524 raw words (60317 effective words) took 0.3s, 230816 effective words/s\n",
      "2023-12-06 15:17:47,725 : INFO : EPOCH 27: training on 99524 raw words (60465 effective words) took 0.3s, 226300 effective words/s\n",
      "2023-12-06 15:17:47,998 : INFO : EPOCH 28: training on 99524 raw words (60322 effective words) took 0.3s, 225472 effective words/s\n",
      "2023-12-06 15:17:48,279 : INFO : EPOCH 29: training on 99524 raw words (60595 effective words) took 0.3s, 218955 effective words/s\n",
      "2023-12-06 15:17:48,280 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812455 effective words) took 8.1s, 222959 effective words/s', 'datetime': '2023-12-06T15:17:48.280298', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:17:48,280 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:17:48.280298', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 83%| | 401/486 [1:04:10<14:54, 10.52s/it]2023-12-06 15:17:52,108 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:17:52,109 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:17:52,131 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:17:52,132 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:17:52,137 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:17:52.137685', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:17:52,138 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:17:52.138687', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:17:52,143 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:17:52,144 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:17:52,144 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:17:52.144898', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:17:52,152 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:17:52,153 : INFO : resetting layer weights\n",
      "2023-12-06 15:17:52,157 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:17:52.157548', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:17:52,444 : INFO : EPOCH 0: training on 99524 raw words (60422 effective words) took 0.3s, 213942 effective words/s\n",
      "2023-12-06 15:17:52,725 : INFO : EPOCH 1: training on 99524 raw words (60295 effective words) took 0.3s, 218794 effective words/s\n",
      "2023-12-06 15:17:53,001 : INFO : EPOCH 2: training on 99524 raw words (60294 effective words) took 0.3s, 222795 effective words/s\n",
      "2023-12-06 15:17:53,274 : INFO : EPOCH 3: training on 99524 raw words (60436 effective words) took 0.3s, 224843 effective words/s\n",
      "2023-12-06 15:17:53,555 : INFO : EPOCH 4: training on 99524 raw words (60264 effective words) took 0.3s, 217540 effective words/s\n",
      "2023-12-06 15:17:53,830 : INFO : EPOCH 5: training on 99524 raw words (60292 effective words) took 0.3s, 223390 effective words/s\n",
      "2023-12-06 15:17:54,113 : INFO : EPOCH 6: training on 99524 raw words (60450 effective words) took 0.3s, 216389 effective words/s\n",
      "2023-12-06 15:17:54,387 : INFO : EPOCH 7: training on 99524 raw words (60431 effective words) took 0.3s, 225266 effective words/s\n",
      "2023-12-06 15:17:54,664 : INFO : EPOCH 8: training on 99524 raw words (60270 effective words) took 0.3s, 221301 effective words/s\n",
      "2023-12-06 15:17:54,935 : INFO : EPOCH 9: training on 99524 raw words (60327 effective words) took 0.3s, 225058 effective words/s\n",
      "2023-12-06 15:17:55,215 : INFO : EPOCH 10: training on 99524 raw words (60460 effective words) took 0.3s, 220503 effective words/s\n",
      "2023-12-06 15:17:55,492 : INFO : EPOCH 11: training on 99524 raw words (60496 effective words) took 0.3s, 222019 effective words/s\n",
      "2023-12-06 15:17:55,766 : INFO : EPOCH 12: training on 99524 raw words (60444 effective words) took 0.3s, 223489 effective words/s\n",
      "2023-12-06 15:17:56,043 : INFO : EPOCH 13: training on 99524 raw words (60371 effective words) took 0.3s, 222684 effective words/s\n",
      "2023-12-06 15:17:56,318 : INFO : EPOCH 14: training on 99524 raw words (60494 effective words) took 0.3s, 223607 effective words/s\n",
      "2023-12-06 15:17:56,595 : INFO : EPOCH 15: training on 99524 raw words (60342 effective words) took 0.3s, 221988 effective words/s\n",
      "2023-12-06 15:17:56,868 : INFO : EPOCH 16: training on 99524 raw words (60390 effective words) took 0.3s, 224457 effective words/s\n",
      "2023-12-06 15:17:57,150 : INFO : EPOCH 17: training on 99524 raw words (60397 effective words) took 0.3s, 217835 effective words/s\n",
      "2023-12-06 15:17:57,422 : INFO : EPOCH 18: training on 99524 raw words (60276 effective words) took 0.3s, 225608 effective words/s\n",
      "2023-12-06 15:17:57,695 : INFO : EPOCH 19: training on 99524 raw words (60387 effective words) took 0.3s, 225062 effective words/s\n",
      "2023-12-06 15:17:57,975 : INFO : EPOCH 20: training on 99524 raw words (60279 effective words) took 0.3s, 218368 effective words/s\n",
      "2023-12-06 15:17:58,250 : INFO : EPOCH 21: training on 99524 raw words (60512 effective words) took 0.3s, 224438 effective words/s\n",
      "2023-12-06 15:17:58,539 : INFO : EPOCH 22: training on 99524 raw words (60571 effective words) took 0.3s, 212272 effective words/s\n",
      "2023-12-06 15:17:58,838 : INFO : EPOCH 23: training on 99524 raw words (60239 effective words) took 0.3s, 205155 effective words/s\n",
      "2023-12-06 15:17:59,113 : INFO : EPOCH 24: training on 99524 raw words (60453 effective words) took 0.3s, 223692 effective words/s\n",
      "2023-12-06 15:17:59,384 : INFO : EPOCH 25: training on 99524 raw words (60475 effective words) took 0.3s, 226612 effective words/s\n",
      "2023-12-06 15:17:59,655 : INFO : EPOCH 26: training on 99524 raw words (60457 effective words) took 0.3s, 227007 effective words/s\n",
      "2023-12-06 15:17:59,928 : INFO : EPOCH 27: training on 99524 raw words (60392 effective words) took 0.3s, 226045 effective words/s\n",
      "2023-12-06 15:18:00,206 : INFO : EPOCH 28: training on 99524 raw words (60316 effective words) took 0.3s, 219617 effective words/s\n",
      "2023-12-06 15:18:00,484 : INFO : EPOCH 29: training on 99524 raw words (60410 effective words) took 0.3s, 221219 effective words/s\n",
      "2023-12-06 15:18:00,485 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811642 effective words) took 8.3s, 217550 effective words/s', 'datetime': '2023-12-06T15:18:00.485999', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:18:00,485 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:18:00.485999', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 83%| | 402/486 [1:04:23<15:29, 11.07s/it]2023-12-06 15:18:04,452 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:18:04,453 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:18:04,475 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:18:04,476 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:18:04,480 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:18:04.480457', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:18:04,480 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:18:04.480457', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:18:04,487 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:18:04,488 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:18:04,488 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:18:04.488737', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:18:04,495 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:18:04,496 : INFO : resetting layer weights\n",
      "2023-12-06 15:18:04,501 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:18:04.501372', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:18:04,756 : INFO : EPOCH 0: training on 99524 raw words (60370 effective words) took 0.3s, 240402 effective words/s\n",
      "2023-12-06 15:18:05,037 : INFO : EPOCH 1: training on 99524 raw words (60383 effective words) took 0.3s, 219732 effective words/s\n",
      "2023-12-06 15:18:05,283 : INFO : EPOCH 2: training on 99524 raw words (60309 effective words) took 0.2s, 249672 effective words/s\n",
      "2023-12-06 15:18:05,537 : INFO : EPOCH 3: training on 99524 raw words (60169 effective words) took 0.2s, 241857 effective words/s\n",
      "2023-12-06 15:18:05,793 : INFO : EPOCH 4: training on 99524 raw words (60273 effective words) took 0.3s, 239240 effective words/s\n",
      "2023-12-06 15:18:06,047 : INFO : EPOCH 5: training on 99524 raw words (60493 effective words) took 0.2s, 242637 effective words/s\n",
      "2023-12-06 15:18:06,302 : INFO : EPOCH 6: training on 99524 raw words (60335 effective words) took 0.3s, 240706 effective words/s\n",
      "2023-12-06 15:18:06,560 : INFO : EPOCH 7: training on 99524 raw words (60444 effective words) took 0.3s, 238875 effective words/s\n",
      "2023-12-06 15:18:06,813 : INFO : EPOCH 8: training on 99524 raw words (60298 effective words) took 0.2s, 242012 effective words/s\n",
      "2023-12-06 15:18:07,070 : INFO : EPOCH 9: training on 99524 raw words (60438 effective words) took 0.3s, 239316 effective words/s\n",
      "2023-12-06 15:18:07,339 : INFO : EPOCH 10: training on 99524 raw words (60310 effective words) took 0.3s, 228368 effective words/s\n",
      "2023-12-06 15:18:07,588 : INFO : EPOCH 11: training on 99524 raw words (60279 effective words) took 0.2s, 245970 effective words/s\n",
      "2023-12-06 15:18:07,854 : INFO : EPOCH 12: training on 99524 raw words (60503 effective words) took 0.3s, 232118 effective words/s\n",
      "2023-12-06 15:18:08,107 : INFO : EPOCH 13: training on 99524 raw words (60289 effective words) took 0.2s, 242081 effective words/s\n",
      "2023-12-06 15:18:08,364 : INFO : EPOCH 14: training on 99524 raw words (60500 effective words) took 0.3s, 239547 effective words/s\n",
      "2023-12-06 15:18:08,639 : INFO : EPOCH 15: training on 99524 raw words (60341 effective words) took 0.3s, 224035 effective words/s\n",
      "2023-12-06 15:18:08,890 : INFO : EPOCH 16: training on 99524 raw words (60443 effective words) took 0.2s, 244665 effective words/s\n",
      "2023-12-06 15:18:09,147 : INFO : EPOCH 17: training on 99524 raw words (60342 effective words) took 0.3s, 238582 effective words/s\n",
      "2023-12-06 15:18:09,402 : INFO : EPOCH 18: training on 99524 raw words (60453 effective words) took 0.3s, 241513 effective words/s\n",
      "2023-12-06 15:18:09,660 : INFO : EPOCH 19: training on 99524 raw words (60380 effective words) took 0.3s, 238372 effective words/s\n",
      "2023-12-06 15:18:09,916 : INFO : EPOCH 20: training on 99524 raw words (60409 effective words) took 0.3s, 240215 effective words/s\n",
      "2023-12-06 15:18:10,181 : INFO : EPOCH 21: training on 99524 raw words (60550 effective words) took 0.3s, 232668 effective words/s\n",
      "2023-12-06 15:18:10,435 : INFO : EPOCH 22: training on 99524 raw words (60407 effective words) took 0.2s, 241917 effective words/s\n",
      "2023-12-06 15:18:10,687 : INFO : EPOCH 23: training on 99524 raw words (60276 effective words) took 0.2s, 244213 effective words/s\n",
      "2023-12-06 15:18:10,939 : INFO : EPOCH 24: training on 99524 raw words (60308 effective words) took 0.2s, 242765 effective words/s\n",
      "2023-12-06 15:18:11,193 : INFO : EPOCH 25: training on 99524 raw words (60372 effective words) took 0.2s, 242320 effective words/s\n",
      "2023-12-06 15:18:11,445 : INFO : EPOCH 26: training on 99524 raw words (60463 effective words) took 0.2s, 244382 effective words/s\n",
      "2023-12-06 15:18:11,708 : INFO : EPOCH 27: training on 99524 raw words (60354 effective words) took 0.3s, 237162 effective words/s\n",
      "2023-12-06 15:18:11,965 : INFO : EPOCH 28: training on 99524 raw words (60458 effective words) took 0.3s, 239592 effective words/s\n",
      "2023-12-06 15:18:12,219 : INFO : EPOCH 29: training on 99524 raw words (60420 effective words) took 0.3s, 241589 effective words/s\n",
      "2023-12-06 15:18:12,476 : INFO : EPOCH 30: training on 99524 raw words (60395 effective words) took 0.3s, 239364 effective words/s\n",
      "2023-12-06 15:18:12,740 : INFO : EPOCH 31: training on 99524 raw words (60266 effective words) took 0.3s, 232437 effective words/s\n",
      "2023-12-06 15:18:13,002 : INFO : EPOCH 32: training on 99524 raw words (60385 effective words) took 0.3s, 235188 effective words/s\n",
      "2023-12-06 15:18:13,256 : INFO : EPOCH 33: training on 99524 raw words (60338 effective words) took 0.2s, 241507 effective words/s\n",
      "2023-12-06 15:18:13,507 : INFO : EPOCH 34: training on 99524 raw words (60493 effective words) took 0.2s, 245707 effective words/s\n",
      "2023-12-06 15:18:13,756 : INFO : EPOCH 35: training on 99524 raw words (60485 effective words) took 0.2s, 247019 effective words/s\n",
      "2023-12-06 15:18:14,014 : INFO : EPOCH 36: training on 99524 raw words (60361 effective words) took 0.3s, 239369 effective words/s\n",
      "2023-12-06 15:18:14,264 : INFO : EPOCH 37: training on 99524 raw words (60375 effective words) took 0.2s, 245012 effective words/s\n",
      "2023-12-06 15:18:14,542 : INFO : EPOCH 38: training on 99524 raw words (60328 effective words) took 0.3s, 220792 effective words/s\n",
      "2023-12-06 15:18:14,795 : INFO : EPOCH 39: training on 99524 raw words (60426 effective words) took 0.2s, 243664 effective words/s\n",
      "2023-12-06 15:18:15,043 : INFO : EPOCH 40: training on 99524 raw words (60427 effective words) took 0.2s, 248025 effective words/s\n",
      "2023-12-06 15:18:15,299 : INFO : EPOCH 41: training on 99524 raw words (60340 effective words) took 0.3s, 240783 effective words/s\n",
      "2023-12-06 15:18:15,547 : INFO : EPOCH 42: training on 99524 raw words (60557 effective words) took 0.2s, 247854 effective words/s\n",
      "2023-12-06 15:18:15,807 : INFO : EPOCH 43: training on 99524 raw words (60368 effective words) took 0.3s, 236210 effective words/s\n",
      "2023-12-06 15:18:16,059 : INFO : EPOCH 44: training on 99524 raw words (60359 effective words) took 0.2s, 243780 effective words/s\n",
      "2023-12-06 15:18:16,314 : INFO : EPOCH 45: training on 99524 raw words (60357 effective words) took 0.2s, 241777 effective words/s\n",
      "2023-12-06 15:18:16,571 : INFO : EPOCH 46: training on 99524 raw words (60393 effective words) took 0.3s, 239161 effective words/s\n",
      "2023-12-06 15:18:16,830 : INFO : EPOCH 47: training on 99524 raw words (60300 effective words) took 0.3s, 237657 effective words/s\n",
      "2023-12-06 15:18:17,091 : INFO : EPOCH 48: training on 99524 raw words (60313 effective words) took 0.3s, 234523 effective words/s\n",
      "2023-12-06 15:18:17,358 : INFO : EPOCH 49: training on 99524 raw words (60300 effective words) took 0.3s, 231495 effective words/s\n",
      "2023-12-06 15:18:17,359 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3018935 effective words) took 12.9s, 234791 effective words/s', 'datetime': '2023-12-06T15:18:17.359609', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:18:17,360 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n5,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:18:17.360616', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 83%| | 403/486 [1:04:40<17:47, 12.87s/it]2023-12-06 15:18:21,514 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:18:21,514 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:18:21,536 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:18:21,537 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:18:21,541 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:18:21.541372', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:18:21,542 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:18:21.542696', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:18:21,547 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:18:21,548 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:18:21,548 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:18:21.548517', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:18:21,556 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:18:21,557 : INFO : resetting layer weights\n",
      "2023-12-06 15:18:21,561 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:18:21.561751', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:18:21,812 : INFO : EPOCH 0: training on 99524 raw words (60435 effective words) took 0.2s, 244070 effective words/s\n",
      "2023-12-06 15:18:22,127 : INFO : EPOCH 1: training on 99524 raw words (60298 effective words) took 0.3s, 197131 effective words/s\n",
      "2023-12-06 15:18:22,395 : INFO : EPOCH 2: training on 99524 raw words (60415 effective words) took 0.3s, 229665 effective words/s\n",
      "2023-12-06 15:18:22,664 : INFO : EPOCH 3: training on 99524 raw words (60431 effective words) took 0.3s, 228165 effective words/s\n",
      "2023-12-06 15:18:22,929 : INFO : EPOCH 4: training on 99524 raw words (60451 effective words) took 0.3s, 231466 effective words/s\n",
      "2023-12-06 15:18:23,196 : INFO : EPOCH 5: training on 99524 raw words (60402 effective words) took 0.3s, 229894 effective words/s\n",
      "2023-12-06 15:18:23,484 : INFO : EPOCH 6: training on 99524 raw words (60383 effective words) took 0.3s, 213439 effective words/s\n",
      "2023-12-06 15:18:23,751 : INFO : EPOCH 7: training on 99524 raw words (60170 effective words) took 0.3s, 229343 effective words/s\n",
      "2023-12-06 15:18:24,019 : INFO : EPOCH 8: training on 99524 raw words (60453 effective words) took 0.3s, 230250 effective words/s\n",
      "2023-12-06 15:18:24,282 : INFO : EPOCH 9: training on 99524 raw words (60203 effective words) took 0.3s, 232098 effective words/s\n",
      "2023-12-06 15:18:24,552 : INFO : EPOCH 10: training on 99524 raw words (60425 effective words) took 0.3s, 228026 effective words/s\n",
      "2023-12-06 15:18:24,821 : INFO : EPOCH 11: training on 99524 raw words (60224 effective words) took 0.3s, 228255 effective words/s\n",
      "2023-12-06 15:18:25,092 : INFO : EPOCH 12: training on 99524 raw words (60136 effective words) took 0.3s, 225924 effective words/s\n",
      "2023-12-06 15:18:25,369 : INFO : EPOCH 13: training on 99524 raw words (60503 effective words) took 0.3s, 221353 effective words/s\n",
      "2023-12-06 15:18:25,637 : INFO : EPOCH 14: training on 99524 raw words (60489 effective words) took 0.3s, 231005 effective words/s\n",
      "2023-12-06 15:18:25,901 : INFO : EPOCH 15: training on 99524 raw words (60475 effective words) took 0.3s, 232965 effective words/s\n",
      "2023-12-06 15:18:26,169 : INFO : EPOCH 16: training on 99524 raw words (60388 effective words) took 0.3s, 229360 effective words/s\n",
      "2023-12-06 15:18:26,451 : INFO : EPOCH 17: training on 99524 raw words (60262 effective words) took 0.3s, 217674 effective words/s\n",
      "2023-12-06 15:18:26,722 : INFO : EPOCH 18: training on 99524 raw words (60480 effective words) took 0.3s, 226553 effective words/s\n",
      "2023-12-06 15:18:26,992 : INFO : EPOCH 19: training on 99524 raw words (60448 effective words) took 0.3s, 228033 effective words/s\n",
      "2023-12-06 15:18:27,262 : INFO : EPOCH 20: training on 99524 raw words (60359 effective words) took 0.3s, 227503 effective words/s\n",
      "2023-12-06 15:18:27,530 : INFO : EPOCH 21: training on 99524 raw words (60321 effective words) took 0.3s, 227940 effective words/s\n",
      "2023-12-06 15:18:27,800 : INFO : EPOCH 22: training on 99524 raw words (60455 effective words) took 0.3s, 228545 effective words/s\n",
      "2023-12-06 15:18:28,077 : INFO : EPOCH 23: training on 99524 raw words (60352 effective words) took 0.3s, 221533 effective words/s\n",
      "2023-12-06 15:18:28,351 : INFO : EPOCH 24: training on 99524 raw words (60258 effective words) took 0.3s, 224156 effective words/s\n",
      "2023-12-06 15:18:28,623 : INFO : EPOCH 25: training on 99524 raw words (60574 effective words) took 0.3s, 227000 effective words/s\n",
      "2023-12-06 15:18:28,887 : INFO : EPOCH 26: training on 99524 raw words (60548 effective words) took 0.3s, 233049 effective words/s\n",
      "2023-12-06 15:18:29,153 : INFO : EPOCH 27: training on 99524 raw words (60320 effective words) took 0.3s, 230409 effective words/s\n",
      "2023-12-06 15:18:29,422 : INFO : EPOCH 28: training on 99524 raw words (60376 effective words) took 0.3s, 228459 effective words/s\n",
      "2023-12-06 15:18:29,683 : INFO : EPOCH 29: training on 99524 raw words (60489 effective words) took 0.3s, 235127 effective words/s\n",
      "2023-12-06 15:18:29,952 : INFO : EPOCH 30: training on 99524 raw words (60443 effective words) took 0.3s, 228335 effective words/s\n",
      "2023-12-06 15:18:30,223 : INFO : EPOCH 31: training on 99524 raw words (60277 effective words) took 0.3s, 226436 effective words/s\n",
      "2023-12-06 15:18:30,492 : INFO : EPOCH 32: training on 99524 raw words (60438 effective words) took 0.3s, 228095 effective words/s\n",
      "2023-12-06 15:18:30,756 : INFO : EPOCH 33: training on 99524 raw words (60465 effective words) took 0.3s, 233208 effective words/s\n",
      "2023-12-06 15:18:31,032 : INFO : EPOCH 34: training on 99524 raw words (60143 effective words) took 0.3s, 221159 effective words/s\n",
      "2023-12-06 15:18:31,304 : INFO : EPOCH 35: training on 99524 raw words (60330 effective words) took 0.3s, 226078 effective words/s\n",
      "2023-12-06 15:18:31,572 : INFO : EPOCH 36: training on 99524 raw words (60426 effective words) took 0.3s, 230048 effective words/s\n",
      "2023-12-06 15:18:31,845 : INFO : EPOCH 37: training on 99524 raw words (60374 effective words) took 0.3s, 224501 effective words/s\n",
      "2023-12-06 15:18:32,112 : INFO : EPOCH 38: training on 99524 raw words (60294 effective words) took 0.3s, 229633 effective words/s\n",
      "2023-12-06 15:18:32,385 : INFO : EPOCH 39: training on 99524 raw words (60459 effective words) took 0.3s, 225717 effective words/s\n",
      "2023-12-06 15:18:32,677 : INFO : EPOCH 40: training on 99524 raw words (60519 effective words) took 0.3s, 210975 effective words/s\n",
      "2023-12-06 15:18:32,946 : INFO : EPOCH 41: training on 99524 raw words (60545 effective words) took 0.3s, 228163 effective words/s\n",
      "2023-12-06 15:18:33,212 : INFO : EPOCH 42: training on 99524 raw words (60313 effective words) took 0.3s, 230875 effective words/s\n",
      "2023-12-06 15:18:33,484 : INFO : EPOCH 43: training on 99524 raw words (60232 effective words) took 0.3s, 225518 effective words/s\n",
      "2023-12-06 15:18:33,751 : INFO : EPOCH 44: training on 99524 raw words (60306 effective words) took 0.3s, 230171 effective words/s\n",
      "2023-12-06 15:18:34,020 : INFO : EPOCH 45: training on 99524 raw words (60360 effective words) took 0.3s, 228186 effective words/s\n",
      "2023-12-06 15:18:34,292 : INFO : EPOCH 46: training on 99524 raw words (60545 effective words) took 0.3s, 225699 effective words/s\n",
      "2023-12-06 15:18:34,558 : INFO : EPOCH 47: training on 99524 raw words (60273 effective words) took 0.3s, 229655 effective words/s\n",
      "2023-12-06 15:18:34,825 : INFO : EPOCH 48: training on 99524 raw words (60360 effective words) took 0.3s, 229419 effective words/s\n",
      "2023-12-06 15:18:35,096 : INFO : EPOCH 49: training on 99524 raw words (60441 effective words) took 0.3s, 227053 effective words/s\n",
      "2023-12-06 15:18:35,097 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3019066 effective words) took 13.5s, 223044 effective words/s', 'datetime': '2023-12-06T15:18:35.097648', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:18:35,098 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n10,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:18:35.098850', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 83%| | 404/486 [1:04:58<19:44, 14.44s/it]2023-12-06 15:18:39,639 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:18:39,639 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:18:39,662 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:18:39,663 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:18:39,667 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:18:39.667500', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:18:39,668 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:18:39.668500', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:18:39,673 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:18:39,673 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:18:39,674 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:18:39.674101', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:18:39,681 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:18:39,682 : INFO : resetting layer weights\n",
      "2023-12-06 15:18:39,685 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:18:39.685718', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:18:39,955 : INFO : EPOCH 0: training on 99524 raw words (60367 effective words) took 0.3s, 227626 effective words/s\n",
      "2023-12-06 15:18:40,253 : INFO : EPOCH 1: training on 99524 raw words (60619 effective words) took 0.3s, 208843 effective words/s\n",
      "2023-12-06 15:18:40,530 : INFO : EPOCH 2: training on 99524 raw words (60466 effective words) took 0.3s, 221995 effective words/s\n",
      "2023-12-06 15:18:40,797 : INFO : EPOCH 3: training on 99524 raw words (60368 effective words) took 0.3s, 229825 effective words/s\n",
      "2023-12-06 15:18:41,069 : INFO : EPOCH 4: training on 99524 raw words (60582 effective words) took 0.3s, 229812 effective words/s\n",
      "2023-12-06 15:18:41,348 : INFO : EPOCH 5: training on 99524 raw words (60479 effective words) took 0.3s, 220258 effective words/s\n",
      "2023-12-06 15:18:41,633 : INFO : EPOCH 6: training on 99524 raw words (60540 effective words) took 0.3s, 216465 effective words/s\n",
      "2023-12-06 15:18:41,923 : INFO : EPOCH 7: training on 99524 raw words (60538 effective words) took 0.3s, 212325 effective words/s\n",
      "2023-12-06 15:18:42,200 : INFO : EPOCH 8: training on 99524 raw words (60474 effective words) took 0.3s, 222273 effective words/s\n",
      "2023-12-06 15:18:42,476 : INFO : EPOCH 9: training on 99524 raw words (60199 effective words) took 0.3s, 222096 effective words/s\n",
      "2023-12-06 15:18:42,753 : INFO : EPOCH 10: training on 99524 raw words (60446 effective words) took 0.3s, 221855 effective words/s\n",
      "2023-12-06 15:18:43,036 : INFO : EPOCH 11: training on 99524 raw words (60359 effective words) took 0.3s, 216881 effective words/s\n",
      "2023-12-06 15:18:43,314 : INFO : EPOCH 12: training on 99524 raw words (60450 effective words) took 0.3s, 220183 effective words/s\n",
      "2023-12-06 15:18:43,587 : INFO : EPOCH 13: training on 99524 raw words (60190 effective words) took 0.3s, 224720 effective words/s\n",
      "2023-12-06 15:18:43,867 : INFO : EPOCH 14: training on 99524 raw words (60416 effective words) took 0.3s, 220056 effective words/s\n",
      "2023-12-06 15:18:44,139 : INFO : EPOCH 15: training on 99524 raw words (60258 effective words) took 0.3s, 225337 effective words/s\n",
      "2023-12-06 15:18:44,412 : INFO : EPOCH 16: training on 99524 raw words (60548 effective words) took 0.3s, 224834 effective words/s\n",
      "2023-12-06 15:18:44,724 : INFO : EPOCH 17: training on 99524 raw words (60412 effective words) took 0.3s, 196874 effective words/s\n",
      "2023-12-06 15:18:45,002 : INFO : EPOCH 18: training on 99524 raw words (60517 effective words) took 0.3s, 220862 effective words/s\n",
      "2023-12-06 15:18:45,275 : INFO : EPOCH 19: training on 99524 raw words (60263 effective words) took 0.3s, 223634 effective words/s\n",
      "2023-12-06 15:18:45,552 : INFO : EPOCH 20: training on 99524 raw words (60444 effective words) took 0.3s, 222335 effective words/s\n",
      "2023-12-06 15:18:45,828 : INFO : EPOCH 21: training on 99524 raw words (60403 effective words) took 0.3s, 221871 effective words/s\n",
      "2023-12-06 15:18:46,109 : INFO : EPOCH 22: training on 99524 raw words (60348 effective words) took 0.3s, 218892 effective words/s\n",
      "2023-12-06 15:18:46,389 : INFO : EPOCH 23: training on 99524 raw words (60308 effective words) took 0.3s, 219052 effective words/s\n",
      "2023-12-06 15:18:46,661 : INFO : EPOCH 24: training on 99524 raw words (60337 effective words) took 0.3s, 225344 effective words/s\n",
      "2023-12-06 15:18:46,937 : INFO : EPOCH 25: training on 99524 raw words (60407 effective words) took 0.3s, 223641 effective words/s\n",
      "2023-12-06 15:18:47,209 : INFO : EPOCH 26: training on 99524 raw words (60396 effective words) took 0.3s, 225329 effective words/s\n",
      "2023-12-06 15:18:47,483 : INFO : EPOCH 27: training on 99524 raw words (60444 effective words) took 0.3s, 223851 effective words/s\n",
      "2023-12-06 15:18:47,777 : INFO : EPOCH 28: training on 99524 raw words (60387 effective words) took 0.3s, 209229 effective words/s\n",
      "2023-12-06 15:18:48,052 : INFO : EPOCH 29: training on 99524 raw words (60367 effective words) took 0.3s, 223034 effective words/s\n",
      "2023-12-06 15:18:48,327 : INFO : EPOCH 30: training on 99524 raw words (60470 effective words) took 0.3s, 224331 effective words/s\n",
      "2023-12-06 15:18:48,604 : INFO : EPOCH 31: training on 99524 raw words (60449 effective words) took 0.3s, 221765 effective words/s\n",
      "2023-12-06 15:18:48,879 : INFO : EPOCH 32: training on 99524 raw words (60444 effective words) took 0.3s, 222788 effective words/s\n",
      "2023-12-06 15:18:49,167 : INFO : EPOCH 33: training on 99524 raw words (60395 effective words) took 0.3s, 213854 effective words/s\n",
      "2023-12-06 15:18:49,446 : INFO : EPOCH 34: training on 99524 raw words (60084 effective words) took 0.3s, 223288 effective words/s\n",
      "2023-12-06 15:18:49,716 : INFO : EPOCH 35: training on 99524 raw words (60414 effective words) took 0.3s, 227810 effective words/s\n",
      "2023-12-06 15:18:49,989 : INFO : EPOCH 36: training on 99524 raw words (60466 effective words) took 0.3s, 225168 effective words/s\n",
      "2023-12-06 15:18:50,268 : INFO : EPOCH 37: training on 99524 raw words (60362 effective words) took 0.3s, 219958 effective words/s\n",
      "2023-12-06 15:18:50,544 : INFO : EPOCH 38: training on 99524 raw words (60454 effective words) took 0.3s, 222898 effective words/s\n",
      "2023-12-06 15:18:50,815 : INFO : EPOCH 39: training on 99524 raw words (60372 effective words) took 0.3s, 226463 effective words/s\n",
      "2023-12-06 15:18:51,101 : INFO : EPOCH 40: training on 99524 raw words (60477 effective words) took 0.3s, 214209 effective words/s\n",
      "2023-12-06 15:18:51,376 : INFO : EPOCH 41: training on 99524 raw words (60508 effective words) took 0.3s, 224802 effective words/s\n",
      "2023-12-06 15:18:51,652 : INFO : EPOCH 42: training on 99524 raw words (60288 effective words) took 0.3s, 221625 effective words/s\n",
      "2023-12-06 15:18:51,931 : INFO : EPOCH 43: training on 99524 raw words (60430 effective words) took 0.3s, 221107 effective words/s\n",
      "2023-12-06 15:18:52,207 : INFO : EPOCH 44: training on 99524 raw words (60253 effective words) took 0.3s, 222288 effective words/s\n",
      "2023-12-06 15:18:52,488 : INFO : EPOCH 45: training on 99524 raw words (60384 effective words) took 0.3s, 218480 effective words/s\n",
      "2023-12-06 15:18:52,759 : INFO : EPOCH 46: training on 99524 raw words (60394 effective words) took 0.3s, 225909 effective words/s\n",
      "2023-12-06 15:18:53,033 : INFO : EPOCH 47: training on 99524 raw words (60507 effective words) took 0.3s, 224315 effective words/s\n",
      "2023-12-06 15:18:53,312 : INFO : EPOCH 48: training on 99524 raw words (60333 effective words) took 0.3s, 220830 effective words/s\n",
      "2023-12-06 15:18:53,591 : INFO : EPOCH 49: training on 99524 raw words (60432 effective words) took 0.3s, 219805 effective words/s\n",
      "2023-12-06 15:18:53,592 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3020248 effective words) took 13.9s, 217189 effective words/s', 'datetime': '2023-12-06T15:18:53.592637', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:18:53,593 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d200,n15,w10,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:18:53.593637', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 83%| | 405/486 [1:05:17<21:17, 15.77s/it]2023-12-06 15:18:58,516 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:18:58,517 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:18:58,543 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:18:58,544 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:18:58,550 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:18:58.550529', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:18:58,550 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:18:58.550529', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:18:58,561 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:18:58,561 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:18:58,562 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:18:58.562528', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:18:58,573 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:18:58,575 : INFO : resetting layer weights\n",
      "2023-12-06 15:18:58,581 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:18:58.581528', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:18:58,730 : INFO : EPOCH 0: training on 99524 raw words (65569 effective words) took 0.1s, 458365 effective words/s\n",
      "2023-12-06 15:18:58,916 : INFO : EPOCH 1: training on 99524 raw words (65630 effective words) took 0.2s, 360507 effective words/s\n",
      "2023-12-06 15:18:59,088 : INFO : EPOCH 2: training on 99524 raw words (65651 effective words) took 0.2s, 398462 effective words/s\n",
      "2023-12-06 15:18:59,252 : INFO : EPOCH 3: training on 99524 raw words (65551 effective words) took 0.2s, 412332 effective words/s\n",
      "2023-12-06 15:18:59,416 : INFO : EPOCH 4: training on 99524 raw words (65530 effective words) took 0.2s, 410860 effective words/s\n",
      "2023-12-06 15:18:59,574 : INFO : EPOCH 5: training on 99524 raw words (65476 effective words) took 0.2s, 426384 effective words/s\n",
      "2023-12-06 15:18:59,734 : INFO : EPOCH 6: training on 99524 raw words (65565 effective words) took 0.2s, 420683 effective words/s\n",
      "2023-12-06 15:18:59,919 : INFO : EPOCH 7: training on 99524 raw words (65420 effective words) took 0.2s, 361694 effective words/s\n",
      "2023-12-06 15:19:00,093 : INFO : EPOCH 8: training on 99524 raw words (65473 effective words) took 0.2s, 389991 effective words/s\n",
      "2023-12-06 15:19:00,259 : INFO : EPOCH 9: training on 99524 raw words (65514 effective words) took 0.2s, 412600 effective words/s\n",
      "2023-12-06 15:19:00,260 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655379 effective words) took 1.7s, 390523 effective words/s', 'datetime': '2023-12-06T15:19:00.260507', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:19:00,260 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:19:00.260507', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 84%| | 406/486 [1:05:21<16:33, 12.41s/it]2023-12-06 15:19:03,087 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:19:03,088 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:19:03,108 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:19:03,109 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:19:03,118 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:19:03.118488', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:19:03,119 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:19:03.119488', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:19:03,128 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:19:03,129 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:19:03,129 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:19:03.129995', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:19:03,146 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:19:03,146 : INFO : resetting layer weights\n",
      "2023-12-06 15:19:03,152 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:19:03.152662', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:19:03,304 : INFO : EPOCH 0: training on 99524 raw words (65569 effective words) took 0.1s, 445021 effective words/s\n",
      "2023-12-06 15:19:03,524 : INFO : EPOCH 1: training on 99524 raw words (65744 effective words) took 0.2s, 305835 effective words/s\n",
      "2023-12-06 15:19:03,701 : INFO : EPOCH 2: training on 99524 raw words (65692 effective words) took 0.2s, 386747 effective words/s\n",
      "2023-12-06 15:19:03,870 : INFO : EPOCH 3: training on 99524 raw words (65413 effective words) took 0.2s, 396499 effective words/s\n",
      "2023-12-06 15:19:04,038 : INFO : EPOCH 4: training on 99524 raw words (65609 effective words) took 0.2s, 398474 effective words/s\n",
      "2023-12-06 15:19:04,198 : INFO : EPOCH 5: training on 99524 raw words (65468 effective words) took 0.2s, 423458 effective words/s\n",
      "2023-12-06 15:19:04,362 : INFO : EPOCH 6: training on 99524 raw words (65515 effective words) took 0.2s, 407044 effective words/s\n",
      "2023-12-06 15:19:04,544 : INFO : EPOCH 7: training on 99524 raw words (65570 effective words) took 0.2s, 373379 effective words/s\n",
      "2023-12-06 15:19:04,714 : INFO : EPOCH 8: training on 99524 raw words (65470 effective words) took 0.2s, 396682 effective words/s\n",
      "2023-12-06 15:19:04,879 : INFO : EPOCH 9: training on 99524 raw words (65389 effective words) took 0.2s, 405644 effective words/s\n",
      "2023-12-06 15:19:04,880 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655439 effective words) took 1.7s, 379581 effective words/s', 'datetime': '2023-12-06T15:19:04.880840', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:19:04,880 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:19:04.880840', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 84%| | 407/486 [1:05:26<13:17, 10.09s/it]2023-12-06 15:19:07,761 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:19:07,762 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:19:07,783 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:19:07,785 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:19:07,790 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:19:07.790577', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:19:07,791 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:19:07.791577', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:19:07,802 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:19:07,803 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:19:07,804 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:19:07.804684', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:19:07,820 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:19:07,820 : INFO : resetting layer weights\n",
      "2023-12-06 15:19:07,825 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:19:07.825193', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:19:07,982 : INFO : EPOCH 0: training on 99524 raw words (65500 effective words) took 0.2s, 429593 effective words/s\n",
      "2023-12-06 15:19:08,179 : INFO : EPOCH 1: training on 99524 raw words (65630 effective words) took 0.2s, 340804 effective words/s\n",
      "2023-12-06 15:19:08,365 : INFO : EPOCH 2: training on 99524 raw words (65539 effective words) took 0.2s, 365629 effective words/s\n",
      "2023-12-06 15:19:08,533 : INFO : EPOCH 3: training on 99524 raw words (65513 effective words) took 0.2s, 403520 effective words/s\n",
      "2023-12-06 15:19:08,699 : INFO : EPOCH 4: training on 99524 raw words (65459 effective words) took 0.2s, 402674 effective words/s\n",
      "2023-12-06 15:19:08,868 : INFO : EPOCH 5: training on 99524 raw words (65530 effective words) took 0.2s, 400063 effective words/s\n",
      "2023-12-06 15:19:09,029 : INFO : EPOCH 6: training on 99524 raw words (65515 effective words) took 0.2s, 419895 effective words/s\n",
      "2023-12-06 15:19:09,211 : INFO : EPOCH 7: training on 99524 raw words (65441 effective words) took 0.2s, 368918 effective words/s\n",
      "2023-12-06 15:19:09,379 : INFO : EPOCH 8: training on 99524 raw words (65477 effective words) took 0.2s, 401161 effective words/s\n",
      "2023-12-06 15:19:09,538 : INFO : EPOCH 9: training on 99524 raw words (65411 effective words) took 0.2s, 423294 effective words/s\n",
      "2023-12-06 15:19:09,539 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655015 effective words) took 1.7s, 382198 effective words/s', 'datetime': '2023-12-06T15:19:09.539687', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:19:09,540 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:19:09.540717', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 84%| | 408/486 [1:05:31<11:00,  8.47s/it]2023-12-06 15:19:12,457 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:19:12,457 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:19:12,480 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:19:12,481 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:19:12,486 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:19:12.486169', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:19:12,487 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:19:12.487166', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:19:12,497 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:19:12,497 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:19:12,498 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:19:12.498743', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:19:12,510 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:19:12,510 : INFO : resetting layer weights\n",
      "2023-12-06 15:19:12,514 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:19:12.514650', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:19:12,654 : INFO : EPOCH 0: training on 99524 raw words (65495 effective words) took 0.1s, 480942 effective words/s\n",
      "2023-12-06 15:19:12,824 : INFO : EPOCH 1: training on 99524 raw words (65766 effective words) took 0.2s, 398805 effective words/s\n",
      "2023-12-06 15:19:13,023 : INFO : EPOCH 2: training on 99524 raw words (65596 effective words) took 0.2s, 346308 effective words/s\n",
      "2023-12-06 15:19:13,197 : INFO : EPOCH 3: training on 99524 raw words (65519 effective words) took 0.2s, 390461 effective words/s\n",
      "2023-12-06 15:19:13,359 : INFO : EPOCH 4: training on 99524 raw words (65439 effective words) took 0.2s, 415735 effective words/s\n",
      "2023-12-06 15:19:13,522 : INFO : EPOCH 5: training on 99524 raw words (65491 effective words) took 0.2s, 412191 effective words/s\n",
      "2023-12-06 15:19:13,686 : INFO : EPOCH 6: training on 99524 raw words (65729 effective words) took 0.2s, 414156 effective words/s\n",
      "2023-12-06 15:19:13,843 : INFO : EPOCH 7: training on 99524 raw words (65404 effective words) took 0.2s, 429437 effective words/s\n",
      "2023-12-06 15:19:14,009 : INFO : EPOCH 8: training on 99524 raw words (65630 effective words) took 0.2s, 406756 effective words/s\n",
      "2023-12-06 15:19:14,165 : INFO : EPOCH 9: training on 99524 raw words (65623 effective words) took 0.2s, 433793 effective words/s\n",
      "2023-12-06 15:19:14,327 : INFO : EPOCH 10: training on 99524 raw words (65475 effective words) took 0.2s, 413683 effective words/s\n",
      "2023-12-06 15:19:14,488 : INFO : EPOCH 11: training on 99524 raw words (65639 effective words) took 0.2s, 420838 effective words/s\n",
      "2023-12-06 15:19:14,653 : INFO : EPOCH 12: training on 99524 raw words (65402 effective words) took 0.2s, 408966 effective words/s\n",
      "2023-12-06 15:19:14,822 : INFO : EPOCH 13: training on 99524 raw words (65575 effective words) took 0.2s, 398749 effective words/s\n",
      "2023-12-06 15:19:14,988 : INFO : EPOCH 14: training on 99524 raw words (65534 effective words) took 0.2s, 409336 effective words/s\n",
      "2023-12-06 15:19:15,148 : INFO : EPOCH 15: training on 99524 raw words (65440 effective words) took 0.2s, 424188 effective words/s\n",
      "2023-12-06 15:19:15,308 : INFO : EPOCH 16: training on 99524 raw words (65424 effective words) took 0.2s, 420318 effective words/s\n",
      "2023-12-06 15:19:15,466 : INFO : EPOCH 17: training on 99524 raw words (65409 effective words) took 0.2s, 426723 effective words/s\n",
      "2023-12-06 15:19:15,626 : INFO : EPOCH 18: training on 99524 raw words (65509 effective words) took 0.2s, 419109 effective words/s\n",
      "2023-12-06 15:19:15,803 : INFO : EPOCH 19: training on 99524 raw words (65539 effective words) took 0.2s, 379039 effective words/s\n",
      "2023-12-06 15:19:15,967 : INFO : EPOCH 20: training on 99524 raw words (65581 effective words) took 0.2s, 412768 effective words/s\n",
      "2023-12-06 15:19:16,128 : INFO : EPOCH 21: training on 99524 raw words (65573 effective words) took 0.2s, 420634 effective words/s\n",
      "2023-12-06 15:19:16,288 : INFO : EPOCH 22: training on 99524 raw words (65446 effective words) took 0.2s, 422354 effective words/s\n",
      "2023-12-06 15:19:16,450 : INFO : EPOCH 23: training on 99524 raw words (65494 effective words) took 0.2s, 417403 effective words/s\n",
      "2023-12-06 15:19:16,613 : INFO : EPOCH 24: training on 99524 raw words (65515 effective words) took 0.2s, 410087 effective words/s\n",
      "2023-12-06 15:19:16,787 : INFO : EPOCH 25: training on 99524 raw words (65522 effective words) took 0.2s, 386986 effective words/s\n",
      "2023-12-06 15:19:16,951 : INFO : EPOCH 26: training on 99524 raw words (65554 effective words) took 0.2s, 411118 effective words/s\n",
      "2023-12-06 15:19:17,115 : INFO : EPOCH 27: training on 99524 raw words (65614 effective words) took 0.2s, 414833 effective words/s\n",
      "2023-12-06 15:19:17,277 : INFO : EPOCH 28: training on 99524 raw words (65452 effective words) took 0.2s, 414488 effective words/s\n",
      "2023-12-06 15:19:17,441 : INFO : EPOCH 29: training on 99524 raw words (65507 effective words) took 0.2s, 410777 effective words/s\n",
      "2023-12-06 15:19:17,441 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965896 effective words) took 4.9s, 399083 effective words/s', 'datetime': '2023-12-06T15:19:17.441463', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:19:17,442 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:19:17.442463', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 84%| | 409/486 [1:05:39<10:43,  8.36s/it]2023-12-06 15:19:20,551 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:19:20,552 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:19:20,578 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:19:20,579 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:19:20,587 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:19:20.587781', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:19:20,588 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:19:20.588784', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:19:20,595 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:19:20,596 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:19:20,597 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:19:20.597842', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:19:20,608 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:19:20,608 : INFO : resetting layer weights\n",
      "2023-12-06 15:19:20,615 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:19:20.615273', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:19:20,774 : INFO : EPOCH 0: training on 99524 raw words (65399 effective words) took 0.2s, 421244 effective words/s\n",
      "2023-12-06 15:19:20,994 : INFO : EPOCH 1: training on 99524 raw words (65602 effective words) took 0.2s, 307780 effective words/s\n",
      "2023-12-06 15:19:21,168 : INFO : EPOCH 2: training on 99524 raw words (65509 effective words) took 0.2s, 391365 effective words/s\n",
      "2023-12-06 15:19:21,336 : INFO : EPOCH 3: training on 99524 raw words (65668 effective words) took 0.2s, 403485 effective words/s\n",
      "2023-12-06 15:19:21,504 : INFO : EPOCH 4: training on 99524 raw words (65570 effective words) took 0.2s, 403531 effective words/s\n",
      "2023-12-06 15:19:21,669 : INFO : EPOCH 5: training on 99524 raw words (65532 effective words) took 0.2s, 405899 effective words/s\n",
      "2023-12-06 15:19:21,835 : INFO : EPOCH 6: training on 99524 raw words (65412 effective words) took 0.2s, 405387 effective words/s\n",
      "2023-12-06 15:19:22,015 : INFO : EPOCH 7: training on 99524 raw words (65661 effective words) took 0.2s, 374302 effective words/s\n",
      "2023-12-06 15:19:22,180 : INFO : EPOCH 8: training on 99524 raw words (65548 effective words) took 0.2s, 409624 effective words/s\n",
      "2023-12-06 15:19:22,346 : INFO : EPOCH 9: training on 99524 raw words (65536 effective words) took 0.2s, 405647 effective words/s\n",
      "2023-12-06 15:19:22,506 : INFO : EPOCH 10: training on 99524 raw words (65541 effective words) took 0.2s, 422512 effective words/s\n",
      "2023-12-06 15:19:22,673 : INFO : EPOCH 11: training on 99524 raw words (65672 effective words) took 0.2s, 406730 effective words/s\n",
      "2023-12-06 15:19:22,838 : INFO : EPOCH 12: training on 99524 raw words (65484 effective words) took 0.2s, 406157 effective words/s\n",
      "2023-12-06 15:19:23,012 : INFO : EPOCH 13: training on 99524 raw words (65631 effective words) took 0.2s, 387225 effective words/s\n",
      "2023-12-06 15:19:23,179 : INFO : EPOCH 14: training on 99524 raw words (65578 effective words) took 0.2s, 404263 effective words/s\n",
      "2023-12-06 15:19:23,344 : INFO : EPOCH 15: training on 99524 raw words (65504 effective words) took 0.2s, 407078 effective words/s\n",
      "2023-12-06 15:19:23,511 : INFO : EPOCH 16: training on 99524 raw words (65479 effective words) took 0.2s, 403289 effective words/s\n",
      "2023-12-06 15:19:23,678 : INFO : EPOCH 17: training on 99524 raw words (65512 effective words) took 0.2s, 403378 effective words/s\n",
      "2023-12-06 15:19:23,844 : INFO : EPOCH 18: training on 99524 raw words (65382 effective words) took 0.2s, 405941 effective words/s\n",
      "2023-12-06 15:19:24,031 : INFO : EPOCH 19: training on 99524 raw words (65549 effective words) took 0.2s, 358630 effective words/s\n",
      "2023-12-06 15:19:24,197 : INFO : EPOCH 20: training on 99524 raw words (65498 effective words) took 0.2s, 407949 effective words/s\n",
      "2023-12-06 15:19:24,362 : INFO : EPOCH 21: training on 99524 raw words (65503 effective words) took 0.2s, 407483 effective words/s\n",
      "2023-12-06 15:19:24,527 : INFO : EPOCH 22: training on 99524 raw words (65647 effective words) took 0.2s, 410924 effective words/s\n",
      "2023-12-06 15:19:24,694 : INFO : EPOCH 23: training on 99524 raw words (65700 effective words) took 0.2s, 407154 effective words/s\n",
      "2023-12-06 15:19:24,861 : INFO : EPOCH 24: training on 99524 raw words (65597 effective words) took 0.2s, 401735 effective words/s\n",
      "2023-12-06 15:19:25,048 : INFO : EPOCH 25: training on 99524 raw words (65699 effective words) took 0.2s, 361452 effective words/s\n",
      "2023-12-06 15:19:25,216 : INFO : EPOCH 26: training on 99524 raw words (65656 effective words) took 0.2s, 399224 effective words/s\n",
      "2023-12-06 15:19:25,383 : INFO : EPOCH 27: training on 99524 raw words (65619 effective words) took 0.2s, 404709 effective words/s\n",
      "2023-12-06 15:19:25,556 : INFO : EPOCH 28: training on 99524 raw words (65514 effective words) took 0.2s, 390301 effective words/s\n",
      "2023-12-06 15:19:25,723 : INFO : EPOCH 29: training on 99524 raw words (65560 effective words) took 0.2s, 404338 effective words/s\n",
      "2023-12-06 15:19:25,724 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1966762 effective words) took 5.1s, 385042 effective words/s', 'datetime': '2023-12-06T15:19:25.724142', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:19:25,725 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:19:25.725141', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 84%| | 410/486 [1:05:47<10:39,  8.41s/it]2023-12-06 15:19:29,084 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:19:29,085 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:19:29,107 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:19:29,108 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:19:29,116 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:19:29.116855', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:19:29,117 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:19:29.117861', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:19:29,127 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:19:29,127 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:19:29,128 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:19:29.128864', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:19:29,140 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:19:29,141 : INFO : resetting layer weights\n",
      "2023-12-06 15:19:29,144 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:19:29.144941', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:19:29,303 : INFO : EPOCH 0: training on 99524 raw words (65462 effective words) took 0.2s, 425358 effective words/s\n",
      "2023-12-06 15:19:29,494 : INFO : EPOCH 1: training on 99524 raw words (65609 effective words) took 0.2s, 352531 effective words/s\n",
      "2023-12-06 15:19:29,674 : INFO : EPOCH 2: training on 99524 raw words (65579 effective words) took 0.2s, 382476 effective words/s\n",
      "2023-12-06 15:19:29,834 : INFO : EPOCH 3: training on 99524 raw words (65568 effective words) took 0.2s, 424142 effective words/s\n",
      "2023-12-06 15:19:29,998 : INFO : EPOCH 4: training on 99524 raw words (65607 effective words) took 0.2s, 410554 effective words/s\n",
      "2023-12-06 15:19:30,159 : INFO : EPOCH 5: training on 99524 raw words (65445 effective words) took 0.2s, 419078 effective words/s\n",
      "2023-12-06 15:19:30,317 : INFO : EPOCH 6: training on 99524 raw words (65468 effective words) took 0.2s, 426780 effective words/s\n",
      "2023-12-06 15:19:30,513 : INFO : EPOCH 7: training on 99524 raw words (65407 effective words) took 0.2s, 342560 effective words/s\n",
      "2023-12-06 15:19:30,672 : INFO : EPOCH 8: training on 99524 raw words (65634 effective words) took 0.2s, 423424 effective words/s\n",
      "2023-12-06 15:19:30,832 : INFO : EPOCH 9: training on 99524 raw words (65501 effective words) took 0.2s, 422022 effective words/s\n",
      "2023-12-06 15:19:31,001 : INFO : EPOCH 10: training on 99524 raw words (65409 effective words) took 0.2s, 398452 effective words/s\n",
      "2023-12-06 15:19:31,160 : INFO : EPOCH 11: training on 99524 raw words (65576 effective words) took 0.2s, 423260 effective words/s\n",
      "2023-12-06 15:19:31,327 : INFO : EPOCH 12: training on 99524 raw words (65573 effective words) took 0.2s, 404765 effective words/s\n",
      "2023-12-06 15:19:31,501 : INFO : EPOCH 13: training on 99524 raw words (65360 effective words) took 0.2s, 385995 effective words/s\n",
      "2023-12-06 15:19:31,667 : INFO : EPOCH 14: training on 99524 raw words (65538 effective words) took 0.2s, 406047 effective words/s\n",
      "2023-12-06 15:19:31,833 : INFO : EPOCH 15: training on 99524 raw words (65534 effective words) took 0.2s, 405165 effective words/s\n",
      "2023-12-06 15:19:31,992 : INFO : EPOCH 16: training on 99524 raw words (65441 effective words) took 0.2s, 421651 effective words/s\n",
      "2023-12-06 15:19:32,160 : INFO : EPOCH 17: training on 99524 raw words (65444 effective words) took 0.2s, 403139 effective words/s\n",
      "2023-12-06 15:19:32,327 : INFO : EPOCH 18: training on 99524 raw words (65437 effective words) took 0.2s, 403752 effective words/s\n",
      "2023-12-06 15:19:32,514 : INFO : EPOCH 19: training on 99524 raw words (65653 effective words) took 0.2s, 360915 effective words/s\n",
      "2023-12-06 15:19:32,681 : INFO : EPOCH 20: training on 99524 raw words (65348 effective words) took 0.2s, 400488 effective words/s\n",
      "2023-12-06 15:19:32,847 : INFO : EPOCH 21: training on 99524 raw words (65532 effective words) took 0.2s, 404146 effective words/s\n",
      "2023-12-06 15:19:33,016 : INFO : EPOCH 22: training on 99524 raw words (65618 effective words) took 0.2s, 402680 effective words/s\n",
      "2023-12-06 15:19:33,185 : INFO : EPOCH 23: training on 99524 raw words (65635 effective words) took 0.2s, 399067 effective words/s\n",
      "2023-12-06 15:19:33,350 : INFO : EPOCH 24: training on 99524 raw words (65647 effective words) took 0.2s, 407508 effective words/s\n",
      "2023-12-06 15:19:33,535 : INFO : EPOCH 25: training on 99524 raw words (65595 effective words) took 0.2s, 367564 effective words/s\n",
      "2023-12-06 15:19:33,704 : INFO : EPOCH 26: training on 99524 raw words (65618 effective words) took 0.2s, 398338 effective words/s\n",
      "2023-12-06 15:19:33,864 : INFO : EPOCH 27: training on 99524 raw words (65769 effective words) took 0.2s, 425083 effective words/s\n",
      "2023-12-06 15:19:34,030 : INFO : EPOCH 28: training on 99524 raw words (65521 effective words) took 0.2s, 404559 effective words/s\n",
      "2023-12-06 15:19:34,197 : INFO : EPOCH 29: training on 99524 raw words (65579 effective words) took 0.2s, 402708 effective words/s\n",
      "2023-12-06 15:19:34,198 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1966107 effective words) took 5.1s, 389130 effective words/s', 'datetime': '2023-12-06T15:19:34.198574', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:19:34,198 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:19:34.198574', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 85%| | 411/486 [1:05:56<10:36,  8.49s/it]2023-12-06 15:19:37,768 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:19:37,769 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:19:37,796 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:19:37,797 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:19:37,803 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:19:37.803528', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:19:37,804 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:19:37.804533', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:19:37,813 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:19:37,813 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:19:37,813 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:19:37.813697', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:19:37,824 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:19:37,825 : INFO : resetting layer weights\n",
      "2023-12-06 15:19:37,831 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:19:37.831238', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:19:37,975 : INFO : EPOCH 0: training on 99524 raw words (65527 effective words) took 0.1s, 469116 effective words/s\n",
      "2023-12-06 15:19:38,146 : INFO : EPOCH 1: training on 99524 raw words (65632 effective words) took 0.2s, 395878 effective words/s\n",
      "2023-12-06 15:19:38,323 : INFO : EPOCH 2: training on 99524 raw words (65676 effective words) took 0.2s, 385866 effective words/s\n",
      "2023-12-06 15:19:38,488 : INFO : EPOCH 3: training on 99524 raw words (65531 effective words) took 0.2s, 410266 effective words/s\n",
      "2023-12-06 15:19:38,650 : INFO : EPOCH 4: training on 99524 raw words (65762 effective words) took 0.2s, 417569 effective words/s\n",
      "2023-12-06 15:19:38,814 : INFO : EPOCH 5: training on 99524 raw words (65398 effective words) took 0.2s, 406521 effective words/s\n",
      "2023-12-06 15:19:38,986 : INFO : EPOCH 6: training on 99524 raw words (65492 effective words) took 0.2s, 394815 effective words/s\n",
      "2023-12-06 15:19:39,153 : INFO : EPOCH 7: training on 99524 raw words (65553 effective words) took 0.2s, 401835 effective words/s\n",
      "2023-12-06 15:19:39,325 : INFO : EPOCH 8: training on 99524 raw words (65593 effective words) took 0.2s, 395466 effective words/s\n",
      "2023-12-06 15:19:39,495 : INFO : EPOCH 9: training on 99524 raw words (65642 effective words) took 0.2s, 400579 effective words/s\n",
      "2023-12-06 15:19:39,658 : INFO : EPOCH 10: training on 99524 raw words (65482 effective words) took 0.2s, 411253 effective words/s\n",
      "2023-12-06 15:19:39,821 : INFO : EPOCH 11: training on 99524 raw words (65712 effective words) took 0.2s, 415595 effective words/s\n",
      "2023-12-06 15:19:39,987 : INFO : EPOCH 12: training on 99524 raw words (65690 effective words) took 0.2s, 408196 effective words/s\n",
      "2023-12-06 15:19:40,167 : INFO : EPOCH 13: training on 99524 raw words (65416 effective words) took 0.2s, 372703 effective words/s\n",
      "2023-12-06 15:19:40,335 : INFO : EPOCH 14: training on 99524 raw words (65607 effective words) took 0.2s, 402861 effective words/s\n",
      "2023-12-06 15:19:40,502 : INFO : EPOCH 15: training on 99524 raw words (65608 effective words) took 0.2s, 405079 effective words/s\n",
      "2023-12-06 15:19:40,669 : INFO : EPOCH 16: training on 99524 raw words (65573 effective words) took 0.2s, 405420 effective words/s\n",
      "2023-12-06 15:19:40,835 : INFO : EPOCH 17: training on 99524 raw words (65501 effective words) took 0.2s, 406647 effective words/s\n",
      "2023-12-06 15:19:40,995 : INFO : EPOCH 18: training on 99524 raw words (65559 effective words) took 0.2s, 421759 effective words/s\n",
      "2023-12-06 15:19:41,161 : INFO : EPOCH 19: training on 99524 raw words (65577 effective words) took 0.2s, 406017 effective words/s\n",
      "2023-12-06 15:19:41,327 : INFO : EPOCH 20: training on 99524 raw words (65535 effective words) took 0.2s, 405587 effective words/s\n",
      "2023-12-06 15:19:41,497 : INFO : EPOCH 21: training on 99524 raw words (65582 effective words) took 0.2s, 396994 effective words/s\n",
      "2023-12-06 15:19:41,667 : INFO : EPOCH 22: training on 99524 raw words (65633 effective words) took 0.2s, 396705 effective words/s\n",
      "2023-12-06 15:19:41,831 : INFO : EPOCH 23: training on 99524 raw words (65607 effective words) took 0.2s, 411275 effective words/s\n",
      "2023-12-06 15:19:41,995 : INFO : EPOCH 24: training on 99524 raw words (65761 effective words) took 0.2s, 412160 effective words/s\n",
      "2023-12-06 15:19:42,169 : INFO : EPOCH 25: training on 99524 raw words (65383 effective words) took 0.2s, 388392 effective words/s\n",
      "2023-12-06 15:19:42,331 : INFO : EPOCH 26: training on 99524 raw words (65784 effective words) took 0.2s, 417785 effective words/s\n",
      "2023-12-06 15:19:42,492 : INFO : EPOCH 27: training on 99524 raw words (65724 effective words) took 0.2s, 420487 effective words/s\n",
      "2023-12-06 15:19:42,654 : INFO : EPOCH 28: training on 99524 raw words (65452 effective words) took 0.2s, 412031 effective words/s\n",
      "2023-12-06 15:19:42,826 : INFO : EPOCH 29: training on 99524 raw words (65819 effective words) took 0.2s, 393879 effective words/s\n",
      "2023-12-06 15:19:42,990 : INFO : EPOCH 30: training on 99524 raw words (65490 effective words) took 0.2s, 412947 effective words/s\n",
      "2023-12-06 15:19:43,163 : INFO : EPOCH 31: training on 99524 raw words (65418 effective words) took 0.2s, 393348 effective words/s\n",
      "2023-12-06 15:19:43,323 : INFO : EPOCH 32: training on 99524 raw words (65641 effective words) took 0.2s, 420399 effective words/s\n",
      "2023-12-06 15:19:43,483 : INFO : EPOCH 33: training on 99524 raw words (65663 effective words) took 0.2s, 423131 effective words/s\n",
      "2023-12-06 15:19:43,644 : INFO : EPOCH 34: training on 99524 raw words (65424 effective words) took 0.2s, 419832 effective words/s\n",
      "2023-12-06 15:19:43,809 : INFO : EPOCH 35: training on 99524 raw words (65561 effective words) took 0.2s, 408475 effective words/s\n",
      "2023-12-06 15:19:43,972 : INFO : EPOCH 36: training on 99524 raw words (65495 effective words) took 0.2s, 414104 effective words/s\n",
      "2023-12-06 15:19:44,147 : INFO : EPOCH 37: training on 99524 raw words (65368 effective words) took 0.2s, 385201 effective words/s\n",
      "2023-12-06 15:19:44,314 : INFO : EPOCH 38: training on 99524 raw words (65456 effective words) took 0.2s, 401010 effective words/s\n",
      "2023-12-06 15:19:44,479 : INFO : EPOCH 39: training on 99524 raw words (65488 effective words) took 0.2s, 408311 effective words/s\n",
      "2023-12-06 15:19:44,642 : INFO : EPOCH 40: training on 99524 raw words (65471 effective words) took 0.2s, 414847 effective words/s\n",
      "2023-12-06 15:19:44,809 : INFO : EPOCH 41: training on 99524 raw words (65588 effective words) took 0.2s, 402414 effective words/s\n",
      "2023-12-06 15:19:44,970 : INFO : EPOCH 42: training on 99524 raw words (65535 effective words) took 0.2s, 418538 effective words/s\n",
      "2023-12-06 15:19:45,147 : INFO : EPOCH 43: training on 99524 raw words (65533 effective words) took 0.2s, 380204 effective words/s\n",
      "2023-12-06 15:19:45,309 : INFO : EPOCH 44: training on 99524 raw words (65567 effective words) took 0.2s, 417107 effective words/s\n",
      "2023-12-06 15:19:45,470 : INFO : EPOCH 45: training on 99524 raw words (65475 effective words) took 0.2s, 418968 effective words/s\n",
      "2023-12-06 15:19:45,632 : INFO : EPOCH 46: training on 99524 raw words (65613 effective words) took 0.2s, 414989 effective words/s\n",
      "2023-12-06 15:19:45,799 : INFO : EPOCH 47: training on 99524 raw words (65532 effective words) took 0.2s, 405520 effective words/s\n",
      "2023-12-06 15:19:45,958 : INFO : EPOCH 48: training on 99524 raw words (65569 effective words) took 0.2s, 423856 effective words/s\n",
      "2023-12-06 15:19:46,130 : INFO : EPOCH 49: training on 99524 raw words (65474 effective words) took 0.2s, 393766 effective words/s\n",
      "2023-12-06 15:19:46,131 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3278172 effective words) took 8.3s, 394977 effective words/s', 'datetime': '2023-12-06T15:19:46.131609', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:19:46,132 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:19:46.132608', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 85%| | 412/486 [1:06:08<11:43,  9.51s/it]2023-12-06 15:19:49,640 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:19:49,641 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:19:49,663 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:19:49,664 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:19:49,672 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:19:49.672627', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:19:49,673 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:19:49.673627', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:19:49,684 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:19:49,684 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:19:49,685 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:19:49.685220', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:19:49,695 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:19:49,696 : INFO : resetting layer weights\n",
      "2023-12-06 15:19:49,704 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:19:49.704266', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:19:49,853 : INFO : EPOCH 0: training on 99524 raw words (65418 effective words) took 0.1s, 449319 effective words/s\n",
      "2023-12-06 15:19:50,033 : INFO : EPOCH 1: training on 99524 raw words (65550 effective words) took 0.2s, 373291 effective words/s\n",
      "2023-12-06 15:19:50,218 : INFO : EPOCH 2: training on 99524 raw words (65572 effective words) took 0.2s, 369265 effective words/s\n",
      "2023-12-06 15:19:50,378 : INFO : EPOCH 3: training on 99524 raw words (65631 effective words) took 0.2s, 424644 effective words/s\n",
      "2023-12-06 15:19:50,536 : INFO : EPOCH 4: training on 99524 raw words (65495 effective words) took 0.2s, 425098 effective words/s\n",
      "2023-12-06 15:19:50,695 : INFO : EPOCH 5: training on 99524 raw words (65416 effective words) took 0.2s, 425413 effective words/s\n",
      "2023-12-06 15:19:50,867 : INFO : EPOCH 6: training on 99524 raw words (65631 effective words) took 0.2s, 391408 effective words/s\n",
      "2023-12-06 15:19:51,069 : INFO : EPOCH 7: training on 99524 raw words (65558 effective words) took 0.2s, 333358 effective words/s\n",
      "2023-12-06 15:19:51,235 : INFO : EPOCH 8: training on 99524 raw words (65472 effective words) took 0.2s, 403851 effective words/s\n",
      "2023-12-06 15:19:51,407 : INFO : EPOCH 9: training on 99524 raw words (65606 effective words) took 0.2s, 394789 effective words/s\n",
      "2023-12-06 15:19:51,575 : INFO : EPOCH 10: training on 99524 raw words (65376 effective words) took 0.2s, 397492 effective words/s\n",
      "2023-12-06 15:19:51,740 : INFO : EPOCH 11: training on 99524 raw words (65680 effective words) took 0.2s, 412479 effective words/s\n",
      "2023-12-06 15:19:51,915 : INFO : EPOCH 12: training on 99524 raw words (65357 effective words) took 0.2s, 384633 effective words/s\n",
      "2023-12-06 15:19:52,086 : INFO : EPOCH 13: training on 99524 raw words (65504 effective words) took 0.2s, 396841 effective words/s\n",
      "2023-12-06 15:19:52,251 : INFO : EPOCH 14: training on 99524 raw words (65598 effective words) took 0.2s, 407803 effective words/s\n",
      "2023-12-06 15:19:52,422 : INFO : EPOCH 15: training on 99524 raw words (65575 effective words) took 0.2s, 397763 effective words/s\n",
      "2023-12-06 15:19:52,595 : INFO : EPOCH 16: training on 99524 raw words (65298 effective words) took 0.2s, 386176 effective words/s\n",
      "2023-12-06 15:19:52,770 : INFO : EPOCH 17: training on 99524 raw words (65536 effective words) took 0.2s, 387461 effective words/s\n",
      "2023-12-06 15:19:52,952 : INFO : EPOCH 18: training on 99524 raw words (65426 effective words) took 0.2s, 371716 effective words/s\n",
      "2023-12-06 15:19:53,121 : INFO : EPOCH 19: training on 99524 raw words (65659 effective words) took 0.2s, 399248 effective words/s\n",
      "2023-12-06 15:19:53,287 : INFO : EPOCH 20: training on 99524 raw words (65536 effective words) took 0.2s, 407257 effective words/s\n",
      "2023-12-06 15:19:53,455 : INFO : EPOCH 21: training on 99524 raw words (65544 effective words) took 0.2s, 399280 effective words/s\n",
      "2023-12-06 15:19:53,622 : INFO : EPOCH 22: training on 99524 raw words (65613 effective words) took 0.2s, 404395 effective words/s\n",
      "2023-12-06 15:19:53,790 : INFO : EPOCH 23: training on 99524 raw words (65536 effective words) took 0.2s, 400987 effective words/s\n",
      "2023-12-06 15:19:53,967 : INFO : EPOCH 24: training on 99524 raw words (65678 effective words) took 0.2s, 381739 effective words/s\n",
      "2023-12-06 15:19:54,133 : INFO : EPOCH 25: training on 99524 raw words (65580 effective words) took 0.2s, 405457 effective words/s\n",
      "2023-12-06 15:19:54,294 : INFO : EPOCH 26: training on 99524 raw words (65769 effective words) took 0.2s, 421914 effective words/s\n",
      "2023-12-06 15:19:54,461 : INFO : EPOCH 27: training on 99524 raw words (65599 effective words) took 0.2s, 401043 effective words/s\n",
      "2023-12-06 15:19:54,627 : INFO : EPOCH 28: training on 99524 raw words (65454 effective words) took 0.2s, 408814 effective words/s\n",
      "2023-12-06 15:19:54,792 : INFO : EPOCH 29: training on 99524 raw words (65428 effective words) took 0.2s, 406923 effective words/s\n",
      "2023-12-06 15:19:54,987 : INFO : EPOCH 30: training on 99524 raw words (65485 effective words) took 0.2s, 343186 effective words/s\n",
      "2023-12-06 15:19:55,155 : INFO : EPOCH 31: training on 99524 raw words (65384 effective words) took 0.2s, 399543 effective words/s\n",
      "2023-12-06 15:19:55,322 : INFO : EPOCH 32: training on 99524 raw words (65403 effective words) took 0.2s, 403910 effective words/s\n",
      "2023-12-06 15:19:55,490 : INFO : EPOCH 33: training on 99524 raw words (65573 effective words) took 0.2s, 399860 effective words/s\n",
      "2023-12-06 15:19:55,655 : INFO : EPOCH 34: training on 99524 raw words (65699 effective words) took 0.2s, 409505 effective words/s\n",
      "2023-12-06 15:19:55,821 : INFO : EPOCH 35: training on 99524 raw words (65670 effective words) took 0.2s, 407272 effective words/s\n",
      "2023-12-06 15:19:56,022 : INFO : EPOCH 36: training on 99524 raw words (65501 effective words) took 0.2s, 335159 effective words/s\n",
      "2023-12-06 15:19:56,187 : INFO : EPOCH 37: training on 99524 raw words (65272 effective words) took 0.2s, 404428 effective words/s\n",
      "2023-12-06 15:19:56,354 : INFO : EPOCH 38: training on 99524 raw words (65618 effective words) took 0.2s, 405553 effective words/s\n",
      "2023-12-06 15:19:56,524 : INFO : EPOCH 39: training on 99524 raw words (65299 effective words) took 0.2s, 394423 effective words/s\n",
      "2023-12-06 15:19:56,693 : INFO : EPOCH 40: training on 99524 raw words (65473 effective words) took 0.2s, 396701 effective words/s\n",
      "2023-12-06 15:19:56,861 : INFO : EPOCH 41: training on 99524 raw words (65661 effective words) took 0.2s, 404317 effective words/s\n",
      "2023-12-06 15:19:57,052 : INFO : EPOCH 42: training on 99524 raw words (65636 effective words) took 0.2s, 351707 effective words/s\n",
      "2023-12-06 15:19:57,218 : INFO : EPOCH 43: training on 99524 raw words (65517 effective words) took 0.2s, 405818 effective words/s\n",
      "2023-12-06 15:19:57,384 : INFO : EPOCH 44: training on 99524 raw words (65305 effective words) took 0.2s, 403716 effective words/s\n",
      "2023-12-06 15:19:57,553 : INFO : EPOCH 45: training on 99524 raw words (65521 effective words) took 0.2s, 400071 effective words/s\n",
      "2023-12-06 15:19:57,720 : INFO : EPOCH 46: training on 99524 raw words (65591 effective words) took 0.2s, 403379 effective words/s\n",
      "2023-12-06 15:19:57,888 : INFO : EPOCH 47: training on 99524 raw words (65466 effective words) took 0.2s, 401745 effective words/s\n",
      "2023-12-06 15:19:58,074 : INFO : EPOCH 48: training on 99524 raw words (65519 effective words) took 0.2s, 360298 effective words/s\n",
      "2023-12-06 15:19:58,239 : INFO : EPOCH 49: training on 99524 raw words (65550 effective words) took 0.2s, 408519 effective words/s\n",
      "2023-12-06 15:19:58,240 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276238 effective words) took 8.5s, 383833 effective words/s', 'datetime': '2023-12-06T15:19:58.240656', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:19:58,240 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:19:58.240656', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 85%| | 413/486 [1:06:20<12:39, 10.40s/it]2023-12-06 15:20:02,119 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:20:02,119 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:20:02,142 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:20:02,143 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:20:02,151 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:20:02.150030', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:20:02,151 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:20:02.151030', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:20:02,161 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:20:02,162 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:20:02,162 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:20:02.162380', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:20:02,177 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:20:02,179 : INFO : resetting layer weights\n",
      "2023-12-06 15:20:02,184 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:20:02.184084', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:20:02,340 : INFO : EPOCH 0: training on 99524 raw words (65423 effective words) took 0.2s, 429145 effective words/s\n",
      "2023-12-06 15:20:02,531 : INFO : EPOCH 1: training on 99524 raw words (65544 effective words) took 0.2s, 352479 effective words/s\n",
      "2023-12-06 15:20:02,714 : INFO : EPOCH 2: training on 99524 raw words (65444 effective words) took 0.2s, 370666 effective words/s\n",
      "2023-12-06 15:20:02,886 : INFO : EPOCH 3: training on 99524 raw words (65526 effective words) took 0.2s, 390408 effective words/s\n",
      "2023-12-06 15:20:03,048 : INFO : EPOCH 4: training on 99524 raw words (65490 effective words) took 0.2s, 416470 effective words/s\n",
      "2023-12-06 15:20:03,211 : INFO : EPOCH 5: training on 99524 raw words (65565 effective words) took 0.2s, 415084 effective words/s\n",
      "2023-12-06 15:20:03,380 : INFO : EPOCH 6: training on 99524 raw words (65430 effective words) took 0.2s, 396874 effective words/s\n",
      "2023-12-06 15:20:03,553 : INFO : EPOCH 7: training on 99524 raw words (65557 effective words) took 0.2s, 387611 effective words/s\n",
      "2023-12-06 15:20:03,727 : INFO : EPOCH 8: training on 99524 raw words (65468 effective words) took 0.2s, 386420 effective words/s\n",
      "2023-12-06 15:20:03,901 : INFO : EPOCH 9: training on 99524 raw words (65580 effective words) took 0.2s, 390949 effective words/s\n",
      "2023-12-06 15:20:04,068 : INFO : EPOCH 10: training on 99524 raw words (65454 effective words) took 0.2s, 402617 effective words/s\n",
      "2023-12-06 15:20:04,239 : INFO : EPOCH 11: training on 99524 raw words (65508 effective words) took 0.2s, 394070 effective words/s\n",
      "2023-12-06 15:20:04,413 : INFO : EPOCH 12: training on 99524 raw words (65613 effective words) took 0.2s, 390133 effective words/s\n",
      "2023-12-06 15:20:04,611 : INFO : EPOCH 13: training on 99524 raw words (65585 effective words) took 0.2s, 339794 effective words/s\n",
      "2023-12-06 15:20:04,787 : INFO : EPOCH 14: training on 99524 raw words (65670 effective words) took 0.2s, 382223 effective words/s\n",
      "2023-12-06 15:20:04,955 : INFO : EPOCH 15: training on 99524 raw words (65444 effective words) took 0.2s, 399080 effective words/s\n",
      "2023-12-06 15:20:05,130 : INFO : EPOCH 16: training on 99524 raw words (65439 effective words) took 0.2s, 386886 effective words/s\n",
      "2023-12-06 15:20:05,294 : INFO : EPOCH 17: training on 99524 raw words (65387 effective words) took 0.2s, 408175 effective words/s\n",
      "2023-12-06 15:20:05,462 : INFO : EPOCH 18: training on 99524 raw words (65467 effective words) took 0.2s, 399166 effective words/s\n",
      "2023-12-06 15:20:05,671 : INFO : EPOCH 19: training on 99524 raw words (65578 effective words) took 0.2s, 322023 effective words/s\n",
      "2023-12-06 15:20:05,838 : INFO : EPOCH 20: training on 99524 raw words (65483 effective words) took 0.2s, 403983 effective words/s\n",
      "2023-12-06 15:20:05,998 : INFO : EPOCH 21: training on 99524 raw words (65495 effective words) took 0.2s, 420478 effective words/s\n",
      "2023-12-06 15:20:06,193 : INFO : EPOCH 22: training on 99524 raw words (65556 effective words) took 0.2s, 345189 effective words/s\n",
      "2023-12-06 15:20:06,364 : INFO : EPOCH 23: training on 99524 raw words (65583 effective words) took 0.2s, 394322 effective words/s\n",
      "2023-12-06 15:20:06,553 : INFO : EPOCH 24: training on 99524 raw words (65486 effective words) took 0.2s, 356111 effective words/s\n",
      "2023-12-06 15:20:06,754 : INFO : EPOCH 25: training on 99524 raw words (65606 effective words) took 0.2s, 337243 effective words/s\n",
      "2023-12-06 15:20:06,922 : INFO : EPOCH 26: training on 99524 raw words (65673 effective words) took 0.2s, 401513 effective words/s\n",
      "2023-12-06 15:20:07,100 : INFO : EPOCH 27: training on 99524 raw words (65797 effective words) took 0.2s, 381927 effective words/s\n",
      "2023-12-06 15:20:07,290 : INFO : EPOCH 28: training on 99524 raw words (65453 effective words) took 0.2s, 352352 effective words/s\n",
      "2023-12-06 15:20:07,461 : INFO : EPOCH 29: training on 99524 raw words (65545 effective words) took 0.2s, 394422 effective words/s\n",
      "2023-12-06 15:20:07,630 : INFO : EPOCH 30: training on 99524 raw words (65502 effective words) took 0.2s, 397480 effective words/s\n",
      "2023-12-06 15:20:07,818 : INFO : EPOCH 31: training on 99524 raw words (65524 effective words) took 0.2s, 358600 effective words/s\n",
      "2023-12-06 15:20:07,995 : INFO : EPOCH 32: training on 99524 raw words (65585 effective words) took 0.2s, 380713 effective words/s\n",
      "2023-12-06 15:20:08,173 : INFO : EPOCH 33: training on 99524 raw words (65666 effective words) took 0.2s, 380166 effective words/s\n",
      "2023-12-06 15:20:08,336 : INFO : EPOCH 34: training on 99524 raw words (65541 effective words) took 0.2s, 416017 effective words/s\n",
      "2023-12-06 15:20:08,505 : INFO : EPOCH 35: training on 99524 raw words (65609 effective words) took 0.2s, 398978 effective words/s\n",
      "2023-12-06 15:20:08,678 : INFO : EPOCH 36: training on 99524 raw words (65638 effective words) took 0.2s, 388898 effective words/s\n",
      "2023-12-06 15:20:08,869 : INFO : EPOCH 37: training on 99524 raw words (65663 effective words) took 0.2s, 352976 effective words/s\n",
      "2023-12-06 15:20:09,045 : INFO : EPOCH 38: training on 99524 raw words (65470 effective words) took 0.2s, 383417 effective words/s\n",
      "2023-12-06 15:20:09,235 : INFO : EPOCH 39: training on 99524 raw words (65522 effective words) took 0.2s, 354506 effective words/s\n",
      "2023-12-06 15:20:09,418 : INFO : EPOCH 40: training on 99524 raw words (65572 effective words) took 0.2s, 368506 effective words/s\n",
      "2023-12-06 15:20:09,601 : INFO : EPOCH 41: training on 99524 raw words (65608 effective words) took 0.2s, 369124 effective words/s\n",
      "2023-12-06 15:20:09,792 : INFO : EPOCH 42: training on 99524 raw words (65522 effective words) took 0.2s, 351448 effective words/s\n",
      "2023-12-06 15:20:09,974 : INFO : EPOCH 43: training on 99524 raw words (65627 effective words) took 0.2s, 375617 effective words/s\n",
      "2023-12-06 15:20:10,147 : INFO : EPOCH 44: training on 99524 raw words (65437 effective words) took 0.2s, 389312 effective words/s\n",
      "2023-12-06 15:20:10,340 : INFO : EPOCH 45: training on 99524 raw words (65449 effective words) took 0.2s, 349502 effective words/s\n",
      "2023-12-06 15:20:10,508 : INFO : EPOCH 46: training on 99524 raw words (65437 effective words) took 0.2s, 401626 effective words/s\n",
      "2023-12-06 15:20:10,699 : INFO : EPOCH 47: training on 99524 raw words (65469 effective words) took 0.2s, 351229 effective words/s\n",
      "2023-12-06 15:20:10,884 : INFO : EPOCH 48: training on 99524 raw words (65597 effective words) took 0.2s, 368591 effective words/s\n",
      "2023-12-06 15:20:11,052 : INFO : EPOCH 49: training on 99524 raw words (65680 effective words) took 0.2s, 400809 effective words/s\n",
      "2023-12-06 15:20:11,053 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276967 effective words) took 8.9s, 369489 effective words/s', 'datetime': '2023-12-06T15:20:11.053745', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:20:11,053 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:20:11.053745', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 85%| | 414/486 [1:06:33<13:27, 11.22s/it]2023-12-06 15:20:15,253 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:20:15,254 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:20:15,276 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:20:15,276 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:20:15,284 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:20:15.284463', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:20:15,284 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:20:15.284463', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:20:15,292 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:20:15,293 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:20:15,293 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:20:15.293363', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:20:15,301 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:20:15,301 : INFO : resetting layer weights\n",
      "2023-12-06 15:20:15,307 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:20:15.307021', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:20:15,455 : INFO : EPOCH 0: training on 99524 raw words (62798 effective words) took 0.1s, 437241 effective words/s\n",
      "2023-12-06 15:20:15,665 : INFO : EPOCH 1: training on 99524 raw words (62793 effective words) took 0.2s, 305611 effective words/s\n",
      "2023-12-06 15:20:15,891 : INFO : EPOCH 2: training on 99524 raw words (62765 effective words) took 0.2s, 292023 effective words/s\n",
      "2023-12-06 15:20:16,054 : INFO : EPOCH 3: training on 99524 raw words (62595 effective words) took 0.2s, 398958 effective words/s\n",
      "2023-12-06 15:20:16,216 : INFO : EPOCH 4: training on 99524 raw words (62875 effective words) took 0.2s, 399783 effective words/s\n",
      "2023-12-06 15:20:16,379 : INFO : EPOCH 5: training on 99524 raw words (62623 effective words) took 0.2s, 396252 effective words/s\n",
      "2023-12-06 15:20:16,541 : INFO : EPOCH 6: training on 99524 raw words (62567 effective words) took 0.2s, 396552 effective words/s\n",
      "2023-12-06 15:20:16,710 : INFO : EPOCH 7: training on 99524 raw words (62646 effective words) took 0.2s, 381396 effective words/s\n",
      "2023-12-06 15:20:16,871 : INFO : EPOCH 8: training on 99524 raw words (62523 effective words) took 0.2s, 399299 effective words/s\n",
      "2023-12-06 15:20:17,025 : INFO : EPOCH 9: training on 99524 raw words (62787 effective words) took 0.2s, 418092 effective words/s\n",
      "2023-12-06 15:20:17,026 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (626972 effective words) took 1.7s, 364750 effective words/s', 'datetime': '2023-12-06T15:20:17.026990', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:20:17,026 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:20:17.026990', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 85%| | 415/486 [1:06:38<10:54,  9.23s/it]2023-12-06 15:20:19,825 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:20:19,825 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:20:19,849 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:20:19,850 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:20:19,855 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:20:19.855601', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:20:19,856 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:20:19.856601', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:20:19,864 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:20:19,864 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:20:19,865 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:20:19.865605', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:20:19,877 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:20:19,878 : INFO : resetting layer weights\n",
      "2023-12-06 15:20:19,881 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:20:19.881807', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:20:20,035 : INFO : EPOCH 0: training on 99524 raw words (62642 effective words) took 0.1s, 419956 effective words/s\n",
      "2023-12-06 15:20:20,236 : INFO : EPOCH 1: training on 99524 raw words (62804 effective words) took 0.2s, 320891 effective words/s\n",
      "2023-12-06 15:20:20,414 : INFO : EPOCH 2: training on 99524 raw words (62672 effective words) took 0.2s, 368493 effective words/s\n",
      "2023-12-06 15:20:20,577 : INFO : EPOCH 3: training on 99524 raw words (62709 effective words) took 0.2s, 395683 effective words/s\n",
      "2023-12-06 15:20:20,739 : INFO : EPOCH 4: training on 99524 raw words (62890 effective words) took 0.2s, 398180 effective words/s\n",
      "2023-12-06 15:20:20,905 : INFO : EPOCH 5: training on 99524 raw words (62667 effective words) took 0.2s, 390132 effective words/s\n",
      "2023-12-06 15:20:21,069 : INFO : EPOCH 6: training on 99524 raw words (62756 effective words) took 0.2s, 390187 effective words/s\n",
      "2023-12-06 15:20:21,264 : INFO : EPOCH 7: training on 99524 raw words (62727 effective words) took 0.2s, 330357 effective words/s\n",
      "2023-12-06 15:20:21,428 : INFO : EPOCH 8: training on 99524 raw words (62616 effective words) took 0.2s, 391282 effective words/s\n",
      "2023-12-06 15:20:21,599 : INFO : EPOCH 9: training on 99524 raw words (62683 effective words) took 0.2s, 382658 effective words/s\n",
      "2023-12-06 15:20:21,600 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627166 effective words) took 1.7s, 365187 effective words/s', 'datetime': '2023-12-06T15:20:21.600017', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:20:21,600 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:20:21.600017', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 86%| | 416/486 [1:06:43<09:09,  7.85s/it]2023-12-06 15:20:24,481 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:20:24,482 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:20:24,504 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:20:24,504 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:20:24,509 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:20:24.509764', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:20:24,510 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:20:24.510764', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:20:24,516 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:20:24,517 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:20:24,518 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:20:24.518764', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:20:24,526 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:20:24,526 : INFO : resetting layer weights\n",
      "2023-12-06 15:20:24,533 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:20:24.533764', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:20:24,684 : INFO : EPOCH 0: training on 99524 raw words (62675 effective words) took 0.1s, 425726 effective words/s\n",
      "2023-12-06 15:20:24,874 : INFO : EPOCH 1: training on 99524 raw words (62678 effective words) took 0.2s, 339177 effective words/s\n",
      "2023-12-06 15:20:25,058 : INFO : EPOCH 2: training on 99524 raw words (62876 effective words) took 0.2s, 350384 effective words/s\n",
      "2023-12-06 15:20:25,222 : INFO : EPOCH 3: training on 99524 raw words (62623 effective words) took 0.2s, 391770 effective words/s\n",
      "2023-12-06 15:20:25,387 : INFO : EPOCH 4: training on 99524 raw words (62903 effective words) took 0.2s, 393166 effective words/s\n",
      "2023-12-06 15:20:25,543 : INFO : EPOCH 5: training on 99524 raw words (62665 effective words) took 0.2s, 413163 effective words/s\n",
      "2023-12-06 15:20:25,700 : INFO : EPOCH 6: training on 99524 raw words (62781 effective words) took 0.2s, 411182 effective words/s\n",
      "2023-12-06 15:20:25,858 : INFO : EPOCH 7: training on 99524 raw words (62797 effective words) took 0.2s, 408307 effective words/s\n",
      "2023-12-06 15:20:26,050 : INFO : EPOCH 8: training on 99524 raw words (62763 effective words) took 0.2s, 335891 effective words/s\n",
      "2023-12-06 15:20:26,219 : INFO : EPOCH 9: training on 99524 raw words (62676 effective words) took 0.2s, 382104 effective words/s\n",
      "2023-12-06 15:20:26,220 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627437 effective words) took 1.7s, 372189 effective words/s', 'datetime': '2023-12-06T15:20:26.220083', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:20:26,220 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:20:26.220083', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 86%| | 417/486 [1:06:47<07:54,  6.88s/it]2023-12-06 15:20:29,088 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:20:29,089 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:20:29,111 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:20:29,112 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:20:29,116 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:20:29.116178', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:20:29,117 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:20:29.117178', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:20:29,122 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:20:29,123 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:20:29,123 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:20:29.123771', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:20:29,135 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:20:29,136 : INFO : resetting layer weights\n",
      "2023-12-06 15:20:29,140 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:20:29.140828', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:20:29,287 : INFO : EPOCH 0: training on 99524 raw words (62733 effective words) took 0.1s, 439868 effective words/s\n",
      "2023-12-06 15:20:29,468 : INFO : EPOCH 1: training on 99524 raw words (62602 effective words) took 0.2s, 357465 effective words/s\n",
      "2023-12-06 15:20:29,630 : INFO : EPOCH 2: training on 99524 raw words (62679 effective words) took 0.2s, 399547 effective words/s\n",
      "2023-12-06 15:20:29,791 : INFO : EPOCH 3: training on 99524 raw words (62565 effective words) took 0.2s, 401830 effective words/s\n",
      "2023-12-06 15:20:29,952 : INFO : EPOCH 4: training on 99524 raw words (62686 effective words) took 0.2s, 403510 effective words/s\n",
      "2023-12-06 15:20:30,108 : INFO : EPOCH 5: training on 99524 raw words (62614 effective words) took 0.2s, 409103 effective words/s\n",
      "2023-12-06 15:20:30,269 : INFO : EPOCH 6: training on 99524 raw words (62671 effective words) took 0.2s, 404432 effective words/s\n",
      "2023-12-06 15:20:30,434 : INFO : EPOCH 7: training on 99524 raw words (62685 effective words) took 0.2s, 390139 effective words/s\n",
      "2023-12-06 15:20:30,595 : INFO : EPOCH 8: training on 99524 raw words (62588 effective words) took 0.2s, 398535 effective words/s\n",
      "2023-12-06 15:20:30,754 : INFO : EPOCH 9: training on 99524 raw words (62618 effective words) took 0.2s, 406798 effective words/s\n",
      "2023-12-06 15:20:30,916 : INFO : EPOCH 10: training on 99524 raw words (62683 effective words) took 0.2s, 396930 effective words/s\n",
      "2023-12-06 15:20:31,075 : INFO : EPOCH 11: training on 99524 raw words (62806 effective words) took 0.2s, 409195 effective words/s\n",
      "2023-12-06 15:20:31,241 : INFO : EPOCH 12: training on 99524 raw words (62624 effective words) took 0.2s, 387823 effective words/s\n",
      "2023-12-06 15:20:31,400 : INFO : EPOCH 13: training on 99524 raw words (62950 effective words) took 0.2s, 406942 effective words/s\n",
      "2023-12-06 15:20:31,559 : INFO : EPOCH 14: training on 99524 raw words (62708 effective words) took 0.2s, 408120 effective words/s\n",
      "2023-12-06 15:20:31,717 : INFO : EPOCH 15: training on 99524 raw words (62736 effective words) took 0.2s, 406924 effective words/s\n",
      "2023-12-06 15:20:31,878 : INFO : EPOCH 16: training on 99524 raw words (62705 effective words) took 0.2s, 402362 effective words/s\n",
      "2023-12-06 15:20:32,038 : INFO : EPOCH 17: training on 99524 raw words (62526 effective words) took 0.2s, 400202 effective words/s\n",
      "2023-12-06 15:20:32,211 : INFO : EPOCH 18: training on 99524 raw words (62681 effective words) took 0.2s, 374386 effective words/s\n",
      "2023-12-06 15:20:32,370 : INFO : EPOCH 19: training on 99524 raw words (62755 effective words) took 0.2s, 404489 effective words/s\n",
      "2023-12-06 15:20:32,532 : INFO : EPOCH 20: training on 99524 raw words (62852 effective words) took 0.2s, 401364 effective words/s\n",
      "2023-12-06 15:20:32,686 : INFO : EPOCH 21: training on 99524 raw words (62734 effective words) took 0.2s, 416293 effective words/s\n",
      "2023-12-06 15:20:32,848 : INFO : EPOCH 22: training on 99524 raw words (62671 effective words) took 0.2s, 399661 effective words/s\n",
      "2023-12-06 15:20:33,007 : INFO : EPOCH 23: training on 99524 raw words (62853 effective words) took 0.2s, 407447 effective words/s\n",
      "2023-12-06 15:20:33,177 : INFO : EPOCH 24: training on 99524 raw words (62913 effective words) took 0.2s, 377376 effective words/s\n",
      "2023-12-06 15:20:33,339 : INFO : EPOCH 25: training on 99524 raw words (62676 effective words) took 0.2s, 400836 effective words/s\n",
      "2023-12-06 15:20:33,506 : INFO : EPOCH 26: training on 99524 raw words (62822 effective words) took 0.2s, 386081 effective words/s\n",
      "2023-12-06 15:20:33,668 : INFO : EPOCH 27: training on 99524 raw words (62951 effective words) took 0.2s, 399841 effective words/s\n",
      "2023-12-06 15:20:33,825 : INFO : EPOCH 28: training on 99524 raw words (62607 effective words) took 0.2s, 410429 effective words/s\n",
      "2023-12-06 15:20:33,984 : INFO : EPOCH 29: training on 99524 raw words (62683 effective words) took 0.2s, 404275 effective words/s\n",
      "2023-12-06 15:20:33,986 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881377 effective words) took 4.8s, 388350 effective words/s', 'datetime': '2023-12-06T15:20:33.986762', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:20:33,986 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:20:33.986762', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 86%| | 418/486 [1:06:55<08:11,  7.23s/it]2023-12-06 15:20:37,121 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:20:37,121 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:20:37,148 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:20:37,149 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:20:37,156 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:20:37.156532', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:20:37,156 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:20:37.156532', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:20:37,162 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:20:37,162 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:20:37,162 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:20:37.162744', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:20:37,175 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:20:37,175 : INFO : resetting layer weights\n",
      "2023-12-06 15:20:37,182 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:20:37.182234', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:20:37,338 : INFO : EPOCH 0: training on 99524 raw words (62936 effective words) took 0.2s, 413171 effective words/s\n",
      "2023-12-06 15:20:37,527 : INFO : EPOCH 1: training on 99524 raw words (62765 effective words) took 0.2s, 343738 effective words/s\n",
      "2023-12-06 15:20:37,712 : INFO : EPOCH 2: training on 99524 raw words (62791 effective words) took 0.2s, 360196 effective words/s\n",
      "2023-12-06 15:20:37,883 : INFO : EPOCH 3: training on 99524 raw words (62567 effective words) took 0.2s, 374012 effective words/s\n",
      "2023-12-06 15:20:38,049 : INFO : EPOCH 4: training on 99524 raw words (62601 effective words) took 0.2s, 390166 effective words/s\n",
      "2023-12-06 15:20:38,210 : INFO : EPOCH 5: training on 99524 raw words (62546 effective words) took 0.2s, 395833 effective words/s\n",
      "2023-12-06 15:20:38,377 : INFO : EPOCH 6: training on 99524 raw words (62806 effective words) took 0.2s, 387031 effective words/s\n",
      "2023-12-06 15:20:38,547 : INFO : EPOCH 7: training on 99524 raw words (62557 effective words) took 0.2s, 377488 effective words/s\n",
      "2023-12-06 15:20:38,712 : INFO : EPOCH 8: training on 99524 raw words (62813 effective words) took 0.2s, 391458 effective words/s\n",
      "2023-12-06 15:20:38,875 : INFO : EPOCH 9: training on 99524 raw words (62677 effective words) took 0.2s, 394688 effective words/s\n",
      "2023-12-06 15:20:39,038 : INFO : EPOCH 10: training on 99524 raw words (62677 effective words) took 0.2s, 395651 effective words/s\n",
      "2023-12-06 15:20:39,202 : INFO : EPOCH 11: training on 99524 raw words (62645 effective words) took 0.2s, 392157 effective words/s\n",
      "2023-12-06 15:20:39,365 : INFO : EPOCH 12: training on 99524 raw words (62603 effective words) took 0.2s, 396413 effective words/s\n",
      "2023-12-06 15:20:39,540 : INFO : EPOCH 13: training on 99524 raw words (62767 effective words) took 0.2s, 368299 effective words/s\n",
      "2023-12-06 15:20:39,704 : INFO : EPOCH 14: training on 99524 raw words (62790 effective words) took 0.2s, 394905 effective words/s\n",
      "2023-12-06 15:20:39,869 : INFO : EPOCH 15: training on 99524 raw words (62808 effective words) took 0.2s, 392725 effective words/s\n",
      "2023-12-06 15:20:40,032 : INFO : EPOCH 16: training on 99524 raw words (62823 effective words) took 0.2s, 396228 effective words/s\n",
      "2023-12-06 15:20:40,196 : INFO : EPOCH 17: training on 99524 raw words (62776 effective words) took 0.2s, 393977 effective words/s\n",
      "2023-12-06 15:20:40,370 : INFO : EPOCH 18: training on 99524 raw words (62704 effective words) took 0.2s, 370151 effective words/s\n",
      "2023-12-06 15:20:40,538 : INFO : EPOCH 19: training on 99524 raw words (62816 effective words) took 0.2s, 386847 effective words/s\n",
      "2023-12-06 15:20:40,701 : INFO : EPOCH 20: training on 99524 raw words (62788 effective words) took 0.2s, 395554 effective words/s\n",
      "2023-12-06 15:20:40,869 : INFO : EPOCH 21: training on 99524 raw words (62881 effective words) took 0.2s, 386060 effective words/s\n",
      "2023-12-06 15:20:41,041 : INFO : EPOCH 22: training on 99524 raw words (62750 effective words) took 0.2s, 376103 effective words/s\n",
      "2023-12-06 15:20:41,208 : INFO : EPOCH 23: training on 99524 raw words (62779 effective words) took 0.2s, 386869 effective words/s\n",
      "2023-12-06 15:20:41,391 : INFO : EPOCH 24: training on 99524 raw words (62712 effective words) took 0.2s, 352016 effective words/s\n",
      "2023-12-06 15:20:41,559 : INFO : EPOCH 25: training on 99524 raw words (62701 effective words) took 0.2s, 385446 effective words/s\n",
      "2023-12-06 15:20:41,725 : INFO : EPOCH 26: training on 99524 raw words (62621 effective words) took 0.2s, 387142 effective words/s\n",
      "2023-12-06 15:20:41,892 : INFO : EPOCH 27: training on 99524 raw words (63074 effective words) took 0.2s, 389333 effective words/s\n",
      "2023-12-06 15:20:42,058 : INFO : EPOCH 28: training on 99524 raw words (62721 effective words) took 0.2s, 386318 effective words/s\n",
      "2023-12-06 15:20:42,224 : INFO : EPOCH 29: training on 99524 raw words (62794 effective words) took 0.2s, 387547 effective words/s\n",
      "2023-12-06 15:20:42,225 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1882289 effective words) took 5.0s, 373257 effective words/s', 'datetime': '2023-12-06T15:20:42.225853', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:20:42,225 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:20:42.225853', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 86%| | 419/486 [1:07:04<08:29,  7.60s/it]2023-12-06 15:20:45,592 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:20:45,593 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:20:45,615 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:20:45,616 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:20:45,623 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:20:45.622113', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:20:45,623 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:20:45.623111', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:20:45,631 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:20:45,632 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:20:45,632 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:20:45.632008', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:20:45,640 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:20:45,642 : INFO : resetting layer weights\n",
      "2023-12-06 15:20:45,648 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:20:45.648304', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:20:45,803 : INFO : EPOCH 0: training on 99524 raw words (62747 effective words) took 0.2s, 416073 effective words/s\n",
      "2023-12-06 15:20:46,016 : INFO : EPOCH 1: training on 99524 raw words (62665 effective words) took 0.2s, 301178 effective words/s\n",
      "2023-12-06 15:20:46,189 : INFO : EPOCH 2: training on 99524 raw words (62678 effective words) took 0.2s, 385705 effective words/s\n",
      "2023-12-06 15:20:46,358 : INFO : EPOCH 3: training on 99524 raw words (62654 effective words) took 0.2s, 384594 effective words/s\n",
      "2023-12-06 15:20:46,519 : INFO : EPOCH 4: training on 99524 raw words (62641 effective words) took 0.2s, 398556 effective words/s\n",
      "2023-12-06 15:20:46,687 : INFO : EPOCH 5: training on 99524 raw words (62729 effective words) took 0.2s, 385311 effective words/s\n",
      "2023-12-06 15:20:46,861 : INFO : EPOCH 6: training on 99524 raw words (62698 effective words) took 0.2s, 368936 effective words/s\n",
      "2023-12-06 15:20:47,031 : INFO : EPOCH 7: training on 99524 raw words (62738 effective words) took 0.2s, 380596 effective words/s\n",
      "2023-12-06 15:20:47,200 : INFO : EPOCH 8: training on 99524 raw words (62668 effective words) took 0.2s, 386128 effective words/s\n",
      "2023-12-06 15:20:47,365 : INFO : EPOCH 9: training on 99524 raw words (62763 effective words) took 0.2s, 389722 effective words/s\n",
      "2023-12-06 15:20:47,533 : INFO : EPOCH 10: training on 99524 raw words (62645 effective words) took 0.2s, 388624 effective words/s\n",
      "2023-12-06 15:20:47,697 : INFO : EPOCH 11: training on 99524 raw words (62695 effective words) took 0.2s, 391440 effective words/s\n",
      "2023-12-06 15:20:47,877 : INFO : EPOCH 12: training on 99524 raw words (62709 effective words) took 0.2s, 357229 effective words/s\n",
      "2023-12-06 15:20:48,047 : INFO : EPOCH 13: training on 99524 raw words (62709 effective words) took 0.2s, 380734 effective words/s\n",
      "2023-12-06 15:20:48,220 : INFO : EPOCH 14: training on 99524 raw words (62757 effective words) took 0.2s, 372526 effective words/s\n",
      "2023-12-06 15:20:48,388 : INFO : EPOCH 15: training on 99524 raw words (62679 effective words) took 0.2s, 382955 effective words/s\n",
      "2023-12-06 15:20:48,555 : INFO : EPOCH 16: training on 99524 raw words (62697 effective words) took 0.2s, 384459 effective words/s\n",
      "2023-12-06 15:20:48,723 : INFO : EPOCH 17: training on 99524 raw words (62751 effective words) took 0.2s, 385338 effective words/s\n",
      "2023-12-06 15:20:48,899 : INFO : EPOCH 18: training on 99524 raw words (62697 effective words) took 0.2s, 371593 effective words/s\n",
      "2023-12-06 15:20:49,067 : INFO : EPOCH 19: training on 99524 raw words (62815 effective words) took 0.2s, 385644 effective words/s\n",
      "2023-12-06 15:20:49,235 : INFO : EPOCH 20: training on 99524 raw words (62753 effective words) took 0.2s, 383583 effective words/s\n",
      "2023-12-06 15:20:49,401 : INFO : EPOCH 21: training on 99524 raw words (62811 effective words) took 0.2s, 386349 effective words/s\n",
      "2023-12-06 15:20:49,571 : INFO : EPOCH 22: training on 99524 raw words (62703 effective words) took 0.2s, 379841 effective words/s\n",
      "2023-12-06 15:20:49,739 : INFO : EPOCH 23: training on 99524 raw words (62914 effective words) took 0.2s, 384437 effective words/s\n",
      "2023-12-06 15:20:49,918 : INFO : EPOCH 24: training on 99524 raw words (62611 effective words) took 0.2s, 359350 effective words/s\n",
      "2023-12-06 15:20:50,083 : INFO : EPOCH 25: training on 99524 raw words (62750 effective words) took 0.2s, 391149 effective words/s\n",
      "2023-12-06 15:20:50,249 : INFO : EPOCH 26: training on 99524 raw words (62976 effective words) took 0.2s, 390024 effective words/s\n",
      "2023-12-06 15:20:50,419 : INFO : EPOCH 27: training on 99524 raw words (62800 effective words) took 0.2s, 378082 effective words/s\n",
      "2023-12-06 15:20:50,584 : INFO : EPOCH 28: training on 99524 raw words (62686 effective words) took 0.2s, 391708 effective words/s\n",
      "2023-12-06 15:20:50,752 : INFO : EPOCH 29: training on 99524 raw words (62663 effective words) took 0.2s, 384516 effective words/s\n",
      "2023-12-06 15:20:50,753 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881802 effective words) took 5.1s, 368679 effective words/s', 'datetime': '2023-12-06T15:20:50.753518', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:20:50,753 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:20:50.753518', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 86%| | 420/486 [1:07:12<08:44,  7.94s/it]2023-12-06 15:20:54,342 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:20:54,342 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:20:54,367 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:20:54,367 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:20:54,374 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:20:54.374956', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:20:54,374 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:20:54.374956', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:20:54,381 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:20:54,382 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:20:54,382 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:20:54.382483', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:20:54,391 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:20:54,392 : INFO : resetting layer weights\n",
      "2023-12-06 15:20:54,396 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:20:54.396504', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:20:54,545 : INFO : EPOCH 0: training on 99524 raw words (62724 effective words) took 0.1s, 434065 effective words/s\n",
      "2023-12-06 15:20:54,725 : INFO : EPOCH 1: training on 99524 raw words (62757 effective words) took 0.2s, 362884 effective words/s\n",
      "2023-12-06 15:20:54,892 : INFO : EPOCH 2: training on 99524 raw words (62801 effective words) took 0.2s, 390138 effective words/s\n",
      "2023-12-06 15:20:55,053 : INFO : EPOCH 3: training on 99524 raw words (62665 effective words) took 0.2s, 400563 effective words/s\n",
      "2023-12-06 15:20:55,213 : INFO : EPOCH 4: training on 99524 raw words (62686 effective words) took 0.2s, 401408 effective words/s\n",
      "2023-12-06 15:20:55,374 : INFO : EPOCH 5: training on 99524 raw words (62757 effective words) took 0.2s, 403139 effective words/s\n",
      "2023-12-06 15:20:55,535 : INFO : EPOCH 6: training on 99524 raw words (62676 effective words) took 0.2s, 398565 effective words/s\n",
      "2023-12-06 15:20:55,704 : INFO : EPOCH 7: training on 99524 raw words (62756 effective words) took 0.2s, 381882 effective words/s\n",
      "2023-12-06 15:20:55,867 : INFO : EPOCH 8: training on 99524 raw words (62786 effective words) took 0.2s, 395294 effective words/s\n",
      "2023-12-06 15:20:56,026 : INFO : EPOCH 9: training on 99524 raw words (62832 effective words) took 0.2s, 408423 effective words/s\n",
      "2023-12-06 15:20:56,186 : INFO : EPOCH 10: training on 99524 raw words (62484 effective words) took 0.2s, 400651 effective words/s\n",
      "2023-12-06 15:20:56,346 : INFO : EPOCH 11: training on 99524 raw words (62915 effective words) took 0.2s, 407011 effective words/s\n",
      "2023-12-06 15:20:56,506 : INFO : EPOCH 12: training on 99524 raw words (62719 effective words) took 0.2s, 402905 effective words/s\n",
      "2023-12-06 15:20:56,669 : INFO : EPOCH 13: training on 99524 raw words (62733 effective words) took 0.2s, 394763 effective words/s\n",
      "2023-12-06 15:20:56,833 : INFO : EPOCH 14: training on 99524 raw words (62774 effective words) took 0.2s, 394347 effective words/s\n",
      "2023-12-06 15:20:56,994 : INFO : EPOCH 15: training on 99524 raw words (62719 effective words) took 0.2s, 400343 effective words/s\n",
      "2023-12-06 15:20:57,154 : INFO : EPOCH 16: training on 99524 raw words (62683 effective words) took 0.2s, 407083 effective words/s\n",
      "2023-12-06 15:20:57,313 : INFO : EPOCH 17: training on 99524 raw words (62711 effective words) took 0.2s, 405620 effective words/s\n",
      "2023-12-06 15:20:57,475 : INFO : EPOCH 18: training on 99524 raw words (62661 effective words) took 0.2s, 396174 effective words/s\n",
      "2023-12-06 15:20:57,641 : INFO : EPOCH 19: training on 99524 raw words (62810 effective words) took 0.2s, 389115 effective words/s\n",
      "2023-12-06 15:20:57,805 : INFO : EPOCH 20: training on 99524 raw words (62942 effective words) took 0.2s, 397734 effective words/s\n",
      "2023-12-06 15:20:57,968 : INFO : EPOCH 21: training on 99524 raw words (62655 effective words) took 0.2s, 396786 effective words/s\n",
      "2023-12-06 15:20:58,130 : INFO : EPOCH 22: training on 99524 raw words (62889 effective words) took 0.2s, 398360 effective words/s\n",
      "2023-12-06 15:20:58,290 : INFO : EPOCH 23: training on 99524 raw words (62880 effective words) took 0.2s, 401900 effective words/s\n",
      "2023-12-06 15:20:58,458 : INFO : EPOCH 24: training on 99524 raw words (62720 effective words) took 0.2s, 389555 effective words/s\n",
      "2023-12-06 15:20:58,625 : INFO : EPOCH 25: training on 99524 raw words (62709 effective words) took 0.2s, 384020 effective words/s\n",
      "2023-12-06 15:20:58,791 : INFO : EPOCH 26: training on 99524 raw words (62859 effective words) took 0.2s, 391747 effective words/s\n",
      "2023-12-06 15:20:58,952 : INFO : EPOCH 27: training on 99524 raw words (62971 effective words) took 0.2s, 401850 effective words/s\n",
      "2023-12-06 15:20:59,112 : INFO : EPOCH 28: training on 99524 raw words (62711 effective words) took 0.2s, 403795 effective words/s\n",
      "2023-12-06 15:20:59,272 : INFO : EPOCH 29: training on 99524 raw words (62752 effective words) took 0.2s, 404201 effective words/s\n",
      "2023-12-06 15:20:59,438 : INFO : EPOCH 30: training on 99524 raw words (62698 effective words) took 0.2s, 389696 effective words/s\n",
      "2023-12-06 15:20:59,611 : INFO : EPOCH 31: training on 99524 raw words (62711 effective words) took 0.2s, 372503 effective words/s\n",
      "2023-12-06 15:20:59,773 : INFO : EPOCH 32: training on 99524 raw words (62657 effective words) took 0.2s, 397863 effective words/s\n",
      "2023-12-06 15:20:59,931 : INFO : EPOCH 33: training on 99524 raw words (62785 effective words) took 0.2s, 407541 effective words/s\n",
      "2023-12-06 15:21:00,094 : INFO : EPOCH 34: training on 99524 raw words (62810 effective words) took 0.2s, 397361 effective words/s\n",
      "2023-12-06 15:21:00,257 : INFO : EPOCH 35: training on 99524 raw words (62869 effective words) took 0.2s, 398375 effective words/s\n",
      "2023-12-06 15:21:00,424 : INFO : EPOCH 36: training on 99524 raw words (62899 effective words) took 0.2s, 387244 effective words/s\n",
      "2023-12-06 15:21:00,588 : INFO : EPOCH 37: training on 99524 raw words (62825 effective words) took 0.2s, 398457 effective words/s\n",
      "2023-12-06 15:21:00,753 : INFO : EPOCH 38: training on 99524 raw words (62700 effective words) took 0.2s, 392765 effective words/s\n",
      "2023-12-06 15:21:00,915 : INFO : EPOCH 39: training on 99524 raw words (62641 effective words) took 0.2s, 397915 effective words/s\n",
      "2023-12-06 15:21:01,082 : INFO : EPOCH 40: training on 99524 raw words (62716 effective words) took 0.2s, 384397 effective words/s\n",
      "2023-12-06 15:21:01,246 : INFO : EPOCH 41: training on 99524 raw words (62853 effective words) took 0.2s, 393220 effective words/s\n",
      "2023-12-06 15:21:01,419 : INFO : EPOCH 42: training on 99524 raw words (62795 effective words) took 0.2s, 373965 effective words/s\n",
      "2023-12-06 15:21:01,583 : INFO : EPOCH 43: training on 99524 raw words (62721 effective words) took 0.2s, 392480 effective words/s\n",
      "2023-12-06 15:21:01,738 : INFO : EPOCH 44: training on 99524 raw words (62575 effective words) took 0.1s, 417179 effective words/s\n",
      "2023-12-06 15:21:01,901 : INFO : EPOCH 45: training on 99524 raw words (62616 effective words) took 0.2s, 396917 effective words/s\n",
      "2023-12-06 15:21:02,070 : INFO : EPOCH 46: training on 99524 raw words (62712 effective words) took 0.2s, 381534 effective words/s\n",
      "2023-12-06 15:21:02,232 : INFO : EPOCH 47: training on 99524 raw words (62681 effective words) took 0.2s, 398899 effective words/s\n",
      "2023-12-06 15:21:02,395 : INFO : EPOCH 48: training on 99524 raw words (62774 effective words) took 0.2s, 396578 effective words/s\n",
      "2023-12-06 15:21:02,557 : INFO : EPOCH 49: training on 99524 raw words (62783 effective words) took 0.2s, 395943 effective words/s\n",
      "2023-12-06 15:21:02,559 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3137558 effective words) took 8.2s, 384447 effective words/s', 'datetime': '2023-12-06T15:21:02.559153', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:21:02,559 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:21:02.559153', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 87%| | 421/486 [1:07:24<09:49,  9.08s/it]2023-12-06 15:21:06,057 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:21:06,058 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:21:06,080 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:21:06,081 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:21:06,087 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:21:06.087615', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:21:06,088 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:21:06.088617', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:21:06,096 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:21:06,097 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:21:06,098 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:21:06.098191', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:21:06,110 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:21:06,110 : INFO : resetting layer weights\n",
      "2023-12-06 15:21:06,114 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:21:06.114196', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:21:06,259 : INFO : EPOCH 0: training on 99524 raw words (62700 effective words) took 0.1s, 447680 effective words/s\n",
      "2023-12-06 15:21:06,428 : INFO : EPOCH 1: training on 99524 raw words (62712 effective words) took 0.2s, 380962 effective words/s\n",
      "2023-12-06 15:21:06,604 : INFO : EPOCH 2: training on 99524 raw words (62719 effective words) took 0.2s, 367184 effective words/s\n",
      "2023-12-06 15:21:06,772 : INFO : EPOCH 3: training on 99524 raw words (62593 effective words) took 0.2s, 384759 effective words/s\n",
      "2023-12-06 15:21:06,938 : INFO : EPOCH 4: training on 99524 raw words (62600 effective words) took 0.2s, 387740 effective words/s\n",
      "2023-12-06 15:21:07,102 : INFO : EPOCH 5: training on 99524 raw words (62679 effective words) took 0.2s, 393354 effective words/s\n",
      "2023-12-06 15:21:07,272 : INFO : EPOCH 6: training on 99524 raw words (62738 effective words) took 0.2s, 379315 effective words/s\n",
      "2023-12-06 15:21:07,437 : INFO : EPOCH 7: training on 99524 raw words (62661 effective words) took 0.2s, 391470 effective words/s\n",
      "2023-12-06 15:21:07,614 : INFO : EPOCH 8: training on 99524 raw words (62791 effective words) took 0.2s, 364284 effective words/s\n",
      "2023-12-06 15:21:07,781 : INFO : EPOCH 9: training on 99524 raw words (62757 effective words) took 0.2s, 388026 effective words/s\n",
      "2023-12-06 15:21:07,945 : INFO : EPOCH 10: training on 99524 raw words (62615 effective words) took 0.2s, 390984 effective words/s\n",
      "2023-12-06 15:21:08,110 : INFO : EPOCH 11: training on 99524 raw words (62656 effective words) took 0.2s, 392350 effective words/s\n",
      "2023-12-06 15:21:08,276 : INFO : EPOCH 12: training on 99524 raw words (62717 effective words) took 0.2s, 387200 effective words/s\n",
      "2023-12-06 15:21:08,441 : INFO : EPOCH 13: training on 99524 raw words (62674 effective words) took 0.2s, 391227 effective words/s\n",
      "2023-12-06 15:21:08,624 : INFO : EPOCH 14: training on 99524 raw words (62760 effective words) took 0.2s, 352012 effective words/s\n",
      "2023-12-06 15:21:08,783 : INFO : EPOCH 15: training on 99524 raw words (62714 effective words) took 0.2s, 405093 effective words/s\n",
      "2023-12-06 15:21:08,945 : INFO : EPOCH 16: training on 99524 raw words (62937 effective words) took 0.2s, 400368 effective words/s\n",
      "2023-12-06 15:21:09,108 : INFO : EPOCH 17: training on 99524 raw words (62746 effective words) took 0.2s, 397061 effective words/s\n",
      "2023-12-06 15:21:09,282 : INFO : EPOCH 18: training on 99524 raw words (62726 effective words) took 0.2s, 369267 effective words/s\n",
      "2023-12-06 15:21:09,455 : INFO : EPOCH 19: training on 99524 raw words (62906 effective words) took 0.2s, 371975 effective words/s\n",
      "2023-12-06 15:21:09,638 : INFO : EPOCH 20: training on 99524 raw words (62811 effective words) took 0.2s, 351896 effective words/s\n",
      "2023-12-06 15:21:09,811 : INFO : EPOCH 21: training on 99524 raw words (62848 effective words) took 0.2s, 375676 effective words/s\n",
      "2023-12-06 15:21:09,978 : INFO : EPOCH 22: training on 99524 raw words (62942 effective words) took 0.2s, 386926 effective words/s\n",
      "2023-12-06 15:21:10,151 : INFO : EPOCH 23: training on 99524 raw words (62805 effective words) took 0.2s, 371760 effective words/s\n",
      "2023-12-06 15:21:10,319 : INFO : EPOCH 24: training on 99524 raw words (62755 effective words) took 0.2s, 388826 effective words/s\n",
      "2023-12-06 15:21:10,478 : INFO : EPOCH 25: training on 99524 raw words (62731 effective words) took 0.2s, 404647 effective words/s\n",
      "2023-12-06 15:21:10,658 : INFO : EPOCH 26: training on 99524 raw words (62878 effective words) took 0.2s, 372363 effective words/s\n",
      "2023-12-06 15:21:10,824 : INFO : EPOCH 27: training on 99524 raw words (62828 effective words) took 0.2s, 388552 effective words/s\n",
      "2023-12-06 15:21:10,987 : INFO : EPOCH 28: training on 99524 raw words (62659 effective words) took 0.2s, 394638 effective words/s\n",
      "2023-12-06 15:21:11,155 : INFO : EPOCH 29: training on 99524 raw words (62863 effective words) took 0.2s, 382142 effective words/s\n",
      "2023-12-06 15:21:11,322 : INFO : EPOCH 30: training on 99524 raw words (62612 effective words) took 0.2s, 385702 effective words/s\n",
      "2023-12-06 15:21:11,486 : INFO : EPOCH 31: training on 99524 raw words (62679 effective words) took 0.2s, 394575 effective words/s\n",
      "2023-12-06 15:21:11,662 : INFO : EPOCH 32: training on 99524 raw words (62812 effective words) took 0.2s, 365793 effective words/s\n",
      "2023-12-06 15:21:11,828 : INFO : EPOCH 33: training on 99524 raw words (62853 effective words) took 0.2s, 388722 effective words/s\n",
      "2023-12-06 15:21:11,992 : INFO : EPOCH 34: training on 99524 raw words (62811 effective words) took 0.2s, 392714 effective words/s\n",
      "2023-12-06 15:21:12,161 : INFO : EPOCH 35: training on 99524 raw words (62754 effective words) took 0.2s, 382394 effective words/s\n",
      "2023-12-06 15:21:12,326 : INFO : EPOCH 36: training on 99524 raw words (62698 effective words) took 0.2s, 390491 effective words/s\n",
      "2023-12-06 15:21:12,491 : INFO : EPOCH 37: training on 99524 raw words (62657 effective words) took 0.2s, 390902 effective words/s\n",
      "2023-12-06 15:21:12,658 : INFO : EPOCH 38: training on 99524 raw words (62536 effective words) took 0.2s, 385973 effective words/s\n",
      "2023-12-06 15:21:12,823 : INFO : EPOCH 39: training on 99524 raw words (62750 effective words) took 0.2s, 392267 effective words/s\n",
      "2023-12-06 15:21:12,986 : INFO : EPOCH 40: training on 99524 raw words (62736 effective words) took 0.2s, 394398 effective words/s\n",
      "2023-12-06 15:21:13,153 : INFO : EPOCH 41: training on 99524 raw words (62701 effective words) took 0.2s, 386006 effective words/s\n",
      "2023-12-06 15:21:13,332 : INFO : EPOCH 42: training on 99524 raw words (62661 effective words) took 0.2s, 360148 effective words/s\n",
      "2023-12-06 15:21:13,498 : INFO : EPOCH 43: training on 99524 raw words (62827 effective words) took 0.2s, 388546 effective words/s\n",
      "2023-12-06 15:21:13,662 : INFO : EPOCH 44: training on 99524 raw words (62808 effective words) took 0.2s, 393693 effective words/s\n",
      "2023-12-06 15:21:13,828 : INFO : EPOCH 45: training on 99524 raw words (62742 effective words) took 0.2s, 389384 effective words/s\n",
      "2023-12-06 15:21:14,001 : INFO : EPOCH 46: training on 99524 raw words (62651 effective words) took 0.2s, 372730 effective words/s\n",
      "2023-12-06 15:21:14,165 : INFO : EPOCH 47: training on 99524 raw words (62641 effective words) took 0.2s, 393508 effective words/s\n",
      "2023-12-06 15:21:14,352 : INFO : EPOCH 48: training on 99524 raw words (62777 effective words) took 0.2s, 343472 effective words/s\n",
      "2023-12-06 15:21:14,514 : INFO : EPOCH 49: training on 99524 raw words (62745 effective words) took 0.2s, 398355 effective words/s\n",
      "2023-12-06 15:21:14,515 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136972 effective words) took 8.4s, 373455 effective words/s', 'datetime': '2023-12-06T15:21:14.515300', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:21:14,515 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:21:14.515300', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 87%| | 422/486 [1:07:37<10:42, 10.05s/it]2023-12-06 15:21:18,368 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:21:18,368 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:21:18,391 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:21:18,392 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:21:18,396 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:21:18.396691', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:21:18,397 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:21:18.397699', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:21:18,404 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:21:18,404 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:21:18,404 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:21:18.404149', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:21:18,417 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:21:18,417 : INFO : resetting layer weights\n",
      "2023-12-06 15:21:18,421 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:21:18.421586', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:21:18,577 : INFO : EPOCH 0: training on 99524 raw words (62639 effective words) took 0.2s, 416299 effective words/s\n",
      "2023-12-06 15:21:18,756 : INFO : EPOCH 1: training on 99524 raw words (62833 effective words) took 0.2s, 359182 effective words/s\n",
      "2023-12-06 15:21:18,937 : INFO : EPOCH 2: training on 99524 raw words (62767 effective words) took 0.2s, 359913 effective words/s\n",
      "2023-12-06 15:21:19,097 : INFO : EPOCH 3: training on 99524 raw words (62589 effective words) took 0.2s, 403890 effective words/s\n",
      "2023-12-06 15:21:19,267 : INFO : EPOCH 4: training on 99524 raw words (62777 effective words) took 0.2s, 380114 effective words/s\n",
      "2023-12-06 15:21:19,433 : INFO : EPOCH 5: training on 99524 raw words (62845 effective words) took 0.2s, 388914 effective words/s\n",
      "2023-12-06 15:21:19,590 : INFO : EPOCH 6: training on 99524 raw words (62762 effective words) took 0.2s, 410283 effective words/s\n",
      "2023-12-06 15:21:19,760 : INFO : EPOCH 7: training on 99524 raw words (62745 effective words) took 0.2s, 378370 effective words/s\n",
      "2023-12-06 15:21:19,920 : INFO : EPOCH 8: training on 99524 raw words (62632 effective words) took 0.2s, 405103 effective words/s\n",
      "2023-12-06 15:21:20,084 : INFO : EPOCH 9: training on 99524 raw words (62578 effective words) took 0.2s, 389727 effective words/s\n",
      "2023-12-06 15:21:20,251 : INFO : EPOCH 10: training on 99524 raw words (62642 effective words) took 0.2s, 386959 effective words/s\n",
      "2023-12-06 15:21:20,419 : INFO : EPOCH 11: training on 99524 raw words (62756 effective words) took 0.2s, 383272 effective words/s\n",
      "2023-12-06 15:21:20,583 : INFO : EPOCH 12: training on 99524 raw words (62622 effective words) took 0.2s, 392779 effective words/s\n",
      "2023-12-06 15:21:20,758 : INFO : EPOCH 13: training on 99524 raw words (62635 effective words) took 0.2s, 367061 effective words/s\n",
      "2023-12-06 15:21:20,921 : INFO : EPOCH 14: training on 99524 raw words (62819 effective words) took 0.2s, 395084 effective words/s\n",
      "2023-12-06 15:21:21,087 : INFO : EPOCH 15: training on 99524 raw words (62891 effective words) took 0.2s, 391354 effective words/s\n",
      "2023-12-06 15:21:21,253 : INFO : EPOCH 16: training on 99524 raw words (62759 effective words) took 0.2s, 388440 effective words/s\n",
      "2023-12-06 15:21:21,418 : INFO : EPOCH 17: training on 99524 raw words (62686 effective words) took 0.2s, 389591 effective words/s\n",
      "2023-12-06 15:21:21,590 : INFO : EPOCH 18: training on 99524 raw words (62720 effective words) took 0.2s, 374861 effective words/s\n",
      "2023-12-06 15:21:21,775 : INFO : EPOCH 19: training on 99524 raw words (62736 effective words) took 0.2s, 348361 effective words/s\n",
      "2023-12-06 15:21:21,940 : INFO : EPOCH 20: training on 99524 raw words (62779 effective words) took 0.2s, 390923 effective words/s\n",
      "2023-12-06 15:21:22,108 : INFO : EPOCH 21: training on 99524 raw words (62910 effective words) took 0.2s, 385782 effective words/s\n",
      "2023-12-06 15:21:22,276 : INFO : EPOCH 22: training on 99524 raw words (62720 effective words) took 0.2s, 385657 effective words/s\n",
      "2023-12-06 15:21:22,444 : INFO : EPOCH 23: training on 99524 raw words (62847 effective words) took 0.2s, 385759 effective words/s\n",
      "2023-12-06 15:21:22,616 : INFO : EPOCH 24: training on 99524 raw words (62844 effective words) took 0.2s, 374113 effective words/s\n",
      "2023-12-06 15:21:22,801 : INFO : EPOCH 25: training on 99524 raw words (62664 effective words) took 0.2s, 349187 effective words/s\n",
      "2023-12-06 15:21:22,967 : INFO : EPOCH 26: training on 99524 raw words (62885 effective words) took 0.2s, 388295 effective words/s\n",
      "2023-12-06 15:21:23,133 : INFO : EPOCH 27: training on 99524 raw words (62757 effective words) took 0.2s, 388709 effective words/s\n",
      "2023-12-06 15:21:23,301 : INFO : EPOCH 28: training on 99524 raw words (62572 effective words) took 0.2s, 382802 effective words/s\n",
      "2023-12-06 15:21:23,468 : INFO : EPOCH 29: training on 99524 raw words (62857 effective words) took 0.2s, 385395 effective words/s\n",
      "2023-12-06 15:21:23,639 : INFO : EPOCH 30: training on 99524 raw words (62762 effective words) took 0.2s, 380114 effective words/s\n",
      "2023-12-06 15:21:23,826 : INFO : EPOCH 31: training on 99524 raw words (62653 effective words) took 0.2s, 342629 effective words/s\n",
      "2023-12-06 15:21:23,994 : INFO : EPOCH 32: training on 99524 raw words (62736 effective words) took 0.2s, 383173 effective words/s\n",
      "2023-12-06 15:21:24,161 : INFO : EPOCH 33: training on 99524 raw words (62770 effective words) took 0.2s, 388876 effective words/s\n",
      "2023-12-06 15:21:24,329 : INFO : EPOCH 34: training on 99524 raw words (62574 effective words) took 0.2s, 381140 effective words/s\n",
      "2023-12-06 15:21:24,496 : INFO : EPOCH 35: training on 99524 raw words (62779 effective words) took 0.2s, 388185 effective words/s\n",
      "2023-12-06 15:21:24,670 : INFO : EPOCH 36: training on 99524 raw words (62611 effective words) took 0.2s, 367868 effective words/s\n",
      "2023-12-06 15:21:24,859 : INFO : EPOCH 37: training on 99524 raw words (62724 effective words) took 0.2s, 339770 effective words/s\n",
      "2023-12-06 15:21:25,026 : INFO : EPOCH 38: training on 99524 raw words (62583 effective words) took 0.2s, 386199 effective words/s\n",
      "2023-12-06 15:21:25,189 : INFO : EPOCH 39: training on 99524 raw words (62655 effective words) took 0.2s, 394697 effective words/s\n",
      "2023-12-06 15:21:25,359 : INFO : EPOCH 40: training on 99524 raw words (62581 effective words) took 0.2s, 380973 effective words/s\n",
      "2023-12-06 15:21:25,519 : INFO : EPOCH 41: training on 99524 raw words (62761 effective words) took 0.2s, 404829 effective words/s\n",
      "2023-12-06 15:21:25,709 : INFO : EPOCH 42: training on 99524 raw words (62677 effective words) took 0.2s, 338737 effective words/s\n",
      "2023-12-06 15:21:25,874 : INFO : EPOCH 43: training on 99524 raw words (62807 effective words) took 0.2s, 394545 effective words/s\n",
      "2023-12-06 15:21:26,039 : INFO : EPOCH 44: training on 99524 raw words (62672 effective words) took 0.2s, 389680 effective words/s\n",
      "2023-12-06 15:21:26,213 : INFO : EPOCH 45: training on 99524 raw words (62722 effective words) took 0.2s, 369985 effective words/s\n",
      "2023-12-06 15:21:26,402 : INFO : EPOCH 46: training on 99524 raw words (62684 effective words) took 0.2s, 342474 effective words/s\n",
      "2023-12-06 15:21:26,577 : INFO : EPOCH 47: training on 99524 raw words (62570 effective words) took 0.2s, 367107 effective words/s\n",
      "2023-12-06 15:21:26,770 : INFO : EPOCH 48: training on 99524 raw words (62613 effective words) took 0.2s, 332491 effective words/s\n",
      "2023-12-06 15:21:26,937 : INFO : EPOCH 49: training on 99524 raw words (62768 effective words) took 0.2s, 387644 effective words/s\n",
      "2023-12-06 15:21:26,938 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3135970 effective words) took 8.5s, 368253 effective words/s', 'datetime': '2023-12-06T15:21:26.938377', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:21:26,938 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:21:26.938377', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 87%| | 423/486 [1:07:49<11:23, 10.85s/it]2023-12-06 15:21:31,094 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:21:31,095 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:21:31,116 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:21:31,117 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:21:31,121 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:21:31.121635', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:21:31,122 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:21:31.122634', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:21:31,127 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:21:31,128 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:21:31,128 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:21:31.128642', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:21:31,135 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:21:31,136 : INFO : resetting layer weights\n",
      "2023-12-06 15:21:31,141 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:21:31.141270', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:21:31,292 : INFO : EPOCH 0: training on 99524 raw words (60508 effective words) took 0.1s, 409659 effective words/s\n",
      "2023-12-06 15:21:31,486 : INFO : EPOCH 1: training on 99524 raw words (60592 effective words) took 0.2s, 322666 effective words/s\n",
      "2023-12-06 15:21:31,663 : INFO : EPOCH 2: training on 99524 raw words (60344 effective words) took 0.2s, 352127 effective words/s\n",
      "2023-12-06 15:21:31,819 : INFO : EPOCH 3: training on 99524 raw words (60268 effective words) took 0.2s, 399763 effective words/s\n",
      "2023-12-06 15:21:31,976 : INFO : EPOCH 4: training on 99524 raw words (60341 effective words) took 0.2s, 396069 effective words/s\n",
      "2023-12-06 15:21:32,138 : INFO : EPOCH 5: training on 99524 raw words (60482 effective words) took 0.2s, 386558 effective words/s\n",
      "2023-12-06 15:21:32,293 : INFO : EPOCH 6: training on 99524 raw words (60235 effective words) took 0.2s, 399689 effective words/s\n",
      "2023-12-06 15:21:32,455 : INFO : EPOCH 7: training on 99524 raw words (60513 effective words) took 0.2s, 382983 effective words/s\n",
      "2023-12-06 15:21:32,615 : INFO : EPOCH 8: training on 99524 raw words (60448 effective words) took 0.2s, 390385 effective words/s\n",
      "2023-12-06 15:21:32,775 : INFO : EPOCH 9: training on 99524 raw words (60408 effective words) took 0.2s, 386425 effective words/s\n",
      "2023-12-06 15:21:32,777 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604139 effective words) took 1.6s, 369471 effective words/s', 'datetime': '2023-12-06T15:21:32.777375', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:21:32,777 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:21:32.777375', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 87%| | 424/486 [1:07:54<09:14,  8.95s/it]2023-12-06 15:21:35,606 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:21:35,606 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:21:35,628 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:21:35,629 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:21:35,635 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:21:35.635440', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:21:35,635 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:21:35.635947', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:21:35,642 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:21:35,643 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:21:35,643 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:21:35.643304', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:21:35,652 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:21:35,653 : INFO : resetting layer weights\n",
      "2023-12-06 15:21:35,658 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:21:35.658284', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:21:35,814 : INFO : EPOCH 0: training on 99524 raw words (60220 effective words) took 0.2s, 397851 effective words/s\n",
      "2023-12-06 15:21:35,997 : INFO : EPOCH 1: training on 99524 raw words (60498 effective words) took 0.2s, 337715 effective words/s\n",
      "2023-12-06 15:21:36,183 : INFO : EPOCH 2: training on 99524 raw words (60414 effective words) took 0.2s, 341248 effective words/s\n",
      "2023-12-06 15:21:36,348 : INFO : EPOCH 3: training on 99524 raw words (60245 effective words) took 0.2s, 377168 effective words/s\n",
      "2023-12-06 15:21:36,513 : INFO : EPOCH 4: training on 99524 raw words (60442 effective words) took 0.2s, 375613 effective words/s\n",
      "2023-12-06 15:21:36,678 : INFO : EPOCH 5: training on 99524 raw words (60406 effective words) took 0.2s, 375839 effective words/s\n",
      "2023-12-06 15:21:36,848 : INFO : EPOCH 6: training on 99524 raw words (60385 effective words) took 0.2s, 364015 effective words/s\n",
      "2023-12-06 15:21:37,009 : INFO : EPOCH 7: training on 99524 raw words (60447 effective words) took 0.2s, 388548 effective words/s\n",
      "2023-12-06 15:21:37,175 : INFO : EPOCH 8: training on 99524 raw words (60382 effective words) took 0.2s, 375245 effective words/s\n",
      "2023-12-06 15:21:37,343 : INFO : EPOCH 9: training on 99524 raw words (60483 effective words) took 0.2s, 370243 effective words/s\n",
      "2023-12-06 15:21:37,344 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603922 effective words) took 1.7s, 358383 effective words/s', 'datetime': '2023-12-06T15:21:37.344263', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:21:37,344 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:21:37.344263', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 87%| | 425/486 [1:07:58<07:46,  7.65s/it]2023-12-06 15:21:40,232 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:21:40,233 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:21:40,259 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:21:40,260 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:21:40,264 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:21:40.264908', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:21:40,264 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:21:40.264908', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:21:40,269 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:21:40,270 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:21:40,270 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:21:40.270807', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:21:40,278 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:21:40,278 : INFO : resetting layer weights\n",
      "2023-12-06 15:21:40,282 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:21:40.282648', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:21:40,436 : INFO : EPOCH 0: training on 99524 raw words (60497 effective words) took 0.1s, 404838 effective words/s\n",
      "2023-12-06 15:21:40,620 : INFO : EPOCH 1: training on 99524 raw words (60549 effective words) took 0.2s, 337862 effective words/s\n",
      "2023-12-06 15:21:40,799 : INFO : EPOCH 2: training on 99524 raw words (60335 effective words) took 0.2s, 351185 effective words/s\n",
      "2023-12-06 15:21:40,963 : INFO : EPOCH 3: training on 99524 raw words (60434 effective words) took 0.2s, 377285 effective words/s\n",
      "2023-12-06 15:21:41,127 : INFO : EPOCH 4: training on 99524 raw words (60414 effective words) took 0.2s, 379507 effective words/s\n",
      "2023-12-06 15:21:41,285 : INFO : EPOCH 5: training on 99524 raw words (60383 effective words) took 0.2s, 394601 effective words/s\n",
      "2023-12-06 15:21:41,462 : INFO : EPOCH 6: training on 99524 raw words (60567 effective words) took 0.2s, 348587 effective words/s\n",
      "2023-12-06 15:21:41,629 : INFO : EPOCH 7: training on 99524 raw words (60535 effective words) took 0.2s, 375524 effective words/s\n",
      "2023-12-06 15:21:41,792 : INFO : EPOCH 8: training on 99524 raw words (60398 effective words) took 0.2s, 378791 effective words/s\n",
      "2023-12-06 15:21:41,957 : INFO : EPOCH 9: training on 99524 raw words (60463 effective words) took 0.2s, 377575 effective words/s\n",
      "2023-12-06 15:21:41,958 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604575 effective words) took 1.7s, 361008 effective words/s', 'datetime': '2023-12-06T15:21:41.958650', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:21:41,958 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:21:41.958650', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 88%| | 426/486 [1:08:03<06:46,  6.77s/it]2023-12-06 15:21:44,948 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:21:44,949 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:21:44,971 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:21:44,972 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:21:44,978 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:21:44.978794', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:21:44,978 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:21:44.978794', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:21:44,984 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:21:44,984 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:21:44,985 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:21:44.985564', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:21:44,992 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:21:44,993 : INFO : resetting layer weights\n",
      "2023-12-06 15:21:44,997 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:21:44.997564', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:21:45,140 : INFO : EPOCH 0: training on 99524 raw words (60424 effective words) took 0.1s, 433224 effective words/s\n",
      "2023-12-06 15:21:45,311 : INFO : EPOCH 1: training on 99524 raw words (60413 effective words) took 0.2s, 361645 effective words/s\n",
      "2023-12-06 15:21:45,497 : INFO : EPOCH 2: training on 99524 raw words (60619 effective words) took 0.2s, 335674 effective words/s\n",
      "2023-12-06 15:21:45,665 : INFO : EPOCH 3: training on 99524 raw words (60338 effective words) took 0.2s, 372040 effective words/s\n",
      "2023-12-06 15:21:45,827 : INFO : EPOCH 4: training on 99524 raw words (60401 effective words) took 0.2s, 386350 effective words/s\n",
      "2023-12-06 15:21:45,994 : INFO : EPOCH 5: training on 99524 raw words (60453 effective words) took 0.2s, 372054 effective words/s\n",
      "2023-12-06 15:21:46,164 : INFO : EPOCH 6: training on 99524 raw words (60386 effective words) took 0.2s, 371214 effective words/s\n",
      "2023-12-06 15:21:46,336 : INFO : EPOCH 7: training on 99524 raw words (60427 effective words) took 0.2s, 361283 effective words/s\n",
      "2023-12-06 15:21:46,495 : INFO : EPOCH 8: training on 99524 raw words (60526 effective words) took 0.2s, 392111 effective words/s\n",
      "2023-12-06 15:21:46,659 : INFO : EPOCH 9: training on 99524 raw words (60264 effective words) took 0.2s, 379442 effective words/s\n",
      "2023-12-06 15:21:46,823 : INFO : EPOCH 10: training on 99524 raw words (60371 effective words) took 0.2s, 380074 effective words/s\n",
      "2023-12-06 15:21:46,988 : INFO : EPOCH 11: training on 99524 raw words (60464 effective words) took 0.2s, 376507 effective words/s\n",
      "2023-12-06 15:21:47,156 : INFO : EPOCH 12: training on 99524 raw words (60338 effective words) took 0.2s, 367406 effective words/s\n",
      "2023-12-06 15:21:47,335 : INFO : EPOCH 13: training on 99524 raw words (60400 effective words) took 0.2s, 352009 effective words/s\n",
      "2023-12-06 15:21:47,511 : INFO : EPOCH 14: training on 99524 raw words (60327 effective words) took 0.2s, 355958 effective words/s\n",
      "2023-12-06 15:21:47,670 : INFO : EPOCH 15: training on 99524 raw words (60266 effective words) took 0.2s, 392248 effective words/s\n",
      "2023-12-06 15:21:47,823 : INFO : EPOCH 16: training on 99524 raw words (60312 effective words) took 0.1s, 405138 effective words/s\n",
      "2023-12-06 15:21:47,982 : INFO : EPOCH 17: training on 99524 raw words (60079 effective words) took 0.2s, 388102 effective words/s\n",
      "2023-12-06 15:21:48,152 : INFO : EPOCH 18: training on 99524 raw words (60385 effective words) took 0.2s, 370957 effective words/s\n",
      "2023-12-06 15:21:48,311 : INFO : EPOCH 19: training on 99524 raw words (60432 effective words) took 0.2s, 389331 effective words/s\n",
      "2023-12-06 15:21:48,473 : INFO : EPOCH 20: training on 99524 raw words (60323 effective words) took 0.2s, 385885 effective words/s\n",
      "2023-12-06 15:21:48,631 : INFO : EPOCH 21: training on 99524 raw words (60318 effective words) took 0.2s, 389914 effective words/s\n",
      "2023-12-06 15:21:48,791 : INFO : EPOCH 22: training on 99524 raw words (60386 effective words) took 0.2s, 388534 effective words/s\n",
      "2023-12-06 15:21:48,951 : INFO : EPOCH 23: training on 99524 raw words (60275 effective words) took 0.2s, 389205 effective words/s\n",
      "2023-12-06 15:21:49,116 : INFO : EPOCH 24: training on 99524 raw words (60509 effective words) took 0.2s, 378578 effective words/s\n",
      "2023-12-06 15:21:49,275 : INFO : EPOCH 25: training on 99524 raw words (60399 effective words) took 0.2s, 392235 effective words/s\n",
      "2023-12-06 15:21:49,431 : INFO : EPOCH 26: training on 99524 raw words (60597 effective words) took 0.2s, 398698 effective words/s\n",
      "2023-12-06 15:21:49,590 : INFO : EPOCH 27: training on 99524 raw words (60643 effective words) took 0.2s, 391463 effective words/s\n",
      "2023-12-06 15:21:49,755 : INFO : EPOCH 28: training on 99524 raw words (60380 effective words) took 0.2s, 376790 effective words/s\n",
      "2023-12-06 15:21:49,917 : INFO : EPOCH 29: training on 99524 raw words (60465 effective words) took 0.2s, 383661 effective words/s\n",
      "2023-12-06 15:21:49,918 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811920 effective words) took 4.9s, 368253 effective words/s', 'datetime': '2023-12-06T15:21:49.918238', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:21:49,919 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:21:49.919238', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 88%| | 427/486 [1:08:11<07:02,  7.16s/it]2023-12-06 15:21:53,013 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:21:53,014 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:21:53,035 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:21:53,036 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:21:53,040 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:21:53.040480', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:21:53,040 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:21:53.040480', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:21:53,045 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:21:53,046 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:21:53,046 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:21:53.046489', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:21:53,052 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:21:53,053 : INFO : resetting layer weights\n",
      "2023-12-06 15:21:53,057 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:21:53.057060', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:21:53,181 : INFO : EPOCH 0: training on 99524 raw words (60360 effective words) took 0.1s, 501511 effective words/s\n",
      "2023-12-06 15:21:53,345 : INFO : EPOCH 1: training on 99524 raw words (60440 effective words) took 0.2s, 378453 effective words/s\n",
      "2023-12-06 15:21:53,505 : INFO : EPOCH 2: training on 99524 raw words (60408 effective words) took 0.2s, 396343 effective words/s\n",
      "2023-12-06 15:21:53,641 : INFO : EPOCH 3: training on 99524 raw words (60189 effective words) took 0.1s, 458410 effective words/s\n",
      "2023-12-06 15:21:53,777 : INFO : EPOCH 4: training on 99524 raw words (60304 effective words) took 0.1s, 454350 effective words/s\n",
      "2023-12-06 15:21:53,915 : INFO : EPOCH 5: training on 99524 raw words (60393 effective words) took 0.1s, 451864 effective words/s\n",
      "2023-12-06 15:21:54,051 : INFO : EPOCH 6: training on 99524 raw words (60500 effective words) took 0.1s, 458960 effective words/s\n",
      "2023-12-06 15:21:54,236 : INFO : EPOCH 7: training on 99524 raw words (60497 effective words) took 0.2s, 335346 effective words/s\n",
      "2023-12-06 15:21:54,373 : INFO : EPOCH 8: training on 99524 raw words (60366 effective words) took 0.1s, 457072 effective words/s\n",
      "2023-12-06 15:21:54,509 : INFO : EPOCH 9: training on 99524 raw words (60386 effective words) took 0.1s, 459014 effective words/s\n",
      "2023-12-06 15:21:54,644 : INFO : EPOCH 10: training on 99524 raw words (60353 effective words) took 0.1s, 462074 effective words/s\n",
      "2023-12-06 15:21:54,779 : INFO : EPOCH 11: training on 99524 raw words (60567 effective words) took 0.1s, 463976 effective words/s\n",
      "2023-12-06 15:21:54,913 : INFO : EPOCH 12: training on 99524 raw words (60229 effective words) took 0.1s, 459955 effective words/s\n",
      "2023-12-06 15:21:55,080 : INFO : EPOCH 13: training on 99524 raw words (60397 effective words) took 0.2s, 372062 effective words/s\n",
      "2023-12-06 15:21:55,216 : INFO : EPOCH 14: training on 99524 raw words (60388 effective words) took 0.1s, 457101 effective words/s\n",
      "2023-12-06 15:21:55,354 : INFO : EPOCH 15: training on 99524 raw words (60220 effective words) took 0.1s, 452792 effective words/s\n",
      "2023-12-06 15:21:55,496 : INFO : EPOCH 16: training on 99524 raw words (60325 effective words) took 0.1s, 439866 effective words/s\n",
      "2023-12-06 15:21:55,639 : INFO : EPOCH 17: training on 99524 raw words (60143 effective words) took 0.1s, 431937 effective words/s\n",
      "2023-12-06 15:21:55,792 : INFO : EPOCH 18: training on 99524 raw words (60385 effective words) took 0.1s, 405720 effective words/s\n",
      "2023-12-06 15:21:55,951 : INFO : EPOCH 19: training on 99524 raw words (60520 effective words) took 0.2s, 402214 effective words/s\n",
      "2023-12-06 15:21:56,097 : INFO : EPOCH 20: training on 99524 raw words (60449 effective words) took 0.1s, 428686 effective words/s\n",
      "2023-12-06 15:21:56,239 : INFO : EPOCH 21: training on 99524 raw words (60454 effective words) took 0.1s, 438122 effective words/s\n",
      "2023-12-06 15:21:56,389 : INFO : EPOCH 22: training on 99524 raw words (60491 effective words) took 0.1s, 418802 effective words/s\n",
      "2023-12-06 15:21:56,553 : INFO : EPOCH 23: training on 99524 raw words (60282 effective words) took 0.2s, 379183 effective words/s\n",
      "2023-12-06 15:21:56,702 : INFO : EPOCH 24: training on 99524 raw words (60474 effective words) took 0.1s, 422015 effective words/s\n",
      "2023-12-06 15:21:56,872 : INFO : EPOCH 25: training on 99524 raw words (60237 effective words) took 0.2s, 362944 effective words/s\n",
      "2023-12-06 15:21:57,016 : INFO : EPOCH 26: training on 99524 raw words (60313 effective words) took 0.1s, 430906 effective words/s\n",
      "2023-12-06 15:21:57,151 : INFO : EPOCH 27: training on 99524 raw words (60526 effective words) took 0.1s, 466502 effective words/s\n",
      "2023-12-06 15:21:57,280 : INFO : EPOCH 28: training on 99524 raw words (60485 effective words) took 0.1s, 484948 effective words/s\n",
      "2023-12-06 15:21:57,422 : INFO : EPOCH 29: training on 99524 raw words (60529 effective words) took 0.1s, 450682 effective words/s\n",
      "2023-12-06 15:21:57,423 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811610 effective words) took 4.4s, 414999 effective words/s', 'datetime': '2023-12-06T15:21:57.423300', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:21:57,424 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:21:57.424302', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 88%| | 428/486 [1:08:19<07:04,  7.33s/it]2023-12-06 15:22:00,730 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:22:00,731 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:22:00,752 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:22:00,752 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:22:00,757 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:22:00.757909', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:22:00,758 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:22:00.758919', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:22:00,763 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:22:00,764 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:22:00,764 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:22:00.764420', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:22:00,771 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:22:00,772 : INFO : resetting layer weights\n",
      "2023-12-06 15:22:00,776 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:22:00.776686', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:22:00,902 : INFO : EPOCH 0: training on 99524 raw words (60430 effective words) took 0.1s, 491908 effective words/s\n",
      "2023-12-06 15:22:01,079 : INFO : EPOCH 1: training on 99524 raw words (60491 effective words) took 0.2s, 350384 effective words/s\n",
      "2023-12-06 15:22:01,254 : INFO : EPOCH 2: training on 99524 raw words (60543 effective words) took 0.2s, 358319 effective words/s\n",
      "2023-12-06 15:22:01,385 : INFO : EPOCH 3: training on 99524 raw words (60279 effective words) took 0.1s, 482700 effective words/s\n",
      "2023-12-06 15:22:01,516 : INFO : EPOCH 4: training on 99524 raw words (60387 effective words) took 0.1s, 475261 effective words/s\n",
      "2023-12-06 15:22:01,659 : INFO : EPOCH 5: training on 99524 raw words (60461 effective words) took 0.1s, 433663 effective words/s\n",
      "2023-12-06 15:22:01,789 : INFO : EPOCH 6: training on 99524 raw words (60445 effective words) took 0.1s, 481986 effective words/s\n",
      "2023-12-06 15:22:01,927 : INFO : EPOCH 7: training on 99524 raw words (60363 effective words) took 0.1s, 454568 effective words/s\n",
      "2023-12-06 15:22:02,097 : INFO : EPOCH 8: training on 99524 raw words (60460 effective words) took 0.2s, 364385 effective words/s\n",
      "2023-12-06 15:22:02,261 : INFO : EPOCH 9: training on 99524 raw words (60280 effective words) took 0.2s, 378579 effective words/s\n",
      "2023-12-06 15:22:02,391 : INFO : EPOCH 10: training on 99524 raw words (60381 effective words) took 0.1s, 478153 effective words/s\n",
      "2023-12-06 15:22:02,523 : INFO : EPOCH 11: training on 99524 raw words (60368 effective words) took 0.1s, 473910 effective words/s\n",
      "2023-12-06 15:22:02,653 : INFO : EPOCH 12: training on 99524 raw words (60532 effective words) took 0.1s, 480851 effective words/s\n",
      "2023-12-06 15:22:02,819 : INFO : EPOCH 13: training on 99524 raw words (60398 effective words) took 0.2s, 376892 effective words/s\n",
      "2023-12-06 15:22:02,948 : INFO : EPOCH 14: training on 99524 raw words (60478 effective words) took 0.1s, 486380 effective words/s\n",
      "2023-12-06 15:22:03,087 : INFO : EPOCH 15: training on 99524 raw words (60424 effective words) took 0.1s, 450612 effective words/s\n",
      "2023-12-06 15:22:03,223 : INFO : EPOCH 16: training on 99524 raw words (60319 effective words) took 0.1s, 454827 effective words/s\n",
      "2023-12-06 15:22:03,393 : INFO : EPOCH 17: training on 99524 raw words (60243 effective words) took 0.2s, 363903 effective words/s\n",
      "2023-12-06 15:22:03,533 : INFO : EPOCH 18: training on 99524 raw words (60288 effective words) took 0.1s, 446351 effective words/s\n",
      "2023-12-06 15:22:03,695 : INFO : EPOCH 19: training on 99524 raw words (60483 effective words) took 0.2s, 385223 effective words/s\n",
      "2023-12-06 15:22:03,843 : INFO : EPOCH 20: training on 99524 raw words (60289 effective words) took 0.1s, 421167 effective words/s\n",
      "2023-12-06 15:22:03,988 : INFO : EPOCH 21: training on 99524 raw words (60548 effective words) took 0.1s, 431247 effective words/s\n",
      "2023-12-06 15:22:04,131 : INFO : EPOCH 22: training on 99524 raw words (60315 effective words) took 0.1s, 435688 effective words/s\n",
      "2023-12-06 15:22:04,284 : INFO : EPOCH 23: training on 99524 raw words (60511 effective words) took 0.1s, 407026 effective words/s\n",
      "2023-12-06 15:22:04,429 : INFO : EPOCH 24: training on 99524 raw words (60484 effective words) took 0.1s, 429750 effective words/s\n",
      "2023-12-06 15:22:04,593 : INFO : EPOCH 25: training on 99524 raw words (60408 effective words) took 0.2s, 377682 effective words/s\n",
      "2023-12-06 15:22:04,733 : INFO : EPOCH 26: training on 99524 raw words (60467 effective words) took 0.1s, 444122 effective words/s\n",
      "2023-12-06 15:22:04,882 : INFO : EPOCH 27: training on 99524 raw words (60463 effective words) took 0.1s, 423129 effective words/s\n",
      "2023-12-06 15:22:05,022 : INFO : EPOCH 28: training on 99524 raw words (60285 effective words) took 0.1s, 444173 effective words/s\n",
      "2023-12-06 15:22:05,167 : INFO : EPOCH 29: training on 99524 raw words (60492 effective words) took 0.1s, 430480 effective words/s\n",
      "2023-12-06 15:22:05,168 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812315 effective words) took 4.4s, 412648 effective words/s', 'datetime': '2023-12-06T15:22:05.168869', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:22:05,169 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:22:05.169873', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 88%| | 429/486 [1:08:27<07:06,  7.48s/it]2023-12-06 15:22:08,566 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:22:08,567 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:22:08,588 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:22:08,589 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:22:08,593 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:22:08.593095', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:22:08,594 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:22:08.594095', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:22:08,598 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:22:08,598 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:22:08,598 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:22:08.598671', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:22:08,606 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:22:08,607 : INFO : resetting layer weights\n",
      "2023-12-06 15:22:08,611 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:22:08.611043', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:22:08,737 : INFO : EPOCH 0: training on 99524 raw words (60348 effective words) took 0.1s, 491573 effective words/s\n",
      "2023-12-06 15:22:08,904 : INFO : EPOCH 1: training on 99524 raw words (60477 effective words) took 0.2s, 371213 effective words/s\n",
      "2023-12-06 15:22:09,060 : INFO : EPOCH 2: training on 99524 raw words (60511 effective words) took 0.1s, 407094 effective words/s\n",
      "2023-12-06 15:22:09,195 : INFO : EPOCH 3: training on 99524 raw words (60316 effective words) took 0.1s, 456085 effective words/s\n",
      "2023-12-06 15:22:09,328 : INFO : EPOCH 4: training on 99524 raw words (60419 effective words) took 0.1s, 470780 effective words/s\n",
      "2023-12-06 15:22:09,463 : INFO : EPOCH 5: training on 99524 raw words (60436 effective words) took 0.1s, 461115 effective words/s\n",
      "2023-12-06 15:22:09,598 : INFO : EPOCH 6: training on 99524 raw words (60325 effective words) took 0.1s, 464262 effective words/s\n",
      "2023-12-06 15:22:09,750 : INFO : EPOCH 7: training on 99524 raw words (60525 effective words) took 0.1s, 409647 effective words/s\n",
      "2023-12-06 15:22:09,886 : INFO : EPOCH 8: training on 99524 raw words (60563 effective words) took 0.1s, 457557 effective words/s\n",
      "2023-12-06 15:22:10,023 : INFO : EPOCH 9: training on 99524 raw words (60352 effective words) took 0.1s, 454643 effective words/s\n",
      "2023-12-06 15:22:10,158 : INFO : EPOCH 10: training on 99524 raw words (60284 effective words) took 0.1s, 460877 effective words/s\n",
      "2023-12-06 15:22:10,291 : INFO : EPOCH 11: training on 99524 raw words (60434 effective words) took 0.1s, 469117 effective words/s\n",
      "2023-12-06 15:22:10,427 : INFO : EPOCH 12: training on 99524 raw words (60479 effective words) took 0.1s, 460172 effective words/s\n",
      "2023-12-06 15:22:10,574 : INFO : EPOCH 13: training on 99524 raw words (60518 effective words) took 0.1s, 422025 effective words/s\n",
      "2023-12-06 15:22:10,709 : INFO : EPOCH 14: training on 99524 raw words (60486 effective words) took 0.1s, 462405 effective words/s\n",
      "2023-12-06 15:22:10,843 : INFO : EPOCH 15: training on 99524 raw words (60253 effective words) took 0.1s, 465305 effective words/s\n",
      "2023-12-06 15:22:10,978 : INFO : EPOCH 16: training on 99524 raw words (60507 effective words) took 0.1s, 459176 effective words/s\n",
      "2023-12-06 15:22:11,134 : INFO : EPOCH 17: training on 99524 raw words (60246 effective words) took 0.2s, 397810 effective words/s\n",
      "2023-12-06 15:22:11,268 : INFO : EPOCH 18: training on 99524 raw words (60333 effective words) took 0.1s, 464714 effective words/s\n",
      "2023-12-06 15:22:11,404 : INFO : EPOCH 19: training on 99524 raw words (60470 effective words) took 0.1s, 457738 effective words/s\n",
      "2023-12-06 15:22:11,539 : INFO : EPOCH 20: training on 99524 raw words (60391 effective words) took 0.1s, 461012 effective words/s\n",
      "2023-12-06 15:22:11,674 : INFO : EPOCH 21: training on 99524 raw words (60605 effective words) took 0.1s, 465209 effective words/s\n",
      "2023-12-06 15:22:11,809 : INFO : EPOCH 22: training on 99524 raw words (60462 effective words) took 0.1s, 460499 effective words/s\n",
      "2023-12-06 15:22:11,958 : INFO : EPOCH 23: training on 99524 raw words (60381 effective words) took 0.1s, 421436 effective words/s\n",
      "2023-12-06 15:22:12,097 : INFO : EPOCH 24: training on 99524 raw words (60388 effective words) took 0.1s, 448785 effective words/s\n",
      "2023-12-06 15:22:12,226 : INFO : EPOCH 25: training on 99524 raw words (60290 effective words) took 0.1s, 487354 effective words/s\n",
      "2023-12-06 15:22:12,358 : INFO : EPOCH 26: training on 99524 raw words (60442 effective words) took 0.1s, 471865 effective words/s\n",
      "2023-12-06 15:22:12,499 : INFO : EPOCH 27: training on 99524 raw words (60503 effective words) took 0.1s, 440534 effective words/s\n",
      "2023-12-06 15:22:12,638 : INFO : EPOCH 28: training on 99524 raw words (60494 effective words) took 0.1s, 446960 effective words/s\n",
      "2023-12-06 15:22:12,776 : INFO : EPOCH 29: training on 99524 raw words (60525 effective words) took 0.1s, 456242 effective words/s\n",
      "2023-12-06 15:22:12,911 : INFO : EPOCH 30: training on 99524 raw words (60484 effective words) took 0.1s, 461420 effective words/s\n",
      "2023-12-06 15:22:13,044 : INFO : EPOCH 31: training on 99524 raw words (60394 effective words) took 0.1s, 466767 effective words/s\n",
      "2023-12-06 15:22:13,180 : INFO : EPOCH 32: training on 99524 raw words (60332 effective words) took 0.1s, 461448 effective words/s\n",
      "2023-12-06 15:22:13,320 : INFO : EPOCH 33: training on 99524 raw words (60439 effective words) took 0.1s, 446697 effective words/s\n",
      "2023-12-06 15:22:13,487 : INFO : EPOCH 34: training on 99524 raw words (60462 effective words) took 0.2s, 368023 effective words/s\n",
      "2023-12-06 15:22:13,623 : INFO : EPOCH 35: training on 99524 raw words (60375 effective words) took 0.1s, 458013 effective words/s\n",
      "2023-12-06 15:22:13,759 : INFO : EPOCH 36: training on 99524 raw words (60433 effective words) took 0.1s, 461686 effective words/s\n",
      "2023-12-06 15:22:13,894 : INFO : EPOCH 37: training on 99524 raw words (60351 effective words) took 0.1s, 462049 effective words/s\n",
      "2023-12-06 15:22:14,039 : INFO : EPOCH 38: training on 99524 raw words (60246 effective words) took 0.1s, 428958 effective words/s\n",
      "2023-12-06 15:22:14,172 : INFO : EPOCH 39: training on 99524 raw words (60382 effective words) took 0.1s, 463964 effective words/s\n",
      "2023-12-06 15:22:14,322 : INFO : EPOCH 40: training on 99524 raw words (60420 effective words) took 0.1s, 416409 effective words/s\n",
      "2023-12-06 15:22:14,461 : INFO : EPOCH 41: training on 99524 raw words (60643 effective words) took 0.1s, 451407 effective words/s\n",
      "2023-12-06 15:22:14,596 : INFO : EPOCH 42: training on 99524 raw words (60338 effective words) took 0.1s, 461596 effective words/s\n",
      "2023-12-06 15:22:14,731 : INFO : EPOCH 43: training on 99524 raw words (60353 effective words) took 0.1s, 462861 effective words/s\n",
      "2023-12-06 15:22:14,883 : INFO : EPOCH 44: training on 99524 raw words (60399 effective words) took 0.1s, 410265 effective words/s\n",
      "2023-12-06 15:22:15,019 : INFO : EPOCH 45: training on 99524 raw words (60402 effective words) took 0.1s, 459495 effective words/s\n",
      "2023-12-06 15:22:15,154 : INFO : EPOCH 46: training on 99524 raw words (60503 effective words) took 0.1s, 459687 effective words/s\n",
      "2023-12-06 15:22:15,287 : INFO : EPOCH 47: training on 99524 raw words (60443 effective words) took 0.1s, 468378 effective words/s\n",
      "2023-12-06 15:22:15,443 : INFO : EPOCH 48: training on 99524 raw words (60480 effective words) took 0.2s, 397711 effective words/s\n",
      "2023-12-06 15:22:15,587 : INFO : EPOCH 49: training on 99524 raw words (60504 effective words) took 0.1s, 435615 effective words/s\n",
      "2023-12-06 15:22:15,588 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3021146 effective words) took 7.0s, 433007 effective words/s', 'datetime': '2023-12-06T15:22:15.588755', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:22:15,588 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:22:15.588755', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 88%| | 430/486 [1:08:37<07:47,  8.34s/it]2023-12-06 15:22:18,930 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:22:18,931 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:22:18,954 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:22:18,955 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:22:18,959 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:22:18.959817', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:22:18,959 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:22:18.959817', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:22:18,964 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:22:18,965 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:22:18,965 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:22:18.965325', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:22:18,972 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:22:18,972 : INFO : resetting layer weights\n",
      "2023-12-06 15:22:18,977 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:22:18.977023', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:22:19,102 : INFO : EPOCH 0: training on 99524 raw words (60354 effective words) took 0.1s, 498764 effective words/s\n",
      "2023-12-06 15:22:19,283 : INFO : EPOCH 1: training on 99524 raw words (60492 effective words) took 0.2s, 348396 effective words/s\n",
      "2023-12-06 15:22:19,437 : INFO : EPOCH 2: training on 99524 raw words (60430 effective words) took 0.1s, 411308 effective words/s\n",
      "2023-12-06 15:22:19,574 : INFO : EPOCH 3: training on 99524 raw words (60265 effective words) took 0.1s, 452833 effective words/s\n",
      "2023-12-06 15:22:19,708 : INFO : EPOCH 4: training on 99524 raw words (60166 effective words) took 0.1s, 462219 effective words/s\n",
      "2023-12-06 15:22:19,845 : INFO : EPOCH 5: training on 99524 raw words (60348 effective words) took 0.1s, 457019 effective words/s\n",
      "2023-12-06 15:22:19,981 : INFO : EPOCH 6: training on 99524 raw words (60453 effective words) took 0.1s, 459942 effective words/s\n",
      "2023-12-06 15:22:20,145 : INFO : EPOCH 7: training on 99524 raw words (60605 effective words) took 0.2s, 378740 effective words/s\n",
      "2023-12-06 15:22:20,281 : INFO : EPOCH 8: training on 99524 raw words (60420 effective words) took 0.1s, 455660 effective words/s\n",
      "2023-12-06 15:22:20,419 : INFO : EPOCH 9: training on 99524 raw words (60428 effective words) took 0.1s, 453860 effective words/s\n",
      "2023-12-06 15:22:20,553 : INFO : EPOCH 10: training on 99524 raw words (60435 effective words) took 0.1s, 464257 effective words/s\n",
      "2023-12-06 15:22:20,714 : INFO : EPOCH 11: training on 99524 raw words (60472 effective words) took 0.2s, 383781 effective words/s\n",
      "2023-12-06 15:22:20,853 : INFO : EPOCH 12: training on 99524 raw words (60229 effective words) took 0.1s, 447864 effective words/s\n",
      "2023-12-06 15:22:20,990 : INFO : EPOCH 13: training on 99524 raw words (60419 effective words) took 0.1s, 455810 effective words/s\n",
      "2023-12-06 15:22:21,126 : INFO : EPOCH 14: training on 99524 raw words (60380 effective words) took 0.1s, 457494 effective words/s\n",
      "2023-12-06 15:22:21,271 : INFO : EPOCH 15: training on 99524 raw words (60527 effective words) took 0.1s, 430140 effective words/s\n",
      "2023-12-06 15:22:21,418 : INFO : EPOCH 16: training on 99524 raw words (60422 effective words) took 0.1s, 430495 effective words/s\n",
      "2023-12-06 15:22:21,552 : INFO : EPOCH 17: training on 99524 raw words (60376 effective words) took 0.1s, 464459 effective words/s\n",
      "2023-12-06 15:22:21,688 : INFO : EPOCH 18: training on 99524 raw words (60166 effective words) took 0.1s, 457661 effective words/s\n",
      "2023-12-06 15:22:21,822 : INFO : EPOCH 19: training on 99524 raw words (60623 effective words) took 0.1s, 468501 effective words/s\n",
      "2023-12-06 15:22:21,987 : INFO : EPOCH 20: training on 99524 raw words (60342 effective words) took 0.2s, 374308 effective words/s\n",
      "2023-12-06 15:22:22,125 : INFO : EPOCH 21: training on 99524 raw words (60300 effective words) took 0.1s, 451113 effective words/s\n",
      "2023-12-06 15:22:22,267 : INFO : EPOCH 22: training on 99524 raw words (60352 effective words) took 0.1s, 441695 effective words/s\n",
      "2023-12-06 15:22:22,405 : INFO : EPOCH 23: training on 99524 raw words (60443 effective words) took 0.1s, 449979 effective words/s\n",
      "2023-12-06 15:22:22,562 : INFO : EPOCH 24: training on 99524 raw words (60412 effective words) took 0.2s, 396394 effective words/s\n",
      "2023-12-06 15:22:22,696 : INFO : EPOCH 25: training on 99524 raw words (60304 effective words) took 0.1s, 462411 effective words/s\n",
      "2023-12-06 15:22:22,835 : INFO : EPOCH 26: training on 99524 raw words (60479 effective words) took 0.1s, 449758 effective words/s\n",
      "2023-12-06 15:22:22,967 : INFO : EPOCH 27: training on 99524 raw words (60525 effective words) took 0.1s, 474225 effective words/s\n",
      "2023-12-06 15:22:23,102 : INFO : EPOCH 28: training on 99524 raw words (60532 effective words) took 0.1s, 460222 effective words/s\n",
      "2023-12-06 15:22:23,237 : INFO : EPOCH 29: training on 99524 raw words (60486 effective words) took 0.1s, 464280 effective words/s\n",
      "2023-12-06 15:22:23,399 : INFO : EPOCH 30: training on 99524 raw words (60324 effective words) took 0.2s, 383399 effective words/s\n",
      "2023-12-06 15:22:23,533 : INFO : EPOCH 31: training on 99524 raw words (60479 effective words) took 0.1s, 463078 effective words/s\n",
      "2023-12-06 15:22:23,667 : INFO : EPOCH 32: training on 99524 raw words (60355 effective words) took 0.1s, 465021 effective words/s\n",
      "2023-12-06 15:22:23,811 : INFO : EPOCH 33: training on 99524 raw words (60563 effective words) took 0.1s, 438035 effective words/s\n",
      "2023-12-06 15:22:23,944 : INFO : EPOCH 34: training on 99524 raw words (60373 effective words) took 0.1s, 462325 effective words/s\n",
      "2023-12-06 15:22:24,080 : INFO : EPOCH 35: training on 99524 raw words (60446 effective words) took 0.1s, 458482 effective words/s\n",
      "2023-12-06 15:22:24,240 : INFO : EPOCH 36: training on 99524 raw words (60357 effective words) took 0.2s, 390629 effective words/s\n",
      "2023-12-06 15:22:24,379 : INFO : EPOCH 37: training on 99524 raw words (60367 effective words) took 0.1s, 447979 effective words/s\n",
      "2023-12-06 15:22:24,533 : INFO : EPOCH 38: training on 99524 raw words (60398 effective words) took 0.1s, 406314 effective words/s\n",
      "2023-12-06 15:22:24,678 : INFO : EPOCH 39: training on 99524 raw words (60395 effective words) took 0.1s, 427879 effective words/s\n",
      "2023-12-06 15:22:24,813 : INFO : EPOCH 40: training on 99524 raw words (60413 effective words) took 0.1s, 461525 effective words/s\n",
      "2023-12-06 15:22:24,947 : INFO : EPOCH 41: training on 99524 raw words (60518 effective words) took 0.1s, 465182 effective words/s\n",
      "2023-12-06 15:22:25,105 : INFO : EPOCH 42: training on 99524 raw words (60403 effective words) took 0.2s, 394323 effective words/s\n",
      "2023-12-06 15:22:25,232 : INFO : EPOCH 43: training on 99524 raw words (60565 effective words) took 0.1s, 492787 effective words/s\n",
      "2023-12-06 15:22:25,380 : INFO : EPOCH 44: training on 99524 raw words (60466 effective words) took 0.1s, 418927 effective words/s\n",
      "2023-12-06 15:22:25,516 : INFO : EPOCH 45: training on 99524 raw words (60495 effective words) took 0.1s, 458939 effective words/s\n",
      "2023-12-06 15:22:25,650 : INFO : EPOCH 46: training on 99524 raw words (60422 effective words) took 0.1s, 461583 effective words/s\n",
      "2023-12-06 15:22:25,787 : INFO : EPOCH 47: training on 99524 raw words (60421 effective words) took 0.1s, 457990 effective words/s\n",
      "2023-12-06 15:22:25,932 : INFO : EPOCH 48: training on 99524 raw words (60462 effective words) took 0.1s, 428115 effective words/s\n",
      "2023-12-06 15:22:26,076 : INFO : EPOCH 49: training on 99524 raw words (60585 effective words) took 0.1s, 436080 effective words/s\n",
      "2023-12-06 15:22:26,077 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3020992 effective words) took 7.1s, 425566 effective words/s', 'datetime': '2023-12-06T15:22:26.077086', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:22:26,077 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:22:26.077086', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 89%| | 431/486 [1:08:48<08:17,  9.05s/it]2023-12-06 15:22:29,641 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:22:29,642 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:22:29,663 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:22:29,664 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:22:29,668 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:22:29.668914', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:22:29,668 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:22:29.668914', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:22:29,673 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:22:29,673 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:22:29,674 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:22:29.674929', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:22:29,680 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:22:29,681 : INFO : resetting layer weights\n",
      "2023-12-06 15:22:29,685 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=5 shrink_windows=True', 'datetime': '2023-12-06T15:22:29.685431', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:22:29,812 : INFO : EPOCH 0: training on 99524 raw words (60316 effective words) took 0.1s, 490033 effective words/s\n",
      "2023-12-06 15:22:29,976 : INFO : EPOCH 1: training on 99524 raw words (60301 effective words) took 0.2s, 381485 effective words/s\n",
      "2023-12-06 15:22:30,125 : INFO : EPOCH 2: training on 99524 raw words (60343 effective words) took 0.1s, 425559 effective words/s\n",
      "2023-12-06 15:22:30,264 : INFO : EPOCH 3: training on 99524 raw words (60356 effective words) took 0.1s, 449056 effective words/s\n",
      "2023-12-06 15:22:30,402 : INFO : EPOCH 4: training on 99524 raw words (60381 effective words) took 0.1s, 452055 effective words/s\n",
      "2023-12-06 15:22:30,540 : INFO : EPOCH 5: training on 99524 raw words (60392 effective words) took 0.1s, 451755 effective words/s\n",
      "2023-12-06 15:22:30,678 : INFO : EPOCH 6: training on 99524 raw words (60484 effective words) took 0.1s, 453703 effective words/s\n",
      "2023-12-06 15:22:30,843 : INFO : EPOCH 7: training on 99524 raw words (60646 effective words) took 0.2s, 377611 effective words/s\n",
      "2023-12-06 15:22:30,980 : INFO : EPOCH 8: training on 99524 raw words (60352 effective words) took 0.1s, 454545 effective words/s\n",
      "2023-12-06 15:22:31,121 : INFO : EPOCH 9: training on 99524 raw words (60478 effective words) took 0.1s, 438949 effective words/s\n",
      "2023-12-06 15:22:31,259 : INFO : EPOCH 10: training on 99524 raw words (60386 effective words) took 0.1s, 453851 effective words/s\n",
      "2023-12-06 15:22:31,403 : INFO : EPOCH 11: training on 99524 raw words (60288 effective words) took 0.1s, 429463 effective words/s\n",
      "2023-12-06 15:22:31,552 : INFO : EPOCH 12: training on 99524 raw words (60398 effective words) took 0.1s, 427650 effective words/s\n",
      "2023-12-06 15:22:31,690 : INFO : EPOCH 13: training on 99524 raw words (60474 effective words) took 0.1s, 453418 effective words/s\n",
      "2023-12-06 15:22:31,828 : INFO : EPOCH 14: training on 99524 raw words (60396 effective words) took 0.1s, 452953 effective words/s\n",
      "2023-12-06 15:22:31,966 : INFO : EPOCH 15: training on 99524 raw words (60272 effective words) took 0.1s, 447763 effective words/s\n",
      "2023-12-06 15:22:32,107 : INFO : EPOCH 16: training on 99524 raw words (60468 effective words) took 0.1s, 445517 effective words/s\n",
      "2023-12-06 15:22:32,267 : INFO : EPOCH 17: training on 99524 raw words (60265 effective words) took 0.2s, 387395 effective words/s\n",
      "2023-12-06 15:22:32,407 : INFO : EPOCH 18: training on 99524 raw words (60422 effective words) took 0.1s, 443839 effective words/s\n",
      "2023-12-06 15:22:32,546 : INFO : EPOCH 19: training on 99524 raw words (60454 effective words) took 0.1s, 447329 effective words/s\n",
      "2023-12-06 15:22:32,685 : INFO : EPOCH 20: training on 99524 raw words (60164 effective words) took 0.1s, 452510 effective words/s\n",
      "2023-12-06 15:22:32,823 : INFO : EPOCH 21: training on 99524 raw words (60561 effective words) took 0.1s, 450612 effective words/s\n",
      "2023-12-06 15:22:32,952 : INFO : EPOCH 22: training on 99524 raw words (60484 effective words) took 0.1s, 485170 effective words/s\n",
      "2023-12-06 15:22:33,138 : INFO : EPOCH 23: training on 99524 raw words (60400 effective words) took 0.2s, 332359 effective words/s\n",
      "2023-12-06 15:22:33,275 : INFO : EPOCH 24: training on 99524 raw words (60312 effective words) took 0.1s, 454057 effective words/s\n",
      "2023-12-06 15:22:33,414 : INFO : EPOCH 25: training on 99524 raw words (60339 effective words) took 0.1s, 447476 effective words/s\n",
      "2023-12-06 15:22:33,555 : INFO : EPOCH 26: training on 99524 raw words (60593 effective words) took 0.1s, 442267 effective words/s\n",
      "2023-12-06 15:22:33,722 : INFO : EPOCH 27: training on 99524 raw words (60644 effective words) took 0.2s, 373935 effective words/s\n",
      "2023-12-06 15:22:33,861 : INFO : EPOCH 28: training on 99524 raw words (60332 effective words) took 0.1s, 445597 effective words/s\n",
      "2023-12-06 15:22:34,007 : INFO : EPOCH 29: training on 99524 raw words (60330 effective words) took 0.1s, 426856 effective words/s\n",
      "2023-12-06 15:22:34,148 : INFO : EPOCH 30: training on 99524 raw words (60264 effective words) took 0.1s, 443531 effective words/s\n",
      "2023-12-06 15:22:34,286 : INFO : EPOCH 31: training on 99524 raw words (60278 effective words) took 0.1s, 447897 effective words/s\n",
      "2023-12-06 15:22:34,423 : INFO : EPOCH 32: training on 99524 raw words (60589 effective words) took 0.1s, 457295 effective words/s\n",
      "2023-12-06 15:22:34,591 : INFO : EPOCH 33: training on 99524 raw words (60525 effective words) took 0.2s, 371277 effective words/s\n",
      "2023-12-06 15:22:34,742 : INFO : EPOCH 34: training on 99524 raw words (60293 effective words) took 0.1s, 409344 effective words/s\n",
      "2023-12-06 15:22:34,879 : INFO : EPOCH 35: training on 99524 raw words (60394 effective words) took 0.1s, 455972 effective words/s\n",
      "2023-12-06 15:22:35,018 : INFO : EPOCH 36: training on 99524 raw words (60350 effective words) took 0.1s, 447620 effective words/s\n",
      "2023-12-06 15:22:35,158 : INFO : EPOCH 37: training on 99524 raw words (60321 effective words) took 0.1s, 443887 effective words/s\n",
      "2023-12-06 15:22:35,326 : INFO : EPOCH 38: training on 99524 raw words (60277 effective words) took 0.2s, 369159 effective words/s\n",
      "2023-12-06 15:22:35,474 : INFO : EPOCH 39: training on 99524 raw words (60507 effective words) took 0.1s, 419500 effective words/s\n",
      "2023-12-06 15:22:35,614 : INFO : EPOCH 40: training on 99524 raw words (60387 effective words) took 0.1s, 444306 effective words/s\n",
      "2023-12-06 15:22:35,752 : INFO : EPOCH 41: training on 99524 raw words (60392 effective words) took 0.1s, 454538 effective words/s\n",
      "2023-12-06 15:22:35,891 : INFO : EPOCH 42: training on 99524 raw words (60391 effective words) took 0.1s, 447872 effective words/s\n",
      "2023-12-06 15:22:36,029 : INFO : EPOCH 43: training on 99524 raw words (60542 effective words) took 0.1s, 453868 effective words/s\n",
      "2023-12-06 15:22:36,201 : INFO : EPOCH 44: training on 99524 raw words (60331 effective words) took 0.2s, 360899 effective words/s\n",
      "2023-12-06 15:22:36,349 : INFO : EPOCH 45: training on 99524 raw words (60442 effective words) took 0.1s, 419513 effective words/s\n",
      "2023-12-06 15:22:36,491 : INFO : EPOCH 46: training on 99524 raw words (60515 effective words) took 0.1s, 439895 effective words/s\n",
      "2023-12-06 15:22:36,628 : INFO : EPOCH 47: training on 99524 raw words (60304 effective words) took 0.1s, 455482 effective words/s\n",
      "2023-12-06 15:22:36,766 : INFO : EPOCH 48: training on 99524 raw words (60525 effective words) took 0.1s, 450565 effective words/s\n",
      "2023-12-06 15:22:36,931 : INFO : EPOCH 49: training on 99524 raw words (60435 effective words) took 0.2s, 397641 effective words/s\n",
      "2023-12-06 15:22:36,932 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3020093 effective words) took 7.2s, 416702 effective words/s', 'datetime': '2023-12-06T15:22:36.932771', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:22:36,933 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:22:36.933999', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 89%| | 432/486 [1:08:59<08:44,  9.72s/it]2023-12-06 15:22:40,919 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:22:40,919 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:22:40,941 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:22:40,942 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:22:40,947 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:22:40.947376', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:22:40,948 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:22:40.948377', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:22:40,955 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:22:40,955 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:22:40,955 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:22:40.955375', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:22:40,966 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:22:40,967 : INFO : resetting layer weights\n",
      "2023-12-06 15:22:40,971 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:22:40.971803', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:22:41,104 : INFO : EPOCH 0: training on 99524 raw words (65415 effective words) took 0.1s, 503003 effective words/s\n",
      "2023-12-06 15:22:41,278 : INFO : EPOCH 1: training on 99524 raw words (65594 effective words) took 0.2s, 392743 effective words/s\n",
      "2023-12-06 15:22:41,423 : INFO : EPOCH 2: training on 99524 raw words (65608 effective words) took 0.1s, 470087 effective words/s\n",
      "2023-12-06 15:22:41,560 : INFO : EPOCH 3: training on 99524 raw words (65586 effective words) took 0.1s, 497050 effective words/s\n",
      "2023-12-06 15:22:41,695 : INFO : EPOCH 4: training on 99524 raw words (65423 effective words) took 0.1s, 497039 effective words/s\n",
      "2023-12-06 15:22:41,834 : INFO : EPOCH 5: training on 99524 raw words (65624 effective words) took 0.1s, 490205 effective words/s\n",
      "2023-12-06 15:22:41,962 : INFO : EPOCH 6: training on 99524 raw words (65620 effective words) took 0.1s, 526873 effective words/s\n",
      "2023-12-06 15:22:42,118 : INFO : EPOCH 7: training on 99524 raw words (65569 effective words) took 0.2s, 434790 effective words/s\n",
      "2023-12-06 15:22:42,259 : INFO : EPOCH 8: training on 99524 raw words (65507 effective words) took 0.1s, 480277 effective words/s\n",
      "2023-12-06 15:22:42,397 : INFO : EPOCH 9: training on 99524 raw words (65344 effective words) took 0.1s, 488100 effective words/s\n",
      "2023-12-06 15:22:42,398 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655290 effective words) took 1.4s, 459453 effective words/s', 'datetime': '2023-12-06T15:22:42.398652', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:22:42,398 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:22:42.398652', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 89%| | 433/486 [1:09:03<07:05,  8.03s/it]2023-12-06 15:22:44,999 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:22:45,000 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:22:45,021 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:22:45,022 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:22:45,027 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:22:45.027326', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:22:45,028 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:22:45.028328', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:22:45,036 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:22:45,037 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:22:45,037 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:22:45.037601', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:22:45,047 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:22:45,048 : INFO : resetting layer weights\n",
      "2023-12-06 15:22:45,053 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:22:45.053168', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:22:45,180 : INFO : EPOCH 0: training on 99524 raw words (65526 effective words) took 0.1s, 530747 effective words/s\n",
      "2023-12-06 15:22:45,356 : INFO : EPOCH 1: training on 99524 raw words (65589 effective words) took 0.2s, 388818 effective words/s\n",
      "2023-12-06 15:22:45,508 : INFO : EPOCH 2: training on 99524 raw words (65623 effective words) took 0.1s, 452649 effective words/s\n",
      "2023-12-06 15:22:45,648 : INFO : EPOCH 3: training on 99524 raw words (65544 effective words) took 0.1s, 484588 effective words/s\n",
      "2023-12-06 15:22:45,786 : INFO : EPOCH 4: training on 99524 raw words (65449 effective words) took 0.1s, 486150 effective words/s\n",
      "2023-12-06 15:22:45,925 : INFO : EPOCH 5: training on 99524 raw words (65451 effective words) took 0.1s, 483616 effective words/s\n",
      "2023-12-06 15:22:46,065 : INFO : EPOCH 6: training on 99524 raw words (65413 effective words) took 0.1s, 486302 effective words/s\n",
      "2023-12-06 15:22:46,217 : INFO : EPOCH 7: training on 99524 raw words (65620 effective words) took 0.1s, 444887 effective words/s\n",
      "2023-12-06 15:22:46,359 : INFO : EPOCH 8: training on 99524 raw words (65361 effective words) took 0.1s, 475839 effective words/s\n",
      "2023-12-06 15:22:46,498 : INFO : EPOCH 9: training on 99524 raw words (65460 effective words) took 0.1s, 486003 effective words/s\n",
      "2023-12-06 15:22:46,498 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655036 effective words) took 1.4s, 453198 effective words/s', 'datetime': '2023-12-06T15:22:46.498805', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:22:46,499 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:22:46.499813', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 89%| | 434/486 [1:09:07<05:58,  6.90s/it]2023-12-06 15:22:49,252 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:22:49,253 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:22:49,273 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:22:49,274 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:22:49,280 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:22:49.280305', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:22:49,280 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:22:49.280811', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:22:49,288 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:22:49,288 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:22:49,288 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:22:49.288348', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:22:49,298 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:22:49,300 : INFO : resetting layer weights\n",
      "2023-12-06 15:22:49,304 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:22:49.304473', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:22:49,430 : INFO : EPOCH 0: training on 99524 raw words (65474 effective words) took 0.1s, 533527 effective words/s\n",
      "2023-12-06 15:22:49,630 : INFO : EPOCH 1: training on 99524 raw words (65544 effective words) took 0.2s, 334937 effective words/s\n",
      "2023-12-06 15:22:49,785 : INFO : EPOCH 2: training on 99524 raw words (65544 effective words) took 0.1s, 444773 effective words/s\n",
      "2023-12-06 15:22:49,928 : INFO : EPOCH 3: training on 99524 raw words (65366 effective words) took 0.1s, 474223 effective words/s\n",
      "2023-12-06 15:22:50,067 : INFO : EPOCH 4: training on 99524 raw words (65594 effective words) took 0.1s, 487044 effective words/s\n",
      "2023-12-06 15:22:50,207 : INFO : EPOCH 5: training on 99524 raw words (65490 effective words) took 0.1s, 481274 effective words/s\n",
      "2023-12-06 15:22:50,351 : INFO : EPOCH 6: training on 99524 raw words (65515 effective words) took 0.1s, 471373 effective words/s\n",
      "2023-12-06 15:22:50,502 : INFO : EPOCH 7: training on 99524 raw words (65404 effective words) took 0.1s, 445718 effective words/s\n",
      "2023-12-06 15:22:50,642 : INFO : EPOCH 8: training on 99524 raw words (65478 effective words) took 0.1s, 483568 effective words/s\n",
      "2023-12-06 15:22:50,782 : INFO : EPOCH 9: training on 99524 raw words (65532 effective words) took 0.1s, 483693 effective words/s\n",
      "2023-12-06 15:22:50,783 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (654941 effective words) took 1.5s, 442913 effective words/s', 'datetime': '2023-12-06T15:22:50.783563', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:22:50,783 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:22:50.783563', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 90%| | 435/486 [1:09:12<05:11,  6.11s/it]2023-12-06 15:22:53,519 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:22:53,520 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:22:53,541 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:22:53,541 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:22:53,546 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:22:53.546783', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:22:53,547 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:22:53.547782', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:22:53,554 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:22:53,554 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:22:53,555 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:22:53.555709', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:22:53,566 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:22:53,566 : INFO : resetting layer weights\n",
      "2023-12-06 15:22:53,571 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:22:53.571709', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:22:53,700 : INFO : EPOCH 0: training on 99524 raw words (65676 effective words) took 0.1s, 525642 effective words/s\n",
      "2023-12-06 15:22:53,875 : INFO : EPOCH 1: training on 99524 raw words (65377 effective words) took 0.2s, 381879 effective words/s\n",
      "2023-12-06 15:22:54,023 : INFO : EPOCH 2: training on 99524 raw words (65498 effective words) took 0.1s, 471688 effective words/s\n",
      "2023-12-06 15:22:54,161 : INFO : EPOCH 3: training on 99524 raw words (65439 effective words) took 0.1s, 489857 effective words/s\n",
      "2023-12-06 15:22:54,300 : INFO : EPOCH 4: training on 99524 raw words (65499 effective words) took 0.1s, 486136 effective words/s\n",
      "2023-12-06 15:22:54,438 : INFO : EPOCH 5: training on 99524 raw words (65465 effective words) took 0.1s, 487566 effective words/s\n",
      "2023-12-06 15:22:54,594 : INFO : EPOCH 6: training on 99524 raw words (65371 effective words) took 0.2s, 431911 effective words/s\n",
      "2023-12-06 15:22:54,734 : INFO : EPOCH 7: training on 99524 raw words (65648 effective words) took 0.1s, 484772 effective words/s\n",
      "2023-12-06 15:22:54,869 : INFO : EPOCH 8: training on 99524 raw words (65546 effective words) took 0.1s, 498014 effective words/s\n",
      "2023-12-06 15:22:55,008 : INFO : EPOCH 9: training on 99524 raw words (65571 effective words) took 0.1s, 491103 effective words/s\n",
      "2023-12-06 15:22:55,148 : INFO : EPOCH 10: training on 99524 raw words (65398 effective words) took 0.1s, 480305 effective words/s\n",
      "2023-12-06 15:22:55,300 : INFO : EPOCH 11: training on 99524 raw words (65493 effective words) took 0.1s, 448761 effective words/s\n",
      "2023-12-06 15:22:55,443 : INFO : EPOCH 12: training on 99524 raw words (65561 effective words) took 0.1s, 473179 effective words/s\n",
      "2023-12-06 15:22:55,579 : INFO : EPOCH 13: training on 99524 raw words (65615 effective words) took 0.1s, 495144 effective words/s\n",
      "2023-12-06 15:22:55,718 : INFO : EPOCH 14: training on 99524 raw words (65400 effective words) took 0.1s, 488985 effective words/s\n",
      "2023-12-06 15:22:55,853 : INFO : EPOCH 15: training on 99524 raw words (65649 effective words) took 0.1s, 498357 effective words/s\n",
      "2023-12-06 15:22:56,008 : INFO : EPOCH 16: training on 99524 raw words (65605 effective words) took 0.2s, 437189 effective words/s\n",
      "2023-12-06 15:22:56,149 : INFO : EPOCH 17: training on 99524 raw words (65401 effective words) took 0.1s, 479840 effective words/s\n",
      "2023-12-06 15:22:56,286 : INFO : EPOCH 18: training on 99524 raw words (65270 effective words) took 0.1s, 490942 effective words/s\n",
      "2023-12-06 15:22:56,426 : INFO : EPOCH 19: training on 99524 raw words (65649 effective words) took 0.1s, 486047 effective words/s\n",
      "2023-12-06 15:22:56,564 : INFO : EPOCH 20: training on 99524 raw words (65425 effective words) took 0.1s, 486782 effective words/s\n",
      "2023-12-06 15:22:56,709 : INFO : EPOCH 21: training on 99524 raw words (65594 effective words) took 0.1s, 466236 effective words/s\n",
      "2023-12-06 15:22:56,847 : INFO : EPOCH 22: training on 99524 raw words (65512 effective words) took 0.1s, 490291 effective words/s\n",
      "2023-12-06 15:22:56,984 : INFO : EPOCH 23: training on 99524 raw words (65684 effective words) took 0.1s, 494707 effective words/s\n",
      "2023-12-06 15:22:57,121 : INFO : EPOCH 24: training on 99524 raw words (65697 effective words) took 0.1s, 494757 effective words/s\n",
      "2023-12-06 15:22:57,257 : INFO : EPOCH 25: training on 99524 raw words (65385 effective words) took 0.1s, 496057 effective words/s\n",
      "2023-12-06 15:22:57,414 : INFO : EPOCH 26: training on 99524 raw words (65760 effective words) took 0.2s, 432459 effective words/s\n",
      "2023-12-06 15:22:57,551 : INFO : EPOCH 27: training on 99524 raw words (65760 effective words) took 0.1s, 491563 effective words/s\n",
      "2023-12-06 15:22:57,691 : INFO : EPOCH 28: training on 99524 raw words (65663 effective words) took 0.1s, 488386 effective words/s\n",
      "2023-12-06 15:22:57,827 : INFO : EPOCH 29: training on 99524 raw words (65580 effective words) took 0.1s, 493675 effective words/s\n",
      "2023-12-06 15:22:57,828 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1966191 effective words) took 4.3s, 461894 effective words/s', 'datetime': '2023-12-06T15:22:57.828707', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:22:57,829 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:22:57.829704', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 90%| | 436/486 [1:09:19<05:24,  6.49s/it]2023-12-06 15:23:00,891 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:23:00,892 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:23:00,912 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:23:00,914 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:23:00,919 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:23:00.919513', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:23:00,920 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:23:00.920528', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:23:00,927 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:23:00,927 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:23:00,928 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:23:00.927523', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:23:00,939 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:23:00,939 : INFO : resetting layer weights\n",
      "2023-12-06 15:23:00,943 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:23:00.943965', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:23:01,072 : INFO : EPOCH 0: training on 99524 raw words (65488 effective words) took 0.1s, 525074 effective words/s\n",
      "2023-12-06 15:23:01,237 : INFO : EPOCH 1: training on 99524 raw words (65613 effective words) took 0.2s, 406488 effective words/s\n",
      "2023-12-06 15:23:01,395 : INFO : EPOCH 2: training on 99524 raw words (65606 effective words) took 0.2s, 433067 effective words/s\n",
      "2023-12-06 15:23:01,535 : INFO : EPOCH 3: training on 99524 raw words (65500 effective words) took 0.1s, 485058 effective words/s\n",
      "2023-12-06 15:23:01,674 : INFO : EPOCH 4: training on 99524 raw words (65478 effective words) took 0.1s, 487447 effective words/s\n",
      "2023-12-06 15:23:01,815 : INFO : EPOCH 5: training on 99524 raw words (65453 effective words) took 0.1s, 478047 effective words/s\n",
      "2023-12-06 15:23:01,954 : INFO : EPOCH 6: training on 99524 raw words (65523 effective words) took 0.1s, 485873 effective words/s\n",
      "2023-12-06 15:23:02,116 : INFO : EPOCH 7: training on 99524 raw words (65525 effective words) took 0.2s, 415123 effective words/s\n",
      "2023-12-06 15:23:02,257 : INFO : EPOCH 8: training on 99524 raw words (65550 effective words) took 0.1s, 480883 effective words/s\n",
      "2023-12-06 15:23:02,396 : INFO : EPOCH 9: training on 99524 raw words (65373 effective words) took 0.1s, 485336 effective words/s\n",
      "2023-12-06 15:23:02,535 : INFO : EPOCH 10: training on 99524 raw words (65431 effective words) took 0.1s, 484491 effective words/s\n",
      "2023-12-06 15:23:02,674 : INFO : EPOCH 11: training on 99524 raw words (65588 effective words) took 0.1s, 487937 effective words/s\n",
      "2023-12-06 15:23:02,809 : INFO : EPOCH 12: training on 99524 raw words (65695 effective words) took 0.1s, 496797 effective words/s\n",
      "2023-12-06 15:23:02,968 : INFO : EPOCH 13: training on 99524 raw words (65554 effective words) took 0.2s, 426498 effective words/s\n",
      "2023-12-06 15:23:03,108 : INFO : EPOCH 14: training on 99524 raw words (65558 effective words) took 0.1s, 479053 effective words/s\n",
      "2023-12-06 15:23:03,249 : INFO : EPOCH 15: training on 99524 raw words (65559 effective words) took 0.1s, 482298 effective words/s\n",
      "2023-12-06 15:23:03,395 : INFO : EPOCH 16: training on 99524 raw words (65400 effective words) took 0.1s, 459435 effective words/s\n",
      "2023-12-06 15:23:03,555 : INFO : EPOCH 17: training on 99524 raw words (65415 effective words) took 0.2s, 422906 effective words/s\n",
      "2023-12-06 15:23:03,710 : INFO : EPOCH 18: training on 99524 raw words (65429 effective words) took 0.1s, 437263 effective words/s\n",
      "2023-12-06 15:23:03,869 : INFO : EPOCH 19: training on 99524 raw words (65553 effective words) took 0.2s, 423169 effective words/s\n",
      "2023-12-06 15:23:04,012 : INFO : EPOCH 20: training on 99524 raw words (65589 effective words) took 0.1s, 475096 effective words/s\n",
      "2023-12-06 15:23:04,152 : INFO : EPOCH 21: training on 99524 raw words (65615 effective words) took 0.1s, 485975 effective words/s\n",
      "2023-12-06 15:23:04,287 : INFO : EPOCH 22: training on 99524 raw words (65518 effective words) took 0.1s, 500527 effective words/s\n",
      "2023-12-06 15:23:04,426 : INFO : EPOCH 23: training on 99524 raw words (65572 effective words) took 0.1s, 484425 effective words/s\n",
      "2023-12-06 15:23:04,563 : INFO : EPOCH 24: training on 99524 raw words (65570 effective words) took 0.1s, 494036 effective words/s\n",
      "2023-12-06 15:23:04,721 : INFO : EPOCH 25: training on 99524 raw words (65532 effective words) took 0.2s, 425818 effective words/s\n",
      "2023-12-06 15:23:04,862 : INFO : EPOCH 26: training on 99524 raw words (65528 effective words) took 0.1s, 479676 effective words/s\n",
      "2023-12-06 15:23:05,006 : INFO : EPOCH 27: training on 99524 raw words (65616 effective words) took 0.1s, 467440 effective words/s\n",
      "2023-12-06 15:23:05,145 : INFO : EPOCH 28: training on 99524 raw words (65554 effective words) took 0.1s, 484007 effective words/s\n",
      "2023-12-06 15:23:05,284 : INFO : EPOCH 29: training on 99524 raw words (65541 effective words) took 0.1s, 490116 effective words/s\n",
      "2023-12-06 15:23:05,285 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965926 effective words) took 4.3s, 452848 effective words/s', 'datetime': '2023-12-06T15:23:05.285260', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:23:05,286 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:23:05.286438', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 90%| | 437/486 [1:09:27<05:34,  6.83s/it]2023-12-06 15:23:08,513 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:23:08,514 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:23:08,537 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:23:08,538 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:23:08,544 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:23:08.544239', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:23:08,545 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:23:08.545250', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:23:08,552 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:23:08,554 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:23:08,554 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:23:08.554058', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:23:08,566 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:23:08,566 : INFO : resetting layer weights\n",
      "2023-12-06 15:23:08,571 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:23:08.571200', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:23:08,702 : INFO : EPOCH 0: training on 99524 raw words (65495 effective words) took 0.1s, 513250 effective words/s\n",
      "2023-12-06 15:23:08,887 : INFO : EPOCH 1: training on 99524 raw words (65509 effective words) took 0.2s, 364030 effective words/s\n",
      "2023-12-06 15:23:09,033 : INFO : EPOCH 2: training on 99524 raw words (65531 effective words) took 0.1s, 469932 effective words/s\n",
      "2023-12-06 15:23:09,174 : INFO : EPOCH 3: training on 99524 raw words (65435 effective words) took 0.1s, 481793 effective words/s\n",
      "2023-12-06 15:23:09,312 : INFO : EPOCH 4: training on 99524 raw words (65572 effective words) took 0.1s, 489840 effective words/s\n",
      "2023-12-06 15:23:09,453 : INFO : EPOCH 5: training on 99524 raw words (65449 effective words) took 0.1s, 476921 effective words/s\n",
      "2023-12-06 15:23:09,595 : INFO : EPOCH 6: training on 99524 raw words (65510 effective words) took 0.1s, 477260 effective words/s\n",
      "2023-12-06 15:23:09,776 : INFO : EPOCH 7: training on 99524 raw words (65580 effective words) took 0.2s, 372593 effective words/s\n",
      "2023-12-06 15:23:09,917 : INFO : EPOCH 8: training on 99524 raw words (65506 effective words) took 0.1s, 478228 effective words/s\n",
      "2023-12-06 15:23:10,056 : INFO : EPOCH 9: training on 99524 raw words (65532 effective words) took 0.1s, 486435 effective words/s\n",
      "2023-12-06 15:23:10,187 : INFO : EPOCH 10: training on 99524 raw words (65458 effective words) took 0.1s, 519295 effective words/s\n",
      "2023-12-06 15:23:10,348 : INFO : EPOCH 11: training on 99524 raw words (65631 effective words) took 0.2s, 416726 effective words/s\n",
      "2023-12-06 15:23:10,489 : INFO : EPOCH 12: training on 99524 raw words (65435 effective words) took 0.1s, 480246 effective words/s\n",
      "2023-12-06 15:23:10,631 : INFO : EPOCH 13: training on 99524 raw words (65437 effective words) took 0.1s, 477939 effective words/s\n",
      "2023-12-06 15:23:10,779 : INFO : EPOCH 14: training on 99524 raw words (65620 effective words) took 0.1s, 453968 effective words/s\n",
      "2023-12-06 15:23:10,941 : INFO : EPOCH 15: training on 99524 raw words (65603 effective words) took 0.2s, 416846 effective words/s\n",
      "2023-12-06 15:23:11,115 : INFO : EPOCH 16: training on 99524 raw words (65498 effective words) took 0.2s, 387246 effective words/s\n",
      "2023-12-06 15:23:11,256 : INFO : EPOCH 17: training on 99524 raw words (65325 effective words) took 0.1s, 479571 effective words/s\n",
      "2023-12-06 15:23:11,396 : INFO : EPOCH 18: training on 99524 raw words (65445 effective words) took 0.1s, 483729 effective words/s\n",
      "2023-12-06 15:23:11,535 : INFO : EPOCH 19: training on 99524 raw words (65487 effective words) took 0.1s, 485751 effective words/s\n",
      "2023-12-06 15:23:11,696 : INFO : EPOCH 20: training on 99524 raw words (65535 effective words) took 0.2s, 418915 effective words/s\n",
      "2023-12-06 15:23:11,837 : INFO : EPOCH 21: training on 99524 raw words (65424 effective words) took 0.1s, 477776 effective words/s\n",
      "2023-12-06 15:23:11,975 : INFO : EPOCH 22: training on 99524 raw words (65665 effective words) took 0.1s, 489770 effective words/s\n",
      "2023-12-06 15:23:12,116 : INFO : EPOCH 23: training on 99524 raw words (65761 effective words) took 0.1s, 480159 effective words/s\n",
      "2023-12-06 15:23:12,258 : INFO : EPOCH 24: training on 99524 raw words (65533 effective words) took 0.1s, 480257 effective words/s\n",
      "2023-12-06 15:23:12,388 : INFO : EPOCH 25: training on 99524 raw words (65518 effective words) took 0.1s, 520234 effective words/s\n",
      "2023-12-06 15:23:12,551 : INFO : EPOCH 26: training on 99524 raw words (65604 effective words) took 0.2s, 413642 effective words/s\n",
      "2023-12-06 15:23:12,690 : INFO : EPOCH 27: training on 99524 raw words (65759 effective words) took 0.1s, 486010 effective words/s\n",
      "2023-12-06 15:23:12,839 : INFO : EPOCH 28: training on 99524 raw words (65428 effective words) took 0.1s, 455527 effective words/s\n",
      "2023-12-06 15:23:12,981 : INFO : EPOCH 29: training on 99524 raw words (65584 effective words) took 0.1s, 473164 effective words/s\n",
      "2023-12-06 15:23:12,982 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965869 effective words) took 4.4s, 445684 effective words/s', 'datetime': '2023-12-06T15:23:12.982571', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:23:12,983 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:23:12.983572', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 90%| | 438/486 [1:09:34<05:42,  7.13s/it]2023-12-06 15:23:16,340 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:23:16,341 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:23:16,366 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:23:16,367 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:23:16,373 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:23:16.373634', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:23:16,373 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:23:16.373634', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:23:16,381 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:23:16,382 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:23:16,382 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:23:16.382969', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:23:16,396 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:23:16,396 : INFO : resetting layer weights\n",
      "2023-12-06 15:23:16,401 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:23:16.401301', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:23:16,539 : INFO : EPOCH 0: training on 99524 raw words (65465 effective words) took 0.1s, 488354 effective words/s\n",
      "2023-12-06 15:23:16,723 : INFO : EPOCH 1: training on 99524 raw words (65524 effective words) took 0.2s, 368184 effective words/s\n",
      "2023-12-06 15:23:16,865 : INFO : EPOCH 2: training on 99524 raw words (65635 effective words) took 0.1s, 488292 effective words/s\n",
      "2023-12-06 15:23:17,001 : INFO : EPOCH 3: training on 99524 raw words (65521 effective words) took 0.1s, 496813 effective words/s\n",
      "2023-12-06 15:23:17,138 : INFO : EPOCH 4: training on 99524 raw words (65567 effective words) took 0.1s, 493174 effective words/s\n",
      "2023-12-06 15:23:17,275 : INFO : EPOCH 5: training on 99524 raw words (65641 effective words) took 0.1s, 494901 effective words/s\n",
      "2023-12-06 15:23:17,413 : INFO : EPOCH 6: training on 99524 raw words (65659 effective words) took 0.1s, 493600 effective words/s\n",
      "2023-12-06 15:23:17,561 : INFO : EPOCH 7: training on 99524 raw words (65688 effective words) took 0.1s, 457352 effective words/s\n",
      "2023-12-06 15:23:17,690 : INFO : EPOCH 8: training on 99524 raw words (65416 effective words) took 0.1s, 521085 effective words/s\n",
      "2023-12-06 15:23:17,819 : INFO : EPOCH 9: training on 99524 raw words (65441 effective words) took 0.1s, 527271 effective words/s\n",
      "2023-12-06 15:23:17,955 : INFO : EPOCH 10: training on 99524 raw words (65347 effective words) took 0.1s, 496096 effective words/s\n",
      "2023-12-06 15:23:18,100 : INFO : EPOCH 11: training on 99524 raw words (65584 effective words) took 0.1s, 466480 effective words/s\n",
      "2023-12-06 15:23:18,252 : INFO : EPOCH 12: training on 99524 raw words (65443 effective words) took 0.1s, 462073 effective words/s\n",
      "2023-12-06 15:23:18,389 : INFO : EPOCH 13: training on 99524 raw words (65607 effective words) took 0.1s, 489830 effective words/s\n",
      "2023-12-06 15:23:18,528 : INFO : EPOCH 14: training on 99524 raw words (65481 effective words) took 0.1s, 489988 effective words/s\n",
      "2023-12-06 15:23:18,665 : INFO : EPOCH 15: training on 99524 raw words (65526 effective words) took 0.1s, 494724 effective words/s\n",
      "2023-12-06 15:23:18,800 : INFO : EPOCH 16: training on 99524 raw words (65467 effective words) took 0.1s, 495940 effective words/s\n",
      "2023-12-06 15:23:18,956 : INFO : EPOCH 17: training on 99524 raw words (65380 effective words) took 0.2s, 433401 effective words/s\n",
      "2023-12-06 15:23:19,095 : INFO : EPOCH 18: training on 99524 raw words (65405 effective words) took 0.1s, 488590 effective words/s\n",
      "2023-12-06 15:23:19,231 : INFO : EPOCH 19: training on 99524 raw words (65757 effective words) took 0.1s, 495923 effective words/s\n",
      "2023-12-06 15:23:19,368 : INFO : EPOCH 20: training on 99524 raw words (65594 effective words) took 0.1s, 493307 effective words/s\n",
      "2023-12-06 15:23:19,518 : INFO : EPOCH 21: training on 99524 raw words (65442 effective words) took 0.1s, 446237 effective words/s\n",
      "2023-12-06 15:23:19,659 : INFO : EPOCH 22: training on 99524 raw words (65699 effective words) took 0.1s, 484534 effective words/s\n",
      "2023-12-06 15:23:19,797 : INFO : EPOCH 23: training on 99524 raw words (65451 effective words) took 0.1s, 490524 effective words/s\n",
      "2023-12-06 15:23:19,937 : INFO : EPOCH 24: training on 99524 raw words (65536 effective words) took 0.1s, 484157 effective words/s\n",
      "2023-12-06 15:23:20,090 : INFO : EPOCH 25: training on 99524 raw words (65414 effective words) took 0.1s, 442982 effective words/s\n",
      "2023-12-06 15:23:20,231 : INFO : EPOCH 26: training on 99524 raw words (65652 effective words) took 0.1s, 480879 effective words/s\n",
      "2023-12-06 15:23:20,371 : INFO : EPOCH 27: training on 99524 raw words (65648 effective words) took 0.1s, 484035 effective words/s\n",
      "2023-12-06 15:23:20,509 : INFO : EPOCH 28: training on 99524 raw words (65599 effective words) took 0.1s, 492342 effective words/s\n",
      "2023-12-06 15:23:20,662 : INFO : EPOCH 29: training on 99524 raw words (65517 effective words) took 0.1s, 441515 effective words/s\n",
      "2023-12-06 15:23:20,797 : INFO : EPOCH 30: training on 99524 raw words (65652 effective words) took 0.1s, 500529 effective words/s\n",
      "2023-12-06 15:23:20,937 : INFO : EPOCH 31: training on 99524 raw words (65508 effective words) took 0.1s, 484530 effective words/s\n",
      "2023-12-06 15:23:21,083 : INFO : EPOCH 32: training on 99524 raw words (65630 effective words) took 0.1s, 465536 effective words/s\n",
      "2023-12-06 15:23:21,222 : INFO : EPOCH 33: training on 99524 raw words (65527 effective words) took 0.1s, 488152 effective words/s\n",
      "2023-12-06 15:23:21,371 : INFO : EPOCH 34: training on 99524 raw words (65497 effective words) took 0.1s, 449807 effective words/s\n",
      "2023-12-06 15:23:21,515 : INFO : EPOCH 35: training on 99524 raw words (65598 effective words) took 0.1s, 473651 effective words/s\n",
      "2023-12-06 15:23:21,654 : INFO : EPOCH 36: training on 99524 raw words (65514 effective words) took 0.1s, 488730 effective words/s\n",
      "2023-12-06 15:23:21,789 : INFO : EPOCH 37: training on 99524 raw words (65509 effective words) took 0.1s, 495935 effective words/s\n",
      "2023-12-06 15:23:21,934 : INFO : EPOCH 38: training on 99524 raw words (65562 effective words) took 0.1s, 467804 effective words/s\n",
      "2023-12-06 15:23:22,071 : INFO : EPOCH 39: training on 99524 raw words (65615 effective words) took 0.1s, 491486 effective words/s\n",
      "2023-12-06 15:23:22,226 : INFO : EPOCH 40: training on 99524 raw words (65356 effective words) took 0.1s, 437430 effective words/s\n",
      "2023-12-06 15:23:22,367 : INFO : EPOCH 41: training on 99524 raw words (65527 effective words) took 0.1s, 475853 effective words/s\n",
      "2023-12-06 15:23:22,502 : INFO : EPOCH 42: training on 99524 raw words (65638 effective words) took 0.1s, 503573 effective words/s\n",
      "2023-12-06 15:23:22,640 : INFO : EPOCH 43: training on 99524 raw words (65697 effective words) took 0.1s, 492481 effective words/s\n",
      "2023-12-06 15:23:22,779 : INFO : EPOCH 44: training on 99524 raw words (65571 effective words) took 0.1s, 484147 effective words/s\n",
      "2023-12-06 15:23:22,916 : INFO : EPOCH 45: training on 99524 raw words (65553 effective words) took 0.1s, 495948 effective words/s\n",
      "2023-12-06 15:23:23,076 : INFO : EPOCH 46: training on 99524 raw words (65604 effective words) took 0.2s, 421060 effective words/s\n",
      "2023-12-06 15:23:23,213 : INFO : EPOCH 47: training on 99524 raw words (65596 effective words) took 0.1s, 490911 effective words/s\n",
      "2023-12-06 15:23:23,351 : INFO : EPOCH 48: training on 99524 raw words (65544 effective words) took 0.1s, 493174 effective words/s\n",
      "2023-12-06 15:23:23,489 : INFO : EPOCH 49: training on 99524 raw words (65465 effective words) took 0.1s, 486076 effective words/s\n",
      "2023-12-06 15:23:23,491 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3277269 effective words) took 7.1s, 462268 effective words/s', 'datetime': '2023-12-06T15:23:23.491839', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:23:23,491 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:23:23.491839', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 90%| | 439/486 [1:09:45<06:22,  8.14s/it]2023-12-06 15:23:26,841 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:23:26,842 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:23:26,862 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:23:26,863 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:23:26,869 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:23:26.869072', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:23:26,870 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:23:26.870073', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:23:26,877 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:23:26,878 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:23:26,878 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:23:26.878582', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:23:26,889 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:23:26,889 : INFO : resetting layer weights\n",
      "2023-12-06 15:23:26,894 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:23:26.894470', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:23:27,022 : INFO : EPOCH 0: training on 99524 raw words (65582 effective words) took 0.1s, 528313 effective words/s\n",
      "2023-12-06 15:23:27,191 : INFO : EPOCH 1: training on 99524 raw words (65573 effective words) took 0.2s, 404009 effective words/s\n",
      "2023-12-06 15:23:27,339 : INFO : EPOCH 2: training on 99524 raw words (65581 effective words) took 0.1s, 468827 effective words/s\n",
      "2023-12-06 15:23:27,481 : INFO : EPOCH 3: training on 99524 raw words (65513 effective words) took 0.1s, 475699 effective words/s\n",
      "2023-12-06 15:23:27,631 : INFO : EPOCH 4: training on 99524 raw words (65459 effective words) took 0.1s, 449920 effective words/s\n",
      "2023-12-06 15:23:27,785 : INFO : EPOCH 5: training on 99524 raw words (65510 effective words) took 0.1s, 438144 effective words/s\n",
      "2023-12-06 15:23:27,929 : INFO : EPOCH 6: training on 99524 raw words (65652 effective words) took 0.1s, 473574 effective words/s\n",
      "2023-12-06 15:23:28,089 : INFO : EPOCH 7: training on 99524 raw words (65495 effective words) took 0.2s, 418837 effective words/s\n",
      "2023-12-06 15:23:28,228 : INFO : EPOCH 8: training on 99524 raw words (65299 effective words) took 0.1s, 484658 effective words/s\n",
      "2023-12-06 15:23:28,370 : INFO : EPOCH 9: training on 99524 raw words (65562 effective words) took 0.1s, 474678 effective words/s\n",
      "2023-12-06 15:23:28,509 : INFO : EPOCH 10: training on 99524 raw words (65520 effective words) took 0.1s, 487092 effective words/s\n",
      "2023-12-06 15:23:28,659 : INFO : EPOCH 11: training on 99524 raw words (65449 effective words) took 0.1s, 446642 effective words/s\n",
      "2023-12-06 15:23:28,812 : INFO : EPOCH 12: training on 99524 raw words (65544 effective words) took 0.1s, 447129 effective words/s\n",
      "2023-12-06 15:23:28,953 : INFO : EPOCH 13: training on 99524 raw words (65534 effective words) took 0.1s, 480353 effective words/s\n",
      "2023-12-06 15:23:29,092 : INFO : EPOCH 14: training on 99524 raw words (65555 effective words) took 0.1s, 486931 effective words/s\n",
      "2023-12-06 15:23:29,233 : INFO : EPOCH 15: training on 99524 raw words (65566 effective words) took 0.1s, 478408 effective words/s\n",
      "2023-12-06 15:23:29,396 : INFO : EPOCH 16: training on 99524 raw words (65497 effective words) took 0.2s, 413661 effective words/s\n",
      "2023-12-06 15:23:29,534 : INFO : EPOCH 17: training on 99524 raw words (65460 effective words) took 0.1s, 488185 effective words/s\n",
      "2023-12-06 15:23:29,673 : INFO : EPOCH 18: training on 99524 raw words (65482 effective words) took 0.1s, 487002 effective words/s\n",
      "2023-12-06 15:23:29,813 : INFO : EPOCH 19: training on 99524 raw words (65688 effective words) took 0.1s, 485376 effective words/s\n",
      "2023-12-06 15:23:29,967 : INFO : EPOCH 20: training on 99524 raw words (65615 effective words) took 0.1s, 438707 effective words/s\n",
      "2023-12-06 15:23:30,108 : INFO : EPOCH 21: training on 99524 raw words (65635 effective words) took 0.1s, 485287 effective words/s\n",
      "2023-12-06 15:23:30,247 : INFO : EPOCH 22: training on 99524 raw words (65688 effective words) took 0.1s, 485683 effective words/s\n",
      "2023-12-06 15:23:30,387 : INFO : EPOCH 23: training on 99524 raw words (65635 effective words) took 0.1s, 483287 effective words/s\n",
      "2023-12-06 15:23:30,548 : INFO : EPOCH 24: training on 99524 raw words (65442 effective words) took 0.2s, 415849 effective words/s\n",
      "2023-12-06 15:23:30,688 : INFO : EPOCH 25: training on 99524 raw words (65578 effective words) took 0.1s, 484028 effective words/s\n",
      "2023-12-06 15:23:30,829 : INFO : EPOCH 26: training on 99524 raw words (65783 effective words) took 0.1s, 482738 effective words/s\n",
      "2023-12-06 15:23:30,977 : INFO : EPOCH 27: training on 99524 raw words (65676 effective words) took 0.1s, 460617 effective words/s\n",
      "2023-12-06 15:23:31,167 : INFO : EPOCH 28: training on 99524 raw words (65449 effective words) took 0.2s, 352428 effective words/s\n",
      "2023-12-06 15:23:31,325 : INFO : EPOCH 29: training on 99524 raw words (65519 effective words) took 0.2s, 429327 effective words/s\n",
      "2023-12-06 15:23:31,484 : INFO : EPOCH 30: training on 99524 raw words (65662 effective words) took 0.2s, 422418 effective words/s\n",
      "2023-12-06 15:23:31,629 : INFO : EPOCH 31: training on 99524 raw words (65434 effective words) took 0.1s, 470686 effective words/s\n",
      "2023-12-06 15:23:31,786 : INFO : EPOCH 32: training on 99524 raw words (65451 effective words) took 0.2s, 430628 effective words/s\n",
      "2023-12-06 15:23:31,927 : INFO : EPOCH 33: training on 99524 raw words (65668 effective words) took 0.1s, 481619 effective words/s\n",
      "2023-12-06 15:23:32,063 : INFO : EPOCH 34: training on 99524 raw words (65392 effective words) took 0.1s, 493572 effective words/s\n",
      "2023-12-06 15:23:32,201 : INFO : EPOCH 35: training on 99524 raw words (65635 effective words) took 0.1s, 492832 effective words/s\n",
      "2023-12-06 15:23:32,340 : INFO : EPOCH 36: training on 99524 raw words (65509 effective words) took 0.1s, 485762 effective words/s\n",
      "2023-12-06 15:23:32,480 : INFO : EPOCH 37: training on 99524 raw words (65558 effective words) took 0.1s, 486247 effective words/s\n",
      "2023-12-06 15:23:32,656 : INFO : EPOCH 38: training on 99524 raw words (65366 effective words) took 0.2s, 380488 effective words/s\n",
      "2023-12-06 15:23:32,796 : INFO : EPOCH 39: training on 99524 raw words (65532 effective words) took 0.1s, 481610 effective words/s\n",
      "2023-12-06 15:23:32,935 : INFO : EPOCH 40: training on 99524 raw words (65528 effective words) took 0.1s, 489984 effective words/s\n",
      "2023-12-06 15:23:33,075 : INFO : EPOCH 41: training on 99524 raw words (65752 effective words) took 0.1s, 486071 effective words/s\n",
      "2023-12-06 15:23:33,233 : INFO : EPOCH 42: training on 99524 raw words (65572 effective words) took 0.2s, 423456 effective words/s\n",
      "2023-12-06 15:23:33,376 : INFO : EPOCH 43: training on 99524 raw words (65369 effective words) took 0.1s, 472588 effective words/s\n",
      "2023-12-06 15:23:33,520 : INFO : EPOCH 44: training on 99524 raw words (65487 effective words) took 0.1s, 474566 effective words/s\n",
      "2023-12-06 15:23:33,660 : INFO : EPOCH 45: training on 99524 raw words (65514 effective words) took 0.1s, 482088 effective words/s\n",
      "2023-12-06 15:23:33,823 : INFO : EPOCH 46: training on 99524 raw words (65456 effective words) took 0.2s, 412416 effective words/s\n",
      "2023-12-06 15:23:33,962 : INFO : EPOCH 47: training on 99524 raw words (65523 effective words) took 0.1s, 482834 effective words/s\n",
      "2023-12-06 15:23:34,103 : INFO : EPOCH 48: training on 99524 raw words (65652 effective words) took 0.1s, 484465 effective words/s\n",
      "2023-12-06 15:23:34,243 : INFO : EPOCH 49: training on 99524 raw words (65492 effective words) took 0.1s, 481244 effective words/s\n",
      "2023-12-06 15:23:34,244 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3277093 effective words) took 7.4s, 445856 effective words/s', 'datetime': '2023-12-06T15:23:34.244900', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:23:34,245 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:23:34.245898', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 91%| | 440/486 [1:09:56<06:55,  9.03s/it]2023-12-06 15:23:37,935 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:23:37,936 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:23:37,957 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:23:37,957 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:23:37,963 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:23:37.963543', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:23:37,964 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:23:37.964543', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:23:37,971 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:23:37,971 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:23:37,971 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:23:37.971538', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:23:37,983 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:23:37,983 : INFO : resetting layer weights\n",
      "2023-12-06 15:23:37,987 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:23:37.987749', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:23:38,115 : INFO : EPOCH 0: training on 99524 raw words (65356 effective words) took 0.1s, 523193 effective words/s\n",
      "2023-12-06 15:23:38,298 : INFO : EPOCH 1: training on 99524 raw words (65584 effective words) took 0.2s, 370743 effective words/s\n",
      "2023-12-06 15:23:38,449 : INFO : EPOCH 2: training on 99524 raw words (65665 effective words) took 0.1s, 452446 effective words/s\n",
      "2023-12-06 15:23:38,591 : INFO : EPOCH 3: training on 99524 raw words (65479 effective words) took 0.1s, 472779 effective words/s\n",
      "2023-12-06 15:23:38,723 : INFO : EPOCH 4: training on 99524 raw words (65502 effective words) took 0.1s, 516855 effective words/s\n",
      "2023-12-06 15:23:38,863 : INFO : EPOCH 5: training on 99524 raw words (65531 effective words) took 0.1s, 480661 effective words/s\n",
      "2023-12-06 15:23:39,028 : INFO : EPOCH 6: training on 99524 raw words (65440 effective words) took 0.2s, 407897 effective words/s\n",
      "2023-12-06 15:23:39,170 : INFO : EPOCH 7: training on 99524 raw words (65611 effective words) took 0.1s, 477684 effective words/s\n",
      "2023-12-06 15:23:39,310 : INFO : EPOCH 8: training on 99524 raw words (65552 effective words) took 0.1s, 482527 effective words/s\n",
      "2023-12-06 15:23:39,451 : INFO : EPOCH 9: training on 99524 raw words (65561 effective words) took 0.1s, 479316 effective words/s\n",
      "2023-12-06 15:23:39,605 : INFO : EPOCH 10: training on 99524 raw words (65445 effective words) took 0.1s, 438766 effective words/s\n",
      "2023-12-06 15:23:39,749 : INFO : EPOCH 11: training on 99524 raw words (65366 effective words) took 0.1s, 468320 effective words/s\n",
      "2023-12-06 15:23:39,891 : INFO : EPOCH 12: training on 99524 raw words (65624 effective words) took 0.1s, 478901 effective words/s\n",
      "2023-12-06 15:23:40,033 : INFO : EPOCH 13: training on 99524 raw words (65477 effective words) took 0.1s, 474656 effective words/s\n",
      "2023-12-06 15:23:40,195 : INFO : EPOCH 14: training on 99524 raw words (65611 effective words) took 0.2s, 416683 effective words/s\n",
      "2023-12-06 15:23:40,335 : INFO : EPOCH 15: training on 99524 raw words (65603 effective words) took 0.1s, 483754 effective words/s\n",
      "2023-12-06 15:23:40,476 : INFO : EPOCH 16: training on 99524 raw words (65529 effective words) took 0.1s, 477072 effective words/s\n",
      "2023-12-06 15:23:40,618 : INFO : EPOCH 17: training on 99524 raw words (65439 effective words) took 0.1s, 480091 effective words/s\n",
      "2023-12-06 15:23:40,772 : INFO : EPOCH 18: training on 99524 raw words (65497 effective words) took 0.1s, 437882 effective words/s\n",
      "2023-12-06 15:23:40,916 : INFO : EPOCH 19: training on 99524 raw words (65657 effective words) took 0.1s, 470727 effective words/s\n",
      "2023-12-06 15:23:41,080 : INFO : EPOCH 20: training on 99524 raw words (65659 effective words) took 0.2s, 411495 effective words/s\n",
      "2023-12-06 15:23:41,219 : INFO : EPOCH 21: training on 99524 raw words (65425 effective words) took 0.1s, 483439 effective words/s\n",
      "2023-12-06 15:23:41,362 : INFO : EPOCH 22: training on 99524 raw words (65501 effective words) took 0.1s, 470735 effective words/s\n",
      "2023-12-06 15:23:41,507 : INFO : EPOCH 23: training on 99524 raw words (65437 effective words) took 0.1s, 467930 effective words/s\n",
      "2023-12-06 15:23:41,648 : INFO : EPOCH 24: training on 99524 raw words (65533 effective words) took 0.1s, 479091 effective words/s\n",
      "2023-12-06 15:23:41,813 : INFO : EPOCH 25: training on 99524 raw words (65562 effective words) took 0.2s, 407687 effective words/s\n",
      "2023-12-06 15:23:41,954 : INFO : EPOCH 26: training on 99524 raw words (65791 effective words) took 0.1s, 480874 effective words/s\n",
      "2023-12-06 15:23:42,094 : INFO : EPOCH 27: training on 99524 raw words (65762 effective words) took 0.1s, 480238 effective words/s\n",
      "2023-12-06 15:23:42,234 : INFO : EPOCH 28: training on 99524 raw words (65520 effective words) took 0.1s, 485496 effective words/s\n",
      "2023-12-06 15:23:42,380 : INFO : EPOCH 29: training on 99524 raw words (65591 effective words) took 0.1s, 462063 effective words/s\n",
      "2023-12-06 15:23:42,521 : INFO : EPOCH 30: training on 99524 raw words (65410 effective words) took 0.1s, 479687 effective words/s\n",
      "2023-12-06 15:23:42,686 : INFO : EPOCH 31: training on 99524 raw words (65468 effective words) took 0.2s, 407770 effective words/s\n",
      "2023-12-06 15:23:42,825 : INFO : EPOCH 32: training on 99524 raw words (65562 effective words) took 0.1s, 482463 effective words/s\n",
      "2023-12-06 15:23:42,969 : INFO : EPOCH 33: training on 99524 raw words (65600 effective words) took 0.1s, 474210 effective words/s\n",
      "2023-12-06 15:23:43,110 : INFO : EPOCH 34: training on 99524 raw words (65622 effective words) took 0.1s, 475441 effective words/s\n",
      "2023-12-06 15:23:43,261 : INFO : EPOCH 35: training on 99524 raw words (65778 effective words) took 0.1s, 452421 effective words/s\n",
      "2023-12-06 15:23:43,402 : INFO : EPOCH 36: training on 99524 raw words (65591 effective words) took 0.1s, 480332 effective words/s\n",
      "2023-12-06 15:23:43,567 : INFO : EPOCH 37: training on 99524 raw words (65459 effective words) took 0.2s, 406634 effective words/s\n",
      "2023-12-06 15:23:43,707 : INFO : EPOCH 38: training on 99524 raw words (65339 effective words) took 0.1s, 479264 effective words/s\n",
      "2023-12-06 15:23:43,848 : INFO : EPOCH 39: training on 99524 raw words (65559 effective words) took 0.1s, 483681 effective words/s\n",
      "2023-12-06 15:23:43,987 : INFO : EPOCH 40: training on 99524 raw words (65459 effective words) took 0.1s, 485566 effective words/s\n",
      "2023-12-06 15:23:44,133 : INFO : EPOCH 41: training on 99524 raw words (65666 effective words) took 0.1s, 462081 effective words/s\n",
      "2023-12-06 15:23:44,295 : INFO : EPOCH 42: training on 99524 raw words (65482 effective words) took 0.2s, 416427 effective words/s\n",
      "2023-12-06 15:23:44,438 : INFO : EPOCH 43: training on 99524 raw words (65524 effective words) took 0.1s, 472212 effective words/s\n",
      "2023-12-06 15:23:44,579 : INFO : EPOCH 44: training on 99524 raw words (65554 effective words) took 0.1s, 481993 effective words/s\n",
      "2023-12-06 15:23:44,721 : INFO : EPOCH 45: training on 99524 raw words (65585 effective words) took 0.1s, 475095 effective words/s\n",
      "2023-12-06 15:23:44,887 : INFO : EPOCH 46: training on 99524 raw words (65194 effective words) took 0.2s, 403960 effective words/s\n",
      "2023-12-06 15:23:45,034 : INFO : EPOCH 47: training on 99524 raw words (65651 effective words) took 0.1s, 462984 effective words/s\n",
      "2023-12-06 15:23:45,178 : INFO : EPOCH 48: training on 99524 raw words (65542 effective words) took 0.1s, 470200 effective words/s\n",
      "2023-12-06 15:23:45,318 : INFO : EPOCH 49: training on 99524 raw words (65501 effective words) took 0.1s, 481383 effective words/s\n",
      "2023-12-06 15:23:45,319 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276856 effective words) took 7.3s, 446990 effective words/s', 'datetime': '2023-12-06T15:23:45.319173', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:23:45,319 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:23:45.319173', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 91%| | 441/486 [1:10:07<07:17,  9.72s/it]2023-12-06 15:23:49,289 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:23:49,290 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:23:49,312 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:23:49,312 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:23:49,317 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:23:49.317009', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:23:49,318 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:23:49.318011', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:23:49,323 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:23:49,323 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:23:49,324 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:23:49.324337', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:23:49,333 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:23:49,333 : INFO : resetting layer weights\n",
      "2023-12-06 15:23:49,336 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:23:49.336810', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:23:49,462 : INFO : EPOCH 0: training on 99524 raw words (62848 effective words) took 0.1s, 520309 effective words/s\n",
      "2023-12-06 15:23:49,632 : INFO : EPOCH 1: training on 99524 raw words (62620 effective words) took 0.2s, 377433 effective words/s\n",
      "2023-12-06 15:23:49,793 : INFO : EPOCH 2: training on 99524 raw words (63053 effective words) took 0.1s, 459191 effective words/s\n",
      "2023-12-06 15:23:49,931 : INFO : EPOCH 3: training on 99524 raw words (62645 effective words) took 0.1s, 469254 effective words/s\n",
      "2023-12-06 15:23:50,070 : INFO : EPOCH 4: training on 99524 raw words (62732 effective words) took 0.1s, 466264 effective words/s\n",
      "2023-12-06 15:23:50,199 : INFO : EPOCH 5: training on 99524 raw words (62737 effective words) took 0.1s, 506486 effective words/s\n",
      "2023-12-06 15:23:50,333 : INFO : EPOCH 6: training on 99524 raw words (62721 effective words) took 0.1s, 482890 effective words/s\n",
      "2023-12-06 15:23:50,492 : INFO : EPOCH 7: training on 99524 raw words (62628 effective words) took 0.2s, 404106 effective words/s\n",
      "2023-12-06 15:23:50,635 : INFO : EPOCH 8: training on 99524 raw words (62659 effective words) took 0.1s, 454090 effective words/s\n",
      "2023-12-06 15:23:50,780 : INFO : EPOCH 9: training on 99524 raw words (62645 effective words) took 0.1s, 447203 effective words/s\n",
      "2023-12-06 15:23:50,781 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627288 effective words) took 1.4s, 434626 effective words/s', 'datetime': '2023-12-06T15:23:50.781124', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:23:50,782 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:23:50.782263', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 91%| | 442/486 [1:10:12<05:53,  8.05s/it]2023-12-06 15:23:53,415 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:23:53,416 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:23:53,437 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:23:53,438 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:23:53,443 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:23:53.443815', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:23:53,443 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:23:53.443815', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:23:53,450 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:23:53,451 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:23:53,451 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:23:53.451235', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:23:53,460 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:23:53,460 : INFO : resetting layer weights\n",
      "2023-12-06 15:23:53,464 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:23:53.464722', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:23:53,590 : INFO : EPOCH 0: training on 99524 raw words (62617 effective words) took 0.1s, 511059 effective words/s\n",
      "2023-12-06 15:23:53,756 : INFO : EPOCH 1: training on 99524 raw words (62849 effective words) took 0.2s, 389897 effective words/s\n",
      "2023-12-06 15:23:53,914 : INFO : EPOCH 2: training on 99524 raw words (62760 effective words) took 0.1s, 447259 effective words/s\n",
      "2023-12-06 15:23:54,042 : INFO : EPOCH 3: training on 99524 raw words (62669 effective words) took 0.1s, 508417 effective words/s\n",
      "2023-12-06 15:23:54,172 : INFO : EPOCH 4: training on 99524 raw words (62725 effective words) took 0.1s, 498636 effective words/s\n",
      "2023-12-06 15:23:54,311 : INFO : EPOCH 5: training on 99524 raw words (62797 effective words) took 0.1s, 463835 effective words/s\n",
      "2023-12-06 15:23:54,449 : INFO : EPOCH 6: training on 99524 raw words (62652 effective words) took 0.1s, 468417 effective words/s\n",
      "2023-12-06 15:23:54,588 : INFO : EPOCH 7: training on 99524 raw words (62793 effective words) took 0.1s, 471047 effective words/s\n",
      "2023-12-06 15:23:54,750 : INFO : EPOCH 8: training on 99524 raw words (62774 effective words) took 0.2s, 400974 effective words/s\n",
      "2023-12-06 15:23:54,887 : INFO : EPOCH 9: training on 99524 raw words (62603 effective words) took 0.1s, 471286 effective words/s\n",
      "2023-12-06 15:23:54,888 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627239 effective words) took 1.4s, 440777 effective words/s', 'datetime': '2023-12-06T15:23:54.888509', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:23:54,888 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:23:54.888509', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 91%| | 443/486 [1:10:16<04:56,  6.89s/it]2023-12-06 15:23:57,598 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:23:57,599 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:23:57,620 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:23:57,621 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:23:57,625 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:23:57.625081', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:23:57,626 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:23:57.626082', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:23:57,631 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:23:57,632 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:23:57,632 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:23:57.632086', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:23:57,641 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:23:57,641 : INFO : resetting layer weights\n",
      "2023-12-06 15:23:57,645 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:23:57.645390', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:23:57,771 : INFO : EPOCH 0: training on 99524 raw words (62778 effective words) took 0.1s, 513544 effective words/s\n",
      "2023-12-06 15:23:57,944 : INFO : EPOCH 1: training on 99524 raw words (62784 effective words) took 0.2s, 372958 effective words/s\n",
      "2023-12-06 15:23:58,099 : INFO : EPOCH 2: training on 99524 raw words (62794 effective words) took 0.1s, 422816 effective words/s\n",
      "2023-12-06 15:23:58,239 : INFO : EPOCH 3: training on 99524 raw words (62533 effective words) took 0.1s, 460283 effective words/s\n",
      "2023-12-06 15:23:58,378 : INFO : EPOCH 4: training on 99524 raw words (62675 effective words) took 0.1s, 468437 effective words/s\n",
      "2023-12-06 15:23:58,506 : INFO : EPOCH 5: training on 99524 raw words (62731 effective words) took 0.1s, 504403 effective words/s\n",
      "2023-12-06 15:23:58,634 : INFO : EPOCH 6: training on 99524 raw words (62616 effective words) took 0.1s, 505028 effective words/s\n",
      "2023-12-06 15:23:58,762 : INFO : EPOCH 7: training on 99524 raw words (62734 effective words) took 0.1s, 507423 effective words/s\n",
      "2023-12-06 15:23:58,926 : INFO : EPOCH 8: training on 99524 raw words (62674 effective words) took 0.2s, 392439 effective words/s\n",
      "2023-12-06 15:23:59,068 : INFO : EPOCH 9: training on 99524 raw words (62857 effective words) took 0.1s, 455279 effective words/s\n",
      "2023-12-06 15:23:59,069 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627176 effective words) took 1.4s, 440544 effective words/s', 'datetime': '2023-12-06T15:23:59.069614', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:23:59,070 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:23:59.070614', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 91%|| 444/486 [1:10:20<04:15,  6.09s/it]2023-12-06 15:24:01,838 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:24:01,839 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:24:01,860 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:24:01,860 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:24:01,865 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:24:01.865370', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:24:01,866 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:24:01.866850', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:24:01,871 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:24:01,872 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:24:01,872 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:24:01.872792', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:24:01,881 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:24:01,882 : INFO : resetting layer weights\n",
      "2023-12-06 15:24:01,886 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:24:01.886381', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:24:02,011 : INFO : EPOCH 0: training on 99524 raw words (62640 effective words) took 0.1s, 513182 effective words/s\n",
      "2023-12-06 15:24:02,181 : INFO : EPOCH 1: training on 99524 raw words (62720 effective words) took 0.2s, 377460 effective words/s\n",
      "2023-12-06 15:24:02,335 : INFO : EPOCH 2: training on 99524 raw words (62658 effective words) took 0.1s, 422506 effective words/s\n",
      "2023-12-06 15:24:02,470 : INFO : EPOCH 3: training on 99524 raw words (62539 effective words) took 0.1s, 477723 effective words/s\n",
      "2023-12-06 15:24:02,598 : INFO : EPOCH 4: training on 99524 raw words (62772 effective words) took 0.1s, 509597 effective words/s\n",
      "2023-12-06 15:24:02,725 : INFO : EPOCH 5: training on 99524 raw words (62772 effective words) took 0.1s, 508585 effective words/s\n",
      "2023-12-06 15:24:02,853 : INFO : EPOCH 6: training on 99524 raw words (62724 effective words) took 0.1s, 507864 effective words/s\n",
      "2023-12-06 15:24:03,014 : INFO : EPOCH 7: training on 99524 raw words (62794 effective words) took 0.2s, 400992 effective words/s\n",
      "2023-12-06 15:24:03,143 : INFO : EPOCH 8: training on 99524 raw words (62691 effective words) took 0.1s, 504548 effective words/s\n",
      "2023-12-06 15:24:03,271 : INFO : EPOCH 9: training on 99524 raw words (62763 effective words) took 0.1s, 509156 effective words/s\n",
      "2023-12-06 15:24:03,407 : INFO : EPOCH 10: training on 99524 raw words (62682 effective words) took 0.1s, 475189 effective words/s\n",
      "2023-12-06 15:24:03,543 : INFO : EPOCH 11: training on 99524 raw words (62836 effective words) took 0.1s, 472828 effective words/s\n",
      "2023-12-06 15:24:03,679 : INFO : EPOCH 12: training on 99524 raw words (62796 effective words) took 0.1s, 480814 effective words/s\n",
      "2023-12-06 15:24:03,827 : INFO : EPOCH 13: training on 99524 raw words (62667 effective words) took 0.1s, 435054 effective words/s\n",
      "2023-12-06 15:24:03,967 : INFO : EPOCH 14: training on 99524 raw words (62764 effective words) took 0.1s, 468671 effective words/s\n",
      "2023-12-06 15:24:04,102 : INFO : EPOCH 15: training on 99524 raw words (62604 effective words) took 0.1s, 476657 effective words/s\n",
      "2023-12-06 15:24:04,238 : INFO : EPOCH 16: training on 99524 raw words (62758 effective words) took 0.1s, 477628 effective words/s\n",
      "2023-12-06 15:24:04,374 : INFO : EPOCH 17: training on 99524 raw words (62664 effective words) took 0.1s, 473473 effective words/s\n",
      "2023-12-06 15:24:04,508 : INFO : EPOCH 18: training on 99524 raw words (62618 effective words) took 0.1s, 481215 effective words/s\n",
      "2023-12-06 15:24:04,663 : INFO : EPOCH 19: training on 99524 raw words (62852 effective words) took 0.2s, 418971 effective words/s\n",
      "2023-12-06 15:24:04,802 : INFO : EPOCH 20: training on 99524 raw words (62699 effective words) took 0.1s, 465007 effective words/s\n",
      "2023-12-06 15:24:04,938 : INFO : EPOCH 21: training on 99524 raw words (62851 effective words) took 0.1s, 478178 effective words/s\n",
      "2023-12-06 15:24:05,074 : INFO : EPOCH 22: training on 99524 raw words (62724 effective words) took 0.1s, 476587 effective words/s\n",
      "2023-12-06 15:24:05,213 : INFO : EPOCH 23: training on 99524 raw words (62673 effective words) took 0.1s, 464790 effective words/s\n",
      "2023-12-06 15:24:05,365 : INFO : EPOCH 24: training on 99524 raw words (62715 effective words) took 0.1s, 424641 effective words/s\n",
      "2023-12-06 15:24:05,500 : INFO : EPOCH 25: training on 99524 raw words (62711 effective words) took 0.1s, 478915 effective words/s\n",
      "2023-12-06 15:24:05,635 : INFO : EPOCH 26: training on 99524 raw words (62882 effective words) took 0.1s, 480364 effective words/s\n",
      "2023-12-06 15:24:05,770 : INFO : EPOCH 27: training on 99524 raw words (62758 effective words) took 0.1s, 478454 effective words/s\n",
      "2023-12-06 15:24:05,922 : INFO : EPOCH 28: training on 99524 raw words (62707 effective words) took 0.1s, 425720 effective words/s\n",
      "2023-12-06 15:24:06,050 : INFO : EPOCH 29: training on 99524 raw words (62747 effective words) took 0.1s, 504322 effective words/s\n",
      "2023-12-06 15:24:06,051 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881781 effective words) took 4.2s, 451739 effective words/s', 'datetime': '2023-12-06T15:24:06.051806', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:24:06,052 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:24:06.052804', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 92%|| 445/486 [1:10:27<04:23,  6.42s/it]2023-12-06 15:24:09,032 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:24:09,033 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:24:09,054 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:24:09,055 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:24:09,060 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:24:09.060604', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:24:09,060 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:24:09.060604', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:24:09,066 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:24:09,066 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:24:09,066 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:24:09.066601', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:24:09,075 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:24:09,076 : INFO : resetting layer weights\n",
      "2023-12-06 15:24:09,080 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:24:09.080728', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:24:09,208 : INFO : EPOCH 0: training on 99524 raw words (62795 effective words) took 0.1s, 506708 effective words/s\n",
      "2023-12-06 15:24:09,400 : INFO : EPOCH 1: training on 99524 raw words (62635 effective words) took 0.2s, 340021 effective words/s\n",
      "2023-12-06 15:24:09,542 : INFO : EPOCH 2: training on 99524 raw words (62671 effective words) took 0.1s, 453173 effective words/s\n",
      "2023-12-06 15:24:09,681 : INFO : EPOCH 3: training on 99524 raw words (62623 effective words) took 0.1s, 466388 effective words/s\n",
      "2023-12-06 15:24:09,819 : INFO : EPOCH 4: training on 99524 raw words (62877 effective words) took 0.1s, 472089 effective words/s\n",
      "2023-12-06 15:24:09,955 : INFO : EPOCH 5: training on 99524 raw words (62667 effective words) took 0.1s, 476113 effective words/s\n",
      "2023-12-06 15:24:10,091 : INFO : EPOCH 6: training on 99524 raw words (62705 effective words) took 0.1s, 474242 effective words/s\n",
      "2023-12-06 15:24:10,250 : INFO : EPOCH 7: training on 99524 raw words (62733 effective words) took 0.2s, 404414 effective words/s\n",
      "2023-12-06 15:24:10,392 : INFO : EPOCH 8: training on 99524 raw words (62756 effective words) took 0.1s, 459744 effective words/s\n",
      "2023-12-06 15:24:10,530 : INFO : EPOCH 9: training on 99524 raw words (62698 effective words) took 0.1s, 467871 effective words/s\n",
      "2023-12-06 15:24:10,671 : INFO : EPOCH 10: training on 99524 raw words (62678 effective words) took 0.1s, 460117 effective words/s\n",
      "2023-12-06 15:24:10,827 : INFO : EPOCH 11: training on 99524 raw words (62964 effective words) took 0.2s, 413290 effective words/s\n",
      "2023-12-06 15:24:10,965 : INFO : EPOCH 12: training on 99524 raw words (62719 effective words) took 0.1s, 473126 effective words/s\n",
      "2023-12-06 15:24:11,100 : INFO : EPOCH 13: training on 99524 raw words (62693 effective words) took 0.1s, 475451 effective words/s\n",
      "2023-12-06 15:24:11,239 : INFO : EPOCH 14: training on 99524 raw words (62756 effective words) took 0.1s, 468078 effective words/s\n",
      "2023-12-06 15:24:11,374 : INFO : EPOCH 15: training on 99524 raw words (62904 effective words) took 0.1s, 479034 effective words/s\n",
      "2023-12-06 15:24:11,511 : INFO : EPOCH 16: training on 99524 raw words (62857 effective words) took 0.1s, 474504 effective words/s\n",
      "2023-12-06 15:24:11,669 : INFO : EPOCH 17: training on 99524 raw words (62630 effective words) took 0.2s, 408658 effective words/s\n",
      "2023-12-06 15:24:11,807 : INFO : EPOCH 18: training on 99524 raw words (62669 effective words) took 0.1s, 467479 effective words/s\n",
      "2023-12-06 15:24:11,947 : INFO : EPOCH 19: training on 99524 raw words (62798 effective words) took 0.1s, 467455 effective words/s\n",
      "2023-12-06 15:24:12,084 : INFO : EPOCH 20: training on 99524 raw words (62762 effective words) took 0.1s, 471848 effective words/s\n",
      "2023-12-06 15:24:12,240 : INFO : EPOCH 21: training on 99524 raw words (62773 effective words) took 0.2s, 411508 effective words/s\n",
      "2023-12-06 15:24:12,380 : INFO : EPOCH 22: training on 99524 raw words (62734 effective words) took 0.1s, 465532 effective words/s\n",
      "2023-12-06 15:24:12,518 : INFO : EPOCH 23: training on 99524 raw words (62812 effective words) took 0.1s, 469294 effective words/s\n",
      "2023-12-06 15:24:12,655 : INFO : EPOCH 24: training on 99524 raw words (62637 effective words) took 0.1s, 471957 effective words/s\n",
      "2023-12-06 15:24:12,791 : INFO : EPOCH 25: training on 99524 raw words (62728 effective words) took 0.1s, 476541 effective words/s\n",
      "2023-12-06 15:24:12,928 : INFO : EPOCH 26: training on 99524 raw words (62780 effective words) took 0.1s, 471003 effective words/s\n",
      "2023-12-06 15:24:13,085 : INFO : EPOCH 27: training on 99524 raw words (62867 effective words) took 0.2s, 415049 effective words/s\n",
      "2023-12-06 15:24:13,221 : INFO : EPOCH 28: training on 99524 raw words (62817 effective words) took 0.1s, 473893 effective words/s\n",
      "2023-12-06 15:24:13,360 : INFO : EPOCH 29: training on 99524 raw words (62661 effective words) took 0.1s, 467594 effective words/s\n",
      "2023-12-06 15:24:13,360 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1882399 effective words) took 4.3s, 439792 effective words/s', 'datetime': '2023-12-06T15:24:13.360684', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:24:13,362 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:24:13.362173', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 92%|| 446/486 [1:10:35<04:30,  6.76s/it]2023-12-06 15:24:16,569 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:24:16,569 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:24:16,593 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:24:16,593 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:24:16,598 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:24:16.598311', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:24:16,599 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:24:16.599312', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:24:16,605 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:24:16,605 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:24:16,606 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:24:16.606458', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:24:16,614 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:24:16,615 : INFO : resetting layer weights\n",
      "2023-12-06 15:24:16,619 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:24:16.619267', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:24:16,745 : INFO : EPOCH 0: training on 99524 raw words (62719 effective words) took 0.1s, 515945 effective words/s\n",
      "2023-12-06 15:24:16,925 : INFO : EPOCH 1: training on 99524 raw words (62815 effective words) took 0.2s, 358599 effective words/s\n",
      "2023-12-06 15:24:17,071 : INFO : EPOCH 2: training on 99524 raw words (62805 effective words) took 0.1s, 452994 effective words/s\n",
      "2023-12-06 15:24:17,208 : INFO : EPOCH 3: training on 99524 raw words (62691 effective words) took 0.1s, 471595 effective words/s\n",
      "2023-12-06 15:24:17,348 : INFO : EPOCH 4: training on 99524 raw words (62675 effective words) took 0.1s, 464554 effective words/s\n",
      "2023-12-06 15:24:17,476 : INFO : EPOCH 5: training on 99524 raw words (62569 effective words) took 0.1s, 506585 effective words/s\n",
      "2023-12-06 15:24:17,603 : INFO : EPOCH 6: training on 99524 raw words (62759 effective words) took 0.1s, 507575 effective words/s\n",
      "2023-12-06 15:24:17,740 : INFO : EPOCH 7: training on 99524 raw words (62793 effective words) took 0.1s, 475028 effective words/s\n",
      "2023-12-06 15:24:17,910 : INFO : EPOCH 8: training on 99524 raw words (62792 effective words) took 0.2s, 380452 effective words/s\n",
      "2023-12-06 15:24:18,046 : INFO : EPOCH 9: training on 99524 raw words (62649 effective words) took 0.1s, 474976 effective words/s\n",
      "2023-12-06 15:24:18,183 : INFO : EPOCH 10: training on 99524 raw words (62606 effective words) took 0.1s, 472416 effective words/s\n",
      "2023-12-06 15:24:18,324 : INFO : EPOCH 11: training on 99524 raw words (62769 effective words) took 0.1s, 459955 effective words/s\n",
      "2023-12-06 15:24:18,490 : INFO : EPOCH 12: training on 99524 raw words (62517 effective words) took 0.2s, 386407 effective words/s\n",
      "2023-12-06 15:24:18,627 : INFO : EPOCH 13: training on 99524 raw words (62559 effective words) took 0.1s, 472191 effective words/s\n",
      "2023-12-06 15:24:18,765 : INFO : EPOCH 14: training on 99524 raw words (62836 effective words) took 0.1s, 470949 effective words/s\n",
      "2023-12-06 15:24:18,906 : INFO : EPOCH 15: training on 99524 raw words (62748 effective words) took 0.1s, 455188 effective words/s\n",
      "2023-12-06 15:24:19,045 : INFO : EPOCH 16: training on 99524 raw words (62694 effective words) took 0.1s, 469595 effective words/s\n",
      "2023-12-06 15:24:19,182 : INFO : EPOCH 17: training on 99524 raw words (62531 effective words) took 0.1s, 468283 effective words/s\n",
      "2023-12-06 15:24:19,341 : INFO : EPOCH 18: training on 99524 raw words (62665 effective words) took 0.2s, 406420 effective words/s\n",
      "2023-12-06 15:24:19,469 : INFO : EPOCH 19: training on 99524 raw words (62750 effective words) took 0.1s, 508490 effective words/s\n",
      "2023-12-06 15:24:19,610 : INFO : EPOCH 20: training on 99524 raw words (62653 effective words) took 0.1s, 460188 effective words/s\n",
      "2023-12-06 15:24:19,747 : INFO : EPOCH 21: training on 99524 raw words (62866 effective words) took 0.1s, 474301 effective words/s\n",
      "2023-12-06 15:24:19,891 : INFO : EPOCH 22: training on 99524 raw words (62782 effective words) took 0.1s, 450759 effective words/s\n",
      "2023-12-06 15:24:20,028 : INFO : EPOCH 23: training on 99524 raw words (62808 effective words) took 0.1s, 469913 effective words/s\n",
      "2023-12-06 15:24:20,188 : INFO : EPOCH 24: training on 99524 raw words (62682 effective words) took 0.2s, 402332 effective words/s\n",
      "2023-12-06 15:24:20,328 : INFO : EPOCH 25: training on 99524 raw words (62709 effective words) took 0.1s, 466526 effective words/s\n",
      "2023-12-06 15:24:20,466 : INFO : EPOCH 26: training on 99524 raw words (62798 effective words) took 0.1s, 464737 effective words/s\n",
      "2023-12-06 15:24:20,614 : INFO : EPOCH 27: training on 99524 raw words (62839 effective words) took 0.1s, 437414 effective words/s\n",
      "2023-12-06 15:24:20,752 : INFO : EPOCH 28: training on 99524 raw words (62714 effective words) took 0.1s, 467781 effective words/s\n",
      "2023-12-06 15:24:20,893 : INFO : EPOCH 29: training on 99524 raw words (62780 effective words) took 0.1s, 463346 effective words/s\n",
      "2023-12-06 15:24:20,894 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881573 effective words) took 4.3s, 440226 effective words/s', 'datetime': '2023-12-06T15:24:20.894266', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:24:20,895 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:24:20.895265', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 92%|| 447/486 [1:10:42<04:33,  7.02s/it]2023-12-06 15:24:24,218 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:24:24,219 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:24:24,240 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:24:24,241 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:24:24,246 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:24:24.246362', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:24:24,246 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:24:24.246362', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:24:24,251 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:24:24,252 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:24:24,252 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:24:24.252968', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:24:24,260 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:24:24,261 : INFO : resetting layer weights\n",
      "2023-12-06 15:24:24,265 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:24:24.265237', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:24:24,391 : INFO : EPOCH 0: training on 99524 raw words (62800 effective words) took 0.1s, 510969 effective words/s\n",
      "2023-12-06 15:24:24,549 : INFO : EPOCH 1: training on 99524 raw words (62623 effective words) took 0.2s, 406319 effective words/s\n",
      "2023-12-06 15:24:24,706 : INFO : EPOCH 2: training on 99524 raw words (62878 effective words) took 0.1s, 436118 effective words/s\n",
      "2023-12-06 15:24:24,842 : INFO : EPOCH 3: training on 99524 raw words (62558 effective words) took 0.1s, 471607 effective words/s\n",
      "2023-12-06 15:24:24,978 : INFO : EPOCH 4: training on 99524 raw words (62733 effective words) took 0.1s, 478561 effective words/s\n",
      "2023-12-06 15:24:25,114 : INFO : EPOCH 5: training on 99524 raw words (62563 effective words) took 0.1s, 474165 effective words/s\n",
      "2023-12-06 15:24:25,250 : INFO : EPOCH 6: training on 99524 raw words (62824 effective words) took 0.1s, 478427 effective words/s\n",
      "2023-12-06 15:24:25,387 : INFO : EPOCH 7: training on 99524 raw words (62827 effective words) took 0.1s, 474237 effective words/s\n",
      "2023-12-06 15:24:25,534 : INFO : EPOCH 8: training on 99524 raw words (62793 effective words) took 0.1s, 434993 effective words/s\n",
      "2023-12-06 15:24:25,663 : INFO : EPOCH 9: training on 99524 raw words (62610 effective words) took 0.1s, 506634 effective words/s\n",
      "2023-12-06 15:24:25,798 : INFO : EPOCH 10: training on 99524 raw words (62670 effective words) took 0.1s, 481724 effective words/s\n",
      "2023-12-06 15:24:25,934 : INFO : EPOCH 11: training on 99524 raw words (62859 effective words) took 0.1s, 477476 effective words/s\n",
      "2023-12-06 15:24:26,084 : INFO : EPOCH 12: training on 99524 raw words (62877 effective words) took 0.1s, 428902 effective words/s\n",
      "2023-12-06 15:24:26,222 : INFO : EPOCH 13: training on 99524 raw words (62596 effective words) took 0.1s, 474233 effective words/s\n",
      "2023-12-06 15:24:26,358 : INFO : EPOCH 14: training on 99524 raw words (62731 effective words) took 0.1s, 475868 effective words/s\n",
      "2023-12-06 15:24:26,492 : INFO : EPOCH 15: training on 99524 raw words (62692 effective words) took 0.1s, 484024 effective words/s\n",
      "2023-12-06 15:24:26,642 : INFO : EPOCH 16: training on 99524 raw words (62725 effective words) took 0.1s, 426952 effective words/s\n",
      "2023-12-06 15:24:26,781 : INFO : EPOCH 17: training on 99524 raw words (62766 effective words) took 0.1s, 468531 effective words/s\n",
      "2023-12-06 15:24:26,914 : INFO : EPOCH 18: training on 99524 raw words (62688 effective words) took 0.1s, 485524 effective words/s\n",
      "2023-12-06 15:24:27,051 : INFO : EPOCH 19: training on 99524 raw words (62769 effective words) took 0.1s, 476075 effective words/s\n",
      "2023-12-06 15:24:27,188 : INFO : EPOCH 20: training on 99524 raw words (62775 effective words) took 0.1s, 473755 effective words/s\n",
      "2023-12-06 15:24:27,321 : INFO : EPOCH 21: training on 99524 raw words (62696 effective words) took 0.1s, 485200 effective words/s\n",
      "2023-12-06 15:24:27,486 : INFO : EPOCH 22: training on 99524 raw words (62866 effective words) took 0.2s, 390687 effective words/s\n",
      "2023-12-06 15:24:27,624 : INFO : EPOCH 23: training on 99524 raw words (62755 effective words) took 0.1s, 468907 effective words/s\n",
      "2023-12-06 15:24:27,759 : INFO : EPOCH 24: training on 99524 raw words (62804 effective words) took 0.1s, 480566 effective words/s\n",
      "2023-12-06 15:24:27,893 : INFO : EPOCH 25: training on 99524 raw words (62871 effective words) took 0.1s, 482581 effective words/s\n",
      "2023-12-06 15:24:28,029 : INFO : EPOCH 26: training on 99524 raw words (62756 effective words) took 0.1s, 481407 effective words/s\n",
      "2023-12-06 15:24:28,180 : INFO : EPOCH 27: training on 99524 raw words (62873 effective words) took 0.1s, 427776 effective words/s\n",
      "2023-12-06 15:24:28,315 : INFO : EPOCH 28: training on 99524 raw words (62676 effective words) took 0.1s, 477842 effective words/s\n",
      "2023-12-06 15:24:28,454 : INFO : EPOCH 29: training on 99524 raw words (62582 effective words) took 0.1s, 467059 effective words/s\n",
      "2023-12-06 15:24:28,587 : INFO : EPOCH 30: training on 99524 raw words (62678 effective words) took 0.1s, 485163 effective words/s\n",
      "2023-12-06 15:24:28,724 : INFO : EPOCH 31: training on 99524 raw words (62650 effective words) took 0.1s, 472018 effective words/s\n",
      "2023-12-06 15:24:28,860 : INFO : EPOCH 32: training on 99524 raw words (62606 effective words) took 0.1s, 476853 effective words/s\n",
      "2023-12-06 15:24:29,018 : INFO : EPOCH 33: training on 99524 raw words (62809 effective words) took 0.2s, 408211 effective words/s\n",
      "2023-12-06 15:24:29,156 : INFO : EPOCH 34: training on 99524 raw words (62683 effective words) took 0.1s, 469712 effective words/s\n",
      "2023-12-06 15:24:29,290 : INFO : EPOCH 35: training on 99524 raw words (62847 effective words) took 0.1s, 479041 effective words/s\n",
      "2023-12-06 15:24:29,426 : INFO : EPOCH 36: training on 99524 raw words (62602 effective words) took 0.1s, 475711 effective words/s\n",
      "2023-12-06 15:24:29,568 : INFO : EPOCH 37: training on 99524 raw words (62746 effective words) took 0.1s, 456650 effective words/s\n",
      "2023-12-06 15:24:29,705 : INFO : EPOCH 38: training on 99524 raw words (62569 effective words) took 0.1s, 473227 effective words/s\n",
      "2023-12-06 15:24:29,859 : INFO : EPOCH 39: training on 99524 raw words (62630 effective words) took 0.2s, 414350 effective words/s\n",
      "2023-12-06 15:24:29,998 : INFO : EPOCH 40: training on 99524 raw words (62572 effective words) took 0.1s, 466959 effective words/s\n",
      "2023-12-06 15:24:30,134 : INFO : EPOCH 41: training on 99524 raw words (62642 effective words) took 0.1s, 473270 effective words/s\n",
      "2023-12-06 15:24:30,271 : INFO : EPOCH 42: training on 99524 raw words (62739 effective words) took 0.1s, 476763 effective words/s\n",
      "2023-12-06 15:24:30,413 : INFO : EPOCH 43: training on 99524 raw words (62721 effective words) took 0.1s, 451575 effective words/s\n",
      "2023-12-06 15:24:30,549 : INFO : EPOCH 44: training on 99524 raw words (62544 effective words) took 0.1s, 475964 effective words/s\n",
      "2023-12-06 15:24:30,698 : INFO : EPOCH 45: training on 99524 raw words (62687 effective words) took 0.1s, 433134 effective words/s\n",
      "2023-12-06 15:24:30,835 : INFO : EPOCH 46: training on 99524 raw words (62769 effective words) took 0.1s, 473384 effective words/s\n",
      "2023-12-06 15:24:30,971 : INFO : EPOCH 47: training on 99524 raw words (62716 effective words) took 0.1s, 477912 effective words/s\n",
      "2023-12-06 15:24:31,106 : INFO : EPOCH 48: training on 99524 raw words (62917 effective words) took 0.1s, 480010 effective words/s\n",
      "2023-12-06 15:24:31,258 : INFO : EPOCH 49: training on 99524 raw words (62576 effective words) took 0.1s, 421980 effective words/s\n",
      "2023-12-06 15:24:31,259 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3135939 effective words) took 7.0s, 448360 effective words/s', 'datetime': '2023-12-06T15:24:31.259692', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:24:31,260 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:24:31.260691', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 92%|| 448/486 [1:10:53<05:05,  8.04s/it]2023-12-06 15:24:34,619 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:24:34,619 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:24:34,642 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:24:34,643 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:24:34,648 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:24:34.648205', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:24:34,648 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:24:34.648205', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:24:34,654 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:24:34,655 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:24:34,655 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:24:34.655297', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:24:34,663 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:24:34,664 : INFO : resetting layer weights\n",
      "2023-12-06 15:24:34,668 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:24:34.668520', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:24:34,792 : INFO : EPOCH 0: training on 99524 raw words (62751 effective words) took 0.1s, 520984 effective words/s\n",
      "2023-12-06 15:24:34,969 : INFO : EPOCH 1: training on 99524 raw words (62646 effective words) took 0.2s, 363933 effective words/s\n",
      "2023-12-06 15:24:35,119 : INFO : EPOCH 2: training on 99524 raw words (62749 effective words) took 0.1s, 468325 effective words/s\n",
      "2023-12-06 15:24:35,260 : INFO : EPOCH 3: training on 99524 raw words (62547 effective words) took 0.1s, 457400 effective words/s\n",
      "2023-12-06 15:24:35,396 : INFO : EPOCH 4: training on 99524 raw words (62643 effective words) took 0.1s, 476981 effective words/s\n",
      "2023-12-06 15:24:35,532 : INFO : EPOCH 5: training on 99524 raw words (62753 effective words) took 0.1s, 475311 effective words/s\n",
      "2023-12-06 15:24:35,669 : INFO : EPOCH 6: training on 99524 raw words (62817 effective words) took 0.1s, 470470 effective words/s\n",
      "2023-12-06 15:24:35,808 : INFO : EPOCH 7: training on 99524 raw words (62776 effective words) took 0.1s, 469938 effective words/s\n",
      "2023-12-06 15:24:35,965 : INFO : EPOCH 8: training on 99524 raw words (62727 effective words) took 0.2s, 407731 effective words/s\n",
      "2023-12-06 15:24:36,104 : INFO : EPOCH 9: training on 99524 raw words (62732 effective words) took 0.1s, 469980 effective words/s\n",
      "2023-12-06 15:24:36,239 : INFO : EPOCH 10: training on 99524 raw words (62757 effective words) took 0.1s, 476640 effective words/s\n",
      "2023-12-06 15:24:36,376 : INFO : EPOCH 11: training on 99524 raw words (62808 effective words) took 0.1s, 474078 effective words/s\n",
      "2023-12-06 15:24:36,514 : INFO : EPOCH 12: training on 99524 raw words (62720 effective words) took 0.1s, 471406 effective words/s\n",
      "2023-12-06 15:24:36,651 : INFO : EPOCH 13: training on 99524 raw words (62646 effective words) took 0.1s, 472983 effective words/s\n",
      "2023-12-06 15:24:36,817 : INFO : EPOCH 14: training on 99524 raw words (62740 effective words) took 0.2s, 386635 effective words/s\n",
      "2023-12-06 15:24:36,954 : INFO : EPOCH 15: training on 99524 raw words (62638 effective words) took 0.1s, 471184 effective words/s\n",
      "2023-12-06 15:24:37,090 : INFO : EPOCH 16: training on 99524 raw words (62717 effective words) took 0.1s, 476653 effective words/s\n",
      "2023-12-06 15:24:37,228 : INFO : EPOCH 17: training on 99524 raw words (62611 effective words) took 0.1s, 469292 effective words/s\n",
      "2023-12-06 15:24:37,371 : INFO : EPOCH 18: training on 99524 raw words (62677 effective words) took 0.1s, 452217 effective words/s\n",
      "2023-12-06 15:24:37,505 : INFO : EPOCH 19: training on 99524 raw words (62842 effective words) took 0.1s, 485402 effective words/s\n",
      "2023-12-06 15:24:37,663 : INFO : EPOCH 20: training on 99524 raw words (62641 effective words) took 0.2s, 405777 effective words/s\n",
      "2023-12-06 15:24:37,802 : INFO : EPOCH 21: training on 99524 raw words (62846 effective words) took 0.1s, 469336 effective words/s\n",
      "2023-12-06 15:24:37,941 : INFO : EPOCH 22: training on 99524 raw words (62829 effective words) took 0.1s, 464289 effective words/s\n",
      "2023-12-06 15:24:38,095 : INFO : EPOCH 23: training on 99524 raw words (62766 effective words) took 0.1s, 419423 effective words/s\n",
      "2023-12-06 15:24:38,262 : INFO : EPOCH 24: training on 99524 raw words (62928 effective words) took 0.2s, 388633 effective words/s\n",
      "2023-12-06 15:24:38,402 : INFO : EPOCH 25: training on 99524 raw words (62756 effective words) took 0.1s, 464332 effective words/s\n",
      "2023-12-06 15:24:38,541 : INFO : EPOCH 26: training on 99524 raw words (62868 effective words) took 0.1s, 465940 effective words/s\n",
      "2023-12-06 15:24:38,679 : INFO : EPOCH 27: training on 99524 raw words (62827 effective words) took 0.1s, 469679 effective words/s\n",
      "2023-12-06 15:24:38,815 : INFO : EPOCH 28: training on 99524 raw words (62718 effective words) took 0.1s, 479454 effective words/s\n",
      "2023-12-06 15:24:38,957 : INFO : EPOCH 29: training on 99524 raw words (62659 effective words) took 0.1s, 452926 effective words/s\n",
      "2023-12-06 15:24:39,122 : INFO : EPOCH 30: training on 99524 raw words (62579 effective words) took 0.2s, 389060 effective words/s\n",
      "2023-12-06 15:24:39,259 : INFO : EPOCH 31: training on 99524 raw words (62730 effective words) took 0.1s, 476682 effective words/s\n",
      "2023-12-06 15:24:39,396 : INFO : EPOCH 32: training on 99524 raw words (62669 effective words) took 0.1s, 472627 effective words/s\n",
      "2023-12-06 15:24:39,532 : INFO : EPOCH 33: training on 99524 raw words (62822 effective words) took 0.1s, 476457 effective words/s\n",
      "2023-12-06 15:24:39,666 : INFO : EPOCH 34: training on 99524 raw words (62882 effective words) took 0.1s, 481621 effective words/s\n",
      "2023-12-06 15:24:39,809 : INFO : EPOCH 35: training on 99524 raw words (62790 effective words) took 0.1s, 453526 effective words/s\n",
      "2023-12-06 15:24:39,975 : INFO : EPOCH 36: training on 99524 raw words (62676 effective words) took 0.2s, 385875 effective words/s\n",
      "2023-12-06 15:24:40,111 : INFO : EPOCH 37: training on 99524 raw words (62633 effective words) took 0.1s, 476433 effective words/s\n",
      "2023-12-06 15:24:40,247 : INFO : EPOCH 38: training on 99524 raw words (62638 effective words) took 0.1s, 475439 effective words/s\n",
      "2023-12-06 15:24:40,384 : INFO : EPOCH 39: training on 99524 raw words (62749 effective words) took 0.1s, 470164 effective words/s\n",
      "2023-12-06 15:24:40,520 : INFO : EPOCH 40: training on 99524 raw words (62518 effective words) took 0.1s, 475870 effective words/s\n",
      "2023-12-06 15:24:40,687 : INFO : EPOCH 41: training on 99524 raw words (62842 effective words) took 0.2s, 402968 effective words/s\n",
      "2023-12-06 15:24:40,816 : INFO : EPOCH 42: training on 99524 raw words (62811 effective words) took 0.1s, 506125 effective words/s\n",
      "2023-12-06 15:24:40,943 : INFO : EPOCH 43: training on 99524 raw words (62771 effective words) took 0.1s, 507579 effective words/s\n",
      "2023-12-06 15:24:41,079 : INFO : EPOCH 44: training on 99524 raw words (62688 effective words) took 0.1s, 475711 effective words/s\n",
      "2023-12-06 15:24:41,225 : INFO : EPOCH 45: training on 99524 raw words (62694 effective words) took 0.1s, 444405 effective words/s\n",
      "2023-12-06 15:24:41,362 : INFO : EPOCH 46: training on 99524 raw words (62787 effective words) took 0.1s, 470347 effective words/s\n",
      "2023-12-06 15:24:41,502 : INFO : EPOCH 47: training on 99524 raw words (62647 effective words) took 0.1s, 459427 effective words/s\n",
      "2023-12-06 15:24:41,640 : INFO : EPOCH 48: training on 99524 raw words (62626 effective words) took 0.1s, 470366 effective words/s\n",
      "2023-12-06 15:24:41,776 : INFO : EPOCH 49: training on 99524 raw words (62755 effective words) took 0.1s, 473594 effective words/s\n",
      "2023-12-06 15:24:41,778 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136442 effective words) took 7.1s, 441173 effective words/s', 'datetime': '2023-12-06T15:24:41.778506', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:24:41,779 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:24:41.779517', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 92%|| 449/486 [1:11:04<05:27,  8.86s/it]2023-12-06 15:24:45,412 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:24:45,413 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:24:45,437 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:24:45,438 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:24:45,443 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:24:45.443240', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:24:45,445 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:24:45.444239', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:24:45,450 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:24:45,451 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:24:45,451 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:24:45.451619', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:24:45,460 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:24:45,461 : INFO : resetting layer weights\n",
      "2023-12-06 15:24:45,466 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:24:45.466256', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:24:45,592 : INFO : EPOCH 0: training on 99524 raw words (62695 effective words) took 0.1s, 509609 effective words/s\n",
      "2023-12-06 15:24:45,755 : INFO : EPOCH 1: training on 99524 raw words (62899 effective words) took 0.2s, 395154 effective words/s\n",
      "2023-12-06 15:24:45,913 : INFO : EPOCH 2: training on 99524 raw words (62870 effective words) took 0.2s, 414437 effective words/s\n",
      "2023-12-06 15:24:46,054 : INFO : EPOCH 3: training on 99524 raw words (62682 effective words) took 0.1s, 456322 effective words/s\n",
      "2023-12-06 15:24:46,183 : INFO : EPOCH 4: training on 99524 raw words (62676 effective words) took 0.1s, 503828 effective words/s\n",
      "2023-12-06 15:24:46,310 : INFO : EPOCH 5: training on 99524 raw words (62727 effective words) took 0.1s, 513072 effective words/s\n",
      "2023-12-06 15:24:46,436 : INFO : EPOCH 6: training on 99524 raw words (62708 effective words) took 0.1s, 513742 effective words/s\n",
      "2023-12-06 15:24:46,575 : INFO : EPOCH 7: training on 99524 raw words (62679 effective words) took 0.1s, 464767 effective words/s\n",
      "2023-12-06 15:24:46,733 : INFO : EPOCH 8: training on 99524 raw words (62619 effective words) took 0.2s, 407439 effective words/s\n",
      "2023-12-06 15:24:46,873 : INFO : EPOCH 9: training on 99524 raw words (62900 effective words) took 0.1s, 466101 effective words/s\n",
      "2023-12-06 15:24:47,002 : INFO : EPOCH 10: training on 99524 raw words (62718 effective words) took 0.1s, 503179 effective words/s\n",
      "2023-12-06 15:24:47,138 : INFO : EPOCH 11: training on 99524 raw words (62865 effective words) took 0.1s, 475608 effective words/s\n",
      "2023-12-06 15:24:47,289 : INFO : EPOCH 12: training on 99524 raw words (62723 effective words) took 0.1s, 424142 effective words/s\n",
      "2023-12-06 15:24:47,422 : INFO : EPOCH 13: training on 99524 raw words (62727 effective words) took 0.1s, 494533 effective words/s\n",
      "2023-12-06 15:24:47,547 : INFO : EPOCH 14: training on 99524 raw words (62757 effective words) took 0.1s, 518275 effective words/s\n",
      "2023-12-06 15:24:47,675 : INFO : EPOCH 15: training on 99524 raw words (62677 effective words) took 0.1s, 509053 effective words/s\n",
      "2023-12-06 15:24:47,829 : INFO : EPOCH 16: training on 99524 raw words (62725 effective words) took 0.1s, 419757 effective words/s\n",
      "2023-12-06 15:24:47,967 : INFO : EPOCH 17: training on 99524 raw words (62628 effective words) took 0.1s, 470454 effective words/s\n",
      "2023-12-06 15:24:48,105 : INFO : EPOCH 18: training on 99524 raw words (62637 effective words) took 0.1s, 468189 effective words/s\n",
      "2023-12-06 15:24:48,244 : INFO : EPOCH 19: training on 99524 raw words (62800 effective words) took 0.1s, 465673 effective words/s\n",
      "2023-12-06 15:24:48,382 : INFO : EPOCH 20: training on 99524 raw words (62838 effective words) took 0.1s, 469417 effective words/s\n",
      "2023-12-06 15:24:48,520 : INFO : EPOCH 21: training on 99524 raw words (62946 effective words) took 0.1s, 470743 effective words/s\n",
      "2023-12-06 15:24:48,685 : INFO : EPOCH 22: training on 99524 raw words (62872 effective words) took 0.2s, 393698 effective words/s\n",
      "2023-12-06 15:24:48,830 : INFO : EPOCH 23: training on 99524 raw words (62760 effective words) took 0.1s, 445156 effective words/s\n",
      "2023-12-06 15:24:48,969 : INFO : EPOCH 24: training on 99524 raw words (62725 effective words) took 0.1s, 461841 effective words/s\n",
      "2023-12-06 15:24:49,109 : INFO : EPOCH 25: training on 99524 raw words (62573 effective words) took 0.1s, 465488 effective words/s\n",
      "2023-12-06 15:24:49,245 : INFO : EPOCH 26: training on 99524 raw words (62662 effective words) took 0.1s, 475692 effective words/s\n",
      "2023-12-06 15:24:49,386 : INFO : EPOCH 27: training on 99524 raw words (62955 effective words) took 0.1s, 462446 effective words/s\n",
      "2023-12-06 15:24:49,547 : INFO : EPOCH 28: training on 99524 raw words (62661 effective words) took 0.2s, 397061 effective words/s\n",
      "2023-12-06 15:24:49,692 : INFO : EPOCH 29: training on 99524 raw words (62705 effective words) took 0.1s, 447361 effective words/s\n",
      "2023-12-06 15:24:49,830 : INFO : EPOCH 30: training on 99524 raw words (62685 effective words) took 0.1s, 469370 effective words/s\n",
      "2023-12-06 15:24:49,967 : INFO : EPOCH 31: training on 99524 raw words (62714 effective words) took 0.1s, 470048 effective words/s\n",
      "2023-12-06 15:24:50,108 : INFO : EPOCH 32: training on 99524 raw words (62808 effective words) took 0.1s, 459086 effective words/s\n",
      "2023-12-06 15:24:50,246 : INFO : EPOCH 33: training on 99524 raw words (62682 effective words) took 0.1s, 471744 effective words/s\n",
      "2023-12-06 15:24:50,407 : INFO : EPOCH 34: training on 99524 raw words (62784 effective words) took 0.2s, 399806 effective words/s\n",
      "2023-12-06 15:24:50,551 : INFO : EPOCH 35: training on 99524 raw words (62819 effective words) took 0.1s, 450675 effective words/s\n",
      "2023-12-06 15:24:50,688 : INFO : EPOCH 36: training on 99524 raw words (62713 effective words) took 0.1s, 469390 effective words/s\n",
      "2023-12-06 15:24:50,826 : INFO : EPOCH 37: training on 99524 raw words (62573 effective words) took 0.1s, 467792 effective words/s\n",
      "2023-12-06 15:24:50,964 : INFO : EPOCH 38: training on 99524 raw words (62557 effective words) took 0.1s, 470000 effective words/s\n",
      "2023-12-06 15:24:51,103 : INFO : EPOCH 39: training on 99524 raw words (62693 effective words) took 0.1s, 466256 effective words/s\n",
      "2023-12-06 15:24:51,263 : INFO : EPOCH 40: training on 99524 raw words (62674 effective words) took 0.2s, 402520 effective words/s\n",
      "2023-12-06 15:24:51,407 : INFO : EPOCH 41: training on 99524 raw words (62675 effective words) took 0.1s, 447136 effective words/s\n",
      "2023-12-06 15:24:51,546 : INFO : EPOCH 42: training on 99524 raw words (62757 effective words) took 0.1s, 466825 effective words/s\n",
      "2023-12-06 15:24:51,673 : INFO : EPOCH 43: training on 99524 raw words (62777 effective words) took 0.1s, 507522 effective words/s\n",
      "2023-12-06 15:24:51,811 : INFO : EPOCH 44: training on 99524 raw words (62612 effective words) took 0.1s, 467900 effective words/s\n",
      "2023-12-06 15:24:51,979 : INFO : EPOCH 45: training on 99524 raw words (62696 effective words) took 0.2s, 386802 effective words/s\n",
      "2023-12-06 15:24:52,123 : INFO : EPOCH 46: training on 99524 raw words (62764 effective words) took 0.1s, 447981 effective words/s\n",
      "2023-12-06 15:24:52,268 : INFO : EPOCH 47: training on 99524 raw words (62744 effective words) took 0.1s, 446730 effective words/s\n",
      "2023-12-06 15:24:52,406 : INFO : EPOCH 48: training on 99524 raw words (62803 effective words) took 0.1s, 468172 effective words/s\n",
      "2023-12-06 15:24:52,544 : INFO : EPOCH 49: training on 99524 raw words (62688 effective words) took 0.1s, 467326 effective words/s\n",
      "2023-12-06 15:24:52,545 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136627 effective words) took 7.1s, 443078 effective words/s', 'datetime': '2023-12-06T15:24:52.545621', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:24:52,546 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:24:52.546622', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 93%|| 450/486 [1:11:15<05:42,  9.51s/it]2023-12-06 15:24:56,425 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:24:56,426 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:24:56,447 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:24:56,448 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:24:56,452 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:24:56.452808', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:24:56,453 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:24:56.453814', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:24:56,458 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:24:56,458 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:24:56,459 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:24:56.459559', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:24:56,465 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:24:56,466 : INFO : resetting layer weights\n",
      "2023-12-06 15:24:56,470 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:24:56.470261', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:24:56,596 : INFO : EPOCH 0: training on 99524 raw words (60376 effective words) took 0.1s, 495550 effective words/s\n",
      "2023-12-06 15:24:56,752 : INFO : EPOCH 1: training on 99524 raw words (60410 effective words) took 0.2s, 398205 effective words/s\n",
      "2023-12-06 15:24:56,905 : INFO : EPOCH 2: training on 99524 raw words (60447 effective words) took 0.1s, 415655 effective words/s\n",
      "2023-12-06 15:24:57,040 : INFO : EPOCH 3: training on 99524 raw words (60392 effective words) took 0.1s, 464665 effective words/s\n",
      "2023-12-06 15:24:57,175 : INFO : EPOCH 4: training on 99524 raw words (60422 effective words) took 0.1s, 460596 effective words/s\n",
      "2023-12-06 15:24:57,311 : INFO : EPOCH 5: training on 99524 raw words (60301 effective words) took 0.1s, 454645 effective words/s\n",
      "2023-12-06 15:24:57,465 : INFO : EPOCH 6: training on 99524 raw words (60410 effective words) took 0.1s, 405589 effective words/s\n",
      "2023-12-06 15:24:57,648 : INFO : EPOCH 7: training on 99524 raw words (60377 effective words) took 0.2s, 339476 effective words/s\n",
      "2023-12-06 15:24:57,791 : INFO : EPOCH 8: training on 99524 raw words (60453 effective words) took 0.1s, 440352 effective words/s\n",
      "2023-12-06 15:24:57,926 : INFO : EPOCH 9: training on 99524 raw words (60388 effective words) took 0.1s, 461901 effective words/s\n",
      "2023-12-06 15:24:57,927 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603976 effective words) took 1.5s, 414521 effective words/s', 'datetime': '2023-12-06T15:24:57.927975', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:24:57,928 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:24:57.928987', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 93%|| 451/486 [1:11:19<04:36,  7.90s/it]2023-12-06 15:25:00,581 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:25:00,581 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:25:00,603 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:25:00,605 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:25:00,608 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:25:00.608618', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:25:00,608 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:25:00.608618', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:25:00,613 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:25:00,613 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:25:00,614 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:25:00.614621', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:25:00,620 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:25:00,621 : INFO : resetting layer weights\n",
      "2023-12-06 15:25:00,625 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:25:00.625050', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:25:00,751 : INFO : EPOCH 0: training on 99524 raw words (60437 effective words) took 0.1s, 493011 effective words/s\n",
      "2023-12-06 15:25:00,924 : INFO : EPOCH 1: training on 99524 raw words (60312 effective words) took 0.2s, 360257 effective words/s\n",
      "2023-12-06 15:25:01,069 : INFO : EPOCH 2: training on 99524 raw words (60458 effective words) took 0.1s, 439449 effective words/s\n",
      "2023-12-06 15:25:01,197 : INFO : EPOCH 3: training on 99524 raw words (60302 effective words) took 0.1s, 482014 effective words/s\n",
      "2023-12-06 15:25:01,338 : INFO : EPOCH 4: training on 99524 raw words (60492 effective words) took 0.1s, 444761 effective words/s\n",
      "2023-12-06 15:25:01,480 : INFO : EPOCH 5: training on 99524 raw words (60316 effective words) took 0.1s, 437472 effective words/s\n",
      "2023-12-06 15:25:01,618 : INFO : EPOCH 6: training on 99524 raw words (60496 effective words) took 0.1s, 455095 effective words/s\n",
      "2023-12-06 15:25:01,770 : INFO : EPOCH 7: training on 99524 raw words (60316 effective words) took 0.1s, 408288 effective words/s\n",
      "2023-12-06 15:25:01,937 : INFO : EPOCH 8: training on 99524 raw words (60363 effective words) took 0.2s, 369526 effective words/s\n",
      "2023-12-06 15:25:02,077 : INFO : EPOCH 9: training on 99524 raw words (60356 effective words) took 0.1s, 444257 effective words/s\n",
      "2023-12-06 15:25:02,078 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603848 effective words) took 1.5s, 415425 effective words/s', 'datetime': '2023-12-06T15:25:02.078925', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:25:02,079 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:25:02.079936', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 93%|| 452/486 [1:11:23<03:51,  6.81s/it]2023-12-06 15:25:04,848 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:25:04,849 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:25:04,870 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:25:04,870 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:25:04,875 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:25:04.875429', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:25:04,876 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:25:04.876890', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:25:04,881 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:25:04,882 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:25:04,882 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:25:04.882187', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:25:04,889 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:25:04,890 : INFO : resetting layer weights\n",
      "2023-12-06 15:25:04,894 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:25:04.894193', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:25:05,019 : INFO : EPOCH 0: training on 99524 raw words (60307 effective words) took 0.1s, 499375 effective words/s\n",
      "2023-12-06 15:25:05,186 : INFO : EPOCH 1: training on 99524 raw words (60545 effective words) took 0.2s, 371496 effective words/s\n",
      "2023-12-06 15:25:05,360 : INFO : EPOCH 2: training on 99524 raw words (60390 effective words) took 0.2s, 358985 effective words/s\n",
      "2023-12-06 15:25:05,504 : INFO : EPOCH 3: training on 99524 raw words (60391 effective words) took 0.1s, 434301 effective words/s\n",
      "2023-12-06 15:25:05,662 : INFO : EPOCH 4: training on 99524 raw words (60314 effective words) took 0.2s, 396762 effective words/s\n",
      "2023-12-06 15:25:05,800 : INFO : EPOCH 5: training on 99524 raw words (60242 effective words) took 0.1s, 454025 effective words/s\n",
      "2023-12-06 15:25:05,927 : INFO : EPOCH 6: training on 99524 raw words (60302 effective words) took 0.1s, 487244 effective words/s\n",
      "2023-12-06 15:25:06,075 : INFO : EPOCH 7: training on 99524 raw words (60412 effective words) took 0.1s, 423149 effective words/s\n",
      "2023-12-06 15:25:06,212 : INFO : EPOCH 8: training on 99524 raw words (60435 effective words) took 0.1s, 457464 effective words/s\n",
      "2023-12-06 15:25:06,341 : INFO : EPOCH 9: training on 99524 raw words (60421 effective words) took 0.1s, 484674 effective words/s\n",
      "2023-12-06 15:25:06,342 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (603759 effective words) took 1.4s, 417228 effective words/s', 'datetime': '2023-12-06T15:25:06.342071', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:25:06,343 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:25:06.343071', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 93%|| 453/486 [1:11:27<03:20,  6.07s/it]2023-12-06 15:25:09,180 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:25:09,181 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:25:09,202 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:25:09,203 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:25:09,208 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:25:09.208162', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:25:09,208 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:25:09.208162', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:25:09,213 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:25:09,214 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:25:09,214 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:25:09.214172', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:25:09,221 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:25:09,221 : INFO : resetting layer weights\n",
      "2023-12-06 15:25:09,225 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:25:09.225986', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:25:09,355 : INFO : EPOCH 0: training on 99524 raw words (60395 effective words) took 0.1s, 484185 effective words/s\n",
      "2023-12-06 15:25:09,541 : INFO : EPOCH 1: training on 99524 raw words (60383 effective words) took 0.2s, 332514 effective words/s\n",
      "2023-12-06 15:25:09,734 : INFO : EPOCH 2: training on 99524 raw words (60525 effective words) took 0.2s, 325009 effective words/s\n",
      "2023-12-06 15:25:09,881 : INFO : EPOCH 3: training on 99524 raw words (60295 effective words) took 0.1s, 429240 effective words/s\n",
      "2023-12-06 15:25:10,009 : INFO : EPOCH 4: training on 99524 raw words (60462 effective words) took 0.1s, 487576 effective words/s\n",
      "2023-12-06 15:25:10,137 : INFO : EPOCH 5: training on 99524 raw words (60261 effective words) took 0.1s, 486564 effective words/s\n",
      "2023-12-06 15:25:10,281 : INFO : EPOCH 6: training on 99524 raw words (60292 effective words) took 0.1s, 431761 effective words/s\n",
      "2023-12-06 15:25:10,421 : INFO : EPOCH 7: training on 99524 raw words (60392 effective words) took 0.1s, 448019 effective words/s\n",
      "2023-12-06 15:25:10,557 : INFO : EPOCH 8: training on 99524 raw words (60295 effective words) took 0.1s, 456733 effective words/s\n",
      "2023-12-06 15:25:10,705 : INFO : EPOCH 9: training on 99524 raw words (60493 effective words) took 0.1s, 421581 effective words/s\n",
      "2023-12-06 15:25:10,856 : INFO : EPOCH 10: training on 99524 raw words (60455 effective words) took 0.1s, 412618 effective words/s\n",
      "2023-12-06 15:25:11,011 : INFO : EPOCH 11: training on 99524 raw words (60450 effective words) took 0.1s, 405273 effective words/s\n",
      "2023-12-06 15:25:11,192 : INFO : EPOCH 12: training on 99524 raw words (60410 effective words) took 0.2s, 341680 effective words/s\n",
      "2023-12-06 15:25:11,331 : INFO : EPOCH 13: training on 99524 raw words (60435 effective words) took 0.1s, 447882 effective words/s\n",
      "2023-12-06 15:25:11,468 : INFO : EPOCH 14: training on 99524 raw words (60493 effective words) took 0.1s, 456534 effective words/s\n",
      "2023-12-06 15:25:11,604 : INFO : EPOCH 15: training on 99524 raw words (60356 effective words) took 0.1s, 460508 effective words/s\n",
      "2023-12-06 15:25:11,744 : INFO : EPOCH 16: training on 99524 raw words (60527 effective words) took 0.1s, 442707 effective words/s\n",
      "2023-12-06 15:25:11,899 : INFO : EPOCH 17: training on 99524 raw words (60384 effective words) took 0.1s, 406572 effective words/s\n",
      "2023-12-06 15:25:12,051 : INFO : EPOCH 18: training on 99524 raw words (60238 effective words) took 0.1s, 410633 effective words/s\n",
      "2023-12-06 15:25:12,203 : INFO : EPOCH 19: training on 99524 raw words (60577 effective words) took 0.1s, 408880 effective words/s\n",
      "2023-12-06 15:25:12,347 : INFO : EPOCH 20: training on 99524 raw words (60414 effective words) took 0.1s, 436005 effective words/s\n",
      "2023-12-06 15:25:12,497 : INFO : EPOCH 21: training on 99524 raw words (60533 effective words) took 0.1s, 414811 effective words/s\n",
      "2023-12-06 15:25:12,666 : INFO : EPOCH 22: training on 99524 raw words (60429 effective words) took 0.2s, 369418 effective words/s\n",
      "2023-12-06 15:25:12,868 : INFO : EPOCH 23: training on 99524 raw words (60432 effective words) took 0.2s, 306101 effective words/s\n",
      "2023-12-06 15:25:13,034 : INFO : EPOCH 24: training on 99524 raw words (60478 effective words) took 0.2s, 380958 effective words/s\n",
      "2023-12-06 15:25:13,184 : INFO : EPOCH 25: training on 99524 raw words (60376 effective words) took 0.1s, 416045 effective words/s\n",
      "2023-12-06 15:25:13,324 : INFO : EPOCH 26: training on 99524 raw words (60397 effective words) took 0.1s, 446551 effective words/s\n",
      "2023-12-06 15:25:13,468 : INFO : EPOCH 27: training on 99524 raw words (60519 effective words) took 0.1s, 431783 effective words/s\n",
      "2023-12-06 15:25:13,621 : INFO : EPOCH 28: training on 99524 raw words (60463 effective words) took 0.1s, 409759 effective words/s\n",
      "2023-12-06 15:25:13,795 : INFO : EPOCH 29: training on 99524 raw words (60329 effective words) took 0.2s, 358007 effective words/s\n",
      "2023-12-06 15:25:13,796 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812488 effective words) took 4.6s, 396621 effective words/s', 'datetime': '2023-12-06T15:25:13.796258', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:25:13,797 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:25:13.797258', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 93%|| 454/486 [1:11:35<03:28,  6.52s/it]2023-12-06 15:25:16,754 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:25:16,754 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:25:16,774 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:25:16,775 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:25:16,779 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:25:16.779926', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:25:16,780 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:25:16.780932', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:25:16,784 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:25:16,786 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:25:16,786 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:25:16.786827', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:25:16,793 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:25:16,793 : INFO : resetting layer weights\n",
      "2023-12-06 15:25:16,796 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:25:16.796842', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:25:16,921 : INFO : EPOCH 0: training on 99524 raw words (60470 effective words) took 0.1s, 503692 effective words/s\n",
      "2023-12-06 15:25:17,122 : INFO : EPOCH 1: training on 99524 raw words (60537 effective words) took 0.2s, 305727 effective words/s\n",
      "2023-12-06 15:25:17,292 : INFO : EPOCH 2: training on 99524 raw words (60525 effective words) took 0.2s, 375953 effective words/s\n",
      "2023-12-06 15:25:17,433 : INFO : EPOCH 3: training on 99524 raw words (60192 effective words) took 0.1s, 440200 effective words/s\n",
      "2023-12-06 15:25:17,571 : INFO : EPOCH 4: training on 99524 raw words (60331 effective words) took 0.1s, 452545 effective words/s\n",
      "2023-12-06 15:25:17,711 : INFO : EPOCH 5: training on 99524 raw words (60404 effective words) took 0.1s, 446447 effective words/s\n",
      "2023-12-06 15:25:17,855 : INFO : EPOCH 6: training on 99524 raw words (60232 effective words) took 0.1s, 432525 effective words/s\n",
      "2023-12-06 15:25:17,992 : INFO : EPOCH 7: training on 99524 raw words (60552 effective words) took 0.1s, 454922 effective words/s\n",
      "2023-12-06 15:25:18,154 : INFO : EPOCH 8: training on 99524 raw words (60310 effective words) took 0.2s, 383831 effective words/s\n",
      "2023-12-06 15:25:18,303 : INFO : EPOCH 9: training on 99524 raw words (60388 effective words) took 0.1s, 415919 effective words/s\n",
      "2023-12-06 15:25:18,449 : INFO : EPOCH 10: training on 99524 raw words (60257 effective words) took 0.1s, 429710 effective words/s\n",
      "2023-12-06 15:25:18,587 : INFO : EPOCH 11: training on 99524 raw words (60473 effective words) took 0.1s, 453931 effective words/s\n",
      "2023-12-06 15:25:18,763 : INFO : EPOCH 12: training on 99524 raw words (60476 effective words) took 0.2s, 351243 effective words/s\n",
      "2023-12-06 15:25:18,909 : INFO : EPOCH 13: training on 99524 raw words (60417 effective words) took 0.1s, 426408 effective words/s\n",
      "2023-12-06 15:25:19,056 : INFO : EPOCH 14: training on 99524 raw words (60502 effective words) took 0.1s, 426932 effective words/s\n",
      "2023-12-06 15:25:19,185 : INFO : EPOCH 15: training on 99524 raw words (60291 effective words) took 0.1s, 479412 effective words/s\n",
      "2023-12-06 15:25:19,326 : INFO : EPOCH 16: training on 99524 raw words (60480 effective words) took 0.1s, 447768 effective words/s\n",
      "2023-12-06 15:25:19,475 : INFO : EPOCH 17: training on 99524 raw words (60195 effective words) took 0.1s, 413930 effective words/s\n",
      "2023-12-06 15:25:19,683 : INFO : EPOCH 18: training on 99524 raw words (60365 effective words) took 0.2s, 298513 effective words/s\n",
      "2023-12-06 15:25:19,823 : INFO : EPOCH 19: training on 99524 raw words (60429 effective words) took 0.1s, 447803 effective words/s\n",
      "2023-12-06 15:25:19,968 : INFO : EPOCH 20: training on 99524 raw words (60316 effective words) took 0.1s, 431162 effective words/s\n",
      "2023-12-06 15:25:20,111 : INFO : EPOCH 21: training on 99524 raw words (60286 effective words) took 0.1s, 434838 effective words/s\n",
      "2023-12-06 15:25:20,248 : INFO : EPOCH 22: training on 99524 raw words (60329 effective words) took 0.1s, 452878 effective words/s\n",
      "2023-12-06 15:25:20,396 : INFO : EPOCH 23: training on 99524 raw words (60423 effective words) took 0.1s, 421983 effective words/s\n",
      "2023-12-06 15:25:20,566 : INFO : EPOCH 24: training on 99524 raw words (60521 effective words) took 0.2s, 365099 effective words/s\n",
      "2023-12-06 15:25:20,709 : INFO : EPOCH 25: training on 99524 raw words (60370 effective words) took 0.1s, 437500 effective words/s\n",
      "2023-12-06 15:25:20,849 : INFO : EPOCH 26: training on 99524 raw words (60522 effective words) took 0.1s, 445541 effective words/s\n",
      "2023-12-06 15:25:21,001 : INFO : EPOCH 27: training on 99524 raw words (60381 effective words) took 0.1s, 411529 effective words/s\n",
      "2023-12-06 15:25:21,139 : INFO : EPOCH 28: training on 99524 raw words (60303 effective words) took 0.1s, 451747 effective words/s\n",
      "2023-12-06 15:25:21,276 : INFO : EPOCH 29: training on 99524 raw words (60306 effective words) took 0.1s, 454072 effective words/s\n",
      "2023-12-06 15:25:21,277 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811583 effective words) took 4.5s, 404447 effective words/s', 'datetime': '2023-12-06T15:25:21.276507', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:25:21,277 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:25:21.277513', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 94%|| 455/486 [1:11:43<03:34,  6.92s/it]2023-12-06 15:25:24,610 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:25:24,611 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:25:24,634 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:25:24,635 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:25:24,642 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:25:24.642448', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:25:24,642 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:25:24.642448', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:25:24,651 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:25:24,652 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:25:24,653 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:25:24.653623', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:25:24,659 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:25:24,660 : INFO : resetting layer weights\n",
      "2023-12-06 15:25:24,665 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:25:24.665618', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:25:24,791 : INFO : EPOCH 0: training on 99524 raw words (60339 effective words) took 0.1s, 492554 effective words/s\n",
      "2023-12-06 15:25:25,016 : INFO : EPOCH 1: training on 99524 raw words (60476 effective words) took 0.2s, 275280 effective words/s\n",
      "2023-12-06 15:25:25,210 : INFO : EPOCH 2: training on 99524 raw words (60429 effective words) took 0.2s, 322018 effective words/s\n",
      "2023-12-06 15:25:25,342 : INFO : EPOCH 3: training on 99524 raw words (60150 effective words) took 0.1s, 474722 effective words/s\n",
      "2023-12-06 15:25:25,475 : INFO : EPOCH 4: training on 99524 raw words (60303 effective words) took 0.1s, 473277 effective words/s\n",
      "2023-12-06 15:25:25,620 : INFO : EPOCH 5: training on 99524 raw words (60422 effective words) took 0.1s, 431238 effective words/s\n",
      "2023-12-06 15:25:25,761 : INFO : EPOCH 6: training on 99524 raw words (60333 effective words) took 0.1s, 439882 effective words/s\n",
      "2023-12-06 15:25:25,902 : INFO : EPOCH 7: training on 99524 raw words (60517 effective words) took 0.1s, 443673 effective words/s\n",
      "2023-12-06 15:25:26,064 : INFO : EPOCH 8: training on 99524 raw words (60463 effective words) took 0.2s, 385008 effective words/s\n",
      "2023-12-06 15:25:26,202 : INFO : EPOCH 9: training on 99524 raw words (60449 effective words) took 0.1s, 452720 effective words/s\n",
      "2023-12-06 15:25:26,362 : INFO : EPOCH 10: training on 99524 raw words (60256 effective words) took 0.2s, 384192 effective words/s\n",
      "2023-12-06 15:25:26,542 : INFO : EPOCH 11: training on 99524 raw words (60426 effective words) took 0.2s, 352144 effective words/s\n",
      "2023-12-06 15:25:26,725 : INFO : EPOCH 12: training on 99524 raw words (60343 effective words) took 0.2s, 337937 effective words/s\n",
      "2023-12-06 15:25:26,884 : INFO : EPOCH 13: training on 99524 raw words (60391 effective words) took 0.2s, 390435 effective words/s\n",
      "2023-12-06 15:25:27,034 : INFO : EPOCH 14: training on 99524 raw words (60503 effective words) took 0.1s, 417087 effective words/s\n",
      "2023-12-06 15:25:27,176 : INFO : EPOCH 15: training on 99524 raw words (60502 effective words) took 0.1s, 437011 effective words/s\n",
      "2023-12-06 15:25:27,326 : INFO : EPOCH 16: training on 99524 raw words (60546 effective words) took 0.1s, 420453 effective words/s\n",
      "2023-12-06 15:25:27,494 : INFO : EPOCH 17: training on 99524 raw words (60386 effective words) took 0.2s, 368756 effective words/s\n",
      "2023-12-06 15:25:27,634 : INFO : EPOCH 18: training on 99524 raw words (60228 effective words) took 0.1s, 441924 effective words/s\n",
      "2023-12-06 15:25:27,773 : INFO : EPOCH 19: training on 99524 raw words (60530 effective words) took 0.1s, 452467 effective words/s\n",
      "2023-12-06 15:25:27,912 : INFO : EPOCH 20: training on 99524 raw words (60328 effective words) took 0.1s, 445859 effective words/s\n",
      "2023-12-06 15:25:28,054 : INFO : EPOCH 21: training on 99524 raw words (60415 effective words) took 0.1s, 437743 effective words/s\n",
      "2023-12-06 15:25:28,194 : INFO : EPOCH 22: training on 99524 raw words (60270 effective words) took 0.1s, 442521 effective words/s\n",
      "2023-12-06 15:25:28,369 : INFO : EPOCH 23: training on 99524 raw words (60474 effective words) took 0.2s, 357601 effective words/s\n",
      "2023-12-06 15:25:28,514 : INFO : EPOCH 24: training on 99524 raw words (60500 effective words) took 0.1s, 430299 effective words/s\n",
      "2023-12-06 15:25:28,666 : INFO : EPOCH 25: training on 99524 raw words (60521 effective words) took 0.1s, 409279 effective words/s\n",
      "2023-12-06 15:25:28,809 : INFO : EPOCH 26: training on 99524 raw words (60590 effective words) took 0.1s, 434477 effective words/s\n",
      "2023-12-06 15:25:28,973 : INFO : EPOCH 27: training on 99524 raw words (60448 effective words) took 0.2s, 380476 effective words/s\n",
      "2023-12-06 15:25:29,117 : INFO : EPOCH 28: training on 99524 raw words (60329 effective words) took 0.1s, 432196 effective words/s\n",
      "2023-12-06 15:25:29,263 : INFO : EPOCH 29: training on 99524 raw words (60522 effective words) took 0.1s, 427784 effective words/s\n",
      "2023-12-06 15:25:29,264 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812389 effective words) took 4.6s, 394147 effective words/s', 'datetime': '2023-12-06T15:25:29.264168', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:25:29,265 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:25:29.265167', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 94%|| 456/486 [1:11:51<03:39,  7.31s/it]2023-12-06 15:25:32,841 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:25:32,841 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:25:32,868 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:25:32,869 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:25:32,873 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:25:32.873688', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:25:32,873 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:25:32.873688', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:25:32,879 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:25:32,879 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:25:32,880 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:25:32.880730', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:25:32,888 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:25:32,888 : INFO : resetting layer weights\n",
      "2023-12-06 15:25:32,893 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:25:32.893274', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:25:33,023 : INFO : EPOCH 0: training on 99524 raw words (60509 effective words) took 0.1s, 478536 effective words/s\n",
      "2023-12-06 15:25:33,194 : INFO : EPOCH 1: training on 99524 raw words (60400 effective words) took 0.2s, 370629 effective words/s\n",
      "2023-12-06 15:25:33,376 : INFO : EPOCH 2: training on 99524 raw words (60605 effective words) took 0.2s, 347144 effective words/s\n",
      "2023-12-06 15:25:33,519 : INFO : EPOCH 3: training on 99524 raw words (60246 effective words) took 0.1s, 438002 effective words/s\n",
      "2023-12-06 15:25:33,656 : INFO : EPOCH 4: training on 99524 raw words (60365 effective words) took 0.1s, 457367 effective words/s\n",
      "2023-12-06 15:25:33,792 : INFO : EPOCH 5: training on 99524 raw words (60270 effective words) took 0.1s, 456126 effective words/s\n",
      "2023-12-06 15:25:33,929 : INFO : EPOCH 6: training on 99524 raw words (60494 effective words) took 0.1s, 456804 effective words/s\n",
      "2023-12-06 15:25:34,091 : INFO : EPOCH 7: training on 99524 raw words (60430 effective words) took 0.2s, 382706 effective words/s\n",
      "2023-12-06 15:25:34,229 : INFO : EPOCH 8: training on 99524 raw words (60376 effective words) took 0.1s, 453120 effective words/s\n",
      "2023-12-06 15:25:34,372 : INFO : EPOCH 9: training on 99524 raw words (60360 effective words) took 0.1s, 437273 effective words/s\n",
      "2023-12-06 15:25:34,515 : INFO : EPOCH 10: training on 99524 raw words (60373 effective words) took 0.1s, 436175 effective words/s\n",
      "2023-12-06 15:25:34,697 : INFO : EPOCH 11: training on 99524 raw words (60484 effective words) took 0.2s, 337545 effective words/s\n",
      "2023-12-06 15:25:34,838 : INFO : EPOCH 12: training on 99524 raw words (60325 effective words) took 0.1s, 445902 effective words/s\n",
      "2023-12-06 15:25:34,988 : INFO : EPOCH 13: training on 99524 raw words (60398 effective words) took 0.1s, 410888 effective words/s\n",
      "2023-12-06 15:25:35,127 : INFO : EPOCH 14: training on 99524 raw words (60430 effective words) took 0.1s, 451288 effective words/s\n",
      "2023-12-06 15:25:35,260 : INFO : EPOCH 15: training on 99524 raw words (60398 effective words) took 0.1s, 466864 effective words/s\n",
      "2023-12-06 15:25:35,419 : INFO : EPOCH 16: training on 99524 raw words (60562 effective words) took 0.2s, 391260 effective words/s\n",
      "2023-12-06 15:25:35,563 : INFO : EPOCH 17: training on 99524 raw words (60207 effective words) took 0.1s, 436580 effective words/s\n",
      "2023-12-06 15:25:35,726 : INFO : EPOCH 18: training on 99524 raw words (60288 effective words) took 0.2s, 377066 effective words/s\n",
      "2023-12-06 15:25:35,864 : INFO : EPOCH 19: training on 99524 raw words (60449 effective words) took 0.1s, 455008 effective words/s\n",
      "2023-12-06 15:25:36,003 : INFO : EPOCH 20: training on 99524 raw words (60369 effective words) took 0.1s, 445139 effective words/s\n",
      "2023-12-06 15:25:36,142 : INFO : EPOCH 21: training on 99524 raw words (60510 effective words) took 0.1s, 450879 effective words/s\n",
      "2023-12-06 15:25:36,290 : INFO : EPOCH 22: training on 99524 raw words (60517 effective words) took 0.1s, 424303 effective words/s\n",
      "2023-12-06 15:25:36,439 : INFO : EPOCH 23: training on 99524 raw words (60452 effective words) took 0.1s, 430795 effective words/s\n",
      "2023-12-06 15:25:36,582 : INFO : EPOCH 24: training on 99524 raw words (60617 effective words) took 0.1s, 440228 effective words/s\n",
      "2023-12-06 15:25:36,729 : INFO : EPOCH 25: training on 99524 raw words (60167 effective words) took 0.1s, 423165 effective words/s\n",
      "2023-12-06 15:25:36,868 : INFO : EPOCH 26: training on 99524 raw words (60557 effective words) took 0.1s, 447013 effective words/s\n",
      "2023-12-06 15:25:37,036 : INFO : EPOCH 27: training on 99524 raw words (60569 effective words) took 0.2s, 386460 effective words/s\n",
      "2023-12-06 15:25:37,179 : INFO : EPOCH 28: training on 99524 raw words (60525 effective words) took 0.1s, 435452 effective words/s\n",
      "2023-12-06 15:25:37,310 : INFO : EPOCH 29: training on 99524 raw words (60394 effective words) took 0.1s, 474702 effective words/s\n",
      "2023-12-06 15:25:37,449 : INFO : EPOCH 30: training on 99524 raw words (60177 effective words) took 0.1s, 450142 effective words/s\n",
      "2023-12-06 15:25:37,588 : INFO : EPOCH 31: training on 99524 raw words (60457 effective words) took 0.1s, 448642 effective words/s\n",
      "2023-12-06 15:25:37,735 : INFO : EPOCH 32: training on 99524 raw words (60354 effective words) took 0.1s, 427011 effective words/s\n",
      "2023-12-06 15:25:37,871 : INFO : EPOCH 33: training on 99524 raw words (60459 effective words) took 0.1s, 460693 effective words/s\n",
      "2023-12-06 15:25:38,012 : INFO : EPOCH 34: training on 99524 raw words (60516 effective words) took 0.1s, 444144 effective words/s\n",
      "2023-12-06 15:25:38,152 : INFO : EPOCH 35: training on 99524 raw words (60349 effective words) took 0.1s, 443401 effective words/s\n",
      "2023-12-06 15:25:38,287 : INFO : EPOCH 36: training on 99524 raw words (60460 effective words) took 0.1s, 463970 effective words/s\n",
      "2023-12-06 15:25:38,426 : INFO : EPOCH 37: training on 99524 raw words (60436 effective words) took 0.1s, 448655 effective words/s\n",
      "2023-12-06 15:25:38,584 : INFO : EPOCH 38: training on 99524 raw words (60520 effective words) took 0.2s, 391950 effective words/s\n",
      "2023-12-06 15:25:38,727 : INFO : EPOCH 39: training on 99524 raw words (60382 effective words) took 0.1s, 436338 effective words/s\n",
      "2023-12-06 15:25:38,876 : INFO : EPOCH 40: training on 99524 raw words (60286 effective words) took 0.1s, 418435 effective words/s\n",
      "2023-12-06 15:25:39,015 : INFO : EPOCH 41: training on 99524 raw words (60508 effective words) took 0.1s, 447443 effective words/s\n",
      "2023-12-06 15:25:39,171 : INFO : EPOCH 42: training on 99524 raw words (60521 effective words) took 0.2s, 399255 effective words/s\n",
      "2023-12-06 15:25:39,311 : INFO : EPOCH 43: training on 99524 raw words (60386 effective words) took 0.1s, 449455 effective words/s\n",
      "2023-12-06 15:25:39,451 : INFO : EPOCH 44: training on 99524 raw words (60277 effective words) took 0.1s, 440171 effective words/s\n",
      "2023-12-06 15:25:39,595 : INFO : EPOCH 45: training on 99524 raw words (60420 effective words) took 0.1s, 433770 effective words/s\n",
      "2023-12-06 15:25:39,741 : INFO : EPOCH 46: training on 99524 raw words (60464 effective words) took 0.1s, 426396 effective words/s\n",
      "2023-12-06 15:25:39,881 : INFO : EPOCH 47: training on 99524 raw words (60411 effective words) took 0.1s, 444716 effective words/s\n",
      "2023-12-06 15:25:40,035 : INFO : EPOCH 48: training on 99524 raw words (60519 effective words) took 0.1s, 403969 effective words/s\n",
      "2023-12-06 15:25:40,166 : INFO : EPOCH 49: training on 99524 raw words (60400 effective words) took 0.1s, 474525 effective words/s\n",
      "2023-12-06 15:25:40,167 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3020948 effective words) took 7.3s, 415292 effective words/s', 'datetime': '2023-12-06T15:25:40.167668', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:25:40,168 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:25:40.168709', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 94%|| 457/486 [1:12:02<04:02,  8.35s/it]2023-12-06 15:25:43,598 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:25:43,598 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:25:43,619 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:25:43,620 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:25:43,624 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:25:43.624875', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:25:43,624 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:25:43.624875', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:25:43,629 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:25:43,629 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:25:43,630 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:25:43.630995', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:25:43,636 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:25:43,637 : INFO : resetting layer weights\n",
      "2023-12-06 15:25:43,641 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:25:43.641497', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:25:43,771 : INFO : EPOCH 0: training on 99524 raw words (60441 effective words) took 0.1s, 482590 effective words/s\n",
      "2023-12-06 15:25:43,950 : INFO : EPOCH 1: training on 99524 raw words (60471 effective words) took 0.2s, 347935 effective words/s\n",
      "2023-12-06 15:25:44,107 : INFO : EPOCH 2: training on 99524 raw words (60416 effective words) took 0.2s, 402532 effective words/s\n",
      "2023-12-06 15:25:44,249 : INFO : EPOCH 3: training on 99524 raw words (60120 effective words) took 0.1s, 436684 effective words/s\n",
      "2023-12-06 15:25:44,379 : INFO : EPOCH 4: training on 99524 raw words (60401 effective words) took 0.1s, 483498 effective words/s\n",
      "2023-12-06 15:25:44,521 : INFO : EPOCH 5: training on 99524 raw words (60368 effective words) took 0.1s, 440713 effective words/s\n",
      "2023-12-06 15:25:44,658 : INFO : EPOCH 6: training on 99524 raw words (60415 effective words) took 0.1s, 450986 effective words/s\n",
      "2023-12-06 15:25:44,817 : INFO : EPOCH 7: training on 99524 raw words (60457 effective words) took 0.2s, 392840 effective words/s\n",
      "2023-12-06 15:25:44,956 : INFO : EPOCH 8: training on 99524 raw words (60292 effective words) took 0.1s, 447070 effective words/s\n",
      "2023-12-06 15:25:45,095 : INFO : EPOCH 9: training on 99524 raw words (60452 effective words) took 0.1s, 448248 effective words/s\n",
      "2023-12-06 15:25:45,238 : INFO : EPOCH 10: training on 99524 raw words (60329 effective words) took 0.1s, 430819 effective words/s\n",
      "2023-12-06 15:25:45,400 : INFO : EPOCH 11: training on 99524 raw words (60359 effective words) took 0.2s, 385106 effective words/s\n",
      "2023-12-06 15:25:45,538 : INFO : EPOCH 12: training on 99524 raw words (60507 effective words) took 0.1s, 454873 effective words/s\n",
      "2023-12-06 15:25:45,676 : INFO : EPOCH 13: training on 99524 raw words (60458 effective words) took 0.1s, 452341 effective words/s\n",
      "2023-12-06 15:25:45,814 : INFO : EPOCH 14: training on 99524 raw words (60568 effective words) took 0.1s, 456771 effective words/s\n",
      "2023-12-06 15:25:45,975 : INFO : EPOCH 15: training on 99524 raw words (60273 effective words) took 0.2s, 383984 effective words/s\n",
      "2023-12-06 15:25:46,113 : INFO : EPOCH 16: training on 99524 raw words (60448 effective words) took 0.1s, 451553 effective words/s\n",
      "2023-12-06 15:25:46,248 : INFO : EPOCH 17: training on 99524 raw words (60319 effective words) took 0.1s, 463290 effective words/s\n",
      "2023-12-06 15:25:46,389 : INFO : EPOCH 18: training on 99524 raw words (60434 effective words) took 0.1s, 444789 effective words/s\n",
      "2023-12-06 15:25:46,540 : INFO : EPOCH 19: training on 99524 raw words (60563 effective words) took 0.1s, 409756 effective words/s\n",
      "2023-12-06 15:25:46,685 : INFO : EPOCH 20: training on 99524 raw words (60444 effective words) took 0.1s, 434815 effective words/s\n",
      "2023-12-06 15:25:46,823 : INFO : EPOCH 21: training on 99524 raw words (60519 effective words) took 0.1s, 450854 effective words/s\n",
      "2023-12-06 15:25:46,959 : INFO : EPOCH 22: training on 99524 raw words (60557 effective words) took 0.1s, 460636 effective words/s\n",
      "2023-12-06 15:25:47,095 : INFO : EPOCH 23: training on 99524 raw words (60577 effective words) took 0.1s, 457728 effective words/s\n",
      "2023-12-06 15:25:47,233 : INFO : EPOCH 24: training on 99524 raw words (60485 effective words) took 0.1s, 455577 effective words/s\n",
      "2023-12-06 15:25:47,396 : INFO : EPOCH 25: training on 99524 raw words (60290 effective words) took 0.2s, 379511 effective words/s\n",
      "2023-12-06 15:25:47,535 : INFO : EPOCH 26: training on 99524 raw words (60424 effective words) took 0.1s, 451096 effective words/s\n",
      "2023-12-06 15:25:47,674 : INFO : EPOCH 27: training on 99524 raw words (60432 effective words) took 0.1s, 448550 effective words/s\n",
      "2023-12-06 15:25:47,813 : INFO : EPOCH 28: training on 99524 raw words (60347 effective words) took 0.1s, 447843 effective words/s\n",
      "2023-12-06 15:25:47,970 : INFO : EPOCH 29: training on 99524 raw words (60407 effective words) took 0.2s, 395235 effective words/s\n",
      "2023-12-06 15:25:48,111 : INFO : EPOCH 30: training on 99524 raw words (60247 effective words) took 0.1s, 440032 effective words/s\n",
      "2023-12-06 15:25:48,265 : INFO : EPOCH 31: training on 99524 raw words (60259 effective words) took 0.2s, 400578 effective words/s\n",
      "2023-12-06 15:25:48,414 : INFO : EPOCH 32: training on 99524 raw words (60412 effective words) took 0.1s, 419911 effective words/s\n",
      "2023-12-06 15:25:48,560 : INFO : EPOCH 33: training on 99524 raw words (60337 effective words) took 0.1s, 426473 effective words/s\n",
      "2023-12-06 15:25:48,697 : INFO : EPOCH 34: training on 99524 raw words (60333 effective words) took 0.1s, 451618 effective words/s\n",
      "2023-12-06 15:25:48,856 : INFO : EPOCH 35: training on 99524 raw words (60495 effective words) took 0.2s, 391677 effective words/s\n",
      "2023-12-06 15:25:48,994 : INFO : EPOCH 36: training on 99524 raw words (60407 effective words) took 0.1s, 453288 effective words/s\n",
      "2023-12-06 15:25:49,130 : INFO : EPOCH 37: training on 99524 raw words (60509 effective words) took 0.1s, 459872 effective words/s\n",
      "2023-12-06 15:25:49,276 : INFO : EPOCH 38: training on 99524 raw words (60339 effective words) took 0.1s, 423171 effective words/s\n",
      "2023-12-06 15:25:49,426 : INFO : EPOCH 39: training on 99524 raw words (60444 effective words) took 0.1s, 416182 effective words/s\n",
      "2023-12-06 15:25:49,598 : INFO : EPOCH 40: training on 99524 raw words (60408 effective words) took 0.2s, 359796 effective words/s\n",
      "2023-12-06 15:25:49,755 : INFO : EPOCH 41: training on 99524 raw words (60571 effective words) took 0.2s, 400025 effective words/s\n",
      "2023-12-06 15:25:49,906 : INFO : EPOCH 42: training on 99524 raw words (60413 effective words) took 0.1s, 413083 effective words/s\n",
      "2023-12-06 15:25:50,044 : INFO : EPOCH 43: training on 99524 raw words (60482 effective words) took 0.1s, 452846 effective words/s\n",
      "2023-12-06 15:25:50,187 : INFO : EPOCH 44: training on 99524 raw words (60417 effective words) took 0.1s, 436396 effective words/s\n",
      "2023-12-06 15:25:50,324 : INFO : EPOCH 45: training on 99524 raw words (60293 effective words) took 0.1s, 450933 effective words/s\n",
      "2023-12-06 15:25:50,484 : INFO : EPOCH 46: training on 99524 raw words (60404 effective words) took 0.2s, 388075 effective words/s\n",
      "2023-12-06 15:25:50,626 : INFO : EPOCH 47: training on 99524 raw words (60378 effective words) took 0.1s, 440922 effective words/s\n",
      "2023-12-06 15:25:50,763 : INFO : EPOCH 48: training on 99524 raw words (60396 effective words) took 0.1s, 454337 effective words/s\n",
      "2023-12-06 15:25:50,901 : INFO : EPOCH 49: training on 99524 raw words (60334 effective words) took 0.1s, 454281 effective words/s\n",
      "2023-12-06 15:25:50,902 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3020451 effective words) took 7.3s, 416061 effective words/s', 'datetime': '2023-12-06T15:25:50.902324', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:25:50,902 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:25:50.902324', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 94%|| 458/486 [1:12:13<04:15,  9.13s/it]2023-12-06 15:25:54,542 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:25:54,542 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:25:54,564 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:25:54,565 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:25:54,570 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:25:54.570170', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:25:54,570 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:25:54.570170', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:25:54,574 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:25:54,575 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:25:54,575 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:25:54.575686', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:25:54,582 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:25:54,582 : INFO : resetting layer weights\n",
      "2023-12-06 15:25:54,587 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=7 shrink_windows=True', 'datetime': '2023-12-06T15:25:54.587902', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:25:54,713 : INFO : EPOCH 0: training on 99524 raw words (60329 effective words) took 0.1s, 491584 effective words/s\n",
      "2023-12-06 15:25:54,875 : INFO : EPOCH 1: training on 99524 raw words (60372 effective words) took 0.2s, 383143 effective words/s\n",
      "2023-12-06 15:25:55,026 : INFO : EPOCH 2: training on 99524 raw words (60416 effective words) took 0.1s, 417580 effective words/s\n",
      "2023-12-06 15:25:55,165 : INFO : EPOCH 3: training on 99524 raw words (60100 effective words) took 0.1s, 442883 effective words/s\n",
      "2023-12-06 15:25:55,302 : INFO : EPOCH 4: training on 99524 raw words (60326 effective words) took 0.1s, 455119 effective words/s\n",
      "2023-12-06 15:25:55,441 : INFO : EPOCH 5: training on 99524 raw words (60451 effective words) took 0.1s, 449061 effective words/s\n",
      "2023-12-06 15:25:55,582 : INFO : EPOCH 6: training on 99524 raw words (60327 effective words) took 0.1s, 440817 effective words/s\n",
      "2023-12-06 15:25:55,748 : INFO : EPOCH 7: training on 99524 raw words (60459 effective words) took 0.2s, 373018 effective words/s\n",
      "2023-12-06 15:25:55,884 : INFO : EPOCH 8: training on 99524 raw words (60512 effective words) took 0.1s, 457769 effective words/s\n",
      "2023-12-06 15:25:56,021 : INFO : EPOCH 9: training on 99524 raw words (60281 effective words) took 0.1s, 456623 effective words/s\n",
      "2023-12-06 15:25:56,159 : INFO : EPOCH 10: training on 99524 raw words (60423 effective words) took 0.1s, 448198 effective words/s\n",
      "2023-12-06 15:25:56,314 : INFO : EPOCH 11: training on 99524 raw words (60406 effective words) took 0.2s, 400568 effective words/s\n",
      "2023-12-06 15:25:56,455 : INFO : EPOCH 12: training on 99524 raw words (60337 effective words) took 0.1s, 448430 effective words/s\n",
      "2023-12-06 15:25:56,591 : INFO : EPOCH 13: training on 99524 raw words (60462 effective words) took 0.1s, 456624 effective words/s\n",
      "2023-12-06 15:25:56,729 : INFO : EPOCH 14: training on 99524 raw words (60525 effective words) took 0.1s, 454275 effective words/s\n",
      "2023-12-06 15:25:56,888 : INFO : EPOCH 15: training on 99524 raw words (60447 effective words) took 0.2s, 390909 effective words/s\n",
      "2023-12-06 15:25:57,032 : INFO : EPOCH 16: training on 99524 raw words (60279 effective words) took 0.1s, 433103 effective words/s\n",
      "2023-12-06 15:25:57,168 : INFO : EPOCH 17: training on 99524 raw words (60226 effective words) took 0.1s, 453167 effective words/s\n",
      "2023-12-06 15:25:57,309 : INFO : EPOCH 18: training on 99524 raw words (60365 effective words) took 0.1s, 442471 effective words/s\n",
      "2023-12-06 15:25:57,476 : INFO : EPOCH 19: training on 99524 raw words (60526 effective words) took 0.2s, 374061 effective words/s\n",
      "2023-12-06 15:25:57,629 : INFO : EPOCH 20: training on 99524 raw words (60330 effective words) took 0.1s, 407287 effective words/s\n",
      "2023-12-06 15:25:57,775 : INFO : EPOCH 21: training on 99524 raw words (60303 effective words) took 0.1s, 430502 effective words/s\n",
      "2023-12-06 15:25:57,914 : INFO : EPOCH 22: training on 99524 raw words (60577 effective words) took 0.1s, 451020 effective words/s\n",
      "2023-12-06 15:25:58,058 : INFO : EPOCH 23: training on 99524 raw words (60557 effective words) took 0.1s, 433341 effective words/s\n",
      "2023-12-06 15:25:58,197 : INFO : EPOCH 24: training on 99524 raw words (60418 effective words) took 0.1s, 448381 effective words/s\n",
      "2023-12-06 15:25:58,356 : INFO : EPOCH 25: training on 99524 raw words (60517 effective words) took 0.2s, 390774 effective words/s\n",
      "2023-12-06 15:25:58,496 : INFO : EPOCH 26: training on 99524 raw words (60500 effective words) took 0.1s, 446218 effective words/s\n",
      "2023-12-06 15:25:58,634 : INFO : EPOCH 27: training on 99524 raw words (60563 effective words) took 0.1s, 454311 effective words/s\n",
      "2023-12-06 15:25:58,779 : INFO : EPOCH 28: training on 99524 raw words (60341 effective words) took 0.1s, 429497 effective words/s\n",
      "2023-12-06 15:25:58,945 : INFO : EPOCH 29: training on 99524 raw words (60519 effective words) took 0.2s, 372420 effective words/s\n",
      "2023-12-06 15:25:59,082 : INFO : EPOCH 30: training on 99524 raw words (60285 effective words) took 0.1s, 455765 effective words/s\n",
      "2023-12-06 15:25:59,221 : INFO : EPOCH 31: training on 99524 raw words (60307 effective words) took 0.1s, 449439 effective words/s\n",
      "2023-12-06 15:25:59,358 : INFO : EPOCH 32: training on 99524 raw words (60492 effective words) took 0.1s, 454111 effective words/s\n",
      "2023-12-06 15:25:59,497 : INFO : EPOCH 33: training on 99524 raw words (60480 effective words) took 0.1s, 449662 effective words/s\n",
      "2023-12-06 15:25:59,639 : INFO : EPOCH 34: training on 99524 raw words (60294 effective words) took 0.1s, 439829 effective words/s\n",
      "2023-12-06 15:25:59,799 : INFO : EPOCH 35: training on 99524 raw words (60495 effective words) took 0.2s, 388007 effective words/s\n",
      "2023-12-06 15:25:59,936 : INFO : EPOCH 36: training on 99524 raw words (60298 effective words) took 0.1s, 452393 effective words/s\n",
      "2023-12-06 15:26:00,076 : INFO : EPOCH 37: training on 99524 raw words (60331 effective words) took 0.1s, 445896 effective words/s\n",
      "2023-12-06 15:26:00,212 : INFO : EPOCH 38: training on 99524 raw words (60281 effective words) took 0.1s, 456705 effective words/s\n",
      "2023-12-06 15:26:00,374 : INFO : EPOCH 39: training on 99524 raw words (60316 effective words) took 0.2s, 383674 effective words/s\n",
      "2023-12-06 15:26:00,520 : INFO : EPOCH 40: training on 99524 raw words (60362 effective words) took 0.1s, 426927 effective words/s\n",
      "2023-12-06 15:26:00,655 : INFO : EPOCH 41: training on 99524 raw words (60667 effective words) took 0.1s, 462275 effective words/s\n",
      "2023-12-06 15:26:00,791 : INFO : EPOCH 42: training on 99524 raw words (60447 effective words) took 0.1s, 459075 effective words/s\n",
      "2023-12-06 15:26:00,952 : INFO : EPOCH 43: training on 99524 raw words (60336 effective words) took 0.2s, 384297 effective words/s\n",
      "2023-12-06 15:26:01,089 : INFO : EPOCH 44: training on 99524 raw words (60547 effective words) took 0.1s, 455998 effective words/s\n",
      "2023-12-06 15:26:01,226 : INFO : EPOCH 45: training on 99524 raw words (60340 effective words) took 0.1s, 455640 effective words/s\n",
      "2023-12-06 15:26:01,371 : INFO : EPOCH 46: training on 99524 raw words (60407 effective words) took 0.1s, 429936 effective words/s\n",
      "2023-12-06 15:26:01,508 : INFO : EPOCH 47: training on 99524 raw words (60183 effective words) took 0.1s, 455003 effective words/s\n",
      "2023-12-06 15:26:01,643 : INFO : EPOCH 48: training on 99524 raw words (60439 effective words) took 0.1s, 462070 effective words/s\n",
      "2023-12-06 15:26:01,805 : INFO : EPOCH 49: training on 99524 raw words (60478 effective words) took 0.2s, 382984 effective words/s\n",
      "2023-12-06 15:26:01,805 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3019979 effective words) took 7.2s, 418403 effective words/s', 'datetime': '2023-12-06T15:26:01.805310', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:26:01,806 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:26:01.806311', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 94%|| 459/486 [1:12:24<04:22,  9.74s/it]2023-12-06 15:26:05,714 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:26:05,714 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:26:05,734 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:26:05,735 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:26:05,742 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:26:05.742546', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:26:05,742 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:26:05.742546', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:26:05,750 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:26:05,750 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:26:05,751 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:26:05.751053', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:26:05,761 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:26:05,761 : INFO : resetting layer weights\n",
      "2023-12-06 15:26:05,766 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:26:05.766053', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:26:05,893 : INFO : EPOCH 0: training on 99524 raw words (65516 effective words) took 0.1s, 530855 effective words/s\n",
      "2023-12-06 15:26:06,053 : INFO : EPOCH 1: training on 99524 raw words (65638 effective words) took 0.2s, 418718 effective words/s\n",
      "2023-12-06 15:26:06,204 : INFO : EPOCH 2: training on 99524 raw words (65525 effective words) took 0.1s, 451209 effective words/s\n",
      "2023-12-06 15:26:06,343 : INFO : EPOCH 3: training on 99524 raw words (65362 effective words) took 0.1s, 485991 effective words/s\n",
      "2023-12-06 15:26:06,480 : INFO : EPOCH 4: training on 99524 raw words (65330 effective words) took 0.1s, 491728 effective words/s\n",
      "2023-12-06 15:26:06,609 : INFO : EPOCH 5: training on 99524 raw words (65319 effective words) took 0.1s, 519940 effective words/s\n",
      "2023-12-06 15:26:06,738 : INFO : EPOCH 6: training on 99524 raw words (65520 effective words) took 0.1s, 529614 effective words/s\n",
      "2023-12-06 15:26:06,881 : INFO : EPOCH 7: training on 99524 raw words (65696 effective words) took 0.1s, 470982 effective words/s\n",
      "2023-12-06 15:26:07,020 : INFO : EPOCH 8: training on 99524 raw words (65563 effective words) took 0.1s, 487515 effective words/s\n",
      "2023-12-06 15:26:07,157 : INFO : EPOCH 9: training on 99524 raw words (65515 effective words) took 0.1s, 494646 effective words/s\n",
      "2023-12-06 15:26:07,158 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (654984 effective words) took 1.4s, 470525 effective words/s', 'datetime': '2023-12-06T15:26:07.158356', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:26:07,158 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:26:07.158356', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 95%|| 460/486 [1:12:28<03:29,  8.04s/it]2023-12-06 15:26:09,795 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:26:09,795 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:26:09,816 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:26:09,816 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:26:09,822 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:26:09.822159', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:26:09,823 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:26:09.823160', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:26:09,830 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:26:09,830 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:26:09,830 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:26:09.830753', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:26:09,842 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:26:09,842 : INFO : resetting layer weights\n",
      "2023-12-06 15:26:09,846 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:26:09.846389', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:26:09,974 : INFO : EPOCH 0: training on 99524 raw words (65518 effective words) took 0.1s, 527707 effective words/s\n",
      "2023-12-06 15:26:10,139 : INFO : EPOCH 1: training on 99524 raw words (65619 effective words) took 0.2s, 408866 effective words/s\n",
      "2023-12-06 15:26:10,295 : INFO : EPOCH 2: training on 99524 raw words (65504 effective words) took 0.1s, 441083 effective words/s\n",
      "2023-12-06 15:26:10,438 : INFO : EPOCH 3: training on 99524 raw words (65384 effective words) took 0.1s, 471001 effective words/s\n",
      "2023-12-06 15:26:10,567 : INFO : EPOCH 4: training on 99524 raw words (65426 effective words) took 0.1s, 523026 effective words/s\n",
      "2023-12-06 15:26:10,694 : INFO : EPOCH 5: training on 99524 raw words (65560 effective words) took 0.1s, 530008 effective words/s\n",
      "2023-12-06 15:26:10,863 : INFO : EPOCH 6: training on 99524 raw words (65578 effective words) took 0.2s, 399625 effective words/s\n",
      "2023-12-06 15:26:11,005 : INFO : EPOCH 7: training on 99524 raw words (65429 effective words) took 0.1s, 477925 effective words/s\n",
      "2023-12-06 15:26:11,145 : INFO : EPOCH 8: training on 99524 raw words (65515 effective words) took 0.1s, 482174 effective words/s\n",
      "2023-12-06 15:26:11,273 : INFO : EPOCH 9: training on 99524 raw words (65624 effective words) took 0.1s, 523943 effective words/s\n",
      "2023-12-06 15:26:11,274 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (655157 effective words) took 1.4s, 458796 effective words/s', 'datetime': '2023-12-06T15:26:11.274934', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:26:11,275 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:26:11.275932', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 95%|| 461/486 [1:12:32<02:52,  6.91s/it]2023-12-06 15:26:14,055 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:26:14,055 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:26:14,076 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:26:14,077 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:26:14,083 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:26:14.083654', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:26:14,083 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:26:14.083654', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:26:14,091 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:26:14,092 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:26:14,092 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:26:14.092268', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:26:14,103 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:26:14,104 : INFO : resetting layer weights\n",
      "2023-12-06 15:26:14,108 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:26:14.108480', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:26:14,237 : INFO : EPOCH 0: training on 99524 raw words (65451 effective words) took 0.1s, 523826 effective words/s\n",
      "2023-12-06 15:26:14,419 : INFO : EPOCH 1: training on 99524 raw words (65573 effective words) took 0.2s, 367055 effective words/s\n",
      "2023-12-06 15:26:14,584 : INFO : EPOCH 2: training on 99524 raw words (65556 effective words) took 0.2s, 416232 effective words/s\n",
      "2023-12-06 15:26:14,726 : INFO : EPOCH 3: training on 99524 raw words (65504 effective words) took 0.1s, 475391 effective words/s\n",
      "2023-12-06 15:26:14,864 : INFO : EPOCH 4: training on 99524 raw words (65336 effective words) took 0.1s, 489356 effective words/s\n",
      "2023-12-06 15:26:15,005 : INFO : EPOCH 5: training on 99524 raw words (65381 effective words) took 0.1s, 481665 effective words/s\n",
      "2023-12-06 15:26:15,145 : INFO : EPOCH 6: training on 99524 raw words (65514 effective words) took 0.1s, 481486 effective words/s\n",
      "2023-12-06 15:26:15,284 : INFO : EPOCH 7: training on 99524 raw words (65632 effective words) took 0.1s, 485609 effective words/s\n",
      "2023-12-06 15:26:15,458 : INFO : EPOCH 8: training on 99524 raw words (65431 effective words) took 0.2s, 386606 effective words/s\n",
      "2023-12-06 15:26:15,598 : INFO : EPOCH 9: training on 99524 raw words (65600 effective words) took 0.1s, 481250 effective words/s\n",
      "2023-12-06 15:26:15,600 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (654978 effective words) took 1.5s, 439146 effective words/s', 'datetime': '2023-12-06T15:26:15.600191', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:26:15,601 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:26:15.601180', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 95%|| 462/486 [1:12:36<02:26,  6.11s/it]2023-12-06 15:26:18,319 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:26:18,320 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:26:18,340 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:26:18,340 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:26:18,346 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:26:18.346590', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:26:18,347 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:26:18.347588', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:26:18,353 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:26:18,355 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:26:18,356 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:26:18.356098', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:26:18,366 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:26:18,367 : INFO : resetting layer weights\n",
      "2023-12-06 15:26:18,371 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:26:18.371097', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:26:18,497 : INFO : EPOCH 0: training on 99524 raw words (65455 effective words) took 0.1s, 531953 effective words/s\n",
      "2023-12-06 15:26:18,676 : INFO : EPOCH 1: training on 99524 raw words (65442 effective words) took 0.2s, 374773 effective words/s\n",
      "2023-12-06 15:26:18,836 : INFO : EPOCH 2: training on 99524 raw words (65579 effective words) took 0.2s, 426987 effective words/s\n",
      "2023-12-06 15:26:18,972 : INFO : EPOCH 3: training on 99524 raw words (65509 effective words) took 0.1s, 493414 effective words/s\n",
      "2023-12-06 15:26:19,111 : INFO : EPOCH 4: training on 99524 raw words (65509 effective words) took 0.1s, 490082 effective words/s\n",
      "2023-12-06 15:26:19,245 : INFO : EPOCH 5: training on 99524 raw words (65450 effective words) took 0.1s, 501157 effective words/s\n",
      "2023-12-06 15:26:19,383 : INFO : EPOCH 6: training on 99524 raw words (65465 effective words) took 0.1s, 493549 effective words/s\n",
      "2023-12-06 15:26:19,537 : INFO : EPOCH 7: training on 99524 raw words (65381 effective words) took 0.2s, 435279 effective words/s\n",
      "2023-12-06 15:26:19,680 : INFO : EPOCH 8: training on 99524 raw words (65613 effective words) took 0.1s, 474965 effective words/s\n",
      "2023-12-06 15:26:19,818 : INFO : EPOCH 9: training on 99524 raw words (65503 effective words) took 0.1s, 488674 effective words/s\n",
      "2023-12-06 15:26:19,955 : INFO : EPOCH 10: training on 99524 raw words (65378 effective words) took 0.1s, 490500 effective words/s\n",
      "2023-12-06 15:26:20,119 : INFO : EPOCH 11: training on 99524 raw words (65592 effective words) took 0.2s, 413286 effective words/s\n",
      "2023-12-06 15:26:20,259 : INFO : EPOCH 12: training on 99524 raw words (65468 effective words) took 0.1s, 480519 effective words/s\n",
      "2023-12-06 15:26:20,397 : INFO : EPOCH 13: training on 99524 raw words (65480 effective words) took 0.1s, 490370 effective words/s\n",
      "2023-12-06 15:26:20,534 : INFO : EPOCH 14: training on 99524 raw words (65539 effective words) took 0.1s, 491593 effective words/s\n",
      "2023-12-06 15:26:20,670 : INFO : EPOCH 15: training on 99524 raw words (65535 effective words) took 0.1s, 497401 effective words/s\n",
      "2023-12-06 15:26:20,810 : INFO : EPOCH 16: training on 99524 raw words (65591 effective words) took 0.1s, 485651 effective words/s\n",
      "2023-12-06 15:26:20,957 : INFO : EPOCH 17: training on 99524 raw words (65544 effective words) took 0.1s, 457542 effective words/s\n",
      "2023-12-06 15:26:21,095 : INFO : EPOCH 18: training on 99524 raw words (65447 effective words) took 0.1s, 493422 effective words/s\n",
      "2023-12-06 15:26:21,232 : INFO : EPOCH 19: training on 99524 raw words (65453 effective words) took 0.1s, 492808 effective words/s\n",
      "2023-12-06 15:26:21,372 : INFO : EPOCH 20: training on 99524 raw words (65652 effective words) took 0.1s, 480811 effective words/s\n",
      "2023-12-06 15:26:21,509 : INFO : EPOCH 21: training on 99524 raw words (65605 effective words) took 0.1s, 493698 effective words/s\n",
      "2023-12-06 15:26:21,647 : INFO : EPOCH 22: training on 99524 raw words (65551 effective words) took 0.1s, 492622 effective words/s\n",
      "2023-12-06 15:26:21,802 : INFO : EPOCH 23: training on 99524 raw words (65749 effective words) took 0.2s, 435848 effective words/s\n",
      "2023-12-06 15:26:21,946 : INFO : EPOCH 24: training on 99524 raw words (65503 effective words) took 0.1s, 468152 effective words/s\n",
      "2023-12-06 15:26:22,083 : INFO : EPOCH 25: training on 99524 raw words (65486 effective words) took 0.1s, 491331 effective words/s\n",
      "2023-12-06 15:26:22,221 : INFO : EPOCH 26: training on 99524 raw words (65688 effective words) took 0.1s, 491093 effective words/s\n",
      "2023-12-06 15:26:22,359 : INFO : EPOCH 27: training on 99524 raw words (65789 effective words) took 0.1s, 492020 effective words/s\n",
      "2023-12-06 15:26:22,496 : INFO : EPOCH 28: training on 99524 raw words (65638 effective words) took 0.1s, 496880 effective words/s\n",
      "2023-12-06 15:26:22,651 : INFO : EPOCH 29: training on 99524 raw words (65540 effective words) took 0.2s, 433578 effective words/s\n",
      "2023-12-06 15:26:22,653 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1966134 effective words) took 4.3s, 459230 effective words/s', 'datetime': '2023-12-06T15:26:22.652808', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:26:22,653 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:26:22.653312', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 95%|| 463/486 [1:12:44<02:28,  6.47s/it]2023-12-06 15:26:25,631 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:26:25,631 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:26:25,652 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:26:25,653 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:26:25,659 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:26:25.659281', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:26:25,659 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:26:25.659281', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:26:25,666 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:26:25,667 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:26:25,667 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:26:25.667153', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:26:25,677 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:26:25,678 : INFO : resetting layer weights\n",
      "2023-12-06 15:26:25,682 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:26:25.682780', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:26:25,808 : INFO : EPOCH 0: training on 99524 raw words (65532 effective words) took 0.1s, 540967 effective words/s\n",
      "2023-12-06 15:26:25,977 : INFO : EPOCH 1: training on 99524 raw words (65426 effective words) took 0.2s, 397441 effective words/s\n",
      "2023-12-06 15:26:26,145 : INFO : EPOCH 2: training on 99524 raw words (65422 effective words) took 0.1s, 466292 effective words/s\n",
      "2023-12-06 15:26:26,283 : INFO : EPOCH 3: training on 99524 raw words (65515 effective words) took 0.1s, 487370 effective words/s\n",
      "2023-12-06 15:26:26,412 : INFO : EPOCH 4: training on 99524 raw words (65433 effective words) took 0.1s, 523630 effective words/s\n",
      "2023-12-06 15:26:26,559 : INFO : EPOCH 5: training on 99524 raw words (65370 effective words) took 0.1s, 461386 effective words/s\n",
      "2023-12-06 15:26:26,686 : INFO : EPOCH 6: training on 99524 raw words (65496 effective words) took 0.1s, 532488 effective words/s\n",
      "2023-12-06 15:26:26,823 : INFO : EPOCH 7: training on 99524 raw words (65265 effective words) took 0.1s, 490532 effective words/s\n",
      "2023-12-06 15:26:26,962 : INFO : EPOCH 8: training on 99524 raw words (65570 effective words) took 0.1s, 488220 effective words/s\n",
      "2023-12-06 15:26:27,099 : INFO : EPOCH 9: training on 99524 raw words (65522 effective words) took 0.1s, 491886 effective words/s\n",
      "2023-12-06 15:26:27,262 : INFO : EPOCH 10: training on 99524 raw words (65462 effective words) took 0.2s, 412266 effective words/s\n",
      "2023-12-06 15:26:27,401 : INFO : EPOCH 11: training on 99524 raw words (65632 effective words) took 0.1s, 486006 effective words/s\n",
      "2023-12-06 15:26:27,538 : INFO : EPOCH 12: training on 99524 raw words (65538 effective words) took 0.1s, 496447 effective words/s\n",
      "2023-12-06 15:26:27,678 : INFO : EPOCH 13: training on 99524 raw words (65491 effective words) took 0.1s, 482832 effective words/s\n",
      "2023-12-06 15:26:27,815 : INFO : EPOCH 14: training on 99524 raw words (65489 effective words) took 0.1s, 489476 effective words/s\n",
      "2023-12-06 15:26:27,975 : INFO : EPOCH 15: training on 99524 raw words (65506 effective words) took 0.2s, 420643 effective words/s\n",
      "2023-12-06 15:26:28,103 : INFO : EPOCH 16: training on 99524 raw words (65589 effective words) took 0.1s, 530636 effective words/s\n",
      "2023-12-06 15:26:28,243 : INFO : EPOCH 17: training on 99524 raw words (65479 effective words) took 0.1s, 483725 effective words/s\n",
      "2023-12-06 15:26:28,380 : INFO : EPOCH 18: training on 99524 raw words (65429 effective words) took 0.1s, 489773 effective words/s\n",
      "2023-12-06 15:26:28,534 : INFO : EPOCH 19: training on 99524 raw words (65481 effective words) took 0.1s, 437919 effective words/s\n",
      "2023-12-06 15:26:28,677 : INFO : EPOCH 20: training on 99524 raw words (65479 effective words) took 0.1s, 477531 effective words/s\n",
      "2023-12-06 15:26:28,813 : INFO : EPOCH 21: training on 99524 raw words (65459 effective words) took 0.1s, 495899 effective words/s\n",
      "2023-12-06 15:26:28,959 : INFO : EPOCH 22: training on 99524 raw words (65527 effective words) took 0.1s, 462573 effective words/s\n",
      "2023-12-06 15:26:29,120 : INFO : EPOCH 23: training on 99524 raw words (65551 effective words) took 0.2s, 418405 effective words/s\n",
      "2023-12-06 15:26:29,259 : INFO : EPOCH 24: training on 99524 raw words (65621 effective words) took 0.1s, 489913 effective words/s\n",
      "2023-12-06 15:26:29,400 : INFO : EPOCH 25: training on 99524 raw words (65448 effective words) took 0.1s, 477569 effective words/s\n",
      "2023-12-06 15:26:29,548 : INFO : EPOCH 26: training on 99524 raw words (65705 effective words) took 0.1s, 457995 effective words/s\n",
      "2023-12-06 15:26:29,700 : INFO : EPOCH 27: training on 99524 raw words (65604 effective words) took 0.1s, 446018 effective words/s\n",
      "2023-12-06 15:26:29,862 : INFO : EPOCH 28: training on 99524 raw words (65603 effective words) took 0.2s, 413605 effective words/s\n",
      "2023-12-06 15:26:30,003 : INFO : EPOCH 29: training on 99524 raw words (65495 effective words) took 0.1s, 477726 effective words/s\n",
      "2023-12-06 15:26:30,004 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965139 effective words) took 4.3s, 454717 effective words/s', 'datetime': '2023-12-06T15:26:30.004793', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:26:30,005 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:26:30.005793', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 95%|| 464/486 [1:12:51<02:29,  6.79s/it]2023-12-06 15:26:33,173 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:26:33,174 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:26:33,193 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:26:33,194 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:26:33,199 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:26:33.199687', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:26:33,200 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:26:33.200686', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:26:33,207 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:26:33,207 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:26:33,208 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:26:33.208815', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:26:33,218 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:26:33,219 : INFO : resetting layer weights\n",
      "2023-12-06 15:26:33,224 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:26:33.224142', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:26:33,351 : INFO : EPOCH 0: training on 99524 raw words (65638 effective words) took 0.1s, 534301 effective words/s\n",
      "2023-12-06 15:26:33,519 : INFO : EPOCH 1: training on 99524 raw words (65717 effective words) took 0.2s, 401587 effective words/s\n",
      "2023-12-06 15:26:33,680 : INFO : EPOCH 2: training on 99524 raw words (65498 effective words) took 0.2s, 423171 effective words/s\n",
      "2023-12-06 15:26:33,820 : INFO : EPOCH 3: training on 99524 raw words (65396 effective words) took 0.1s, 482055 effective words/s\n",
      "2023-12-06 15:26:33,961 : INFO : EPOCH 4: training on 99524 raw words (65457 effective words) took 0.1s, 480876 effective words/s\n",
      "2023-12-06 15:26:34,104 : INFO : EPOCH 5: training on 99524 raw words (65331 effective words) took 0.1s, 472162 effective words/s\n",
      "2023-12-06 15:26:34,265 : INFO : EPOCH 6: training on 99524 raw words (65567 effective words) took 0.2s, 420624 effective words/s\n",
      "2023-12-06 15:26:34,407 : INFO : EPOCH 7: training on 99524 raw words (65473 effective words) took 0.1s, 473598 effective words/s\n",
      "2023-12-06 15:26:34,546 : INFO : EPOCH 8: training on 99524 raw words (65559 effective words) took 0.1s, 481824 effective words/s\n",
      "2023-12-06 15:26:34,687 : INFO : EPOCH 9: training on 99524 raw words (65467 effective words) took 0.1s, 482526 effective words/s\n",
      "2023-12-06 15:26:34,826 : INFO : EPOCH 10: training on 99524 raw words (65437 effective words) took 0.1s, 484152 effective words/s\n",
      "2023-12-06 15:26:34,966 : INFO : EPOCH 11: training on 99524 raw words (65563 effective words) took 0.1s, 479496 effective words/s\n",
      "2023-12-06 15:26:35,139 : INFO : EPOCH 12: training on 99524 raw words (65510 effective words) took 0.2s, 391054 effective words/s\n",
      "2023-12-06 15:26:35,279 : INFO : EPOCH 13: training on 99524 raw words (65477 effective words) took 0.1s, 481490 effective words/s\n",
      "2023-12-06 15:26:35,422 : INFO : EPOCH 14: training on 99524 raw words (65627 effective words) took 0.1s, 473562 effective words/s\n",
      "2023-12-06 15:26:35,561 : INFO : EPOCH 15: training on 99524 raw words (65576 effective words) took 0.1s, 492865 effective words/s\n",
      "2023-12-06 15:26:35,699 : INFO : EPOCH 16: training on 99524 raw words (65275 effective words) took 0.1s, 487042 effective words/s\n",
      "2023-12-06 15:26:35,841 : INFO : EPOCH 17: training on 99524 raw words (65364 effective words) took 0.1s, 471559 effective words/s\n",
      "2023-12-06 15:26:36,000 : INFO : EPOCH 18: training on 99524 raw words (65520 effective words) took 0.2s, 430575 effective words/s\n",
      "2023-12-06 15:26:36,144 : INFO : EPOCH 19: training on 99524 raw words (65526 effective words) took 0.1s, 475022 effective words/s\n",
      "2023-12-06 15:26:36,286 : INFO : EPOCH 20: training on 99524 raw words (65438 effective words) took 0.1s, 475506 effective words/s\n",
      "2023-12-06 15:26:36,425 : INFO : EPOCH 21: training on 99524 raw words (65571 effective words) took 0.1s, 483567 effective words/s\n",
      "2023-12-06 15:26:36,564 : INFO : EPOCH 22: training on 99524 raw words (65501 effective words) took 0.1s, 486426 effective words/s\n",
      "2023-12-06 15:26:36,706 : INFO : EPOCH 23: training on 99524 raw words (65508 effective words) took 0.1s, 478411 effective words/s\n",
      "2023-12-06 15:26:36,874 : INFO : EPOCH 24: training on 99524 raw words (65509 effective words) took 0.2s, 401918 effective words/s\n",
      "2023-12-06 15:26:37,015 : INFO : EPOCH 25: training on 99524 raw words (65568 effective words) took 0.1s, 476971 effective words/s\n",
      "2023-12-06 15:26:37,156 : INFO : EPOCH 26: training on 99524 raw words (65617 effective words) took 0.1s, 479183 effective words/s\n",
      "2023-12-06 15:26:37,296 : INFO : EPOCH 27: training on 99524 raw words (65662 effective words) took 0.1s, 485334 effective words/s\n",
      "2023-12-06 15:26:37,480 : INFO : EPOCH 28: training on 99524 raw words (65384 effective words) took 0.2s, 364099 effective words/s\n",
      "2023-12-06 15:26:37,628 : INFO : EPOCH 29: training on 99524 raw words (65575 effective words) took 0.1s, 453124 effective words/s\n",
      "2023-12-06 15:26:37,629 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1965311 effective words) took 4.4s, 446128 effective words/s', 'datetime': '2023-12-06T15:26:37.629767', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:26:37,630 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:26:37.630846', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 96%|| 465/486 [1:12:59<02:29,  7.12s/it]2023-12-06 15:26:41,057 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:26:41,058 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:26:41,078 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:26:41,079 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:26:41,085 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:26:41.085639', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:26:41,085 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:26:41.085639', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:26:41,092 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:26:41,093 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:26:41,093 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:26:41.093873', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:26:41,105 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:26:41,106 : INFO : resetting layer weights\n",
      "2023-12-06 15:26:41,110 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:26:41.110941', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:26:41,242 : INFO : EPOCH 0: training on 99524 raw words (65573 effective words) took 0.1s, 513296 effective words/s\n",
      "2023-12-06 15:26:41,444 : INFO : EPOCH 1: training on 99524 raw words (65581 effective words) took 0.2s, 331514 effective words/s\n",
      "2023-12-06 15:26:41,637 : INFO : EPOCH 2: training on 99524 raw words (65625 effective words) took 0.2s, 356532 effective words/s\n",
      "2023-12-06 15:26:41,788 : INFO : EPOCH 3: training on 99524 raw words (65460 effective words) took 0.1s, 450661 effective words/s\n",
      "2023-12-06 15:26:41,930 : INFO : EPOCH 4: training on 99524 raw words (65591 effective words) took 0.1s, 473704 effective words/s\n",
      "2023-12-06 15:26:42,074 : INFO : EPOCH 5: training on 99524 raw words (65444 effective words) took 0.1s, 471127 effective words/s\n",
      "2023-12-06 15:26:42,221 : INFO : EPOCH 6: training on 99524 raw words (65604 effective words) took 0.1s, 460227 effective words/s\n",
      "2023-12-06 15:26:42,368 : INFO : EPOCH 7: training on 99524 raw words (65562 effective words) took 0.1s, 460333 effective words/s\n",
      "2023-12-06 15:26:42,528 : INFO : EPOCH 8: training on 99524 raw words (65447 effective words) took 0.2s, 419582 effective words/s\n",
      "2023-12-06 15:26:42,669 : INFO : EPOCH 9: training on 99524 raw words (65501 effective words) took 0.1s, 478094 effective words/s\n",
      "2023-12-06 15:26:42,813 : INFO : EPOCH 10: training on 99524 raw words (65482 effective words) took 0.1s, 467327 effective words/s\n",
      "2023-12-06 15:26:42,957 : INFO : EPOCH 11: training on 99524 raw words (65597 effective words) took 0.1s, 471777 effective words/s\n",
      "2023-12-06 15:26:43,096 : INFO : EPOCH 12: training on 99524 raw words (65509 effective words) took 0.1s, 487362 effective words/s\n",
      "2023-12-06 15:26:43,267 : INFO : EPOCH 13: training on 99524 raw words (65476 effective words) took 0.2s, 390123 effective words/s\n",
      "2023-12-06 15:26:43,406 : INFO : EPOCH 14: training on 99524 raw words (65644 effective words) took 0.1s, 488474 effective words/s\n",
      "2023-12-06 15:26:43,543 : INFO : EPOCH 15: training on 99524 raw words (65541 effective words) took 0.1s, 493043 effective words/s\n",
      "2023-12-06 15:26:43,681 : INFO : EPOCH 16: training on 99524 raw words (65561 effective words) took 0.1s, 490331 effective words/s\n",
      "2023-12-06 15:26:43,822 : INFO : EPOCH 17: training on 99524 raw words (65539 effective words) took 0.1s, 480439 effective words/s\n",
      "2023-12-06 15:26:43,962 : INFO : EPOCH 18: training on 99524 raw words (65415 effective words) took 0.1s, 483063 effective words/s\n",
      "2023-12-06 15:26:44,123 : INFO : EPOCH 19: training on 99524 raw words (65608 effective words) took 0.2s, 417042 effective words/s\n",
      "2023-12-06 15:26:44,262 : INFO : EPOCH 20: training on 99524 raw words (65575 effective words) took 0.1s, 487500 effective words/s\n",
      "2023-12-06 15:26:44,405 : INFO : EPOCH 21: training on 99524 raw words (65559 effective words) took 0.1s, 472322 effective words/s\n",
      "2023-12-06 15:26:44,558 : INFO : EPOCH 22: training on 99524 raw words (65632 effective words) took 0.1s, 443212 effective words/s\n",
      "2023-12-06 15:26:44,746 : INFO : EPOCH 23: training on 99524 raw words (65580 effective words) took 0.2s, 358378 effective words/s\n",
      "2023-12-06 15:26:44,909 : INFO : EPOCH 24: training on 99524 raw words (65388 effective words) took 0.2s, 419729 effective words/s\n",
      "2023-12-06 15:26:45,087 : INFO : EPOCH 25: training on 99524 raw words (65427 effective words) took 0.2s, 376357 effective words/s\n",
      "2023-12-06 15:26:45,230 : INFO : EPOCH 26: training on 99524 raw words (65674 effective words) took 0.1s, 469642 effective words/s\n",
      "2023-12-06 15:26:45,377 : INFO : EPOCH 27: training on 99524 raw words (65695 effective words) took 0.1s, 466441 effective words/s\n",
      "2023-12-06 15:26:45,532 : INFO : EPOCH 28: training on 99524 raw words (65525 effective words) took 0.1s, 440067 effective words/s\n",
      "2023-12-06 15:26:45,689 : INFO : EPOCH 29: training on 99524 raw words (65646 effective words) took 0.2s, 428114 effective words/s\n",
      "2023-12-06 15:26:45,840 : INFO : EPOCH 30: training on 99524 raw words (65490 effective words) took 0.1s, 446916 effective words/s\n",
      "2023-12-06 15:26:46,004 : INFO : EPOCH 31: training on 99524 raw words (65541 effective words) took 0.2s, 409843 effective words/s\n",
      "2023-12-06 15:26:46,148 : INFO : EPOCH 32: training on 99524 raw words (65524 effective words) took 0.1s, 467497 effective words/s\n",
      "2023-12-06 15:26:46,289 : INFO : EPOCH 33: training on 99524 raw words (65578 effective words) took 0.1s, 480088 effective words/s\n",
      "2023-12-06 15:26:46,440 : INFO : EPOCH 34: training on 99524 raw words (65577 effective words) took 0.1s, 448498 effective words/s\n",
      "2023-12-06 15:26:46,595 : INFO : EPOCH 35: training on 99524 raw words (65577 effective words) took 0.2s, 433545 effective words/s\n",
      "2023-12-06 15:26:46,724 : INFO : EPOCH 36: training on 99524 raw words (65562 effective words) took 0.1s, 525650 effective words/s\n",
      "2023-12-06 15:26:46,862 : INFO : EPOCH 37: training on 99524 raw words (65482 effective words) took 0.1s, 488560 effective words/s\n",
      "2023-12-06 15:26:47,002 : INFO : EPOCH 38: training on 99524 raw words (65421 effective words) took 0.1s, 487013 effective words/s\n",
      "2023-12-06 15:26:47,168 : INFO : EPOCH 39: training on 99524 raw words (65419 effective words) took 0.2s, 401606 effective words/s\n",
      "2023-12-06 15:26:47,310 : INFO : EPOCH 40: training on 99524 raw words (65434 effective words) took 0.1s, 474120 effective words/s\n",
      "2023-12-06 15:26:47,451 : INFO : EPOCH 41: training on 99524 raw words (65515 effective words) took 0.1s, 483751 effective words/s\n",
      "2023-12-06 15:26:47,588 : INFO : EPOCH 42: training on 99524 raw words (65501 effective words) took 0.1s, 492125 effective words/s\n",
      "2023-12-06 15:26:47,729 : INFO : EPOCH 43: training on 99524 raw words (65681 effective words) took 0.1s, 481924 effective words/s\n",
      "2023-12-06 15:26:47,868 : INFO : EPOCH 44: training on 99524 raw words (65529 effective words) took 0.1s, 491339 effective words/s\n",
      "2023-12-06 15:26:48,021 : INFO : EPOCH 45: training on 99524 raw words (65477 effective words) took 0.1s, 437644 effective words/s\n",
      "2023-12-06 15:26:48,163 : INFO : EPOCH 46: training on 99524 raw words (65584 effective words) took 0.1s, 479634 effective words/s\n",
      "2023-12-06 15:26:48,303 : INFO : EPOCH 47: training on 99524 raw words (65425 effective words) took 0.1s, 478980 effective words/s\n",
      "2023-12-06 15:26:48,441 : INFO : EPOCH 48: training on 99524 raw words (65608 effective words) took 0.1s, 491188 effective words/s\n",
      "2023-12-06 15:26:48,601 : INFO : EPOCH 49: training on 99524 raw words (65552 effective words) took 0.2s, 422086 effective words/s\n",
      "2023-12-06 15:26:48,602 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276938 effective words) took 7.5s, 437473 effective words/s', 'datetime': '2023-12-06T15:26:48.602005', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:26:48,602 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:26:48.602005', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 96%|| 466/486 [1:13:10<02:44,  8.25s/it]2023-12-06 15:26:51,936 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:26:51,937 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:26:51,957 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:26:51,957 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:26:51,964 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:26:51.964285', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:26:51,965 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:26:51.965285', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:26:51,972 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:26:51,973 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:26:51,973 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:26:51.973284', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:26:51,983 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:26:51,984 : INFO : resetting layer weights\n",
      "2023-12-06 15:26:51,988 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:26:51.988797', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:26:52,117 : INFO : EPOCH 0: training on 99524 raw words (65440 effective words) took 0.1s, 522947 effective words/s\n",
      "2023-12-06 15:26:52,317 : INFO : EPOCH 1: training on 99524 raw words (65628 effective words) took 0.2s, 334229 effective words/s\n",
      "2023-12-06 15:26:52,471 : INFO : EPOCH 2: training on 99524 raw words (65593 effective words) took 0.1s, 443779 effective words/s\n",
      "2023-12-06 15:26:52,611 : INFO : EPOCH 3: training on 99524 raw words (65385 effective words) took 0.1s, 483202 effective words/s\n",
      "2023-12-06 15:26:52,748 : INFO : EPOCH 4: training on 99524 raw words (65418 effective words) took 0.1s, 490228 effective words/s\n",
      "2023-12-06 15:26:52,887 : INFO : EPOCH 5: training on 99524 raw words (65545 effective words) took 0.1s, 486359 effective words/s\n",
      "2023-12-06 15:26:53,027 : INFO : EPOCH 6: training on 99524 raw words (65454 effective words) took 0.1s, 485398 effective words/s\n",
      "2023-12-06 15:26:53,165 : INFO : EPOCH 7: training on 99524 raw words (65615 effective words) took 0.1s, 488057 effective words/s\n",
      "2023-12-06 15:26:53,332 : INFO : EPOCH 8: training on 99524 raw words (65625 effective words) took 0.2s, 402622 effective words/s\n",
      "2023-12-06 15:26:53,472 : INFO : EPOCH 9: training on 99524 raw words (65534 effective words) took 0.1s, 485493 effective words/s\n",
      "2023-12-06 15:26:53,612 : INFO : EPOCH 10: training on 99524 raw words (65420 effective words) took 0.1s, 479158 effective words/s\n",
      "2023-12-06 15:26:53,750 : INFO : EPOCH 11: training on 99524 raw words (65583 effective words) took 0.1s, 490449 effective words/s\n",
      "2023-12-06 15:26:53,910 : INFO : EPOCH 12: training on 99524 raw words (65574 effective words) took 0.2s, 422250 effective words/s\n",
      "2023-12-06 15:26:54,048 : INFO : EPOCH 13: training on 99524 raw words (65603 effective words) took 0.1s, 487633 effective words/s\n",
      "2023-12-06 15:26:54,188 : INFO : EPOCH 14: training on 99524 raw words (65559 effective words) took 0.1s, 483577 effective words/s\n",
      "2023-12-06 15:26:54,329 : INFO : EPOCH 15: training on 99524 raw words (65494 effective words) took 0.1s, 479466 effective words/s\n",
      "2023-12-06 15:26:54,490 : INFO : EPOCH 16: training on 99524 raw words (65331 effective words) took 0.2s, 417874 effective words/s\n",
      "2023-12-06 15:26:54,632 : INFO : EPOCH 17: training on 99524 raw words (65571 effective words) took 0.1s, 475276 effective words/s\n",
      "2023-12-06 15:26:54,772 : INFO : EPOCH 18: training on 99524 raw words (65365 effective words) took 0.1s, 485832 effective words/s\n",
      "2023-12-06 15:26:54,910 : INFO : EPOCH 19: training on 99524 raw words (65624 effective words) took 0.1s, 491083 effective words/s\n",
      "2023-12-06 15:26:55,048 : INFO : EPOCH 20: training on 99524 raw words (65481 effective words) took 0.1s, 486802 effective words/s\n",
      "2023-12-06 15:26:55,187 : INFO : EPOCH 21: training on 99524 raw words (65510 effective words) took 0.1s, 484266 effective words/s\n",
      "2023-12-06 15:26:55,361 : INFO : EPOCH 22: training on 99524 raw words (65568 effective words) took 0.2s, 388060 effective words/s\n",
      "2023-12-06 15:26:55,500 : INFO : EPOCH 23: training on 99524 raw words (65585 effective words) took 0.1s, 487939 effective words/s\n",
      "2023-12-06 15:26:55,639 : INFO : EPOCH 24: training on 99524 raw words (65627 effective words) took 0.1s, 485750 effective words/s\n",
      "2023-12-06 15:26:55,779 : INFO : EPOCH 25: training on 99524 raw words (65497 effective words) took 0.1s, 485256 effective words/s\n",
      "2023-12-06 15:26:55,944 : INFO : EPOCH 26: training on 99524 raw words (65675 effective words) took 0.2s, 406943 effective words/s\n",
      "2023-12-06 15:26:56,083 : INFO : EPOCH 27: training on 99524 raw words (65626 effective words) took 0.1s, 485597 effective words/s\n",
      "2023-12-06 15:26:56,231 : INFO : EPOCH 28: training on 99524 raw words (65564 effective words) took 0.1s, 457735 effective words/s\n",
      "2023-12-06 15:26:56,370 : INFO : EPOCH 29: training on 99524 raw words (65590 effective words) took 0.1s, 487628 effective words/s\n",
      "2023-12-06 15:26:56,523 : INFO : EPOCH 30: training on 99524 raw words (65504 effective words) took 0.1s, 440503 effective words/s\n",
      "2023-12-06 15:26:56,666 : INFO : EPOCH 31: training on 99524 raw words (65615 effective words) took 0.1s, 480333 effective words/s\n",
      "2023-12-06 15:26:56,805 : INFO : EPOCH 32: training on 99524 raw words (65510 effective words) took 0.1s, 485837 effective words/s\n",
      "2023-12-06 15:26:56,941 : INFO : EPOCH 33: training on 99524 raw words (65614 effective words) took 0.1s, 499472 effective words/s\n",
      "2023-12-06 15:26:57,079 : INFO : EPOCH 34: training on 99524 raw words (65463 effective words) took 0.1s, 490689 effective words/s\n",
      "2023-12-06 15:26:57,220 : INFO : EPOCH 35: training on 99524 raw words (65655 effective words) took 0.1s, 480809 effective words/s\n",
      "2023-12-06 15:26:57,391 : INFO : EPOCH 36: training on 99524 raw words (65605 effective words) took 0.2s, 394128 effective words/s\n",
      "2023-12-06 15:26:57,531 : INFO : EPOCH 37: training on 99524 raw words (65510 effective words) took 0.1s, 483255 effective words/s\n",
      "2023-12-06 15:26:57,670 : INFO : EPOCH 38: training on 99524 raw words (65401 effective words) took 0.1s, 485431 effective words/s\n",
      "2023-12-06 15:26:57,816 : INFO : EPOCH 39: training on 99524 raw words (65543 effective words) took 0.1s, 462617 effective words/s\n",
      "2023-12-06 15:26:57,945 : INFO : EPOCH 40: training on 99524 raw words (65427 effective words) took 0.1s, 524226 effective words/s\n",
      "2023-12-06 15:26:58,084 : INFO : EPOCH 41: training on 99524 raw words (65510 effective words) took 0.1s, 485260 effective words/s\n",
      "2023-12-06 15:26:58,245 : INFO : EPOCH 42: training on 99524 raw words (65591 effective words) took 0.2s, 417571 effective words/s\n",
      "2023-12-06 15:26:58,386 : INFO : EPOCH 43: training on 99524 raw words (65667 effective words) took 0.1s, 482099 effective words/s\n",
      "2023-12-06 15:26:58,531 : INFO : EPOCH 44: training on 99524 raw words (65525 effective words) took 0.1s, 464891 effective words/s\n",
      "2023-12-06 15:26:58,686 : INFO : EPOCH 45: training on 99524 raw words (65545 effective words) took 0.1s, 439734 effective words/s\n",
      "2023-12-06 15:26:58,839 : INFO : EPOCH 46: training on 99524 raw words (65459 effective words) took 0.1s, 438027 effective words/s\n",
      "2023-12-06 15:26:58,972 : INFO : EPOCH 47: training on 99524 raw words (65517 effective words) took 0.1s, 513011 effective words/s\n",
      "2023-12-06 15:26:59,112 : INFO : EPOCH 48: training on 99524 raw words (65544 effective words) took 0.1s, 482546 effective words/s\n",
      "2023-12-06 15:26:59,252 : INFO : EPOCH 49: training on 99524 raw words (65515 effective words) took 0.1s, 484050 effective words/s\n",
      "2023-12-06 15:26:59,253 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3276804 effective words) took 7.3s, 451069 effective words/s', 'datetime': '2023-12-06T15:26:59.253418', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:26:59,254 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:26:59.254420', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 96%|| 467/486 [1:13:21<02:52,  9.08s/it]2023-12-06 15:27:02,958 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:27:02,959 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:27:02,980 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:27:02,980 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:27:02,985 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 1966 unique words (27.59% of original 7125, drops 5159)', 'datetime': '2023-12-06T15:27:02.985519', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:02,986 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 90923 word corpus (91.36% of original 99524, drops 8601)', 'datetime': '2023-12-06T15:27:02.986527', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:02,993 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:27:02,994 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:27:02,994 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 61217.03702549995 word corpus (67.3%% of prior 90923)', 'datetime': '2023-12-06T15:27:02.994529', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:03,005 : INFO : estimated required memory for 1966 words and 200 dimensions: 8441600 bytes\n",
      "2023-12-06 15:27:03,006 : INFO : resetting layer weights\n",
      "2023-12-06 15:27:03,010 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1966 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:27:03.010802', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:27:03,138 : INFO : EPOCH 0: training on 99524 raw words (65515 effective words) took 0.1s, 529931 effective words/s\n",
      "2023-12-06 15:27:03,303 : INFO : EPOCH 1: training on 99524 raw words (65605 effective words) took 0.2s, 407380 effective words/s\n",
      "2023-12-06 15:27:03,455 : INFO : EPOCH 2: training on 99524 raw words (65799 effective words) took 0.1s, 450805 effective words/s\n",
      "2023-12-06 15:27:03,585 : INFO : EPOCH 3: training on 99524 raw words (65386 effective words) took 0.1s, 520933 effective words/s\n",
      "2023-12-06 15:27:03,727 : INFO : EPOCH 4: training on 99524 raw words (65669 effective words) took 0.1s, 477946 effective words/s\n",
      "2023-12-06 15:27:03,856 : INFO : EPOCH 5: training on 99524 raw words (65367 effective words) took 0.1s, 521854 effective words/s\n",
      "2023-12-06 15:27:03,986 : INFO : EPOCH 6: training on 99524 raw words (65574 effective words) took 0.1s, 522029 effective words/s\n",
      "2023-12-06 15:27:04,138 : INFO : EPOCH 7: training on 99524 raw words (65642 effective words) took 0.1s, 447734 effective words/s\n",
      "2023-12-06 15:27:04,279 : INFO : EPOCH 8: training on 99524 raw words (65356 effective words) took 0.1s, 477128 effective words/s\n",
      "2023-12-06 15:27:04,419 : INFO : EPOCH 9: training on 99524 raw words (65547 effective words) took 0.1s, 483574 effective words/s\n",
      "2023-12-06 15:27:04,549 : INFO : EPOCH 10: training on 99524 raw words (65418 effective words) took 0.1s, 522757 effective words/s\n",
      "2023-12-06 15:27:04,696 : INFO : EPOCH 11: training on 99524 raw words (65612 effective words) took 0.1s, 462461 effective words/s\n",
      "2023-12-06 15:27:04,837 : INFO : EPOCH 12: training on 99524 raw words (65679 effective words) took 0.1s, 487581 effective words/s\n",
      "2023-12-06 15:27:04,980 : INFO : EPOCH 13: training on 99524 raw words (65593 effective words) took 0.1s, 476421 effective words/s\n",
      "2023-12-06 15:27:05,118 : INFO : EPOCH 14: training on 99524 raw words (65597 effective words) took 0.1s, 491487 effective words/s\n",
      "2023-12-06 15:27:05,282 : INFO : EPOCH 15: training on 99524 raw words (65602 effective words) took 0.2s, 410805 effective words/s\n",
      "2023-12-06 15:27:05,425 : INFO : EPOCH 16: training on 99524 raw words (65548 effective words) took 0.1s, 472117 effective words/s\n",
      "2023-12-06 15:27:05,564 : INFO : EPOCH 17: training on 99524 raw words (65643 effective words) took 0.1s, 484452 effective words/s\n",
      "2023-12-06 15:27:05,706 : INFO : EPOCH 18: training on 99524 raw words (65544 effective words) took 0.1s, 480985 effective words/s\n",
      "2023-12-06 15:27:05,858 : INFO : EPOCH 19: training on 99524 raw words (65593 effective words) took 0.1s, 441433 effective words/s\n",
      "2023-12-06 15:27:06,005 : INFO : EPOCH 20: training on 99524 raw words (65530 effective words) took 0.1s, 466109 effective words/s\n",
      "2023-12-06 15:27:06,146 : INFO : EPOCH 21: training on 99524 raw words (65678 effective words) took 0.1s, 478982 effective words/s\n",
      "2023-12-06 15:27:06,289 : INFO : EPOCH 22: training on 99524 raw words (65492 effective words) took 0.1s, 471501 effective words/s\n",
      "2023-12-06 15:27:06,448 : INFO : EPOCH 23: training on 99524 raw words (65601 effective words) took 0.2s, 425763 effective words/s\n",
      "2023-12-06 15:27:06,588 : INFO : EPOCH 24: training on 99524 raw words (65612 effective words) took 0.1s, 484084 effective words/s\n",
      "2023-12-06 15:27:06,729 : INFO : EPOCH 25: training on 99524 raw words (65488 effective words) took 0.1s, 477678 effective words/s\n",
      "2023-12-06 15:27:06,869 : INFO : EPOCH 26: training on 99524 raw words (65814 effective words) took 0.1s, 485930 effective words/s\n",
      "2023-12-06 15:27:07,029 : INFO : EPOCH 27: training on 99524 raw words (65677 effective words) took 0.2s, 419555 effective words/s\n",
      "2023-12-06 15:27:07,170 : INFO : EPOCH 28: training on 99524 raw words (65497 effective words) took 0.1s, 478081 effective words/s\n",
      "2023-12-06 15:27:07,300 : INFO : EPOCH 29: training on 99524 raw words (65499 effective words) took 0.1s, 523420 effective words/s\n",
      "2023-12-06 15:27:07,442 : INFO : EPOCH 30: training on 99524 raw words (65537 effective words) took 0.1s, 480023 effective words/s\n",
      "2023-12-06 15:27:07,615 : INFO : EPOCH 31: training on 99524 raw words (65470 effective words) took 0.2s, 388100 effective words/s\n",
      "2023-12-06 15:27:07,754 : INFO : EPOCH 32: training on 99524 raw words (65518 effective words) took 0.1s, 483907 effective words/s\n",
      "2023-12-06 15:27:07,905 : INFO : EPOCH 33: training on 99524 raw words (65660 effective words) took 0.1s, 450834 effective words/s\n",
      "2023-12-06 15:27:08,047 : INFO : EPOCH 34: training on 99524 raw words (65609 effective words) took 0.1s, 474399 effective words/s\n",
      "2023-12-06 15:27:08,186 : INFO : EPOCH 35: training on 99524 raw words (65643 effective words) took 0.1s, 485187 effective words/s\n",
      "2023-12-06 15:27:08,341 : INFO : EPOCH 36: training on 99524 raw words (65591 effective words) took 0.1s, 439222 effective words/s\n",
      "2023-12-06 15:27:08,482 : INFO : EPOCH 37: training on 99524 raw words (65508 effective words) took 0.1s, 478338 effective words/s\n",
      "2023-12-06 15:27:08,628 : INFO : EPOCH 38: training on 99524 raw words (65534 effective words) took 0.1s, 463502 effective words/s\n",
      "2023-12-06 15:27:08,769 : INFO : EPOCH 39: training on 99524 raw words (65583 effective words) took 0.1s, 481146 effective words/s\n",
      "2023-12-06 15:27:08,910 : INFO : EPOCH 40: training on 99524 raw words (65619 effective words) took 0.1s, 481940 effective words/s\n",
      "2023-12-06 15:27:09,050 : INFO : EPOCH 41: training on 99524 raw words (65518 effective words) took 0.1s, 480525 effective words/s\n",
      "2023-12-06 15:27:09,212 : INFO : EPOCH 42: training on 99524 raw words (65645 effective words) took 0.2s, 415214 effective words/s\n",
      "2023-12-06 15:27:09,361 : INFO : EPOCH 43: training on 99524 raw words (65652 effective words) took 0.1s, 455196 effective words/s\n",
      "2023-12-06 15:27:09,508 : INFO : EPOCH 44: training on 99524 raw words (65538 effective words) took 0.1s, 460518 effective words/s\n",
      "2023-12-06 15:27:09,648 : INFO : EPOCH 45: training on 99524 raw words (65380 effective words) took 0.1s, 481379 effective words/s\n",
      "2023-12-06 15:27:09,789 : INFO : EPOCH 46: training on 99524 raw words (65446 effective words) took 0.1s, 477771 effective words/s\n",
      "2023-12-06 15:27:09,948 : INFO : EPOCH 47: training on 99524 raw words (65580 effective words) took 0.2s, 423337 effective words/s\n",
      "2023-12-06 15:27:10,087 : INFO : EPOCH 48: training on 99524 raw words (65538 effective words) took 0.1s, 490304 effective words/s\n",
      "2023-12-06 15:27:10,226 : INFO : EPOCH 49: training on 99524 raw words (65501 effective words) took 0.1s, 484212 effective words/s\n",
      "2023-12-06 15:27:10,227 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3278247 effective words) took 7.2s, 454289 effective words/s', 'datetime': '2023-12-06T15:27:10.227555', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:27:10,227 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc5,s0.001,t3>', 'datetime': '2023-12-06T15:27:10.227555', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 96%|| 468/486 [1:13:32<02:55,  9.73s/it]2023-12-06 15:27:14,197 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:27:14,197 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:27:14,219 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:27:14,220 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:27:14,224 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:27:14.224269', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:14,225 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:27:14.225272', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:14,230 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:27:14,231 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:27:14,231 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:27:14.231827', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:14,240 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:27:14,240 : INFO : resetting layer weights\n",
      "2023-12-06 15:27:14,244 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:27:14.244887', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:27:14,372 : INFO : EPOCH 0: training on 99524 raw words (62818 effective words) took 0.1s, 508361 effective words/s\n",
      "2023-12-06 15:27:14,529 : INFO : EPOCH 1: training on 99524 raw words (62873 effective words) took 0.2s, 411632 effective words/s\n",
      "2023-12-06 15:27:14,680 : INFO : EPOCH 2: training on 99524 raw words (62682 effective words) took 0.1s, 430451 effective words/s\n",
      "2023-12-06 15:27:14,819 : INFO : EPOCH 3: training on 99524 raw words (62599 effective words) took 0.1s, 465455 effective words/s\n",
      "2023-12-06 15:27:14,956 : INFO : EPOCH 4: training on 99524 raw words (62616 effective words) took 0.1s, 470953 effective words/s\n",
      "2023-12-06 15:27:15,093 : INFO : EPOCH 5: training on 99524 raw words (62717 effective words) took 0.1s, 469868 effective words/s\n",
      "2023-12-06 15:27:15,249 : INFO : EPOCH 6: training on 99524 raw words (62651 effective words) took 0.2s, 414806 effective words/s\n",
      "2023-12-06 15:27:15,389 : INFO : EPOCH 7: training on 99524 raw words (62780 effective words) took 0.1s, 464356 effective words/s\n",
      "2023-12-06 15:27:15,525 : INFO : EPOCH 8: training on 99524 raw words (62713 effective words) took 0.1s, 472668 effective words/s\n",
      "2023-12-06 15:27:15,660 : INFO : EPOCH 9: training on 99524 raw words (62686 effective words) took 0.1s, 477538 effective words/s\n",
      "2023-12-06 15:27:15,661 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627135 effective words) took 1.4s, 442652 effective words/s', 'datetime': '2023-12-06T15:27:15.661915', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:27:15,662 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:27:15.662915', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 97%|| 469/486 [1:13:36<02:16,  8.05s/it]2023-12-06 15:27:18,322 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:27:18,322 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:27:18,345 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:27:18,345 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:27:18,350 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:27:18.350534', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:18,351 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:27:18.351535', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:18,356 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:27:18,357 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:27:18,357 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:27:18.357045', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:18,366 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:27:18,366 : INFO : resetting layer weights\n",
      "2023-12-06 15:27:18,370 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:27:18.370579', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:27:18,497 : INFO : EPOCH 0: training on 99524 raw words (62599 effective words) took 0.1s, 509737 effective words/s\n",
      "2023-12-06 15:27:18,655 : INFO : EPOCH 1: training on 99524 raw words (62699 effective words) took 0.2s, 407350 effective words/s\n",
      "2023-12-06 15:27:18,806 : INFO : EPOCH 2: training on 99524 raw words (62767 effective words) took 0.1s, 430176 effective words/s\n",
      "2023-12-06 15:27:18,950 : INFO : EPOCH 3: training on 99524 raw words (62699 effective words) took 0.1s, 449266 effective words/s\n",
      "2023-12-06 15:27:19,077 : INFO : EPOCH 4: training on 99524 raw words (62712 effective words) took 0.1s, 507146 effective words/s\n",
      "2023-12-06 15:27:19,222 : INFO : EPOCH 5: training on 99524 raw words (62814 effective words) took 0.1s, 450039 effective words/s\n",
      "2023-12-06 15:27:19,351 : INFO : EPOCH 6: training on 99524 raw words (62670 effective words) took 0.1s, 503249 effective words/s\n",
      "2023-12-06 15:27:19,488 : INFO : EPOCH 7: training on 99524 raw words (62796 effective words) took 0.1s, 474519 effective words/s\n",
      "2023-12-06 15:27:19,615 : INFO : EPOCH 8: training on 99524 raw words (62651 effective words) took 0.1s, 509157 effective words/s\n",
      "2023-12-06 15:27:19,752 : INFO : EPOCH 9: training on 99524 raw words (62642 effective words) took 0.1s, 472333 effective words/s\n",
      "2023-12-06 15:27:19,753 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627049 effective words) took 1.4s, 453738 effective words/s', 'datetime': '2023-12-06T15:27:19.753341', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:27:19,753 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:27:19.753341', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 97%|| 470/486 [1:13:41<01:49,  6.86s/it]2023-12-06 15:27:22,412 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:27:22,413 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:27:22,434 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:27:22,435 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:27:22,439 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:27:22.439728', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:22,439 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:27:22.439728', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:22,445 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:27:22,445 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:27:22,446 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:27:22.446675', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:22,454 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:27:22,454 : INFO : resetting layer weights\n",
      "2023-12-06 15:27:22,459 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:27:22.459653', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:27:22,583 : INFO : EPOCH 0: training on 99524 raw words (62563 effective words) took 0.1s, 516845 effective words/s\n",
      "2023-12-06 15:27:22,747 : INFO : EPOCH 1: training on 99524 raw words (62678 effective words) took 0.2s, 392391 effective words/s\n",
      "2023-12-06 15:27:22,898 : INFO : EPOCH 2: training on 99524 raw words (62792 effective words) took 0.1s, 430880 effective words/s\n",
      "2023-12-06 15:27:23,042 : INFO : EPOCH 3: training on 99524 raw words (62652 effective words) took 0.1s, 446679 effective words/s\n",
      "2023-12-06 15:27:23,181 : INFO : EPOCH 4: training on 99524 raw words (62806 effective words) took 0.1s, 469346 effective words/s\n",
      "2023-12-06 15:27:23,322 : INFO : EPOCH 5: training on 99524 raw words (62762 effective words) took 0.1s, 458359 effective words/s\n",
      "2023-12-06 15:27:23,494 : INFO : EPOCH 6: training on 99524 raw words (62659 effective words) took 0.2s, 374557 effective words/s\n",
      "2023-12-06 15:27:23,632 : INFO : EPOCH 7: training on 99524 raw words (62755 effective words) took 0.1s, 466999 effective words/s\n",
      "2023-12-06 15:27:23,772 : INFO : EPOCH 8: training on 99524 raw words (62635 effective words) took 0.1s, 463993 effective words/s\n",
      "2023-12-06 15:27:23,911 : INFO : EPOCH 9: training on 99524 raw words (62766 effective words) took 0.1s, 465693 effective words/s\n",
      "2023-12-06 15:27:23,912 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (627068 effective words) took 1.5s, 431597 effective words/s', 'datetime': '2023-12-06T15:27:23.912691', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:27:23,913 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:27:23.913692', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 97%|| 471/486 [1:13:45<01:31,  6.08s/it]2023-12-06 15:27:26,667 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:27:26,668 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:27:26,688 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:27:26,688 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:27:26,694 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:27:26.694098', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:26,694 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:27:26.694098', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:26,700 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:27:26,700 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:27:26,701 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:27:26.701105', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:26,708 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:27:26,709 : INFO : resetting layer weights\n",
      "2023-12-06 15:27:26,713 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:27:26.713126', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:27:26,840 : INFO : EPOCH 0: training on 99524 raw words (62594 effective words) took 0.1s, 507132 effective words/s\n",
      "2023-12-06 15:27:27,000 : INFO : EPOCH 1: training on 99524 raw words (62840 effective words) took 0.2s, 402866 effective words/s\n",
      "2023-12-06 15:27:27,158 : INFO : EPOCH 2: training on 99524 raw words (62655 effective words) took 0.2s, 412761 effective words/s\n",
      "2023-12-06 15:27:27,294 : INFO : EPOCH 3: training on 99524 raw words (62517 effective words) took 0.1s, 475522 effective words/s\n",
      "2023-12-06 15:27:27,431 : INFO : EPOCH 4: training on 99524 raw words (62687 effective words) took 0.1s, 473645 effective words/s\n",
      "2023-12-06 15:27:27,568 : INFO : EPOCH 5: training on 99524 raw words (62926 effective words) took 0.1s, 474126 effective words/s\n",
      "2023-12-06 15:27:27,720 : INFO : EPOCH 6: training on 99524 raw words (62793 effective words) took 0.1s, 425827 effective words/s\n",
      "2023-12-06 15:27:27,856 : INFO : EPOCH 7: training on 99524 raw words (62743 effective words) took 0.1s, 476332 effective words/s\n",
      "2023-12-06 15:27:27,995 : INFO : EPOCH 8: training on 99524 raw words (62517 effective words) took 0.1s, 466259 effective words/s\n",
      "2023-12-06 15:27:28,130 : INFO : EPOCH 9: training on 99524 raw words (62724 effective words) took 0.1s, 476159 effective words/s\n",
      "2023-12-06 15:27:28,265 : INFO : EPOCH 10: training on 99524 raw words (62612 effective words) took 0.1s, 479477 effective words/s\n",
      "2023-12-06 15:27:28,416 : INFO : EPOCH 11: training on 99524 raw words (62807 effective words) took 0.1s, 429414 effective words/s\n",
      "2023-12-06 15:27:28,553 : INFO : EPOCH 12: training on 99524 raw words (62823 effective words) took 0.1s, 472655 effective words/s\n",
      "2023-12-06 15:27:28,688 : INFO : EPOCH 13: training on 99524 raw words (62623 effective words) took 0.1s, 479298 effective words/s\n",
      "2023-12-06 15:27:28,825 : INFO : EPOCH 14: training on 99524 raw words (62908 effective words) took 0.1s, 475969 effective words/s\n",
      "2023-12-06 15:27:28,960 : INFO : EPOCH 15: training on 99524 raw words (62684 effective words) took 0.1s, 482075 effective words/s\n",
      "2023-12-06 15:27:29,094 : INFO : EPOCH 16: training on 99524 raw words (62656 effective words) took 0.1s, 480493 effective words/s\n",
      "2023-12-06 15:27:29,246 : INFO : EPOCH 17: training on 99524 raw words (62690 effective words) took 0.1s, 422929 effective words/s\n",
      "2023-12-06 15:27:29,384 : INFO : EPOCH 18: training on 99524 raw words (62794 effective words) took 0.1s, 471997 effective words/s\n",
      "2023-12-06 15:27:29,518 : INFO : EPOCH 19: training on 99524 raw words (62933 effective words) took 0.1s, 486208 effective words/s\n",
      "2023-12-06 15:27:29,654 : INFO : EPOCH 20: training on 99524 raw words (62772 effective words) took 0.1s, 474565 effective words/s\n",
      "2023-12-06 15:27:29,808 : INFO : EPOCH 21: training on 99524 raw words (63013 effective words) took 0.1s, 421236 effective words/s\n",
      "2023-12-06 15:27:29,948 : INFO : EPOCH 22: training on 99524 raw words (63011 effective words) took 0.1s, 465651 effective words/s\n",
      "2023-12-06 15:27:30,085 : INFO : EPOCH 23: training on 99524 raw words (62777 effective words) took 0.1s, 473351 effective words/s\n",
      "2023-12-06 15:27:30,221 : INFO : EPOCH 24: training on 99524 raw words (62630 effective words) took 0.1s, 474674 effective words/s\n",
      "2023-12-06 15:27:30,379 : INFO : EPOCH 25: training on 99524 raw words (62659 effective words) took 0.2s, 404651 effective words/s\n",
      "2023-12-06 15:27:30,517 : INFO : EPOCH 26: training on 99524 raw words (62953 effective words) took 0.1s, 476008 effective words/s\n",
      "2023-12-06 15:27:30,657 : INFO : EPOCH 27: training on 99524 raw words (62861 effective words) took 0.1s, 461673 effective words/s\n",
      "2023-12-06 15:27:30,792 : INFO : EPOCH 28: training on 99524 raw words (62821 effective words) took 0.1s, 479044 effective words/s\n",
      "2023-12-06 15:27:30,928 : INFO : EPOCH 29: training on 99524 raw words (62647 effective words) took 0.1s, 476700 effective words/s\n",
      "2023-12-06 15:27:30,929 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1882670 effective words) took 4.2s, 446638 effective words/s', 'datetime': '2023-12-06T15:27:30.929229', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:27:30,930 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:27:30.930229', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 97%|| 472/486 [1:13:52<01:29,  6.40s/it]2023-12-06 15:27:33,818 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:27:33,818 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:27:33,839 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:27:33,840 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:27:33,845 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:27:33.845067', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:33,845 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:27:33.845067', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:33,851 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:27:33,852 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:27:33,852 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:27:33.852070', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:33,859 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:27:33,860 : INFO : resetting layer weights\n",
      "2023-12-06 15:27:33,864 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:27:33.864591', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:27:33,989 : INFO : EPOCH 0: training on 99524 raw words (62560 effective words) took 0.1s, 516652 effective words/s\n",
      "2023-12-06 15:27:34,149 : INFO : EPOCH 1: training on 99524 raw words (62715 effective words) took 0.2s, 403652 effective words/s\n",
      "2023-12-06 15:27:34,312 : INFO : EPOCH 2: training on 99524 raw words (62931 effective words) took 0.2s, 404100 effective words/s\n",
      "2023-12-06 15:27:34,450 : INFO : EPOCH 3: training on 99524 raw words (62698 effective words) took 0.1s, 468265 effective words/s\n",
      "2023-12-06 15:27:34,590 : INFO : EPOCH 4: training on 99524 raw words (62604 effective words) took 0.1s, 466767 effective words/s\n",
      "2023-12-06 15:27:34,719 : INFO : EPOCH 5: training on 99524 raw words (62770 effective words) took 0.1s, 500775 effective words/s\n",
      "2023-12-06 15:27:34,856 : INFO : EPOCH 6: training on 99524 raw words (62705 effective words) took 0.1s, 471172 effective words/s\n",
      "2023-12-06 15:27:34,995 : INFO : EPOCH 7: training on 99524 raw words (62779 effective words) took 0.1s, 464804 effective words/s\n",
      "2023-12-06 15:27:35,156 : INFO : EPOCH 8: training on 99524 raw words (62970 effective words) took 0.2s, 400701 effective words/s\n",
      "2023-12-06 15:27:35,293 : INFO : EPOCH 9: training on 99524 raw words (62593 effective words) took 0.1s, 475393 effective words/s\n",
      "2023-12-06 15:27:35,421 : INFO : EPOCH 10: training on 99524 raw words (62800 effective words) took 0.1s, 504660 effective words/s\n",
      "2023-12-06 15:27:35,559 : INFO : EPOCH 11: training on 99524 raw words (62837 effective words) took 0.1s, 471390 effective words/s\n",
      "2023-12-06 15:27:35,714 : INFO : EPOCH 12: training on 99524 raw words (62851 effective words) took 0.2s, 417873 effective words/s\n",
      "2023-12-06 15:27:35,855 : INFO : EPOCH 13: training on 99524 raw words (62616 effective words) took 0.1s, 461551 effective words/s\n",
      "2023-12-06 15:27:35,993 : INFO : EPOCH 14: training on 99524 raw words (62665 effective words) took 0.1s, 464875 effective words/s\n",
      "2023-12-06 15:27:36,130 : INFO : EPOCH 15: training on 99524 raw words (62700 effective words) took 0.1s, 473770 effective words/s\n",
      "2023-12-06 15:27:36,296 : INFO : EPOCH 16: training on 99524 raw words (62625 effective words) took 0.2s, 387963 effective words/s\n",
      "2023-12-06 15:27:36,437 : INFO : EPOCH 17: training on 99524 raw words (62714 effective words) took 0.1s, 459743 effective words/s\n",
      "2023-12-06 15:27:36,574 : INFO : EPOCH 18: training on 99524 raw words (62758 effective words) took 0.1s, 473807 effective words/s\n",
      "2023-12-06 15:27:36,711 : INFO : EPOCH 19: training on 99524 raw words (62770 effective words) took 0.1s, 471652 effective words/s\n",
      "2023-12-06 15:27:36,847 : INFO : EPOCH 20: training on 99524 raw words (62777 effective words) took 0.1s, 472932 effective words/s\n",
      "2023-12-06 15:27:36,985 : INFO : EPOCH 21: training on 99524 raw words (62977 effective words) took 0.1s, 474122 effective words/s\n",
      "2023-12-06 15:27:37,143 : INFO : EPOCH 22: training on 99524 raw words (62764 effective words) took 0.2s, 408933 effective words/s\n",
      "2023-12-06 15:27:37,277 : INFO : EPOCH 23: training on 99524 raw words (62683 effective words) took 0.1s, 482904 effective words/s\n",
      "2023-12-06 15:27:37,416 : INFO : EPOCH 24: training on 99524 raw words (62719 effective words) took 0.1s, 465811 effective words/s\n",
      "2023-12-06 15:27:37,553 : INFO : EPOCH 25: training on 99524 raw words (62835 effective words) took 0.1s, 471586 effective words/s\n",
      "2023-12-06 15:27:37,718 : INFO : EPOCH 26: training on 99524 raw words (62648 effective words) took 0.2s, 388707 effective words/s\n",
      "2023-12-06 15:27:37,855 : INFO : EPOCH 27: training on 99524 raw words (62906 effective words) took 0.1s, 475835 effective words/s\n",
      "2023-12-06 15:27:38,000 : INFO : EPOCH 28: training on 99524 raw words (62761 effective words) took 0.1s, 446861 effective words/s\n",
      "2023-12-06 15:27:38,138 : INFO : EPOCH 29: training on 99524 raw words (62686 effective words) took 0.1s, 468473 effective words/s\n",
      "2023-12-06 15:27:38,139 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1882417 effective words) took 4.3s, 440422 effective words/s', 'datetime': '2023-12-06T15:27:38.139249', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:27:38,139 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:27:38.139249', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 97%|| 473/486 [1:13:59<01:27,  6.72s/it]2023-12-06 15:27:41,290 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:27:41,291 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:27:41,310 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:27:41,311 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:27:41,316 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:27:41.316494', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:41,317 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:27:41.317499', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:41,323 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:27:41,323 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:27:41,324 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:27:41.324045', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:41,333 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:27:41,333 : INFO : resetting layer weights\n",
      "2023-12-06 15:27:41,338 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:27:41.338045', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:27:41,469 : INFO : EPOCH 0: training on 99524 raw words (62663 effective words) took 0.1s, 490546 effective words/s\n",
      "2023-12-06 15:27:41,666 : INFO : EPOCH 1: training on 99524 raw words (62735 effective words) took 0.2s, 324666 effective words/s\n",
      "2023-12-06 15:27:41,837 : INFO : EPOCH 2: training on 99524 raw words (62668 effective words) took 0.2s, 391252 effective words/s\n",
      "2023-12-06 15:27:41,964 : INFO : EPOCH 3: training on 99524 raw words (62511 effective words) took 0.1s, 507036 effective words/s\n",
      "2023-12-06 15:27:42,102 : INFO : EPOCH 4: training on 99524 raw words (62733 effective words) took 0.1s, 470428 effective words/s\n",
      "2023-12-06 15:27:42,241 : INFO : EPOCH 5: training on 99524 raw words (62700 effective words) took 0.1s, 467203 effective words/s\n",
      "2023-12-06 15:27:42,403 : INFO : EPOCH 6: training on 99524 raw words (62675 effective words) took 0.2s, 397431 effective words/s\n",
      "2023-12-06 15:27:42,540 : INFO : EPOCH 7: training on 99524 raw words (62650 effective words) took 0.1s, 470205 effective words/s\n",
      "2023-12-06 15:27:42,683 : INFO : EPOCH 8: training on 99524 raw words (62692 effective words) took 0.1s, 454700 effective words/s\n",
      "2023-12-06 15:27:42,820 : INFO : EPOCH 9: training on 99524 raw words (62620 effective words) took 0.1s, 468357 effective words/s\n",
      "2023-12-06 15:27:42,977 : INFO : EPOCH 10: training on 99524 raw words (62651 effective words) took 0.2s, 410299 effective words/s\n",
      "2023-12-06 15:27:43,117 : INFO : EPOCH 11: training on 99524 raw words (62798 effective words) took 0.1s, 468293 effective words/s\n",
      "2023-12-06 15:27:43,254 : INFO : EPOCH 12: training on 99524 raw words (62707 effective words) took 0.1s, 470339 effective words/s\n",
      "2023-12-06 15:27:43,394 : INFO : EPOCH 13: training on 99524 raw words (62709 effective words) took 0.1s, 460565 effective words/s\n",
      "2023-12-06 15:27:43,534 : INFO : EPOCH 14: training on 99524 raw words (62754 effective words) took 0.1s, 464761 effective words/s\n",
      "2023-12-06 15:27:43,693 : INFO : EPOCH 15: training on 99524 raw words (62677 effective words) took 0.2s, 406931 effective words/s\n",
      "2023-12-06 15:27:43,833 : INFO : EPOCH 16: training on 99524 raw words (62662 effective words) took 0.1s, 459793 effective words/s\n",
      "2023-12-06 15:27:43,971 : INFO : EPOCH 17: training on 99524 raw words (62676 effective words) took 0.1s, 466973 effective words/s\n",
      "2023-12-06 15:27:44,113 : INFO : EPOCH 18: training on 99524 raw words (62640 effective words) took 0.1s, 459869 effective words/s\n",
      "2023-12-06 15:27:44,250 : INFO : EPOCH 19: training on 99524 raw words (62773 effective words) took 0.1s, 470104 effective words/s\n",
      "2023-12-06 15:27:44,388 : INFO : EPOCH 20: training on 99524 raw words (62703 effective words) took 0.1s, 468735 effective words/s\n",
      "2023-12-06 15:27:44,553 : INFO : EPOCH 21: training on 99524 raw words (62830 effective words) took 0.2s, 393055 effective words/s\n",
      "2023-12-06 15:27:44,691 : INFO : EPOCH 22: training on 99524 raw words (62855 effective words) took 0.1s, 467239 effective words/s\n",
      "2023-12-06 15:27:44,830 : INFO : EPOCH 23: training on 99524 raw words (62752 effective words) took 0.1s, 467160 effective words/s\n",
      "2023-12-06 15:27:44,969 : INFO : EPOCH 24: training on 99524 raw words (62925 effective words) took 0.1s, 466022 effective words/s\n",
      "2023-12-06 15:27:45,135 : INFO : EPOCH 25: training on 99524 raw words (62780 effective words) took 0.2s, 388041 effective words/s\n",
      "2023-12-06 15:27:45,277 : INFO : EPOCH 26: training on 99524 raw words (62783 effective words) took 0.1s, 456521 effective words/s\n",
      "2023-12-06 15:27:45,415 : INFO : EPOCH 27: training on 99524 raw words (62911 effective words) took 0.1s, 469039 effective words/s\n",
      "2023-12-06 15:27:45,554 : INFO : EPOCH 28: training on 99524 raw words (62696 effective words) took 0.1s, 468037 effective words/s\n",
      "2023-12-06 15:27:45,722 : INFO : EPOCH 29: training on 99524 raw words (62730 effective words) took 0.2s, 382037 effective words/s\n",
      "2023-12-06 15:27:45,723 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1881659 effective words) took 4.4s, 429097 effective words/s', 'datetime': '2023-12-06T15:27:45.723315', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:27:45,724 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:27:45.724319', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 98%|| 474/486 [1:14:07<01:24,  7.05s/it]2023-12-06 15:27:49,094 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:27:49,094 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:27:49,116 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:27:49,117 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:27:49,121 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:27:49.121316', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:49,122 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:27:49.122825', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:49,128 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:27:49,128 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:27:49,129 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:27:49.128340', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:49,137 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:27:49,138 : INFO : resetting layer weights\n",
      "2023-12-06 15:27:49,142 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:27:49.142344', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:27:49,269 : INFO : EPOCH 0: training on 99524 raw words (62714 effective words) took 0.1s, 509268 effective words/s\n",
      "2023-12-06 15:27:49,433 : INFO : EPOCH 1: training on 99524 raw words (62862 effective words) took 0.2s, 393219 effective words/s\n",
      "2023-12-06 15:27:49,597 : INFO : EPOCH 2: training on 99524 raw words (62867 effective words) took 0.2s, 401417 effective words/s\n",
      "2023-12-06 15:27:49,724 : INFO : EPOCH 3: training on 99524 raw words (62655 effective words) took 0.1s, 507713 effective words/s\n",
      "2023-12-06 15:27:49,860 : INFO : EPOCH 4: training on 99524 raw words (62769 effective words) took 0.1s, 474903 effective words/s\n",
      "2023-12-06 15:27:49,990 : INFO : EPOCH 5: training on 99524 raw words (62615 effective words) took 0.1s, 502071 effective words/s\n",
      "2023-12-06 15:27:50,129 : INFO : EPOCH 6: training on 99524 raw words (62706 effective words) took 0.1s, 465814 effective words/s\n",
      "2023-12-06 15:27:50,278 : INFO : EPOCH 7: training on 99524 raw words (62756 effective words) took 0.1s, 431871 effective words/s\n",
      "2023-12-06 15:27:50,416 : INFO : EPOCH 8: training on 99524 raw words (62792 effective words) took 0.1s, 469070 effective words/s\n",
      "2023-12-06 15:27:50,550 : INFO : EPOCH 9: training on 99524 raw words (62731 effective words) took 0.1s, 481965 effective words/s\n",
      "2023-12-06 15:27:50,687 : INFO : EPOCH 10: training on 99524 raw words (62582 effective words) took 0.1s, 473468 effective words/s\n",
      "2023-12-06 15:27:50,823 : INFO : EPOCH 11: training on 99524 raw words (62722 effective words) took 0.1s, 474833 effective words/s\n",
      "2023-12-06 15:27:50,979 : INFO : EPOCH 12: training on 99524 raw words (62769 effective words) took 0.2s, 414878 effective words/s\n",
      "2023-12-06 15:27:51,115 : INFO : EPOCH 13: training on 99524 raw words (62635 effective words) took 0.1s, 477719 effective words/s\n",
      "2023-12-06 15:27:51,255 : INFO : EPOCH 14: training on 99524 raw words (62686 effective words) took 0.1s, 460790 effective words/s\n",
      "2023-12-06 15:27:51,392 : INFO : EPOCH 15: training on 99524 raw words (62586 effective words) took 0.1s, 471422 effective words/s\n",
      "2023-12-06 15:27:51,532 : INFO : EPOCH 16: training on 99524 raw words (62833 effective words) took 0.1s, 463907 effective words/s\n",
      "2023-12-06 15:27:51,669 : INFO : EPOCH 17: training on 99524 raw words (62809 effective words) took 0.1s, 471866 effective words/s\n",
      "2023-12-06 15:27:51,823 : INFO : EPOCH 18: training on 99524 raw words (62716 effective words) took 0.1s, 419253 effective words/s\n",
      "2023-12-06 15:27:51,960 : INFO : EPOCH 19: training on 99524 raw words (62769 effective words) took 0.1s, 472237 effective words/s\n",
      "2023-12-06 15:27:52,098 : INFO : EPOCH 20: training on 99524 raw words (62752 effective words) took 0.1s, 470610 effective words/s\n",
      "2023-12-06 15:27:52,235 : INFO : EPOCH 21: training on 99524 raw words (62796 effective words) took 0.1s, 472462 effective words/s\n",
      "2023-12-06 15:27:52,386 : INFO : EPOCH 22: training on 99524 raw words (62916 effective words) took 0.1s, 431909 effective words/s\n",
      "2023-12-06 15:27:52,528 : INFO : EPOCH 23: training on 99524 raw words (62726 effective words) took 0.1s, 456254 effective words/s\n",
      "2023-12-06 15:27:52,662 : INFO : EPOCH 24: training on 99524 raw words (62777 effective words) took 0.1s, 482040 effective words/s\n",
      "2023-12-06 15:27:52,798 : INFO : EPOCH 25: training on 99524 raw words (62630 effective words) took 0.1s, 473131 effective words/s\n",
      "2023-12-06 15:27:52,956 : INFO : EPOCH 26: training on 99524 raw words (62802 effective words) took 0.2s, 410967 effective words/s\n",
      "2023-12-06 15:27:53,092 : INFO : EPOCH 27: training on 99524 raw words (62744 effective words) took 0.1s, 475723 effective words/s\n",
      "2023-12-06 15:27:53,234 : INFO : EPOCH 28: training on 99524 raw words (62718 effective words) took 0.1s, 456860 effective words/s\n",
      "2023-12-06 15:27:53,372 : INFO : EPOCH 29: training on 99524 raw words (62733 effective words) took 0.1s, 469223 effective words/s\n",
      "2023-12-06 15:27:53,527 : INFO : EPOCH 30: training on 99524 raw words (62822 effective words) took 0.2s, 418672 effective words/s\n",
      "2023-12-06 15:27:53,667 : INFO : EPOCH 31: training on 99524 raw words (62785 effective words) took 0.1s, 461972 effective words/s\n",
      "2023-12-06 15:27:53,803 : INFO : EPOCH 32: training on 99524 raw words (62659 effective words) took 0.1s, 472645 effective words/s\n",
      "2023-12-06 15:27:53,939 : INFO : EPOCH 33: training on 99524 raw words (62904 effective words) took 0.1s, 482278 effective words/s\n",
      "2023-12-06 15:27:54,115 : INFO : EPOCH 34: training on 99524 raw words (62820 effective words) took 0.2s, 366478 effective words/s\n",
      "2023-12-06 15:27:54,251 : INFO : EPOCH 35: training on 99524 raw words (62840 effective words) took 0.1s, 475534 effective words/s\n",
      "2023-12-06 15:27:54,388 : INFO : EPOCH 36: training on 99524 raw words (62641 effective words) took 0.1s, 468975 effective words/s\n",
      "2023-12-06 15:27:54,526 : INFO : EPOCH 37: training on 99524 raw words (62758 effective words) took 0.1s, 471571 effective words/s\n",
      "2023-12-06 15:27:54,685 : INFO : EPOCH 38: training on 99524 raw words (62599 effective words) took 0.2s, 403584 effective words/s\n",
      "2023-12-06 15:27:54,825 : INFO : EPOCH 39: training on 99524 raw words (62733 effective words) took 0.1s, 461769 effective words/s\n",
      "2023-12-06 15:27:54,966 : INFO : EPOCH 40: training on 99524 raw words (62723 effective words) took 0.1s, 459536 effective words/s\n",
      "2023-12-06 15:27:55,102 : INFO : EPOCH 41: training on 99524 raw words (62953 effective words) took 0.1s, 478342 effective words/s\n",
      "2023-12-06 15:27:55,254 : INFO : EPOCH 42: training on 99524 raw words (62657 effective words) took 0.1s, 424749 effective words/s\n",
      "2023-12-06 15:27:55,393 : INFO : EPOCH 43: training on 99524 raw words (62714 effective words) took 0.1s, 466116 effective words/s\n",
      "2023-12-06 15:27:55,530 : INFO : EPOCH 44: training on 99524 raw words (62560 effective words) took 0.1s, 470244 effective words/s\n",
      "2023-12-06 15:27:55,690 : INFO : EPOCH 45: training on 99524 raw words (62811 effective words) took 0.2s, 403484 effective words/s\n",
      "2023-12-06 15:27:55,857 : INFO : EPOCH 46: training on 99524 raw words (62577 effective words) took 0.2s, 389733 effective words/s\n",
      "2023-12-06 15:27:55,994 : INFO : EPOCH 47: training on 99524 raw words (62627 effective words) took 0.1s, 474724 effective words/s\n",
      "2023-12-06 15:27:56,145 : INFO : EPOCH 48: training on 99524 raw words (62732 effective words) took 0.1s, 427444 effective words/s\n",
      "2023-12-06 15:27:56,282 : INFO : EPOCH 49: training on 99524 raw words (62747 effective words) took 0.1s, 472746 effective words/s\n",
      "2023-12-06 15:27:56,283 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136830 effective words) took 7.1s, 439292 effective words/s', 'datetime': '2023-12-06T15:27:56.283212', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:27:56,284 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:27:56.284215', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 98%|| 475/486 [1:14:18<01:28,  8.08s/it]2023-12-06 15:27:59,600 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:27:59,601 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:27:59,622 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:27:59,623 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:27:59,628 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:27:59.628732', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:59,629 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:27:59.629238', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:59,633 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:27:59,634 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:27:59,634 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:27:59.634758', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:27:59,643 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:27:59,644 : INFO : resetting layer weights\n",
      "2023-12-06 15:27:59,647 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:27:59.647967', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:27:59,773 : INFO : EPOCH 0: training on 99524 raw words (62679 effective words) took 0.1s, 516425 effective words/s\n",
      "2023-12-06 15:27:59,928 : INFO : EPOCH 1: training on 99524 raw words (62711 effective words) took 0.2s, 414788 effective words/s\n",
      "2023-12-06 15:28:00,081 : INFO : EPOCH 2: training on 99524 raw words (62930 effective words) took 0.1s, 427201 effective words/s\n",
      "2023-12-06 15:28:00,220 : INFO : EPOCH 3: training on 99524 raw words (62565 effective words) took 0.1s, 466750 effective words/s\n",
      "2023-12-06 15:28:00,354 : INFO : EPOCH 4: training on 99524 raw words (62591 effective words) took 0.1s, 481725 effective words/s\n",
      "2023-12-06 15:28:00,490 : INFO : EPOCH 5: training on 99524 raw words (62638 effective words) took 0.1s, 476503 effective words/s\n",
      "2023-12-06 15:28:00,627 : INFO : EPOCH 6: training on 99524 raw words (62794 effective words) took 0.1s, 476552 effective words/s\n",
      "2023-12-06 15:28:00,781 : INFO : EPOCH 7: training on 99524 raw words (62705 effective words) took 0.2s, 413888 effective words/s\n",
      "2023-12-06 15:28:00,921 : INFO : EPOCH 8: training on 99524 raw words (62816 effective words) took 0.1s, 465449 effective words/s\n",
      "2023-12-06 15:28:01,057 : INFO : EPOCH 9: training on 99524 raw words (62745 effective words) took 0.1s, 474570 effective words/s\n",
      "2023-12-06 15:28:01,194 : INFO : EPOCH 10: training on 99524 raw words (62539 effective words) took 0.1s, 475013 effective words/s\n",
      "2023-12-06 15:28:01,329 : INFO : EPOCH 11: training on 99524 raw words (62775 effective words) took 0.1s, 477078 effective words/s\n",
      "2023-12-06 15:28:01,493 : INFO : EPOCH 12: training on 99524 raw words (62869 effective words) took 0.2s, 393297 effective words/s\n",
      "2023-12-06 15:28:01,628 : INFO : EPOCH 13: training on 99524 raw words (62603 effective words) took 0.1s, 477094 effective words/s\n",
      "2023-12-06 15:28:01,765 : INFO : EPOCH 14: training on 99524 raw words (62831 effective words) took 0.1s, 471825 effective words/s\n",
      "2023-12-06 15:28:01,903 : INFO : EPOCH 15: training on 99524 raw words (62723 effective words) took 0.1s, 473752 effective words/s\n",
      "2023-12-06 15:28:02,057 : INFO : EPOCH 16: training on 99524 raw words (62750 effective words) took 0.2s, 417958 effective words/s\n",
      "2023-12-06 15:28:02,194 : INFO : EPOCH 17: training on 99524 raw words (62656 effective words) took 0.1s, 467924 effective words/s\n",
      "2023-12-06 15:28:02,330 : INFO : EPOCH 18: training on 99524 raw words (62654 effective words) took 0.1s, 476398 effective words/s\n",
      "2023-12-06 15:28:02,468 : INFO : EPOCH 19: training on 99524 raw words (62887 effective words) took 0.1s, 472131 effective words/s\n",
      "2023-12-06 15:28:02,614 : INFO : EPOCH 20: training on 99524 raw words (62825 effective words) took 0.1s, 443006 effective words/s\n",
      "2023-12-06 15:28:02,763 : INFO : EPOCH 21: training on 99524 raw words (62876 effective words) took 0.1s, 441006 effective words/s\n",
      "2023-12-06 15:28:02,898 : INFO : EPOCH 22: training on 99524 raw words (62779 effective words) took 0.1s, 480849 effective words/s\n",
      "2023-12-06 15:28:03,036 : INFO : EPOCH 23: training on 99524 raw words (62894 effective words) took 0.1s, 473400 effective words/s\n",
      "2023-12-06 15:28:03,173 : INFO : EPOCH 24: training on 99524 raw words (62735 effective words) took 0.1s, 472065 effective words/s\n",
      "2023-12-06 15:28:03,300 : INFO : EPOCH 25: training on 99524 raw words (62736 effective words) took 0.1s, 509466 effective words/s\n",
      "2023-12-06 15:28:03,436 : INFO : EPOCH 26: training on 99524 raw words (62849 effective words) took 0.1s, 478419 effective words/s\n",
      "2023-12-06 15:28:03,592 : INFO : EPOCH 27: training on 99524 raw words (62836 effective words) took 0.2s, 415833 effective words/s\n",
      "2023-12-06 15:28:03,728 : INFO : EPOCH 28: training on 99524 raw words (62712 effective words) took 0.1s, 474947 effective words/s\n",
      "2023-12-06 15:28:03,869 : INFO : EPOCH 29: training on 99524 raw words (62798 effective words) took 0.1s, 459298 effective words/s\n",
      "2023-12-06 15:28:04,008 : INFO : EPOCH 30: training on 99524 raw words (62649 effective words) took 0.1s, 463912 effective words/s\n",
      "2023-12-06 15:28:04,144 : INFO : EPOCH 31: training on 99524 raw words (62624 effective words) took 0.1s, 474528 effective words/s\n",
      "2023-12-06 15:28:04,280 : INFO : EPOCH 32: training on 99524 raw words (62808 effective words) took 0.1s, 477029 effective words/s\n",
      "2023-12-06 15:28:04,453 : INFO : EPOCH 33: training on 99524 raw words (62888 effective words) took 0.2s, 372919 effective words/s\n",
      "2023-12-06 15:28:04,589 : INFO : EPOCH 34: training on 99524 raw words (62843 effective words) took 0.1s, 476992 effective words/s\n",
      "2023-12-06 15:28:04,725 : INFO : EPOCH 35: training on 99524 raw words (62816 effective words) took 0.1s, 478650 effective words/s\n",
      "2023-12-06 15:28:04,860 : INFO : EPOCH 36: training on 99524 raw words (62680 effective words) took 0.1s, 476277 effective words/s\n",
      "2023-12-06 15:28:04,996 : INFO : EPOCH 37: training on 99524 raw words (62744 effective words) took 0.1s, 474815 effective words/s\n",
      "2023-12-06 15:28:05,152 : INFO : EPOCH 38: training on 99524 raw words (62536 effective words) took 0.2s, 413214 effective words/s\n",
      "2023-12-06 15:28:05,297 : INFO : EPOCH 39: training on 99524 raw words (62637 effective words) took 0.1s, 451396 effective words/s\n",
      "2023-12-06 15:28:05,440 : INFO : EPOCH 40: training on 99524 raw words (62631 effective words) took 0.1s, 453488 effective words/s\n",
      "2023-12-06 15:28:05,583 : INFO : EPOCH 41: training on 99524 raw words (62743 effective words) took 0.1s, 454893 effective words/s\n",
      "2023-12-06 15:28:05,729 : INFO : EPOCH 42: training on 99524 raw words (62750 effective words) took 0.1s, 445404 effective words/s\n",
      "2023-12-06 15:28:05,865 : INFO : EPOCH 43: training on 99524 raw words (62784 effective words) took 0.1s, 476305 effective words/s\n",
      "2023-12-06 15:28:06,026 : INFO : EPOCH 44: training on 99524 raw words (62560 effective words) took 0.2s, 399771 effective words/s\n",
      "2023-12-06 15:28:06,164 : INFO : EPOCH 45: training on 99524 raw words (62596 effective words) took 0.1s, 475303 effective words/s\n",
      "2023-12-06 15:28:06,306 : INFO : EPOCH 46: training on 99524 raw words (62762 effective words) took 0.1s, 457290 effective words/s\n",
      "2023-12-06 15:28:06,442 : INFO : EPOCH 47: training on 99524 raw words (62675 effective words) took 0.1s, 475109 effective words/s\n",
      "2023-12-06 15:28:06,601 : INFO : EPOCH 48: training on 99524 raw words (62784 effective words) took 0.2s, 405055 effective words/s\n",
      "2023-12-06 15:28:06,739 : INFO : EPOCH 49: training on 99524 raw words (62746 effective words) took 0.1s, 466583 effective words/s\n",
      "2023-12-06 15:28:06,740 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136757 effective words) took 7.1s, 442262 effective words/s', 'datetime': '2023-12-06T15:28:06.740883', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:28:06,741 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:28:06.741886', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 98%|| 476/486 [1:14:28<01:28,  8.87s/it]2023-12-06 15:28:10,308 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:28:10,308 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:28:10,331 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:28:10,332 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:28:10,337 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 retains 1509 unique words (21.18% of original 7125, drops 5616)', 'datetime': '2023-12-06T15:28:10.337297', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:28:10,337 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=7 leaves 88436 word corpus (88.86% of original 99524, drops 11088)', 'datetime': '2023-12-06T15:28:10.337297', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:28:10,342 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:28:10,342 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:28:10,343 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 58412.99681199358 word corpus (66.1%% of prior 88436)', 'datetime': '2023-12-06T15:28:10.343816', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:28:10,352 : INFO : estimated required memory for 1509 words and 200 dimensions: 7481900 bytes\n",
      "2023-12-06 15:28:10,353 : INFO : resetting layer weights\n",
      "2023-12-06 15:28:10,357 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1509 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:28:10.357608', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:28:10,483 : INFO : EPOCH 0: training on 99524 raw words (62758 effective words) took 0.1s, 512198 effective words/s\n",
      "2023-12-06 15:28:10,640 : INFO : EPOCH 1: training on 99524 raw words (62643 effective words) took 0.2s, 408751 effective words/s\n",
      "2023-12-06 15:28:10,797 : INFO : EPOCH 2: training on 99524 raw words (62812 effective words) took 0.1s, 419577 effective words/s\n",
      "2023-12-06 15:28:10,937 : INFO : EPOCH 3: training on 99524 raw words (62709 effective words) took 0.1s, 462915 effective words/s\n",
      "2023-12-06 15:28:11,066 : INFO : EPOCH 4: training on 99524 raw words (62760 effective words) took 0.1s, 502803 effective words/s\n",
      "2023-12-06 15:28:11,193 : INFO : EPOCH 5: training on 99524 raw words (62670 effective words) took 0.1s, 506360 effective words/s\n",
      "2023-12-06 15:28:11,322 : INFO : EPOCH 6: training on 99524 raw words (62657 effective words) took 0.1s, 504775 effective words/s\n",
      "2023-12-06 15:28:11,486 : INFO : EPOCH 7: training on 99524 raw words (62741 effective words) took 0.2s, 393459 effective words/s\n",
      "2023-12-06 15:28:11,625 : INFO : EPOCH 8: training on 99524 raw words (62764 effective words) took 0.1s, 463727 effective words/s\n",
      "2023-12-06 15:28:11,753 : INFO : EPOCH 9: training on 99524 raw words (62655 effective words) took 0.1s, 505724 effective words/s\n",
      "2023-12-06 15:28:11,882 : INFO : EPOCH 10: training on 99524 raw words (62619 effective words) took 0.1s, 502056 effective words/s\n",
      "2023-12-06 15:28:12,046 : INFO : EPOCH 11: training on 99524 raw words (62856 effective words) took 0.2s, 392952 effective words/s\n",
      "2023-12-06 15:28:12,185 : INFO : EPOCH 12: training on 99524 raw words (62539 effective words) took 0.1s, 465522 effective words/s\n",
      "2023-12-06 15:28:12,314 : INFO : EPOCH 13: training on 99524 raw words (62728 effective words) took 0.1s, 502876 effective words/s\n",
      "2023-12-06 15:28:12,444 : INFO : EPOCH 14: training on 99524 raw words (62742 effective words) took 0.1s, 498957 effective words/s\n",
      "2023-12-06 15:28:12,591 : INFO : EPOCH 15: training on 99524 raw words (62860 effective words) took 0.1s, 441648 effective words/s\n",
      "2023-12-06 15:28:12,730 : INFO : EPOCH 16: training on 99524 raw words (62779 effective words) took 0.1s, 466433 effective words/s\n",
      "2023-12-06 15:28:12,858 : INFO : EPOCH 17: training on 99524 raw words (62708 effective words) took 0.1s, 504975 effective words/s\n",
      "2023-12-06 15:28:12,998 : INFO : EPOCH 18: training on 99524 raw words (62696 effective words) took 0.1s, 461019 effective words/s\n",
      "2023-12-06 15:28:13,144 : INFO : EPOCH 19: training on 99524 raw words (62777 effective words) took 0.1s, 442900 effective words/s\n",
      "2023-12-06 15:28:13,290 : INFO : EPOCH 20: training on 99524 raw words (62794 effective words) took 0.1s, 452237 effective words/s\n",
      "2023-12-06 15:28:13,430 : INFO : EPOCH 21: training on 99524 raw words (62855 effective words) took 0.1s, 464387 effective words/s\n",
      "2023-12-06 15:28:13,570 : INFO : EPOCH 22: training on 99524 raw words (62749 effective words) took 0.1s, 465093 effective words/s\n",
      "2023-12-06 15:28:13,720 : INFO : EPOCH 23: training on 99524 raw words (62764 effective words) took 0.1s, 428296 effective words/s\n",
      "2023-12-06 15:28:13,868 : INFO : EPOCH 24: training on 99524 raw words (62806 effective words) took 0.1s, 438969 effective words/s\n",
      "2023-12-06 15:28:14,011 : INFO : EPOCH 25: training on 99524 raw words (62609 effective words) took 0.1s, 450906 effective words/s\n",
      "2023-12-06 15:28:14,138 : INFO : EPOCH 26: training on 99524 raw words (62851 effective words) took 0.1s, 513606 effective words/s\n",
      "2023-12-06 15:28:14,279 : INFO : EPOCH 27: training on 99524 raw words (63042 effective words) took 0.1s, 463752 effective words/s\n",
      "2023-12-06 15:28:14,420 : INFO : EPOCH 28: training on 99524 raw words (62696 effective words) took 0.1s, 459108 effective words/s\n",
      "2023-12-06 15:28:14,586 : INFO : EPOCH 29: training on 99524 raw words (62718 effective words) took 0.2s, 388317 effective words/s\n",
      "2023-12-06 15:28:14,724 : INFO : EPOCH 30: training on 99524 raw words (62631 effective words) took 0.1s, 464151 effective words/s\n",
      "2023-12-06 15:28:14,865 : INFO : EPOCH 31: training on 99524 raw words (62577 effective words) took 0.1s, 459659 effective words/s\n",
      "2023-12-06 15:28:15,002 : INFO : EPOCH 32: training on 99524 raw words (62808 effective words) took 0.1s, 472730 effective words/s\n",
      "2023-12-06 15:28:15,183 : INFO : EPOCH 33: training on 99524 raw words (62855 effective words) took 0.2s, 356689 effective words/s\n",
      "2023-12-06 15:28:15,325 : INFO : EPOCH 34: training on 99524 raw words (62735 effective words) took 0.1s, 455097 effective words/s\n",
      "2023-12-06 15:28:15,463 : INFO : EPOCH 35: training on 99524 raw words (62736 effective words) took 0.1s, 469482 effective words/s\n",
      "2023-12-06 15:28:15,601 : INFO : EPOCH 36: training on 99524 raw words (62762 effective words) took 0.1s, 467149 effective words/s\n",
      "2023-12-06 15:28:15,744 : INFO : EPOCH 37: training on 99524 raw words (62688 effective words) took 0.1s, 453922 effective words/s\n",
      "2023-12-06 15:28:15,916 : INFO : EPOCH 38: training on 99524 raw words (62637 effective words) took 0.2s, 374369 effective words/s\n",
      "2023-12-06 15:28:16,061 : INFO : EPOCH 39: training on 99524 raw words (62716 effective words) took 0.1s, 446125 effective words/s\n",
      "2023-12-06 15:28:16,202 : INFO : EPOCH 40: training on 99524 raw words (62691 effective words) took 0.1s, 456272 effective words/s\n",
      "2023-12-06 15:28:16,341 : INFO : EPOCH 41: training on 99524 raw words (62838 effective words) took 0.1s, 469232 effective words/s\n",
      "2023-12-06 15:28:16,511 : INFO : EPOCH 42: training on 99524 raw words (62586 effective words) took 0.2s, 377272 effective words/s\n",
      "2023-12-06 15:28:16,650 : INFO : EPOCH 43: training on 99524 raw words (62815 effective words) took 0.1s, 467502 effective words/s\n",
      "2023-12-06 15:28:16,795 : INFO : EPOCH 44: training on 99524 raw words (62720 effective words) took 0.1s, 444657 effective words/s\n",
      "2023-12-06 15:28:16,936 : INFO : EPOCH 45: training on 99524 raw words (62702 effective words) took 0.1s, 460468 effective words/s\n",
      "2023-12-06 15:28:17,093 : INFO : EPOCH 46: training on 99524 raw words (62686 effective words) took 0.2s, 408289 effective words/s\n",
      "2023-12-06 15:28:17,232 : INFO : EPOCH 47: training on 99524 raw words (62665 effective words) took 0.1s, 466087 effective words/s\n",
      "2023-12-06 15:28:17,371 : INFO : EPOCH 48: training on 99524 raw words (62736 effective words) took 0.1s, 465284 effective words/s\n",
      "2023-12-06 15:28:17,512 : INFO : EPOCH 49: training on 99524 raw words (62601 effective words) took 0.1s, 460913 effective words/s\n",
      "2023-12-06 15:28:17,512 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3136542 effective words) took 7.2s, 438381 effective words/s', 'datetime': '2023-12-06T15:28:17.512306', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:28:17,513 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc7,s0.001,t3>', 'datetime': '2023-12-06T15:28:17.513309', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 98%|| 477/486 [1:14:40<01:26,  9.56s/it]2023-12-06 15:28:21,463 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:28:21,463 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:28:21,484 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:28:21,485 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:28:21,489 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:28:21.489137', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:28:21,490 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:28:21.490287', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:28:21,495 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:28:21,496 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:28:21,496 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:28:21.496271', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:28:21,502 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:28:21,503 : INFO : resetting layer weights\n",
      "2023-12-06 15:28:21,506 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:28:21.506949', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:28:21,633 : INFO : EPOCH 0: training on 99524 raw words (60467 effective words) took 0.1s, 495205 effective words/s\n",
      "2023-12-06 15:28:21,788 : INFO : EPOCH 1: training on 99524 raw words (60501 effective words) took 0.2s, 402087 effective words/s\n",
      "2023-12-06 15:28:21,970 : INFO : EPOCH 2: training on 99524 raw words (60454 effective words) took 0.1s, 404462 effective words/s\n",
      "2023-12-06 15:28:22,098 : INFO : EPOCH 3: training on 99524 raw words (60303 effective words) took 0.1s, 494037 effective words/s\n",
      "2023-12-06 15:28:22,232 : INFO : EPOCH 4: training on 99524 raw words (60305 effective words) took 0.1s, 464025 effective words/s\n",
      "2023-12-06 15:28:22,368 : INFO : EPOCH 5: training on 99524 raw words (60298 effective words) took 0.1s, 459514 effective words/s\n",
      "2023-12-06 15:28:22,503 : INFO : EPOCH 6: training on 99524 raw words (60379 effective words) took 0.1s, 458942 effective words/s\n",
      "2023-12-06 15:28:22,659 : INFO : EPOCH 7: training on 99524 raw words (60441 effective words) took 0.2s, 401239 effective words/s\n",
      "2023-12-06 15:28:22,796 : INFO : EPOCH 8: training on 99524 raw words (60492 effective words) took 0.1s, 450271 effective words/s\n",
      "2023-12-06 15:28:22,933 : INFO : EPOCH 9: training on 99524 raw words (60546 effective words) took 0.1s, 456637 effective words/s\n",
      "2023-12-06 15:28:22,934 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604186 effective words) took 1.4s, 423485 effective words/s', 'datetime': '2023-12-06T15:28:22.934618', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:28:22,935 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:28:22.935621', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 98%|| 478/486 [1:14:44<01:03,  7.92s/it]2023-12-06 15:28:25,574 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:28:25,574 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:28:25,596 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:28:25,597 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:28:25,601 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:28:25.601090', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:28:25,602 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:28:25.602095', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:28:25,606 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:28:25,607 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:28:25,607 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:28:25.607094', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:28:25,614 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:28:25,614 : INFO : resetting layer weights\n",
      "2023-12-06 15:28:25,617 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:28:25.617646', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:28:25,742 : INFO : EPOCH 0: training on 99524 raw words (60366 effective words) took 0.1s, 502345 effective words/s\n",
      "2023-12-06 15:28:25,896 : INFO : EPOCH 1: training on 99524 raw words (60538 effective words) took 0.1s, 404005 effective words/s\n",
      "2023-12-06 15:28:26,050 : INFO : EPOCH 2: training on 99524 raw words (60498 effective words) took 0.1s, 408053 effective words/s\n",
      "2023-12-06 15:28:26,188 : INFO : EPOCH 3: training on 99524 raw words (60349 effective words) took 0.1s, 450793 effective words/s\n",
      "2023-12-06 15:28:26,315 : INFO : EPOCH 4: training on 99524 raw words (60434 effective words) took 0.1s, 490225 effective words/s\n",
      "2023-12-06 15:28:26,442 : INFO : EPOCH 5: training on 99524 raw words (60314 effective words) took 0.1s, 490448 effective words/s\n",
      "2023-12-06 15:28:26,578 : INFO : EPOCH 6: training on 99524 raw words (60409 effective words) took 0.1s, 460262 effective words/s\n",
      "2023-12-06 15:28:26,723 : INFO : EPOCH 7: training on 99524 raw words (60356 effective words) took 0.1s, 427577 effective words/s\n",
      "2023-12-06 15:28:26,859 : INFO : EPOCH 8: training on 99524 raw words (60445 effective words) took 0.1s, 458600 effective words/s\n",
      "2023-12-06 15:28:26,987 : INFO : EPOCH 9: training on 99524 raw words (60334 effective words) took 0.1s, 489686 effective words/s\n",
      "2023-12-06 15:28:26,987 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604043 effective words) took 1.4s, 440912 effective words/s', 'datetime': '2023-12-06T15:28:26.987788', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:28:26,989 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:28:26.989109', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 99%|| 479/486 [1:14:48<00:47,  6.79s/it]2023-12-06 15:28:29,716 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:28:29,717 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:28:29,737 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:28:29,738 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:28:29,742 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:28:29.742675', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:28:29,743 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:28:29.743680', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:28:29,747 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:28:29,748 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:28:29,748 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:28:29.748679', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:28:29,755 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:28:29,756 : INFO : resetting layer weights\n",
      "2023-12-06 15:28:29,760 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:28:29.760821', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:28:29,887 : INFO : EPOCH 0: training on 99524 raw words (60517 effective words) took 0.1s, 497497 effective words/s\n",
      "2023-12-06 15:28:30,046 : INFO : EPOCH 1: training on 99524 raw words (60538 effective words) took 0.2s, 388124 effective words/s\n",
      "2023-12-06 15:28:30,214 : INFO : EPOCH 2: training on 99524 raw words (60326 effective words) took 0.2s, 374405 effective words/s\n",
      "2023-12-06 15:28:30,353 : INFO : EPOCH 3: training on 99524 raw words (60223 effective words) took 0.1s, 444923 effective words/s\n",
      "2023-12-06 15:28:30,482 : INFO : EPOCH 4: training on 99524 raw words (60381 effective words) took 0.1s, 488968 effective words/s\n",
      "2023-12-06 15:28:30,621 : INFO : EPOCH 5: training on 99524 raw words (60368 effective words) took 0.1s, 446781 effective words/s\n",
      "2023-12-06 15:28:30,788 : INFO : EPOCH 6: training on 99524 raw words (60338 effective words) took 0.2s, 370460 effective words/s\n",
      "2023-12-06 15:28:30,916 : INFO : EPOCH 7: training on 99524 raw words (60451 effective words) took 0.1s, 485867 effective words/s\n",
      "2023-12-06 15:28:31,046 : INFO : EPOCH 8: training on 99524 raw words (60396 effective words) took 0.1s, 482081 effective words/s\n",
      "2023-12-06 15:28:31,175 : INFO : EPOCH 9: training on 99524 raw words (60485 effective words) took 0.1s, 484331 effective words/s\n",
      "2023-12-06 15:28:31,176 : INFO : Doc2Vec lifecycle event {'msg': 'training on 995240 raw words (604023 effective words) took 1.4s, 426797 effective words/s', 'datetime': '2023-12-06T15:28:31.176590', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:28:31,177 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:28:31.177590', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 99%|| 480/486 [1:14:52<00:36,  6.02s/it]2023-12-06 15:28:33,959 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:28:33,959 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:28:33,980 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:28:33,982 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:28:33,985 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:28:33.985988', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:28:33,986 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:28:33.986988', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:28:33,990 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:28:33,990 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:28:33,991 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:28:33.991988', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:28:33,997 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:28:33,998 : INFO : resetting layer weights\n",
      "2023-12-06 15:28:34,002 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:28:34.002988', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:28:34,128 : INFO : EPOCH 0: training on 99524 raw words (60265 effective words) took 0.1s, 491806 effective words/s\n",
      "2023-12-06 15:28:34,290 : INFO : EPOCH 1: training on 99524 raw words (60418 effective words) took 0.2s, 387133 effective words/s\n",
      "2023-12-06 15:28:34,454 : INFO : EPOCH 2: training on 99524 raw words (60391 effective words) took 0.1s, 423929 effective words/s\n",
      "2023-12-06 15:28:34,592 : INFO : EPOCH 3: training on 99524 raw words (60236 effective words) took 0.1s, 450274 effective words/s\n",
      "2023-12-06 15:28:34,728 : INFO : EPOCH 4: training on 99524 raw words (60512 effective words) took 0.1s, 459176 effective words/s\n",
      "2023-12-06 15:28:34,865 : INFO : EPOCH 5: training on 99524 raw words (60363 effective words) took 0.1s, 455654 effective words/s\n",
      "2023-12-06 15:28:35,023 : INFO : EPOCH 6: training on 99524 raw words (60423 effective words) took 0.2s, 392232 effective words/s\n",
      "2023-12-06 15:28:35,161 : INFO : EPOCH 7: training on 99524 raw words (60518 effective words) took 0.1s, 455518 effective words/s\n",
      "2023-12-06 15:28:35,296 : INFO : EPOCH 8: training on 99524 raw words (60300 effective words) took 0.1s, 461702 effective words/s\n",
      "2023-12-06 15:28:35,432 : INFO : EPOCH 9: training on 99524 raw words (60457 effective words) took 0.1s, 459703 effective words/s\n",
      "2023-12-06 15:28:35,566 : INFO : EPOCH 10: training on 99524 raw words (60348 effective words) took 0.1s, 462526 effective words/s\n",
      "2023-12-06 15:28:35,721 : INFO : EPOCH 11: training on 99524 raw words (60492 effective words) took 0.1s, 404105 effective words/s\n",
      "2023-12-06 15:28:35,857 : INFO : EPOCH 12: training on 99524 raw words (60455 effective words) took 0.1s, 461372 effective words/s\n",
      "2023-12-06 15:28:35,992 : INFO : EPOCH 13: training on 99524 raw words (60278 effective words) took 0.1s, 457447 effective words/s\n",
      "2023-12-06 15:28:36,131 : INFO : EPOCH 14: training on 99524 raw words (60414 effective words) took 0.1s, 452105 effective words/s\n",
      "2023-12-06 15:28:36,284 : INFO : EPOCH 15: training on 99524 raw words (60327 effective words) took 0.1s, 404548 effective words/s\n",
      "2023-12-06 15:28:36,421 : INFO : EPOCH 16: training on 99524 raw words (60509 effective words) took 0.1s, 455244 effective words/s\n",
      "2023-12-06 15:28:36,558 : INFO : EPOCH 17: training on 99524 raw words (60361 effective words) took 0.1s, 456807 effective words/s\n",
      "2023-12-06 15:28:36,693 : INFO : EPOCH 18: training on 99524 raw words (60295 effective words) took 0.1s, 457793 effective words/s\n",
      "2023-12-06 15:28:36,831 : INFO : EPOCH 19: training on 99524 raw words (60467 effective words) took 0.1s, 452037 effective words/s\n",
      "2023-12-06 15:28:36,984 : INFO : EPOCH 20: training on 99524 raw words (60280 effective words) took 0.1s, 405236 effective words/s\n",
      "2023-12-06 15:28:37,111 : INFO : EPOCH 21: training on 99524 raw words (60342 effective words) took 0.1s, 493959 effective words/s\n",
      "2023-12-06 15:28:37,247 : INFO : EPOCH 22: training on 99524 raw words (60523 effective words) took 0.1s, 461358 effective words/s\n",
      "2023-12-06 15:28:37,382 : INFO : EPOCH 23: training on 99524 raw words (60492 effective words) took 0.1s, 458513 effective words/s\n",
      "2023-12-06 15:28:37,539 : INFO : EPOCH 24: training on 99524 raw words (60461 effective words) took 0.2s, 396553 effective words/s\n",
      "2023-12-06 15:28:37,677 : INFO : EPOCH 25: training on 99524 raw words (60400 effective words) took 0.1s, 454603 effective words/s\n",
      "2023-12-06 15:28:37,815 : INFO : EPOCH 26: training on 99524 raw words (60634 effective words) took 0.1s, 451775 effective words/s\n",
      "2023-12-06 15:28:37,952 : INFO : EPOCH 27: training on 99524 raw words (60607 effective words) took 0.1s, 459566 effective words/s\n",
      "2023-12-06 15:28:38,086 : INFO : EPOCH 28: training on 99524 raw words (60295 effective words) took 0.1s, 462255 effective words/s\n",
      "2023-12-06 15:28:38,241 : INFO : EPOCH 29: training on 99524 raw words (60433 effective words) took 0.2s, 399031 effective words/s\n",
      "2023-12-06 15:28:38,242 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1812296 effective words) took 4.2s, 427511 effective words/s', 'datetime': '2023-12-06T15:28:38.242967', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:28:38,243 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:28:38.243963', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 99%|| 481/486 [1:14:59<00:31,  6.40s/it]2023-12-06 15:28:41,218 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:28:41,219 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:28:41,240 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:28:41,241 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:28:41,246 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:28:41.246327', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:28:41,246 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:28:41.246327', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:28:41,251 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:28:41,251 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:28:41,252 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:28:41.251843', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:28:41,259 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:28:41,259 : INFO : resetting layer weights\n",
      "2023-12-06 15:28:41,264 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:28:41.264359', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:28:41,389 : INFO : EPOCH 0: training on 99524 raw words (60331 effective words) took 0.1s, 497780 effective words/s\n",
      "2023-12-06 15:28:41,544 : INFO : EPOCH 1: training on 99524 raw words (60465 effective words) took 0.2s, 397473 effective words/s\n",
      "2023-12-06 15:28:41,706 : INFO : EPOCH 2: training on 99524 raw words (60245 effective words) took 0.2s, 387838 effective words/s\n",
      "2023-12-06 15:28:41,842 : INFO : EPOCH 3: training on 99524 raw words (60313 effective words) took 0.1s, 455803 effective words/s\n",
      "2023-12-06 15:28:41,982 : INFO : EPOCH 4: training on 99524 raw words (60460 effective words) took 0.1s, 448392 effective words/s\n",
      "2023-12-06 15:28:42,120 : INFO : EPOCH 5: training on 99524 raw words (60345 effective words) took 0.1s, 454466 effective words/s\n",
      "2023-12-06 15:28:42,255 : INFO : EPOCH 6: training on 99524 raw words (60377 effective words) took 0.1s, 460029 effective words/s\n",
      "2023-12-06 15:28:42,418 : INFO : EPOCH 7: training on 99524 raw words (60438 effective words) took 0.2s, 380545 effective words/s\n",
      "2023-12-06 15:28:42,564 : INFO : EPOCH 8: training on 99524 raw words (60351 effective words) took 0.1s, 427097 effective words/s\n",
      "2023-12-06 15:28:42,710 : INFO : EPOCH 9: training on 99524 raw words (60399 effective words) took 0.1s, 428126 effective words/s\n",
      "2023-12-06 15:28:42,845 : INFO : EPOCH 10: training on 99524 raw words (60248 effective words) took 0.1s, 459550 effective words/s\n",
      "2023-12-06 15:28:42,983 : INFO : EPOCH 11: training on 99524 raw words (60420 effective words) took 0.1s, 451999 effective words/s\n",
      "2023-12-06 15:28:43,152 : INFO : EPOCH 12: training on 99524 raw words (60379 effective words) took 0.2s, 366535 effective words/s\n",
      "2023-12-06 15:28:43,288 : INFO : EPOCH 13: training on 99524 raw words (60440 effective words) took 0.1s, 458651 effective words/s\n",
      "2023-12-06 15:28:43,426 : INFO : EPOCH 14: training on 99524 raw words (60337 effective words) took 0.1s, 450066 effective words/s\n",
      "2023-12-06 15:28:43,565 : INFO : EPOCH 15: training on 99524 raw words (60456 effective words) took 0.1s, 450726 effective words/s\n",
      "2023-12-06 15:28:43,720 : INFO : EPOCH 16: training on 99524 raw words (60351 effective words) took 0.2s, 400742 effective words/s\n",
      "2023-12-06 15:28:43,857 : INFO : EPOCH 17: training on 99524 raw words (60409 effective words) took 0.1s, 451332 effective words/s\n",
      "2023-12-06 15:28:43,994 : INFO : EPOCH 18: training on 99524 raw words (60315 effective words) took 0.1s, 453559 effective words/s\n",
      "2023-12-06 15:28:44,144 : INFO : EPOCH 19: training on 99524 raw words (60472 effective words) took 0.1s, 420212 effective words/s\n",
      "2023-12-06 15:28:44,286 : INFO : EPOCH 20: training on 99524 raw words (60481 effective words) took 0.1s, 439053 effective words/s\n",
      "2023-12-06 15:28:44,448 : INFO : EPOCH 21: training on 99524 raw words (60447 effective words) took 0.2s, 384228 effective words/s\n",
      "2023-12-06 15:28:44,584 : INFO : EPOCH 22: training on 99524 raw words (60396 effective words) took 0.1s, 457205 effective words/s\n",
      "2023-12-06 15:28:44,732 : INFO : EPOCH 23: training on 99524 raw words (60426 effective words) took 0.1s, 422102 effective words/s\n",
      "2023-12-06 15:28:44,869 : INFO : EPOCH 24: training on 99524 raw words (60371 effective words) took 0.1s, 452889 effective words/s\n",
      "2023-12-06 15:28:45,004 : INFO : EPOCH 25: training on 99524 raw words (60291 effective words) took 0.1s, 458229 effective words/s\n",
      "2023-12-06 15:28:45,165 : INFO : EPOCH 26: training on 99524 raw words (60469 effective words) took 0.2s, 387727 effective words/s\n",
      "2023-12-06 15:28:45,303 : INFO : EPOCH 27: training on 99524 raw words (60500 effective words) took 0.1s, 453433 effective words/s\n",
      "2023-12-06 15:28:45,430 : INFO : EPOCH 28: training on 99524 raw words (60321 effective words) took 0.1s, 487926 effective words/s\n",
      "2023-12-06 15:28:45,572 : INFO : EPOCH 29: training on 99524 raw words (60538 effective words) took 0.1s, 440347 effective words/s\n",
      "2023-12-06 15:28:45,573 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811791 effective words) took 4.3s, 420491 effective words/s', 'datetime': '2023-12-06T15:28:45.573645', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:28:45,574 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:28:45.574644', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 99%|| 482/486 [1:15:07<00:26,  6.73s/it]2023-12-06 15:28:48,733 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:28:48,733 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:28:48,754 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:28:48,754 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:28:48,759 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:28:48.759303', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:28:48,759 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:28:48.759806', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:28:48,764 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:28:48,764 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:28:48,765 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:28:48.765468', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:28:48,771 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:28:48,772 : INFO : resetting layer weights\n",
      "2023-12-06 15:28:48,776 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:28:48.776796', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:28:48,901 : INFO : EPOCH 0: training on 99524 raw words (60321 effective words) took 0.1s, 498660 effective words/s\n",
      "2023-12-06 15:28:49,063 : INFO : EPOCH 1: training on 99524 raw words (60432 effective words) took 0.2s, 381286 effective words/s\n",
      "2023-12-06 15:28:49,238 : INFO : EPOCH 2: training on 99524 raw words (60349 effective words) took 0.2s, 355961 effective words/s\n",
      "2023-12-06 15:28:49,381 : INFO : EPOCH 3: training on 99524 raw words (60322 effective words) took 0.1s, 437612 effective words/s\n",
      "2023-12-06 15:28:49,520 : INFO : EPOCH 4: training on 99524 raw words (60348 effective words) took 0.1s, 444494 effective words/s\n",
      "2023-12-06 15:28:49,660 : INFO : EPOCH 5: training on 99524 raw words (60402 effective words) took 0.1s, 446955 effective words/s\n",
      "2023-12-06 15:28:49,801 : INFO : EPOCH 6: training on 99524 raw words (60353 effective words) took 0.1s, 443353 effective words/s\n",
      "2023-12-06 15:28:49,960 : INFO : EPOCH 7: training on 99524 raw words (60508 effective words) took 0.2s, 390924 effective words/s\n",
      "2023-12-06 15:28:50,098 : INFO : EPOCH 8: training on 99524 raw words (60382 effective words) took 0.1s, 448644 effective words/s\n",
      "2023-12-06 15:28:50,237 : INFO : EPOCH 9: training on 99524 raw words (60310 effective words) took 0.1s, 448876 effective words/s\n",
      "2023-12-06 15:28:50,376 : INFO : EPOCH 10: training on 99524 raw words (60318 effective words) took 0.1s, 449398 effective words/s\n",
      "2023-12-06 15:28:50,523 : INFO : EPOCH 11: training on 99524 raw words (60339 effective words) took 0.1s, 426161 effective words/s\n",
      "2023-12-06 15:28:50,703 : INFO : EPOCH 12: training on 99524 raw words (60362 effective words) took 0.2s, 342638 effective words/s\n",
      "2023-12-06 15:28:50,841 : INFO : EPOCH 13: training on 99524 raw words (60500 effective words) took 0.1s, 461149 effective words/s\n",
      "2023-12-06 15:28:50,991 : INFO : EPOCH 14: training on 99524 raw words (60483 effective words) took 0.1s, 411592 effective words/s\n",
      "2023-12-06 15:28:51,129 : INFO : EPOCH 15: training on 99524 raw words (60233 effective words) took 0.1s, 455215 effective words/s\n",
      "2023-12-06 15:28:51,270 : INFO : EPOCH 16: training on 99524 raw words (60291 effective words) took 0.1s, 436526 effective words/s\n",
      "2023-12-06 15:28:51,432 : INFO : EPOCH 17: training on 99524 raw words (60246 effective words) took 0.2s, 380776 effective words/s\n",
      "2023-12-06 15:28:51,574 : INFO : EPOCH 18: training on 99524 raw words (60342 effective words) took 0.1s, 440823 effective words/s\n",
      "2023-12-06 15:28:51,712 : INFO : EPOCH 19: training on 99524 raw words (60413 effective words) took 0.1s, 452496 effective words/s\n",
      "2023-12-06 15:28:51,849 : INFO : EPOCH 20: training on 99524 raw words (60350 effective words) took 0.1s, 452822 effective words/s\n",
      "2023-12-06 15:28:51,989 : INFO : EPOCH 21: training on 99524 raw words (60448 effective words) took 0.1s, 448050 effective words/s\n",
      "2023-12-06 15:28:52,154 : INFO : EPOCH 22: training on 99524 raw words (60437 effective words) took 0.2s, 375284 effective words/s\n",
      "2023-12-06 15:28:52,300 : INFO : EPOCH 23: training on 99524 raw words (60515 effective words) took 0.1s, 430341 effective words/s\n",
      "2023-12-06 15:28:52,427 : INFO : EPOCH 24: training on 99524 raw words (60305 effective words) took 0.1s, 490775 effective words/s\n",
      "2023-12-06 15:28:52,564 : INFO : EPOCH 25: training on 99524 raw words (60375 effective words) took 0.1s, 452767 effective words/s\n",
      "2023-12-06 15:28:52,722 : INFO : EPOCH 26: training on 99524 raw words (60527 effective words) took 0.2s, 396492 effective words/s\n",
      "2023-12-06 15:28:52,860 : INFO : EPOCH 27: training on 99524 raw words (60671 effective words) took 0.1s, 451322 effective words/s\n",
      "2023-12-06 15:28:52,998 : INFO : EPOCH 28: training on 99524 raw words (60456 effective words) took 0.1s, 452403 effective words/s\n",
      "2023-12-06 15:28:53,142 : INFO : EPOCH 29: training on 99524 raw words (60285 effective words) took 0.1s, 429844 effective words/s\n",
      "2023-12-06 15:28:53,144 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2985720 raw words (1811623 effective words) took 4.4s, 414871 effective words/s', 'datetime': '2023-12-06T15:28:53.144018', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:28:53,144 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:28:53.144018', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      " 99%|| 483/486 [1:15:15<00:21,  7.03s/it]2023-12-06 15:28:56,475 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:28:56,476 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:28:56,497 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:28:56,498 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:28:56,503 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:28:56.503639', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:28:56,503 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:28:56.503639', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:28:56,508 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:28:56,508 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:28:56,509 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:28:56.509841', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:28:56,515 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:28:56,516 : INFO : resetting layer weights\n",
      "2023-12-06 15:28:56,521 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:28:56.521873', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:28:56,646 : INFO : EPOCH 0: training on 99524 raw words (60309 effective words) took 0.1s, 500694 effective words/s\n",
      "2023-12-06 15:28:56,829 : INFO : EPOCH 1: training on 99524 raw words (60453 effective words) took 0.2s, 337178 effective words/s\n",
      "2023-12-06 15:28:57,007 : INFO : EPOCH 2: training on 99524 raw words (60398 effective words) took 0.2s, 358550 effective words/s\n",
      "2023-12-06 15:28:57,145 : INFO : EPOCH 3: training on 99524 raw words (60258 effective words) took 0.1s, 450149 effective words/s\n",
      "2023-12-06 15:28:57,281 : INFO : EPOCH 4: training on 99524 raw words (60295 effective words) took 0.1s, 455286 effective words/s\n",
      "2023-12-06 15:28:57,419 : INFO : EPOCH 5: training on 99524 raw words (60419 effective words) took 0.1s, 452209 effective words/s\n",
      "2023-12-06 15:28:57,554 : INFO : EPOCH 6: training on 99524 raw words (60342 effective words) took 0.1s, 465352 effective words/s\n",
      "2023-12-06 15:28:57,699 : INFO : EPOCH 7: training on 99524 raw words (60505 effective words) took 0.1s, 426805 effective words/s\n",
      "2023-12-06 15:28:57,836 : INFO : EPOCH 8: training on 99524 raw words (60458 effective words) took 0.1s, 456968 effective words/s\n",
      "2023-12-06 15:28:57,972 : INFO : EPOCH 9: training on 99524 raw words (60446 effective words) took 0.1s, 460635 effective words/s\n",
      "2023-12-06 15:28:58,105 : INFO : EPOCH 10: training on 99524 raw words (60344 effective words) took 0.1s, 467462 effective words/s\n",
      "2023-12-06 15:28:58,262 : INFO : EPOCH 11: training on 99524 raw words (60416 effective words) took 0.2s, 393612 effective words/s\n",
      "2023-12-06 15:28:58,403 : INFO : EPOCH 12: training on 99524 raw words (60413 effective words) took 0.1s, 446738 effective words/s\n",
      "2023-12-06 15:28:58,543 : INFO : EPOCH 13: training on 99524 raw words (60423 effective words) took 0.1s, 444544 effective words/s\n",
      "2023-12-06 15:28:58,712 : INFO : EPOCH 14: training on 99524 raw words (60446 effective words) took 0.2s, 368532 effective words/s\n",
      "2023-12-06 15:28:58,856 : INFO : EPOCH 15: training on 99524 raw words (60315 effective words) took 0.1s, 431459 effective words/s\n",
      "2023-12-06 15:28:58,994 : INFO : EPOCH 16: training on 99524 raw words (60312 effective words) took 0.1s, 454130 effective words/s\n",
      "2023-12-06 15:28:59,122 : INFO : EPOCH 17: training on 99524 raw words (60399 effective words) took 0.1s, 486238 effective words/s\n",
      "2023-12-06 15:28:59,257 : INFO : EPOCH 18: training on 99524 raw words (60244 effective words) took 0.1s, 463329 effective words/s\n",
      "2023-12-06 15:28:59,392 : INFO : EPOCH 19: training on 99524 raw words (60437 effective words) took 0.1s, 463916 effective words/s\n",
      "2023-12-06 15:28:59,544 : INFO : EPOCH 20: training on 99524 raw words (60520 effective words) took 0.1s, 407442 effective words/s\n",
      "2023-12-06 15:28:59,679 : INFO : EPOCH 21: training on 99524 raw words (60362 effective words) took 0.1s, 461631 effective words/s\n",
      "2023-12-06 15:28:59,818 : INFO : EPOCH 22: training on 99524 raw words (60453 effective words) took 0.1s, 449616 effective words/s\n",
      "2023-12-06 15:28:59,980 : INFO : EPOCH 23: training on 99524 raw words (60484 effective words) took 0.2s, 381930 effective words/s\n",
      "2023-12-06 15:29:00,124 : INFO : EPOCH 24: training on 99524 raw words (60494 effective words) took 0.1s, 436333 effective words/s\n",
      "2023-12-06 15:29:00,275 : INFO : EPOCH 25: training on 99524 raw words (60466 effective words) took 0.1s, 412057 effective words/s\n",
      "2023-12-06 15:29:00,412 : INFO : EPOCH 26: training on 99524 raw words (60559 effective words) took 0.1s, 455585 effective words/s\n",
      "2023-12-06 15:29:00,551 : INFO : EPOCH 27: training on 99524 raw words (60531 effective words) took 0.1s, 447628 effective words/s\n",
      "2023-12-06 15:29:00,692 : INFO : EPOCH 28: training on 99524 raw words (60476 effective words) took 0.1s, 446207 effective words/s\n",
      "2023-12-06 15:29:00,827 : INFO : EPOCH 29: training on 99524 raw words (60315 effective words) took 0.1s, 458523 effective words/s\n",
      "2023-12-06 15:29:00,992 : INFO : EPOCH 30: training on 99524 raw words (60239 effective words) took 0.2s, 375515 effective words/s\n",
      "2023-12-06 15:29:01,129 : INFO : EPOCH 31: training on 99524 raw words (60376 effective words) took 0.1s, 451464 effective words/s\n",
      "2023-12-06 15:29:01,263 : INFO : EPOCH 32: training on 99524 raw words (60491 effective words) took 0.1s, 468409 effective words/s\n",
      "2023-12-06 15:29:01,399 : INFO : EPOCH 33: training on 99524 raw words (60487 effective words) took 0.1s, 459544 effective words/s\n",
      "2023-12-06 15:29:01,538 : INFO : EPOCH 34: training on 99524 raw words (60350 effective words) took 0.1s, 447919 effective words/s\n",
      "2023-12-06 15:29:01,702 : INFO : EPOCH 35: training on 99524 raw words (60443 effective words) took 0.2s, 377998 effective words/s\n",
      "2023-12-06 15:29:01,838 : INFO : EPOCH 36: training on 99524 raw words (60453 effective words) took 0.1s, 461548 effective words/s\n",
      "2023-12-06 15:29:01,976 : INFO : EPOCH 37: training on 99524 raw words (60383 effective words) took 0.1s, 448451 effective words/s\n",
      "2023-12-06 15:29:02,112 : INFO : EPOCH 38: training on 99524 raw words (60274 effective words) took 0.1s, 460913 effective words/s\n",
      "2023-12-06 15:29:02,270 : INFO : EPOCH 39: training on 99524 raw words (60288 effective words) took 0.2s, 390056 effective words/s\n",
      "2023-12-06 15:29:02,406 : INFO : EPOCH 40: training on 99524 raw words (60235 effective words) took 0.1s, 458171 effective words/s\n",
      "2023-12-06 15:29:02,543 : INFO : EPOCH 41: training on 99524 raw words (60550 effective words) took 0.1s, 457815 effective words/s\n",
      "2023-12-06 15:29:02,679 : INFO : EPOCH 42: training on 99524 raw words (60337 effective words) took 0.1s, 456161 effective words/s\n",
      "2023-12-06 15:29:02,834 : INFO : EPOCH 43: training on 99524 raw words (60446 effective words) took 0.1s, 403267 effective words/s\n",
      "2023-12-06 15:29:02,970 : INFO : EPOCH 44: training on 99524 raw words (60319 effective words) took 0.1s, 456027 effective words/s\n",
      "2023-12-06 15:29:03,113 : INFO : EPOCH 45: training on 99524 raw words (60355 effective words) took 0.1s, 436507 effective words/s\n",
      "2023-12-06 15:29:03,248 : INFO : EPOCH 46: training on 99524 raw words (60409 effective words) took 0.1s, 461485 effective words/s\n",
      "2023-12-06 15:29:03,384 : INFO : EPOCH 47: training on 99524 raw words (60353 effective words) took 0.1s, 456929 effective words/s\n",
      "2023-12-06 15:29:03,542 : INFO : EPOCH 48: training on 99524 raw words (60556 effective words) took 0.2s, 393240 effective words/s\n",
      "2023-12-06 15:29:03,679 : INFO : EPOCH 49: training on 99524 raw words (60485 effective words) took 0.1s, 455493 effective words/s\n",
      "2023-12-06 15:29:03,681 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3020121 effective words) took 7.2s, 421866 effective words/s', 'datetime': '2023-12-06T15:29:03.681054', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:29:03,682 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n5,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:29:03.682174', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "100%|| 484/486 [1:15:25<00:16,  8.08s/it]2023-12-06 15:29:06,985 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:29:06,986 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:29:07,006 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:29:07,007 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:29:07,011 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:29:07.011538', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:29:07,012 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:29:07.012665', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:29:07,016 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:29:07,017 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:29:07,017 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:29:07.017479', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:29:07,024 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:29:07,024 : INFO : resetting layer weights\n",
      "2023-12-06 15:29:07,028 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:29:07.028478', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:29:07,154 : INFO : EPOCH 0: training on 99524 raw words (60289 effective words) took 0.1s, 494445 effective words/s\n",
      "2023-12-06 15:29:07,323 : INFO : EPOCH 1: training on 99524 raw words (60377 effective words) took 0.2s, 366974 effective words/s\n",
      "2023-12-06 15:29:07,491 : INFO : EPOCH 2: training on 99524 raw words (60329 effective words) took 0.2s, 371012 effective words/s\n",
      "2023-12-06 15:29:07,631 : INFO : EPOCH 3: training on 99524 raw words (60444 effective words) took 0.1s, 452329 effective words/s\n",
      "2023-12-06 15:29:07,767 : INFO : EPOCH 4: training on 99524 raw words (60289 effective words) took 0.1s, 453408 effective words/s\n",
      "2023-12-06 15:29:07,908 : INFO : EPOCH 5: training on 99524 raw words (60311 effective words) took 0.1s, 445367 effective words/s\n",
      "2023-12-06 15:29:08,047 : INFO : EPOCH 6: training on 99524 raw words (60361 effective words) took 0.1s, 451044 effective words/s\n",
      "2023-12-06 15:29:08,210 : INFO : EPOCH 7: training on 99524 raw words (60338 effective words) took 0.2s, 380282 effective words/s\n",
      "2023-12-06 15:29:08,348 : INFO : EPOCH 8: training on 99524 raw words (60479 effective words) took 0.1s, 451554 effective words/s\n",
      "2023-12-06 15:29:08,485 : INFO : EPOCH 9: training on 99524 raw words (60370 effective words) took 0.1s, 453100 effective words/s\n",
      "2023-12-06 15:29:08,622 : INFO : EPOCH 10: training on 99524 raw words (60397 effective words) took 0.1s, 458331 effective words/s\n",
      "2023-12-06 15:29:08,780 : INFO : EPOCH 11: training on 99524 raw words (60425 effective words) took 0.2s, 389971 effective words/s\n",
      "2023-12-06 15:29:08,921 : INFO : EPOCH 12: training on 99524 raw words (60423 effective words) took 0.1s, 445469 effective words/s\n",
      "2023-12-06 15:29:09,055 : INFO : EPOCH 13: training on 99524 raw words (60430 effective words) took 0.1s, 462797 effective words/s\n",
      "2023-12-06 15:29:09,193 : INFO : EPOCH 14: training on 99524 raw words (60436 effective words) took 0.1s, 454495 effective words/s\n",
      "2023-12-06 15:29:09,329 : INFO : EPOCH 15: training on 99524 raw words (60393 effective words) took 0.1s, 457682 effective words/s\n",
      "2023-12-06 15:29:09,486 : INFO : EPOCH 16: training on 99524 raw words (60322 effective words) took 0.2s, 396807 effective words/s\n",
      "2023-12-06 15:29:09,624 : INFO : EPOCH 17: training on 99524 raw words (60481 effective words) took 0.1s, 453355 effective words/s\n",
      "2023-12-06 15:29:09,761 : INFO : EPOCH 18: training on 99524 raw words (60284 effective words) took 0.1s, 454930 effective words/s\n",
      "2023-12-06 15:29:09,896 : INFO : EPOCH 19: training on 99524 raw words (60468 effective words) took 0.1s, 461938 effective words/s\n",
      "2023-12-06 15:29:10,033 : INFO : EPOCH 20: training on 99524 raw words (60321 effective words) took 0.1s, 454835 effective words/s\n",
      "2023-12-06 15:29:10,195 : INFO : EPOCH 21: training on 99524 raw words (60392 effective words) took 0.2s, 392384 effective words/s\n",
      "2023-12-06 15:29:10,330 : INFO : EPOCH 22: training on 99524 raw words (60584 effective words) took 0.1s, 462214 effective words/s\n",
      "2023-12-06 15:29:10,460 : INFO : EPOCH 23: training on 99524 raw words (60387 effective words) took 0.1s, 483650 effective words/s\n",
      "2023-12-06 15:29:10,596 : INFO : EPOCH 24: training on 99524 raw words (60313 effective words) took 0.1s, 456444 effective words/s\n",
      "2023-12-06 15:29:10,731 : INFO : EPOCH 25: training on 99524 raw words (60294 effective words) took 0.1s, 459798 effective words/s\n",
      "2023-12-06 15:29:10,890 : INFO : EPOCH 26: training on 99524 raw words (60386 effective words) took 0.2s, 389938 effective words/s\n",
      "2023-12-06 15:29:11,035 : INFO : EPOCH 27: training on 99524 raw words (60488 effective words) took 0.1s, 431709 effective words/s\n",
      "2023-12-06 15:29:11,163 : INFO : EPOCH 28: training on 99524 raw words (60456 effective words) took 0.1s, 490942 effective words/s\n",
      "2023-12-06 15:29:11,299 : INFO : EPOCH 29: training on 99524 raw words (60322 effective words) took 0.1s, 456227 effective words/s\n",
      "2023-12-06 15:29:11,463 : INFO : EPOCH 30: training on 99524 raw words (60315 effective words) took 0.2s, 376479 effective words/s\n",
      "2023-12-06 15:29:11,599 : INFO : EPOCH 31: training on 99524 raw words (60451 effective words) took 0.1s, 463473 effective words/s\n",
      "2023-12-06 15:29:11,733 : INFO : EPOCH 32: training on 99524 raw words (60470 effective words) took 0.1s, 463655 effective words/s\n",
      "2023-12-06 15:29:11,876 : INFO : EPOCH 33: training on 99524 raw words (60566 effective words) took 0.1s, 439175 effective words/s\n",
      "2023-12-06 15:29:12,043 : INFO : EPOCH 34: training on 99524 raw words (60606 effective words) took 0.2s, 370684 effective words/s\n",
      "2023-12-06 15:29:12,181 : INFO : EPOCH 35: training on 99524 raw words (60572 effective words) took 0.1s, 454820 effective words/s\n",
      "2023-12-06 15:29:12,318 : INFO : EPOCH 36: training on 99524 raw words (60444 effective words) took 0.1s, 455547 effective words/s\n",
      "2023-12-06 15:29:12,453 : INFO : EPOCH 37: training on 99524 raw words (60325 effective words) took 0.1s, 459742 effective words/s\n",
      "2023-12-06 15:29:12,602 : INFO : EPOCH 38: training on 99524 raw words (60373 effective words) took 0.1s, 415844 effective words/s\n",
      "2023-12-06 15:29:12,744 : INFO : EPOCH 39: training on 99524 raw words (60203 effective words) took 0.1s, 437431 effective words/s\n",
      "2023-12-06 15:29:12,881 : INFO : EPOCH 40: training on 99524 raw words (60341 effective words) took 0.1s, 454139 effective words/s\n",
      "2023-12-06 15:29:13,018 : INFO : EPOCH 41: training on 99524 raw words (60526 effective words) took 0.1s, 456732 effective words/s\n",
      "2023-12-06 15:29:13,158 : INFO : EPOCH 42: training on 99524 raw words (60409 effective words) took 0.1s, 442649 effective words/s\n",
      "2023-12-06 15:29:13,303 : INFO : EPOCH 43: training on 99524 raw words (60514 effective words) took 0.1s, 430983 effective words/s\n",
      "2023-12-06 15:29:13,432 : INFO : EPOCH 44: training on 99524 raw words (60400 effective words) took 0.1s, 484394 effective words/s\n",
      "2023-12-06 15:29:13,568 : INFO : EPOCH 45: training on 99524 raw words (60407 effective words) took 0.1s, 457757 effective words/s\n",
      "2023-12-06 15:29:13,706 : INFO : EPOCH 46: training on 99524 raw words (60448 effective words) took 0.1s, 454212 effective words/s\n",
      "2023-12-06 15:29:13,844 : INFO : EPOCH 47: training on 99524 raw words (60338 effective words) took 0.1s, 453124 effective words/s\n",
      "2023-12-06 15:29:14,009 : INFO : EPOCH 48: training on 99524 raw words (60437 effective words) took 0.2s, 374881 effective words/s\n",
      "2023-12-06 15:29:14,144 : INFO : EPOCH 49: training on 99524 raw words (60531 effective words) took 0.1s, 462484 effective words/s\n",
      "2023-12-06 15:29:14,145 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3020265 effective words) took 7.1s, 424415 effective words/s', 'datetime': '2023-12-06T15:29:14.145802', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:29:14,146 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:29:14.146802', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "100%|| 485/486 [1:15:36<00:08,  8.90s/it]2023-12-06 15:29:17,799 : INFO : collecting all words and their counts\n",
      "2023-12-06 15:29:17,799 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 15:29:17,819 : INFO : collected 7125 word types and 4313 unique tags from a corpus of 4313 examples and 99524 words\n",
      "2023-12-06 15:29:17,820 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 15:29:17,823 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 retains 1231 unique words (17.28% of original 7125, drops 5894)', 'datetime': '2023-12-06T15:29:17.823614', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:29:17,825 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=9 leaves 86370 word corpus (86.78% of original 99524, drops 13154)', 'datetime': '2023-12-06T15:29:17.825013', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:29:17,829 : INFO : deleting the raw counts dictionary of 7125 items\n",
      "2023-12-06 15:29:17,831 : INFO : sample=0.001 downsamples 52 most-common words\n",
      "2023-12-06 15:29:17,831 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 56081.60853763763 word corpus (64.9%% of prior 86370)', 'datetime': '2023-12-06T15:29:17.831291', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 15:29:17,838 : INFO : estimated required memory for 1231 words and 200 dimensions: 6898100 bytes\n",
      "2023-12-06 15:29:17,839 : INFO : resetting layer weights\n",
      "2023-12-06 15:29:17,843 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 1231 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=15 window=10 shrink_windows=True', 'datetime': '2023-12-06T15:29:17.843729', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:29:17,968 : INFO : EPOCH 0: training on 99524 raw words (60418 effective words) took 0.1s, 501497 effective words/s\n",
      "2023-12-06 15:29:18,127 : INFO : EPOCH 1: training on 99524 raw words (60464 effective words) took 0.2s, 388312 effective words/s\n",
      "2023-12-06 15:29:18,290 : INFO : EPOCH 2: training on 99524 raw words (60365 effective words) took 0.2s, 384524 effective words/s\n",
      "2023-12-06 15:29:18,435 : INFO : EPOCH 3: training on 99524 raw words (60165 effective words) took 0.1s, 431352 effective words/s\n",
      "2023-12-06 15:29:18,576 : INFO : EPOCH 4: training on 99524 raw words (60263 effective words) took 0.1s, 443700 effective words/s\n",
      "2023-12-06 15:29:18,712 : INFO : EPOCH 5: training on 99524 raw words (60532 effective words) took 0.1s, 459295 effective words/s\n",
      "2023-12-06 15:29:18,876 : INFO : EPOCH 6: training on 99524 raw words (60382 effective words) took 0.2s, 379181 effective words/s\n",
      "2023-12-06 15:29:19,004 : INFO : EPOCH 7: training on 99524 raw words (60361 effective words) took 0.1s, 486121 effective words/s\n",
      "2023-12-06 15:29:19,132 : INFO : EPOCH 8: training on 99524 raw words (60359 effective words) took 0.1s, 489391 effective words/s\n",
      "2023-12-06 15:29:19,271 : INFO : EPOCH 9: training on 99524 raw words (60470 effective words) took 0.1s, 449936 effective words/s\n",
      "2023-12-06 15:29:19,434 : INFO : EPOCH 10: training on 99524 raw words (60379 effective words) took 0.2s, 377873 effective words/s\n",
      "2023-12-06 15:29:19,562 : INFO : EPOCH 11: training on 99524 raw words (60304 effective words) took 0.1s, 489062 effective words/s\n",
      "2023-12-06 15:29:19,691 : INFO : EPOCH 12: training on 99524 raw words (60507 effective words) took 0.1s, 486253 effective words/s\n",
      "2023-12-06 15:29:19,830 : INFO : EPOCH 13: training on 99524 raw words (60456 effective words) took 0.1s, 450949 effective words/s\n",
      "2023-12-06 15:29:19,966 : INFO : EPOCH 14: training on 99524 raw words (60443 effective words) took 0.1s, 455104 effective words/s\n",
      "2023-12-06 15:29:20,126 : INFO : EPOCH 15: training on 99524 raw words (60442 effective words) took 0.2s, 389082 effective words/s\n",
      "2023-12-06 15:29:20,254 : INFO : EPOCH 16: training on 99524 raw words (60337 effective words) took 0.1s, 486508 effective words/s\n",
      "2023-12-06 15:29:20,381 : INFO : EPOCH 17: training on 99524 raw words (60327 effective words) took 0.1s, 492930 effective words/s\n",
      "2023-12-06 15:29:20,518 : INFO : EPOCH 18: training on 99524 raw words (60506 effective words) took 0.1s, 456107 effective words/s\n",
      "2023-12-06 15:29:20,658 : INFO : EPOCH 19: training on 99524 raw words (60438 effective words) took 0.1s, 447446 effective words/s\n",
      "2023-12-06 15:29:20,804 : INFO : EPOCH 20: training on 99524 raw words (60391 effective words) took 0.1s, 423590 effective words/s\n",
      "2023-12-06 15:29:20,940 : INFO : EPOCH 21: training on 99524 raw words (60508 effective words) took 0.1s, 459657 effective words/s\n",
      "2023-12-06 15:29:21,096 : INFO : EPOCH 22: training on 99524 raw words (60483 effective words) took 0.2s, 398963 effective words/s\n",
      "2023-12-06 15:29:21,224 : INFO : EPOCH 23: training on 99524 raw words (60631 effective words) took 0.1s, 492685 effective words/s\n",
      "2023-12-06 15:29:21,367 : INFO : EPOCH 24: training on 99524 raw words (60531 effective words) took 0.1s, 438030 effective words/s\n",
      "2023-12-06 15:29:21,509 : INFO : EPOCH 25: training on 99524 raw words (60350 effective words) took 0.1s, 447740 effective words/s\n",
      "2023-12-06 15:29:21,655 : INFO : EPOCH 26: training on 99524 raw words (60394 effective words) took 0.1s, 428378 effective words/s\n",
      "2023-12-06 15:29:21,782 : INFO : EPOCH 27: training on 99524 raw words (60585 effective words) took 0.1s, 491644 effective words/s\n",
      "2023-12-06 15:29:21,953 : INFO : EPOCH 28: training on 99524 raw words (60459 effective words) took 0.2s, 362693 effective words/s\n",
      "2023-12-06 15:29:22,091 : INFO : EPOCH 29: training on 99524 raw words (60526 effective words) took 0.1s, 451729 effective words/s\n",
      "2023-12-06 15:29:22,231 : INFO : EPOCH 30: training on 99524 raw words (60307 effective words) took 0.1s, 448032 effective words/s\n",
      "2023-12-06 15:29:22,379 : INFO : EPOCH 31: training on 99524 raw words (60463 effective words) took 0.1s, 418808 effective words/s\n",
      "2023-12-06 15:29:22,519 : INFO : EPOCH 32: training on 99524 raw words (60449 effective words) took 0.1s, 446260 effective words/s\n",
      "2023-12-06 15:29:22,678 : INFO : EPOCH 33: training on 99524 raw words (60291 effective words) took 0.2s, 390277 effective words/s\n",
      "2023-12-06 15:29:22,816 : INFO : EPOCH 34: training on 99524 raw words (60313 effective words) took 0.1s, 451274 effective words/s\n",
      "2023-12-06 15:29:22,952 : INFO : EPOCH 35: training on 99524 raw words (60512 effective words) took 0.1s, 458509 effective words/s\n",
      "2023-12-06 15:29:23,089 : INFO : EPOCH 36: training on 99524 raw words (60461 effective words) took 0.1s, 455962 effective words/s\n",
      "2023-12-06 15:29:23,226 : INFO : EPOCH 37: training on 99524 raw words (60369 effective words) took 0.1s, 455435 effective words/s\n",
      "2023-12-06 15:29:23,386 : INFO : EPOCH 38: training on 99524 raw words (60337 effective words) took 0.2s, 388980 effective words/s\n",
      "2023-12-06 15:29:23,525 : INFO : EPOCH 39: training on 99524 raw words (60401 effective words) took 0.1s, 448721 effective words/s\n",
      "2023-12-06 15:29:23,661 : INFO : EPOCH 40: training on 99524 raw words (60389 effective words) took 0.1s, 458134 effective words/s\n",
      "2023-12-06 15:29:23,796 : INFO : EPOCH 41: training on 99524 raw words (60491 effective words) took 0.1s, 460702 effective words/s\n",
      "2023-12-06 15:29:23,938 : INFO : EPOCH 42: training on 99524 raw words (60495 effective words) took 0.1s, 442508 effective words/s\n",
      "2023-12-06 15:29:24,103 : INFO : EPOCH 43: training on 99524 raw words (60576 effective words) took 0.2s, 377141 effective words/s\n",
      "2023-12-06 15:29:24,230 : INFO : EPOCH 44: training on 99524 raw words (60376 effective words) took 0.1s, 490008 effective words/s\n",
      "2023-12-06 15:29:24,367 : INFO : EPOCH 45: training on 99524 raw words (60343 effective words) took 0.1s, 456275 effective words/s\n",
      "2023-12-06 15:29:24,506 : INFO : EPOCH 46: training on 99524 raw words (60337 effective words) took 0.1s, 446970 effective words/s\n",
      "2023-12-06 15:29:24,645 : INFO : EPOCH 47: training on 99524 raw words (60334 effective words) took 0.1s, 448735 effective words/s\n",
      "2023-12-06 15:29:24,818 : INFO : EPOCH 48: training on 99524 raw words (60437 effective words) took 0.2s, 370016 effective words/s\n",
      "2023-12-06 15:29:24,955 : INFO : EPOCH 49: training on 99524 raw words (60492 effective words) took 0.1s, 452809 effective words/s\n",
      "2023-12-06 15:29:24,956 : INFO : Doc2Vec lifecycle event {'msg': 'training on 4976200 raw words (3020949 effective words) took 7.1s, 424715 effective words/s', 'datetime': '2023-12-06T15:29:24.956914', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 15:29:24,957 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n15,mc9,s0.001,t3>', 'datetime': '2023-12-06T15:29:24.957920', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n",
      "100%|| 486/486 [1:15:47<00:00,  9.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.99911195\n",
      "Best Parameters: {'vector_size': 200, 'dm': 0, 'window': 7, 'min_count': 5, 'epochs': 10, 'negative': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "best_score = 0\n",
    "best_params = None\n",
    "\n",
    "# Create all combinations of parameters\n",
    "param_combinations = [dict(zip(param_grid.keys(), v)) for v in product(*param_grid.values())]\n",
    "\n",
    "for params in tqdm(param_combinations):\n",
    "    score = train_evaluate_doc2vec(params, train_docs, test_docs, test_values)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = params\n",
    "\n",
    "print(\"Best Score:\", best_score)\n",
    "print(\"Best Parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the model with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_docs = [TaggedDocument(doc, [i]) for i, doc in enumerate(documents_with_bigrams)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 19:07:13,158 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow,d200,n10,mc5,s0.001,t3>', 'datetime': '2023-12-06T19:07:13.158389', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# implementing the model with the best configuration of parametes\n",
    "doc2vec_final = Doc2Vec(vector_size = 200,\n",
    "                    dm = 0, \n",
    "                    window = 7, \n",
    "                    min_count= 5, \n",
    "                    epochs= 10,\n",
    "                    negative = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 19:07:13,553 : INFO : collecting all words and their counts\n",
      "2023-12-06 19:07:13,553 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-12-06 19:07:13,573 : INFO : collected 7871 word types and 5392 unique tags from a corpus of 5392 examples and 124966 words\n",
      "2023-12-06 19:07:13,574 : INFO : Creating a fresh vocabulary\n",
      "2023-12-06 19:07:13,580 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 2275 unique words (28.90% of original 7871, drops 5596)', 'datetime': '2023-12-06T19:07:13.580047', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 19:07:13,581 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 115612 word corpus (92.51% of original 124966, drops 9354)', 'datetime': '2023-12-06T19:07:13.581048', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 19:07:13,589 : INFO : deleting the raw counts dictionary of 7871 items\n",
      "2023-12-06 19:07:13,590 : INFO : sample=0.001 downsamples 49 most-common words\n",
      "2023-12-06 19:07:13,590 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 78391.21413317196 word corpus (67.8%% of prior 115612)', 'datetime': '2023-12-06T19:07:13.590044', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'prepare_vocab'}\n",
      "2023-12-06 19:07:13,607 : INFO : estimated required memory for 2275 words and 200 dimensions: 10169500 bytes\n",
      "2023-12-06 19:07:13,608 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "# building the vocabulary\n",
    "doc2vec_final.build_vocab(tagged_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 19:07:13,901 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 2275 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=10 window=7 shrink_windows=True', 'datetime': '2023-12-06T19:07:13.901084', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n",
      "2023-12-06 19:07:14,059 : INFO : EPOCH 0: training on 124966 raw words (83737 effective words) took 0.2s, 544776 effective words/s\n",
      "2023-12-06 19:07:14,212 : INFO : EPOCH 1: training on 124966 raw words (83826 effective words) took 0.1s, 562677 effective words/s\n",
      "2023-12-06 19:07:14,364 : INFO : EPOCH 2: training on 124966 raw words (83706 effective words) took 0.1s, 567348 effective words/s\n",
      "2023-12-06 19:07:14,521 : INFO : EPOCH 3: training on 124966 raw words (83753 effective words) took 0.2s, 543556 effective words/s\n",
      "2023-12-06 19:07:14,676 : INFO : EPOCH 4: training on 124966 raw words (83718 effective words) took 0.2s, 553236 effective words/s\n",
      "2023-12-06 19:07:14,831 : INFO : EPOCH 5: training on 124966 raw words (83979 effective words) took 0.2s, 558419 effective words/s\n",
      "2023-12-06 19:07:14,993 : INFO : EPOCH 6: training on 124966 raw words (83715 effective words) took 0.2s, 528031 effective words/s\n",
      "2023-12-06 19:07:15,149 : INFO : EPOCH 7: training on 124966 raw words (83693 effective words) took 0.2s, 551073 effective words/s\n",
      "2023-12-06 19:07:15,303 : INFO : EPOCH 8: training on 124966 raw words (83641 effective words) took 0.2s, 555517 effective words/s\n",
      "2023-12-06 19:07:15,463 : INFO : EPOCH 9: training on 124966 raw words (83885 effective words) took 0.2s, 541621 effective words/s\n",
      "2023-12-06 19:07:15,464 : INFO : Doc2Vec lifecycle event {'msg': 'training on 1249660 raw words (837653 effective words) took 1.6s, 536070 effective words/s', 'datetime': '2023-12-06T19:07:15.464266', 'gensim': '4.3.1', 'python': '3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.22621-SP0', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "doc2vec_final.train(tagged_docs, total_examples=doc2vec_final.corpus_count, epochs=doc2vec_final.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r doc_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5392\n",
      "5392\n"
     ]
    }
   ],
   "source": [
    "# we make sure that the list of topic vectors and the list of document vectors have the same size\n",
    "print(len(doc_topics))\n",
    "print(len(tagged_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we transform the doc2vec object in a numpy array of vectors\n",
    "doc2vec_vec = []\n",
    "for i in range(len(tagged_docs)):\n",
    "    doc2vec_vec.append(doc2vec_final[i])\n",
    "\n",
    "doc2vec_vec = np.array(doc_topic_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5392"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can now concatenate the topic probability vectors and the doc2vec vectors for each document\n",
    "\n",
    "doc_topic_vec = np.array([np.concatenate([vec1, vec2]) for vec1, vec2 in zip(doc_topics, doc2vec_vec)])\n",
    "len(doc_topic_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'doc_topic_vec' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store doc_topic_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'labels_df' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store labels_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
